Random-access Memory (RAM; ) ist eine Art von Computerspeicher, die in jeder Reihenfolge gelesen und geändert werden kann, in der Regel zur Speicherung von Arbeitsdaten und Maschinencode verwendet werden. Ein Zufallsspeicher-Gerät ermöglicht es, Daten in nahezu derselben Menge zu lesen oder zu schreiben, unabhängig vom physischen Standort der Daten innerhalb des Gedächtnisses, im Gegensatz zu anderen direkt zugänglichen Datenspeichermedien (wie Festplatten, CD-RWs, DVD-RWs und die älteren Magnetbande und Verfälschungen), wo die Zeit, die erforderlich ist, um Datenmaterial zu lesen und zu schreiben, je nach den physischen Standorten im Aufzeichnungsmedium erheblich variieren kann, weil mechanische Beschränkungen wie z.B. Mediengeschwindigkeiten und -bewegungen bestehen. RAM enthält mehrerexing- und demultiplexierende Schaltkreise, um die Datenlinien an die angegangene Speicherung zu binden oder den Eintrag zu schreiben. In der Regel werden mehr als ein Teil der Lagerung von derselben Adresse genutzt, und RAM-Geräte verfügen oft über mehrere Datenlinien und werden als 8-bit oder 16-bit, usw. Geräte bezeichnet. In der heutigen Technologie erfolgt das zufällige Gedächtnis in Form integrierter Schaltkreise (IC) mit MOS (Metall-Oxide-Semiconduktor). RAM ist in der Regel mit volatilen Arten von Gedächtnis (wie dynamischen Zufallsspeicher-Modulen (DRAM) verbunden), wo gespeicherte Informationen verloren gehen, wenn die Macht entfernt wird, obwohl auch nicht-volatile RAM entwickelt wurde. Andere Arten von nicht-volatile-Speichern sind vorhanden, die einen zufälligen Zugang zu lesenden Vorgängen ermöglichen, aber entweder erlauben sie keine Abschreibungen oder haben andere Arten von Einschränkungen. Dazu zählen die meisten Arten von ROM und eine Art von Flashspeicher namens NOR-Flash. Die beiden Haupttypen des flüchtigen zufälligen zufälligen Halbleiterspeichers sind statisches Zufalls-Zugangsspeicher (SRAM) und dynamisches zufälliges zufälliges (DRAM). Kommerzielle Verwendungen von Halbleiter RAM bis 1965, als IBM den SP95® Chip für ihr System/360 Modell 95 Computer eingeführt hat, und Toshiba verwendete DRAM-Speicherzellen für seinen elektronischen Rechner für die 270l BC-1411, beide auf bipolaren Transistors. MOS-Speicher, basierend auf MOS-Transistoren, wurde in den späten 1960er Jahren entwickelt und ist seitdem die Grundlage für alle kommerziellen Halbleiterspeicher. Der erste kommerzielle DRAM IC Chip, der Intel 1103, wurde im Oktober 1970 eingeführt. Synchron dynamisches zufälliges Zufallsspeicher (SDRAM) später mit dem Samsung KM48SL2000 Chip im Jahr 1992. Frühcomputer benutzten Relais, mechanische Gegensätze oder Verzögerungslinien für die wichtigsten Speicherfunktionen. Ultrasonic verspätete Linien waren serielle Geräte, die nur Daten in der Reihenfolge, die sie geschrieben hatte, reproduzieren könnten. Trommelspeicher könnte zu relativ niedrigen Kosten erweitert werden, aber eine effiziente Rückgewinnung von Speichergütern erforderte das Wissen über die physische Gestaltung des Trommels, um die Geschwindigkeit zu optimieren. Latchen, die aus Vakuumröhren-Triodes gebaut wurden, und später wurden aus unabhängigen Transisten für kleinere und schnellere Speicher wie Register verwendet. Solche Register waren relativ groß und zu teuer, um große Datenmengen zu verwenden; in der Regel könnten nur ein paar Dutzend oder wenige hundert Bits solcher Speicher bereitgestellt werden. Die erste praktische Form des zufälligen Gedächtnisses war die Williamstube Anfang 1947. Sie gespeicherte Daten als Elektro-Gebühren vor einem Kathodenstrahlröhre. Da der Elektronenstrahl der CRT in jeder Reihenfolge die Flecken auf der Tube lesen und schreiben konnte, war das Gedächtnis zufällig. Die Kapazität des Williamsrohrs war ein paarhundert bis rund tausend Bits, aber es war viel kleiner, schneller und krafteffizienter als die Verwendung einzelner Vakuumröhren. In England entwickelte sich die Williams Tube, auf der das erste elektronisch gespeicherte Programm im Manchester Baby Computer umgesetzt wurde, das erstmals am 21. Juni 1948 erfolgreich lief. Konkret war das Baby eher ein Testbett, um die Zuverlässigkeit des Gedächtnisses zu demonstrieren. Magnetkernspeicher wurde 1947 entwickelt und bis Mitte der siebziger Jahre entwickelt. Es wurde zu einer weit verbreiteten Form des zufälligen Gedächtnisses, die auf einer Reihe von Magnetenringen basiert. Durch eine Änderung des Sinnes der Magnetisierung jedes Rings könnten Daten mit einem Bit pro Ring gespeichert werden. Da jeder Ring eine Kombination von Adresskabeln hatte, um ihn auszuwählen und zu lesen oder zu schreiben, war der Zugang zu jedem Speicherstandort in jeder Sequenz möglich. Magnetkernspeicher war die Standardform von Computerspeichersystemen, bis die Halbleiterspeicher in integrierten Schaltkreisen (ICs) in den frühen 1970er Jahren durch solide MOS (Metall-Oxide-silicon) vertrieben wurden. Vor der Entwicklung integrierter Lese-nur-Speicher (ROM)-Szenarios wurde häufig ein permanentes (oder reines) Random-Zugangsspeicher mit matrice Dioden gebaut, die von Decoders angetrieben werden, oder speziell Wundenkerne. Halbleiterspeicher begann in den 60er Jahren mit bipolarem Gedächtnis, das bipolare Transistors benutzte. Obwohl die Leistung verbessert wurde, konnte sie nicht mit dem niedrigeren Preis des Magnetkernspeichers konkurrieren. MOS RAM Die Erfindung des MOSFET (Metall-Oxide-Semiconduktor-Feld-Wirkungstransistor), auch bekannt als MOS transistor, von Mohamed M. Atalla und Dawon Kahng in Bell Labs 1959, führte zur Entwicklung von Metalloxide-Semiconduktor (MOS) Gedächtnis von John Schmidt bei Fairchild Semiconductor im Jahr 1964. Neben einer höheren Leistung war MOS Halbleiterspeicher billiger und verbrauchte weniger Strom als Magnetkernspeicher. Durch die Entwicklung von Silizium-Gates MOS integrierte Schaltkreise (MOS IC) von Federico Faggin bei Fairchild im Jahr 1968 konnten MOS-Speicherchips hergestellt werden. MOS-Speicher übertrow Magnetkernspeicher als beherrschende Speichertechnologie in den frühen 1970er Jahren. Im Jahr 1963 wurde ein integriertes bipolares statisches Zufallsspeicher (SRAM) von Robert H. Norman bei Fairchild Semiconductor entwickelt. Im Jahr 1964 folgte die Entwicklung von MOS Packard durch John Schmidt auf Fairchild. Turbine wurde zu einer Alternative zum Magnet-core-Speicher, benötigte jedoch sechs MOS-Transistors für jeden Teil der Daten. Kommerzielle Verwendung von Fujitsu begann 1965, als IBM den SP95 Speicherchip für das System/360 Modell 95 eingeführt hat. Dynamischer zufälliger Zufallsspeicher (DRAM) ermöglichte die Ersetzung eines 4 oder 6-transistor-Latchenkreises durch einen einzigen Transistor für jeden Speicher, der die Speicherdichte bei den Kosten der Volatilität erheblich erhöht. Daten wurden in der winzigen Kapazitätsauslastung jedes transistor gespeichert und mussten in regelmäßigen Abständen alle wenigen Milleniumsfrischer auffrischen, bevor die Abgabe abgeschaltet werden konnte. Toshibas Alpl BC-1411 elektronisches Rechner, das 1965 eingeführt wurde, nutzte eine Art von kapazitätsfördernden bipolaren DRAM, die 180-bit-Daten auf diskreten Speicherzellen speichern, bestehend aus bipolaren Transistoren und Kondensatoren. Obwohl er eine verbesserte Leistung über Magnetkernspeicher bot, konnte Bipolar DRAM nicht mit dem niedrigeren Preis des damals marktbeherrschenden Magnetkernspeichers konkurrieren. MOS-Technologie ist die Grundlage für moderne DRAM. 1966 arbeitete Dr. Robert H. Dennard am IBM Thomas J. Watson Research Center am MOS-Speicher. Während er die Merkmale der MOS-Technologie untersuchte, stellte er fest, dass es in der Lage war, Kondensatoren zu bauen, und dass die Lagerung einer Gebühr oder keiner Abgabe auf den MOS-Kondens die 1 und 0 eines Bits darstellen könnte, während der MOS-Transistor die Abgabe an den Kondensatoren kontrollieren könnte. Dies führte zu seiner Entwicklung einer einzigen DRAM-Speicherzelle. Im Jahr 1967 meldete die Firma Dennard ein Patent unter IBM für eine Single-Transistor DRAM-Speicherzelle auf der Grundlage der MOS-Technologie an. Der erste kommerzielle DRAM IC-Chip war der Intel 1103, der auf einem 8 μm MOS-Prozess mit einer Kapazität von 1 kbit hergestellt wurde und 1970 freigegeben wurde. Samsung Electronics wurde von Samsung Electronics entwickelt. Der erste kommerzielle SDRAM-Chip war der Samsung KM48SL2000, der eine Kapazität von 16 Mbit hatte. Es wurde 1992 von Samsung eingeführt und 1993 produziert. Die erste kommerzielle DDR SDRAM (doppelte Datenquote SDRAM) war Samsungs 64 Mbit DDR SDRAM Chip, der im Juni 1998 freigegeben wurde. GDDR (graphische DDR) ist eine Form der DDR SGRAM (synchronische Grafik RAM), die erstmals von Samsung als 16 Mbit-Speicherchip im Jahr 1998 freigegeben wurde. Art Die beiden weit verbreiteten Formen des modernen RAM sind statisches RAM (SRAM) und dynamisches RAM (DRAM). In kW wird ein Teil der Daten unter Verwendung des Stands einer sechstransistor-Speicherzelle gespeichert, die in der Regel sechs MOSFETs (Metall-Oxide-semiconduktor Feld-Effekt-Transistors) verwendet. Diese Form von RAM ist teurer, um zu produzieren, ist aber im Allgemeinen schneller und erfordert weniger Dynamik als DRAM. BMW wird in modernen Computern häufig als Speicher für die CPU verwendet. DRAM speichert ein paar Daten mit einem transistor- und Kondensatorenpaar (normalerweise ein MOSFET- und MOS-Kondens), das zusammen eine DRAM-zelle umfasst. Der Kondensator verfügt über eine hohe oder niedrige Gebühr (1 oder 0), und der Transistor fungiert als Schaltgang, der die Steuerungskreise auf dem Chip den Zustand der Belastung oder die Änderung des Inhalts des Kondensators widerspiegelt. Da diese Form des Gedächtnisses weniger teuer ist, um als statisches RAM zu produzieren, ist es die überwiegende Form des Computerspeichers in modernen Computern. Sowohl statisches als auch dynamisches RAM gelten als volatile, da ihr Staat verloren geht oder neu angesiedelt ist, wenn die Macht aus dem System entfernt wird. Lesen Sie hingegen nur Gedächtnis (ROM) speichert Daten, indem sie ausgewählten Transisten dauerhaft die Möglichkeit geben oder entziehen, so dass das Gedächtnis nicht verändert werden kann. Meldebare Varianten von ROM (wie EEPROM und Flashspeicher) teilen Eigenschaften sowohl der ROM als auch des RAM, so dass Daten ohne Macht aufrechterhalten und ohne besondere Ausrüstung aktualisiert werden können. Diese persistenten Formen von Halbleiter ROM umfassen USB-Flash-Laufwerke, Speicherkarten für Kameras und tragbare Geräte und feste Antriebe. ECC-Speicher (die entweder BMW oder DRAM sein kann) umfasst spezielle Schaltkreise zur Erkennung und/oder Berichtigung von Zufallsfehlern (memoryfehler) in den gespeicherten Daten unter Verwendung von Parity Bits oder Fehlerkorrekturcodes. Insgesamt bezieht sich der Begriff RAM ausschließlich auf solide Speichergeräte (entweder DRAM oder Fujitsu) und insbesondere auf das Hauptspeicher in den meisten Computern. In der optischen Lagerung ist der Begriff DVD-RAM etwas von einem Fehlwert, da es im Gegensatz zu CD-RW oder DVD-RW nicht vor der Wiederverwendung gelöscht werden muss. Jedoch funktioniert ein DVD-RAM viel wie eine harte Scheibe, wenn etwas langsamer. Gedächtniszelle Die Speicherzelle ist der grundlegende Baustein des Computerspeichers. Die Speicherzelle ist ein elektronischer Schaltkreis, der einen Teil von binären Informationen speichert und eine Logik 1 (hochspannungspegel) speichern und eine Logik 0 (niedrige Spannung) speichern muss. Ihr Wert wird beibehalten/ vermarktet, bis es durch den festgelegten/reset-Prozess geändert wird. Der Wert in der Speicherzelle ist durch Lesen zu verstehen. In Chrysler ist die Speicherzelle eine Art von Flip-Flo-Sender, in der Regel mit FETs implementiert. Dies bedeutet, dass Fujitsu sehr geringe Macht benötigt, wenn es nicht möglich ist, aber es ist teuer und hat eine niedrige Lagerdichte. DRAM basiert auf einem Kondensator. Erhebung und Entladung dieses Kondensators können eine 1 oder 0 in der Zelle speichern. Jedoch ist die Gebühr in diesem Kondensator langsam weggefallen und muss regelmäßig aktualisiert werden. DRAM nutzt aufgrund dieses Auffrischungsvorgangs mehr Macht, aber es kann größere Lagerdichten und niedrigere Stückkosten im Vergleich zu BMC erreichen. Adresse Um nützlich zu sein, müssen Speicherzellen lesbar und abgeschrieben werden. Innerhalb des RAM-Geräts werden Multiplexing und demultiplexierende Schaltkreise verwendet, um Speicherzellen auszuwählen. In der Regel verfügt ein RAM-Gerät über eine Reihe von Adressen A0... Ein und für jede Kombination von Bits, die auf diese Strecken angewendet werden können, werden eine Reihe von Speicherzellen aktiviert. RAM-Geräte verfügen praktisch immer über eine Speicherkapazität, die eine Kraft von zwei ist. In der Regel teilen mehrere Speicherzellen dieselbe Adresse. Beispielsweise verfügt ein 4 Bit breite RAM-Chip über 4 Speicherzellen für jede Adresse. Häufig ist die Breite des Gedächtnisses und des Mikroprozessor unterschiedlich, für einen 32 Bit-Mikroprozessor würden acht 4 Bit RAM-Chips benötigt. Häufig werden mehr Adressen benötigt als von einem Gerät bereitgestellt. In diesem Fall werden externe Multiplexors zum Gerät verwendet, um das richtige Gerät zu aktivieren, das zugänglich ist. Gedächtnishierarchie Eine kann Daten in RAM lesen und überschreiben. Viele Computersysteme verfügen über eine Speicherhierarchie, die sich aus Prozessorregistern, On-the-Chips, externen Caches, DRAM, Paging-Systemen und virtuellen Speicher- oder Tauschraum auf einer harten Antriebskraft zusammensetzt. Dieser gesamte Speicherpool kann von vielen Entwicklern als RAM bezeichnet werden, obwohl die verschiedenen Teilsysteme sehr unterschiedliche Zugangszeiten haben können, was dem ursprünglichen Konzept hinter dem Zufallszugangstermin in RAM zuwiderläuft. Selbst innerhalb einer Hierarchieebene, wie DRAM, die spezifische Folge, Spalte, Bank, Rang, Kanal oder Interleave Organisation der Komponenten, ist die Zugangszeit variabel, auch wenn der Zugangszeitraum zur Rotation der Speichermedien oder ein bürokratischer Aufwand unterschiedlich ist. Gesamtziel der Nutzung einer Speicherhierarchie ist es, die höchstmögliche durchschnittliche Zugangsleistung zu erhalten und gleichzeitig die Gesamtkosten des gesamten Speichersystems zu minimieren (allgemein folgt die Speicherhierarchie der Zugangszeit mit den schnellen CPU-Registern auf höchster und die langsame harte Fahrt am Boden). In vielen modernen persönlichen Computern kommt das RAM in einer leicht modernisierten Form von Module namens Speichermodulen oder DRAM-Modulen über die Größe von wenigen Aufklebern von Kaugummi. Diese können schnell ersetzt werden, wenn sie beschädigt werden oder wenn sich die Bedürfnisse ändern. Wie oben vorgeschlagen, sind auch kleinere Mengen von RAM (fastly Fujitsu) in die CPU und andere ICs auf dem Mutterboard sowie in den Festplatten, CD-ROMs und mehreren anderen Teilen des Computersystems integriert. Weitere Verwendungen von RAMIn zusätzlich zu einer vorübergehenden Lagerung und einem Arbeitsraum für das Betriebssystem und die Anwendungen wird RAM auf zahlreiche andere Weise verwendet. virtuelles Gedächtnis Die meisten modernen Betriebssysteme beschäftigen eine Methode zur Erweiterung der RAM-Kapazität, bekannt als „virtuelles Gedächtnis“. Ein Teil der harten Antriebskraft des Computers ist für eine Paging-Datei oder eine Grundspaltung vorgesehen, und die Kombination von physischem RAM und die Paging-Datei bilden den gesamten Speicher. (z.B. wenn ein Computer 2 GB (10243 B) von RAM und eine 1 GB-Seite hat, verfügt das Betriebssystem über 3 GB-Gesamtspeicher. Wenn das System auf physischem Gedächtnis niedrig ist, kann es Teile von RAM in die Paging-Datei eintauschen, um Raum für neue Daten zu schaffen und zuvor vertauschte Informationen zurück in RAM zu lesen. Eine übermäßige Nutzung dieses Mechanismus führt zu einer dreifachen und generell behindernden Gesamtsystemleistung, vor allem weil harte Antriebe weit langsamer sind als RAM. RAM-Chip-Software kann einen Teil des RAM-Chips von Computern austeilen und es ermöglichen, als viel schnelleres Festplatten zu wirken, das als RAM-Chip bezeichnet wird. Eine RAM-Videobox verliert die gespeicherten Daten, wenn der Computer abgeschaltet ist, es sei denn, das Speicher ist so angeordnet, dass eine Position Batteriequelle vorhanden ist, oder Änderungen der RAM-Laufwerke werden auf eine nicht-volatile-Gruppe geschrieben. Die RAM-Videobox wird auf der RAM-Ausrichtung von der physischen Scheibe abgeladen. Schattenige RAM-Zeiten, der Inhalt eines relativ langsamen ROM-Chips wird kopiert, um das Gedächtnis zu lesen oder zu schreiben, um kürzere Zugangszeiten zu ermöglichen. Der ROM-Chip ist dann behindert, während die anfänglichen Speicherstandorte auf dem gleichen Block von Adressen (häufig abgeschrieben). Dieser Prozess, manchmal als Schatten bezeichnet, ist in beiden Computern und eingebetteten Systemen recht üblich. Als gemeinsames Beispiel hat das BIO in typischen persönlichen Computern oft eine Option namens „use Schatten“ oder ähnliche. Können Funktionen, die sich auf Daten der ROM stützen, anstatt DRAM-Standorte zu nutzen (meist können auch das Schatten von Videokarten ROM oder anderen ROM-Abschnitten schützen). Je nach System kann dies nicht zu einer höheren Leistung führen und kann Unvereinbarkeiten verursachen. Manche Hardware kann zum Beispiel nicht in Anspruch genommen werden, wenn Schatten RAM verwendet wird. In einigen Systemen kann der Nutzen hypothetisch sein, da das BIO nicht verwendet wird, wenn es um den direkten Hardware-Zugang geht. Freies Gedächtnis wird durch die Größe der Schattenländer verringert. Jüngste Entwicklungen Mehrere neue Arten von Non-volatile RAM, die Daten speichern und gleichzeitig mit der Verarbeitung angetrieben werden, werden derzeit entwickelt. Die verwendeten Technologien umfassen Carbon nanotubes und Konzepte, die Tunnel Magnetoresistenance verwenden. Unter der 1. Generation MRAM wurde im Sommer 2003 ein 128 kbit (128 × 210 vontes) Chip mit 0,18 μm Technologie hergestellt. Infineon Technologies stellte im Juni 2004 einen 16 MB (16 × 220 vontes) vor, der auf 0,18 μm-Technologie basiert. In der Entwicklung gibt es derzeit zwei Verfahren der zweiten Generation: thermischer, unterstützter Wechsel (TAS), der von Crocus Technology entwickelt wird, und Wirbelsäule (STT), auf denen Crocus, Hynix, IBM und mehrere andere Unternehmen arbeiten. Nantero hat im Jahr 2004 einen funktionierenden Kohlenstoff-Norröhrenspeicher-Prototyp 10 GB (10 × 230 Bytes) gebaut. Ob einige dieser Technologien letztlich einen erheblichen Marktanteil von DRAM, Fujitsu oder Flash-Memory-Technologie einnehmen können, bleibt jedoch zu sehen. Seit 2006 werden „Solid-State-Laufwerke“ (auf der Grundlage des Flashspeichers) mit Kapazitäten über 256 Gigabyte und Leistung, die weit über die traditionellen Festplatten hinausgehen, zur Verfügung gestellt. Diese Entwicklung hat begonnen, die Definition zwischen traditionellen zufälligen Gedächtnis- und Festplatten zu verwischen, was den Leistungsunterschied drastisch verringert. Manche Arten von zufälligem Gedächtnis, wie EcoRAM, sind speziell für Server-Betriebe konzipiert, wo ein niedriger Stromverbrauch wichtiger ist als Geschwindigkeit. Gedächtniswand Die „Memory-Bau“ ist die zunehmende Disparität der Geschwindigkeit zwischen CPU und Gedächtnis außerhalb des CPU-Chips. Ein wichtiger Grund für diese Disparität ist die begrenzte Kommunikationsbreite über die Chipgrenzen hinaus, die auch als Breitbandwand bezeichnet wird. Zwischen 1986 und 2000 verbesserte sich die CPU-Geschwindigkeit auf einen jährlichen Wert von 55 %, während die Speichergeschwindigkeit nur um 10 % verbessert wurde. Angesichts dieser Trends wurde davon ausgegangen, dass Gedächtnisversagen zu einem überwältigenden Engpass in der Computerleistung werden. CPU-Geschwindigkeitsverbesserungen verlangsamten sich teilweise aufgrund großer physischer Hindernisse und teilweise, weil die aktuellen CPU-Designer die Speichermauer bereits in gewissem Maße getroffen haben. Intel hat diese Ursachen in einem Dokument von 2005 zusammengefasst. Erstens, da sich die geometrien schrumpfen und die Taktfrequenzen erhöhen, die derzeit zu überhöhten Stromverbrauch und Wärme führen...Secondly, die Vorteile höherer Taktgeschwindigkeiten werden teilweise durch Gedächtnisverzögerung verdrängt, da die Speicherzeiten nicht in der Lage waren, mit steigenden Frequenzen Schritt zu halten. Drittens, für bestimmte Anwendungen werden traditionelle Serienarchitekturen weniger effizient, da die Verarbeiter schneller (im Sinne der sogenannten "Abton Engneck") bekommen, wodurch die Gewinne, die die Frequenzerhöhungen ansonsten kaufen könnten, weiter unterschnitten werden. Darüber hinaus sind die Verspätungen bei der Signalübertragung zum Teil aufgrund der Beschränkungen der Herstellung von Induktivität innerhalb solider staatlicher Geräte immer größer als die Größe, was zusätzliche Engpässe verursacht, die die Häufigkeit nicht erhöht. Die Verzögerungen bei der Signalübertragung wurden auch in "Clock Rate versus IPC:The End of the Road for Conventional Microarchitures" festgestellt, die eine maximale jährliche Steigerung der Leistung von 12,5 % zwischen 2000 und 2014 projizieren. Ein anderes Konzept ist die prozessuale Leistungslücke, die durch 3D integrierte Schaltkreise behoben werden kann, die den Abstand zwischen Logik- und Gedächtnisaspekten verringern, die in einem 2D-Chip weiter voneinander abweichen. Gedächtnis Subsystemdesign erfordert einen Fokus auf die Lücke, die sich über die Zeit vergrößert. Hauptmethode zur Überbrückung der Lücke ist die Verwendung von Kläranlagen; kleine Mengen von Hochgeschwindigkeitsspeicher, die in der Nähe des Verarbeiters vor kurzem tätig sind, beschleunigen die Ausführung dieser Operationen oder Anweisungen in Fällen, in denen sie häufig aufgerufen werden. Multi-Level-Kupfer wurden entwickelt, um die wachsende Lücke zu schließen, und die Leistung moderner Hochgeschwindigkeits-Computer beruht auf den sich entwickelnden Kupftechniken. Man kann bis zu 53 % Differenz zwischen dem Wachstum der Geschwindigkeit des Verarbeiters und der rasanten Geschwindigkeit des wichtigsten Speicherzugangs aufweisen. Solid-staatliche Festplatten haben die Geschwindigkeit weiter erhöht, von ~400 Mbit/s über SATA3 im Jahr 2012 bis zu ~3 GB/s über NVMe/PCIe im Jahr 2018, die Kluft zwischen RAM und Festplattengeschwindigkeiten geschlossen, obwohl RAM weiterhin eine Größenordnung schneller ist, mit einer einzigenspurigen DDR4 3200 in der Lage ist, 25 GB/s und modernen GDDR sogar schneller.Fast, billige, nicht-volatile solide Staatsantriebe haben einige Funktionen ersetzt, die zuvor von RAM ausgeführt wurden, wie etwa die Speicherung bestimmter Daten für die sofortige Verfügbarkeit in Server-Betrieben - 1 terabyte der SSD-Lagerung kann für $200, während 1 TB RAM Tausende von Dollar kosten würde. Zeitfahrräder DRAM SDRAM SGRAM und Europcar Siehe auch Verweise auf externe Links Medien im Zusammenhang mit RAM bei der Wikimedia Commons