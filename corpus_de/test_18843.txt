Die Philosophie der künstlichen Intelligenz ist eine Zweige der Technologie, die künstliche Intelligenz und ihre Auswirkungen auf Wissen und Verständnis von Intelligenz, Ethik, Bewusstsein, Epistemologie und freiem Willen untersucht. Darüber hinaus ist die Technologie mit der Schaffung künstlicher Tiere oder künstlicher Menschen (oder zumindest künstlicher Natur; siehe künstliches Leben), so dass die Disziplin für die Philosophen von großem Interesse ist. Diese Faktoren trugen zur Entstehung der Philosophie der künstlichen Intelligenz bei. Manche Wissenschaftler argumentieren, dass die Abweisung der Philosophie durch die AI-Gemeinschaft Nachteile hat. Philosophie der künstlichen Intelligenz Versuche, solche Fragen wie folgt zu beantworten: Kann eine Maschine intelligent handeln? Kann sie ein Problem lösen, das eine Person durch Denken lösen würde? Sind menschliche Intelligenz und maschinelle Intelligenz gleich? Ist das menschliche Gehirn im Wesentlichen ein Computer? Kann eine Maschine einen Geist, geistige Staaten und Bewusstsein im gleichen Sinne haben, dass ein Mensch? Kann es sich fühlen, wie Dinge sind? Fragen wie diese spiegeln die unterschiedlichen Interessen von AI-Forschern, kognitiven Wissenschaftlern und Philosophen wider. wissenschaftliche Antworten auf diese Fragen hängen von der Definition von Intelligenz und Bewusstsein ab und genau welche Maschinen derzeit diskutiert werden. Wichtige Vorwürfe in der Philosophie der AI umfassen einige der folgenden: Turing's "Polite Konvention:" Wenn sich eine Maschine als Menschen intelligent verhalten, dann ist sie als Mensch intelligent. Vorschlag für den Europäischen Kommissar: "Jeder Aspekt des Lernens oder jeder sonstigen Kennzeichen kann genau beschrieben werden, dass eine Maschine zur Simulation dieses Problems eingesetzt werden kann." Allen Newell und Herbert A. Simons physisches Symbolsystem hypothesis: „Ein physikalisches Symbolsystem hat die notwendigen und ausreichenden Mittel für allgemeine intelligente Maßnahmen. " John Searle starke AI hypothesis: "Der geeignete, mit den richtigen Inputs und Outputs programmierte Computer hätte somit einen Blick in genau denselben Sinne, dass Menschen Gedanken haben." Mechanismus: "Aus Gründen ... ist nichts, sondern rekontingent, was die Folgen der allgemeinen Bezeichnungen, die für die Kennzeichnung und die Unterzeichnung unserer Gedanken vereinbart wurden, ergänzt und erweitert. Kann eine Maschine allgemeine Intelligenz zeigen? Kann eine Maschine geschaffen werden, die alle Probleme lösen kann, die Menschen mit Hilfe ihrer Intelligenz lösen können? In dieser Frage wird der Geltungsbereich der Maschinen in Zukunft festgelegt und die Richtung der AI-Forschung dargelegt. Es geht nur um das Verhalten von Maschinen und ignoriert die Interessen von Psychologen, kognitiven Wissenschaftlern und Philosophen; um diese Frage zu beantworten, ist es nicht Sache, ob eine Maschine wirklich Denken (als eine Person betrachtet) oder gerade wie es aussieht. Die Grundposition der meisten AI-Forscher wird in dieser Erklärung zusammengefasst, die im Vorschlag für den Campus von 1956 erschienen ist: "Jeder Aspekt des Lernens oder jeder sonstigen Kennzeichen kann genau beschrieben werden, dass eine Maschine zur Vereinfachung eingesetzt werden kann. " Argumente gegen die grundlegende Prämisse müssen zeigen, dass der Aufbau eines funktionierenden AI-Systems unmöglich ist, weil es eine praktische Beschränkung der Fähigkeiten von Computern gibt oder dass es eine besondere Qualität des menschlichen Geistes gibt, die für intelligentes Verhalten erforderlich ist und noch nicht durch eine Maschine (oder durch die Methoden der aktuellen AI-Forschung) verdoppelt werden kann. Argumente für die grundlegende Prämisse müssen zeigen, dass ein solches System möglich ist. Es ist auch möglich, die Verbindung zwischen den beiden Teilen des oben genannten Vorschlags aufzufangen. Beispielsweise erreicht das maschinelle Lernen, angefangen mit Turings im berühmten Kindermaschinen-Vorschlag, im Wesentlichen das gewünschte Merkmal der Intelligenz ohne präzise Gestaltungszeitbeschreibung, wie es genau funktioniert. Das Konto auf dem Roboter stillschweigendes Wissen beseitigt die Notwendigkeit einer genauen Beschreibung. Der erste Schritt zur Beantwortung der Frage besteht darin, die Intelligenz klar zu definieren. Intelligenz Turing Test Alan Turing verringerte das Problem der Definition von Intelligenz zu einer einfachen Frage des Gesprächs. Er schlägt vor, dass: Wenn eine Maschine jede Frage beantworten kann, die sie gestellt wird, unter Verwendung derselben Worte, die eine gewöhnliche Person würde, dann können wir diese Maschine intelligent anrufen. Eine moderne Version seines experimentellen Designs würde einen Online-Chatraum benutzen, in dem eine der Teilnehmer eine echte Person ist und eine der Teilnehmer ein Computerprogramm ist. Das Programm führt den Test, wenn niemand sagen kann, was die beiden Teilnehmer sind. Turing stellt fest, dass niemand (ausgenommen Philosophen) immer die Frage "Kann denken? "Er schreibt "anstatt ständig über diesen Punkt zu sprechen, es ist üblich, ein ordentliches Übereinkommen zu haben, das alle denken". Turings Test erweitert dieses konservative Übereinkommen auf Maschinen: Wenn eine Maschine als Menschen intelligent handelt, dann ist sie als Mensch intelligent. Kritik am Turing-Test ist, dass es nur den menschlichen Charakter des Verhaltens der Maschine und nicht die Intelligenz des Verhaltens beeinträchtigt. Da menschliches Verhalten und intelligentes Verhalten nicht genau das gleiche sind, wird der Test die Intelligenz nicht messen. Stuart J. Russell und Peter Norvig schreiben vor, dass "aeronautische Engineering-Texte nicht das Ziel ihres Feldes als "Fernmaschinen definieren, die so genau wie Seehechte fahren, die sie andere Seehecht katastrofen können". Intelligente Substanz Definition des zwanzigsten Jahrhunderts AI-Forschung definiert Intelligenz im Hinblick auf intelligente Agenten. Ein Agenten ist etwas, das in einem Umfeld wahrgenommen wird. Eine „Leistungsmaßnahme“ definiert, was als Erfolg für den Agenten gilt. „Wenn ein Agenten so wirkt, dass er den erwarteten Wert einer leistungsbezogenen Maßnahme auf der Grundlage früherer Erfahrungen und Kenntnisse maximiert, dann ist es intelligent. "Definitionen wie diese versuchen, den Inhalt der Intelligenz zu erfassen. Sie haben den Vorteil, dass sie im Gegensatz zum Turing-Test nicht auch für unintelligente menschliche Merkmale, wie z.B. die Erkennung von Fehlern oder die Fähigkeit, sich zu erholen, testen. Sie haben die Benachteiligung, dass sie nicht zwischen "Waren, die denken" und "Nichts" unterscheiden können. Mit dieser Definition hat sogar eine gekühlte rudimentäre Intelligenz. Argumente, dass eine Maschine allgemeine Intelligenz anzeigen kann Hubert Dreyfus kann dieses Argument simuliert werden, da er behauptet, dass "wenn das Nervensystem den Gesetzen der Physik und der Chemie entspricht, die wir jeden Grund haben, dies zu fordern .... wir sollten das Verhalten des Nervensystems mit einem bestimmten physischen Gerät wiederverfolgen können". Dieses von Hans Moravec 1988 erstmalig eingeführte Argument ist nun mit Futurist Ray Kurzweil verbunden, die Schätzungen zufolge die Computerleistung bis zum Jahr 2029 ausreichen wird. 2005 wurde eine nicht reale Simulation eines thalamocortischen Modells durchgeführt, das die Größe des menschlichen Gehirns (1011 Neuronen) besitzt und 50 Tage dauerte, um 1 zweite Gehirndynamik auf einem Cluster von 27 Prozessoren zu simulieren. Manche Meinungsverschiedenheiten, dass eine Gehirnsimulation in der Theorie möglich ist, selbst Kritiker von AI wie Hubert Dreyfus und John Searle. Searle weist jedoch darauf hin, dass grundsätzlich alles von einem Computer simuliert werden kann; dadurch führt die Definition zu seinem Bruchpunkt zu dem Schluss, dass jeder Prozess bei allen technisch als Berechnung angesehen werden kann. " Was wollen wir wissen, was den Blick von Thermostaten und Lebern unterscheidet“, schreibt er. Nur das Funktionieren eines Gehirns würde in sich selbst eine Zulassung von Unwissenheit in Bezug auf die Intelligenz und die Natur des Geistes sein. menschliches Denken ist Symbolverarbeitung im Jahr 1963, Allen Newell und Herbert A. Simon schlugen vor, dass "Symbolmanipulation" sowohl die menschliche als auch die maschinelle Intelligenz ist. Sie schrieben: "Ein physikalisches Symbolsystem hat die notwendigen und ausreichenden Mittel für allgemeine intelligente Maßnahmen. " Dieser Anspruch ist sehr stark: Es bedeutet, dass menschliches Denken eine Art von Symbolmanipulation ist (da ein Symbolsystem für Intelligenz notwendig ist) und dass Maschinen intelligent sein können (da ein Symbolsystem ausreichend für Intelligenz ist). Eine weitere Version dieser Position wurde von Hubert Dreyfus beschrieben, der sie "die psychologische Annahme:" "Der Geist kann als ein Gerät angesehen werden, das auf Bits von Informationen nach den formalen Regeln funktioniert. " Symbole, die Newell, Simon und Dreyfus diskutierten, waren Worte ähnlich und hoch – Symbole, die direkt mit Gegenständen in der Welt, wie z.B. Die meisten AI-Programme zwischen 1956 und 1990 nutzten diese Art von Symbol. Moderne AI, die auf Statistiken und mathematischen Optimierungen basiert, nutzt nicht die hochrangige „Symbol-Verarbeitung“, die Newell und Simon erörtert haben. Argumente gegen die symbolische Verarbeitung Diese Argumente zeigen, dass menschliches Denken nicht (überwiegend) von hochrangigen Symbolmanipulation besteht. Sie zeigen nicht, dass künstliche Intelligenz unmöglich ist, nur dass mehr als eine symbolische Verarbeitung erforderlich ist. Gödelian antimechanistische Argumente Kurt Gödel zeigte sich im Jahr 1931 mit einer unvollständigen Feststellung, dass es immer möglich ist, eine "Gödel-Erklärung" zu erstellen, dass ein einheitliches formales System der Logik (wie ein hochwertiges Symbolmanipulationsprogramm) nicht nachweisen konnte. Trotz einer echten Erklärung ist die ausgestellte Gödel-Erklärung im gegebenen System unprovisiert.() Die Wahrheit der ausgestellten Gödel-Erklärung hängt von der Kohärenz des jeweiligen Systems ab; die Anwendung des gleichen Prozesses auf ein nicht inkohärentes System wird sich als Erfolg erweisen, wird aber tatsächlich eine falsche "Gödel-Erklärung" anstelle) liefern. Mehr spekulative, Gödel vertrat die Auffassung, dass der menschliche Geist die Wahrheit oder die Ungewißheit einer gut begründeten mathematischen Erklärung (einschließlich etwaiger Gödel-Erklärung) korrekt bestimmen kann und dass daher die Macht des Menschen nicht für einen Mechanismus verwertbar ist. Philosopher John Lucas (seit 1961) und Roger Penrose (seit 1989) haben dieses weltanschauliche Anti-Mechanismus vorangetrieben. Gödelian anti-mechanistische Argumente stützen sich tendenziell auf den unwiderruflichen Anspruch, dass ein System menschlicher Säugetiere (oder eine gewisse Idealisierung menschlicher Säugetiere) sowohl konsistent (vollständig freien Fehler) als auch in seiner eigenen Konsistenz (und können alle logischen Gleichgültigkeiten, die sich aus ihrer eigenen Konsistenz, einschließlich der Überzeugung in der Gödel-Erklärung, ergeben). Dies ist für eine Turing-Maschine (und, durch eine informelle Erweiterung, jede bekannte Art von mechanischem Computer) nicht möglich; daher gelangt die Gödelian zu dem Schluss, dass menschliche Gründe zu stark in einer Maschine gefangen werden. Jedoch ist der moderne Konsens in der wissenschaftlichen und mathematischen Gemeinschaft der Auffassung, dass die tatsächliche menschliche Begründung uneinheitlich ist; dass eine konsequente "idealisierte" H menschlicher Grundbildung logischerweise gezwungen wäre, eine gesunde, aber gegeneinander gerichtete offene Skepsis über die Konsistenz von H zu verabschieden (sonstiges H ist uneinheitlich); und dass Gödel's theorems nicht zu einem gültigen Argument führen würde, dass der Mensch mathematische Grundfähigkeiten über das hinausgehen könnte. Dieser Konsens, dass Gödelian antimechanistische Argumente gegen Misserfolg verübt werden, ist in der künstlichen Intelligenz fest verankert: "jeder Versuch, (Gödel's unvollständigness Results) zu nutzen, um die rechnerische Thesis zu bekämpfen, ist gebunden, da diese Ergebnisse mit der rechnerischen Thesis in Einklang stehen." Mehrpragmatically, Russell und Norvig weisen darauf hin, dass das Argument von Gödel nur auf das anwendbar ist, was sich in theoretischer Hinsicht als unendliches Gedächtnis und Zeit erweisen kann. In der Praxis verfügen echte Maschinen (einschließlich Menschen) über finite Ressourcen und werden Schwierigkeiten haben, viele Theorems zu entdecken. Man muss nicht alles nachweisen, um intelligent zu sein. Douglas Hofstadter, in seinem Pulitzer-Preisgewinn Gödel, Escher, Bach: An EINE GoldenWELL, stellt fest, dass diese Gödel-statements immer auf das System selbst verweisen, was der Art und Weise entspricht, wie die Epimenides paradoxe Aussagen, die auf sich beziehen, wie "diese Erklärung ist falsch" oder "Ich bin heim. Selbstverständlich gilt die Epimenides paradox für alles, was Aussagen macht, ob sie Maschinen oder Menschen sind, selbst Lucas selbst. Kann nicht die Wahrheit dieser Erklärung geltend machen. Diese Erklärung ist wahr, kann aber nicht von Lucas geltend gemacht werden. Dies zeigt, dass Lucas selbst denselben Grenzen unterliegt, die er für Maschinen, wie alle Menschen, beschreibt, und dass das Argument von Lucas punktlos ist. Nach dem Schluss, dass menschliches Denken nicht stichhaltig ist, kam Penrose zu umstrittenen Spekulationen, dass einige hypothetische nicht-komputierbare Prozesse, die den Zusammenbruch von Quanten mechanischen Staaten betreffen, den Menschen einen besonderen Vorteil gegenüber vorhandenen Computern verschaffen. existierende Quantencomputer sind nur in der Lage, die Komplexität von Turing komutable Aufgaben zu reduzieren und sich weiterhin auf Aufgaben im Bereich der Turing-Maschinen zu beschränken. Durch die Argumente von Penrose und Lucas reichen die vorhandenen Quantencomputer nicht aus, so dass Penrose versucht, einen anderen Prozess, der neue Physik einschließt, zum Beispiel Quantensprung, der neue Physik im Maßstab der Zellmasse durch spontanen Quantenzusammenbruch der Wellenfunktion manifestieren könnte. Diese Staaten schlug er vor, sowohl innerhalb der Neuronen als auch über einen Neuronen. Andere Wissenschaftler weisen jedoch darauf hin, dass es keine plausiblen organischen Mechanismen im Gehirn gibt, um jede Art von Quantenberechnung zu nutzen, und dass die Zeitspanne der Quantenkohärenz zu schnell scheint, um die Neuronen zu beeinflussen. Dreyfus: Der Primat der impliziten Fähigkeiten Hubert Dreyfus argumentierte, dass die menschliche Intelligenz und das Know-how in erster Linie auf implizite Fähigkeiten und nicht explizite symbolische Manipulationen angewiesen sind, und argumentierte, dass diese Fähigkeiten nie in formalen Regeln erfasst würden. Dreyfuss Argument war von Turing in seinen 1950 erschienenen Papiermaschinen und Erkenntnissen ausgegangen worden, wo er dies als "Argument der Unregelmäßigkeit des Verhaltens" eingestuft hatte. "Dass wir nicht wissen, welche Regeln für ein komplexes Verhalten gelten, bedeutet dies nicht, dass solche Regeln existieren. Er schrieb: „Wir können uns nicht so einfach davon überzeugen, dass es keine vollständigen Verhaltensregeln gibt. Nur wissen wir, solche Gesetze zu finden, ist wissenschaftliche Beobachtung, und wir wissen sicher, dass keine Umstände, unter denen wir sagen könnten, „Wir haben genug gesucht. Es gibt keine solchen Gesetze.'Russelland Norvig weist darauf hin, dass in den Jahren, in denen Dreyfus seine Kritik veröffentlicht hat, Fortschritte gemacht wurden, um die Regeln zu entdecken, die unbewußte Begründungen regeln. Die Bewegung in der Robotik-Forschung versucht, unsere unbewussten Fähigkeiten in Wahrnehmung und Aufmerksamkeit zu erfassen. Kynthetische Intelligenz Paradigmen wie Neuralnetze, Evolutionsalgorithmen und damit werden hauptsächlich auf unbewusste Grund- und Lernprozesse ausgerichtet. Statistische Ansätze der AI können Vorhersagen machen, die die Genauigkeit menschlicher Mathematiker angehen. Forschung in gemeinsames Wissen konzentrierte sich auf die Förderung des Hintergrunds oder Kontextes des Wissens. Konkret hat die AI-Forschung im Allgemeinen von der hohen Symbolmanipulation auf neue Modelle verlagert, die mehr unserer unbewussten Begründung erfassen sollen. Seinetorian und AI-Forschunger Daniel Crevier schrieb, dass "die Zeit hat die Richtigkeit und das Gefühl einiger der Kommentare von Dreyfus bewiesen. Hält er sie weniger aggressive, konstruktive Maßnahmen, die sie vorgeschlagen haben, hätten viel früher ergriffen werden können." Kann eine Maschine ein Bewusstsein, Bewusstsein und geistige Staaten haben? Dies ist eine philosophische Frage, die mit dem Problem anderer Köpfe und dem harten Bewusstseinsproblem zusammenhängt. Die Frage stellt sich um eine von John Searle definierte Position als "starke AI:" ein physisches Symbolsystem kann einen Geist und geistige Staaten haben. Searle unterscheidet diese Position von dem, was er als "weak AI:" bezeichnete," ein physikalisches Symbolsystem kann intelligent wirken. Searle hat die Bedingungen eingeführt, um starke AI von schwacher AI zu isolieren, so dass er sich auf das konzentrieren könnte, was er dachte, das interessante und debatiblere Thema. Er argumentierte, selbst wenn wir davon ausgehen, dass wir ein Computerprogramm haben, das genau wie ein menschliches Denken gehandelt hat, wäre es noch eine schwierige philosophische Frage, die beantwortet werden muss. Keiner der beiden Positionen von Searle ist für die AI-Forschung von großer Bedeutung, da sie nicht direkt die Frage beantworten, "eine maschinelle Anzeige allgemeiner Intelligenz?" (nicht es kann auch gezeigt werden, dass das Bewusstsein für die Intelligenz notwendig ist). Lassen Sie mich nicht den Eindruck erwecken, dass ich glaube, dass es kein Geheimnis gibt...[b]ut Ich glaube nicht, dass diese Geheimnisse notwendigerweise gelöst werden müssen, bevor wir die Frage beantworten können.“ Russell und Norvig sind sich einig: „Most AI-Forscher nehmen die schwachen AI-Präsen für gewährte und nicht auf die starke Hypothesis der AI. Manche Forscher sind der Meinung, dass das Bewusstsein ein wesentliches Element in der Intelligenz ist, wie Igor Aleksander, Stan Franklin, Ron Sun und Pentti Haikonen, obwohl ihre Definition von Bewusstsein Strays sehr nahe der Intelligenz ist.“(Siehe künstliches Bewusstsein). Bevor wir diese Frage beantworten können, müssen wir klar sein, was wir durch Köpfe, "mentale Staaten" und Bewusstsein bedeuten. Bewusstsein, Köpfe, geistige Staaten, Bedeutung Denkweise und Bewusstsein werden von verschiedenen Gemeinschaften auf unterschiedliche Weise genutzt. Manche neue Denker zum Alter verwenden zum Beispiel das Wortbewusstsein, um etwas ähnlich zu beschreiben wie Bergson's "élan lebenswichtiges:" eine unsichtbare, energische Flüssigkeit, die das Leben und vor allem das Denken beeinträchtigt. wissenschaftliche Schriftsteller verwenden das Wort, um einige wesentliches Eigentum zu beschreiben, das uns Menschen macht: eine Maschine oder ein Ausländer, die sich bewusst ist, wird als voll menschlicher Charakter mit Intelligenz, Wünschen, Einblick, Stolz und so präsentiert. wissenschaftliche Schriftsteller verwenden auch die Worte, die sie geschickt haben, Sapience, Selbstbewusstsein oder Geister – wie im Ghost in der Shell-Manga- und der Animationsreihe –, um dieses grundlegende menschliche Eigentum zu beschreiben. Andere, die Worte und das Bewusstsein werden als eine Art säkularen Synonym für die Seele verwendet. für Philosophen, Neurowissenschaftler und kognitive Wissenschaftler werden die Wörter auf eine Weise verwendet, die sowohl präziser als auch stärker ist: Sie beziehen sich auf die vertraute, alltägliche Erfahrung mit "obwohl in Ihrem Kopf" wie eine Wahrnehmung, einen Traum, eine Absicht oder einen Plan sowie auf die Art und Weise, wie wir etwas wissen oder etwas verstehen. " Es ist nicht schwer, eine gemeinsame Definition des Bewusstseins zu geben“, sagt Philosoph John Searle. Maßgeblich und faszinierend ist nicht so viel, was es ist, sondern wie ist: Wie ist ein Klump an Fettgewebe und Strom zu diesem (miliaren) Erfahrungsschatz von Perceiving, Bedeutung oder Denken? Philosophen rufen dieses Problem auf. Es ist die neueste Version eines klassischen Problems in der Philosophie des Denkens, das das "innere Problem". " Ein verwandtes Problem ist das Problem der Bedeutung oder des Verständnisses (die Philosophen fordern Absichtserklärung): Was ist die Verbindung zwischen unseren Gedanken und was wir überdenken (d.h. Gegenstände und Situationen in der Welt)? Ein drittes Thema ist das Problem der Erfahrung (oder der Phenomenologie): Wenn zwei Menschen dasselbe sehen, haben sie dieselben Erfahrungen? Oder gibt es "in deren Kopf" (sogenannte qualia), die von der Person zu unterscheiden sind? Neurobiologen glauben, dass alle diese Probleme gelöst werden, da wir beginnen, die Neuralen des Bewusstseins zu erkennen: die tatsächliche Beziehung zwischen den Maschinen in unseren Köpfen und ihren kollektiven Eigenschaften, wie dem Geist, der Erfahrung und dem Verständnis. Manche der schlimmsten Kritiker der künstlichen Intelligenz sind sich darin einig, dass das Gehirn nur eine Maschine ist und dass Bewusstsein und Intelligenz das Ergebnis körperlicher Prozesse im Gehirn sind. Die schwierige Frage ist dies: kann ein Computerprogramm, das auf einer digitalen Maschine läuft, die die binären Ziffern von Null und einem zerstreut, die Fähigkeit der Neuronen, Denkanstöße zu schaffen, mit psychischen Staaten (wie dem Verständnis oder der Verfolgung) und letztlich auch die Erfahrung des Bewusstseins?Argumente, dass ein Computer kein Geistes- und Geistesstaat des chinesischen Raums John Searle haben kann, fordern uns auf, einen Gedankenversuch zu erwägen: Wir haben ein Computerprogramm, das den Turing-Test angibt und allgemeine intelligente Maßnahmen zeigt. insbesondere, dass das Programm in fließender chinesischer Sprache umgekehrt. Schreiben Sie das Programm auf 3x5 Karten und geben sie an eine normale Person, die nicht mit China spricht. Locken Sie die Person in einen Raum und folgen ihm den Anweisungen zu den Karten. Er wird chinesische Zeichen kopieren und durch einen Slot in und aus dem Raum übergeben. Von außen wird es erscheinen, dass der chinesische Raum eine voll intelligente Person enthält, die chinesische Sprache spricht. Dies ist dies: es gibt alle (oder alles) im Raum, der China versteht? Es gibt alles, was den psychischen Zustand hat oder das Bewusstsein für das, was in China diskutiert wird? Der Mann ist klar nicht bewusst. Das Zimmer kann nicht wissen. Die Karten sind sicher nicht bekannt. Searle kommt zu dem Schluss, dass der chinesische Raum oder ein anderes physisches Symbolsystem keinen Sinn haben können. Searle geht darum, zu argumentieren, dass tatsächliche geistige Staaten und Bewusstseinsbildung (noch zu beschreibende) "tatsächliche physikalische Eigenschaften der eigentlichen menschlichen Gehirne" erfordern. "He argumentiert, es gibt spezielle "kausale Eigenschaften" von Gehirnen und Neuronen, die zu Köpfen geführt haben: in seinen Worten "brains verursachen Köpfe". verwandte Argumente: die Eisenerz, der Telefonaustausch von Davis, die chinesische Nation und die Blockhead-Grenze von Korfu waren im Wesentlichen dasselbe Argument wie Searle in 1714, wobei die Idee, das Gehirn auszuweiten, bis die Größe einer Mühle war. Lawrence Davis stellte 1974 vor, das Gehirn mit Telefonleitungen und Büros, die von Menschen beschäftigt sind, zu vervollständigen, und 1978 die gesamte Bevölkerung Chinas, die an einer solchen Gehirnsimulation beteiligt ist. Es handelt sich um "die chinesische Nation" oder "das chinesische Zentrum". Ned Block schlug auch sein Blockhead- Argument vor, das eine Version des chinesischen Raums ist, in dem das Programm in eine einfache Reihe von Regeln des Formulars "siehe dies, das bedeutet," aus dem Programm entfernen. Antworten auf den chinesischen Raum auf den chinesischen Raum unterstreichen mehrere Punkte. Antworten auf die Systeme und die virtuelle Antwort: In dieser Antwort wird argumentiert, dass das System, einschließlich des Mannes, des Programms, des Raums und der Karten, das ist, was China versteht. Searle behauptet, dass der Mann im Raum die einzige Sache ist, die möglicherweise "einen Geist" oder verstehen könnte, aber andere sind sich darüber einig, dass es möglich ist, zwei Denkanstöße im gleichen physischen Ort zu sein, ähnlich wie die Art und Weise, wie ein Computer gleichzeitig zwei Maschinen sein kann: ein physischer (wie ein Notebook) und ein virtuelles (wie ein Textverarbeiter). Geschwindigkeit, Leistung und Komplexität: Mehrere Kritiker weisen darauf hin, dass der Mann im Raum wahrscheinlich Millionen von Jahren nehmen würde, um auf eine einfache Frage zu reagieren, und würden "filierende Kabinette" von Astronomen erfordern. Dies bringt die Klarheit der Seelle in Zweifel. Antwort: Manche glauben, dass der chinesische Raum Augen und Hände braucht. Hans Moravec schreibt: „Wenn wir einen Roboter in ein mit Gründen versehenes Programm umwandeln könnten, brauchen wir nicht mehr eine Person, um die Bedeutung mehr zu verleihen: es würde aus der Welt kommen. " Gehirn Simulator Antwort: Was, wenn das Programm die Sequenz von Nervenspalten auf den Synaps eines tatsächlichen Gehirns eines chinesischen Sprechers simuliert? Der Mann im Raum würde ein tatsächliches Gehirn simuliert. Es handelt sich um eine Variante der "Systemantwort", die plausibel erscheint, weil "das System" jetzt eindeutig wie ein menschliches Gehirn funktioniert, das die Intuation verstärkt, dass es etwas neben dem Mann im Raum gibt, der China verstehen könnte. Kommentare und Antworten zu Epiphenomena: Mehrere Menschen haben festgestellt, dass das Argument von Searle nur eine Version des Problems anderer Köpfe ist, die auf Maschinen angewendet werden. Da es schwierig ist, zu entscheiden, ob die Menschen tatsächlich denken, sollten wir nicht überraschen, dass es schwierig ist, die gleiche Frage über Maschinen zu beantworten. Eine verwandte Frage ist, ob das Bewusstsein (wie es Searle versteht) existiert. Searle argumentiert, dass die Erfahrung des Bewusstseins nicht durch die Prüfung des Verhaltens einer Maschine, eines Menschen oder eines anderen Tiers erkannt werden kann. Daniel Dennett weist darauf hin, dass die natürliche Auswahl ein Merkmal eines Tieres, das keine Auswirkungen auf das Verhalten des Tieres hat, nicht erhalten kann, und damit das Bewusstsein (als Seerle versteht, dass es) nicht durch natürliche Auswahl produziert werden kann. Jede natürliche Auswahl hat daher nicht das Bewusstsein erzeugt, oder „starke AI“ ist korrekt insofern, dass das Bewusstsein durch die entsprechende Gestaltung des Turing-Tests erkannt werden kann. Ist eine Art von Berechnung? Die rechnerische Theorie des Geistes oder des Rechenismus behauptet, dass die Beziehung zwischen Geist und Gehirn ähnlich ist (falls nicht identisch) der Beziehung zwischen einem laufenden Programm und einem Computer. Die Idee hat die Wurzeln in Hobbys (die angebliche Begründung war "nicht mehr als Rekoning")," (die versuchten, ein logisches kalkulierbares Gesamtkonzept für menschliche Ideen zu schaffen), Hume (die die Wahrnehmung auf "atomische Eindrücke" und Kant (die alle Erfahrungen analysiert haben, die durch formale Regeln kontrolliert werden). Die neueste Version ist mit Philosophen Hilary Putnam und Jerry Fodor verbunden. Diese Frage trägt zu unseren früheren Fragen: Wenn das menschliche Gehirn eine Art Computer ist, können Computer intelligent und bewusst sein und sowohl die praktischen als auch philosophischen Fragen der AI beantworten. In Bezug auf die praktische Frage der AI ("Kann einer Maschinenanzeige allgemeine Intelligenz") machen einige Versionen des Rechenismus den Anspruch geltend, der (wie Hobbys schrieb): Gründe hierfür sind nichts, sondern zurück. Mit anderen Worten, unsere Intelligenz ist von einer Berechnungsform abhängig, ähnlich wie Arithmetic. Dies ist das oben diskutierte physische Symbolsystem, das bedeutet, dass künstliche Intelligenz möglich ist. In Bezug auf die philosophische Frage der AI ("Kann einer Maschine haben Geist, geistige Staaten und Bewusstsein?", behaupten die meisten Versionen des Rechenismus, dass (wie Stevan Harnad sie kennzeichnet): psychische Staaten sind gerade die Umsetzung von (Recht) Computerprogrammen. John Searle's "starke AI" wurde oben diskutiert und es ist das eigentliche Ziel des chinesischen Raums (nach Harnad). Andere verwandte Fragen Kann eine Maschine Emotionen haben? Wenn die Emotionen nur im Hinblick auf ihre Wirkung auf das Verhalten oder auf die Funktionsweise eines Organismus definiert werden, können die Emotionen als Mechanismus angesehen werden, mit dem ein intelligenter Wirkstoff verwendet wird, um den Nutzen seiner Handlungen zu maximieren. Hans Moravec ist der Ansicht, dass "Robots im Allgemeinen sehr emotional sein werden, um glückliche Menschen zu sein". Angst ist eine Quelle der Dringlichkeit. Emopathie ist ein notwendiger Bestandteil guter menschlicher Interaktion. Er sagt Roboter "wir versuchen, Sie auf scheinbar selbstverständliche Weise zu bitten, weil es ein Gefühl dieser positiven Verstärkung bekommen wird. Sie können dies als eine Art Liebe interpretieren. " Daniel Crevier schreibt "Moravec's Point: Die Emotionen sind nur Instrumente, um das Verhalten in einer Richtung zu lenken, die dem Überleben einer Art förderlich ist". Kann eine Maschine selbst wissen? Selbstbewusstsein, wie oben erwähnt, wird manchmal von wissenschaftlichen Fiktors als Namen für das wesentliche menschliche Eigentum verwendet, das einen ganz menschlichen Charakter verleiht. Stränge weg alle anderen Eigenschaften des Menschen und kürzen die Frage auf "eine Maschine ist Gegenstand ihrer eigenen Gedanken". " Kann man selbst denken? Auf diese Weise kann ein Programm geschrieben werden, das über seine eigenen internen Staaten, wie z.B. überhöht, berichten kann. Obwohl ein unmissverständliches Selbstbewußtsein oft ein wenig mehr Fähigkeiten vermutet; eine Maschine, die in irgendeiner Weise bedeutet, nicht nur ihren eigenen Staat, sondern im allgemeinen Fragen ohne feste Antworten zu behandeln: die Kontextnatur ihrer Existenz; wie sie mit früheren Staaten oder Plänen für die Zukunft, die Grenzen und den Wert ihrer Arbeit vergleicht, wie sie ihre Leistung wertschätzt oder mit anderen verglichen. Kann eine Maschine Original oder kreativ sein? Turing reduziert dies auf die Frage, ob eine Maschine "wir durch Überraschung" nehmen kann, und argumentiert, dass dies offensichtlich wahr ist, da jeder Programmierer testen kann. Er weist darauf hin, dass ein Computer mit ausreichender Speicherkapazität in einer Audi-Nummer unterschiedlicher Art agieren kann. Es muss auch für einen Computer möglich sein, der Ideen vertritt, um sie auf neue Weise zu kombinieren. (Douglas Lenats automatisierte Mathematician, ein Beispiel, kombinierte Ideen, um neue mathematische Wahrheiten zu entdecken). Kaplan und Haenlein weisen darauf hin, dass Maschinen wissenschaftliche Kreativität zeigen können, während es wahrscheinlich scheint, dass der Mensch die obere Hand haben wird, in der künstlerische Kreativität betroffen ist. 2009 gründeten Wissenschaftler an der Aberystwyth University in Wales und der University of Cambridge einen Roboter namens Adam, dass sie die erste Maschine sind, um sich unabhängig mit neuen wissenschaftlichen Erkenntnissen zu befassen. Im Jahr 2009 entwickelten die Forscher in Cornell Eureqa, ein Computerprogramm, mit dem die verwendeten Daten in Einklang gebracht werden können, wie z.B. bei der Suche nach Bewegungsgesetzen aus einem Pendulum. Kann eine Maschine benevolent oder feindselig werden? Diese Frage (wie viele andere in der Philosophie der künstlichen Intelligenz) kann in zwei Formen gestellt werden. " Feindseligkeiten können in Bezug auf Funktion oder Verhalten definiert werden, in dem feindselige Fälle mit gefährlich werden.“ Or es kann im Hinblick auf die Absicht definiert werden: Kann eine Maschine, die absichtlich zum Schaden bestimmt ist? Letzteres ist die Frage "eine Maschine hat bewusste Staaten?" (wie Absichten) in einer anderen Form. Die Frage, ob hochintelligente und vollständige autonome Maschinen gefährlich wären, wurde im Detail von Futuristen (wie dem Forschungsinstitut für Maschinennachrichten) untersucht. Das offensichtliche Element des Dramas hat auch das Thema in der Science-Fiction bekannt gemacht, das viele unterschiedliche Szenarien in Betracht gezogen hat, in denen intelligente Maschinen eine Bedrohung für die Menschheit darstellen; die künstliche Intelligenz in der Fiktion. Ein Problem ist, dass Maschinen die Autonomie und Intelligenz erwerben können, die für sehr schnell gefährlich sind. Vernor Vinge hat vorgeschlagen, dass über nur wenige Jahre Computer plötzlich Tausende oder Millionen von Zeiten intelligenter werden als Menschen. Er appelliert an diese "Sache". Er schlägt vor, dass es für den Menschen etwas oder vielleicht sehr gefährlich sein könnte. Erörtert wird dies durch eine Philosophie namens Singitamismus. Im Jahr 2009 nahmen Wissenschaftler und technische Experten an einer Konferenz teil, um die möglichen Auswirkungen von Robotern und Computern und die Auswirkungen der hypothetischen Möglichkeit zu diskutieren, dass sie selbst reichen und ihre eigenen Entscheidungen treffen können. Sie erörterten die Möglichkeit und den Umfang, in dem Computer und Roboter alle Autonomiestufen erwerben können und in welchem Maße sie solche Fähigkeiten nutzen könnten, um eine Bedrohung oder Gefahr zu verursachen. Sie stellten fest, dass einige Maschinen verschiedene Formen der Halbautonomie erworben haben, darunter die Möglichkeit, eigene Stromquellen zu finden und eigenständige Ziele für den Angriff auf Waffen zu wählen. Sie wiesen auch darauf hin, dass einige Computerviren die Abschaffung verhindern können und „Cockroach Intelligence“ erreicht haben. " Sie wiesen darauf hin, dass Selbstbewusstsein, wie in Wissenschaft dargestellt, wahrscheinlich unwahrscheinlich ist, aber dass es andere potenzielle Gefahren und Gefahren gab. Manche Experten und Wissenschaftler haben die Verwendung von Robotern für militärische Kämpfe in Frage gestellt, insbesondere wenn solche Roboter einen gewissen Grad autonomer Funktionen erhalten. Die US-Katastrophe hat einen Bericht finanziert, in dem darauf hingewiesen wird, dass militärische Roboter komplexer werden, dass die Auswirkungen ihrer Fähigkeit, autonome Entscheidungen zu treffen, stärker berücksichtigt werden sollten. Der Präsident der Vereinigung für die Förderung der künstlichen Intelligenz hat eine Studie in Auftrag gegeben, um diese Frage zu prüfen. Sie weisen auf Programme wie das Instrument für den Erwerb von Sprachen hin, das die menschliche Interaktion verschmutzen kann. Manche haben eine Notwendigkeit vorgeschlagen, "sichere AI" zu bauen, d.h. die bereits mit der AI auftretenden Vorschüsse sollten auch Anstrengungen unternehmen, um AI intrinsischer und menschlicher Hinsicht zu machen. Kann eine Maschine alle menschlichen Merkmale einsparen? Turing sagte: "Es ist üblich, ein Korn des Komforts zu bieten, in Form einer Erklärung, dass einige eigens menschliches Merkmal nie durch eine Maschine verändert werden könnten.... Ich kann keinen solchen Komfort bieten, denn ich glaube, dass keine solchen Bindungen gesetzt werden können. " Turing stellte fest, dass es viele Argumente der Form "eine Maschine wird nie tun, X", wo X viele Dinge sein kann, z.B.: Be-Art, ressourcenschonend, schön, freundschaftlich, bekennen, aus falschen Gründen sagen, Irrtümer zu machen, Liebe, Erdbeeren und Creme zu genießen, dass jemand mit ihm zu Liebe kommt, aus Erfahrung lernen, Worte zu verwenden, das Thema des eigenen Denkens zu sein, wie viel Vielfalt des Verhaltens als Mann, wirklich Neues. Turing argumentiert, dass diese Einwände häufig auf naiven Annahmen über die Vielfalt der Maschinen beruhen oder "verschiedene Formen des Arguments aus dem Bewusstsein" sind. Lesen Sie ein Programm, das ein solches Verhalten zeigt "wir nicht viel von einem Eindruck machen". All diese Argumente sind die Grundidee von AI, es sei denn, es kann gezeigt werden, dass eine dieser Merkmale für allgemeine Intelligenz unerlässlich ist. Kann eine Maschine eine Seele haben? Letztlich können diejenigen, die in der Existenz einer Seele glauben, argumentieren, dass "Thinking eine Funktion der unsterblichen Seele des Menschen ist. " Alan Turing nannte diesen "logischen Widerspruch". Er schreibt Versuch, solche Maschinen zu bauen, sollten wir uns nicht unentschlossen machen Seine Macht zur Schaffung von Seeleuten, jeder mehr als wir in der Kindererziehung sind: Wir sind in beiden Fällen eher Instrumente seines Willens, die Menschen für die von ihm geschaffenen Seele zu machen. Ansichten zur Rolle der Philosophie Manche Wissenschaftler argumentieren, dass die Abweisung der Philosophie durch die AI-Gemeinschaft Nachteile hat. Manche Philosophen argumentierten in der Wissenschaftsbibliothek der Philosophie, dass die Rolle der Philosophie in der AI im Vergleich steht. Physicist David Deutsch argumentiert, dass die Entwicklung der AI ohne Verständnis der Philosophie oder ihrer Konzepte durch mangelnde Fortschritte beeinträchtigt würde. Konferenzs Die wichtigste Konferenzreihe zu diesem Thema ist "Philosophy und Theorie of AI" (PT-AI), die von Vincent C. Müller geleitet wird. Die Hauptbibliographie zu diesem Thema, mit mehreren Abschnitten, ist PhilPapers. Siehe auch Hinweise Adam, Alison (1989). Künstliches Know-how: Geschlecht und Denkmaschine. Routledge & CRC Press. https://www.routledge.com/Artificial-Knowing-Gender-and-the-Thinking-Maschinen/Adam/p/book/9780415129633 Benjamin, Ruha G. Rasse nach Technologie: Abolitionist Werkzeuge für den neuen Jim Code.Wiley.ISBNUNG AM1-509-52643-7 Blackmore, Susan (2005), Bewusstsein: Eine sehr kurze Einführung, Oxford University Press Bo, Nick (2014), Superintelligence: Paths, Dangers, Strategien, Oxford University Press, ISBN [0-19-967811-2 Brooks, Rodney (1990), "Elephants Don't Play" (PDF), Robotik und autonome Systeme, 6–2): 3–15, S.30, S. Künstliche Intelligenz: Ein Einführungsüberblick für Recht und Verordnung, 34.Chalmers, David J (1996,) Das Bewusstsein: In der Suche nach einer Grundtheorie, Oxford University Press, New York, [0-1911789-9 Cole, David (Frühjahr 2004), "Der chinesische Raum," in Zalta, Edward N. (ed), Veröffentlichung von Philosophie. Crawford, Kate (2021). Atlas of AI: Power, Politik und Planetary Costs of Künstlicher Intelligenz. University Press.Crevier, Daniel (1993), AI: The Tumultous Search for Künstliche Intelligenz, New York, NY: Grundbuch, ISBN 0-465-02997-3 Dennett, Daniel (1991), Bewusstseinsbewältigung, The Penguin Press, [0-7139-9037-9 Dreyfus, Hubert (...), Was Computer Kann nicht Do, New York: Presse, [0-061082-6 Dreyfus, Hubert My You] Presse. Dreyfus, Hubert; Dreyfus, Stuart (1986), Mind over Maschinen: The Power of Humanwissen and Expertise in the Era of the Computer, Oxford, UK: Blackwell begrüßen, Nicholas (2007), The Letzte Antworten zu den ältesten Fragen: A Philosophisches Abenteuer mit den Greatest Thinkers, New York: Grove Press Gladwell, Malcolm (2005), Blink: Denkkraft ohne Denken, Boston: Little, Brown, ISBN @0-3-17-5.Harnads. Kommentare zum chinesischen Raum für Searle, Oxford University Press Haraway, Donna (1985). A Cyborg Manifesto. Haugeland, John (1985), Künstliche Intelligenz: The Sehr Idee, Cambridge, Mass. MIT Presse. Hofstadter, Douglas 1979, Gödel, Escher, Bach: ein E-Mails. Horst, Steven (2009), "The Computational Theorie of Mind", in Zalta, Edward N. (ed.), The Stanford emia of Philosophie, Metaphysik Research Lab, Universität Stanford. Kaplan, Andreas; Haenlein, Michael (2018), "Siri, Siri in meiner Hand, der die Fairest im Land ist? Kontakt zu den Interpretationen, Darstellungen und Folgen der künstlichen Intelligenz" Business Horizons, 62: 15-25, doi:106/j.bushor.2018.08.004 Kurzweil, Ray (2005), The Singity ist fast, New York: Viking Press, [0-670-03384-3.Lucas, John (1961,) "Minds, Maschinen und Gödel", in Anderson, A.R (ed). Minds und Maschinen. Malabou, Catherine (2019). Morphing Intelligence: VonIQ-Messungen bis künstliche Gehirns.(C Shread, Trans). Columbia University Press. McCarthy, John; Minsky, Marvin; Rochester, Nathan; Shannon, Claude (1955), ein Vorschlag für das Forschungsprojekt für den frühen Sommer im Bereich der Künstlichen Intelligenz, das aus dem Original 2008-09-30 hergestellt wurde. McDermott, Drew (Mai 14, 1997), "Wie Smart is Deep Blue," New York Times, Archiviert vom Original am 4. Oktober 2007, fand am 10. Oktober 2007 Moravec, Hans Mind Children, Harvard University Press Penrose, (1989), Roger, The Kaiser's New Mind: Was Computer, Minds und The Laws of Physics, Oxford University Press, [0-144534-2 Sear, JohnMinds, Brains, Brains and" (PDF). Turing, Alan (Oktober 1950), „. Maschinen und Nachrichten“, LIX (236): 433–460, doi:10.1093/mind/LIX.236.433, ISSN 0026-4423 Yee, Richard (1993), "Verbesserung von Maschinen und Symbolverarbeitung: Warum echte Computer Don't Mind Chinese Kaisers" (PDF), Lyceum, 5 (1): 37-59Page-Nummern über und Graphik-Inhalte beziehen sich auf den Lyceum PDF-Druck des Artikels.