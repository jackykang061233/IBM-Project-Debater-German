Die maschinelle Übersetzung, die manchmal von der Abkürzung MT (nicht mit computergestützter Übersetzung, maschinengestützter menschlicher Übersetzung oder interaktiver Übersetzung verwechselt werden soll) ist ein Unterfeld von rechnergestützten Linguistiken, die die Verwendung von Software zur Übersetzung von Text oder Sprache von einer Sprache in eine andere untersucht. Auf einer Grundebene führt MT mechanische Substitution von Wörtern in einer Sprache für Wörter in einer anderen Sprache durch, aber das allein selten eine gute Übersetzung erzeugt, weil die Anerkennung von ganzen Phrasen und deren engsten Gegenstücken in der Zielsprache erforderlich ist. Nicht alle Wörter in einer Sprache haben gleichwertige Wörter in einer anderen Sprache, und viele Wörter haben mehr als eine Bedeutung. Das Lösen dieses Problems mit corpus statistischen und neuronalen Techniken ist ein schnell wachsendes Feld, das zu besseren Übersetzungen, Umgang mit Unterschieden in der sprachlichen Typologie, Übersetzung von Idiomen und der Isolierung von Anomalien führt. Die aktuelle maschinelle Übersetzungssoftware ermöglicht oft die Anpassung an Domänen oder Beruf (wie Wetterberichte), die Verbesserung der Leistung durch Einschränkung des Umfangs der zulässigen Substitutionen. Diese Technik ist besonders effektiv in Bereichen, in denen formale oder formulierte Sprache verwendet wird. Daraus folgt, dass die maschinelle Übersetzung von Regierungs- und Rechtsdokumenten die nutzbare Leistung leichter erzeugt als das Gespräch oder weniger standardisierter Text. Eine verbesserte Ausgangsqualität kann auch durch menschliches Eingreifen erreicht werden: Zum Beispiel können einige Systeme genauer übersetzen, wenn der Benutzer eindeutig identifiziert hat, welche Wörter im Text richtige Namen sind. Mit Hilfe dieser Techniken hat sich MT als Werkzeug für die Unterstützung menschlicher Übersetzer bewährt und kann in einer sehr begrenzten Anzahl von Fällen sogar Ausgabe produzieren, die wie (z.B. Wetterberichte) verwendet werden kann. Der Fortschritt und das Potenzial der maschinellen Übersetzung wurden durch seine Geschichte viel diskutiert. Seit den 50er Jahren haben eine Reihe von Gelehrten, vor allem Yehoshua Bar-Hillel, die Möglichkeit, vollautomatische maschinelle Übersetzung von hoher Qualität zu erreichen. Geschichte Ursprung Der Ursprung der maschinellen Übersetzung kann auf die Arbeit von Al-Kindi zurückverfolgt werden, einem arabischen Kryptographen aus dem 9. Jahrhundert, der Techniken für die systemische Sprachübersetzung entwickelt hat, einschließlich Kryptanalyse, Frequenzanalyse und Wahrscheinlichkeit und Statistiken, die in der modernen maschinellen Übersetzung verwendet werden. Die Idee der maschinellen Übersetzung erschien später im 17. Jahrhundert. Im Jahre 1629 schlug René Descartes eine universelle Sprache vor, mit äquivalenten Ideen in verschiedenen Zungen, die ein Symbol teilen. Die Idee, digitale Computer zur Übersetzung natürlicher Sprachen zu verwenden, wurde bereits 1946 von Englands A. D. Booth und Warren Weaver bei der Rockefeller Foundation vorgeschlagen. " Das von Warren Weaver 1949 geschriebene Memorandum ist vielleicht die einflussreichste Publikation in den frühesten Tagen der maschinellen Übersetzung." Andere folgten. Eine Demonstration wurde 1954 auf der APEXC-Maschine am Birkbeck College (University of London) einer rudimentären Übersetzung von Englisch ins Französische durchgeführt. Mehrere Beiträge zum Thema wurden damals veröffentlicht, und sogar Artikel in populären Zeitschriften (z.B. ein Artikel von Cleave und Zacharov in der September 1955 Ausgabe von Wireless World.) Eine ähnliche Anwendung, die damals auch am Birkbeck College Pionier war, lesen und komponieren Braille Texte per Computer. 1950sDer erste Forscher auf dem Gebiet, Yehoshua Bar-Hillel, begann seine Forschung am MIT (1951). Ein Forschungsteam der Georgetown University MT, geleitet von Professor Michael Zarechnak, folgte 1951 mit einer öffentlichen Demonstration seines Georgetown-IBM-Experimentsystems im Jahr 1954. MT-Forschungsprogramme tauchten in Japan und Russland (1955) auf und die erste MT-Konferenz fand in London statt (1956). David G. Hays "wrote über computergestützte Sprachverarbeitung bereits 1957" und "war Projektleiter bei Computerlinguistik bei Rand von 1955 bis 1968." 1960-1975 In den USA (1962) und der Nationalen Akademie der Wissenschaften bildete das Beratungskomitee für die automatische Sprachverarbeitung (ALPAC) zum Studium MT (1964). Der reale Fortschritt war jedoch viel langsamer, und nach dem ALPAC-Bericht (1966), in dem festgestellt wurde, dass die zehnjährige Forschung die Erwartungen nicht erfüllte, wurde die Finanzierung erheblich reduziert. Laut einem Bericht von 1972 des Direktors für Verteidigungsforschung und -technik (DDR&E) wurde die Machbarkeit von groß angelegtem MT durch den Erfolg des Logos MT-Systems bei der Übersetzung von Militärhandbüchern in Vietnamesisch während dieses Konflikts wiederhergestellt. Das Französische Textilinstitut nutzte auch MT, um Abstracts aus und in Französisch, Englisch, Deutsch und Spanisch (1970) zu übersetzen; Brigham Young University begann ein Projekt, um Mormon-Texte durch automatisierte Übersetzung zu übersetzen (1971.) 1975 und über SYSTRAN, die "das Feld unter Verträgen von der US-Regierung" in den 1960er Jahren, wurde von Xerox verwendet, um technische Handbücher zu übersetzen (1978). In den späten 1980er Jahren, da die Rechenleistung zugenommen und weniger teuer wurde, wurde mehr Interesse in statistischen Modellen für die maschinelle Übersetzung gezeigt. MT wurde nach dem Aufkommen von Computern populärer. Das erste Implementierungssystem von SYSTRAN wurde 1988 durch den Online-Service des französischen Postdienstes Minitel realisiert. Es wurden auch verschiedene computergestützte Übersetzungsunternehmen ins Leben gerufen, darunter auch Trados (1984), die die erste für die Entwicklung und den Markt der Translation Memory-Technologie (1989) war, obwohl dies nicht das gleiche wie MT ist. Das erste kommerzielle MT-System für Russisch / Englisch / Deutsch-Ukrainisch wurde an der Kharkov State University (1991) entwickelt. Bis 1998, "für so wenig wie $29.95" könnte man "ein Programm für die Übersetzung in eine Richtung zwischen Englisch und einer großen europäischen Sprache Ihrer Wahl" auf einem PC laufen. MT im Web begann mit SYSTRAN, die kostenlose Übersetzung von kleinen Texten (1996) und dann über AltaVista Babelfish, die bis zu 500.000 Anfragen pro Tag (1997). Der zweite kostenlose Übersetzungsservice im Web war Lernout & Hauspie's GlobaLink. Das Atlantic Magazine schrieb 1998, dass "Systran's Babelfish and GlobaLink's Comprende" mit einer "kompetenten Aufführung" "Nehmen Sie keine Bank drauf". " Franz Josef Och (der zukünftige Leiter der Übersetzungsentwicklung AT Google) gewann den Speed MT-Wettbewerb von DARPA (2003). Weitere Innovationen in dieser Zeit waren MOSES, der Open-Source-Statistik-MT-Engine (2007), ein Text/SMS-Übersetzungsservice für Handys in Japan (2008) und ein Mobiltelefon mit eingebauter Sprach-zu-Sprach-Übersetzungsfunktionalität für Englisch, Japanisch und Chinesisch (2009). Im Jahr 2012, Google bekannt gegeben, dass Google Translate übersetzt etwa genug Text, um 1 Million Bücher an einem Tag zu füllen. Übersetzungsprozess Der menschliche Übersetzungsprozess kann als: Dekodieren der Bedeutung des Quelltextes und Umcodieren dieser Bedeutung in der Zielsprache beschrieben werden. Hinter diesem ostensibel einfachen Verfahren liegt eine komplexe kognitive Operation. Um die Bedeutung des Quelltextes in seiner Gesamtheit zu decodieren, muss der Übersetzer alle Merkmale des Textes interpretieren und analysieren, einen Prozess, der eingehende Kenntnisse der Grammatik, Semantik, Syntax, Idiome usw. der Quellsprache sowie der Kultur seiner Lautsprecher erfordert. Der Übersetzer braucht die gleichen eingehenden Kenntnisse, um die Bedeutung in der Zielsprache neu zu kodieren. Dabei liegt die Herausforderung in der maschinellen Übersetzung: Wie man einen Computer programmiert, der einen Text als Person versteht, und der einen neuen Text in der Zielsprache erstellt, der so klingt, als ob er von einer Person geschrieben wurde. Es sei denn, eine "Wissensbasis" MT bietet nur eine allgemeine, wenn auch unvollkommene Annäherung des ursprünglichen Textes, die Gist von ihm (ein Prozess namens Gisting) erhalten. Dies ist für viele Zwecke ausreichend, einschließlich der bestmöglichen Nutzung der endlichen und teuren Zeit eines menschlichen Übersetzers, reserviert für diejenigen Fälle, in denen die Gesamtgenauigkeit unerlässlich ist. Approaches maschinelle Übersetzung kann eine auf sprachlichen Regeln basierende Methode verwenden, was bedeutet, dass Wörter auf sprachliche Weise übersetzt werden – die am besten geeigneten (orally sprechenden) Wörter der Zielsprache ersetzen die in der Quellsprache. Es wird oft argumentiert, dass der Erfolg der maschinellen Übersetzung das Problem des natürlichen Sprachverständnisses erfordert, zuerst gelöst zu werden. Generell werden regelbasierte Methoden einen Text parsiert, der in der Regel eine intermediäre, symbolische Darstellung erstellt, aus der der Text in der Zielsprache erzeugt wird. Gemäß der Art der Zwischendarstellung wird ein Ansatz als interlinguale maschinelle Übersetzung oder transferbasierte maschinelle Übersetzung beschrieben. Diese Methoden erfordern umfangreiche Lexikone mit morphologischen, syntaktischen und semantischen Informationen und großen Regeln. Bei ausreichenden Daten arbeiten maschinelle Übersetzungsprogramme oft gut genug für einen Muttersprachler einer Sprache, um die ungefähre Bedeutung dessen zu bekommen, was von dem anderen Muttersprachler geschrieben wird. Die Schwierigkeit besteht darin, genügend Daten der richtigen Art zu erhalten, um die jeweilige Methode zu unterstützen. So ist z.B. der große mehrsprachige Korpus der Daten, die für statistische Methoden zur Arbeit benötigt werden, für die grammatikbasierten Methoden nicht erforderlich. Aber dann brauchen die Grammatikmethoden einen qualifizierten Linguisten, um die Grammatik sorgfältig zu gestalten, die sie verwenden. Um zwischen eng verwandten Sprachen zu übersetzen, kann die in der Regel basierende maschinelle Übersetzung verwendet werden. Regelmäßig Das Regelbasierte maschinelle Übersetzungsparadigma umfasst übertragungsbasierte maschinelle Übersetzung, interlinguale maschinelle Übersetzung und wörterbuchbasierte maschinelle Übersetzungsparadigmen. Diese Art der Übersetzung wird hauptsächlich bei der Erstellung von Wörterbüchern und Grammatik-Programmen verwendet. Im Gegensatz zu anderen Methoden, RBMT beinhaltet mehr Informationen über die Linguistik der Quell- und Zielsprachen, unter Verwendung der morphologischen und syntaktischen Regeln und semantischen Analyse beider Sprachen. Der grundsätzliche Ansatz beinhaltet die Verknüpfung der Struktur des Eingabesatzes mit der Struktur des Ausgabesatzes mit einem Parser und einem Analysator für die Quellsprache, einem Generator für die Zielsprache und einem Transferlexikon für die eigentliche Übersetzung. RBMTs größter Untergang ist, dass alles explizit gemacht werden muss: orthographische Variation und fehlerhafte Eingabe müssen Teil des Quellsprachenanalysators sein, um damit zu umgehen, und lexische Auswahlregeln müssen für alle Fälle von Mehrdeutigkeit geschrieben werden. Die Anpassung an neue Domänen an sich ist nicht so hart, da die Core-Grammatik über Domänen gleich ist und die Domain-spezifische Anpassung auf die lexische Selektionseinstellung beschränkt ist. Transferbasierte maschinelle Übersetzung Übertragen basierte maschinelle Übersetzung ist ähnlich der interlingualen maschinellen Übersetzung, indem sie eine Übersetzung aus einer Zwischendarstellung erzeugt, die die Bedeutung des ursprünglichen Satzes simuliert. Anders als interlingual MT hängt es teilweise von dem Sprachpaar ab, das an der Übersetzung beteiligt ist. Interlingual Interlingual maschinelle Übersetzung ist eine Instanz von regelbasierten maschinellen Übersetzungsansätzen. In diesem Ansatz wird die Quellsprache, d.h. der zu übersetzende Text, in eine interlinguale Sprache umgewandelt, d.h. eine von jeder Sprache unabhängige "Sprachneutrale" Darstellung. Die Zielsprache wird dann aus dem Interlingua generiert. Einer der Hauptvorteile dieses Systems ist, dass die Interlingua wertvoller wird, da die Anzahl der Zielsprachen erhöht werden kann. Das einzige interlinguale maschinelle Übersetzungssystem, das auf kommerzieller Ebene eingesetzt wurde, ist jedoch das KANT-System (Nyberg und Mitamura, 1992), das dazu bestimmt ist, Caterpillar Technical English (CTE) in andere Sprachen zu übersetzen. Wörterbuchbasierte maschinelle Übersetzung kann eine auf Wörterbucheinträgen basierende Methode verwenden, was bedeutet, dass die Wörter übersetzt werden, wie sie durch ein Wörterbuch sind. Statistische maschinelle Übersetzung versucht, Übersetzungen mit statistischen Methoden zu erstellen, die auf zweisprachigen Texten basieren, wie z.B. die kanadische Hansard corpus, die englisch-französische Aufzeichnung des kanadischen Parlaments und EUROPARL, die Aufzeichnung des Europäischen Parlaments. Wenn solche Korporate zur Verfügung stehen, können gute Ergebnisse erzielt werden, die ähnliche Texte übersetzen, aber solche Korporate sind noch selten für viele Sprachpaare. Die erste statistische maschinelle Übersetzungssoftware war CANDIDE von IBM. Google verwendet SYSTRAN für mehrere Jahre, aber im Oktober 2007 auf eine statistische Übersetzungsmethode umgestellt. 2005 verbesserte Google seine internen Übersetzungsfunktionen durch die Verwendung von rund 200 Milliarden Wörtern aus Materialien der Vereinten Nationen, um ihr System zu trainieren; die Übersetzungsgenauigkeit verbesserte sich. Google Translate und ähnliche statistische Übersetzungsprogramme arbeiten, indem Sie Muster in Hunderten von Millionen von Dokumenten, die zuvor von Menschen übersetzt wurden und intelligente Erraten basierend auf den Ergebnissen. In der Regel, die menschlich übersetzten Dokumente in einer bestimmten Sprache verfügbar, desto wahrscheinlicher ist es, dass die Übersetzung von guter Qualität sein wird. Neue Ansätze zur statistischen maschinellen Übersetzung wie METIS II und PRESEMT verwenden minimale Korpusgröße und konzentrieren sich stattdessen auf die Ableitung syntaktischer Struktur durch Mustererkennung. Mit der Weiterentwicklung kann dies die statistische maschinelle Übersetzung von einem einsprachigen Textkorpus ermöglichen. Der größte Untergang von SMT beinhaltet, dass er von großen Mengen von parallelen Texten, seinen Problemen mit morphologiereichen Sprachen (insbesondere bei der Übersetzung in solche Sprachen) und seiner Unfähigkeit, Singletonfehler zu korrigieren abhängig ist. Beispielbasierte maschinelle Übersetzung (EBMT) wurde 1984 von Makoto Nagao vorgeschlagen. Beispielbasierte maschinelle Übersetzung basiert auf der Idee der Analogie. Bei diesem Ansatz ist der verwendete Korpus eine, die bereits übersetzte Texte enthält. Bei einem Satz, der übersetzt werden soll, werden Sätze aus diesem Korpus ausgewählt, die ähnliche subsentielle Komponenten enthalten. Die ähnlichen Sätze werden dann verwendet, um die subsentiellen Komponenten des ursprünglichen Satzes in die Zielsprache zu übersetzen, und diese Sätze werden zu einer vollständigen Übersetzung zusammengefügt. Hybrid MT Hybride maschinelle Übersetzung (HMT) nutzt die Stärken statistischer und regelbasierter Übersetzungsmethoden. Mehrere MT-Organisationen behaupten einen hybriden Ansatz, der sowohl Regeln als auch Statistiken verwendet. Die Ansätze unterscheiden sich in einer Reihe von Möglichkeiten: Regeln, die durch Statistiken nachverarbeitet werden: Übersetzungen werden mit einem regelbasierten Motor durchgeführt. Statistiken werden dann in einem Versuch verwendet, die Leistung von der Regelmaschine einzustellen/korrigieren. Statistiken nach Regeln: Mit Regeln werden Daten vorprozessiert, um den statistischen Motor besser zu führen. Außerdem werden Regeln verwendet, um die statistische Ausgabe nachzuarbeiten, um Funktionen wie die Normalisierung durchzuführen. Dieser Ansatz hat viel mehr Leistung, Flexibilität und Kontrolle beim Übersetzen. Es bietet auch eine umfassende Kontrolle über die Art und Weise, wie der Inhalt während der Vorübersetzung (z.B. Beschriftung von Inhalten und nicht übertragbaren Begriffen) und der Nachübersetzung (z.B. Nachübersetzungskorrekturen und Anpassungen) verarbeitet wird. Vor kurzem, mit dem Aufkommen von Neural MT, eine neue Version der hybriden maschinellen Übersetzung entsteht, die die Vorteile von Regeln, statistische und neurale maschinelle Übersetzung kombiniert. Der Ansatz ermöglicht die Vor- und Nachbearbeitung in einem Regel geführten Workflow sowie die Vorteile von NMT und SMT. Der Nachteil ist die inhärente Komplexität, die den Ansatz nur für bestimmte Anwendungsfälle geeignet macht. Neural MTA Deep Learning-Base-Ansatz zu MT, neurale maschinelle Übersetzung hat in den letzten Jahren schnelle Fortschritte gemacht, und Google hat angekündigt, seine Übersetzungsdienste nutzen diese Technologie jetzt bevorzugt über ihre früheren statistischen Methoden. Ein Microsoft-Team behauptet, dass er am WMT-2017 ("EMNLP 2017 Second Conference On Machine Translation") im Jahr 2018 menschliche Parität erreicht habe, was einen historischen Meilenstein markiert. Viele Forscher haben jedoch diesen Anspruch kritisiert, ihre Experimente neu zu führen und zu diskutieren; aktueller Konsens ist, dass die so genannte menschliche Parität nicht real ist, ganz auf begrenzten Domänen, Sprachpaaren und bestimmten Testanzügen basiert, d.h. es fehlt an statistischer Bedeutung. Es gibt noch eine lange Reise, bevor NMT echte menschliche Gleichheitsleistungen erreicht. Um die idiomatische Phrasenübersetzung, Multiwortausdrücke und niederfrequente Wörter (auch OOV genannt, oder Out-of-vocabulary Wortübersetzung) anzugehen, wurden sprachorientierte sprachliche Merkmale in hochmodernen neuronalen Maschinenübersetzungsmodellen (NMT) erforscht. So haben sich die chinesischen Charakterzersetzungen in Radikale und Schlaganfälle als hilfreich erwiesen, um mehrwörtliche Ausdrücke in NMT zu übersetzen. Wichtige Fragen Disambiguation Wort-Sense-Diambiguation betrifft eine geeignete Übersetzung zu finden, wenn ein Wort mehr als eine Bedeutung haben kann. Das Problem wurde in den 1950er Jahren von Yehoshua Bar-Hillel aufgeworfen. Er wies darauf hin, dass ohne "universale Enzyklopädie" eine Maschine niemals zwischen den beiden Bedeutungen eines Wortes unterscheiden könne. Heute gibt es zahlreiche Ansätze, um dieses Problem zu überwinden. Sie können annähernd in flache Ansätze und tiefe Ansätze unterteilt werden. Langsame Ansätze nehmen keine Kenntnis des Textes an. Sie wenden einfach statistische Methoden auf die Wörter an, die das mehrdeutige Wort umgeben. Tiefe Ansätze vermuten ein umfassendes Wissen über das Wort. Bisher waren flache Ansätze erfolgreicher. Claude Piron, ein langjähriger Übersetzer für die Vereinten Nationen und die Weltgesundheitsorganisation, schrieb, dass die maschinelle Übersetzung bestenfalls den leichteren Teil eines Übersetzers automatisiert; der härtere und zeitaufwendigere Teil beinhaltet in der Regel umfangreiche Forschung, um Mehrdeutigkeiten im Quelltext zu lösen, die die grammatikalischen und lexischen Ausprägungen der Zielsprache erfordern zu lösen: Warum braucht ein Übersetzer einen ganzen Arbeitstag, um fünf Seiten zu übersetzen, und nicht eine Stunde oder zwei?...Über 90% eines Durchschnittstextes entspricht diesen einfachen Bedingungen. Aber leider gibt es die anderen 10 % Es ist dieser Teil, der sechs [mehr] Stunden Arbeit erfordert. Es gibt Mehrdeutigkeiten, die man lösen muss. So zitierte der Autor des Quelltextes, ein australischer Arzt, das Beispiel einer Epidemie, die während des Zweiten Weltkriegs in einem "japanischen Kriegsgefangenen" erklärt wurde. Hat er von einem amerikanischen Lager mit japanischen Gefangenen oder einem japanischen Lager mit amerikanischen Gefangenen gesprochen? Das Englische hat zwei Sinne. Es ist daher notwendig, Forschung zu tun, vielleicht im Ausmaß eines Anrufs nach Australien. Die ideale tiefe Herangehensweise würde die Übersetzungssoftware dazu zwingen, alle für diese Art von Disambiguation notwendigen Forschungen alleine durchzuführen; dies würde jedoch einen höheren Grad an KI erfordern, als noch erreicht wurde. Eine flache Herangehensweise, die einfach im Sinne der mehrdeutigen englischen Phrase erraten hat, die Piron erwähnt (basierend, vielleicht, auf welcher Art von Gefangenenlager häufiger in einem bestimmten Korpus erwähnt wird) eine vernünftige Chance haben würde, ziemlich oft falsch zu erraten. Ein flacher Ansatz, der "die Benutzer über jede Mehrdeutigkeit" beinhaltet, würde nach Pirons Schätzung nur etwa 25% der Arbeit eines professionellen Übersetzers automatisieren, so dass die härteren 75% noch von einem Menschen zu tun. Nicht standardisierte Rede Eines der wichtigsten Fallstricke von MT ist seine Unfähigkeit, nicht standardisierte Sprache mit der gleichen Genauigkeit wie Standardsprache zu übersetzen. Heuristische oder statistische basierte MT nimmt von verschiedenen Quellen in Standardform einer Sprache ein. Regelbasierte Übersetzung enthält naturgemäß keine gemeinsamen nicht standardmäßigen Nutzungen. Dies führt zu Irrtümern bei der Übersetzung aus einer vernakulären Quelle oder in kolloquiale Sprache. Einschränkungen der Übersetzung aus lässiger Rede stellen Probleme bei der Verwendung von maschineller Übersetzung in mobilen Geräten dar. Name In der Informationsgewinnung beziehen sich benannte Entitäten in engem Sinne auf konkrete oder abstrakte Entitäten in der realen Welt wie Menschen, Organisationen, Unternehmen und Orte, die einen richtigen Namen haben: George Washington, Chicago, Microsoft.Es bezieht sich auch auf Ausdrücke von Zeit, Raum und Menge wie 1. Juli 2011, $500. Im Satz "Smith ist der Präsident von Fabrionix" sind sowohl Smith als auch Fabrionix benannte Wesen und können über Vornamen oder andere Informationen weiterqualifiziert werden; Präsident ist es nicht, da Smith früher eine andere Position bei Fabrionix, z.B. Vice President, haben könnte. Der Begriff starrer Designator definiert diese Verwendungen zur Analyse in der statistischen maschinellen Übersetzung. Die benannten Stellen müssen zunächst im Text identifiziert werden; wenn nicht, können sie irrtümlich als gemeinsame Nouns übersetzt werden, was die BLEU-Bewertung der Übersetzung am ehesten nicht beeinflussen würde, sondern die menschliche Lesbarkeit des Textes verändern würde. Sie können aus der Ausgabeübersetzung weggelassen werden, was auch Auswirkungen auf die Lesbarkeit und Nachricht des Textes hätte. Transliteration beinhaltet das Finden der Buchstaben in der Zielsprache, die am engsten dem Namen in der Quellsprache entsprechen. Dies wurde jedoch als teilweise Verschlechterung der Qualität der Übersetzung bezeichnet. Für "Southern California" sollte das erste Wort direkt übersetzt werden, während das zweite Wort transliteriert werden sollte. Maschinen transliterate oft beide, weil sie sie als eine Einheit behandelt. Wörter wie diese sind schwer für maschinelle Übersetzer, auch solche mit einer Transliterationskomponente, zu verarbeiten. Verwendung einer Do-No-Translate-Liste, die das gleiche Ziel hat – Transliteration im Gegensatz zur Übersetzung. immer noch auf die korrekte Identifizierung der benannten Stellen. Ein dritter Ansatz ist ein klassenbasiertes Modell. Namenseinheiten werden durch ein Zeichen ersetzt, um ihre Klasse zu vertreten; Ted und Erica würden beide durch Personenklasse-Token ersetzt. Dann kann die statistische Verteilung und Verwendung von Personennamen im Allgemeinen analysiert werden, anstatt die Verteilungen von Ted und Erica einzeln zu betrachten, so dass die Wahrscheinlichkeit eines bestimmten Namens in einer bestimmten Sprache die zugeordnete Wahrscheinlichkeit einer Übersetzung nicht beeinträchtigt. Eine Studie von Stanford über die Verbesserung dieses Bereichs der Übersetzung gibt den Beispielen, dass verschiedene Wahrscheinlichkeiten zugeordnet werden "David geht für einen Spaziergang" und "Ankit geht für einen Spaziergang" für Englisch als Zielsprache aufgrund der unterschiedlichen Anzahl von Ereignissen für jeden Namen in den Trainingsdaten. Ein frustrierendes Ergebnis der gleichen Studie von Stanford (und andere Versuche, die genannte Erkennungsübersetzung zu verbessern) ist, dass viele Male, eine Abnahme der BLEU-Scores für die Übersetzung aus der Aufnahme von Methoden für benannte Einheit Übersetzung. Etwas verwandt sind die Phrasen "Tee mit Milch trinken" vs. "Tee mit Molly trinken". Übersetzung aus multiparallelen Quellen Einige Arbeiten wurden in der Nutzung der multiparallelen Korporation durchgeführt, das ist ein Text, der in 3 oder mehr Sprachen übersetzt wurde. Mit diesen Methoden kann ein Text, der in 2 oder mehr Sprachen übersetzt wurde, in Kombination verwendet werden, um eine genauere Übersetzung in eine dritte Sprache zu liefern, als wenn nur eine dieser Quellsprachen allein verwendet wurden. Ontologien in MTAn-Ontologie ist eine formale Darstellung von Wissen, die die Konzepte (wie Objekte, Prozesse etc.) in einer Domäne und einige Beziehungen zwischen ihnen einschließt. Wenn die gespeicherten Informationen sprachlich sind, kann man von einem Lexikon sprechen. In NLP können Onlogien als Wissensquelle für maschinelle Übersetzungssysteme verwendet werden. Mit Zugang zu einer großen Wissensbasis können Systeme in der Lage sein, viele (insbesondere lexische) Mehrdeutigkeiten auf eigene Faust zu lösen. In den folgenden klassischen Beispielen, als Menschen, sind wir in der Lage, den präpositionalen Satz nach dem Kontext zu interpretieren, weil wir unser Weltwissen verwenden, in unseren Lexikonen gespeichert: "Ich sah einen Mann/Sterne/Molekule mit einem Mikroskop/Tescope/Binokular." Ein maschinelles Übersetzungssystem wäre zunächst nicht in der Lage, zwischen den Bedeutungen zu unterscheiden, da sich Syntax nicht ändert. Mit einer großen genug Ontologie als Wissensquelle können jedoch die möglichen Interpretationen von mehrdeutigen Wörtern in einem bestimmten Kontext reduziert werden. Weitere Nutzungsbereiche für Ontologien innerhalb von NLP beinhalten Informationsabruf, Informationsextraktion und Textzusammenfassung. Bau von Onlogien Die 1993 für das wissensbasierte Maschinenübersetzungssystem PANGLOSS generierte Ontologie kann als Beispiel dafür dienen, wie eine Ontologie für NLP-Zwecke zusammengestellt werden kann: Eine großformatige Ontologie ist notwendig, um das Parsing in den aktiven Modulen des maschinellen Übersetzungssystems zu unterstützen. Im PANGLOSS-Beispiel sollen etwa 50.000 Knoten unter dem kleineren, manuell aufgebauten oberen (abstrakten) Bereich der Ontologie subsumiert werden. Aufgrund seiner Größe musste sie automatisch erstellt werden. Ziel war es, die beiden Ressourcen LDOCE online und WordNet zusammenzuführen, um die Vorteile beider zu kombinieren: präzisieren Definitionen von Longman, und semantische Beziehungen, die eine halbautomatische Taxonomisierung auf die Ontologie von WordNet ermöglichen. Ein Definitionsvergleichsalgorithmus wurde erstellt, um automatisch die richtigen Bedeutungen von mehrdeutigen Wörtern zwischen den beiden Online-Ressourcen zusammenzufassen, basierend auf den Wörtern, die die Definitionen dieser Bedeutungen in LDOCE und WordNet gemeinsam haben. Mit einer Ähnlichkeitsmatrix passt der Algorithmus zwischen Bedeutungen einschließlich eines Vertrauensfaktors. Dieser Algorithmus allein passte jedoch nicht alle Bedeutungen richtig auf sich. Es wurde daher ein zweiter Hierarchie-Match-Algorithmus erstellt, der die in WordNet (Deep Hierarchies) und teilweise in LDOCE (Flachhierarchien) gefundenen taxonomischen Hierarchien verwendet. Dies funktioniert, indem man zunächst eindeutige Bedeutungen abgleicht und den Suchraum nur auf die jeweiligen Vorfahren und Nachkommen dieser übereinstimmenden Bedeutungen begrenzt. So hat der Algorithmus lokal eindeutige Bedeutungen (z.B. während das Wortsiegel als solches mehrdeutig ist, gibt es in der Tiersubhierarchie nur eine Bedeutung des Siegels). Beide Algorithmen ergänzten sich und halfen, eine großformatige Ontologie für das maschinelle Übersetzungssystem aufzubauen. Die WordNet-Hierarchien, gepaart mit den entsprechenden Definitionen von LDOCE, wurden der Oberregion der Ontologie untergeordnet. Dadurch konnte das PANGLOSS MT-System vor allem in seinem Generationselement diese Wissensbasis nutzen. Anwendungen Während kein System den heiligen Grail der vollautomatischen qualitativ hochwertigen maschinellen Übersetzung von unbeschränktem Text bietet, produzieren viele vollautomatische Systeme eine angemessene Leistung. Die Qualität der maschinellen Übersetzung wird wesentlich verbessert, wenn die Domain eingeschränkt und gesteuert wird. Trotz ihrer inhärenten Einschränkungen werden MT-Programme weltweit genutzt. Wahrscheinlich der größte institutionellen Benutzer ist die Europäische Kommission. Das von der Universität Göteborg koordinierte Projekt MOLTO erhielt von der EU mehr als 2,375 Millionen Euro Projektunterstützung, um ein zuverlässiges Übersetzungstool zu schaffen, das eine Mehrheit der EU-Sprachen umfasst. Die Weiterentwicklung der MT-Systeme kommt zu einer Zeit, in der Budgetkürzungen in der menschlichen Übersetzung die Abhängigkeit der EU von zuverlässigen MT-Programmen erhöhen können. Die Europäische Kommission hat 3,72 Millionen Euro (über ihr ISA-Programm) für die Schaffung von MT@EC, einem auf die administrativen Bedürfnisse der EU zugeschnittenen statistischen maschinellen Übersetzungsprogramm, zur Ersetzung eines vorherigen regelbasierten maschinellen Übersetzungssystems beigetragen. Im Jahr 2005 behauptete Google, dass vielversprechende Ergebnisse mit einer proprietären statistischen Maschine Übersetzungsmaschine erhalten wurden. Die in den Google-Sprachwerkzeugen verwendete statistische Übersetzungsmaschine für Arabisch <-> Englisch und Chinesisch <-> Englisch hatte eine Gesamtwertung von 0,4281 über den Vorläufer IBMs BLEU-4 Punktzahl von 0,3954 (Sommer 2006) in Tests des National Institute for Standards and Technology. Mit dem jüngsten Fokus auf den Terrorismus investieren die militärischen Quellen in den Vereinigten Staaten beträchtliche Mengen an Geld in die natürliche Sprachtechnik. In-Q-Tel (ein Risikokapitalfonds, der größtenteils von der US Intelligence Community finanziert wird, um neue Technologien durch Privatunternehmer zu stimulieren) brachte Unternehmen wie Language Weaver auf. Derzeit interessiert sich die Militärgemeinschaft für die Übersetzung und Verarbeitung von Sprachen wie Arabisch, Pashto und Dari.In diesen Sprachen steht der Fokus auf Schlüsselphrasen und schnelle Kommunikation zwischen Militärmitgliedern und Zivilisten durch die Verwendung von Handy-Apps. Das Informationsverarbeitungstechnologiebüro in DARPA beherbergt Programme wie TIDES und Babylon Übersetzer. US Air Force hat einen $1 Million Vertrag zur Entwicklung einer Sprachübersetzungstechnologie vergeben. Der bemerkenswerte Anstieg der sozialen Vernetzung im Internet in den letzten Jahren hat noch eine weitere Nische für die Anwendung der maschinellen Übersetzungssoftware geschaffen – in Diensten wie Facebook oder Instant Messaging-Clients wie Skype, GoogleTalk, MSN Messenger, etc. – so dass Nutzer, die verschiedene Sprachen sprechen, miteinander kommunizieren können. Auch für die meisten mobilen Geräte wurden maschinelle Übersetzungsanwendungen veröffentlicht, darunter Mobiltelefone, Pocket-PCs, PDAs, etc. Aufgrund ihrer Portabilität sind solche Instrumente als mobile Übersetzungstools bezeichnet worden, die es ermöglichen, die mobile Unternehmensvernetzung zwischen Partnern, die verschiedene Sprachen sprechen, zu ermöglichen oder sowohl Fremdsprachenerwerb als auch unbegleitetes Reisen in fremde Länder zu erleichtern, ohne dass die Vermittlung eines menschlichen Übersetzers erforderlich ist. Obwohl der von der Regierung der Vereinigten Staaten zusammengefügte Automated Language Processing Advisory Committee 1966 als unwürdiger Konkurrent zur menschlichen Übersetzung bezeichnet wurde, wurde die Qualität der maschinellen Übersetzung nun so verbessert, dass seine Anwendung in der Online-Kooperation und im medizinischen Bereich untersucht wird. Die Anwendung dieser Technologie in medizinischen Einstellungen, in denen menschliche Übersetzer abwesend sind, ist ein weiteres Thema der Forschung, aber Schwierigkeiten entstehen aufgrund der Bedeutung der genauen Übersetzungen in der medizinischen Diagnose. Bewertung Es gibt viele Faktoren, die beeinflussen, wie maschinelle Übersetzungssysteme ausgewertet werden. Diese Faktoren umfassen den Verwendungszweck der Übersetzung, die Art der maschinellen Übersetzungssoftware und die Art des Übersetzungsprozesses. Verschiedene Programme können für verschiedene Zwecke gut funktionieren. Beispielsweise übertrifft die statistische maschinelle Übersetzung (SMT) in der Regel eine exemplarische maschinelle Übersetzung (EBMT), aber Forscher fanden heraus, dass EBMT bei der Bewertung von englischer bis französischer Übersetzung besser arbeitet. Das gleiche Konzept gilt für technische Dokumente, die durch SMT aufgrund ihrer formalen Sprache leichter übersetzt werden können. In bestimmten Anwendungen, z.B. Produktbeschreibungen, die in einer kontrollierten Sprache geschrieben werden, hat ein wörterbuchbasiertes maschinelles Übersetzungssystem jedoch zufriedenstellende Übersetzungen erzeugt, die keinen menschlichen Eingriff zur Qualitätsprüfung erfordern. Es gibt verschiedene Mittel zur Auswertung der Ausgangsqualität von maschinellen Übersetzungssystemen. Die älteste ist die Verwendung menschlicher Richter zur Beurteilung der Qualität der Übersetzung. Obwohl die menschliche Auswertung zeitaufwendig ist, ist es nach wie vor die zuverlässigste Methode, verschiedene Systeme wie regelbasierte und statistische Systeme zu vergleichen. Automatisierte Bewertungsmittel sind BLEU, NIST, METEOR und LEPOR. Die ausschließlich auf ungeahnte maschinelle Übersetzung zu begreifen ignoriert die Tatsache, dass die Kommunikation in der menschlichen Sprache kontextgebunden ist und dass es eine Person braucht, um den Kontext des Originaltextes mit einer angemessenen Wahrscheinlichkeit zu verstehen. Es ist sicherlich wahr, dass selbst rein human erzeugte Übersetzungen fehleranfällig sind. Um sicherzustellen, dass eine maschinell erzeugte Übersetzung für einen Menschen nützlich sein wird und dass eine Veröffentlichungsqualität erreicht wird, müssen diese Übersetzungen von einem Menschen überprüft und bearbeitet werden. Der späte Claude Piron schrieb, dass die maschinelle Übersetzung am besten den leichteren Teil eines Übersetzers automatisiert; der härtere und zeitaufwendigere Teil beinhaltet in der Regel umfangreiche Forschung, um Mehrdeutigkeiten im Quelltext zu lösen, die die grammatikalischen und lexischen Ausprägungen der Zielsprache erfordern zu lösen. Eine solche Forschung ist ein notwendiges Vorspiel für die Vorbeschriftung, die erforderlich ist, um die Eingabe für die maschinelle Übersetzungssoftware so zu gestalten, dass die Ausgabe nicht bedeutungslos ist. Neben Disambiguationsproblemen kann aufgrund unterschiedlicher Trainingsdaten für maschinelle Übersetzungsprogramme eine geringere Genauigkeit auftreten. Sowohl die exemplarische als auch die statistische maschinelle Übersetzung verlassen sich auf eine Vielzahl von realen Beispielsätzen als Basis für die Übersetzung, und wenn zu viele oder zu wenige Sätze analysiert werden, wird die Genauigkeit gefährdet. Forscher fanden heraus, dass, wenn ein Programm auf 203,529 Sätze Paarungen trainiert wird, die Genauigkeit tatsächlich verringert. Das optimale Niveau der Trainingsdaten scheint knapp über 100.000 Sätze zu sein, möglicherweise weil mit zunehmenden Trainingsdaten die Anzahl der möglichen Sätze zunimmt, wodurch es schwieriger wird, ein exaktes Übersetzungsspiel zu finden. Werkzeugübersetzung als Lehrwerkzeug Obwohl es Bedenken hinsichtlich der Genauigkeit der maschinellen Übersetzung gab, hat Dr. Ana Nino von der Universität Manchester einige der Vorteile bei der Nutzung der maschinellen Übersetzung im Klassenzimmer untersucht. Eine solche pädagogische Methode wird mit "MT als Bad Model" bezeichnet. MT als Bad Model zwingt den Sprachlerner dazu, Inkonsistenzen oder falsche Aspekte einer Übersetzung zu identifizieren; wiederum besitzt der individuelle Wille (hoffentlich) ein besseres Verständnis der Sprache. Dr. Nino zitiert, dass dieses Lehrinstrument in den späten 1980er Jahren umgesetzt wurde. Am Ende der verschiedenen Semester konnte Dr. Nino Umfrageergebnisse von Studenten erhalten, die MT als Bad Model (sowie andere Modelle) verwendet hatten. Überwältigend fühlten die Schüler, dass sie ein verbessertes Verständnis, ein lexisches Retrieval und ein erhöhtes Vertrauen in ihre Zielsprache beobachtet hatten. maschinelle Übersetzung und signierte Sprachen Anfang der 2000er Jahre waren die Optionen für die maschinelle Übersetzung zwischen gesprochenen und unterschriebenen Sprachen stark eingeschränkt. Es war ein allgemeiner Glaube, dass taube Individuen traditionelle Übersetzer verwenden könnten. Allerdings werden Stress, Intonation, Pech und Timing in gesprochenen Sprachen im Vergleich zu signierten Sprachen sehr unterschiedlich vermittelt. Daher kann ein taubes Individuum über die Bedeutung von geschriebenem Text, der auf einer gesprochenen Sprache basiert, falsch interpretieren oder verwirren. Forscher Zhao, et al.(2000,) entwickelten einen Prototyp namens TEAM (Übersetzung von Englisch zu ASL durch Maschine), der englische Übersetzungen zu American Sign Language (ASL) abschließte. Das Programm würde zunächst die syntaktischen, grammatischen und morphologischen Aspekte des englischen Textes analysieren. Nach diesem Schritt greift das Programm auf einen Sign-Synthesizer auf, der als Wörterbuch für ASL fungierte. Dieser Synthesizer beherbergte den Prozess, dem man folgen muss, um ASL-Zeichen zu vervollständigen, sowie die Bedeutungen dieser Zeichen. Sobald der gesamte Text analysiert wird und die zur Vervollständigung der Übersetzung notwendigen Zeichen im Synthesizer liegen, erschien ein Computer, der Mensch erzeugte und ASL verwendet, um den englischen Text dem Benutzer zu unterschreiben. Urheberrecht Nur Werke, die originell sind, unterliegen dem Urheberrechtsschutz, so behaupten einige Wissenschaftler, dass maschinelle Übersetzungsergebnisse nicht zum Urheberrecht berechtigt sind, da MT keine Kreativität beinhaltet. Das Urheberrecht ist für eine Derivatisierung; der Urheber der Originalarbeit in der Originalsprache verliert seine Rechte nicht, wenn ein Werk übersetzt wird: ein Übersetzer muss eine Übersetzung veröffentlichen. Siehe auch Hinweise Weiter lesen Cohen, J. M. (1986,) Übersetzung, Encyclopedia Americana, 27, pp.12–15 Hutchins, W. John; Somers, Harold L. (1992). Eine Einführung in die maschinelle Übersetzung. London: Akademische Presse. ISBN 0-12-362830-X. Lewis-Kraus, Gideon, "Tower of Babble", New York Times Magazine, 7. Juni 2015, pp.48–52 Externe Links Die Vorteile und Nachteile der maschinellen Übersetzung Warum Google niemals eine Übersetzungsagentur International Association for Machine Translation (IAMT)Machine Translation Archive von John Hutchins ersetzen wird. Ein elektronisches Repository (und Bibliographie) von Artikeln, Büchern und Papieren auf dem Gebiet der maschinellen Übersetzung und Computer-basierte Übersetzungstechnologie Maschine Übersetzung (Computer-basierte Übersetzung) – Publikationen von John Hutchins (inklusive PDFs von mehreren Büchern auf maschinelle Übersetzung) Maschine Übersetzung und Minority Sprachen John Hutchins 1999A Crowbar, auch genannt ein Wracking Bar, Pry Bar oder Prybar, Pinch-Bar, Großbritannien Crowbars werden häufig verwendet, um vernägte Holzkisten zu öffnen oder zerlegen Bretter. Das Design kann als jede der drei Hebelklassen verwendet werden. Das gekrümmte Ende wird üblicherweise als ein erstklassiger Hebel und das flache Ende als zweitklassiger Hebel verwendet. Designs aus dickem Flachstahlstab werden oft als Gebrauchsbalken bezeichnet. Materialien und Konstruktion Normalerweise aus mittel-Kohlenstoff-Stahl können Krähen alternativ aus Titan hergestellt werden, was den Vorteil hat, leichter zu sein. Üblicherweise werden Krähen aus langen Stahlerzeugnissen geschmiedet, entweder sechseckig oder teilweise zylindrisch. Alternative Ausführungen können mit einer gerundeten I-förmigen Querschnittswelle geschmiedet werden. Versionen mit relativ breiten flachen Stahlbalken werden oft als Utility Bars bezeichnet. Etymologie und Nutzung Die akzeptierte Etymologie identifiziert die erste Komponente des Wortes crowbar mit der Vogelnamen crow, vielleicht aufgrund der Ähnlichkeit der crowbar zu den Füßen oder Schnabel einer Krähe. Die erste Bestätigung des Wortes ist auf ca. 1400 zurückgegangen. Sie wurden auch nur Krähen genannt, oder Eisen Krähen; William Shakespeare verwendet den Begriff Eisen Krähe an vielen Orten, einschließlich seines Spiels Romeo und Julia, Act 5, Szene 2: "Get mir eine Eisenkrähe und bringt sie direkt in meine Zelle. " In Daniel Defoes 1719 Roman Robinson Crusoe verwendet der Protagonist Crowbars als Pickaxes, bezieht sich aber auf diese Werkzeuge als Eisenpfeile: "Als für die Pickaxe habe ich die Eisenkrähen benutzt, die richtig genug waren, obwohl schwer. "In Großbritannien, Irland, Neuseeland und Australien kann aufgrund des Einflusses der amerikanischen Mediencrowbar gelegentlich lose für dieses Tool verwendet werden, aber es wird immer noch hauptsächlich verwendet, um ein größeres geraderes Werkzeug, seine ursprüngliche englische Bedeutung (siehe Graben Bar). Der Begriff Jammy oder Jimmy bezieht sich am häufigsten auf das Werkzeug, wenn für Einbruch verwendet. Typen Ausrichtung Pry Bar, auch als Sleeve Bar Cat Kralle Pry Bar bezeichnet, mehr einfach als Claw Bar Digging Pry Bar Flat pry bar Gooseneck Pry Bar Heavy Duty Pry Bar Molding Pry Bar Rolling Kopf Pry Bar See auch Digging Bar Halligan Bar Reifen Eisen Halb-Life (Videospielserie) == Referenzen ==