In der computergestützten Intelligenz (CI) ist ein evolutionärer Algorithmus (EA) eine Untermenge evolutionärer Berechnung, ein generischpopulationsbasierter metaheuristischer Optimierungsalgorithmus. Ein EA verwendet Mechanismen, die von der biologischen Evolution inspiriert sind, wie Reproduktion, Mutation, Rekombination und Selektion. Kandidatenlösungen für das Optimierungsproblem spielen die Rolle von Individuen in einer Bevölkerung und die Fitnessfunktion bestimmt die Qualität der Lösungen (siehe auch Verlustfunktion). Die Evolution der Bevölkerung erfolgt dann nach der wiederholten Anwendung der oben genannten Betreiber. Evolutionäre Algorithmen führen häufig gut anpassende Lösungen für alle Arten von Problemen durch, weil sie idealerweise keine Annahme über die zugrunde liegende Fitness-Landschaft machen. Techniken aus evolutionären Algorithmen, die auf die Modellierung der biologischen Evolution angewendet werden, sind in der Regel auf Erkundungen mikroevolutionärer Prozesse und Planungsmodelle basierend auf zellulären Prozessen beschränkt. In den meisten realen Anwendungen von EAs ist die rechnerische Komplexität ein verbietender Faktor. In der Tat ist diese rechnerische Komplexität auf die Bewertung von Fitness-Funktionen zurückzuführen. Fitness Approximation ist eine der Lösungen, um diese Schwierigkeit zu überwinden. Jedoch kann scheinbar einfache EA oft komplexe Probleme lösen; daher kann es keine direkte Verbindung zwischen Algorithmus-Komplexität und Problemkomplexität geben. Durchführung Das folgende ist ein Beispiel für einen generischen einobjektiven genetischen Algorithmus. Schritt 1: Generieren Sie die anfängliche Bevölkerung von Personen zufällig.(Erste Generation) Schritt 2: Wiederholen Sie die folgenden Regenerationsschritte bis zur Beendigung: Bewerten Sie die Fitness jedes einzelnen in der Bevölkerung (Zeitgrenze, ausreichende Fitness, etc.) Wählen Sie die fittest Individuen für die Reproduktion.(Parents)Breed neue Individuen durch Crossover und Mutation Operationen zur Geburt an Nachkommen. Ersetzen Sie die am wenigsten geeigneten Individuen der Bevölkerung mit neuen Individuen. Arten Ähnliche Techniken unterscheiden sich in der genetischen Darstellung und anderen Implementierungsdetails, und die Art des jeweiligen angewandten Problems. Genereller Algorithmus – Dies ist die beliebteste Art von EA. Man sucht die Lösung eines Problems in Form von Zeichenketten von Zahlen (traditionell binär, obwohl die besten Darstellungen in der Regel diejenigen sind, die etwas über das Problem lösen,) durch Anwendung von Operatoren wie Rekombination und Mutation (manchmal einmal ein, manchmal beides). Diese Art von EA wird häufig bei Optimierungsproblemen eingesetzt. Generelle Programmierung – Hier sind die Lösungen in Form von Computerprogrammen, und ihre Fitness wird durch ihre Fähigkeit, ein Rechenproblem zu lösen bestimmt. Evolutionäre Programmierung – Ähnlich wie bei der genetischen Programmierung, aber die Struktur des Programms ist fixiert und seine numerischen Parameter können sich entwickeln. Genexpressions-Programmierung – Wie genetische Programmierung entwickelt GEP auch Computerprogramme, aber es erforscht ein Genotyp-Phenotyp-System, wo Computerprogramme verschiedener Größen in linearen Chromosomen fester Länge kodiert werden. Evolution Strategie – Funktioniert mit Vektoren von realen Zahlen als Darstellungen von Lösungen und verwendet typischerweise selbstadaptive Mutationsraten. Differenzielle Evolution – Basierend auf Vektordifferenzen und ist daher vor allem für numerische Optimierungsprobleme geeignet. Neuroevolution – Ähnlich der genetischen Programmierung, aber die Genome stellen künstliche neuronale Netzwerke dar, indem Struktur und Verbindungsgewichte beschrieben werden. Die Genomcodierung kann direkt oder indirekt erfolgen. Lernklassifizierungssystem – Hier ist die Lösung ein Satz von Klassifikatoren (Regeln oder Bedingungen). Ein Michigan-LCS entwickelt sich auf der Ebene der einzelnen Klassifikatoren, während ein Pittsburgh-LCS Bevölkerungen von Klassifikatoren-Sets verwendet. Zunächst waren Klassifikatoren nur binär, umfassen aber jetzt echte, neuronale Netze oder S-Expressionstypen. Die Fitness wird typischerweise mit einem stärke- oder genauigkeitsbasierten Verstärkungslernen oder einem überwachten Lernansatz bestimmt. Vergleich zu biologischen Prozessen Eine mögliche Einschränkung vieler evolutionärer Algorithmen ist ihr Fehlen einer klaren Genotyp-Phenotyp-Unterscheidung. In der Natur erfährt die befruchtete Eizelle einen komplexen Prozess, der als Embryogenese bekannt ist, um zu einem reifen Phänotyp zu werden. Diese indirekte Kodierung wird angenommen, um die genetische Suche robuster zu machen (d.h. die Wahrscheinlichkeit tödlicher Mutationen zu verringern), und kann auch die Entfaltbarkeit des Organismus verbessern. Solche indirekten (auch als generative oder entwicklungspolitische) Kodierungen ermöglichen es auch, die Regelmäßigkeit in der Umwelt auszunutzen. Die jüngste Arbeit im Bereich der künstlichen embryogenen oder künstlichen Entwicklungssysteme versucht, diese Bedenken zu lösen. Und Genexpressions-Programmierung erforscht erfolgreich ein Genotyp-Phenotyp-System, wo der Genotyp aus linearen multigenen Chromosomenen fester Länge besteht und der Phenotyp aus mehreren Expressionsbäumen oder Computerprogrammen unterschiedlicher Größe und Formen besteht. Ähnliche Techniken Swarm Algorithmen enthalten Die Ant-Kolonie-Optimierung basiert auf den Ideen der Ameise, die durch Pheromone-Kommunikation zu Pfaden führt. Primär geeignet für kombinatorische Optimierungs- und Diagrammprobleme. Der Runner-root-Algorithmus (RRA) ist inspiriert von der Funktion von Läufern und Wurzeln von Pflanzen in der Natur Artificial bee Kolonie Algorithmus basiert auf der Honigbiene Futterverhalten. Primär vorgeschlagen zur numerischen Optimierung und erweitert um kombinatorische, eingeschränkte und multiobjektive Optimierungsprobleme zu lösen. Bienenalgorithmus basiert auf dem Futterverhalten von Honigbienen. Es wurde in vielen Anwendungen wie Routing und Schieduling angewendet. Die Cuckoo-Suche ist inspiriert vom Brutparasitism der Kuckuckspezies. Es nutzt auch Lévy-Flüge und passt damit zu globalen Optimierungsproblemen. Partikelschwarm-Optimierung basiert auf den Vorstellungen von Tierflockungsverhalten. Auch vor allem für numerische Optimierungsprobleme geeignet. Andere bevölkerungsbasierte metaheuristische Methoden Jagd Suche – Eine Methode inspiriert durch die Gruppenjagd von einigen Tieren wie Wölfe, die ihre Position organisieren, um die Beute zu umgeben, jeder von ihnen relativ zur Position der anderen und vor allem die von ihrem Führer. Es handelt sich um ein kontinuierliches Optimierungsverfahren, das als kombinatorisches Optimierungsverfahren ausgebildet ist. Adaptive Maßsuche – Im Gegensatz zu naturinspirierten metaheuristischen Techniken implementiert ein adaptiver dimensionaler Suchalgorithmus keine Metapher als zugrunde liegendes Prinzip. Vielmehr verwendet es eine einfache leistungsorientierte Methode, basierend auf der Aktualisierung des Suchdimensionalitätsverhältnisses (SDR) Parameters bei jeder Iteration. Firefly-Algorithmus ist inspiriert von dem Verhalten der Feuerfliegen, die sich gegenseitig durch blinkendes Licht anziehen. Dies ist insbesondere für die multimodale Optimierung von Nutzen. Harmoniesuche – Basierend auf den Ideen des Verhaltens der Musiker bei der Suche nach besseren Harmonien. Dieser Algorithmus eignet sich sowohl zur kombinatorischen Optimierung als auch zur Parameteroptimierung. Gaussische Anpassung – basierend auf der Informationstheorie. Verwendet für die Maximierung der Produktionsausbeute, mittlere Fitness oder durchschnittliche Informationen. Siehe zum Beispiel Entropy in der Thermodynamik und Informationstheorie. Memetischer Algorithmus – Eine Hybrid-Methode, inspiriert von Richard Dawkins Vorstellung einer Meme, nimmt es in der Regel die Form eines bevölkerungsbasierten Algorithmus zusammen mit einzelnen Lernprozessen, die lokale Verfeinerung durchführen können. Erhöht die Ausbeutung von problemspezifischen Kenntnissen und versucht, die lokale und globale Suche synergistisch zu orchestrieren. Beispiele Im Jahr 2020 erklärte Google, dass ihr AutoML-Zero klassische Algorithmen wie das Konzept von neuronalen Netzwerken erfolgreich wiederentdecken kann. Die Computersimulationen Tierra und Avida versuchen, makroevolutionäre Dynamiken zu modellieren. Galerie Referenzen Externe Links Eine Übersicht über die Geschichte und Flavors of Evolutionary Algorithms Bibliography Ashlock, D. (2006,) Evolutionary Computation for Modeling and Optimization, Springer, ISBN 0-387-22196-4.Bäck, T. (1996,) Evolutionäre Algorithmen in Theorie und Praxis: EvolutionPress Strategien, Evolutionary Programming, Genetic Algorithms, Oxford. Bäck, T,. Fogel, D,. Michalewicz, Z. (1997), Handbuch der Evolutionary Computation, Oxford Univ.Press. Banzhaf, W,. Nordin, P,. Keller, R,. Francone, F. (1998,) Genetische Programmierung - An Einführung, Morgan Kaufmann, San Francisco Eiben, A.E, Smith, J.E (2003,) Einführung in Evolutionary Computing, Springer. Holland, J. H. (1992), Adaptation in Natural and Artificial Systems, The University of Michigan Press, Ann Arbor Michalewicz Z,. Fogel D.B (2004). Wie man es löst: Moderne Heuristik, Springer. Benko, Attila; Dosa, Gyorgy; Tuza, Zsolt (2010). " Bin Packing/Covering with Delivery, gelöst mit der Entwicklung von Algorithmen".2010 IEEE Fünfte Internationale Konferenz zum Thema Bio-Inspired Computing: Theorien und Anwendungen (BIC-TA).pp.298–302.doi:10.1109/BICTA.2010.5645312.ISBN 978-1-4244-6437-1.S2CID 16875144.Poli, R.; Langdon, W. B.; McPhee, N. F. (2008). A Field Guide to Genetic Programming. Lulu.com, frei verfügbar aus dem Internet. ISBN 978-1-4092-0073-4.Archiviert aus dem Original auf 2016-05-27.Retrieved 2011-03-05.Preis, K,. Storn, R.M, Lampinen, J.A, (2005)." Differenz Evolution: Ein praktischer Ansatz zur globalen Optimierung", Springer. Ingo Rechenberg (1971): Evolutionsstrategie - Optimierung technischer Systeme nach Bakterien der biologischen Evolution (PhD-Thesis). Aufgedruckt von Fromman-Holzboog (1973). Hans-Paul Schwefel (1974): Numerische Optimierung von Computer-Modellen (PhD-Thesis). Nachgedruckt von Birkhäuser (1977).Simon, D. (2013): Evolutionary Optimization Algorithms, Wiley.Computational Intelligenz: Eine methodische Einführung von Kruse, Borgelt, Klawonn, Moewes, Steinbrecher, Held, 2013, Springer, ISBN 978-1-4471-5012-1 Rahman, Rosshairy Abd.; Kendall, Graham; Ramli, Razamin; Jamari, Zainoddin; Ku-Mahamud, Ku Ruhana (2017). " Shrimp Feed Formulierung über Evolutionary Algorithm mit Power Heuristics for Handling Constraints".Komplexität 2017: 1–12.doi:10.1155/2017/7053710