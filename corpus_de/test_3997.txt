Eine Hash-Funktion ist jede Funktion, die verwendet werden kann, um Daten beliebiger Größe auf Festgrößenwerte abzubilden. Die von einer Hash-Funktion zurückgegebenen Werte werden Hash-Werte, Hash-Codes, Verdauungen oder einfach Hashes genannt. Die Werte werden in der Regel verwendet, um eine Fix-Größe-Tabelle namens Hash-Tabelle zu indexieren. Verwendung einer Hash-Funktion zur Indexierung einer Hash-Tabelle wird Hashing oder Scatter-Speicheradresse genannt. Hash-Funktionen und deren zugehörigen Hash-Tabellen werden in Datenspeicher- und -abrufanwendungen verwendet, um Daten in einer kleinen und fast konstanten Zeit pro Abruf zuzugreifen, und benötigen eine Menge Speicherplatz nur fraktioniert größer als der für die Daten benötigte Gesamtraum bzw. Aufzeichnungen selbst. Hashing ist eine rechnerisch und speicherplatzsparende Form des Datenzugriffs, der die nichtlineare Zugriffszeit von bestellten und ungeordneten Listen und strukturierten Bäumen und die oft exponentiellen Speicheranforderungen des direkten Zugriffs von Staatsräumen von großen oder variablen Schlüsseln vermeidet. Der Einsatz von Hash-Funktionen beruht auf statistischen Eigenschaften von Schlüssel- und Funktionsinteraktion: Das schlimmste Verhalten ist mit einer verschwindend geringen Wahrscheinlichkeit untragbar schlecht, und das durchschnittliche Verhalten kann nahezu optimal sein (minimale Kollision). Hash-Funktionen sind mit (und oft verwirrt mit) Prüfsummen, überprüfen Ziffern, Fingerabdrücke, verlustige Kompression, randomization-Funktionen, fehlerkorrigierende Codes, und Chiffren. Obwohl sich die Konzepte in gewissem Maße überschneiden, hat jeder seinen eigenen Gebrauch und Anforderungen und ist anders gestaltet und optimiert. Die Hash-Funktionen unterscheiden sich von den Konzepten, die hauptsächlich in Bezug auf die Datenintegrität nummeriert sind. Überblick Eine Hash-Funktion nimmt eine Eingabe als Schlüssel, die einem Datum oder Datensatz zugeordnet ist und verwendet, um es zur Datenspeicherung und Abrufanwendung zu identifizieren. Die Tasten können wie eine ganze Zahl oder eine variable Länge wie ein Name festgelegt werden. In einigen Fällen ist der Schlüssel das Datum selbst. Die Ausgabe ist ein Hash-Code, der verwendet wird, um eine Hash-Tabelle, die die Daten oder Aufzeichnungen, oder Zeiger zu ihnen. Eine Hashfunktion kann als drei Funktionen betrachtet werden: Konvertieren Sie Variablenlängenschlüssel in feste Länge (in der Regel Maschinenwortlänge oder weniger) Werte, indem Sie diese mit Wörtern oder anderen Einheiten mit einem Parity-Reserving-Operator wie ADD oder XOR falten. Scramble die Bits der Taste, so dass die resultierenden Werte gleichmäßig über den Schlüsselraum verteilt werden. die Schlüsselwerte in einen, der kleiner oder gleich der Größe der Tabelle ist Eine gute Hashfunktion erfüllt zwei Grundeigenschaften: 1) sollte es sehr schnell zu berechnen sein; 2) es sollte die Vervielfältigung der Ausgangswerte (Kollisionen) minimieren. Hash-Funktionen verlassen sich auf die Erzeugung günstiger Wahrscheinlichkeitsverteilungen für ihre Wirksamkeit und reduzieren die Zugriffszeit auf nahezu konstant. Hohe Tabellenbelastungsfaktoren, pathologische Schlüsselsätze und schlecht gestaltete Hash-Funktionen können dazu führen, dass Zugriffszeiten linear in der Anzahl der Positionen in der Tabelle nähern. Hash-Funktionen können entworfen werden, um die beste schlechteste Leistung, gute Leistung unter hohen Tabellenbelastung Faktoren, und in speziellen Fällen, perfekte (kollisionlose) Mapping von Schlüsseln in Hash-Codes. Die Implementierung basiert auf paritätserhaltenden Bitoperationen (XOR und ADD), multiplizieren oder teilen. Ein notwendiger Übergang zur Hash-Funktion ist ein Kollisionsauflösungsverfahren, das eine Hilfsdatenstruktur wie verknüpfte Listen verwendet, oder eine systematische Bewährung der Tabelle, um einen leeren Slot zu finden. Hash-Tabellen Hash-Funktionen werden in Verbindung mit Hash-Tabelle verwendet, um Datenelemente oder Datensätze zu speichern und abzurufen. Die Hash-Funktion übersetzt den Schlüssel, der jedem Datum oder Datensatz zugeordnet ist, in einen Hash-Code, der zur Indexierung der Hash-Tabelle verwendet wird. Wenn ein Element der Tabelle hinzugefügt werden soll, kann der Hash-Code einen leeren Slot (auch als Bucket bezeichnet) indizieren, in welchem Fall der Artikel der Tabelle hinzugefügt wird. Wenn der Hash-Code einen vollen Slot indiziert, ist eine Art Kollisionsauflösung erforderlich: das neue Element kann weggelassen werden (nicht in der Tabelle hinzugefügt), oder das alte Element ersetzen, oder es kann in einem anderen Ort durch ein bestimmtes Verfahren zur Tabelle hinzugefügt werden. Dieses Verfahren hängt von der Struktur der Hashtabelle ab: Bei gekettetem Hashing ist jeder Schlitz der Kopf einer gelinkten Liste oder Kette, und Gegenstände, die am Schlitz kollidieren, werden der Kette hinzugefügt. Ketten können in beliebiger Reihenfolge gehalten und linear oder in serieller Reihenfolge gesucht werden, oder als selbstbestellende Liste mit Frequenz, um den Zugriff zu beschleunigen. Bei offener Adresshastung wird der Tisch ausgehend von dem belegten Schlitz in vorgegebener Weise, üblicherweise durch lineares Anheben, quadratisches Anheben oder Doppelhaspeln, bis sich ein offener Schlitz befindet oder der gesamte Tisch (Überlauf) abgetastet. Die Suche nach dem Artikel folgt dem gleichen Verfahren, bis sich der Artikel befindet, wird ein offener Schlitz gefunden oder die gesamte Tabelle durchsucht (Stück nicht in der Tabelle). Spezielle Hash-Funktionen werden auch verwendet, um Caches für große Datensätze zu bauen, die in langsamen Medien gespeichert sind. Ein Cache ist im Allgemeinen einfacher als ein Hashed-Suchtisch, da jede Kollision durch Verwerfen oder Zurückschreiben des älteren der beiden kollidierenden Elemente aufgelöst werden kann. Hash-Funktionen sind ein wesentlicher Bestandteil des Bloom-Filters, eine platzsparende probabilistische Datenstruktur, die verwendet wird, um zu testen, ob ein Element ein Element eines Satzes ist. Ein spezieller Fall der Hashing ist als geometrisches Hashing oder das Rasterverfahren bekannt. In diesen Anwendungen ist der Satz aller Eingänge eine Art metrischen Raum, und die Hashingfunktion kann als eine Partition dieses Raumes in ein Netz von Zellen interpretiert werden. Die Tabelle ist oft ein Array mit zwei oder mehr Indizes (genannte Rasterdatei, Rasterindex, Eimergitter und ähnliche Namen), und die Hash-Funktion gibt einen Indextuple zurück. Dieses Prinzip wird in Computergrafiken, Rechengeometrie und vielen anderen Disziplinen weit verbreitet, um viele Näherungsprobleme in der Ebene oder im dreidimensionalen Raum zu lösen, wie zum Beispiel am nächsten paarweise in einer Reihe von Punkten zu finden, ähnliche Formen in einer Liste von Formen, ähnliche Bilder in einer Bilddatenbank usw. Hash-Tabellen werden auch verwendet, um assoziative Arrays und dynamische Sets zu implementieren. Eigenschaften Gleichmäßigkeit Eine gute Hash-Funktion sollte die erwarteten Eingänge möglichst gleichmäßig über den Ausgangsbereich abbilden. Das heißt, jeder Hash-Wert im Ausgabebereich sollte mit etwa der gleichen Wahrscheinlichkeit erzeugt werden. Der Grund für diese letzte Anforderung ist, dass die Kosten für Hashing-basierte Verfahren stark ansteigen, da die Anzahl der Kollisionen - Paare von Eingängen, die auf den gleichen Hashwert abgebildet werden - zunimmt. Wenn einige Hash-Werte wahrscheinlicher auftreten als andere, ein größerer Teil der Lookup-Operationen muss durch eine größere Menge von kollidierenden Tabelleneinträgen suchen. Beachten Sie, dass dieses Kriterium nur den Wert gleichmäßig verteilt, nicht zufällig in irgendeiner Weise. Eine gute randomisierende Funktion ist in der Regel eine gute Wahl als Hash-Funktion, aber die Umkehr muss nicht wahr sein. Hash-Tabellen enthalten oft nur eine kleine Teilmenge der gültigen Eingänge. Zum Beispiel kann eine Club-Mitgliedsliste nur hundert oder so Mitgliedernamen enthalten, aus dem sehr großen Satz aller möglichen Namen. In diesen Fällen sollte das Gleichmäßigkeitskriterium für fast alle typischen Teilmengen von Einträgen bestehen, die in der Tabelle zu finden sind, nicht nur für den globalen Satz aller möglichen Einträge. Mit anderen Worten, wenn ein typischer Satz von m-Datensätzen auf n-Tabellen-Slots verschoben wird, sollte die Wahrscheinlichkeit eines Schaufels, der viele mehr als m/n-Datensätze erhält, verschwindend gering sein. Insbesondere, wenn m kleiner als n ist, sollten sehr wenige Eimer mehr als ein oder zwei Datensätze haben. Eine kleine Anzahl von Kollisionen ist praktisch unvermeidlich, auch wenn n viel größer als m ist – siehe das Geburtstagsproblem. In speziellen Fällen, in denen die Schlüssel vorab bekannt sind und der Schlüsselsatz statisch ist, kann eine Hash-Funktion gefunden werden, die eine absolute (oder kollisionslose) Gleichmäßigkeit erreicht. Eine solche Hash-Funktion soll perfekt sein. Es gibt keine algorithmische Art, eine solche Funktion zu konstruieren - die Suche nach einer ist eine faktorielle Funktion der Anzahl der Tasten, die abgebildet werden, im Vergleich zu der Anzahl der Tabellenschlitze, in die sie eingegriffen werden. Die Suche nach einer perfekten Hash-Funktion über mehr als einen sehr kleinen Tastensatz ist in der Regel rechnerisch undurchführbar; die resultierende Funktion ist wahrscheinlich rechnerisch komplexer als eine Standard Hash-Funktion und bietet nur einen marginalen Vorteil gegenüber einer Funktion mit guten statistischen Eigenschaften, die eine minimale Anzahl von Kollisionen liefert. Siehe universelle Hash-Funktion. Prüfung und Messung Bei der Prüfung einer Hash-Funktion kann die Gleichmäßigkeit der Verteilung von Hash-Werten durch den Chi-Quadrat-Test ausgewertet werden. Dieser Test ist eine bewährte Maßnahme: Es ist die tatsächliche Verteilung von Gegenständen in Eimern gegenüber der erwarteten (oder einheitlichen) Verteilung von Gegenständen. Die Formel ist: Ein Verhältnis innerhalb eines Konfidenzintervalls (0,95 - 1,05) zeigt, dass die ausgewertete Hashfunktion eine erwartete gleichmäßige Verteilung aufweist. Hash-Funktionen können einige technische Eigenschaften haben, die es wahrscheinlicher machen, dass sie eine gleichmäßige Verteilung bei der Anwendung haben. Eins ist das strenge Lawinenkriterium: Wenn ein einzelnes Eingabebit ergänzt wird, ändert sich jedes der Ausgabebits mit einer 50% Wahrscheinlichkeit. Der Grund für diese Eigenschaft ist, dass ausgewählte Teilmengen des Schlüsselraums eine geringe Variabilität aufweisen können. Für die gleichmäßige Verteilung der Ausgabe sollte eine geringe Variabilität, auch ein Bit, in eine hohe Variabilität (d.h. Verteilung über den Tischraum) im Ausgang übergehen. Jedes Bit sollte sich mit einer Wahrscheinlichkeit von 50% ändern, weil, wenn einige Bits sich nicht ändern, die Schlüssel um diese Werte geclustert werden. Wenn sich die Bits zu leicht ändern wollen, nähert sich das Mapping einer festen XOR-Funktion eines einzigen Bits. Standardtests für diese Eigenschaft wurden in der Literatur beschrieben. Hier wird die Relevanz des Kriteriums für eine multiplikative Hashfunktion beurteilt. Effizienz Bei der Datenspeicherung und -abrufung handelt es sich bei der Verwendung einer Hash-Funktion um einen Kompromiss zwischen Suchzeit und Datenspeicher. Wenn die Suchzeit unbelastet wäre, wäre eine sehr kompakte ungeordnete lineare Liste das beste Medium; wenn der Speicherplatz unbelastet wäre, wäre eine zufällig zugängliche Struktur, die durch den Schlüsselwert indiziert werden kann, sehr groß, sehr sparsam, aber sehr schnell. Eine Hash-Funktion benötigt eine endliche Zeit, um einen potenziell großen Schlüsselraum auf eine mögliche Menge von Speicherplatz, der in einer begrenzten Zeit gesucht werden kann, unabhängig von der Anzahl der Tasten. In den meisten Anwendungen sollte die Hash-Funktion mit minimaler Latenz und zweitens in einer Mindestanzahl von Anweisungen berechnet werden. Die rechnerische Komplexität variiert mit der Anzahl der benötigten Instruktionen und der Latenz einzelner Instruktionen, wobei die bitweisesten Methoden (Falten) und die multiplikativen Methoden am einfachsten sind. Weil Kollisionen selten sein sollten und eine marginale Verzögerung verursachen, aber ansonsten harmlos sind, ist es in der Regel bevorzugt, eine schnellere Hash-Funktion über eine zu wählen, die mehr Berechnung benötigt, aber ein paar Kollisionen speichert. Die bereichsbasierten Implementierungen können von besonderer Bedeutung sein, da die Division auf nahezu allen Chiparchitekturen mikroprogrammiert ist. Divide (Modulo) durch eine Konstante kann invertiert werden, um durch das Wort-Größe multiplikativ-inverse der Konstante multipliziert zu werden. Dies kann vom Programmierer oder vom Compiler geschehen. Auch kann Divide direkt in eine Reihe von Shift-Subtrakten und Shift-Adds reduziert werden, obwohl die Minimierung der Anzahl solcher Operationen erforderlich ist ein Daunting-Problem; die Anzahl der resultierenden Montageanleitungen kann mehr als ein Dutzend sein, und die Pipeline tauschen. Wenn die Architektur Hardware multiplizieren Funktionseinheiten hat, ist die multipliziert-by-inverse wahrscheinlich ein besserer Ansatz. Wir können zulassen, dass die Tischgröße n nicht eine Leistung von 2 ist und noch keinen Rest- oder Teilungsbetrieb ausführen muss, da diese Berechnungen manchmal kostspielig sind. Lassen Sie beispielsweise n deutlich weniger als 2b sein. Betrachten Sie eine auf dem Intervall [0, 2b - 1] gleichmäßige Pseudozufallszahlengeneratorfunktion P(key). Eine Hashfunktionseinheit im Intervall [0, n-1] ist n P(key)/2b. Wir können die Division durch eine (möglicherweise schnellere) rechte Bitverschiebung ersetzen: nP(key) >> b.Wenn Tasten wiederholt gelöscht werden und die Hash-Funktion kostspielig ist, kann die Rechenzeit durch Vorgabe der Hash-Codes gespeichert und mit den Tasten gespeichert werden. Passende Hash-Codes fast sicher bedeutet, dass die Schlüssel identisch sind. Diese Technik wird für die Transpositionstabelle in Spielprogrammen verwendet, die eine 64-Bit-raffinierte Darstellung der Boardposition speichert. Universalität Ein universelles Hashingschema ist ein randomisierter Algorithmus, der eine Hashingfunktion h unter einer Familie solcher Funktionen so wählt, dass die Wahrscheinlichkeit einer Kollision von zwei verschiedenen Schlüsseln 1/m beträgt, wobei m die Anzahl der bestimmten Hash-Werte ist - unabhängig von den beiden Tasten. Das universelle Hashing sorgt (im probabilistischen Sinne) dafür, dass sich die Hash-Funktionsapplikation ebenso verhalten wird, als ob sie eine zufällige Funktion zur Verteilung der Eingangsdaten verwendet. Es wird jedoch mehr Kollisionen als perfektes Hashing haben und kann mehr Operationen als eine spezielle Hash-Funktion erfordern. Anwendbarkeit Eine Hash-Funktion ist in einer Vielzahl von Situationen anwendbar. Eine Hash-Funktion, die nur bestimmte Tischgrößen, Strings nur bis zu einer bestimmten Länge erlaubt oder einen Samen nicht akzeptieren kann (d.h. Doppel Hashing zulassen) ist nicht so nützlich wie eine, die tut. Bestimmung Ein Hash-Verfahren muss deterministisch sein, d.h. es muss für einen bestimmten Eingangswert immer denselben Hash-Wert erzeugen. Mit anderen Worten, es muss eine Funktion der zu hashenden Daten sein, im mathematischen Sinne des Begriffs. Diese Anforderung schließt Hash-Funktionen aus, die von externen variablen Parametern, wie Pseudo-Zufallszahlengeneratoren oder der Tageszeit, abhängen. Es schließt auch Funktionen aus, die von der Speicheradresse des Objekts abhängig sind, in Fällen, in denen sich die Adresse während der Ausführung ändern kann (wie dies bei Systemen geschehen kann, die bestimmte Methoden der Müllentnahme verwenden), obwohl manchmal eine Umrüstung des Gegenstandes möglich ist. Der Determinismus liegt im Kontext der Wiederverwendung der Funktion. Zum Beispiel fügt Python das Feature hinzu, das Hash-Funktionen einen randomisierten Samen verwenden, der einmal erzeugt wird, wenn der Python-Prozess neben der zu hashenden Eingabe beginnt. Die Python Hash (SipHash) ist immer noch eine gültige Hash-Funktion, wenn sie innerhalb eines einzigen Laufs verwendet wird. Wenn aber die Werte bestehen bleiben (z.B. auf Festplatte geschrieben) können sie nicht mehr als gültige Hashwerte behandelt werden, da sich im nächsten Durchlauf der Zufallswert unterscheiden könnte. Definierte Reichweite Oft ist es wünschenswert, dass die Ausgabe einer Hash-Funktion feste Größe hat (siehe unten). Wird beispielsweise der Ausgang auf 32-Bit-Integer-Werte beschränkt, so können die Hash-Werte zur Indexierung in ein Array verwendet werden. Ein solches Hashing wird häufig verwendet, um die Datensuche zu beschleunigen. Die Erzeugung von Festlängenausgang aus der variablen Längeneingabe kann durch Brechen der Eingangsdaten in Stücke bestimmter Größe erfolgen. Hash-Funktionen, die für die Datensuche verwendet werden, verwenden einen arithmetischen Ausdruck, der iterativ Schnitte der Eingabe (wie die Zeichen in einem String) verarbeitet, um den Hash-Wert zu erzeugen. Variable Reichweite In vielen Anwendungen kann der Bereich der Hash-Werte für jeden Programmablauf unterschiedlich sein oder sich entlang des gleichen Laufs ändern (z.B. wenn eine Hash-Tabelle erweitert werden muss). In diesen Situationen benötigt man eine Hash-Funktion, die zwei Parameter - die Eingabedaten z und die Anzahl n der erlaubten Hash-Werte - übernimmt. Eine gemeinsame Lösung besteht darin, eine feste Hash-Funktion mit einem sehr großen Bereich (Schema 0 bis 232 - 1) zu berechnen, das Ergebnis durch n zu teilen und den Rest der Division zu verwenden. Wenn n selbst eine Leistung von 2 ist, kann dies durch Bitmasken und Bitschaltung erfolgen. Bei Verwendung dieses Ansatzes muss die Hashfunktion so gewählt werden, dass das Ergebnis für jeden Wert von n, der in der Anwendung auftreten kann, eine gleichmäßige Verteilung zwischen 0 und n - 1 aufweist. Je nach Funktion kann der Rest nur für bestimmte Werte von n, z.B. ungerade oder Primzahlen, gleichförmig sein. Variabler Bereich mit minimaler Bewegung (dynamische Hashfunktion) Wenn die Hash-Funktion verwendet wird, um Werte in einer Hash-Tabelle zu speichern, die den Ablauf des Programms überlebt, und die Hash-Tabelle muss erweitert oder geschrumpft werden, wird die Hash-Tabelle als dynamische Hash-Tabelle bezeichnet. Eine Hash-Funktion, die die Mindestanzahl an Datensätzen verlagern wird, wenn die Tabelle umgesiedelt wird, ist wünschenswert. Was benötigt wird, ist eine Hash-Funktion H(z,n) – wobei z der Schlüssel hashed ist und n die Anzahl der erlaubten Hash-Werte ist – so dass H(z,n + 1) = H(z,n) mit Wahrscheinlichkeit nahe n/(n + 1). Lineare Hashing- und Spiralspeicherung sind Beispiele für dynamische Hash-Funktionen, die in konstanter Zeit ausführen, aber die Eigenschaft der Gleichmäßigkeit entspannen, um die minimale Bewegungseigenschaft zu erreichen. Erweiterbare Hashing verwendet eine dynamische Hash-Funktion, die Raum proportional zu n benötigt, um die Hash-Funktion zu berechnen, und es wird eine Funktion der vorherigen Tasten, die eingefügt wurden. Es wurden mehrere Algorithmen erfunden, die die Gleichmäßigkeitseigenschaft erhalten, jedoch die Zeit proportional zu n zur Berechnung des Wertes von H(z,n) benötigen. Eine Hash-Funktion mit minimaler Bewegung ist besonders in verteilten Hash-Tabellen nützlich. Datennormalisierung In einigen Anwendungen können die Eingabedaten Merkmale enthalten, die für Vergleichszwecke irrelevant sind. Beispielsweise kann es bei der Suche nach einem persönlichen Namen wünschenswert sein, die Unterscheidung zwischen Ober- und Unterbuchstaben zu ignorieren. Für diese Daten muss eine Hash-Funktion verwendet werden, die mit dem verwendeten Datenequivalenzkriterium kompatibel ist: d.h. alle zwei als gleichwertig betrachteten Eingänge müssen den gleichen Hash-Wert liefern. Dies kann erreicht werden, indem die Eingabe vor dem Hashing normalisiert wird, wie durch das Umsetzen aller Buchstaben. Hashing ganze Datentypen Es gibt mehrere gemeinsame Algorithmen für das Hashing von Ganzzahlen. Das Verfahren zur besten Verteilung ist datenabhängig. Eines der einfachsten und allgemeinsten Methoden in der Praxis ist das Modulo-Divisionsverfahren. Identität Hash-Funktion Wenn die zu hashenden Daten klein genug sind, können die Daten selbst (als ganze Zahl neu interpretiert) als Hashedwert verwendet werden. Die Kosten für die Berechnung dieser Identität Hash-Funktion ist effektiv Null. Diese Hash-Funktion ist perfekt, da sie jede Eingabe auf einen bestimmten Hash-Wert abbildet. Die Bedeutung von "klein genug" hängt von der Größe der Art ab, die als Hashed-Wert verwendet wird. Beispielsweise ist in Java der Hash-Code eine 32-Bit-Integer. So können die 32-Bit-Integer- und 32-Bit-Schwebepunkt-Schwebeobjekte einfach den Wert direkt verwenden, während die 64-Bit-Integer- und 64-Bit-Schwebepunkt-Doppel diese Methode nicht verwenden können. Andere Arten von Daten können auch dieses Hashing-Programm verwenden. Beispielsweise kann bei der Zuordnung von Zeichenketten zwischen Ober- und Unterfall die binäre Kodierung jedes Zeichens, interpretiert als ganze Zahl, eine Tabelle, die die alternative Form dieses Zeichens gibt (A für a, 8 für 8 usw.) verwendet werden.Wird jedes Zeichen in 8 Bits (wie in erweitertem ASCII oder ISO Latin 1) gespeichert, hat die Tabelle nur 28 = 256 Einträge; bei Unicode-Zeichen würde die Tabelle 17×216 = 1114112 Einträge haben. Die gleiche Technik kann verwendet werden, um zwei-Buchstaben Ländercodes wie uns oder za zu Landnamen (262 = 676 Tabelleneinträge), 5-stellige Zip-Codes wie 13083 zu Stadtnamen (100000 Einträge) usw. Invalide Datenwerte (z. B. Ländercode xx oder Postleitzahl 00000) können in der Tabelle nicht definiert oder auf einen entsprechenden Nullwert abgebildet werden. Trivial Hash Funktion Sind die Schlüssel gleichmäßig oder ausreichend gleichmäßig über den Schlüsselraum verteilt, so daß die Schlüsselwerte im wesentlichen zufällig sind, so können sie als bereits überstrichen angesehen werden. In diesem Fall kann jede beliebige Anzahl von Bits in der Taste ausgewählt und als Index in die Hash-Tabelle zusammengefasst werden. Eine einfache Hash-Funktion wäre es, die unteren m Bits abzublenden, um als Index in eine Tabelle der Größe 2m zu verwenden. Falten Ein Falt Hash-Code wird erzeugt, indem der Eingang in n Abschnitte von m Bits geteilt wird, wobei 2^m die Tischgröße ist, und mit einem paritätserhaltenden bitweisen Betrieb wie ADD oder XOR, um die Abschnitte zu kombinieren. Der Endbetrieb ist eine Maske oder Verschiebungen, um überschüssige Bits am hohen oder niedrigen Ende abzuschneiden. Beispielsweise gibt es für eine Tischgröße von 15 Bits und Schlüsselwert von 0x0123456789ABCDEF 5 Abschnitte 0x4DEF, 0x1357, 0x159E, 0x091A und 0x8. Hinzufügen, erhalten wir 0x7AA4, einen 15-Bit-Wert. Halbquare Ein Mid-Squares-Hasch-Code wird erzeugt, indem die Eingabe gequetscht und eine entsprechende Anzahl von mittleren Ziffern oder Bits extrahiert wird. Wenn z.B. der Eingang 123.456,789 und die Hashtabellengröße 10.000 Squaring der Schlüssel 15,241.578.750,190,521 erzeugt, so wird der Hashcode als die mittleren 4 Ziffern der 17-stelligen Zahl (ignorieren der hohen Zahl) 8750 genommen. Die Mid-Squares-Methode erzeugt einen vernünftigen Hash-Code, wenn es nicht viele führende oder nachlaufende Nullen im Schlüssel gibt. Dies ist eine Variante des multiplikativen Hashings, aber nicht so gut, weil ein willkürlicher Schlüssel kein guter Multiplikator ist. Division hashing Eine Standard-Technik ist die Verwendung einer Modulfunktion auf dem Schlüssel, indem eine Divisor M \{displaystyle M}, die eine Hauptzahl in der Nähe der Tischgröße ist, so h ( K ) = K mod M \{displaystyle h(K)=K\mod M} .Die Tischgröße ist in der Regel eine Leistung von 2. Dies ergibt eine Verteilung von {0,M-1} \{displaystyle {0,M-1} . Dies gibt gute Ergebnisse über eine große Anzahl von Schlüsselsets. Ein wesentlicher Nachteil der Division Hashing ist, dass die Division auf den meisten modernen Architekturen einschließlich x86 mikroprogrammiert ist und 10 mal langsamer als multipliziert sein kann. Ein zweiter Nachteil ist, dass es keine geclusterten Schlüssel zerbricht. Zum Beispiel die Tasten 123000, 456000, 789000, etc.modulo 1000 alle Karte auf die gleiche Adresse. Diese Technik funktioniert in der Praxis gut, da viele Schlüsselsätze bereits ausreichend zufällig sind und die Wahrscheinlichkeit, dass ein Schlüsselsatz durch eine große Grundzahl zyklisch sein wird, gering ist. Algebraic codierende Algebraic Codierung ist eine Variante der Divisionsmethode des Hashings, die die Division durch ein Polynommodulo 2 anstelle einer ganzen Zahl verwendet, um n Bits zu m Bits zu ordnen. In diesem Ansatz M = 2 m \{displaystyle M=2^{m} und wir postulieren ein m \{displaystyle m} der Grad Polynom Z ( x ) = x m + ζ m - 1 x m - 1 + . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . *m-1}x{m-1}+...+\zeta _{0} .A key K = (k n - 1 . . . k 1 k 0 ) 2 \{displaystyle K=(k_{n-1}...k_{1}k_{0})_{2 kann als Polynom K (x ) = k n - 1 x n - 1 +... + k 1 x + k 0{displaystyle K(x)=k_{n-1}x{n-1}-1 Der Rest mit polynomem arithmetischem Modul 2 ist K ( x ) mod Z ( x ) = h m - 1 x m - 1 +... + h 1 x + h 0 \{displaystyle K(x)\mod Z(x)}=h_{m-1}x{m-1}+...+h_{1}x+h_{0 .Dann h ( K ) = ( h m - 1 . . . . h 1 h 0 ) 2 \{displaystyle h(K)=(h_{m-1}...h_{1}h_{0})_{2 .Wenn Z ( x ) \{displaystyle Z(x)} zu t oder weniger Nicht-Null-Koeffizienten aufgebaut ist, dann werden Tasten, die weniger als t-Bits teilen, garantiert. Z eine Funktion von k, t und n, einem Divisor von 2k-1, ist aus dem GF(2k)-Feld aufgebaut. Knuth gibt ein Beispiel: für n=15, m=10 und t=7, Z ( x ) = x 10 + x 8 + x 5 + x 4 + x 2 + x + 1 \{displaystyle Z(x)=x^{10}+x{8}+x{5}+x{4}+x{2}+x+1 .Die Ableitung ist wie folgt: ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ Dann ist der Grad von P ( x ) =  of S | \{displaystyle P(x)=|S} .Seit α 2 j \{displaystyle \alpha ^{2j} eine Wurzel von P (x ) \{displaystyle P(x)} ist, wenn α j \{displaystyle \^{j} eine Wurzel ist, folgt, dass die Koeffizienten p i \{display} p_{i}{2}=p_{i, so dass sie alle 0 oder 1 sind. Wenn R ( x ) = r ( n - 1 ) x n - 1 + . . + r 1 x + r 0 \{displaystyle R(x)=r_{(n-1)}x^{n-1}+...+r_{1}x+r_{0 ein nicht-Null-Polynommodulo 2 mit höchstens t Nicht-Null-Koeffizienten ist, dann R (x ) \{display 2. Wenn folgt, dass die entsprechende Hash-Funktion Schlüssel mit weniger als t Bits gemeinsam auf eindeutige Indizes abbildet. Das übliche Ergebnis ist, dass entweder n wird groß, oder twill wird groß, oder beides, für das Schema rechnerisch machbar. Daher ist es besser geeignet für die Hardware- oder Mikrocode-Implementierung. Einzigartige Permutation Hashing Sehen Sie auch einzigartige Permutation Hashing, die eine garantiert beste schlimmste Einschubzeit hat. Multiplicative hashing Standard multiplicative hashing verwendet die Formel h a ( K ) = ⌊ ( a K mod W ) / ( W / M ) ⌋ \{displaystyle h_{a}(K)=\lfloor (aK{\bmod {W}) / (W/M)\rfloor } die einen Stilwert in {0, ...}, M -1 Der Wert a \{displaystyle a} ist ein entsprechend gewählter Wert, der relativ primär zu W \{displaystyle W} sein sollte; er sollte groß und seine binäre Darstellung eine zufällige Mischung aus 1's und 0's sein. Ein wichtiger praktischer Sonderfall tritt auf, wenn W = 2 w \{displaystyle W=2^{w} und M = 2 m \{displaystyle M=2^{m} Leistungen von 2 sind und w \{displaystyle w} die Maschinenwortgröße ist. In diesem Fall wird diese Formel h a (K) = ⌊ (a K mod 2 w ) / 2 w - m ⌋ \{displaystyle h_{a}(K)=\lfloor (aK{\bmod 2}^{w}/2^{w-m}\rfloor } . Dies ist besonders, weil arithmetic modulo 2 w \{displaystyle 2^{w} standardmäßig in Low-Level Programmiersprachen und Integer Division durch eine Leistung von 2 durchgeführt wird, ist einfach eine Rechtsverschiebung, so wird diese Funktion in C zum Beispiel unsigned hash(unsigned K) { return (a*K) > (w-m;) Multiplikatives Hashing ist anfällig für einen "gemeinsamen Fehler", der zu einer schlechten Diffusion führt - höhere Werte-Eingangsbits beeinflussen nicht niederwertige Ausgabebits. Eine Transmutation am Eingang, die die Spanne der zurückgehaltenen Top-Bits nach unten verschiebt und XORs oder ADDs zu der Taste, bevor der Multiplikationsschritt dafür korrigiert. So sieht die resultierende Funktion aus: unsigned hash(unsigned K) { K ^= K >> (w-m;) return (a*K) >> (w-m;) } Fibonacci hashing Fibonacci hashing ist eine Form von multiplicativem Hashing, bei der der Multiplikator 2 w / φ \{displaystyle 2^{w}/\phi } ist, wobei φ \{displaystyle \phi } ist eine irrationale Zahl mit ungefährem Wert 5/3 und Dezimalausdehnung von 1.618033 Eine Eigenschaft dieses Multiplikators ist, dass es gleichmäßig über den Tischraum verteilt, Blöcke von aufeinanderfolgenden Schlüsseln in Bezug auf jeden Block von Bits in der Taste. Konnektive Tasten innerhalb der hohen Bits oder niedriger Bits des Schlüssels (oder eines anderen Feldes) sind relativ häufig. Die Multiplizierer für verschiedene Wortlängen w \{displaystyle ^{w} sind: 16: a=4050310 32: a=265443576910 48: a=17396110258977110 64: a=1140071481932319848510 Zobrist Hashing Tabulation Hashing, allgemein bekannt als Zobrist Hashing nach Albert Zobrist, ein amerikanischer Informatiker, ist eine Methode, universelle Familien von Hash-Funktionen zu konstruieren, indem Tabelle Lookup mit XOR Operationen kombiniert. Dieser Algorithmus hat sich als sehr schnell und von hoher Qualität für Hashing Zwecke erwiesen (insbesondere Hashing von Ganzzahlschlüsseln). Zobrist Hashing wurde ursprünglich als Mittel zur kompakten Darstellung von Schachpositionen in Computerspielprogrammen eingeführt. Jede Art von Stück (sechs je für Schwarz und Weiß) auf jedem Raum der Platte wurde eine eindeutige Zufallszahl zugeordnet. So wird zu Beginn des Programms eine Tabelle von 64x12 solche Zahlen initialisiert. Die Zufallszahlen könnten jede Länge sein, aber 64 Bit waren aufgrund der 64 Quadrate auf der Platine natürlich. Eine Position wurde durch Radfahren durch die Stücke in einer Position, Indexierung der entsprechenden Zufallszahlen ( Leerstellen wurden nicht in die Berechnung einbezogen), und XORing sie zusammen (der Startwert könnte 0 sein, der Identitätswert für XOR, oder ein zufälliges Saatgut.) Der resultierende Wert wurde durch Modulo, Falten oder eine andere Operation zur Herstellung eines Hash-Tabellenindex reduziert. Die ursprüngliche Zobrist Hash wurde in der Tabelle als Darstellung der Position gespeichert. Später wurde das Verfahren auf Hashing-Integer erweitert, indem jedes Byte in jeder von 4 möglichen Positionen im Wort durch eine eindeutige 32-Bit-Zufallszahl repräsentiert wurde. So ist eine Tabelle von 28x4 solcher Zufallszahlen aufgebaut. Eine 32-Bit Hashed Integer wird durch sukzessive Indexierung der Tabelle mit dem Wert jedes Bytes der Klartext-Integer und XOR gemeinsam die geladenen Werte (wiederum kann der Startwert der Identitätswert oder ein Zufallssaat sein). Die natürliche Ausdehnung auf 64-Bit-Integer ist die Verwendung einer Tabelle mit 28x8 64-Bit-Zufallszahlen. Diese Art von Funktion hat einige schöne theoretische Eigenschaften, von denen einer als 3-fache Unabhängigkeit bezeichnet wird, was bedeutet, dass jedes 3-fache von Schlüsseln gleichermaßen wahrscheinlich zu jedem 3-fachen von Hash-Werten abgebildet werden. Kundenspezifische Hash-Funktion Eine Hash-Funktion kann entworfen werden, um bestehende Entropie in den Schlüsseln auszunutzen. Haben die Tasten führende oder nachlaufende Nullen oder bestimmte Felder, die nicht verwendet werden, immer Null oder eine andere Konstante, oder in der Regel nur wenig, dann maskieren nur die flüchtigen Bits und Hashing auf diesen wird eine bessere und möglicherweise schneller Hash-Funktion. Ausgewählte Divisoren oder Multiplikatoren in den Divisions- und Multiplikatorensystemen können einheitlichere Hashfunktionen ausführen, wenn die Tasten zyklisch sind oder andere Redundanzen haben. Hashing variabler Längendaten Wenn die Datenwerte lange (oder variable Länge) Zeichenfolgen sind - wie z.B. persönliche Namen, Webseiten-Adressen oder Mail-Nachrichten -, ist ihre Verteilung in der Regel sehr ungleichmäßig, mit komplizierten Abhängigkeiten. Zum Beispiel hat Text in jeder natürlichen Sprache sehr ungleichmäßige Verteilungen von Zeichen und Zeichenpaaren, charakteristisch für die Sprache. Für solche Daten ist es ratsam, eine Hash-Funktion zu verwenden, die von allen Zeichen des Strings abhängt - und von jedem Zeichen auf andere Weise abhängt. Mittlere und ende Simplistische Hash-Funktionen können die ersten und letzten n Zeichen eines Strings zusammen mit der Länge hinzufügen oder eine Wortgröße Hash aus den mittleren 4 Zeichen eines Strings bilden. Dies spart iterating über den (potentiell langen) String, aber Hash-Funktionen, die nicht auf allen Zeichen einer String kann leicht linear durch Redundanzen, Clustering oder andere Pathologien im Schlüsselsatz. Solche Strategien können als benutzerdefinierte Hash-Funktion wirksam sein, wenn die Struktur der Tasten so ist, dass entweder die Mitte, die Enden oder andere Felder sind null oder eine andere invariante Konstante, die die Tasten nicht unterscheidet; dann können die invarianten Teile der Tasten ignoriert werden. Charakterfaltung Das paradigmatische Beispiel des Umklappens durch Zeichen ist die Addition der Ganzzahlwerte aller Zeichen in der Zeichenfolge. Eine bessere Idee ist es, die Hashsumme um eine konstante, typischerweise eine sisierbare Primzahl zu multiplizieren, bevor sie im nächsten Zeichen addiert wird und Überlauf ignoriert. Die Verwendung von exklusiven oder anstelle von Add ist auch eine plausible Alternative. Die Endoperation wäre ein Modul, eine Maske oder eine andere Funktion, um den Wortwert auf einen Index der Größe der Tabelle zu reduzieren. Die Schwäche dieses Verfahrens besteht darin, dass Informationen in den oberen oder unteren Bits der Bytes Clustern können, die im Hashed-Ergebnis verbleiben und mehr Kollisionen verursachen als ein richtiger randomisierender Hash. ASCII-Byte-Codes besitzen beispielsweise ein oberes Bit von 0 und bedruckbare Strings verwenden nicht die ersten 32-Byte-Codes, so dass die Informationen (95-Byte-Codes) in den übrigen Bits unwiderstehlich geclustert werden. Die klassische Herangehensweise, die PJW gegraben hat, basiert auf der Arbeit von Peter. J Weinberger bei ATT Bell Labs in den 1970er Jahren wurde ursprünglich für Hashing-Identifier in Compiler-Symboltabellen wie im "Dragon Book" angegeben konzipiert. Diese Hash-Funktion versetzt die Bytes 4 Bit, bevor sie zusammen ADD.Wenn sich die Menge umwickelt, werden die hohen 4 Bits ausgeschoben und wenn nicht-Null, XORed zurück in den niedrigen Byte der kumulativen Menge. Es ergibt sich ein Wortgröße Hash-Code, auf den ein Modulo oder ein anderer Reduktionsvorgang zur Erzeugung des End Hash-Index angewendet werden kann. Heute, vor allem mit dem Aufkommen von 64-Bit Wortgrößen, ist viel effizientere variable Längen-String Hashing durch Wort-Chunks verfügbar. Moderne Mikroprozessoren ermöglichen eine viel schnellere Verarbeitung, wenn 8-Bit-Zeichenstrings nicht durch Verarbeitung eines Zeichens zu einem Zeitpunkt gerafft werden, sondern durch Interpretation des Strings als Array von 32-Bit oder 64-Bit-Integern und Hashing/Akkuierung dieser "weiten Wort"-Integerwerte mittels arithmetischen Operationen (z.B. Multiplikation durch Konstante und Bitschaltung). Das Endwort, das gegebenenfalls unbesetzte Bytepositionen aufweisen kann, wird vor dem Einklappen in die Hash mit Nullen oder einem vorgegebenen Zufallswert gefüllt. Der akkumulierte Hash-Code wird um ein Endmodul oder eine andere Operation reduziert, um einen Index in die Tabelle zu liefern. Analog dazu kann eine ASCII- oder EBCDIC-Zeichenfolge, die eine Dezimalzahl darstellt, in eine numerische Größe für das Computing umgewandelt werden, eine variable Längenstring als (x0ak-1+x1ak-2+...+xk-2a+xk-1) umgewandelt werden. Dies ist einfach ein Polynom in einem Nicht-Nullradius a!=1, der die Komponenten (x0,x1,...,xk-1) als Zeichen der Eingangsstringlänge k einnimmt. Es kann direkt als Hash-Code oder eine Hash-Funktion verwendet werden, um den potenziell großen Wert auf die Hash-Tabellengröße abzubilden. Der Wert von a ist in der Regel eine Primzahl mindestens groß genug, um die Anzahl der verschiedenen Zeichen im Zeichensatz der möglichen Tasten zu halten. Radix Umwandlung Hashing von Strings minimiert die Anzahl der Kollisionen. Verfügbare Datengrößen können die maximale Länge des Strings einschränken, der mit diesem Verfahren überholt werden kann. Beispielsweise wird ein 128-Bit-Doppel-Long-Wort nur eine 26-Zeichen-Alphabetic-String (ignoring case) mit einem Radium von 29 besitzen; ein bedruckbarer ASCII-String ist auf 9 Zeichen mit Radien 97 und einem 64-Bit langen Wort begrenzt. Jedoch sind alphabetische Schlüssel meist bescheidener Länge, da Schlüssel in der Hash-Tabelle gespeichert werden müssen. Numerische Zeichenketten sind in der Regel kein Problem; 64 Bit können bis zu 1019 oder 19 Dezimalziffern mit Radik 10 zählen. Rolling Hash In manchen Anwendungen, wie z.B. der Substring-Suche, kann man eine Hash-Funktion h für jede k-Kennzeichen-Substrierung einer bestimmten n-Kennzeichen-String durch Vorschieben eines Fensters der Breite k-Zeichen entlang der Strings berechnen; wobei k eine feste ganze Zahl ist und n größer als k ist. Die unkomplizierte Lösung, die ein solches Unterstreichen an jeder Zeichenposition im Text und die Berechnung h getrennt ausziehen soll, erfordert eine Reihe von Operationen, die k·n proportional sind. Mit der richtigen Wahl von h kann man jedoch die Technik des Rollens von Hash verwenden, um alle diese Hashes mit einem Aufwand proportional zu mk + n zu berechnen, wobei m die Anzahl der Ereignisse des Unterstichs ist. Der bekannteste Algorithmus dieser Art ist Rabin-Karp mit der besten und durchschnittlichen Fallleistung O(n+mk) und dem schlimmsten Fall O(n·k) (in aller Fairness ist der schlimmste Fall hier schwer pathologisch: sowohl die Textstring als auch Substring bestehen aus einem wiederholten Einzelcharakter, wie z.B. t="AAAAAAAAAAA, und s="AAA.) Die für den Algorithmus verwendete Hash-Funktion ist in der Regel der Rabin Fingerabdruck, entworfen, um Kollisionen in 8-Bit Zeichenketten zu vermeiden, aber auch andere geeignete Hash-Funktionen werden verwendet. Analyse Das schlimmste Fallergebnis für eine Hash-Funktion lässt sich zwei Methoden beurteilen: theoretisch und praktisch. Theoretisch schlimmsten Fall ist die Wahrscheinlichkeit, dass alle Schlüssel zu einem einzigen slot. Praktischer schlimmster Fall wird erwartet längste Sondensequenz (Hash-Funktion + Kollisionsauflösung Methode.) Diese Analyse betrachtet einheitliches Hashing, d.h. jeder Schlüssel wird zu jedem bestimmten Slot mit Wahrscheinlichkeit 1/m, charakteristisch für universelle Hash-Funktionen. Während Knuth sich Sorgen um den adversarialen Angriff auf Echtzeit-Systeme macht, hat Gonnet gezeigt, dass die Wahrscheinlichkeit eines solchen Falles "rassig klein" ist. Seine Darstellung war, dass die Wahrscheinlichkeit von k von n Schlüsseln, die auf einen einzelnen Schlitz abgebildet sind, e - α α k k ! \{displaystyle \{frac e^{-\alpha \}alpha ^k}{k} wobei α der Lastfaktor ist, n/m. Geschichte Der Begriff Hash bietet eine natürliche Analogie mit seiner nicht-technischen Bedeutung (um ein Chaos zu hacken oder "ein Chaos zu machen" aus etwas), da Hash-Funktionen ihre Eingabedaten verwürfeln, um ihre Ausgabe abzuleiten. In seiner Forschung für den genauen Ursprung des Begriffs stellt Donald Knuth fest, dass, während Hans Peter Luhn von IBM scheint, der erste gewesen zu sein, um das Konzept einer Hash-Funktion in einem Memo vom Januar 1953 zu verwenden, würde der Begriff selbst erst in der veröffentlichten Literatur in den späten 1960er Jahren erscheinen, auf Herbert Hellermans Digital Computer System Principles, obwohl es damals bereits weit verbreitete Jargon war. Siehe auch Hinweise Referenzen Externe Links Berechnen Hash eines bestimmten Wertes von Timo Denk Die Goulburn Hashing Function (PDF) von Mayur Patel Hash Function Construction for Textual and Geometrical Data Retrieval (PDF)Letzte Trends auf Computern, Bd.2, pp.483–489, CSCC Konferenz, Korfu, 2010