Optische Zeichenerkennung oder optischer Zeichenleser (OCR) ist die elektronische oder mechanische Umwandlung von Bildern des eingegebenen, handschriftlichen oder gedruckten Textes in maschinencodierten Text, sei es aus einem gescannten Dokument, einem Foto eines Dokuments, einem Szenenbild (z.B. dem Text auf Zeichen und Plakaten in einem Landschaftsbild) oder aus Untertiteltext, der auf einem Bild überlagert ist (z. Weit verbreitet als Dateneingabe aus gedruckten Papierdatensätzen – ob Passdokumente, Rechnungen, Bankaussagen, EDV-Empfänge, Visitenkarten, Post, Druckausdrucke von statischen Daten oder jede geeignete Dokumentation – ist es eine gemeinsame Methode zur Digitalisierung von gedruckten Texten, damit sie elektronisch bearbeitet, gesucht, kompakter gespeichert, online angezeigt und in maschinellen Prozessen wie kognitives Computing, maschinelle Übersetzung verwendet werden können (ausgezeichnete Textdaten). OCR ist ein Bereich der Forschung in der Mustererkennung, künstliche Intelligenz und Computer Vision. Frühe Versionen mussten mit Bildern jedes Charakters trainiert werden und zu einer Zeit an einer Schrift gearbeitet werden. Fortgeschrittene Systeme, die in der Lage sind, eine hohe Erkennungsgenauigkeit für die meisten Schriften zu erzeugen, sind jetzt üblich und unterstützen eine Vielzahl von digitalen Bilddateiformateingängen. Einige Systeme sind in der Lage, formatierte Ausgabe, die eng an die ursprüngliche Seite annähert, einschließlich Bilder, Spalten und andere nicht-textuelle Komponenten. Geschichte Frühe optische Charaktererkennung kann auf Technologien, die Telegrafie und die Erstellung von Lesegeräten für Blinde, verfolgt werden. Im Jahr 1914 entwickelte Emanuel Goldberg eine Maschine, die Zeichen liest und in Standard-Telegrammcode umgewandelt. Gleichzeitig, Edmund Fournier d'Albe entwickelte das Optophon, einen Handscanner, der beim Umfahren auf einer gedruckten Seite Töne erzeugte, die bestimmten Buchstaben oder Zeichen entsprachen. In den späten 1920er Jahren und in die 1930er Jahre entwickelte Emanuel Goldberg, was er als "Statistical Machine" für die Suche nach Mikrofilm-Archiven mit einem optischen Codeerkennungssystem nannte. Im Jahre 1931 wurde ihm die US-PS 1.838.389 für die Erfindung erteilt. Das Patent wurde von IBM erworben. Blinde und Sehbehinderte Im Jahr 1974 begann Ray Kurzweil die Firma Kurzweil Computer Products, Inc. und die Weiterentwicklung von omni-font OCR, die Text in praktisch jeder Schrift gedruckt erkennen könnte (Kurzweil wird oft mit der Erfinder omni-font OCR, aber es war in Gebrauch von Unternehmen, einschließlich CompuScan, in den späten 1960er und 1970er Jahren). Kurzweil entschied, dass die beste Anwendung dieser Technologie wäre, eine Lesemaschine für den Blinden zu schaffen, die Blinden erlauben würde, einen Computer-Lesetext zu ihnen laut zu haben. Dieses Gerät erforderte die Erfindung von zwei Freigabetechnologien – dem CCD-Flachbettscanner und dem Text-zu-Sprach-Synthesizer. Am 13. Januar 1976 wurde das erfolgreiche fertige Produkt während einer von Kurzweil und den Führern der National Federation of the Blind geführten Nachrichtenkonferenz vorgestellt. 1978 begann Kurzweil Computer Products mit dem Verkauf einer kommerziellen Version des optischen Zeichenerkennungs-Computerprogramms. LexisNexis war einer der ersten Kunden und kaufte das Programm, um Papier- und Nachrichtendokumente auf seine nascent Online-Datenbanken hochzuladen. Zwei Jahre später verkaufte Kurzweil sein Unternehmen an Xerox, das Interesse daran hatte, die Textumwandlung von Papier zu Computer weiter zu vermarkten. Xerox versponnen es schließlich als Scansoft, die mit Nuance Communications verschmolzen. In den 2000er Jahren wurde OCR online als Dienst (WebOCR) in einer Cloud-Computing-Umgebung und in mobilen Anwendungen wie Echtzeit-Übersetzung von Fremdsprachenzeichen auf einem Smartphone zur Verfügung gestellt. Mit dem Aufkommen von smart-phones und smartglasses, OCR kann in internetgebundenen mobilen Geräteanwendungen verwendet werden, die Text mit der Kamera des Geräts erfasst extrahieren. Diese Geräte, die keine OCR-Funktionalität in das Betriebssystem eingebaut haben, verwenden typischerweise eine OCR-API, um den Text aus der von dem Gerät erfassten und bereitgestellten Bilddatei zu extrahieren. Die OCR-API gibt den extrahierten Text zusammen mit Informationen über den Ort des detektierten Textes im Originalbild zurück zur Geräteapplikation zur Weiterverarbeitung (z.B. Text-zu-Sprache) oder Anzeige zurück. Verschiedene kommerzielle und Open Source OCR-Systeme stehen für die meisten gängigen Schreibsysteme zur Verfügung, darunter lateinische, kyrillische, arabische, hebräische, indic, Bengali (Bangla,) Devanagari, Tamil, chinesische, japanische und koreanische Zeichen. Anwendungen OCR-Motoren wurden in viele Arten von Domain-spezifischen OCR-Anwendungen entwickelt, wie Empfang OCR, Rechnung OCR, überprüfen OCR, Legal Billing Document OCR. Sie können für: Dateneingabe für Geschäftsdokumente, z.B. Schecks, Reisepass, Rechnung, Bankerklärung und Quittung Automatische Nummernschilderkennung In Flughäfen, für Passerkennung und Informationsextraktion Automatische Versicherungsdokumente Schlüsselinformationen Extraktion VerkehrszeichenerkennungAusziehen von Visitenkarteninformationen in eine Kontaktliste Schneller Textversionen von gedruckten Dokumenten, z.B. Buch-Scannen für Project Gutenberg Machen Sie elektronische Bilder von gedruckten Dokumenten durchsuchbar, z.B. Google Books Konvertieren von Handschrift in Echtzeit, um einen Computer (Pen Computing) zu steuern. Ziel kann es auch sein, die Robustheit von CAPTCHA Anti-Bot-Systemen zu testen. Assistive Technologie für blinde und visuell beeinträchtigte Benutzer Schreiben Sie die Anweisungen für Fahrzeuge, indem Sie CAD-Bilder in einer Datenbank, die für die Fahrzeuggestaltung geeignet sind, als es in Echtzeit ändert. Scannen von gescannten Dokumenten durch Umwandeln in durchsuchbare PDFs Typen Optische Zeichenerkennung (OCR) – Ziele eingegebenen Text, ein Glyphen oder Zeichen zu einer Zeit. Optische Worterkennung – Ziele geschrieben Text, ein Wort zu einem Zeitpunkt (für Sprachen, die einen Raum als Wortteiler verwenden). ( Normalerweise nur OCR" genannt.) Intelligente Charaktererkennung (ICR) – zielt auch auf handschriftliche Druckschrift oder Cursive Text ein Glyphen oder Zeichen zu einer Zeit, in der Regel mit maschinellem Lernen. Intelligente Worterkennung (IWR) – zielt auch auf handschriftliche Druckschrift oder Cursive Text, ein Wort zu einer Zeit. Dies ist besonders nützlich für Sprachen, in denen Glyphen nicht in Cursive-Skript getrennt sind. OCR ist in der Regel ein Offline-Prozess, der ein statisches Dokument analysiert. Es gibt Cloud-basierte Dienste, die einen Online-OCR-API-Service bieten. Handschriftbewegungsanalyse kann als Eingabe zur Handschrifterkennung verwendet werden. Anstelle der bloßen Verwendung der Formen von Glyphen und Wörtern ist diese Technik in der Lage, Bewegungen zu erfassen, wie die Reihenfolge, in der Segmente gezogen werden, die Richtung, und das Muster des Setzens des Stiftes nach unten und Heben. Diese zusätzlichen Informationen können den End-to-End-Prozess genauer machen. Diese Technologie wird auch als "on-line-Zeichenerkennung", "dynamische Charaktererkennung", "real-time-Zeichenerkennung" und "intelligente Charaktererkennung" bezeichnet. Techniques Pre-Processing OCR Software verarbeitet oft Bilder, um die Chancen einer erfolgreichen Erkennung zu verbessern. Techniken umfassen: De-skew – Wenn das Dokument beim Scannen nicht richtig ausgerichtet war, muss es möglicherweise einige Grad im Uhrzeigersinn oder im Gegenuhrzeigersinn gekippt werden, um Textlinien perfekt horizontal oder vertikal zu machen. Despeckle – entfernen Sie positive und negative Spots, Glättungskanten Binarisation – Konvertieren Sie ein Bild von Farbe oder Grauwert zu Schwarz-Weiß (genanntes "binäres Bild", weil es zwei Farben gibt). Die Aufgabe der Binarisierung wird als einfache Möglichkeit ausgeführt, den Text (oder jede andere gewünschte Bildkomponente) vom Hintergrund zu trennen. Die Aufgabe der Binarisierung selbst ist notwendig, da die meisten kommerziellen Erkennungsalgorithmen nur auf binären Bildern arbeiten, da es sich als einfacher erweist. Darüber hinaus beeinflusst die Wirksamkeit des Binarisationsschrittes in erheblichem Maße die Qualität der Zeichenerkennungsstufe und die sorgfältigen Entscheidungen werden bei der Wahl der für einen bestimmten Eingabebildtyp verwendeten Binarisierung getroffen; da die Qualität des verwendeten Binarisationsverfahrens zur Gewinnung des Binärergebnisses von der Art des Eingabebildes (Scannendokument, Szenentextbild, historisches degradiertes Dokument usw.) abhängt. Linienentfernung – Reinigt Nicht-Glyphen-Boxen und Zeilen Layout-Analyse oder Zeoning – identifiziert Spalten, Absätze, Beschriftungen, etc. als verschiedene Blöcke. Besonders wichtig in Mehrsäulenlayouts und Tabellen. Zeilen- und Worterkennung – Erstellt Basislinie für Wort- und Zeichenformen, trennt bei Bedarf Wörter. Script Anerkennung – In mehrsprachigen Dokumenten kann sich das Skript auf der Ebene der Wörter ändern und somit ist eine Identifizierung des Skripts erforderlich, bevor das richtige OCR aufgerufen werden kann, um das spezifische Skript zu handhaben. Charakterisolation oder Segmentierung – Für den Per-Charakter OCR müssen mehrere Zeichen, die aufgrund von Bildartefakten verbunden sind, getrennt werden; einzelne Zeichen, die aufgrund von Artefakten in mehrere Stücke zerlegt werden, müssen angeschlossen werden. Normalisieren Sie Aspektverhältnis und SkalaSegmentierung von Fest-Pitch-Schriften wird relativ einfach dadurch erreicht, dass das Bild auf ein einheitliches Raster ausgerichtet wird, basierend darauf, dass sich vertikale Gitterlinien zumindest oft schwarze Bereiche schneiden. Für proportionale Schriftarten werden anspruchsvollere Techniken benötigt, weil der Weißraum zwischen Buchstaben manchmal größer sein kann als der zwischen Wörtern und vertikalen Linien mehr als ein Zeichen schneiden können. Texterkennung Es gibt zwei grundlegende Arten von Kern-OCR-Algorithmus, die eine rangierte Liste von Kandidatenzeichen erstellen können. Bei der Matrixanpassung wird ein Bild mit einem gespeicherten Glyph auf Pixel-by-Pixel-Basis verglichen; es wird auch als "Pattern-Anpassung", "Pattern-Erkennung" oder "Bildkorrelation" bezeichnet. Dies beruht darauf, dass der Eingabeglyphen aus dem Rest des Bildes korrekt isoliert wird und dass der gespeicherte Glyph in einer ähnlichen Schrift und in derselben Skala liegt. Diese Technik funktioniert am besten mit Schriftschrift und funktioniert nicht gut, wenn neue Schriftarten auftreten. Dies ist die Technik der frühen physikalischen photozellbasierten OCR umgesetzt, eher direkt. Feature-Extraktion zersetzt Glyphen in Funktionen wie Linien, geschlossene Schleifen, Linienrichtung und Linienkreuzungen. Die Extraktionsmerkmale reduzieren die Dimensionalität der Darstellung und machen den Erkennungsprozess rechnerisch effizient. Diese Merkmale werden mit einer abstrakten vektorähnlichen Darstellung eines Zeichens verglichen, das zu einem oder mehreren Glyphen-Prototypen reduziert werden kann. Allgemeine Techniken der Funktionserkennung in der Computer-Vision sind auf diese Art von OCR anwendbar, die häufig in intelligenter Handschrifterkennung und in der Tat modernste OCR-Software gesehen wird. Naheste Nachbar-Klassifikatoren wie der k-nächste Nachbaralgorithmus werden verwendet, um Bildmerkmale mit gespeicherten Glyph-Features zu vergleichen und das nächste Spiel auszuwählen. Software wie Cuneiform und Tesseract nutzen einen Zwei-Pass-Ansatz zur Charaktererkennung. Der zweite Pass ist als "adaptive Erkennung" bekannt und verwendet die mit hohem Vertrauen auf den ersten Pass erkannten Briefformen, um die übrigen Buchstaben am zweiten Pass besser zu erkennen. Dies ist für ungewöhnliche Schriftarten oder hochwertige Scans vorteilhaft, bei denen die Schrift verzerrt ist (z.B. verwischt oder verblasst). Moderne OCR-Software wie beispielsweise OCRopus oder Tesseract verwendet neuronale Netzwerke, die ausgebildet wurden, um ganze Textzeilen zu erkennen, anstatt sich auf einzelne Zeichen zu konzentrieren. Eine neue Technik, die als iteratives OCR bekannt ist, schneidet automatisch ein Dokument in Abschnitte auf der Seite Layout. OCR wird auf den Abschnitten individuell mit variablen Zeichen-Konfidenz-Spannungsschwellen durchgeführt, um die OCR-Genauigkeit auf Seitenebene zu maximieren. Für diese Methode wurde ein Patent des Patentamts der Vereinigten Staaten erteilt. Das OCR-Ergebnis kann im standardisierten ALTO-Format gespeichert werden, einem dedizierten XML-Schema der United States Library of Congress. Weitere gängige Formate sind hOCR und PAGE XML. Für eine Liste der optischen Zeichenerkennungssoftware siehe Vergleich der optischen Zeichenerkennungssoftware. Nachbearbeitung OCR-Genauigkeit kann erhöht werden, wenn die Ausgabe durch ein Lexikon eingeschränkt wird – eine Liste von Wörtern, die in einem Dokument auftreten dürfen. Dies kann beispielsweise alle Wörter in der englischen Sprache oder ein technischeres Lexikon für ein bestimmtes Feld sein. Diese Technik kann problematisch sein, wenn das Dokument Wörter nicht im Lexikon enthält, wie richtige Nouns. Tesseract verwendet sein Wörterbuch, um den Charaktersegmentierungsschritt zu beeinflussen, um die Genauigkeit zu verbessern. Der Ausgabestrom kann ein einfacher Text-Stream oder eine Zeichendatei sein, aber anspruchsvollere OCR-Systeme können das ursprüngliche Layout der Seite bewahren und z.B. ein annotiertes PDF produzieren, das sowohl das ursprüngliche Bild der Seite als auch eine durchsuchbare Textdarstellung umfasst."Near-neighbor-Analyse" kann die Mit-Ocurrence-Frequenzen zur Fehlerbehebung nutzen, indem man feststellt, dass bestimmte Wörter oft zusammen gesehen werden. Zum Beispiel ist "Washington, D.C" in der Regel weit verbreiteter in Englisch als "Washington DOC". Die Kenntnis der Grammatik der gescannten Sprache kann auch dazu beitragen, festzustellen, ob ein Wort zum Beispiel ein Verb oder ein Noun sein kann, was eine größere Genauigkeit ermöglicht. Der Levenshtein Entfernungsalgorithmus wurde auch in der OCR-Nachbearbeitung verwendet, um die Ergebnisse einer OCR-API weiter zu optimieren. Anwendungsspezifische Optimierungen In den letzten Jahren begannen die großen OCR-Technologie-Anbieter, OCR-Systeme zu optimieren, um mit bestimmten Arten von Eingaben effizienter umzugehen. Jenseits eines anwendungsspezifischen Lexikons kann eine bessere Leistung durch Berücksichtigung von Geschäftsregeln, Standardausdruck oder reichen Informationen in Farbbildern erzielt werden. Diese Strategie heißt "Application-Oriented OCR" oder "Customized OCR", und wurde auf OCR von Lizenzplatten, Rechnungen, Screenshots, ID-Karten, Führerscheine und Automobilherstellung angewendet. Die New York Times hat die OCR-Technologie in ein proprietäres Werkzeug angepasst, das sie berechtigen, Document Helper, das ihr interaktives Nachrichtenteam ermöglicht, die Verarbeitung von Dokumenten zu beschleunigen, die überprüft werden müssen. Sie weisen darauf hin, dass es ihnen ermöglicht, in Vorbereitung auf die Reporter, die Inhalte zu überprüfen, so viele bis zu 5400 Seiten pro Stunde zu verarbeiten. Workarounds Es gibt mehrere Techniken zur Lösung des Problems der Charaktererkennung mit anderen als verbesserten OCR-Algorithmen. Spezielle Schriftarten wie OCR-A, OCR-B oder MICR Schriften, mit genau festgelegten Größen, Abständen und markanten Charakterformen, ermöglichen eine höhere Genauigkeitsrate bei der Transkription in der Banküberprüfungsverarbeitung. Ironischerweise wurden jedoch mehrere prominente OCR-Motoren entwickelt, um Text in populären Schriften wie Arial oder Times New Roman zu erfassen, und sind nicht in der Lage, Text in diesen Schriften zu erfassen, die spezialisiert sind und viel von populär verwendeten Schriften verschieden sind. Da Google Tesseract ausgebildet werden kann, um neue Schriftarten zu erkennen, kann es OCR-A, OCR-B und MICR Schriftarten erkennen. "Comb-Felder" sind vorgedruckte Boxen, die Menschen dazu ermutigen, lesbarer zu schreiben – ein Glyphen pro Box. Diese werden oft in einer "Dropout-Farbe" bedruckt, die durch das OCR-System leicht entfernt werden kann. Palm OS verwendet eine spezielle Menge von Glyphen, bekannt als Graffiti, die ähnlich gedruckten englischen Zeichen sind, aber vereinfacht oder geändert für eine einfachere Erkennung auf der rechnerisch begrenzten Hardware der Plattform. Benutzer müssten lernen, wie man diese speziellen Glyphen schreibt. Zonenbasiertes OCR beschränkt das Bild auf einen bestimmten Teil eines Dokuments. Dies wird oft als "Template OCR" bezeichnet. Crowdsourcing Crowdsourcing-Menschen, um die Charaktererkennung durchzuführen, können schnell Bilder wie computergesteuertes OCR verarbeiten, aber mit höherer Genauigkeit für das Erkennen von Bildern als mit Computern erhalten. Praktische Systeme umfassen den Amazon Mechanical Turk und reCAPTCHA. Die National Library of Finland hat eine Online-Schnittstelle für Benutzer entwickelt, um OCRed-Texte im standardisierten ALTO-Format zu korrigieren. Crowd sourcing wurde auch nicht verwendet, um Charaktererkennung direkt durchzuführen, sondern Software-Entwickler einzuladen, Bildverarbeitungsalgorithmen zu entwickeln, beispielsweise durch die Verwendung von Rang-Order-Turniere. Die von der US-Abteilung für Energie (DOE) in Auftrag gegebene Genauigkeit des Instituts für Informationswissenschaft (ISRI) hatte die Aufgabe, die Verbesserung der automatisierten Technologien für das Verständnis von maschinell gedruckten Dokumenten zu fördern, und sie führte die maßgeblichste der jährlichen Prüfung der OCR-Beschleunigung von 1992 bis 1996 durch. Die Erkennung von lateinisch-schriftlichen, geschriebenen Text ist noch nicht 100% genau, auch wenn klare Bildgebung zur Verfügung steht. Eine Studie auf der Grundlage der Anerkennung der Zeitungsseiten des 19. und des frühen 20. Jahrhunderts kam zu dem Schluss, dass die Charakter-by-Charakter-OCR-Genauigkeit für kommerzielle OCR-Software von 81% auf 99% variierte; Gesamtgenauigkeit kann durch menschliche Überprüfung oder Data Dictionary Authentication erreicht werden. Andere Bereiche – einschließlich der Anerkennung von Handdruck, kursivem Handschreiben und gedrucktem Text in anderen Skripten (insbesondere jene ostasiatischen Sprachzeichen, die viele Schlaganfälle für einen einzigen Charakter haben) – sind immer noch Gegenstand aktiver Forschung. Die MNIST-Datenbank wird häufig verwendet, um die Fähigkeit der Systeme zu testen, handschriftliche Ziffern zu erkennen. Genauigkeitsraten können auf verschiedene Weise gemessen werden und wie sie gemessen werden, können die gemeldete Genauigkeitsrate stark beeinflussen. Wird beispielsweise der Wortkontext (im Wesentlichen ein Lexikon von Wörtern) nicht verwendet, um die Software zu korrigieren, die nicht vorhandene Wörter findet, kann eine Zeichenfehlerrate von 1 % (99% Genauigkeit) zu einer Fehlerrate von 5 % (95 % Genauigkeit) oder schlechter führen, wenn die Messung darauf beruht, ob jedes ganze Wort ohne falsche Buchstaben erkannt wurde. Die Verwendung eines großen genug Datensatzes ist in einem neuralen Netzwerk basierenden Handschrifterkennungslösungen so wichtig. Andererseits ist die Herstellung natürlicher Datensätze sehr aufwendig und zeitraubend. Ein Beispiel für die Schwierigkeiten der Digitalisierung des alten Textes ist die Unfähigkeit des OCR, zwischen den "langen s" und f Zeichen zu unterscheiden. Webbasierte OCR-Systeme zur Erkennung von handgedruckten Texten auf der Fliege sind in den letzten Jahren als kommerzielle Produkte bekannt geworden (siehe Tablet PC-Geschichte). Genauigkeitsraten von 80% bis 90% auf ordentliche, saubere handbedruckte Zeichen können durch Pen-Computing-Software erreicht werden, aber diese Genauigkeitsrate übersetzt noch Dutzende von Fehlern pro Seite, so dass die Technologie nur in sehr begrenzten Anwendungen nützlich. Das Erkennen von kursiven Texten ist ein aktiver Forschungsbereich, der sogar niedrigere Anerkennungsquoten als die des handgedruckten Textes aufweist. Höhere Erkennungsraten des allgemeinen Cursive-Skripts werden wahrscheinlich ohne die Verwendung kontextueller oder grammatischer Informationen nicht möglich sein. Zum Beispiel ist das Erkennen von ganzen Wörtern aus einem Wörterbuch einfacher als das Ausprobieren einzelner Zeichen aus dem Skript. Die Ablesung der Summenlinie eines Schecks (die immer eine Ausschreibnummer ist) ist ein Beispiel, bei dem die Verwendung eines kleineren Wörterbuchs die Erkennungsraten stark erhöhen kann. Die Formen einzelner Cursive-Zeichen selbst enthalten einfach nicht genug Informationen, um genau (größer als 98%) alle handschriftlichen Cursive-Skripte zu erkennen. Die meisten Programme ermöglichen es Benutzern, "Konfidenzraten" festzulegen. Dies bedeutet, dass, wenn die Software ihre gewünschte Genauigkeit nicht erreicht, ein Benutzer zur manuellen Überprüfung benachrichtigt werden kann. Ein Fehler, der durch OCR-Scannen eingeführt wird, wird manchmal als Scanno bezeichnet (analog mit dem Begriff typo). Unicode Characters zur Unterstützung von OCR wurden dem Unicode Standard im Juni 1993 hinzugefügt, mit der Version 1.1. Einige dieser Zeichen werden von bestimmten Schriftarten MICR, OCR-A oder OCR-B abgebildet. Siehe auch Referenzen Externe Links Unicode OCR – Hex Range: 2440-245F Optische Zeichenerkennung in Unicode Annotierte Bibliographie von Referenzen zur Handschriftzeichenerkennung und Pen Computing