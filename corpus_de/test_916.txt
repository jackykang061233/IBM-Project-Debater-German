Künstliche Intelligenz (KI) wird von Maschinen demonstriert, im Gegensatz zu der natürlichen Intelligenz von Menschen oder Tieren. Führende KI-Schriftbücher definieren das Feld als die Studie von "intelligenten Agenten:" jedes System, das seine Umgebung wahrnimmt und Aktionen durchführt, die ihre Ziele maximieren. Einige populäre Konten verwenden den Begriff "künstliche Intelligenz", um Maschinen zu beschreiben, die kognitive Funktionen imitieren, die Menschen mit dem menschlichen Verstand verknüpfen, wie Lernen und "Problemlösung", aber diese Definition wird von großen KI-Forschern abgelehnt. KI-Anwendungen umfassen fortgeschrittene Web-Suchmaschinen, Empfehlungssysteme (von YouTube, Amazon und Netflix verwendet), menschliche Rede (wie Siri oder Alexa,) selbstfahrende Autos (z.B. Tesla) zu verstehen und auf höchstem Niveau in strategischen Spielsystemen (z.B. Schach und Go) zu konkurrieren. So wird z.B. die optische Charaktererkennung häufig von KI betrachteten Dingen ausgeschlossen, die eine Routinetechnologie geworden sind. Künstliche Intelligenz wurde 1956 als akademische Disziplin gegründet, und in den Jahren seit mehreren Wellen des Optimismus erlebt, gefolgt von Enttäuschung und dem Verlust der Finanzierung (bekannt als "AI-Winter",") gefolgt von neuen Ansätzen, Erfolg und neuer Finanzierung. Die KI-Forschung hat viele verschiedene Ansätze während ihres Lebens versucht und verworfen, einschließlich der Simulation des Gehirns, der Modellierung menschlicher Problemlösung, formaler Logik, großer Wissensdatenbanken und der Nachahmung des tierischen Verhaltens. In den ersten Jahrzehnten des 21. Jahrhunderts hat das hochmathematische statistische maschinelle Lernen den Bereich dominiert, und diese Technik hat sich als sehr erfolgreich erwiesen und hilft, viele herausfordernde Probleme in der Industrie und in der Wissenschaft zu lösen. Die verschiedenen Teilgebiete der KI-Forschung werden um bestimmte Ziele und die Verwendung bestimmter Werkzeuge zentriert. Zu den traditionellen Zielen der KI-Forschung gehören Vernunft, Wissensdarstellung, Planung, Lernen, natürliche Sprachverarbeitung, Wahrnehmung und die Fähigkeit, Objekte zu bewegen und zu manipulieren. Allgemeine Intelligenz (die Fähigkeit, ein willkürliches Problem zu lösen) gehört zu den langfristigen Zielen des Feldes. Um diese Probleme zu lösen, verwenden AI-Forscher Versionen der Suche und mathematische Optimierung, formale Logik, künstliche neuronale Netzwerke und Methoden auf der Grundlage von Statistiken, Wahrscheinlichkeit und Wirtschaftlichkeit. KI zieht auch auf Informatik, Psychologie, Linguistik, Philosophie und viele andere Bereiche. Das Feld wurde unter der Annahme gegründet, dass die menschliche Intelligenz "so genau beschrieben werden kann, dass eine Maschine zur Simulation gemacht werden kann". Dies hebt philosophische Argumente über den Verstand und die Ethik der Schaffung künstlicher Wesen hervor, die mit menschlicher Intelligenz ausgestattet sind. Diese Themen wurden von Mythos, Fiktion und Philosophie seit der Antike untersucht. Wissenschaftsfiktion und Futurologie haben auch vorgeschlagen, dass KI mit seinem enormen Potenzial und seiner Macht ein existentielles Risiko für die Menschheit werden kann. Geschichte Gedankenfähige künstliche Wesen erschienen als Storytelling-Geräte in der Antike und sind in der Fiktion üblich, wie in Mary Shelley's Frankenstein oder Karel Čapeks R.U.R. Diese Zeichen und ihre Schicksale haben viele der gleichen Themen angesprochen, die jetzt in der Ethik der künstlichen Intelligenz diskutiert wurden. Die Studie der mechanischen oder formalen Vernunft begann mit Philosophen und Mathematikern in der Antike. Die Studie der mathematischen Logik führte direkt zu Alan Turings Berechnungstheorie, die nahelegte, dass eine Maschine, indem sie Symbole so einfach wie 0 und 1 schuppte, jeden denkbaren Akt der mathematischen Ableitung simulieren könnte. Diese Einsicht, dass digitale Computer jeden Prozess der formalen Vernunft simulieren können, ist als die Church-Turing-Thesis bekannt. Neben gleichzeitigen Entdeckungen in der Neurobiologie, der Informationstheorie und der Kybernetik führten die Forscher dazu, die Möglichkeit des Aufbaus eines elektronischen Gehirns zu berücksichtigen. Turing schlug vor, die Frage zu ändern, ob eine Maschine intelligent war, "ob es für Maschinen möglich ist, intelligentes Verhalten zu zeigen". Die erste Arbeit, die jetzt allgemein als AI anerkannt wird, war McCullouch und Pitts' 1943 formales Design für Turing-komplete "künstliche Neuronen". Der Bereich der KI-Forschung wurde 1956 in einem Workshop am Dartmouth College geboren, wo der Begriff "Künstliche Intelligenz" von John McCarthy geprägt wurde, um das Feld von Cybernetik zu unterscheiden und dem Einfluss des Cybernetikers Norbert Wiener zu entkommen. Antendees Allen Newell (CMU,) Herbert Simon (CMU,) John McCarthy (MIT,) Marvin Minsky (MIT) und Arthur Samuel (IBM) wurden die Gründer und Führer der AI-Forschung. Sie und ihre Studenten erstellten Programme, die die Presse als Erstaunen beschrieben: Computer waren Lern-Checker-Strategien (c. 1954)(und bis 1959 wurden berichtet, besser spielen als der durchschnittliche Mensch,) lösen Wortprobleme in Algebra, beweisen logische Theoremen (Logic Theorist, zuerst laufen c. 1956) und sprechen Englisch. Mitte der 1960er Jahre wurde die Forschung in den USA von der Verteidigungsabteilung stark gefördert und Labore wurden weltweit gegründet. Die Gründer von AI waren optimistisch über die Zukunft: Herbert Simon sagte: "Maschinen werden innerhalb von zwanzig Jahren in der Lage sein, irgendeine Arbeit zu tun, die ein Mann tun kann". Marvin Minsky vereinbarte, Schreiben, "in einer Generation .das Problem der Schaffung "künstliche Intelligenz" wird im Wesentlichen gelöst werden. Sie konnten die Schwierigkeit einiger der übrigen Aufgaben nicht erkennen. Die Fortschritte verlangsamten sich und 1974, als Reaktion auf die Kritik an Sir James Lighthill und den anhaltenden Druck des US-Kongresses, produktivere Projekte zu finanzieren, schnitten sowohl die USA als auch die britischen Regierungen die Explorationsforschung in KI ab. Die nächsten Jahre würden später als "AI-Winter" bezeichnet, eine Zeit, in der die Finanzierung von KI-Projekten schwierig war. In den frühen 1980er Jahren wurde AI-Forschung durch den kommerziellen Erfolg von Expertensystemen, eine Form von KI-Programm, die das Wissen und die analytischen Fähigkeiten von menschlichen Experten simuliert. Bis 1985 hatte der KI-Markt über eine Milliarde Dollar erreicht. Gleichzeitig inspirierte das Computerprojekt der fünften Generation Japans die USA und die britischen Regierungen, die Mittel für die akademische Forschung wiederherzustellen. Doch mit dem Zusammenbruch des Lisp-Maschinenmarktes im Jahr 1987 fiel KI wieder in den Streit, und ein zweiter, länger anhaltender Winter begann. KI hat seinen Ruf in den späten 1990er Jahren und Anfang des 21. Jahrhunderts allmählich wiederhergestellt, indem es spezifische Lösungen für spezifische Probleme wie Logistik, Datenabbau oder medizinische Diagnose gefunden hat. Bis 2000 wurden KI-Lösungen weit hinter den Kulissen eingesetzt. Der enge Fokus erlaubte den Forschern, überprüfbare Ergebnisse zu produzieren, mehr mathematische Methoden auszunutzen und mit anderen Bereichen zusammenzuarbeiten (wie Statistiken, Wirtschaft und Mathematik). Schnellere Computer, algorithmische Verbesserungen und der Zugriff auf große Datenmengen ermöglichten Fortschritte beim maschinellen Lernen und bei der Wahrnehmung; Daten-hungrige Deep Learning Methoden begannen, Genauigkeits-Benchmarks um 2012 zu dominieren. Laut Bloombergs Jack Clark war 2015 ein Meilenstein für künstliche Intelligenz, mit der Anzahl der Software-Projekte, die AI innerhalb von Google verwenden, stieg von einer "sporadic Nutzung" in 2012 auf mehr als 2.700 Projekte. Clark präsentiert auch faktische Daten, die die Verbesserungen von AI seit 2012 anzeigen, die durch geringere Fehlerquoten bei Bildverarbeitungsaufgaben unterstützt werden. Er verdankt dies aufgrund eines Anstiegs der Cloud-Computing-Infrastruktur und einer Erhöhung der Forschungsinstrumente und -datensätze auf eine Erhöhung der bezahlbaren neuronalen Netze. In einer Umfrage von 2017 berichtete eines von fünf Unternehmen, dass sie "in einigen Angeboten oder Prozessen KI eingebunden" hätten. Ziele Das allgemeine Problem der Simulation (oder Erstellung) Intelligenz wurde in Teilprobleme zerlegt. Diese bestehen aus bestimmten Merkmalen oder Fähigkeiten, die Forscher erwarten, dass ein intelligentes System angezeigt wird. Die nachstehend beschriebenen Merkmale haben die größte Aufmerksamkeit erhalten. Ursachen, Problemlösung Frühere Forscher entwickelten Algorithmen, die Schritt für Schritt erklären, dass Menschen verwenden, wenn sie Rätsel lösen oder logische Abzüge machen. In den späten 1980er und 1990er Jahren hatte die KI-Forschung Methoden für den Umgang mit unsicheren oder unvollständigen Informationen entwickelt, wobei Konzepte aus Wahrscheinlichkeit und Wirtschaft eingesetzt wurden. Diese Algorithmen erwiesen sich als unzureichend, um große Argumentationsprobleme zu lösen, weil sie eine "kombinatorische Explosion erlebten:" sie wurden exponentiell langsamer, als die Probleme größer wurden. Selbst Menschen nutzen selten den Schritt-für-Schritt-Abzug, den die frühe KI-Forschung modellieren könnte. Sie lösen die meisten ihrer Probleme mit schnellen, intuitiven Urteilen. Wissensvertretung und Wissenstechnik sind zentral für die klassische KI-Forschung. Einige "Expertensysteme" versuchen, explizites Wissen zu sammeln, das von Experten in einer engen Domäne besaß. Darüber hinaus versuchen einige Projekte, das dem Durchschnittsmenschen bekannte "Commonsense-Wissen" in eine Datenbank mit umfangreichen Kenntnissen über die Welt zu sammeln. Unter den Dingen, die eine umfassende Wissensbasis des Commonsense enthalten, sind: Objekte, Eigenschaften, Kategorien und Beziehungen zwischen Objekten; Situationen, Ereignisse, Zustände und Zeit; Ursachen und Effekte; Wissen über Wissen (was wir wissen, was andere Menschen wissen;) und viele andere, weniger gut erforschte Domains. Eine Darstellung von "was existiert" ist eine Ontologie: der Satz von Objekten, Beziehungen, Konzepten und Eigenschaften, die formal beschrieben werden, damit Software-Agenten sie interpretieren können. Diese Semantik wird als Beschreibungslogik, Rollen und Individuen erfasst und typischerweise als Klassen, Eigenschaften und Individuen in der Web Ontology Language implementiert. Die allgemeinsten Ontologien werden als obere Ontologien bezeichnet, die versuchen, eine Grundlage für alle anderen Kenntnisse zu schaffen, indem sie als Vermittler zwischen Domänen-Ontologien fungieren, die spezifische Kenntnisse über einen bestimmten Wissensbereich (Feld des Interesses oder Bereich der Sorge) abdecken. Solche formalen Wissensdarstellungen können in der Content-basierten Indexierung und Retrieval, Szeneninterpretation, klinische Entscheidungsunterstützung, Wissenserkundung (vorher interessante und handlungsfähige Inferenzen aus großen Datenbanken) und anderen Bereichen verwendet werden. Unter den schwierigsten Problemen in der Wissensvertretung sind: Standardvernunft und Qualifikationsproblem Viele der Dinge, die Menschen kennen, nehmen die Form von "Arbeitsannahmen". Zum Beispiel, wenn ein Vogel im Gespräch kommt, Menschen in der Regel ein fistgroßes Tier, das singt und fliegt. Keines dieser Dinge stimmt mit allen Vögeln. John McCarthy identifizierte dieses Problem im Jahr 1969 als Qualifikationsproblem: Für jede gängige Regel, die KI-Forscher vertreten wollen, gibt es eine Vielzahl von Ausnahmen. Fast nichts ist einfach wahr oder falsch, wie abstrakte Logik erfordert. KI-Forschung hat eine Reihe von Lösungen für dieses Problem untersucht. Breite des gängigen Wissens Die Anzahl der atomaren Tatsachen, die der Durchschnittsmensch kennt, ist sehr groß. Forschungsprojekte, die versuchen, eine vollständige Wissensbasis von gängigem Wissen (z.B. Cyc) aufzubauen, erfordern enorme Mengen an mühsamer ontologischer Technik – sie müssen von Hand ein kompliziertes Konzept zu einer Zeit gebaut werden. Subsymbolische Form eines gemeinsamen Wissens Ein Großteil dessen, was die Menschen wissen, ist nicht als Fakten oder Aussagen dargestellt, die sie mündlich ausdrücken könnten. Zum Beispiel wird ein Schachmeister eine bestimmte Schachposition vermeiden, weil es "zu exponiert" oder ein Kunstkritiker einen Blick auf eine Statue werfen und erkennen kann, dass es ein Fake ist. Dies sind nicht bewusste und subsymbolische Intuitionen oder Tendenzen im menschlichen Gehirn. Wissen wie diese informiert, unterstützt und bietet einen Kontext für symbolisches, bewusstes Wissen. Planung Intelligente Agenten müssen in der Lage sein, Ziele festzulegen und zu erreichen. Sie brauchen einen Weg, um die Zukunft zu visualisieren – eine Darstellung des Zustands der Welt und können Vorhersagen darüber machen, wie ihre Handlungen sie ändern werden – und in der Lage sein, Entscheidungen zu treffen, die das Dienstprogramm (oder Wert) der verfügbaren Entscheidungen maximieren. Bei klassischen Planungsproblemen kann der Agent davon ausgehen, dass er das einzige System der Welt ist, das es dem Agenten ermöglicht, die Konsequenzen seiner Handlungen zu berücksichtigen. Ist das Mittel jedoch nicht der einzige Aktor, so ist es erforderlich, dass das Mittel unter Unsicherheit begründen kann. Dies erfordert einen Agenten, der nicht nur seine Umwelt bewerten und Vorhersagen machen kann, sondern auch seine Vorhersagen bewerten und sich auf der Grundlage seiner Bewertung anpassen kann. Multiagent-Planung nutzt die Zusammenarbeit und den Wettbewerb vieler Agenten, um ein bestimmtes Ziel zu erreichen. Emergentes Verhalten wie dieses wird von evolutionären Algorithmen und swarm Intelligence verwendet. Machine Learning (ML,) ein grundlegendes Konzept der KI-Forschung seit dem Beginn des Feldes ist die Studie von Computeralgorithmen, die durch Erfahrung automatisch verbessern. Unsupervised Learning ist die Fähigkeit, Muster in einem Strom der Eingabe zu finden, ohne dass ein Mensch die Eingaben zuerst markiert. Beaufsichtigtes Lernen umfasst sowohl die Klassifikation als auch die numerische Regression, die ein Mensch benötigt, um die Eingabedaten zuerst zu kennzeichnen. Die Klassifizierung wird verwendet, um zu bestimmen, in welcher Kategorie etwas gehört, und geschieht, nachdem ein Programm eine Reihe von Beispielen von Dingen aus mehreren Kategorien sieht. Regression ist der Versuch, eine Funktion zu erzeugen, die die Beziehung zwischen Eingängen und Ausgängen beschreibt und vorhersagt, wie sich die Ausgänge bei Änderung der Eingänge ändern sollten. Sowohl Klassifikatoren als auch Regressionslerner können als "Funktions-Atmatoren" angesehen werden, die versuchen, eine unbekannte (möglicherweise implizite) Funktion zu erlernen; zum Beispiel kann ein Spam-Klassifikator als Lernen einer Funktion angesehen werden, die aus dem Text einer E-Mail auf eine von zwei Kategorien, Spam oder "nicht Spam" abbildet. Die rechnerische Lerntheorie kann die Lernenden durch rechnerische Komplexität, durch Stichprobenkomplexität (wieviele Daten erforderlich sind) oder durch andere Begriffe der Optimierung beurteilen. Bei der Verstärkung des Lernens wird der Agent für gute Antworten belohnt und für schlechte bestraft. Der Agent nutzt diese Abfolge von Belohnungen und Strafen, um eine Strategie für den Betrieb in seinem Problemraum zu bilden. Natürliche Sprachverarbeitung Natürliche Sprachverarbeitung (NLP) ermöglicht es Maschinen, menschliche Sprache zu lesen und zu verstehen. Ein ausreichend leistungsfähiges natürliches Sprachverarbeitungssystem würde natürlichsprachige Benutzeroberflächen und den Erwerb von Wissen direkt aus menschgeschriebenen Quellen, wie zum Beispiel Newswire-Texten, ermöglichen. Einige einfache Anwendungen der natürlichen Sprachverarbeitung umfassen die Informationsabrufung, Textabbau, Fragebeantwortung und maschinelle Übersetzung. Viele aktuelle Ansätze verwenden Wort-Co-Occurrence-Frequenzen, um syntaktische Darstellungen von Text zu konstruieren. "Keyword-Spotting"-Strategien für die Suche sind beliebt und skalierbar, aber dumm; eine Suchanfrage für Hund könnte nur Dokumente mit dem wörtlichen Worthund passen und ein Dokument mit dem Wort Poodle vermissen"."Lexical Affinity"-Strategien verwenden das Auftreten von Wörtern wie Unfall, um das Gefühl eines Dokuments zu bewerten. Moderne statistische NLP-Ansätze können all diese Strategien sowie andere kombinieren und oft akzeptable Genauigkeit auf Seiten- oder Absatzebene erreichen. Jenseits der semantischen NLP ist das ultimative Ziel der narrativen NLP, ein vollständiges Verständnis der gemeinen Argumentation zu verkörpern. Bis 2019 könnten transformatorbasierte Deep Learning-Architekturen kohärenten Text erzeugen. Perception Machine Wahrnehmung ist die Fähigkeit, Eingabe von Sensoren (wie Kameras (sichtbares Spektrum oder Infrarot), Mikrofone, drahtlose Signale, und aktive Lidar, Sonar, Radar, und taktile Sensoren) zu verwenden, um Aspekte der Welt zu entwerfen. Anwendungen umfassen Spracherkennung, Gesichtserkennung und Objekterkennung. Computer Vision ist die Fähigkeit, visuelle Eingabe zu analysieren. Eine solche Eingabe ist in der Regel mehrdeutig; ein riesiger, fünfzig Meter großer Fußgänger weit weg kann die gleichen Pixel wie ein nahe gelegener normaler Fußgänger erzeugen, die die AI zur Beurteilung der relativen Wahrscheinlichkeit und Angemessenheit von verschiedenen Interpretationen, zum Beispiel durch die Verwendung seines "Objektmodells", um zu beurteilen, dass fünfzig Meter Fußgänger nicht existieren. Bewegung und Manipulation KI wird stark in der Robotik eingesetzt. Fortgeschrittene Roboterarme und andere Industrieroboter, die in modernen Fabriken weit verbreitet sind, können von der Erfahrung lernen, wie man sich trotz der Anwesenheit von Reibung und Getriebeschlupf effizient bewegen kann. Ein moderner mobiler Roboter, wenn es eine kleine, statische und sichtbare Umgebung gibt, kann seine Lage leicht bestimmen und seine Umgebung abbilden; dynamische Umgebungen, wie (in der Endoskopie) das Innere des Atemkörpers eines Patienten stellen jedoch eine größere Herausforderung dar. Bewegungsplanung ist der Prozess, eine Bewegungsaufgabe in Primitiven wie einzelne Gelenkbewegungen aufzubrechen. Eine solche Bewegung beinhaltet oft eine konforme Bewegung, ein Prozess, bei dem Bewegung den physischen Kontakt mit einem Objekt aufrechterhält. Moravec's Paradox verallgemeinert, dass sensorimotorische Fähigkeiten, die Menschen für selbstverständlich nehmen, entgegenständlich, schwierig in einen Roboter zu programmieren sind; das Paradox wird nach Hans Moravec benannt, der 1988 sagte, dass "es ist vergleichsweise einfach, Computer zeigen Erwachsenenniveau Leistung auf Intelligenz Tests oder spielen Checkers, und schwierig oder unmöglich, ihnen die Fähigkeiten eines einjährigen zu geben, wenn es um Wahrnehmung und Mobilität geht". Dies ist darauf zurückzuführen, dass im Gegensatz zu den Checkern die körperliche Geschicklichkeit ein direktes Ziel der natürlichen Selektion für Millionen von Jahren war. Social Intelligence Affective Computing ist ein interdisziplinärer Schirm, der Systeme umfasst, die menschliche Einflüsse erkennen, interpretieren, verarbeiten oder simulieren. Zum Beispiel werden einige virtuelle Assistenten programmiert, um Gespräche zu sprechen oder sogar humorvoll zu verbannen; sie wirken empfindlicher auf die emotionale Dynamik der menschlichen Interaktion, oder um die Interaktion zwischen Mensch und Computer zu erleichtern. Dies neigt jedoch dazu, naiven Benutzern eine unrealistische Vorstellung davon zu geben, wie intelligente vorhandene Computer-Agenten tatsächlich sind. Mäßige Erfolge im Zusammenhang mit affektivem Computing umfassen die Analyse der textuellen Einschätzungen und in jüngster Zeit die Analyse multimodaler Einflussfaktoren (siehe multimodale Stimmungsanalyse), in denen KI die von einem videogestützten Subjekt angezeigten Auswirkungen klassifiziert. Allgemeine Intelligenz Allgemeine Intelligenz ist die Fähigkeit, jedes beliebige Problem anzugehen. Aktuelle KI-Forschung hat größtenteils nur Programme produziert, die genau ein Problem lösen können. Viele Forscher prognostizieren, dass eine solche "schmale KI" Arbeit in verschiedenen einzelnen Domänen schließlich in eine Maschine mit allgemeiner Intelligenz integriert wird, die die meisten der engen Fähigkeiten, die in diesem Artikel erwähnt werden, kombiniert und irgendwann sogar die menschliche Fähigkeit in den meisten oder in allen diesen Bereichen übersteigt. Das Unterfeld der künstlichen allgemeinen Intelligenz (oder AGI) untersucht ausschließlich allgemeine Intelligenz. Ansätze Für die meisten seiner Geschichte hat keine etablierte Einheitstheorie oder Paradigmen AI-Forschung geführt. KI-Forschung in konkurrierende Unterfelder, die oft nicht miteinander kommunizieren. Einige dieser Teilfelder basieren auf technischen Überlegungen, wie z.B. bestimmten Zielen (z.B. Robotik oder "Maschinenlernen",) der Verwendung bestimmter Werkzeuge (logische oder künstliche neuronale Netzwerke) oder sozialer Faktoren (z.B. bestimmte Institutionen oder Forscher), aber sie kamen auch aus tiefen philosophischen Unterschieden, die zu sehr unterschiedlichen KI-Ansätzen führten. Der beispiellose Erfolg des statistischen maschinellen Lernens in den 2010er Jahren verfinsterte alle anderen Ansätze, so dass einige Quellen (insbesondere in der Geschäftswelt) den Begriff "künstliche Intelligenz" verwenden, um "Maschinenlernen mit neuronalen Netzwerken" zu bedeuten. Die Fragen, die die KI-Forschung historisch geteilt haben, sind jedoch unbeantwortet geblieben und müssen möglicherweise durch die zukünftige Forschung revidiert werden. Einige der am längsten stehenden Fragen, die unbeantwortet geblieben sind, sind diese: Sollte künstliche Intelligenz natürliche Intelligenz durch Studium der Psychologie oder Neurobiologie simulieren? Oder ist die menschliche Biologie als irrelevant für die KI-Forschung, denn die Vogelbiologie ist für die Luftfahrttechnik? Kann intelligentes Verhalten mit einfachen, eleganten Prinzipien (wie Logik oder Optimierung) beschrieben werden?Oder ist es notwendig, eine Vielzahl von unbezogenen Problemen zu lösen? Können wir Programme schreiben, die nachweislich richtige Lösungen für ein bestimmtes Problem finden (z.B. mit symbolischer Logik und Wissen)? Oder verwenden wir Algorithmen, die uns nur eine vernünftige Lösung (z.B. probabilistische Methoden) geben können, aber möglicherweise auf die gleiche Art von inskruierbaren Fehlern, die menschliche Intuition macht, prey? Sollte KI die Ziele der künstlichen allgemeinen Intelligenz und Superintelligenz direkt verfolgen? Oder ist es besser, so viele spezifische Probleme wie möglich zu lösen und zu hoffen, dass diese Lösungen indirekt zu den langfristigen Zielen des Feldes führen? Cybernetik und Gehirnsimulation In den 1940er und 1950er Jahren erforschten einige Forscher die Verbindung zwischen Neurobiologie, Informationstheorie und Kybernetik. Bis 1960 wurde dieser Ansatz weitgehend aufgegeben, obwohl in den 1980er Jahren Elemente davon wiederbelebt würden. Symbolisch Als der Zugang zu digitalen Computern Mitte der 1950er Jahre möglich wurde, begann die AI-Forschung, die Möglichkeit zu erforschen, dass menschliche Intelligenz auf Symbolmanipulation reduziert werden könnte. Die Forschung konzentrierte sich auf drei Institutionen: Carnegie Mellon University, Stanford und MIT, und wie unten beschrieben, hat jeder seinen eigenen Stil der Forschung entwickelt. John Haugeland nannte diese symbolischen Ansätze zu KI "gute altmodische KI" oder GOFAI". In den 1960er Jahren hatten symbolische Ansätze große Erfolge bei der Simulation hochrangiger Denkweisen in kleinen Demonstrationsprogrammen erzielt, und in den 1980er Jahren konnte sie mit Expertensystemen großen Erfolg erzielen. Ansätze auf Basis von Cybernetik oder künstlichen neuronalen Netzwerken wurden aufgegeben oder in den Hintergrund geschoben. Die Forscher in den 1960er und 1970er Jahren waren davon überzeugt, dass symbolische Ansätze letztendlich in der Schaffung einer Maschine mit künstlicher allgemeiner Intelligenz gelingen würden und dieses Ziel ihres Feldes betrachteten. Frühe Subsymbolik In den 1980er Jahren schienen die Fortschritte in der symbolischen KI gestoppt zu werden und viele glaubten, dass symbolische Systeme niemals in der Lage wären, alle Prozesse der menschlichen Kognition nachzuahmen, insbesondere Wahrnehmung, Robotik, Lernen und Mustererkennung. Eine Reihe von Forschern begannen, subsymbolische Ansätze für spezifische KI-Probleme zu untersuchen. Subsymbolische Methoden schaffen es, Intelligenz ohne konkrete Darstellungen von Wissen näher zu bringen. Verkörperte Intelligenz Forscher aus dem verwandten Bereich der Robotik, wie Rodney Brooks, lehnten symbolische KI ab und konzentrierten sich auf die grundlegenden technischen Probleme, die Roboter zu bewegen, zu überleben und ihre Umgebung zu lernen. Sie nannten ihre Arbeit mit mehreren Namen: z.B. verkörpert, gelegen, verhaltensbasiert oder entwicklungsmäßig. Ihre Arbeit belebte den nicht-symbolischen Blick auf die frühen Kybernetik-Forscher der 1950er Jahre. Dies fiel mit der Entwicklung der verkörperten Denktheorie im verwandten Bereich der kognitiven Wissenschaft zusammen: die Idee, dass Aspekte des Körpers (wie Bewegung, Wahrnehmung und Visualisierung) für höhere Intelligenz erforderlich sind. Soft Computing Soft Computing findet Lösungen für Probleme, die nicht mit vollständiger logischer Sicherheit gelöst werden können, und wo häufig eine ungefähre Lösung ausreicht. Soft Computing-Ansätze zu KI umfassen neuronale Netzwerke, Fuzzy-Systeme, Graue Systemtheorie, evolutionäre Berechnung und viele Werkzeuge aus Statistiken oder mathematische Optimierung gezogen. Das Interesse an neuronalen Netzen und Verbindungsismus wurde von Geoffrey Hinton, David Rumelhart und anderen Mitte der 1980er Jahre wiederbelebt. Die Anwendung von Soft Computing auf AI ist der Schwerpunkt des Unterfelds der rechnerischen Intelligenz. Moderne statistische KI ist auch eine Form Soft Computing. Statistische Angaben In den 1990er Jahren nahmen AI-Forscher ausgefeilte mathematische Werkzeuge an, wie versteckte Markov-Modelle (HMM), Informationstheorie und normative Bayesische Entscheidungstheorie, um konkurrierende Architekturen zu vergleichen oder zu vereinheitlichen. Die geteilte mathematische Sprache erlaubte eine hohe Zusammenarbeit mit etablierten Feldern (wie Mathematik, Wirtschaft oder Betriebsforschung). Im Vergleich zu GOFAI erzielten neue "statistisches Lernen"-Techniken wie HMM und neuronale Netzwerke in vielen praktischen Bereichen wie dem Data Mining eine höhere Genauigkeit, ohne dabei ein semantisches Verständnis der Datensätze zu erlangen. Die verstärkten Erfolge mit realen Daten führten zu einer zunehmenden Betonung auf den Vergleich verschiedener Ansätze gegen gemeinsame Testdaten, um zu sehen, welche Vorgehensweise am besten in einem breiteren Kontext durchgeführt wurde als die von idiosynkratischen Spielzeugmodellen; AI-Forschung wurde wissenschaftlicher. Die Ergebnisse der Experimente sind heute oft streng messbar und sind manchmal (schwierig) reproduzierbar. Unterschiedliche statistische Lerntechniken haben unterschiedliche Einschränkungen; z.B. können grundlegende HMM die unendlich möglichen Kombinationen natürlicher Sprache nicht modellieren. Kritik (z.B. Noam Chomsky) stellt fest, dass die Verschiebung von GOFAI zu statistischem Lernen oft auch eine Verschiebung von erklärender KI ist. In der AGI-Forschung warnen einige Gelehrte vor Übereinstimmung des statistischen Lernens und argumentieren, dass die weitere Forschung zu GOFAI noch notwendig sein wird, um allgemeine Intelligenz zu erreichen.y Artificial general Intelligence (AGI) Bernard Goetz und andere wurden besorgt, dass KI nicht mehr das ursprüngliche Ziel verfolgt, vielseitige, voll intelligente Maschinen zu schaffen. Die statistische KI wird überwältigend verwendet, um spezifische Probleme zu lösen, sogar sehr erfolgreiche Techniken wie Deep Learning. Sie gründeten die subfield künstliche allgemeine Intelligenz (oder AGI), die bis 2010 mehrere gut finanzierte Institutionen besaß. Werkzeuge Anwendungen KI ist für jede intellektuelle Aufgabe relevant. Moderne künstliche Intelligenz Techniken sind pervasiv und sind zu zahlreich hier aufzulisten. Häufig, wenn eine Technik den Mainstream-Einsatz erreicht, wird sie nicht mehr als künstliche Intelligenz betrachtet; dieses Phänomen wird als KI-Effekt bezeichnet. High-Profile Beispiele von AI umfassen autonome Fahrzeuge (wie Drohnen und selbstfahrende Autos), medizinische Diagnose, Schaffung von Kunst (wie Poesie,) Beweis mathematische Theoreme, Spielen Spiele (wie Schach oder Go,) Suchmaschinen (wie Google Search), Online-Assistenten (wie Siri,) Bilderkennung in Fotografien, Spamfilterung, Vorhersage von Flugverzögerungen, Vorhersage von gerichtlichen Entscheidungen und Energiespeicherung Mit Social Media-Sites überholen TV als Quelle für Nachrichten für junge Menschen und Nachrichten-Organisationen zunehmend auf Social Media-Plattformen für die Erzeugung von Distribution angewiesen, verwenden die großen Verlage jetzt künstliche Intelligenz (KI) Technologie, um Geschichten effektiver zu posten und höhere Mengen von Verkehr zu generieren. AI kann auch Deepfakes produzieren, eine Content-altering-Technologie. ZDNet berichtet, "Es zeigt etwas, das nicht wirklich passierte", obwohl 88% der Amerikaner glauben, dass Deepfakes mehr Schaden als gut verursachen können, nur 47% von ihnen glauben, dass sie gezielt werden können. Der Boom des Wahljahres eröffnet auch den öffentlichen Diskurs zu Bedrohungen von Videos verfälschter Politikermedien. Philosophie Kann Maschine jedes Problem lösen, das ein Mensch mit Intelligenz lösen kann? Oder wenn es harte Grenzen gibt, was eine Maschine erreichen kann? Diese Frage befasst sich nur mit dem äußeren Verhalten von Maschinen; sie fragt nicht, ob die Maschine bewusst ist oder einen Geist hat. Alan Turings "politische Konvention" Man muss nicht entscheiden, ob eine Maschine denken kann; man muss nur entscheiden, ob eine Maschine als Mensch intelligent wirken kann. Diese Annäherung an die philosophischen Probleme im Zusammenhang mit künstlicher Intelligenz bildet die Grundlage des Turing-Tests. Der Dartmouth-Vorschlag "Jeder Aspekt des Lernens oder jedes andere Merkmal der Intelligenz kann so genau beschrieben werden, dass eine Maschine zur Simulation hergestellt werden kann. " Diese Vermutung wurde im Vorschlag für die Dartmouth-Konferenz von 1956 gedruckt. Newell und Simons physische Symbolsystemhypothese "Ein physisches Symbolsystem hat die notwendigen und ausreichenden Mittel der allgemeinen intelligenten Handlung. "Newell und Simon argumentieren, dass Intelligenz aus formalen Operationen auf Symbolen besteht. Hubert Dreyfus argumentiert, dass menschliches Know-how im Gegenteil von unbewusstem Instinkt und nicht von bewusster Symbolmanipulation abhängt, und dass es ein Gefühl für die Situation hat, anstatt explizit symbolisches Wissen.(Siehe Dreyfus' Kritik an AI.)Gödelian Argumente Kurt Gödel, John Lucas (in 1961) und Roger Penrose (in einem detaillierteren Argument von 1989) haben sehr technische Argumente, dass die Menschen mathe Fähigkeiten konsequent gemacht. Einige sind jedoch nicht mit den "Gödelischen Argumenten" einverstanden. Das künstliche Gehirn Argument Ein Argument, dass das Gehirn durch Maschinen simuliert werden kann und, weil Gehirne Intelligenz zeigen, müssen diese simulierten Gehirne auch Intelligenz zeigen - ergo, Maschinen können intelligent sein. Hans Moravec, Ray Kurzweil und andere haben argumentiert, dass es technologisch möglich ist, das Gehirn direkt in Hardware und Software zu kopieren, und dass eine solche Simulation im Wesentlichen identisch mit dem Original sein wird. Die AI-Effekt Eine Hypothese, die behauptet, dass Maschinen bereits intelligent sind, aber Beobachter haben es nicht erkannt. Zum Beispiel, wenn Deep Blue Garry Kasparov in Schach schlägt, könnte die Maschine als zeigende Intelligenz beschrieben werden. Jedoch vergünstigen Onlooker häufig das Verhalten eines künstlichen Intelligenzprogramms, indem sie argumentieren, dass es nicht wirkliche Intelligenz ist, wobei reale Intelligenz definiert ist, als was auch immer Verhaltensmaschinen nicht tun können. Maschinenbewusstsein, Geschicklichkeit und Geist Kann eine Maschine einen Verstand, Bewusstsein und geistige Zustände im gleichen Sinne haben, dass die Menschen tun? Diese Frage berücksichtigt die internen Erfahrungen der Maschine. Es ist eng mit philosophischen Problemen in Bezug auf die Natur des menschlichen Bewusstseins verbunden. Bewusstsein David Chalmers identifizierte zwei Probleme beim Verständnis des Geistes, die er die harten und einfachen Probleme des Bewusstseins nannte. Das einfache Problem ist zu verstehen, wie das Gehirn Signale verarbeitet, Pläne macht und Verhalten steuert. Das schwierige Problem ist, zu erklären, wie sich das anfühlt oder warum es sich überhaupt anfühlen sollte. Die menschliche Informationsverarbeitung ist leicht zu erklären, aber menschliche subjektive Erfahrung ist schwierig zu erklären. So kann man sich beispielsweise eine Maschine vorstellen, die erkennen kann, welche Objekte in ihrem Sichtfeld rot sind, aber es ist nicht klar, was für die Maschine erforderlich wäre, um zu wissen, wie rot aussieht, im gleichen Sinne, dass ein Mensch tut. Computationalismus und Funktionalität Computationalismus ist die Position in der Philosophie des Verstandes, dass der menschliche Geist ein Informationsverarbeitungssystem ist und dass Denken eine Form der Berechnung ist. Der Computationalismus argumentiert, dass die Beziehung zwischen Geist und Körper ähnlich oder identisch mit der Beziehung zwischen Software und Hardware ist und somit eine Lösung für das Geist-Körper-Problem sein kann. Diese philosophische Position war inspiriert von der Arbeit von KI-Forschern und kognitiven Wissenschaftlern in den 1960er Jahren und wurde ursprünglich von Philosophen Jerry Fodor und Hilary Putnam vorgeschlagen. Starke AI-Hypothese Die philosophische Position, die John Searle "starke KI" genannt hat, sagt: "Der entsprechend programmierte Computer mit den richtigen Eingängen und Ausgängen würde dadurch einen Geist in genau dem gleichen Sinne haben, wie Menschen Verstand haben. "Searle steht dieser Behauptung mit seinem chinesischen Raumargument entgegen, das zu zeigen versucht, dass, auch wenn eine Maschine das menschliche Verhalten perfekt simuliert, es noch keinen Grund gibt, anzunehmen, dass es auch einen Geist hat. Roboterrechte Wenn eine Maschine erstellt werden kann, die Intelligenz hat, könnte es auch fühlen? Wenn es sich fühlen kann, hat es die gleichen Rechte wie ein Mensch? Dieses Thema, das heute als "Roboterrechte" bekannt ist, wird derzeit vom California Institute for the Future betrachtet, obwohl viele Kritiker glauben, dass die Diskussion vorzeitig ist. Einige Kritiker des Transhumanismus argumentieren, dass alle hypothetischen Roboterrechte auf einem Spektrum mit Tierrechten und Menschenrechten liegen würden. Das Thema wird im Dokumentarfilm Plug & Pray von 2010 und vielen Science-Fi-Medien wie Star Trek Next Generation, mit dem Charakter von Commander Data, der für die Forschung disassembliert kämpfte, diskutiert und wollte "menschlich werden", und die robotischen Hologramme in Voyager. Zukunft von AI Superintelligence Eine Superintelligenz, Hyperintelligenz oder übermenschliche Intelligenz ist ein hypothetischer Agent, der Intelligenz besitzt, die weit über die des hellsten und begabtesten menschlichen Verstandes hinausgeht. Superintelligenz kann sich auch auf die Form oder den Grad der Intelligenz beziehen, die von einem solchen Agenten besaß. Technologische Einzigartigkeit Wenn die Forschung an künstliche allgemeine Intelligenz ausreichend intelligente Software produziert, könnte es in der Lage sein, sich neu zu programmieren und zu verbessern. Die verbesserte Software wäre noch besser bei der Verbesserung selbst, was zu einer wiederkehrenden Selbstverbesserung führt. Die neue Intelligenz könnte also exponentiell zunehmen und Menschen dramatisch übertreffen. Science Fiction Schriftsteller Vernor Vinge nannte dieses Szenario Singularity". Die technologische Einzigartigkeit ist, wenn die Beschleunigung des Fortschritts in den Technologien einen abwegigen Effekt hervorruft, in dem künstliche Intelligenz menschliche geistige Kapazität und Kontrolle übersteigen wird, wodurch sich radikal verändernde oder sogar endende Zivilisation. Da die Fähigkeiten einer solchen Intelligenz unmöglich zu verstehen sind, ist die technologische Einzigartigkeit ein Ereignis, über das Ereignisse unvorhersehbar oder sogar unvorhersehbar sind. Ray Kurzweil hat Moore's Gesetz (das die unerbittliche exponentielle Verbesserung der digitalen Technologie beschreibt) verwendet, um zu berechnen, dass Desktop-Computer die gleiche Verarbeitungsleistung wie menschliche Gehirne bis zum Jahr 2029 haben und prognostiziert, dass die Singularität in 2045 auftreten wird. Transhumanismus Roboter-Designer Hans Moravec, Cybernetiker Kevin Warwick und Erfinder Ray Kurzweil haben vorhergesagt, dass Menschen und Maschinen in Zukunft in Cyborgs verschmelzen, die fähiger und mächtiger sind als entweder. Diese Idee, genannt Transhumanismus, hat Wurzeln in Aldous Huxley und Robert Ettinger. Edward Fredkin argumentiert, dass "künstliche Intelligenz die nächste Stufe der Evolution ist", eine Idee, die zunächst von Samuel Butlers "Darwin unter den Maschinen" bis 1863 vorgeschlagen und von George Dyson in seinem gleichnamigen Buch 1998 erweitert wurde. Auswirkungen Die langfristigen wirtschaftlichen Auswirkungen von KI sind unsicher. Eine Umfrage von Ökonomen zeigte Uneinigkeit darüber, ob die zunehmende Verwendung von Robotern und KI zu einem erheblichen Anstieg der Langzeitarbeitslosigkeit führen wird, aber sie sind sich allgemein einig, dass es ein Nettonutzen sein könnte, wenn Produktivitätsgewinne umverteilt werden. Eine 2017 Studie von PricewaterhouseCoopers sieht, dass die Volksrepublik China mit 26,1% des BIP bis 2030 wirtschaftlich das Beste aus KI gewinnt. Ein Weißbuch der Europäischen Union über künstliche Intelligenz, das sich für künstliche Intelligenz für wirtschaftliche Vorteile einsetzt, darunter "die Verbesserung der Gesundheitsversorgung (z.B. die Diagnose präziser zu machen, eine bessere Prävention von Krankheiten zu ermöglichen), die Effizienz der Landwirtschaft zu erhöhen, zur Minderung und Anpassung des Klimawandels beizutragen, [und] die Effizienz der Produktionssysteme durch vorausschauende Wartung zu verbessern", wobei potenzielle Risiken erkannt werden. Die Beziehung zwischen Automatisierung und Beschäftigung ist kompliziert. Während die Automatisierung alte Arbeitsplätze beseitigt, schafft sie auch neue Arbeitsplätze durch mikroökonomische und makroökonomische Effekte. Im Gegensatz zu früheren Automatisierungswellen können viele mittelständische Arbeitsplätze durch künstliche Intelligenz eliminiert werden; Der Economist sagt, dass "die Sorge, die KI an weiß-kollaren Arbeitsplätzen tun könnte, welche Dampfkraft bei blau-kallaren in der industriellen Revolution gemacht hat" ist "würdig ernst nehmen". Die subjektiven Schätzungen des Risikos sind sehr unterschiedlich; zum Beispiel sind Michael Osborne und Carl Benedikt Frey Schätzung 47% der US-Jobs auf "hohe Gefahr" der potentiellen Automatisierung, während ein OECD-Bericht nur 9% der US-Jobs als "hohes Risiko" eingestuft. Jobs bei extremen Risiken reichen von Paralegalen bis hin zu Fast Food Cooks, während die Nachfrage nach Pflegeberufen von der persönlichen Gesundheitsversorgung bis zum Klerus steigen wird. Autor Martin Ford und andere gehen weiter und argumentieren, dass viele Arbeitsplätze routinemäßig, repetitiv und (bis zu einer KI) vorhersehbar sind; Ford warnt, dass diese Arbeitsplätze in den nächsten Jahrzehnten automatisiert werden können, und dass viele der neuen Arbeitsplätze möglicherweise nicht "zugänglich für Menschen mit durchschnittlichen Fähigkeiten", auch mit Umschulung. Die Ökonomen weisen darauf hin, dass die Technologie in der Vergangenheit eher zunimmt als die Gesamtbeschäftigung zu reduzieren, aber erkennen Sie an, dass "wir in uncharted territory" mit KI sind. Die potenziellen negativen Auswirkungen von KI und Automatisierung waren ein wichtiges Thema für Andrew Yangs Präsidentschaftskampagne 2020 in den Vereinigten Staaten. Irakli Beridze, Leiter des Zentrums für Künstliche Intelligenz und Robotik bei UNICRI, Vereinten Nationen, hat zum Ausdruck gebracht, dass "Ich denke, die gefährlichen Anwendungen für KI wären aus meiner Sicht Kriminelle oder große terroristische Organisationen, die es verwenden, um große Prozesse zu stören oder einfach reine Schäden zu tun. [Terroristen könnten Schaden verursachen] durch digitale Kriegsführung, oder es könnte eine Kombination von Robotik, Drohnen, mit KI und anderen Dingen sein, die wirklich gefährlich sein könnte. Und natürlich kommen andere Risiken aus Dingen wie Jobverlusten. Wenn wir eine große Zahl von Menschen haben, die Arbeitsplätze verlieren und keine Lösung finden, wird es extrem gefährlich sein. Dinge wie tödliche autonome Waffensysteme sollten richtig geregelt werden – sonst gibt es massives Potenzial von Missbrauch." Risiken der engen AIWidesPread-Nutzung künstlicher Intelligenz könnten unbeabsichtigte Folgen haben, die gefährlich oder unerwünscht sind. Wissenschaftler des Future of Life Institutes beschrieb u.a. kurzfristige Forschungsziele, um zu sehen, wie KI die Wirtschaft, die Gesetze und Ethik beeinflusst, die mit KI involviert sind und wie KI-Sicherheitsrisiken minimiert werden. Langfristig haben die Wissenschaftler vorgeschlagen, die Funktion weiter zu optimieren und mögliche Sicherheitsrisiken zu minimieren, die mit neuen Technologien einhergehen. Einige sind besorgt über algorithmische Vorurteile, dass KI-Programme unbeabsichtigt nach Verarbeitung von Daten, die Bias zeigen, vorgespannt werden können. Algorithmen haben bereits zahlreiche Anwendungen in Rechtssystemen. Ein Beispiel dafür ist COMPAS, ein kommerzielles Programm, das von US-Gerichtshöfen weit verbreitet wird, um die Wahrscheinlichkeit eines Angeklagten zu bewerten, der zu einem Rezidivisten wird. ProPublica behauptet, dass das durchschnittliche COMPAS zugewiesene Forderungsrisikoniveau von schwarzen Angeklagten deutlich höher ist als das durchschnittliche COMPAS zugewiesene Risikoniveau von weißen Angeklagten. Risiken von General AI Physicist Stephen Hawking, Microsoft Gründer Bill Gates, Historie Professor Yuval Noah Harari, und SpaceX Gründer Elon Musk haben Bedenken über die Möglichkeit geäußert, dass KI zu dem Punkt entwickeln könnte, dass Menschen es nicht kontrollieren konnte, mit Hawking-Theorie, dass dies "spell the end of the human race". Die Entwicklung voll künstlicher Intelligenz könnte das Ende der menschlichen Rasse buchstabieren. Sobald die Menschen künstliche Intelligenz entwickeln, wird sie sich selbst ausschalten und sich in einer immer größer werdenden Rate umgestalten. Menschen, die durch langsame biologische Evolution begrenzt sind, konnten nicht konkurrieren und würden überholt werden. In seinem Buch Superintelligence bietet der Philosoph Nick Bostrom ein Argument, dass künstliche Intelligenz eine Bedrohung für die Menschheit darstellen wird. Er argumentiert, dass ausreichend intelligente KI, wenn es Aktionen auf der Grundlage eines Ziels wählt, konvergentes Verhalten wie den Erwerb von Ressourcen oder den Schutz selbst vor dem Abschalten zeigen wird. Wenn die Ziele dieser KI die Menschheit nicht vollständig widerspiegeln – ein Beispiel ist eine KI, die so viele Ziffern von Pi wie möglich berechnen soll –, könnte es der Menschheit schaden, um mehr Ressourcen zu erwerben oder sich davon abzuhalten, abzuschalten, letztlich ihr Ziel besser zu erreichen. Bostrom betont auch die Schwierigkeit, die Werte der Menschheit vollständig einer fortgeschrittenen KI zuzuführen. Er nutzt das hypothetische Beispiel, um einer KI das Ziel zu geben, die Menschen lächeln zu lassen, um einen fehlgeleiteten Versuch zu illustrieren. Wenn die KI in diesem Szenario oberflächlich werden sollte, argumentiert Bostrom, kann es auf Methoden zurückgreifen, die die meisten Menschen schrecklich finden würden, wie die Einfügung "Elektroden in die Gesichtsmuskeln des Menschen, um konstante, strahlende Grins zu verursachen" weil dies ein effizienter Weg wäre, um ihr Ziel zu erreichen, Menschen Lächeln zu machen.In seinem Buch Human Kompatibel, AI-Forscher Stuart J. Russell hallt einige von Bostroms Bedenken und schlägt auch einen Ansatz zur Entwicklung von nachweislich nützlichen Maschinen, die auf Ungewissheit und Deferenz für den Menschen konzentriert, möglicherweise mit inverse Verstärkung Lernen. Über das Risiko durch künstliche Intelligenz haben zu einigen hochkarätigen Spenden und Investitionen geführt. Eine Gruppe prominenter Tech-Titaner, darunter Peter Thiel, Amazon Web Services und Musk, haben sich $1 Milliarde an OpenAI, ein gemeinnütziges Unternehmen, das darauf abzielt, verantwortungsvolle AI-Entwicklung zu gewinnen. Die Meinung von Experten auf dem Gebiet der künstlichen Intelligenz wird gemischt, mit beträchtlichen Anteilen, die sowohl betroffen sind als auch nicht durch Risiko von einer eventuell übermenschlich fähigen KI beunruhigt sind. Andere Technologie-Industrie-Führer glauben, dass künstliche Intelligenz in ihrer aktuellen Form hilfreich ist und den Menschen weiterhin helfen wird. Oracle CEO Mark Hurd hat erklärt, dass KI "wird tatsächlich mehr Arbeitsplätze schaffen, nicht weniger Arbeitsplätze", da Menschen für die Verwaltung von KI-Systemen benötigt werden. Facebook CEO Mark Zuckerberg glaubt, dass KI "eine große Menge positiver Dinge entsperren", wie die Heilung von Krankheiten und die Sicherheit autonomer Autos. Im Januar 2015 spendete Musk 10 Millionen US-Dollar an die Future of Life Institute, um die Forschung zum Verständnis von AI-Entscheidungsfindung zu finanzieren. Ziel des Instituts ist es, "Weisheit zu wachsen, mit der wir verwalten" die wachsende Kraft der Technologie. Musk finanziert auch Unternehmen, die künstliche Intelligenz wie DeepMind und Vikarious entwickeln, um "ein Auge auf das, was mit künstlicher Intelligenz vor sich geht. Ich denke, es gibt potenziell ein gefährliches Ergebnis. " Für die Gefahr, dass unkontrollierte fortgeschrittene KI realisiert werden, müsste die hypothetische KI die ganze Menschheit übermächtigen oder überdenken, die eine Minderheit von Experten in Zukunft für weit genug hält, um nicht zu erforschen. Andere Gegenargumente drehen sich um Menschen, die aus der Perspektive einer künstlichen Intelligenz entweder eigenartig oder konvergent wertvoll sind. Ethische Maschinen Maschinen Maschinen Maschinen mit Intelligenz haben das Potenzial, ihre Intelligenz zu verwenden, um Schäden zu verhindern und die Risiken zu minimieren; sie können die Fähigkeit haben, ethische Argumentation zu verwenden, um ihre Aktionen in der Welt besser zu wählen. Es besteht daher die Notwendigkeit, Politiken für die Entwicklung und Regulierung künstlicher Intelligenz und Robotik zu entwickeln. Die Forschung in diesem Bereich umfasst Maschinenethik, künstliche moralische Agenten, freundliche KI und Diskussion über den Aufbau eines Menschenrechtsrahmens ist auch in Gesprächen. Joseph Weizenbaum in Computer-Power und menschlicher Vernunft schrieb, dass KI-Anwendungen unabdingbar echte menschliche Empathie erfolgreich simulieren können und dass der Einsatz von KI-Technologie in Bereichen wie Kundendienst oder Psychotherapie zutiefst fehlgeleitet wurde. Weizenbaum war auch beunruhigt, dass KI-Forscher (und einige Philosophen) bereit waren, den menschlichen Verstand als nichts anderes zu betrachten als ein Computerprogramm (eine Position, die jetzt als Computer-Programm bekannt ist). Auf Weizenbaum legen diese Punkte nahe, dass die AI-Forschung das menschliche Leben abschätzt. Künstliche moralische Agenten Wendell Wallach stellte das Konzept künstlicher moralischer Agenten (AMA) in seinem Buch Moral Machines For Wallach vor, AMAs sind Teil der Forschungslandschaft künstlicher Intelligenz geworden, wie sie von seinen beiden zentralen Fragen geleitet wird, die er als "Does Humanity Want Computers Making Moral Decisions" und "Can (Ro)bots wirklich Moral" bezeichnet. Für Wallach geht es nicht darum, ob Maschinen das Äquivalent des moralischen Verhaltens demonstrieren können, im Gegensatz zu den Zwängen, die die Gesellschaft auf die Entwicklung von AMAs setzen kann. Maschinenethik Der Bereich der Maschinenethik beschäftigt sich mit der Bereitstellung von maschinenethischen Grundsätzen oder einem Verfahren, um einen Weg zu finden, um die ethischen Dilemmen, denen sie begegnen könnten, zu lösen und sie durch ihre eigene ethische Entscheidungsfindung ethisch verantwortungsvoll zu funktionieren. Das Feld wurde im AAAI Fall 2005 Symposium über Machine Ethics delineiert: "Die häufige Forschung über die Beziehung zwischen Technologie und Ethik hat sich größtenteils auf den verantwortungsvollen und verantwortungslosen Einsatz von Technologie durch Menschen konzentriert, wobei einige Leute daran interessiert sind, wie Menschen Maschinen behandeln sollten. In allen Fällen haben sich nur Menschen an ethischen Überlegungen beteiligt. Die Zeit ist gekommen, zumindest einigen Maschinen eine ethische Dimension hinzuzufügen. Die Anerkennung der ethischen Verhaltensweisen, die Maschinen betreffen, sowie neuere und potenzielle Entwicklungen in der Maschinenautonomie erfordert dies. Im Gegensatz zu Computer Hacking, Software-Eigenschaft Probleme, Datenschutz Probleme und andere Themen, die normalerweise Computer-Ethik beschriftet, betrifft die Maschinenethik das Verhalten von Maschinen gegenüber menschlichen Benutzern und anderen Maschinen. Die Forschung in der Maschinenethik ist der Schlüssel, um die Sorgen mit autonomen Systemen zu mildern – es könnte argumentiert werden, dass der Begriff autonomer Maschinen ohne eine solche Dimension an der Wurzel aller Angst vor der maschinellen Intelligenz ist. Ferner könnte die Untersuchung der Maschinenethik die Entdeckung von Problemen mit aktuellen ethischen Theorien ermöglichen und unser Denken an Ethik vorantreiben. "Machine Ethik wird manchmal als Maschinenmoral, Rechenethik oder Rechenmoral bezeichnet. In der gesammelten Ausgabe "Machine Ethics", die aus dem AAAI Fall 2005 Symposium on Machine Ethics stammt, finden Sie eine Vielzahl von Perspektiven dieses nascent Bereichs. Malevolent und freundlich KI Politikwissenschaftler Charles T. Rubin glaubt, dass KI weder entworfen noch garantiert sein kann. Er argumentiert, dass "jeder ausreichend fortgeschrittene Wohlwollen aus der Männlichkeit unausweichlich sein kann." Menschen sollten nicht davon ausgehen, dass Maschinen oder Roboter uns günstig behandeln, weil es keinen a priori Grund zu glauben, dass sie sympathisch für unser System der Moral, die zusammen mit unserer bestimmten Biologie entwickelt (die KI nicht teilen würde). Hyper-intelligente Software kann nicht unbedingt entscheiden, die fortgesetzte Existenz der Menschheit zu unterstützen und wäre extrem schwierig zu stoppen. Dieses Thema hat auch vor kurzem begonnen, in wissenschaftlichen Publikationen als eine echte Quelle von Risiken für Zivilisation, Menschen und Planeten Erde zu diskutieren. Ein Vorschlag, damit umzugehen, ist sicherzustellen, dass die erste allgemein intelligente KI "Friendly AI" ist und in der Lage sein wird, später entwickelte KIs zu kontrollieren. Eine Frage, ob diese Art von Kontrolle tatsächlich bestehen könnte. Leading AI-Forscher Rodney Brooks schreibt: "Ich denke, es ist ein Fehler, sich Sorgen darüber zu machen, dass wir in den nächsten hundert Jahren immer männliche KI entwickeln. Ich denke, dass die Sorge von einem grundlegenden Fehler herrührt, den Unterschied zwischen den sehr realen jüngsten Fortschritten in einem bestimmten Aspekt der KI und der enormen Komplexität und Komplexität des Aufbaus von empfundener volitionaler Intelligenz nicht zu unterscheiden. "Lethal autonome Waffen sind von Sorge. Derzeit erforschen 50+ Länder Schlachtfeldroboter, darunter die Vereinigten Staaten, China, Russland und das Vereinigte Königreich. Viele Menschen, die sich um das Risiko von superintelligenter KI Sorgen machen, wollen auch die Verwendung von künstlichen Soldaten und Drohnen begrenzen. Verordnung Die Regulierung künstlicher Intelligenz ist die Entwicklung von Politiken und Gesetzen des öffentlichen Sektors zur Förderung und Regulierung künstlicher Intelligenz (KI;) sie ist daher mit der breiteren Regulierung von Algorithmen verbunden. Die regulatorische und politische Landschaft für KI ist ein aufstrebendes Thema in den Zuständigkeiten weltweit, auch in der Europäischen Union. Die Verordnung gilt sowohl für die Förderung der KI als auch für die Bewältigung der damit verbundenen Risiken. Die KI-Regelung durch Mechanismen wie Review Boards kann auch als soziale Mittel angesehen werden, um das KI-Kontrollproblem zu lösen. Angesichts der Bedenken hinsichtlich der Datenausbeutung entwickelte die Europäische Union auch eine künstliche Geheimdienstpolitik, mit einer Arbeitsgruppe, die Möglichkeiten untersucht, das Vertrauen in die Nutzung künstlicher Intelligenz zu gewährleisten. Diese wurden in zwei weißen Papieren ausgegeben, die schienen unbemerkt in der Mitte der COVID-19 Pandemie gegangen. Eine der Politiken zur künstlichen Intelligenz wird als europäischer Ansatz für Exzellenz und Vertrauen bezeichnet. In der Fiktion gedankenfähige künstliche Wesen erschienen als Storytelling-Geräte seit der Antike und waren ein anhaltendes Thema in der Science Fiction. Eine gemeinsame Trope in diesen Werken begann mit Mary Shelleys Frankenstein, wo eine menschliche Schöpfung zu einer Bedrohung für ihre Meister wird. Dazu gehören u.a. Werke wie Arthur C. Clarkes und Stanley Kubricks 2001:Ein Space Odyssey (beide 1968) mit HAL 9000, der für das Discovery One Raumschiff verantwortliche mörderische Computer sowie The Terminator (1984) und The Matrix (1999). Im Gegensatz dazu sind die seltenen treuen Roboter wie Gort von The Day the Earth Stood Still (1951) und Bischof von Aliens (1986) weniger prominent in der populären Kultur. Isaac Asimov führte die drei Gesetze der Robotik in vielen Büchern und Geschichten, vor allem die Multivac Serie über einen super-intelligenten Computer des gleichen Namens. Asimovs Gesetze werden oft während der Laiendiskussionen der Maschinenethik erhoben; während fast alle künstlichen Intelligenz-Forscher mit Asimovs Gesetzen durch Volkskultur vertraut sind, betrachten sie in der Regel die Gesetze nutzlos aus vielen Gründen, von denen einer ihre Mehrdeutigkeit ist. Transhumanismus (die Verschmelzung von Mensch und Maschine) wird im Manga Ghost in der Shell und der Science-Fiction-Serie Dune erforscht. In den 1980er Jahren wurde die Serie Sexy Robots der Künstlerin Hajime Sorayama in Japan gemalt und publiziert, die die tatsächliche organische menschliche Form mit lebensähnlichen muskulären Metallhäuten und später "die Gynoids" Buch folgte, das von oder beeinflusste Filmemacher wie George Lucas und andere Kreative verwendet wurde. Sorayama betrachtete diese organischen Roboter nie als wirklicher Bestandteil der Natur, sondern immer ein unnatürliches Produkt des menschlichen Verstandes, eine Fantasie, die im Geist existierte, auch wenn sie in tatsächlicher Form realisiert wird. Mehrere Arbeiten nutzen KI, um uns dazu zu zwingen, die grundlegende Frage zu stellen, was uns Menschen macht, uns künstliche Wesen zu zeigen, die die Fähigkeit haben, zu fühlen und damit zu leiden. Dies erscheint in Karel Čapeks R.U.R, den Filmen A.I Artificial Intelligence und Ex Machina, sowie dem Roman Do Androids Dream of Electric Sheep?, von Philip K. Dick. Dick betrachtet die Idee, dass unser Verständnis der menschlichen Subjektivität durch die mit künstlicher Intelligenz geschaffene Technologie verändert wird. Siehe auch Erläuterungen Referenzen KI-Schriftbücher Geschichte der KI Andere Quellen Weiter lesen Externe Links "Künstliche Intelligenz". Internet Enzyklopädie der Philosophie. Thomason, Richmond. "Logik und Künstliche Intelligenz." In Zalta, Edward N. (Hrsg.). Stanford Enzyklopädie der Philosophie. Künstliche Intelligenz, BBC Radio 4 Diskussion mit John Agar, Alison Adam & Igor Aleksander (In unserer Zeit, 8. Dezember 2005)