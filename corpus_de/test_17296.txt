Ein Datenzentrum (Amerikanisches Englisch) oder Datenzentrum (britisches Englisch) ist ein Gebäude, ein eigener Raum innerhalb eines Gebäudes oder eine Gruppe von Gebäuden, die für Computersysteme und zugehörigen Komponenten wie Telekommunikation und Speichersysteme verwendet werden. IT-Operationen sind für die Kontinuität von Unternehmen von entscheidender Bedeutung, umfassen in der Regel überflüssige oder Reservekomponenten und Infrastruktur für die Stromversorgung, Datenkommunikationsverbindungen, Umweltkontrollen (z.B. Klimaanlage, Brandschutz) und verschiedene Sicherheitseinrichtungen. Ein großes Datenzentrum ist ein industrieller Betrieb, der als kleine Stadt so viel Strom nutzt. Geschichtsdatenzentren haben ihre Wurzeln in den riesigen Computerräumen der 1940er Jahre, die von ENIAC benannt wurden, eines der frühesten Beispiele eines Datenzentrums. Frühcomputersysteme, die komplex sind, um zu betreiben und zu halten, erfordern ein spezielles Umfeld, in dem sie arbeiten. Viele Kabel waren notwendig, um alle Komponenten zu verbinden, und Methoden, um dies zu berücksichtigen und zu organisieren, wurden entwickelt, wie Standardträger, um Ausrüstungen, aufgestockte Böden und Kabelschalen (installierte Überbuchung oder im erhöhten Boden). Ein einheitlicher Hauptrahmen erforderte ein großes Machtvolumen und musste abgekühlt werden, um Überhitzung zu vermeiden. Sicherheit wurde wichtig – Computer waren teuer und wurden häufig für militärische Zwecke verwendet. Grundfertigkeiten zur Kontrolle des Zugangs zum Computerraum wurden daher entwickelt. Während des Booms der Mikrocomputerindustrie, insbesondere in den 80er Jahren, begannen die Nutzer, überall Computer zu installieren, in vielen Fällen mit wenig oder gar keiner Sorgfalt über Betriebsanforderungen. Da jedoch die IT-Ressourcen (IT) in der Komplexität angestiegen sind, haben sich die Organisationen der Notwendigkeit bewusst, IT-Ressourcen zu kontrollieren. In Verbindung mit den neuen Standards für das Netzwerk, das strukturiert ist, konnte ein hierarchisches Design verwendet werden, das die Server in einem bestimmten Raum innerhalb des Unternehmens aufbaut. Die Verwendung des Begriffs "Datenzentrum", wie er auf speziell konzipierte Computerräume angewandt wurde, begann mit der Anerkennung dieser Zeit. Der Boom der Datenzentren kam während der Dot-com-Blase von 1997 bis 2000. Unternehmen brauchten schnelle Internet-Anbindung und Nicht-Stop-Betrieb, um Systeme zu installieren und eine Präsenz im Internet zu schaffen. Installation solcher Geräte war für viele kleinere Unternehmen nicht tragfähig. Viele Unternehmen haben sehr große Einrichtungen geschaffen, sogenannte Internet-Datenzentren (IDCs), die verbesserte Fähigkeiten, wie z. "Wenn eine Bell Atlantic-Linie abgeschnitten ist, können wir sie auf ... übertragen, um die Zeit des Ausstiegs zu minimieren. " Cloud-Datenzentren (CDC) wurden genutzt. Datenzentren kosten in der Regel viel zu bauen und zu erhalten. In zunehmendem Maße ist die Aufteilung dieser Begriffe fast verschwunden und sie werden in den Begriff „Datenzentrum“ integriert. Anforderungen an moderne Datenzentren Modernisierung und Datenverarbeitung verbessert Leistung und Energieeffizienz. Informationssicherheit ist ebenfalls ein Anliegen und daher muss ein Datenzentrum ein sicheres Umfeld bieten, das die Chancen eines Sicherheitsverstößes minimiert. Ein Datenzentrum muss daher hohe Standards einhalten, um die Integrität und Funktionalität seiner besuchten Computerumgebung zu gewährleisten. Industrieforschungsgesellschaft International Data Corporation (IDC) stellt das durchschnittliche Alter eines Datenzentrums in neun Jahren vor. Bloomberg, ein anderes Forschungsunternehmen, sagt Datenzentren, die älter als sieben Jahre sind, sind veraltet. Das Wachstum der Daten (163 zettabyte bis 2025) ist ein Faktor, der die Notwendigkeit einer Modernisierung der Datenzentren fördert. Konzentration auf die Modernisierung ist nicht neu: Die Sorge über veraltete Geräte wurde 2007 und 2011 aufgehoben. Uptime Institute war besorgt über das Zeitalter der dort befindlichen Ausrüstung. Bis 2018 hatte die Besorgnis erneut zugenommen, diese Zeit bis zum Alter des Personals: „Die Mitarbeiter des Rechenzentrums sind schneller als die Ausrüstung. Normen für Datenzentren Die Telekommunikation Industry Association’s Telecommunications Infrastructure Standard for Data Centers legt die Mindestanforderungen für Telekommunikationsinfrastruktur von Rechenzentren und Computerräumen fest, darunter einzelne Mieter-Unternehmensdatenbanken und Multi-tenant-Internet-Center. Die in diesem Dokument vorgeschlagene Topologie soll für jede Größe des Datenzentrums gelten. Telcordia GR-3160, NEBS Anforderungen für Telekommunikation Data Center Equipment and Spaces, bietet Leitlinien für Datenzentren innerhalb der Telekommunikationsnetze und Umweltanforderungen für die für die Installation in diesen Räumen vorgesehenen Geräte. Diese Kriterien wurden gemeinsam von Telcordia und Industrievertretern entwickelt. Sie können auf Anlagen des Datacenters zur Datenverarbeitung oder zur Informationstechnologie (IT) angewendet werden. Die Ausrüstung kann verwendet werden, um: Operate und die Verwaltung eines Telekommunikationsnetzes, das Datenzentrum auf Basis von Anwendungen direkt an die Kunden des Luftfahrtunternehmens bietet, die Dienste für Dritte anbieten, die ihren Kunden eine Kombination aus diesen und ähnlichen Datenzentrumanwendungen Datenzentrumtransformation bieten, wird durch integrierte Projekte, die im Laufe der Zeit durchgeführt werden, ein schrittweises Konzept durchlaufen. Es unterscheidet sich von einer traditionellen Methode der Datenzentren, die einen seriellen und schwefelfreien Ansatz verfolgt. Die typischen Projekte im Rahmen einer Datenverarbeitungsinitiative umfassen Normung/Konsolidierung, Virtualisierung, Automatisierung und Sicherheit. Normung/Konsolidierung: Die Verringerung der Anzahl der Datenzentren und die Vermeidung von Server-Sprawl (sowohl physische als auch virtuelle) umfassen oft die Ersetzung eines alternden Datenzentrums und wird durch Normung unterstützt. Virtualisierung: Geringere Kapital- und Betriebskosten senken den Energieverbrauch. virtuelle Desktops können in Datenzentren untergebracht und auf Abonnementbasis gemietet werden. Investitionsbank Lazard Capital Markets, die 2008 geschätzt wurde, dass bis 2012 48 Prozent der Unternehmenstätigkeiten virtueller abgewickelt werden. Bloomberg betrachtet die Virtualisierung als Katalysator für die Modernisierung. Automatisierung: Automatisierende Aufgaben wie Bereitstellung, Konfiguration, Zerkleinerung, Freisetzungsmanagement und Einhaltung sind nicht nur bei weniger qualifizierten IT-Arbeitern erforderlich. Sicherung: Der Schutz virtueller Systeme ist mit der bestehenden Sicherheit der physischen Infrastrukturen integriert. Maschinenraum Der Begriff "Maschinensaal" wird zu Zeiten verwendet, um den großen Raum innerhalb eines Datenzentrums zu nennen, in dem die tatsächliche Zentralverarbeitungsstelle liegt; dies kann von dort getrennt werden, wo Hochgeschwindigkeitsdrucker liegen. Klimaanlage ist im Maschinenraum besonders wichtig. Neben Klimaanlagen müssen Überwachungsausrüstungen vorhanden sein, von denen eine Art von Wasser vor Überschwemmungen erkannt werden soll. Ein Unternehmen, das seit mehreren Jahrzehnten eine Aktiengesellschaft hat: Wasser Alert. Das Unternehmen hat ab 2018 zwei konkurrierende Hersteller (Invetex, Hydro-Temp) und drei konkurrierende Vertriebshändler (Langden, Nordostboden, Slayton). Raisierte Boden A erweiterte Bodennormenleitfaden namens GR-2930 wurde von Telcordia Technologies, einer Tochtergesellschaft von Ericsson, entwickelt. Obwohl der erste aufgebrachte Bodencomputerraum von IBM im Jahr 1956 geschaffen wurde, und sie haben sich „für die 1960er Jahre rund um die 60er Jahre“ ausgesprochen, so war es die 1970er Jahre, die es für Computerzentren mehr üblich gemacht hat, um eine effizientere Verbreitung der kühlen Luft zu ermöglichen. Der erste Zweck des angesprochenen Bodens war es, den Zugang zu Kabeln zu ermöglichen. Beleuchtung des Beleuchtungszentrums Beleuchtung, das auch als dunkles oder dunkles Datenzentrum bekannt ist, ist ein Datenzentrum, das im Idealfall alle hat, aber die Notwendigkeit eines direkten Zugriffs durch das Personal außer unter außergewöhnlichen Umständen beseitigt. Wegen des fehlenden Bedarfs an Personal, das Datenzentrum zu betreten, kann es ohne Beleuchtung betrieben werden. Alle Geräte werden von entlegenen Systemen empfangen und verwaltet, mit Automationsprogramme, die zur Durchführung unbeabsichtigter Operationen verwendet werden. Neben den Energieeinsparungen, der Senkung der Personalkosten und der Fähigkeit, die Website weiter von den Bevölkerungszentren zu finden, verringert die Durchführung eines Beleuchtungszentrums die Gefahr von Schadanschlägen auf die Infrastruktur. Datenzentralen und -stufen Die beiden Organisationen in den Vereinigten Staaten, die Standards für das Datenzentrum veröffentlichen, sind der Telekommunikationsindustrieverband (TIA) und das Uptime Institute. Internationale Normen EN50600and ISO22237 Informationstechnologie – Datenzentrumanlagen und Infrastrukturen Klasse 1 Einzelweglösung Klasse 2 kombinierter Pfad mit Entlassungslösung Klasse 3 Multiple Pfade, die eine gleichzeitige Reparatur-/Betriebslösungsklasse 4 verschiedene Wege bieten, die eine schuldhafte Lösung (ausgenommen während der Wartung) bieten, Telecommunications Industry Association The Telecommunications Industry Association The Telecommunications Industry Association’s TIA-942 Standard für Datenzentren, veröffentlicht 2005 und aktualisiert vier Mal seit der Definition von vier Infrastrukturstufen. Stufe 1 - im Wesentlichen ein Serverraum, der nach den Grundzügen der Stufe 4 konzipiert ist, um die kritischsten Computersysteme mit vollständig entlassenen Subsystemen zu nutzen, die Fähigkeit, während der Primärenergieausbrüche kontinuierlich für eine unbefristete Zeit zu arbeiten. Uptime Institute – Datenzentrum Tierklassifikation Standard Four Tiers werden im Uptime Institute Standard definiert: Tier I: wird als CAPACITY bezeichnet und muss ein UPS-Ti II umfassen: wird als REDUNDANT CAPACITY beschrieben und wird entlassene Kraft und Kühlung Tier III hinzugefügt: wird als KONCURRENTLY MAINTAINABLE beschrieben und stellt sicher, dass ANY-Komponenten ohne Auswirkungen auf die Produktion von Tier IV aus dem Dienst genommen werden können: wird als FAULT TOLERANT bezeichnet, damit jede Produktionskapazität von ANY-Typen des Ausfalls isoliert werden kann. Datenzentrum Design In verschiedenen Richtungen wächst das Gebiet des Datenzentrums seit Jahrzehnten, darunter Neubau groß und klein neben der kreativen Wiederverwendung bestehender Einrichtungen wie aufgegebener Einzelhandelsraum, alte Salzminen und Kriegsschiffen. ein 65-story-Datenzentrum wurde bereits vorgeschlagen, die Zahl der Datenzentren im Jahr 2016 über 3 Millionen US-weit gewachsen zu sein, und mehr als die Dreifache, dass die Zahl der weltweiten Wocal-Baucodes die Mindesthöhen und andere Parameter bestimmen kann. Manche Überlegungen an der Gestaltung von Datenzentren sind: Größe - ein Gebäuderaum, ein oder mehrere Böden oder ein ganzes Gebäude, und können 1.000 oder mehr Server Raumfahrt, Kraft, Kühlung und Kosten im Datenzentrum halten. Maschinenbauinfrastruktur - Heizung, Belüftung und Klimaanlage (HVAC); Feuchtigkeits- und Dehumidifizierungsausrüstung; Pressung. elektrotechnische Infrastrukturgestaltung - Versorgungsdienstleistungsplanung, Vertrieb, Wechsel und Umgehung von Stromquellen; uninterruptible Stromquelle (UPS) Systeme und mehr. Gestaltungskriterien und Anforderungen an die Verfügbarkeit von Waren: Kosten der Vermeidung von Abstunden sollten nicht über die Kosten von Abstunden selbst hinausgehen Standortauswahl: Standortfaktoren umfassen die Nähe zu Stromnetzen, Telekommunikationsinfrastruktur, Vernetzungsdienste, Transportlinien und Notdiensten. Andere sind Flugwege, benachbarte Nutzungen, geologische Risiken und Klima (assoziiert mit Kühlkosten). Häufig verfügbare Macht ist schwer zu ändern. Eine hohe Verfügbarkeit verschiedener Parameter besteht darin, die Datenverfügbarkeit zu messen, die sich aus der Daten-Zentrumsverfügbarkeit über 95 % in der Zeit ergibt, wobei die Zahl der Neunen nach 99 % liegt. Einfachheit und Flexibilität sind Schlüsselelemente, damit ein Datenzentrum im Laufe der Zeit wachsen und ändern kann. Datenzentrum-Module sind vorgefertigte, standardisierte Bausteine, die leicht konzipiert und nach Bedarf verlegt werden können. Ein modulares Datenzentrum kann aus Datenzentrum-Geräten bestehen, die in Seecontainern oder ähnlichen tragbaren Containern enthalten sind. Komponenten des Datenzentrums können vorgefertigten und standardisierten Bauteilen hergestellt werden, die gegebenenfalls den Übergang erleichtern. Umweltkontrolltemperatur und Luftfeuchtigkeit werden über folgendes kontrolliert: Klimaanlage indirekte Kühlung, wie die Verwendung außerhalb der Luft, Indirekte Evaporative Kühlung (IDEC)-Einheiten und die Verwendung von Seewasser. Stromersatzleistung besteht aus einem oder mehreren uninterruptbaren Stromlieferungen, Batteriebanken und/oder Diesel- / Gasturbinengeneratoren. Um einzelne Mängel zu verhindern, sind alle Elemente der elektrischen Systeme, einschließlich der Sicherungssysteme, in der Regel vollständig verdoppelt, und kritische Server sind mit den A-side- und B-side-Kraftstoffen verbunden. Diese Regelung wird oft getroffen, um N+1 in den Systemen zu erreichen. Statische Überweisungen werden manchmal verwendet, um eine sofortige Umstellung von einer Lieferung auf die andere im Falle eines Ausfalls zu gewährleisten. Niederspannungskabelverbindung Optionen sind: Datenflächung lässt sich aus Sicherheitsgründen durch überhöhte Kabelfläschchen ausschließen und den Zusatz von Kühlsystemen über den Netzen vermeiden. Kleinere bzw. kostengünstigere Datenzentren ohne aufgestockte Bodenbeläge können Antistatische Fliesen für eine Bodenoberfläche verwenden. Luftfluss Luftflussmanagement befasst sich mit der Notwendigkeit, die Datenzentrum-Computerkühlung effizienter zu gestalten, indem verhindert wird, dass heiße Luft aus IT-Geräten freigesetzt wird und der Luftfluss verringert wird. Es gibt mehrere Methoden zur Trennung von Warm- und Kaltluftleitungen, wie heiße/kold aisle Eindämmung und stille Kühleinheiten. Aisle enthalten Kalte Aisle-Einnahmen werden durch die Ausbringung von Ausrüstungsmitteln durchgeführt, während die Fronten der Server mit Türen und Abdeckungen verschlossen sind. Computerkabinette werden häufig für die Eindämmung von Warm-/Cold-Aisles organisiert. Ducting verhindert das Mischen von Kühl- und Abgasen. Lenkungsketten sind miteinander konfrontiert, so dass Kühlluft die Aufnahme von Geräten und warme Luft in die Kühler ohne Mischen erreichen kann. Alternativ kann eine Reihe von Unterboden-Panels effiziente Kalte Luftwege schaffen, die auf die angeschnittenen Bodenfliesen ausgerichtet sind. Entweder die kalte Aisle oder die heiße Aisle können enthalten sein. Eine andere Alternative ist die Ausstattung von Kabinetten mit vertikalen Abgasrohren (chimney) Hotspot-Ausstiegen, die die Luft in ein besonderes Jahr über einer Tropfenobergrenze und zurück zu den Kühleinheiten oder zu externen venten können. Mit dieser Konfiguration ist die traditionelle heiße/cold aisle-Konformität nicht erforderlich. Feuerschutzdatenzentren sind Brandschutzsysteme, einschließlich passiver und aktiver Designelemente, sowie die Umsetzung von Brandschutzprogrammen in Betrieben. Rauchmelde werden in der Regel installiert, um ein Feuer in der jeweiligen Ausgangsphase frühzeitig zu verwarnungen. Zwei wasserbasierte Optionen sind: geräuchertes mist kein Wasser – einige der Vorteile der Verwendung chemischer Unterdrückung (sauberes, gasförmiges Feuerlöschsystem). Sicherheits physischen Zugang ist in der Regel eingeschränkt. Vielschichtige Sicherheit beginnt oft mit Fencing, Bollarden und Mantraps. Videokamera-Überwachung und ständige Sicherheitsschütze sind fast immer vorhanden, wenn das Datenzentrum groß ist oder sensible Informationen enthält. Fingerprint Anerkennung Mantraps beginnt zu einem gemeinsamen Ort. Loging Access ist durch einige Datenschutzbestimmungen erforderlich; einige Organisationen verbinden dies eng mit den Zugangskontrollsystemen. Mehr Log-Einführungen können an den Haupteingang, Eingang in interne Räume und an Betriebsschränken erfolgen. Zugangskontrollen bei den Kabinetten können mit intelligenten Stromverteilungseinheiten integriert werden, so dass Schleusen durch dasselbe Gerät vernetzt werden. Energieverbrauch ist ein zentrales Thema für Datenzentren. Power-Abonnement reicht von einer wenigen kW für eine Reihe von Servern in einer Schale bis zu mehreren zehn MW für große Anlagen. Manche Einrichtungen verfügen über Kraftwerksdichten von über 100-mal. Für höhere Kraftwerke sind die Stromkosten marktbeherrschend und machen über 10 % der Gesamtkosten des Eigentums (TCO) eines Datenzentrums aus. Stromkosten für 2012 überstiegen oft die Kosten der ursprünglichen Kapitalanlage. Greenpeace schätzte den weltweiten Stromverbrauch für 2012 als etwa 382 Milliarden kWh. Globale Datenzentren nutzten 2016 etwa 416 TWh, fast 40% mehr als das gesamte Vereinigte Königreich; US-amerikanische DC-Verbrauch betrug 90 Milliarden kWh. 2007 wurden die gesamten Informations- und Kommunikationstechnologien oder der IKT-Sektor für etwa 2 % der weltweiten CO2-Emissionen mit Datenzentren verantwortlich gemacht, die 14 % des IKT-Fußabdrucks ausmachen. Laut Schätzungen der US-WPA sind Server und Datenzentren für bis zu 1,5 % des Gesamtstromverbrauchs in den USA oder etwa 8,5 % der Treibhausgasemissionen in den USA für 2007 verantwortlich. Angesichts eines Business as usual Szenario werden Treibhausgasemissionen aus Datenzentren bis 2020 auf mehr als doppelter Basis projiziert. In einer 18-monatigen Untersuchung von Wissenschaftlern am Flughafen Rice University's Baker Institute for Public Policy in Houston und dem Institut für nachhaltige und angewandte Infodynamik in Singapur werden die schwerpunktmäßigen Emissionen bis 2020 mehr als dreifach. Energieeffizienz und Überbuchung Die am häufigsten verwendete Energieeffizienz von Datenzentrum Energieeffizienz ist die Effizienz der Energienutzung (PUE), berechnet als das Verhältnis der Gesamtleistung, die in das Datenzentrum eindringt, aufgeteilt nach der von IT-Geräten verwendeten Leistung. P U E = Total Facility Power IT Equipment Power Memedisplaystyle \ Mathematikrm {PUE} \=mbox{Gesamt Facility Power} Mit ihm wird der Prozentsatz der von Überkopf (Abkühlung, Beleuchtung usw.) eingesetzten Leistung gemessen. Das durchschnittliche US-Datenzentrum verfügt über eine PUE von 2.0, d. h. zwei Kilowatt der Gesamtleistung (überwiegend + IT-Ausrüstung) für jeden Watt, der an IT-Ausrüstung geliefert wird. Schätzungsweise werden rund 1,2 % des Staates geschätzt. Google veröffentlicht vierteljährliche Effizienz von Datenzentren. Die US-Umweltschutzagentur hat eine Energy-Star-Bewertung für eigenständige oder große Datenzentren. Um für das Umweltzeichen in Betracht zu kommen, muss ein Datenzentrum in der oberen Energieeffizienz aller gemeldeten Anlagen liegen. Nach dem Energieeffizienz-Verbesserungsgesetz von 2015 (Vereinigte Staaten) müssen Bundeseinrichtungen – einschließlich Datenzentren – effizienter arbeiten. Kaliforniens Titel 24 (2014) des Kodex von Kalifornien Mandate, dass jedes neu errichtete Datenzentrum eine Form des Luftflusses zur Optimierung der Energieeffizienz haben muss. Europäische Union hat auch eine ähnliche Initiative: EU-Verhaltenskodex für Datenzentren. Energienutzungsanalyse und Projekte Der Schwerpunkt der Messung und Analyse der Energienutzung liegt über dem, was von IT-Ausrüstung verwendet wird; die Anlage unterstützt Hardware wie Kühler und Fans auch Energie. 2011 wurden Serverträger in Datenzentren für mehr als 25 kW konzipiert und der typische Server wurde auf etwa 30 % des verbrauchten Stroms geschätzt. Energienachfrage nach Informationsspeichersystemen stieg ebenfalls an. Es wurde geschätzt, dass ein Hochleistungs-Datenzentrum eine 1 Megawatt (MW)-Anforderung hat und über seine Lebensdauer 20 000 000 Strom verbraucht, wobei die Kühlung 35 % bis 45 % der Gesamtkosten des Datenzentrums entspricht. Berechnungen zeigten, dass in zwei Jahren die Kosten für den Kauf und die Kühlung eines Servers den Kosten des Kaufs der Server-Hardware entsprechen könnten. Forschung im Jahr 2018 hat gezeigt, dass ein erheblicher Anteil an Energie durch die Optimierung der IT-Erfrischungsraten und die zunehmende Nutzung von Server erhalten bleiben könnte. 2011 gründeten Facebook, Rackspace und andere das Open Compute Project (OCP), um offene Standards für umweltfreundlichere Datenzentrum-.technologien zu entwickeln und zu veröffentlichen. Facebook hat im Rahmen des Projekts den Entwurf seines Servers veröffentlicht, den es für sein erstes spezielles Datenzentrum in Prineville gebaut hatte. Nutzung von Servern mit höherem Abstand für effizientere Wärmesenken und ermöglichte den Einsatz von Fans, die mehr Luft mit weniger Energie transportiert haben. Indem der Energieverbrauch aufgrund unnötiger Expansions-Slots auf dem Mutterboard und ungelöster Komponenten, wie z.B. einer Grafikkarte, nicht kommerziell genutzt wird, wurde ebenfalls eingespart. 2016 Google kam dem Projekt bei und veröffentlichte die Entwürfe seines 48V DC-Span-Datenzentrums.Dieses Design war lange Teil von Google Datacentern. Google hat durch die Beseitigung der in der Regel in Datenzentren eingesetzten Multiplen Transformatoren eine Steigerung der Energieeffizienz um 30 % erreicht. Im Jahr 2017 wird der Verkauf von Datenzentrum Hardware mit Sitz in OCP bis zu 1,2 Milliarden $ und bis 2021 voraussichtlich 6 Milliarden $ erreichen. Power and Kühl Analysis Power ist die größte wiederkehrende Kosten für den Nutzer eines Datenzentrums. Kühlung auf oder unter 70 °F (21 °C) Abfall Geld und Energie. Darüber hinaus können überkühlende Geräte in Umgebungen mit hoher relativer Luftfeuchtigkeit die Ausrüstung auf einen hohen Feuchtigkeitsgehalt ausstellen, der das Wachstum von Salzeinlagen auf funktionstüchtigen Filamenten in den Kreislauf erleichtert. Eine Energie- und Kühlanalyse, die auch als thermische Bewertung bezeichnet wird, misst die relativen Temperaturen in bestimmten Bereichen sowie die Fähigkeit der Kühlsysteme zur Behandlung bestimmter Umgebungstemperaturen. Leistungs- und Kühlungsanalysen können dazu beitragen, Hotspots, überkühlte Gebiete zu ermitteln, die eine höhere Stromverbrauchdichte, den Bruch der Ausrüstungsladung, die Wirksamkeit einer erhöhten Basisstrategie und eine optimale Ausrüstungsposition (wie AC-Einheiten) zum Ausgleich der Temperaturen im gesamten Datenzentrum bewältigen können. Kraftkühlungsdichte ist eine Maßnahme, wie viel Quadratmaterial das Zentrum mit maximaler Kapazität kühlen kann. Die Kühlung von Datenzentren ist der zweitgrößte Stromverbraucher nach Servern. Die Kühlenergie variiert zwischen 10 % des Gesamtenergieverbrauchs in den effizientesten Datenzentren und erreicht bis zu 45 % in den Standard-Luftlichtzentren. Energieeffizienzanalyse Eine Energieeffizienz-Analyse misst der Energieverbrauch von Datenzentrum IT und Anlagen. Maßnahmen zur Energieeffizienz-Analyse sind typische Faktoren wie die Effizienz des Datenzentrums (PUE) gegen Industrienormen, die Ermittlung mechanischer und elektrischer Quellen von Ineffizienz und die Ermittlung von Luftqualitätsparametern. Jedoch besteht die Begrenzung der meisten aktuellen Parameter und Ansätze darin, dass sie IT in der Analyse nicht enthalten. Fallstudien haben gezeigt, dass durch die ganzheitliche Energieeffizienz in einem Datenzentrum größere Effizienzgewinne erreicht werden können, die ansonsten nicht möglich sind. Analyse der Chole Flüssigkeitsdynamik (CFD) Diese Art der Analyse verwendet anspruchsvolle Werkzeuge und Techniken, um die einzigartigen thermischen Bedingungen, die in jedem Datenzentrum vorhanden sind, zu verstehen – Bewertung der Temperatur, des Luftflusses und des Druckverhaltens eines Datenzentrums zur Bewertung der Leistung und des Energieverbrauchs mit numerischem Modell. Indem man die Auswirkungen dieser Umweltbedingungen vorhergesagt hat, kann die Analyse des französischen Datenzentrums verwendet werden, um die Auswirkungen von Hochlasten, die mit Niedriglastermitteln kombiniert werden, und die Auswirkungen auf Kühlmittel, schlechte Infrastrukturmanagementpraktiken und AC-Versäumnisse oder AC-Abfall für die planbare Wartung vorherzusagen. Kartierung der Wärmezone Kartierung von Sensoren und Computermodellierung, um ein dreidimensionales Bild der heißen und kühlen Zonen in einem Datenzentrum zu schaffen. Diese Informationen können dazu beitragen, eine optimale Positionierung der Datenzentrum-Ausrüstung zu finden. Beispielsweise könnten kritische Server in einer Kühlzone platziert werden, die von den entlassenen AC-Einheiten bedient wird. Green Datacenter Datacenter verwenden viel Strom, das von zwei Hauptnutzungen verbraucht wird: die benötigte Leistung, um die tatsächliche Ausrüstung durchzuführen, und dann die für die Kühlung der Ausrüstung erforderliche Leistung. Leistungseffizienz verringert die erste Kategorie. Kostensenkungen auf natürliche Weise umfassen Standortentscheidungen: Wenn der Schwerpunkt nicht in der Nähe einer guten Glasfaserverbindung, Stromnetzverbindungen und Personalkonzentrationen zur Verwaltung der Ausrüstung liegt, kann ein Datenzentrum von den Nutzern entfernt werden. Massendatenzentren wie Google oder Facebook müssen nicht in der Nähe von Bevölkerungszentren liegen. Arktis-Standorte können außerhalb der Luft genutzt werden, die Kühlung bietet. Erneuerbare Energiequellen sind ein weiteres Plus. Länder mit günstigen Bedingungen wie Kanada, Finnland, Schweden, Norwegen und die Schweiz versuchen, Cloud-.-Datenzentren anzulocken. Bitcoin Mining wird zunehmend als mögliche Möglichkeit angesehen, Datenzentren auf dem Gebiet der Stromerzeugung aus erneuerbaren Energien aufzubauen. Klügelte Energieträger können genutzt werden, um Transaktionen auf der ELEK zu sichern, die den Erzeugern erneuerbarer Energien einen weiteren Umsatzstrom bieten. Wiederverwendung von Energie Es ist sehr schwierig, die Wärme wieder zu nutzen, die aus luftgekühlten Rechenzentren stammt. Datenzentruminfrastrukturen sind daher häufiger mit Wärmepumpen ausgestattet. Alternative zu Wärmepumpen ist die Annahme von Flüssigkeitskühlung in einem Datenzentrum. Verschiedene flüssige Kühltechniken werden gemischt und kombiniert, um eine vollständig liquide, gekühlte Infrastruktur zu ermöglichen, die alle Wärme in Wasser abdeckt. Verschiedene flüssige Technologien werden in drei Hauptgruppen zusammengefasst, indirekte Flüssigkeitskühlung (Wasserkühlmittel), Direktkühlung (direkt-zu-Chip-kühlung) und Total flüssige Kühlung (unvollständiges Eintauchen in Flüssigkeiten, siehe Server-Einfallkühlung). Diese Kombination von Technologien ermöglicht die Schaffung einer thermischen Kaskade im Rahmen von Temperaturketten-Szenarios zur Erzeugung von Hochtemperaturwasser aus dem Datenzentrum. Dynamische Infrastruktur für dynamische Infrastruktur bietet die Möglichkeit, intelligente, automatisch und sichere Arbeitsbelastungen innerhalb eines Datenzentrums jederzeit überall, für Migrationen, Bereitstellung, Leistungssteigerung oder Kolokation zu schaffen. Es erleichtert auch die routinemäßige Wartung von physischen oder virtuellen Systemenall bei gleichzeitiger Minimierung von Unterbrechungen. Ein verwandtes Konzept ist eine konjunkturierbare Infrastruktur, die eine dynamische Neuausrichtung der verfügbaren Ressourcen ermöglicht, um den Bedürfnissen gerecht zu werden. Nebenleistungen umfassen die Senkung der Kosten für die Kontinuität der Unternehmen und die hohe Verfügbarkeit von Cloud und Grid Computing. Kommunikationsnetze in Datenzentren basieren heute am häufigsten auf Netzen, die die IP-Protokoll-Einheit betreiben. Datenzentren enthalten eine Reihe von Routern und Schaltern, die den Verkehr zwischen den Servern und der Außenwelt, die nach der Netzarchitektur des Datenzentrums miteinander verbunden sind. Redundancy des Internet-Anschlusses wird oft von zwei oder mehr vorgelagerten Diensteanbietern (siehe Multihoming) bereitgestellt. Manche Server im Datenzentrum werden für die Durchführung der grundlegenden Internet- und Intranet-Dienste verwendet, die von internen Nutzern der Organisation benötigt werden, z.B. E-Mail-Server, Benchmark-Servern und DNS-Servern. Netzsicherheitselemente werden in der Regel auch eingesetzt: Firewalls, VPN-Gates, Intrusionserkennungssysteme und so. Auch gemeinsame Überwachungssysteme für das Netz und einige Anwendungen. Zusätzliche Überwachungssysteme vor Ort sind auch im Falle eines Ausfalls der Kommunikation im Datenzentrum typisch. Software/Datensicherung Nicht-mutbare exklusive Optionen für die Datensicherung sind: Onsite Offsite Onsite ist traditionelle, und ein großer Vorteil ist sofortige Verfügbarkeit. Offsite-Schutzdatensicherungstechniken umfassen eine verschlüsselte Kopie der Daten vor Ort. Methoden, die für die Datenbeförderung verwendet werden, sind: wenn der Kunde die Daten an ein physisches Medium, wie Magnetband, schreibt und dann den bürokratischen Aufwand anderswo transportiert. direkte Übermittlung der Daten an eine andere Stelle während der Sicherung unter Verwendung geeigneter Links, um die Daten "in die Cloud"-Datenzentrum einzuladen Manche großen Hardware-Anbieter haben mobile/Modular-Lösungen entwickelt, die in sehr kurzer Zeit installiert und in Betrieb genommen werden können. Siehe auch Hinweise zu externen Links Lawrence Lab - Forschung, Entwicklung, Demonstration und Einsatz energieeffizienter Technologien und Praktiken für Datenzentren DC Power For Data Centers of The Future - FAQ: 380VDC-Test und Demonstration in einem Sun Data Center. Weißbuch - Immobiliensteuern: Die neue Herausforderung für Datenzentren Die Europäische Kommission H2020 EURECA Data Centre Project - Leitlinien für Energieeffizienz im Datenzentrum, umfangreiche Online-Ausbildungsmaterial, Fallstudien/Abbildungen (unter Veranstaltungsseite) und Werkzeuge.