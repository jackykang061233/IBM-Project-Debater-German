In der Informatik und der mathematischen Optimierung ist eine Metaheuristik ein übergeordnetes Verfahren oder Heuristik, das entwickelt wurde, um eine heuristische (Teilsuchalgorithmus) zu finden, zu erzeugen oder auszuwählen, die eine hinreichend gute Lösung für ein Optimierungsproblem bieten kann, insbesondere mit unvollständigen oder unvollkommenen Informationen oder eingeschränkter Rechenkapazität. Metaheuristics Probe eine Untermenge von Lösungen, die sonst zu groß ist, um vollständig aufgezählt oder anderweitig erforscht zu werden. Metaheuristiken können relativ wenige Annahmen über das zu lösende Optimierungsproblem machen und so für verschiedene Probleme nutzbar sein. Im Vergleich zu Optimierungsalgorithmen und iterativen Methoden garantieren Metaheuristiken nicht, dass auf einigen Problemen eine global optimale Lösung gefunden werden kann. Viele Metaheuristiken implementieren eine Form der stochastischen Optimierung, so dass die gefundene Lösung von der Menge der generierten Zufallsvariablen abhängig ist. In der kombinatorischen Optimierung, durch die Suche nach einem großen Satz von durchführbaren Lösungen, können Metaheuristiken oft gute Lösungen mit weniger Rechenaufwand als Optimierungsalgorithmen, iterative Methoden oder einfache Heuristik finden. Als solche sind sie nützliche Ansätze für Optimierungsprobleme. Zu diesem Thema wurden mehrere Bücher und Erhebungspapiere veröffentlicht. Die meisten Literatur über Metaheuristiken sind experimentell in der Natur und beschreiben empirische Ergebnisse basierend auf Computerexperimenten mit den Algorithmen. Aber auch einige formale theoretische Ergebnisse sind verfügbar, oft über Konvergenz und die Möglichkeit, das globale Optimum zu finden. Viele metaheuristische Methoden wurden mit Ansprüchen an Neuheit und praktische Wirksamkeit veröffentlicht. Während der Bereich auch qualitativ hochwertige Forschung, viele der Publikationen waren von schlechter Qualität; Fehler sind Vase, Mangel an konzeptueller Ausarbeitung, schlechte Experimente und Unwissenheit der vorherigen Literatur. Eigenschaften Dies sind Eigenschaften, die die meisten Metaheuristiken charakterisieren: Metaheuristiken sind Strategien, die den Suchprozess führen. Das Ziel ist es, den Suchraum effizient zu erkunden, um nahe-optimale Lösungen zu finden. Techniken, die metaheuristische Algorithmen bilden, reichen von einfachen lokalen Suchvorgängen bis hin zu komplexen Lernprozessen. Metaheuristische Algorithmen sind ungefährlich und in der Regel nicht-deterministisch. Metaheuristiken sind nicht problematisch. Einstufung Es gibt eine Vielzahl von Metaheuristiken und eine Reihe von Eigenschaften, die sie klassifizieren. Lokale Suche vs. globale Suche Ein Ansatz ist, die Art der Suchstrategie zu charakterisieren. Eine Art von Suchstrategie ist eine Verbesserung auf einfachen lokalen Suchalgorithmen. Ein bekannter lokaler Suchalgorithmus ist die Hill-Kletter-Methode, die verwendet wird, um lokale Optimitäten zu finden. Bergsteigen garantiert jedoch nicht, globale optimale Lösungen zu finden. Viele metaheuristische Ideen wurden vorgeschlagen, um die lokale Suche heuristisch zu verbessern, um bessere Lösungen zu finden. Solche Metaheuristiken umfassen simulierte Glühung, Tabusuche, iterierte lokale Suche, variable Nachbarschaftssuche und GRASP. Diese Metaheuristiken können sowohl als lokale Such- oder globale Suchmetaheuristik eingestuft werden. Andere globale Suchmetaheuristik, die nicht lokal auf der Suche basieren, sind in der Regel bevölkerungsbasierte Metaheuristiken. Solche Metaheuristiken umfassen Ameisenkolonie-Optimierung, evolutionäre Berechnung, Partikelschwarm-Optimierung, genetischer Algorithmus und Fahrer-Optimierungsalgorithmus Single-Solution vs. Populationsbasierte Eine weitere Klassifizierungsdimension ist Single-Lösung vs Populationsbasierte Suchanfragen. Einzellösungsansätze konzentrieren sich auf die Modifizierung und Verbesserung einer einzigen Kandidatenlösung; Einzellösung Metaheuristiken umfassen simulierte Glühung, iterierte lokale Suche, variable Nachbarschaftssuche und geführte lokale Suche. Bevölkerungsbasierte Ansätze pflegen und verbessern mehrere Kandidatenlösungen, oft mit Bevölkerungsmerkmalen, um die Suche zu führen; Populationsbasierte Metaheuristiken umfassen evolutionäre Berechnung, genetische Algorithmen und Partikelschwarm-Optimierung. Eine andere Kategorie von Metaheuristiken ist die Swarm-Intelligenz, die ein kollektives Verhalten dezentraler, selbstorganisierter Agenten in einer Bevölkerung oder Schwarm ist. Ameisenkolonie Optimierung, Partikelschwarmoptimierung, soziale kognitive Optimierung sind Beispiele dieser Kategorie. Hybridisierung und memetische Algorithmen Eine hybride Metaheuristik ist eine, die eine Metaheuristik mit anderen Optimierungsansätzen kombiniert, wie Algorithmen aus der mathematischen Programmierung, der konstratierten Programmierung und dem maschinellen Lernen. Beide Komponenten einer hybriden Metaheuristik können gleichzeitig laufen und Informationen austauschen, um die Suche zu führen.Andererseits stellen Memetische Algorithmen die Synergie von evolutionären oder bevölkerungsbasierten Ansatz mit separaten individuellen Lern- oder lokalen Verbesserungsverfahren für die Problemsuche dar. Ein Beispiel für den memetischen Algorithmus ist die Verwendung eines lokalen Suchalgorithmus anstelle eines grundlegenden Mutationsoperators in evolutionären Algorithmen. Parallele Metaheuristiken Eine parallele Metaheuristik ist eine, die die Techniken der parallelen Programmierung verwendet, um mehrere metaheuristische Suchvorgänge parallel durchzuführen; diese können von einfachen verteilten Systemen bis zu gleichzeitigen Suchläufen reichen, die zur Verbesserung der Gesamtlösung interagieren. Naturinspirierte und metaphorische Metaheuristiken Ein sehr aktiver Forschungsbereich ist das Design natur inspirierter Metaheuristiken. Viele neue Metaheuristiken, insbesondere evolutionäre Berechnungsalgorithmen, sind von natürlichen Systemen inspiriert. Natur ist eine Quelle von Konzepten, Mechanismen und Prinzipien für die Gestaltung von künstlichen Rechensystemen, um komplexe Rechenprobleme zu bewältigen. Solche Metaheuristiken umfassen simulierte Glühung, evolutionäre Algorithmen, Ameisenkolonieoptimierung und Partikelschwarmoptimierung. Eine Vielzahl neuer Metapher-inspirierter Metaheuristiken begannen, in der Forschungsgemeinschaft Kritik zu gewinnen, weil sie ihr Mangel an Neuheit hinter einer aufwendigen Metapher versteckten. Für die kombinatorische Optimierung werden Metaheuristiken verwendet, bei denen eine optimale Lösung über einen diskreten Suchraum gesucht wird. Ein Beispiel ist das Problem der Reiseverkäufer, bei dem der Suchraum von Kandidatenlösungen mit zunehmender Größe schneller wächst als exponentiell, was eine erschöpfende Suche nach der optimalen Lösung undurchführbar macht. Darüber hinaus leiden multidimensionale kombinatorische Probleme, darunter die meisten konstruktiven Probleme in der Technik wie Formfindung und Verhaltensfindung, an der Fluktuation der Dimensionalität, die sie auch für erschöpfende Such- oder Analysemethoden unfehlbar macht. Metaheuristiken sind auch weit verbreitet für Jobshop-Scheduling- und Jobauswahlprobleme. Zu den beliebten Metaheuristiken für kombinatorische Probleme gehören simulierte Glühung von Kirkpatrick et al., genetische Algorithmen von Holland et al., Scatter-Suche und Tabu-Suche von Glover. Literaturrezension zur metaheuristischen Optimierung schlug vor, dass es Fred Glover war, der das Wort Metaheuristik geprägt hat. Metaheuristische Optimierungsrahmen (MOFs)A MOF kann als „eine Reihe von Software-Tools definiert werden, die eine korrekte und wiederverwendbare Implementierung einer Reihe von Metaheuristiken und die grundlegenden Mechanismen zur Beschleunigung der Implementierung ihrer Partner-untergeordneten Heuristiken (möglicherweise einschließlich Lösungscodierungen und technikspezifische Operatoren) bereitstellen, die zur Lösung einer bestimmten Probleminstanz mit bereitgestellten Techniken erforderlich sind“. Es gibt viele Kandidaten-Optimierungs-Tools, die als MOF von verschiedenen Funktionen betrachtet werden können: Komet, EvA2, evolvica, Evolution::Algorithm, GAPlayground, jaga, JCLEC, JGAP, jMetal, n-genes, Open Beagle, Opt4j, ParadisEO/EO, Pisa, Watchmaker, FOM, Hypercube, HotFrame, Templar, EasyLocal, iOpt, OptQuest, JDEAL, Optimization Algorithm Toolkit, HeurIB Viele verschiedene Metaheuristiken sind vorhanden und neue Varianten werden laufend vorgeschlagen. Einige der wichtigsten Beiträge zu diesem Bereich sind: 1952: Robbins und Monro arbeiten an stochastischen Optimierungsmethoden. 1954:Barricelli führt die ersten Simulationen des Evolutionsprozesses durch und nutzt diese bei allgemeinen Optimierungsproblemen. 1963:Rastrigin schlägt zufällige Suche vor. 1965:Matyas schlägt eine zufällige Optimierung vor.1965:Nelder und Mead schlagen eine simplex heuristic, die von Powell gezeigt wurde, um zu nicht-stationären Punkten auf einige Probleme zu konvergieren.1965:Ingo Rechenberg entdeckt den ersten Evolutionsstrategien-Algorithmus.1966:Fogel et al.propose evolutionäre Programmierung. 1970:Hastings schlägt den Metropolis-Hastings-Algorithmus vor.1970:Cavicchio schlägt die Anpassung der Steuerparameter für einen Optimierer vor. 1970:Kernighan und Lin schlagen eine Graphen-Partitioning-Methode vor, die mit einer veränderlichen Suche und einer Verbots-basierten (tabu) Suche zusammenhängt. 1975:Holland schlägt den genetischen Algorithmus.1977:Glover schlägt Streusuche vor. 1978:Mercer und Sampson schlagen ein Metaplan zur Abstimmung der Parameter eines Optimierers unter Verwendung eines anderen Optimierers vor.1980:Smith beschreibt die genetische Programmierung. 1983:Kirkpatrick et al.propose simulierte Glühung.1986:Glover schlägt tabusuche vor, erste Erwähnung des Begriffs metaheuristic.1989:Moscato schlägt memetische Algorithmen vor.1990: Moscato und Fontanari und Dueck und Scheuer schlugen unabhängig voneinander eine deterministische Aktualisierungsregel zur simulierten Glühung vor, die die Suche beschleunigte. Dies führte zu der Schwelle, die metaheuristisch akzeptierte. 1992:Dorigo führt ant Kolonie Optimierung in seiner Doktorarbeit ein. 1995:Wolpert und Macready beweisen die kein kostenloses Mittagessen Theorems. Siehe auch Stochastic search Meta-optimization Matheuristics Hyper-heuristics Swarm Intelligence Genetische Algorithmen Simulierte Glühung Workforce Modeling ReferencesWeiter lesen Sörensen, Kenneth; Sevaux, Marc; Glover, Fred (2017-01-16)."A History of Metaheuristics" (PDF.) In Martí, Rafael; Panos, Pardalos; Resende, Mauricio (Hrsg.). Handbuch der Heuristik.Springer.ISBN 978-3-319-07123-7. Externe Links Fred Glover und Kenneth Sörensen (Hg.)."Metaheuristics". Scholarpedia.EU/ME Forum für Forscher auf dem Gebiet.