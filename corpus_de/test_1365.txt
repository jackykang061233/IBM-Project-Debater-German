Das World Wide Web (WWW oder "The Web") ist ein globales Informationsmedium, auf das Benutzer über Computer zugreifen können, die mit dem Internet verbunden sind. Der Begriff wird oft irrtümlich als Synonym für das Internet selbst verwendet, aber das Web ist ein Dienst, der über das Internet arbeitet, wie E-Mail und Usenet auch tun. Die Geschichte des Internets geht deutlich weiter als die des World Wide Web. Vorläufer Der Hypertextanteil des Internets hat insbesondere eine komplizierte geistige Geschichte; bemerkenswerte Einflüsse und Vorläufer sind Vannevar Bushs Memex, IBMs Generalized Markup Language und Ted Nelsons Projekt Xanadu. Das Mundaneum-Projekt von Paul Otlet wurde auch als Vorläufer des Webs aus dem frühen 20. Jahrhundert benannt. Das Konzept eines globalen Informationssystems, das Häuser verbindet, ist in "A Logic Named Joe", einer Kurzgeschichte von Murray Leinster von 1946, in der Computerterminals, sogenannte Logiken, in jedem Zuhause vorhanden sind. Obwohl das Computersystem in der Geschichte zentralisiert ist, erwartet die Geschichte eine allgegenwärtige Informationsumgebung ähnlich dem Web. Die kulturellen Auswirkungen des Webs wurden in einer kurzen Geschichte von E. M. Forster, "The Machine Stops", die 1909 veröffentlicht wurde, noch weiter vorgestellt. 1980-1991: Erfindung und Umsetzung Im Jahr 1980, Tim Berners-Lee, ein englischer unabhängiger Auftragnehmer der Europäischen Organisation für Kernforschung (CERN) in der Schweiz, baute ENQUIRE als persönliche Datenbank von Menschen und Software-Modellen, aber auch als Möglichkeit, mit Hypertext zu spielen; jede neue Seite von Informationen in ENQUIRE musste mit einer Seite verknüpft werden. Berners-Lees Vertrag von 1980 war von Juni bis Dezember, aber 1984 kehrte er in einer ständigen Rolle an CERN zurück und betrachtete seine Probleme des Informationsmanagements: Physiker aus der ganzen Welt benötigt, um Daten zu teilen, aber sie fehlten an gemeinsamen Maschinen und jeder gemeinsamen Präsentationssoftware. Kurz nach der Rückkehr von Berners-Lee zum CERN wurden TCP/IP-Protokolle auf einigen Key-Non-Unix-Maschinen an der Institution installiert und in wenigen Jahren in die größte Internet-Site Europas verwandelt. Damit war die Infrastruktur des CERN für Berners-Lee bereit, das Web zu erstellen.Berners-Lee schrieb im März 1989 einen Vorschlag für "eine große Hypertext-Datenbank mit eingegebenen Links". Obwohl der Vorschlag wenig Interesse an sich zog, wurde Berners-Lee von seinem Chef, Mike Sendall, ermutigt, sein System auf einem neu erworbenen NeXT-Workstation zu implementieren. Er betrachtete mehrere Namen, darunter Information Mesh, The Information Mine oder Mine of Information, ließ sich aber im World Wide Web nieder. Berners-Lee und Cailliau haben im September 1990 Berners-Lees Ideen auf die Europäische Konferenz über Hypertexttechnologie gedrängt, fanden aber keine Anbieter, die seine Vision schätzen konnten, Hypertext mit dem Internet zu heiraten. Bis Weihnachten 1990 hatte Berners-Lee alle für ein funktionierendes Web erforderlichen Tools aufgebaut: das HyperText Transfer Protocol (HTTP), die HyperText Markup Language (HTML), den ersten Webbrowser (Name WorldWideWeb, auch Web-Editor), die erste HTTP-Server-Software (später CERN httpd), den ersten Webserver (http://info.cern.ch) und die ersten Webseiten, die das Projekt selbst beschreiben. Der Browser konnte auch auf Usenet-Newsgroups und FTP-Dateien zugreifen. Es konnte jedoch nur auf dem NeXT laufen; Nicola Pellow hat deshalb einen einfachen Textbrowser erstellt, der als Zeilenmodusbrowser bezeichnet wird, der auf fast jedem Computer laufen könnte. Um den Einsatz innerhalb des CERN zu fördern, legte Bernd Pollermann das CERN-Telefonverzeichnis im Internet – früher mussten sich die Benutzer auf den Mainframe anmelden, um Telefonnummern zu sehen. Berners-Lee verbrachte während der Erfinderschaft und der Arbeit an der Einrichtung des Internets den größten Teil seiner Arbeitszeit im Gebäude 31 (zweite Etage) am CERN (46.2325°N 6.0450°E / 46.2325; 6.0450 (CERN Building 31, Geburtsort des World Wide Web), aber auch in seinen beiden Häusern, eines in Frankreich, eines in der Schweiz. Im Januar 1991 wurden die ersten Webserver außerhalb des CERN selbst eingeschaltet. Die erste Seite kann verloren gehen, aber Paul Jones von UNC-Chapel Hill in North Carolina hat im Mai 2013 gezeigt, dass er eine Kopie einer Seite, die ihm 1991 von Berners-Lee gesendet wurde, die die älteste bekannte Webseite ist. Jones hat die Klartext-Seite mit Hyperlinks, auf einer Diskette und auf seinem NeXT-Computer gespeichert. CERN legte die älteste bekannte Web-Seite im Jahr 2014 online, komplett mit Hyperlinks, die den Benutzern geholfen haben, zu starten und half ihnen navigieren, was dann ein sehr kleines Web war. 1991–1995: Das Internet geht öffentlich, frühes Wachstum Am 6. August 1991 veröffentlichte Berners-Lee eine kurze Zusammenfassung des World Wide Web-Projekts auf der alt.hypertext-Newsgroup, die Mitarbeiter einladen. Dieses Datum ist manchmal mit der öffentlichen Verfügbarkeit der ersten Webserver verwechselt, die Monate zuvor aufgetreten waren. Paul Kunz vom Stanford Linear Accelerator Center (SLAC) besuchte im September 1991 das CERN und wurde vom Web begeistert. Er brachte die NeXT-Software zurück zu SLAC, wo librarian Louise Addis sie für das VM/CMS Betriebssystem auf dem IBM Mainframe als eine Möglichkeit zur Darstellung des SLAC-Katalogs von Online-Dokumenten angepasst hat; dies war der erste Webserver außerhalb Europas und der erste in Nordamerika. Die www-talk Mailing-Liste wurde im selben Monat gestartet. 1992 unterstützte die Computing and Networking Department of CERN unter der Leitung von David Williams Berners-Lees Arbeit nicht. Eine zweiseitige E-Mail von Williams erklärte, dass die Arbeit von Berners-Lee, mit dem Ziel, eine Einrichtung zum Austausch von Informationen wie Ergebnisse und Kommentare von CERN-Experimenten an die wissenschaftliche Gemeinschaft zu schaffen, war nicht die Kernaktivität von CERN und war eine Fehlallokation von CERN IT-Ressourcen. Nach dieser Entscheidung verließ Tim Berners-Lee CERN trotz vieler seiner Kollegen im IT-Zentrum, die sich für seine Unterstützung, insbesondere M. Ben Segal aus dem verteilten SHIFT-Projekt befürworteten. Er verließ das Massachusetts Institute of Technology (MIT), wo er HTTP weiter entwickelte. Ein früher CERN-bezogener Beitrag zum Web war die Parodie-Band Les Horribles Cernettes, deren Werbebild zu den ersten fünf Bildern des Web gehört. Das Foto wurde als GIF-Datei mit Adobe Photoshop auf einem Macintosh gescannt. Im Einklang mit seiner Geburt am CERN und der ersten Seite wurden frühe Adopter des Internets in erster Linie universitäre wissenschaftliche Abteilungen oder Physiklabore wie Fermilab und SLAC. Bis Januar 1993 gab es weltweit fünfzig Webserver. Im April 1993 veröffentlichte CERN eine offizielle Erklärung und machte das World Wide Web lizenzfrei zur Verfügung. Bis Oktober 1993 waren über fünfhundert Server online. Zwei der frühesten Webcomics begannen 1993 im World Wide Web:Doctor Fun und NetBoy. Im Juli 1993 veröffentlichte die Wharton School eine der ersten Sammlungen von PDFs und wurde in Adobes Jahresbericht 1995 über die Verwendung von PDFs im Internet hervorgehoben. Frühe Webseiten, die Links sowohl für das HTTP-Webprotokoll als auch für das dann-populäre Gopher-Protokoll, die Zugriff auf Inhalte durch Hypertext-Menüs, die als Dateisystem dargestellt wurden, statt durch HTML-Dateien. Früh Web-Nutzer navigieren entweder durch Bookmarking populären Verzeichnis-Seiten, wie Berners-Lees erste Website unter http://info.cern.ch, oder durch Beratung aktualisierte Listen wie die NCSA "What's New" Seite. Einige Seiten wurden auch von WAIS indexiert, so dass Benutzer Volltextsuche ähnlich der Fähigkeit, die später von Suchmaschinen zur Verfügung gestellt. Praktische Medienverteilung und Streaming-Medien über das Web wurden durch Fortschritte in der Datenkompression ermöglicht, aufgrund der unpräzise hohen Bandbreitenanforderungen unkomprimierter Medien. Eine wichtige Kompressionstechnik in dieser Hinsicht ist die diskrete Cosin-Transformation (DCT), ein verlustiger Kompressionsalgorithmus, der ursprünglich von Nasir Ahmed, T. Natarajan und K. R. Rao an der University of Texas 1973 entwickelt wurde. Nach der Einführung des Internets wurden mehrere DCT-basierte Medienformate für die praktische Medienverteilung und das Streaming über das Internet eingeführt, einschließlich des MPEG-Videoformats 1991 und des JPEG-Bildformats 1992. Das hohe Niveau der Bildkompression machte JPEG ein gutes Format, um langsame Internet-Zugangsgeschwindigkeiten zu kompensieren, typisch im Alter der Anwahlverbindungen. JPEG wurde das am weitesten verbreitete Bildformat für das World Wide Web.Eine DCT-Variation, der modifizierte diskrete Cosine-Transformations-Algorithmus, entwickelt von J. P. Princen, A. W. Johnson und A. B. Bradley an der University of Surrey 1987, führte zur Entwicklung von MP3, die 1994 eingeführt wurde und wurde das erste beliebte Audioformat im Web. Das Web startete 1993 bis 1994 in den Alltag. Bis Ende 1994 war die Gesamtzahl der Webseiten im Vergleich zu den aktuellen Zahlen noch kurz, aber eine ganze Reihe von bemerkenswerten Websites waren bereits aktiv, von denen viele die Vorläufer sind oder inspirierende Beispiele der heutigen beliebtesten Dienste sind. Im Januar 1994 wurde Yahoo! von Jerry Yang und David Filo gegründet, dann Studenten an der Stanford University. Yahoo!Directory, gestartet im Januar 1994, wurde das erste beliebte Web-Verzeichnis. Yahoo!Search, später 1995 gestartet, wurde die erste beliebte Suchmaschine im World Wide Web. Yahoo! wurde zum Quintessenzbeispiel eines ersten Movers im Web. Web-Commerce begann auch 1995 mit der Gründung von eBay von Pierre Omidyar und Amazon von Jeff Bezos. Frühe Browser Zunächst war ein Webbrowser nur für das NeXT Betriebssystem verfügbar. Dieser Mangel wurde im Januar 1992 diskutiert und im April 1992 durch die Veröffentlichung von Erwise, einer an der Technischen Universität Helsinki entwickelten Anwendung, und im Mai von ViolaWW, erstellt von Pei-Yuan Wei, die erweiterte Funktionen wie Embedded Graphics, Skripting und Animation umfasste. ViolaWWWW war ursprünglich eine Anwendung für HyperCard. Beide Programme liefen auf dem X Window System für Unix. 1992 wurden die ersten Tests zwischen Browsern auf verschiedenen Plattformen erfolgreich zwischen Gebäuden 513 und 31 in CERN, zwischen Browsern auf der NexT-Station und dem X11-portierten Mosaic-Browser abgeschlossen. Studierende der Universität Kansas haben einen vorhandenen Text-nur Hypertext-Browser, Lynx, angepasst, um auf das Internet zuzugreifen. Lynx war auf Unix und DOS verfügbar, und einige Web-Designer, unbeeindruckt mit glänzenden grafischen Webseiten, hielten, dass eine Website, die nicht über Lynx zugänglich war nicht Besuch wert. Der erste Microsoft Windows-Browser war Cello, geschrieben von Thomas R. Bruce für das Legal Information Institute an der Cornell Law School, um rechtliche Informationen zu liefern, da der Zugriff auf Windows unter Anwälten weit verbreiteter war als der Zugang zu Unix. Cello wurde im Juni 1993 veröffentlicht. Das Web wurde erstmals von Mosaic, einem grafischen Browser, der 1993 von Marc Andreessens Team am National Center for Supercomputing Applications (NCSA) an der Universität Illinois in Urbana-Champaign (UIUC) gestartet wurde, populär gemacht. Die Ursprünge von Mosaic reichen bis 1992. Im November 1992 hat die NCSA an der Universität Illinois (UIUC) eine Website eingerichtet. Im Dezember 1992 begannen Andreessen und Eric Bina, Studierende der UIUC und der NCSA, mit der Finanzierung der High-Performance Computing and Communications Initiative, einem Forschungs- und Entwicklungsprogramm der US-Bundesstaaten, Mosaic. Andreessen und Bina veröffentlichten eine Unix-Version des Browsers im Februar 1993; Mac- und Windows-Versionen folgten im August 1993. Der Browser gewann Popularität aufgrund seiner starken Unterstützung von integrierten Multimedia, und die Autoren schnelle Antwort auf Benutzer Bug Berichte und Empfehlungen für neue Funktionen. Nach dem Abschluss von UIUC trafen sich Andreessen und James H. Clark, ehemaliger CEO von Silicon Graphics, im April 1994 die Mosaic Communications Corporation, um den Browser Mosaic Netscape kommerziell zu entwickeln. Das Unternehmen änderte später seinen Namen in Netscape, und der Browser wurde weiter als Netscape Navigator entwickelt. Web Governance Im Mai 1994 fand auf der CERN die erste Internationale WWW-Konferenz, organisiert von Robert Cailliau, statt, die seit jedem Jahr stattfindet. Im April 1993 hatte CERN vereinbart, dass jeder das Web-Protokoll nutzen und lizenzfrei kodieren könnte; dies war zum Teil eine Reaktion auf die Besorgnis der Universität von Minnesota, die bekannt gab, dass es beginnen würde, Lizenzgebühren für die Umsetzung des Gopher-Protokolls zu berechnen. Im September 1994 gründete Berners-Lee das World Wide Web Consortium (W3C) am Massachusetts Institute of Technology mit Unterstützung der Defense Advanced Research Projects Agency (DARPA) und der Europäischen Kommission. Es umfasste verschiedene Unternehmen, die bereit waren, Standards und Empfehlungen zu schaffen, um die Qualität des Web zu verbessern.Berners-Lee machte das Web frei, ohne Patent und keine Lizenzgebühren. Der W3C entschied, dass seine Standards auf lizenzfreie Technologie basieren müssen, so dass sie leicht von jedem übernommen werden können. 1995–2004: Commercialization, dot-com boom and bust, aftermath Mit der Veröffentlichung von Windows 95 und dem beliebten Internet Explorer Browser wurde es für die meisten öffentlich gehandelten Unternehmen offensichtlich, dass eine öffentliche Web-Präsenz nicht mehr optional war. Obwohl zunächst die Menschen vor allem die Möglichkeiten der kostenlosen Veröffentlichung und sofortigen weltweiten Informationen sahen, führte die zunehmende Vertrautheit mit der Zwei-Wege-Kommunikation über das Internet zu der Möglichkeit des direkten Web-basierten Handels (E-Commerce) und der momentanen Gruppenkommunikation weltweit. Weitere Dotcoms, die Produkte auf Hypertext-Webseiten anzeigen, wurden im Web hinzugefügt. Im Jahr 1996 entwickelte Robin Li RankDex, die erste Web-Suchmaschine mit einem Site-Scoring-Algorithmus für das Ergebnisseiten-Ranking und erhielt ein US-Patent für die Technologie. Es war die erste Suchmaschine, die Hyperlinks verwendet, um die Qualität der Websites, die es Indexing war, zu messen, predating das ähnliche PageRank Algorithmus Patent später von Google eingereicht. Li nutzte später seine Rankdex-Technologie für die Baidu-Suchmaschine, die Li im Jahr 2000 gegründet und gestartet hat. Google Search, die für seinen PageRank-Algorithmus bemerkenswert war, wurde von Larry Page, Sergey Brin und Scott Hassan zwischen 1996 und 1997 entwickelt. Seite referenziert Lis Arbeit an RankDex in einigen seiner US-Patente für PageRank. Google wurde schließlich 1998 von Page und Brin gegründet. Niedrige Zinssätze 1998-1999 erleichterten einen Anstieg der Start-up-Unternehmen. Obwohl einige dieser neuen Unternehmer realistische Pläne und administrative Fähigkeiten hatten, fehlten die meisten dieser Merkmale, konnten aber ihre Ideen an Investoren verkaufen, weil die Neuheit des dot-com-Konzepts. Historisch gesehen ist der Punkt-Com-Boom ähnlich wie eine Reihe von anderen technologie-inspirierten Booms der Vergangenheit einschließlich Eisenbahnen in den 1840er Jahren, Automobile im frühen 20. Jahrhundert, Radio in den 1920er Jahren, Fernsehen in den 1940er Jahren, Transistorelektronik in den 1950er Jahren, Computer-Zeit-Sharing in den 1960er Jahren, Heimcomputer und Biotechnologie in den 1980er Jahren. Im Jahr 2000, die Punkt-com-Bubble Burst, und viele Dot-com-Starts gingen aus dem Geschäft nach dem Brennen durch ihr Venture-Kapital und nicht profitabel zu werden. Viele andere aber haben im frühen 21. Jahrhundert überlebt und gedeiht. Viele Unternehmen, die als Online-Händler begannen blühten und wurde sehr profitabel. Mehr konventionelle Einzelhändler fanden Online-Meerhandising zu einer profitablen zusätzlichen Umsatzquelle. Während einige Online-Entertainment-und Nachrichten-Outlets scheiterten, als ihre Saatgut-Kapital ausgelaufen, andere blieben bestehen und schließlich wurde wirtschaftlich selbstständig. Traditionelle Medienauslässe (insbesondere Zeitungsverleger, Broadcaster und Kabelveranstalter) fanden auch das Web als nützlicher und profitabler Zusatzkanal für den Content-Vertrieb und als zusätzliche Mittel zur Erzeugung von Werbeeinnahmen. Die Standorte, die nach dem Blasenplatz überlebt und schließlich gedeihen, hatten zwei Dinge gemeinsam: ein solider Geschäftsplan und eine Nische auf dem Marktplatz, die, wenn nicht einmalig, besonders gut definiert und gepflegt war. In der akademischen und wissenschaftlichen Gemeinschaft katalysierten Web-Entwicklungen in den 1990er Jahren die Transformation von bibliographischen Indexen in bibliographische Datenbanken, von denen viele zu digitalen Bibliotheken entwickelt wurden. Im Anschluss an die Dot-com-Blase hatten Telekommunikationsunternehmen eine große Überkapazität, da viele Internet-Business-Kunden vollzogen. Das, plus laufende Investitionen in lokale Zellinfrastruktur blieb Konnektivität Gebühren niedrig, half, High-Speed-Internet-Konnektivität erschwinglicher zu machen. Während dieser Zeit hat eine Handvoll Unternehmen Erfolge bei der Entwicklung von Geschäftsmodellen gefunden, die dazu beigetragen haben, das World Wide Web zu einem überzeugenderen Erlebnis zu machen. Dazu gehören Airline-Buchungs-Websites, Googles Suchmaschine und sein profitabler Ansatz für Keyword-basierte Werbung, sowie eBays Auktions-Website und Amazon.com Online-Geschäft. 2005–präsent: Ubiquity und Web 2.0 Bis Mitte der 2000er Jahre haben sich neue Ideen für den Austausch und den Austausch von Inhalten ad hoc, wie z.B. Weblogs und RSS, im Web rasch angenommen. Dieses neue Modell für den Informationsaustausch, vor allem mit benutzergenerierten und benutzergestützten Webseiten, wurde Web 2.0 (ein Begriff, der 1999 geprägt und 2004 populär wurde, der einen Platz im englischen Lexikon gefunden hat) gegraben. Der Web 2.0-Boom sah viele neue service-orientierte Startups Catering zu einem neu demokratisierten Web. Diese neue Ära hat auch Social Networking-Websites wie Friendster, MySpace, Facebook und Twitter vergessen, die schnell Akzeptanz erlangten und zum zentralen Teil der Jugendkultur wurde. Die 2010er sahen auch die Entstehung verschiedener kontroverser Trends, wie die Expansion von Cyberkriminalität und der Internetzensur. Da das Web einfacher zu abfragen wurde, erreichte es eine größere Benutzerfreundlichkeit insgesamt und erlangte ein Gefühl der Organisation, die in einer Periode der schnellen Popularisierung verwendet. Viele neue Websites wie Wikipedia und ihre Schwesterprojekte der Wikimedia Foundation basieren auf dem Konzept der benutzerbezogenen Inhalte. Im Jahr 2005 haben drei ehemalige PayPal-Mitarbeiter, Steve Chen, Chad Hurley und Jawed Karim, eine Video-View-Website namens YouTube erstellt, die schnell populär wurde und ein neues Konzept von benutzergestützten Inhalten in großen Veranstaltungen eingeführt. Die Popularität von YouTube, Facebook, etc., kombiniert mit der zunehmenden Verfügbarkeit und Erreichbarkeit von High-Speed-Verbindungen hat Videoinhalte weit verbreiteter auf allen Arten von Websites gemacht. Viele Video-Content-Hosting- und Kreation-Websites bieten ein einfaches Mittel, um ihre Videos ohne Bezahlung oder Erlaubnis auf Websites Dritter einzubetten. Diese Kombination aus mehr benutzerdefinierten oder bearbeiteten Inhalten und einfachen Mitteln zum Teilen von Inhalten, wie z.B. über RSS Widgets und Videoeinbettung, hat zu vielen Seiten mit einem typischen "Web 2.0"-Feeling geführt. Sie haben Artikel mit eingebettetem Video, benutzerdefinierte Kommentare unter dem Artikel und RSS-Boxen auf der Seite, einige der neuesten Artikel von anderen Seiten. Die weitere Erweiterung des Internets hat sich auf die Verbindung von Geräten mit dem Internet konzentriert, geprägt Intelligent Device Management. Da Internet-Konnektivität ubiquit wird, haben die Hersteller begonnen, die erweiterte Rechenleistung ihrer Geräte zu nutzen, um ihre Usability und Fähigkeit zu verbessern. Durch die Internet-Konnektivität sind Hersteller nun in der Lage, mit den Geräten, die sie verkauft und an ihre Kunden versendet haben, zu interagieren, und Kunden können mit dem Hersteller (und anderen Anbietern) interagieren, um auf viele neue Inhalte zuzugreifen. Siehe auch Hypermedia Linked Data Computer Lib/Dream Machines Geschichte der Hypertext Geschichte der Internetgeschichte des Webbrowsers Geschichte der Web-Syndikationstechnologie Liste der vor 1995 gegründeten Webseiten Hinweise Weiter lesen Brügger, Niels, ed, Web25: Historien aus den ersten 25 Jahren des World Wide Web (Peter Lang, 2017.) Externe Links Die erste Website Bemer, Bob, "A History of Source Concepts for the Internet/Web" Das World Wide Web History Project Wichtige Ereignisse in der Geschichte des World Wide Web "Principal Figures in the Development of the Internet and the World Wide Web". University of North Carolina. Archiviert aus dem Original am 7. Mai 2006. Retrieved 3. Juli 2006."How It All Started" (Schiebe), Tim Berners-Lee, W3C, Dezember 2004 "Eine kleine Geschichte des World Wide Web: von 1945 bis 1995", Dan Connolly, W3C, 2000 "The World Wide Web: Vergangenheit, Gegenwart und Zukunft", Tim Berners-Lee, August 1996 Internetgeschichte, ComputergeschichteMuseumMuZero ist ein Computerprogramm, das vom Forschungsunternehmen DeepMind entwickelt wurde, um Spiele zu meistern, ohne ihre Regeln zu kennen. Seine Veröffentlichung im Jahr 2019 beinhaltete Benchmarks seiner Performance in Go, Schach, Shigi und eine Standard-Suite von Atari-Spielen. Der Algorithmus verwendet einen Ansatz ähnlich AlphaZero. Es passte AlphaZeros Performance in Schach und Shigi, verbesserte sich auf seine Performance in Go (eine neue Weltrekord) und verbesserte sich auf dem Stand der Technik bei der Meisterung einer Suite von 57 Atari-Spielen (die Arcade Learning Environment), einer visuell-komplexen Domäne. MuZero wurde über Selbstspiel ausgebildet, ohne Zugriff auf Regeln, Eröffnung von Büchern oder Endspiel-Tabellen. Der ausgebildete Algorithmus verwendet die gleichen Faltungs- und Restalgorithmen wie AlphaZero, aber mit 20% weniger Berechnungsschritte pro Knoten in der Suchstruktur. Geschichte MuZero entdeckt wirklich für sich, wie man ein Modell baut und es nur von ersten Prinzipien versteht. Am 19. November 2019 veröffentlichte das DeepMind Team einen Vordruck mit MuZero. Die Ableitung von AlphaZero MuZero (MZ) ist eine Kombination aus der leistungsfähigen Planung des AlphaZero (AZ) Algorithmus mit Ansätzen zum modellfreien Verstärkungslernen. Die Kombination ermöglicht ein effizienteres Training in klassischen Planungsregime, wie Go, während auch Domains mit viel komplexeren Inputs auf jeder Stufe, wie visuelle Videospiele, behandelt werden. MuZero wurde direkt von AZ-Code abgeleitet und teilte seine Regeln für die Einstellung von Hyperparametern. Unterschiede zwischen den Ansätzen umfassen: Der Planungsprozess von AZ verwendet einen Simulator. Der Simulator kennt die Regeln des Spiels. Es muss explizit programmiert werden. Ein neuronales Netz prognostiziert dann die Politik und den Wert einer zukünftigen Position. Die perfekte Kenntnis der Spielregeln wird bei der Modellierung von Zustandsübergängen im Suchbaum, an jedem Knoten verfügbaren Aktionen und der Beendigung eines Zweiges des Baumes verwendet. MZ hat keinen Zugang zu den Regeln und lernt stattdessen eines mit neuronalen Netzwerken. AZ hat ein einziges Modell für das Spiel (vom Board-Zustand bis zu Vorhersagen); MZ hat separate Modelle für die Darstellung des aktuellen Zustands (vom Board-Zustand in seine interne Einbettung), Dynamik von Zuständen (wie Aktionen Repräsentationen von Board-Zuständen ändern), und Vorhersage von Politik und Wert einer zukünftigen Position (bei der Darstellung eines Staates). Das versteckte Modell von MZ kann komplex sein, und es kann sich herausstellen, dass es Berechnungen durchführen kann; die Erkundung der Details des versteckten Modells in einer geschulten Instanz von MZ ist ein Thema für zukünftige Explorationen. MZ erwartet kein Zweispieler-Spiel, in dem die Gewinner alles nehmen. Es funktioniert mit Standard-Verstärkungs-Learning-Szenarien, einschließlich ein-agent Umgebungen mit kontinuierlichen Zwischenbelohnungen, möglicherweise beliebiger Größe und mit Zeitvergünstigung. AZ wurde für Zweispielerspiele entwickelt, die gewonnen, gezogen oder verloren werden konnten. Vergleich mit R2D2 Der bisherige Stand der Technik zum Lernen, die Suite der Atari-Spiele zu spielen, war R2D2, das Recurrent Replay Distributed DQN. MuZero übertraf sowohl R2D2 die mittlere und mediane Leistung über die Suite der Spiele, obwohl es nicht besser in jedem Spiel. Training und Ergebnisse MuZero verwendet 16 Tensor-Prozesseinheiten der dritten Generation (TPUs) für Training, und 1000 TPUs für Selfplay für Brettspiele, mit 800 Simulationen pro Schritt und 8 TPUs für Training und 32 TPUs für Selfplay für Atari-Spiele, mit 50 Simulationen pro Schritt. AlphaZero verwendete 64 TPU der ersten Generation für das Training und 5000 TPU der zweiten Generation für das Selbstspiel. Da sich das TPU-Design verbessert hat (die Chips der dritten Generation sind 2x so leistungsstark einzeln als Chips der zweiten Generation, mit weiteren Fortschritten in der Bandbreite und Vernetzung über Chips in einem Pod), sind dies vergleichbare Trainings-Setups. R2D2 wurde 5 Tage lang durch 2M Trainingsschritte trainiert. Erste Ergebnisse MuZero entsprach AlphaZeros Performance in Schach und Shogi nach rund 1 Million Trainingsschritten. Nach 500 Tausend Trainingsschritten hat AZ seine Leistung in Go übertroffen und um 1 Million Stufen übertroffen. Es passte R2D2s mittlere und mediane Leistung über die Atari-Spielsuite nach 500 Tausend Trainingsschritten und übertraf es um 1 Million Schritte, obwohl es nie gut auf 6 Spiele in der Suite durchgeführt. Reaktionen und verwandte Arbeit MuZero wurde als eine signifikante Weiterentwicklung über AlphaZero angesehen, und ein allgemeiner Schritt nach vorn in unübertroffenen Lerntechniken. Die Arbeit wurde als fortschreitendes Verständnis für die Zusammenstellung von Systemen aus kleineren Komponenten gesehen, eine System-Level-Entwicklung mehr als eine reine maschinelle Lernentwicklung. Während nur Pseudocode vom Entwicklungsteam veröffentlicht wurde, produzierte Werner Duvaud eine Open Source-Implementierung. MuZero wurde als Referenz-Implementierung in anderen Arbeiten verwendet, beispielsweise als Möglichkeit, modellbasiertes Verhalten zu erzeugen. Siehe auch General Spiel spielen ReBeL, Facebook allgemeine Spiel-Spieler, die zusätzlich behandelt Poker Unsupervised Learning Referenzen Externe Links Initial MuZero Vordruck. Open Source Implementierungen