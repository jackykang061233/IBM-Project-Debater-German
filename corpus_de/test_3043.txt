In der Statistik und beim maschinellen Lernen verwenden Ensemble-Methoden mehrere Lernalgorithmen, um eine bessere Vorhersageleistung zu erzielen, als sie allein von einem der konstituierenden Lernalgorithmen erhalten werden könnten. Im Gegensatz zu einem statistischen Ensemble in der statistischen Mechanik, das in der Regel unendlich ist, besteht ein Machine Learning-Ensemble nur aus einem konkreten endlichen Satz von alternativen Modellen, ermöglicht aber in der Regel eine viel flexiblere Struktur unter diesen Alternativen zu existieren. Übergeordnete Lernalgorithmen führen die Aufgabe durch einen Hypothesenraum, um eine geeignete Hypothese zu finden, die gute Vorhersagen mit einem bestimmten Problem machen wird. Selbst wenn der Hypothesenraum Hypothesen enthält, die für ein bestimmtes Problem sehr gut geeignet sind, kann es sehr schwierig sein, ein gutes zu finden. Ensembles kombinieren mehrere Hypothesen zu einer (hoffentlich) besseren Hypothese. Der Begriff Ensemble ist in der Regel für Methoden reserviert, die mehrere Hypothesen mit demselben Basislerner erzeugen. Der breitere Begriff mehrerer Klassifikatorsysteme umfasst auch die Hybridisierung von Hypothesen, die nicht von demselben Basislerner induziert werden. Die Bewertung der Vorhersage eines Ensembles erfordert in der Regel mehr Berechnung als die Bewertung der Vorhersage eines einzelnen Modells. In einem Sinne kann das Ensemble-Lernen als eine Möglichkeit betrachtet werden, schlechte Lernalgorithmen zu kompensieren, indem eine Menge zusätzliche Berechnung durchgeführt wird. Andererseits besteht die Alternative darin, auf einem nicht montierten System viel mehr zu lernen. Ein Ensemble-System kann effizienter sein, um die Gesamtgenauigkeit für die gleiche Erhöhung der Rechen-, Speicher- oder Kommunikationsressourcen zu verbessern, indem diese Erhöhung auf zwei oder mehr Methoden verwendet wird, als durch eine Erhöhung der Ressourcennutzung für eine einzige Methode verbessert worden wäre. Schnelle Algorithmen wie Entscheidungsbäume werden häufig in Ensemblemethoden (z.B. zufällige Wälder) verwendet, obwohl auch langsamere Algorithmen von Ensembletechniken profitieren können. Analog wurden auch Ensembletechniken in unübertroffenen Lernszenarien eingesetzt, beispielsweise im Konsens-Clustering oder in der Anomalie-Erkennung. Musiktheorie Empirisch neigen Ensembles zu besseren Ergebnissen, wenn es eine signifikante Vielfalt unter den Modellen gibt. Viele Ensemble-Methoden versuchen daher, Vielfalt unter den Modellen zu fördern, die sie kombinieren. Obwohl vielleicht nicht-intuitive, mehr zufällige Algorithmen (wie zufällige Entscheidungsbäume) verwendet werden können, um ein stärkeres Ensemble zu erzeugen als sehr bewusste Algorithmen (wie entropiereduzierende Entscheidungsbäume). Mit einer Vielzahl von starken Lernalgorithmen hat sich jedoch gezeigt, dass sie effektiver sind als mit Techniken, die versuchen, die Modelle zu vergraben, um Vielfalt zu fördern. Es ist möglich, die Diversität in der Ausbildungsphase des Modells durch Korrelation für Regressionsaufgaben zu erhöhen oder Informationsmassnahmen wie Cross Entropy für Klassifikationsaufgaben zu verwenden. Größe des Ensembles Während die Anzahl der Komponenten-Klassifikatoren eines Ensembles einen großen Einfluss auf die Genauigkeit der Vorhersage hat, gibt es eine begrenzte Anzahl von Studien, die dieses Problem ansprechen. A priori Bestimmung der Ensemblegröße und der Volumen und Geschwindigkeit der großen Datenströme machen dies für Online-Ensemble Klassifikatoren noch entscheidender. Die meisten statistischen Tests wurden zur Bestimmung der richtigen Anzahl von Komponenten verwendet. In jüngerer Zeit schlug ein theoretischer Rahmen vor, dass es eine ideale Anzahl von Komponenten-Klassifikatoren für ein Ensemble gibt, so dass mit mehr oder weniger als dieser Anzahl von Klassifikatoren die Genauigkeit verschlechtern würde. Es heißt "das Gesetz der abnehmenden Rückkehr im Ensemblebau. " Ihr theoretischer Rahmen zeigt, dass mit der gleichen Anzahl von unabhängigen Komponenten-Klassifikatoren wie Klassen-Etiketten die höchste Genauigkeit ergibt. Gemeinsame Arten von Ensembles Buchten optimaler Klassifikator Der Bayes optimale Klassifikator ist eine Klassifikationstechnik. Es ist ein Ensemble aller Hypothesen im Hypothesenraum. Im Durchschnitt kann kein anderes Ensemble es übertreffen. Der naive Bayes optimale Klassifikator ist eine Version davon, dass die Daten bedingt unabhängig von der Klasse sind und die Berechnung machbar macht. Jede Hypothese gibt eine Stimme, die proportional zur Wahrscheinlichkeit ist, dass der Trainingsdatensatz von einem System abgefragt würde, wenn diese Hypothese wahr wäre. Um Ausbildungsdaten von endlicher Größe zu erleichtern, wird die Abstimmung jeder Hypothese auch mit der vorherigen Wahrscheinlichkeit dieser Hypothese multipliziert. Der optimale Klassifikator der Buchten kann mit folgender Gleichung ausgedrückt werden: y = r g m a x c j ε C Σ h i ε H P (c j | h i ) P (T | h i ) P (h i ) \\displaystyle y={\underset c_{j}\in C{\mathrm {argmax}\sum h_{i}in HINTERGRUND P(c_{j}|h_{i})P(T|h_{i})P(h_{i, wo y \{displaystyle y} die vorhergesagte Klasse ist, C \{displaystyle C} ist der Satz aller möglichen Klassen, H \{displaystyle H} ist der Hypothesenraum, P \{displaystyle P} bezieht sich auf eine Wahrscheinlichkeit, und T \{displaystyle-Daten} ist die Hypothese. Als Ensemble stellt der Bayes optimale Klassifikator eine Hypothese dar, die nicht unbedingt in H \{displaystyle H} liegt.Die Hypothese, die durch den Bayes optimalen Klassifikator repräsentiert wird, ist jedoch die optimale Hypothese im Ensembleraum (der Raum aller möglichen Ensembles, die nur aus Hypothesen in H \{displaystyle H} bestehen). Diese Formel kann mit Bayes' Theorem restauriert werden, das besagt, dass der Posterior proportional zu den Wahrscheinlichkeitszeiten des Vorstehenden ist: P (h i | T ) a P (T | h i ) P (h i ) \{displaystyle P(h_{i}|T)\propto P(T|h_{i})P(h_{i also y = a r g m a x c j ε C Σ h i ε H P (c j | h i ) P (h i ) T ) \{displaystyle y={\underset c_{j} in C{\mathrm {argmax \}sum h_{i}in H}{P(c_{j}|h_{i})P(h_{i})T Bootstrap aggregating (bagging)Bootstrap aggregating, oft als Bagging abgekürzt, beinhaltet jedes Modell in der Ensemblestimme mit gleichem Gewicht. Um die Modellvarianz zu fördern, trainiert jedes Modell im Ensemble mit einer zufällig gezogenen Teilmenge des Trainingssets. Als Beispiel kombiniert der zufällige Waldalgorithmus zufällige Entscheidungsbäume mit Gepäck, um eine sehr hohe Klassifizierungsgenauigkeit zu erreichen. Beim Absacken werden die Proben so erzeugt, dass die Proben voneinander verschieden sind, jedoch ein Austausch erlaubt ist. Ersetzung bedeutet, dass eine Instanz mehrfach in mehreren Proben auftreten kann oder sie überhaupt nicht in einigen Proben erscheinen kann. Diese Muster werden dann mehreren Lernenden gegeben und dann die Ergebnisse jedes Lernenden in Form von Abstimmungen zusammengefasst. Boosting Boosting beinhaltet inkrementellen Aufbau eines Ensembles, indem jede neue Modellinstanz trainiert wird, um die Ausbildungsinstanzen hervorzuheben, die frühere Modelle fehlklassifiziert haben. In einigen Fällen hat sich eine Steigerung gezeigt, um eine bessere Genauigkeit als das Absacken zu erzielen, aber sie neigt auch dazu, die Trainingsdaten zu übertreffen. Bislang ist die häufigste Implementierung der Steigerung Adaboost, obwohl einige neuere Algorithmen gemeldet werden, um bessere Ergebnisse zu erzielen. Bei Boosting werden die Probenausbildungsdaten (vgl. D1) in der Anfangsrunde ein gleiches Gewicht (gleiche Wahrscheinlichkeitsverteilung) angegeben. Diese Daten (D1) werden dann einem Basislerner (Test L1) gegeben. Die falsch klassifizierten Instanzen von L1 werden einem Gewicht zugeordnet, das höher ist als die korrekt klassifizierten Instanzen, wobei jedoch die Gesamtwahrscheinlichkeitsverteilung gleich 1 sein wird. Diese verstärkten Daten (Test D2) werden dann dem zweiten Basislerner (Test L2) und so weiter gegeben. Die Ergebnisse werden dann in Form einer Abstimmung zusammengefasst. Bayesian model averaging Bayesian model averaging (BMA) macht Vorhersagen mit einem Durchschnitt über mehrere Modelle mit Gewichten, die durch die posterior Wahrscheinlichkeit jedes Modells gegeben die Daten. BMA ist bekannt, im allgemeinen bessere Antworten zu geben als ein einziges Modell, das z.B. durch schrittweise Regression erhalten wird, insbesondere dann, wenn sehr unterschiedliche Modelle im Trainingsset nahezu identische Leistung haben, ansonsten aber ganz anders ausgeführt werden können. Die offensichtlichste Frage mit jeder Technik, die Bayes' Theorem verwendet, ist der vorherige, d.h. eine Spezifikation der Wahrscheinlichkeit (subjektiv, vielleicht), dass jedes Modell das beste für einen bestimmten Zweck zu verwenden ist. Konzeptionell kann BMA mit jedem vorherigen verwendet werden. Die EnsembleBMA- und BMA-Pakete für R verwenden das zuvor vom Bayesischen Informationskriterium (BIC) nach Raftery (1995). Das BAS-Paket für R unterstützt die Verwendung der durch das Akaike-Informationskriterium (AIC) und andere Kriterien über die alternativen Modelle sowie Vorstufen über die Koeffizienten angedeuteten Vorstufen. Der Unterschied zwischen BIC und AIC ist die Stärke der Vorliebe für Parsimony. Die Strafe für die Modellkomplexität ist ln ċ ( n ) k \{displaystyle \ln(n)k} für die BIC und 2 k \{displaystyle 2k} für die AIC. Große Stichprobe asymptotische Theorie hat festgestellt, dass, wenn es ein bestes Modell gibt, dann mit zunehmenden Probengrößen, BIC ist stark konsistent, d.h. wird es fast sicher finden, während AIC nicht, weil AIC kann weiterhin übermäßige posterior Wahrscheinlichkeit auf Modelle, die komplizierter als sie sein müssen. Wenn wir andererseits mehr mit der Effizienz, d.h. mit minimalem mittleren quadratischen Vorhersagefehler beschäftigt sind, dann sind AIC und AICc asymmetrisch „effizient“, während BIC nicht ist. Burnham und Anderson (1998, 2002) trugen maßgeblich dazu bei, ein breiteres Publikum zu den Grundideen des Bayesischen Modells einzurichten und die Methodik zu populär zu machen. Die Verfügbarkeit von Software, einschließlich anderer freier Open-Source-Pakete für R über die oben genannten hinaus, half, die Methoden für ein breiteres Publikum zugänglich zu machen. Haussler et al.(1994) zeigte, dass bei Verwendung von BMA zur Klassifikation der erwartete Fehler maximal das Doppelte des erwarteten Fehlers des Bayes optimalen Klassifikators ist. Bayesische Modell-Kombination Bayesian Modell-Kombination (BMC) ist eine algorithmische Korrektur der Bayesischen Modell-Mittelung (BMA). Anstatt jedes Modell im Ensemble einzeln abzutasten, mustert es aus dem Raum der möglichen Ensembles (mit Modellgewichtungen, die zufällig aus einer Dirichletverteilung mit einheitlichen Parametern gezogen werden). Diese Modifikation überwindet die Tendenz von BMA zu konvergieren, um das ganze Gewicht zu einem einzigen Modell zu geben. Obwohl BMC etwas rechnerisch teurer ist als BMA, neigt es dazu, dramatisch bessere Ergebnisse zu erzielen. Die Ergebnisse von BMC wurden im Durchschnitt (mit statistischer Bedeutung) besser als BMA und beim Absacken gezeigt. Die Verwendung von Bayes' Gesetz zur Berechnung von Modellgewichten erfordert die Berechnung der Wahrscheinlichkeit der Daten jedes Modells. Typischerweise sind keine der Modelle im Ensemble genau die Verteilung, aus der die Trainingsdaten generiert wurden, so dass sie alle für diesen Begriff einen Wert nahe Null erhalten. Dies würde gut funktionieren, wenn das Ensemble groß genug wäre, um den gesamten Modellraum zu probieren, aber das ist selten möglich. Infolgedessen wird jedes Muster in den Trainingsdaten dazu führen, dass sich das Ensemblegewicht auf das Modell im Ensemble, das der Verteilung der Trainingsdaten am nächsten ist, verlagert. Sie reduziert sich im Wesentlichen auf ein unnötig komplexes Verfahren zur Modellauswahl. Die möglichen Gewichtungen für ein Ensemble können auf einem Simplex als liegend visualisiert werden. An jedem Scheitel des Simplexs wird das Gewicht einem einzigen Modell im Ensemble gegeben. BMA konvergiert zum Scheitel, der der Verteilung der Trainingsdaten am nächsten ist. Dagegen konvergiert BMC zu dem Punkt, an dem diese Verteilung auf den Simplex projiziert. Mit anderen Worten, anstatt das eine Modell auszuwählen, das der Erzeugungsverteilung am nächsten ist, sucht es die Kombination von Modellen, die der Erzeugungsverteilung am nächsten sind. Die Ergebnisse von BMA können oft durch Cross-Validierung angenähert werden, um das beste Modell aus einem Eimer von Modellen auszuwählen. Ebenso können die Ergebnisse von BMC durch Kreuzvalidierung angenähert werden, um aus einer zufälligen Probenahme möglicher Gewichtungen die beste Ensemblekombination auszuwählen. Bucket von Modellen Ein "Bucket von Modellen" ist eine Ensembletechnik, in der ein Modellauswahlalgorithmus verwendet wird, um das beste Modell für jedes Problem zu wählen. Bei der Prüfung mit nur einem Problem kann ein Eimer von Modellen keine besseren Ergebnisse produzieren als das beste Modell im Set, aber bei der Auswertung über viele Probleme wird es in der Regel viel bessere Ergebnisse im Durchschnitt, als jedes Modell im Set. Der häufigste Ansatz, der für die Modellauswahl verwendet wird, ist die Cross-Validation-Auswahl (manchmal als "Bake-off-Wettbewerb"). Es wird mit dem folgenden Pseudo-Code beschrieben: Für jedes Modell m im Eimer: c mal: (wo c etwas konstant ist) Zufällig teilen Sie den Trainingsdatensatz in zwei Datensätze: A, und B. Train m mit A Test m mit B Wählen Sie das Modell, das die höchste durchschnittliche Punktzahl Cross-Validation Selection erhält, kann als: "probieren Sie sie alle mit dem Trainingsset und wählen Sie den, der am besten funktioniert". Gating ist eine Verallgemeinerung der Cross-Validation Selection. Es beinhaltet die Ausbildung eines anderen Lernmodells zu entscheiden, welche der Modelle im Eimer am besten geeignet ist, das Problem zu lösen. Oft wird für das Gatingmodell ein Perceptron verwendet. Es kann verwendet werden, um das beste Modell auszuwählen, oder es kann verwendet werden, um ein lineares Gewicht zu den Vorhersagen von jedem Modell im Eimer zu geben. Wenn ein Eimer von Modellen mit einer großen Reihe von Problemen verwendet wird, kann es wünschenswert sein, einige der Modelle zu vermeiden, die eine lange Zeit zu trainieren. Wahrzeichenbildung ist ein meta-Learning-Ansatz, der versucht, dieses Problem zu lösen. Es beinhaltet Training nur die schnellen (aber unpräzisen) Algorithmen im Eimer, und dann die Leistung dieser Algorithmen zu helfen zu bestimmen, welche langsamen (aber genauen) Algorithmus am wahrscheinlichsten zu tun ist. Stacking Stacking (manchmal gestapelte Verallgemeinerung genannt) beinhaltet die Ausbildung eines Lernalgorithmus, um die Vorhersagen mehrerer anderer Lernalgorithmen zu kombinieren. Zunächst werden alle anderen Algorithmen mit den verfügbaren Daten trainiert, dann wird ein Mähdrescheralgorithmus ausgebildet, um eine endgültige Vorhersage mit allen Vorhersagen der anderen Algorithmen als zusätzliche Eingaben vorzunehmen. Wird ein beliebiger Mähdrescheralgorithmus verwendet, so kann das Stapeln theoretisch jede der in diesem Artikel beschriebenen Ensembletechniken darstellen, obwohl in der Praxis oft ein logistisches Regressionsmodell als Mähdrescher verwendet wird. Stapeln liefert typischerweise Leistung besser als jede einzelne der geschulten Modelle. Es wurde sowohl bei beaufsichtigten Lernaufgaben (Regression, Klassifikation und Fernlernen) als auch bei ununterbrochenem Lernen (Density-Schätzung) erfolgreich eingesetzt. Es wurde auch verwendet, um die Fehlerrate des Gepäcks zu schätzen. Es wurde gemeldet, um die ex-perform Bayesian Modell-Averaging. Die beiden Top-Performer im Netflix-Wettbewerb nutzten die Mischung, die als eine Form der Stapelung angesehen werden kann. Implementierungen in Statistikpaketen R: mindestens drei Pakete bieten Bayesische Modell-Aging-Tools, darunter das BMS-Paket (ein Akronym für Bayesian Model Selection), das BAS (ein Akronym für Bayesian Adaptive Sampling) und das BMA-Paket. Python: Scikit-learn, ein Paket für maschinelles Lernen in Python bietet Pakete für das Ensemblelernen, einschließlich Pakete für Gepäck und Mittelungsverfahren. MATLAB: Klassifikationsensembles werden in Statistics and Machine Learning Toolbox implementiert. Anwendungen für das Lernen von Ensembles In den letzten Jahren ist aufgrund der wachsenden Rechenkraft, die die Ausbildung eines großen Ensemble-Lernens in einem angemessenen Zeitrahmen ermöglicht, die Zahl seiner Anwendungen zunehmend gewachsen. Einige der Anwendungen von Ensemble-Klassifikatoren umfassen: Die Landbedeckung Mapping ist eine der wichtigsten Anwendungen der Erdbeobachtungssatellitensensoren, die mit Hilfe von Fernerkundungs- und Geospatialdaten die Materialien und Objekte identifizieren, die sich auf der Oberfläche der Zielgebiete befinden. In der Regel umfassen die Klassen der Zielmaterialien Straßen, Gebäude, Flüsse, Seen und Vegetation. Einige verschiedene Ensemble Lernansätze basierend auf künstlichen neuronalen Netzwerken, Kernel Hauptkomponentenanalyse (KPCA), Entscheidungsbäume mit Boost, zufälligen Wald und automatischem Design von mehreren Klassifikatorsystemen, werden vorgeschlagen, Landbedeckungsobjekte effizient zu identifizieren. Änderungserkennung Änderungserkennung ist ein Problem der Bildanalyse, bestehend aus der Identifizierung von Orten, an denen sich die Landabdeckung im Laufe der Zeit verändert hat. Die Veränderungserkennung ist weit verbreitet in Bereichen wie Stadtwachstum, Wald- und Vegetationsdynamik, Landnutzung und Katastrophenüberwachung. Die frühesten Anwendungen von Ensemble-Klassifikatoren in der Änderungserkennung sind mit der Mehrheitswahl, Bayesian Durchschnitt und die maximale posterior Wahrscheinlichkeit entworfen. Computer-Sicherheit Verteilte Denial des Dienstes Verteilte Denial des Dienstes ist eine der bedrohlichsten Cyber-Angriffe, die einem Internet-Service-Anbieter passieren können. Durch die Kombination der Leistung einzelner Klassifikatoren reduzieren Ensemble Klassifikatoren den Gesamtfehler, solche Angriffe von legitimen Flash-Crowds zu erkennen und zu diskriminieren. Malware Detection Klassifizierung von Malware-Codes wie Computer-Viren, Computer-Würmer, Trojaner, Ransomware und Spyware mit der Nutzung von maschinellen Lerntechniken, ist inspiriert durch das Dokument Kategorisierung Problem. Ensemble Lernsysteme haben in diesem Bereich eine richtige Wirksamkeit gezeigt. Intrusionserkennung Ein Intrusions-Detektionssystem überwacht Computernetzwerke oder Computersysteme, um Intruder-Codes wie ein Anomaly-Detektionsprozess zu identifizieren. Ensemble Learning unterstützt solche Überwachungssysteme erfolgreich, um ihren Gesamtfehler zu reduzieren. Gesichtserkennung Gesichtserkennung, die vor kurzem zu einem der beliebtesten Forschungsbereiche der Mustererkennung geworden ist, kopiert die Identifikation oder Überprüfung einer Person durch ihre digitalen Bilder.Hierarchische Ensembles auf der Grundlage von Gabor Fisher Klassifikator und unabhängige Komponentenanalyse Vorverarbeitungstechniken sind einige der frühesten Ensembles, die in diesem Bereich eingesetzt werden. Emotion Anerkennung Während die Spracherkennung vor allem auf Deep Learning basiert, weil die meisten der Branchenspieler in diesem Bereich wie Google, Microsoft und IBM zeigen, dass die Kerntechnologie ihrer Spracherkennung auf diesem Ansatz basiert, kann die sprachbasierte Emotionserkennung auch eine befriedigende Leistung mit Ensemble-Learning haben. Es wird auch erfolgreich in der Gesichtsemotionserkennung verwendet. Betrugsdetektion Betrugsdetektion behandelt die Identifizierung von Bankbetrug, wie Geldwäsche, Kreditkartenbetrug und Telekommunikationsbetrug, die große Bereiche der Forschung und Anwendungen des maschinellen Lernens haben. Da das Ensemblelernen die Robustheit der normalen Verhaltensmodellierung verbessert, wurde es als effiziente Technik vorgeschlagen, solche betrügerischen Fälle und Aktivitäten in Bank- und Kreditkartensystemen zu erkennen. Finanzielle Entscheidungsfindung Die Genauigkeit der Prognose des Unternehmensversagens ist ein sehr entscheidendes Problem bei der Finanzentscheidung. Daher werden verschiedene Ensemble-Klassifikatoren vorgeschlagen, Finanzkrisen und finanzielle Not vorherzusagen. Auch im handelsbasierten Manipulationsproblem, bei dem Trader versuchen, Aktienpreise durch Kauf und Verkauf von Aktivitäten zu manipulieren, sind Ensemble-Klassifikatoren erforderlich, um die Veränderungen in den Aktienmarktdaten zu analysieren und verdächtige Symptom der Börsenkursmanipulation zu erkennen. Medizin-Ensemble-Klassifikatoren wurden erfolgreich in der Neurowissenschaften, Proteomik und medizinischen Diagnostik eingesetzt, wie in der neurokognitiven Störung (d.h. Alzheimer oder myotonic dystrophy) Erkennung auf Basis von MRI-Datensätzen. Siehe auch Ensemble averaging (Maschinenlernen)Bayesische strukturelle Zeitreihe (BSTS) Referenzen Weitere Lesung Zhou Zhihua (2012). Ensemble Methoden: Stiftungen und Algorithmen. Chapman und Hall/CRC.ISBN 978-1-439-83003-1.Robert Schapire; Yoav Freund (2012). Boosting: Stiftungen und Algorithmen. MIT.ISBN 978-0-262-01718-3. Externe Links Robi Polikar (ed.)."Ensemble learning". Scholarpedia. Das Waffles (Maschinenlernen) Toolkit enthält Implementierungen von Bagging, Boosting, Bayesian Model Averaging, Bayesian Model Combination, Bucket-of-Modelle und andere Ensembletechniken