Das Informationszeitalter (auch bekannt als Computeralter, digitales Alter oder neues Medienalter) ist ein historischer Zeitraum, der Mitte des 20. Jahrhunderts begann, der durch eine schnelle historische Verlagerung von der traditionellen Industrie, die von der Industrial Revolution in eine Wirtschaft vor allem auf der Grundlage der Informationstechnologie gegründet wurde. Der Beginn des Informationszeitalters kann mit der Entwicklung der transistor-Technologie in Verbindung gebracht werden. Laut dem Public Administration Network der Vereinten Nationen wurde das Informationszeitalter durch die Kapitalisierung auf Computer-Mikrominiaturisierungsvorschüssen gebildet, die zu modernisierten Information und Kommunikationsprozessen führen würden, wenn die Gesellschaft die treibende Kraft der sozialen Entwicklung wird. Überblick über die frühen Entwicklungen in der Bibliothek Erweiterung und den Ausbau der Rechtsbibliothek von Moore wurde im Jahr 1945 von Fremont Wheel berechnet, um alle 16 Jahre, in denen ausreichend Platz zur Verfügung gestellt wurde, die Kapazität zu verdoppeln. Er plädierte für die Ersetzung von Massenvernichtungsstücken mit Miniaturierten Mikroform- analogen Fotos, die auf Abruf für Bibliotheksprioritäten und andere Institutionen verdoppelt werden könnten. Wheel sah jedoch nicht vor, dass die digitale Technologie, die Jahrzehnte später folgen würde, um Analog-Mikroform mit digitaler Bildgebung, Lagerung und Übertragungsmedien zu ersetzen, wodurch ein erheblicher Anstieg der Schnelligkeit des Informationswachstums durch automatisierte, potenziell verlustlose digitale Technologien möglich wäre. So würde das im Jahr 1965 formulierte Gesetz von Moore berechnen, dass die Zahl der Transisten in einem dichten integrierten Schaltkreis etwa alle zwei Jahre verdoppelt. In den frühen 80er Jahren ermöglichte die Verbreitung der kleineren und weniger teuren persönlichen Computer den sofortigen Zugang zu Informationen und die Fähigkeit, diese für immer mehr Arbeitnehmer zu teilen und zu speichern. Konnektivität zwischen Computern innerhalb von Organisationen ermöglichte Arbeitnehmern auf verschiedenen Ebenen Zugang zu mehr Informationen. Informationsspeicherung und Kryder-Gesetz Die technische Kapazität der Welt, Informationen zu speichern, stieg von 2,6 (optimalen Druck) Exabyte (EB) im Jahre 1986 auf 15,8 EB im Jahr 1993; über 54.5 EB im Jahr 2000 und 295 (optimalen Druck) EB im Jahr 2007. Dies ist das Informationsverhältnis von weniger als einer 730-Megabyte (MB) CD-ROM pro Person im Jahr 1986 (539 MB pro Person); etwa vier CD-ROM pro Person im Jahr 1993; 12 CD-ROM pro Person im Jahr 2000 und fast sechszig eine CD-ROM pro Person im Jahr 2007. Es wird geschätzt, dass die Fähigkeit der Welt, Informationen zu speichern, im Jahr 2014 5 zettabytes erreicht hat, das Informationsäquivalent von 4 500 Druckbüchern aus der Erde auf die Sonne. Die Menge der gespeicherten digitalen Daten scheint in etwa exponentieller Weise zu wachsen, was an die Rechtsvorschriften von Moore erinnert. Das Kryder-Gesetz schreibt daher vor, dass der Umfang der verfügbaren Speicherfläche in etwa exponentieller Weise wächst. Information Übertragung Im Jahr 2000 waren 432 Exabyte (optimaler Druck) von (optimalen) Informationen; 715 (optimaler Druck) Exabyte im Jahr 1993; 1.2 (optimaler Druck) zettabyte im Jahr 2000; und 1,9 zettabyte im Jahr 2007, das Informationsäquivalent von 174 Zeitungen pro Tag. Die wirksame Fähigkeit der Welt, Informationen über zwei Telekommunikationsnetze auszutauschen, lag im Jahr 1986 bei 281 Heimabyte (optimaler Druck) und im Jahr 1993 bei 471 Petabyte; 2,2 (optimaler Druck) Exabyte im Jahr 2000; und 65 (optimal) Exabyte im Jahr 2007, dem Informationsäquivalent von 6 Zeitungen pro Tag. In den 90er Jahren führte die Verbreitung des Internets zu einem plötzlichen Sprung in den Zugang und die Fähigkeit, Informationen in Unternehmen und Häusern weltweit zu teilen. Technologie entwickelt sich so schnell, dass 1997 ein EDV-Kosten in Höhe von 3000 $ im Jahr 2000 zwei Jahre später und 1000 $ im folgenden Jahr kosten würde. Fertigstellung Die technologische Fähigkeit der Welt, Informationen mit humangesteuerten allgemeinen Computern zu berechnen, stieg von 3,0 × 108 MIPS 1986 auf 4,4 × 109 MIPS im Jahr 1993; auf 2,9 × 1011 MIPS im Jahr 2000; auf 6,4 × 1012 MIPS im Jahr 2007. Laut einem Artikel, der 2016 in den Fachzeitschriften Trends in Ökologie und Entwicklung aufgeführt ist, ist Folgendes zu verzeichnen:[Digital Technology] hat die kognitive Kapazität jedes einzelnen Menschen erheblich übertroffen und hat dieses Jahrzehnt früher als vorhergesagt. Kapazität gibt es zwei Maßnahmen, die von Bedeutung sind: die Anzahl der Operationen, die ein System durchführen kann, und die Menge der Informationen, die gespeichert werden können. Die Zahl der synaptischen Operationen pro Sekunde in einem menschlichen Gehirn liegt zwischen 10^15 und 10^17. Diese Zahl ist beeindruckend, auch im Jahr 2007 waren die allgemeinen Computer der Menschheit in der Lage, gut über 10^18 Anweisungen pro Sekunde durchzuführen. Schätzungen weisen darauf hin, dass die Speicherkapazität eines einzelnen menschlichen Gehirns etwa 10^12 vontes ist. Pro-Kopf-Basis wird dies durch die aktuelle digitale Lagerhaltung (5x10^21 vontes pro 7.2x10^9 Menschen) ergänzt. Differenzierung der stufenweisen Konzepte Es gibt verschiedene Konzepte des Informationszeitalters. Manche konzentrieren sich auf die Entwicklung von Informationen über die Altersgruppen, die Unterscheidung zwischen dem Grundinformationsalter und dem Sekundärinformationsalter. Informationen im primären Informationszeitalter wurden von Zeitungen, Radio und Fernsehen bearbeitet. Sekundärinformation Alter wurde durch das Internet, Satellitenfernsehen und Mobiltelefone entwickelt. Das Tertiäre Informationszeitalter entstand durch Medien des primären Informationszeitalters, das mit Medien des Sekundarinformationsalters in Verbindung steht. Andere nennen es in Bezug auf die etablierten Schumpeterischen langen Wellen oder Kondratiev-Wellen. Hier unterscheiden die Autoren drei unterschiedliche langfristige Metaparadigmen, jeweils mit unterschiedlichen langen Wellen. In erster Linie konzentrierte sich die Umwandlung von Material, einschließlich Stein, Bronze und Eisen. Die zweite, oft als industrielle Revolution bezeichnete, war für die Energieumwandlung, einschließlich Wasser, Dampf, Elektro und Verbrennungskraft. Letztendlich zielt der jüngste Metaparadigm darauf ab, Informationen zu verwandeln. Es begann mit der Verbreitung von Kommunikation und gespeicherten Daten und hat nun das Alter von Algorithmen aufgenommen, mit dem automatisierte Prozesse geschaffen werden sollen, um die vorhandenen Informationen in ein handlungsfähiges Wissen umzuwandeln. Wirtschaft Kurzum, Information und Kommunikationstechnologien (IKT)i. Computer, computergestützte Maschinen, Glasfaser, Kommunikationsatelliten, Internet und andere IKT-Werkzeuge – ein wichtiger Bestandteil der Weltwirtschaft, da die Entwicklung von Mikrocomputern viele Unternehmen und Industrien stark verändert hat. Nicholas Monteponte hat den Kern dieser Änderungen in seinem Buch 1995, nämlich der Digital, in dem er die Ähnlichkeiten und Unterschiede zwischen Produkten aus Atomen und Produkten von Bits erörtert. Im Wesentlichen kann eine Kopie eines Produkts aus Bits kostengünstig und schnell geliefert werden, dann ist dies zu sehr niedrigen Kosten möglich. Beschäftigung und Einkommensverteilung Das Informationszeitalter hat die Belegschaft auf mehrere Weise beeinträchtigt, wie z.B. Zwangsarbeiter, um auf einem globalen Arbeitsmarkt zu konkurrieren. Eines der offensichtlichsten Anliegen ist die Ersetzung von Humanarbeit durch Computer, die ihre Arbeit schneller und effizienter machen können, so dass eine Situation geschaffen wird, in der Personen, die leicht automatisiert werden können, gezwungen sind, eine Beschäftigung zu finden, wenn ihre Arbeit nicht als Einweg verfügbar ist. Dies schafft insbesondere Probleme für diejenigen in Industriestädten, bei denen Lösungen in der Regel eine niedrigere Arbeitszeit beinhalten, die häufig sehr widersprüchlich ist. Personen, die ihre Arbeitsplätze verlieren, können daher dazu gedrängt werden, sich an "minderende Arbeitnehmer" zu beteiligen (z.B. Ingenieure, Ärzte, Rechtsanwälte, Lehrer, Professoren, Wissenschaftler, Führungskräfte, Journalisten, Berater), die erfolgreich auf dem Weltmarkt konkurrieren und (relativ) hohe Löhne erhalten. Neben der Automatisierung haben sich auch die traditionell mit der mittleren Klasse (z.B. Montagelinie, Datenverarbeitung, Management und Überwachung) verbundenen Arbeitsplätze infolge von Outsourcing verschwinden lassen. Nicht in der Lage, mit denen in Entwicklungsländern zu konkurrieren, Produktions- und Service-Arbeitnehmer in postindustriellen (d. h. entwickelten) Gesellschaften verlieren ihre Arbeitsplätze durch Outsourcing, akzeptieren Lohnkürzungen oder legen sich für geringqualifizierte, gering bezahlte Dienstleistungen vor. Künftig würde das wirtschaftliche Schicksal des Einzelnen an das des Landes gebunden sein. Beispielsweise wurden Arbeitnehmer in den Vereinigten Staaten im Vergleich zu denen in anderen Ländern einmal gut bezahlt. Mit der Einführung des Informationszeitalters und der Verbesserung der Kommunikation ist dies nicht mehr der Fall, da die Arbeitnehmer nun auf einem globalen Jobmarkt konkurrieren müssen, wo Löhne weniger vom Erfolg oder Misserfolg einzelner Volkswirtschaften abhängig sind. Mit der Wirkung einer globalisierten Erwerbsbevölkerung hat das Internet auch in den Entwicklungsländern eine größere Chance, so dass es den Arbeitnehmern in solchen Orten möglich ist, Dienstleistungen im Personenverkehr anzubieten, so dass sie direkt mit ihren Kollegen in anderen Nationen konkurrieren. Dieser Wettbewerbsvorteil führt zu mehr Chancen und höheren Löhnen. Automatisierung, Produktivität und Arbeitsplatzgewinn Das Informationszeitalter hat die Belegschaft insofern beeinträchtigt, als Automatisierung und Computerisierung zu einer höheren Produktivität und einem Netto-Jobverlust in der Fertigung geführt haben. In den Vereinigten Staaten sank beispielsweise von Januar 1972 bis August 2010 die Zahl der Beschäftigten im verarbeitenden Gewerbe von 17,500.000 auf 11,500.000, während der Produktionswert 270% stieg. Obwohl zunächst der Arbeitsplatzverlust im Industriesektor durch das schnelle Wachstum der Arbeitsplätze in der Informationstechnologie teilweise kompensiert werden könnte, war die Rezession im März 2001 ein drastischer Rückgang der Zahl der Arbeitsplätze in der Branche. Dieser Rückgang der Arbeitsplätze würde bis 2003 fortgesetzt, und die Daten haben gezeigt, dass die Technologie insgesamt mehr Arbeitsplätze schafft als sie selbst kurzfristig zerstört. Informationstechnologie Industrie ist mehr informationsintensiver geworden, weniger arbeits- und kapitalintensiv. Dies hat wichtige Auswirkungen auf die Belegschaft hinterlassen, da die Arbeitnehmer immer produktiver geworden sind, da der Wert ihrer Arbeit sinkt. Für das System des Kapitalismus selbst verringert sich der Wert der Arbeit, der Wert der Kapitalerhöhung. Investitionen in Human- und Finanzkapital sind im klassischen Modell wichtige Vorhersagen für die Leistung eines neuen Unternehmens. Laut Mark Zuckerberg und Facebook scheint es nun möglich, dass eine Gruppe relativ unerfahrener Menschen mit beschränktem Kapital erfolgreich auf einem großen Maßstab sein kann. InnovationThe Information Age wurde durch die in der Digitalen Revolution entwickelte Technologie ermöglicht, die selbst durch den Aufbau der technologischen Revolution ermöglicht wurde. Kernwaffen Der Beginn des Informationszeitalters kann mit der Entwicklung der transistor-Technologie in Verbindung gebracht werden. Das Konzept eines Feldeffekt-Transistor wurde erstmals von Julius Edgar LIenfeld im Jahr 1916 umgesetzt. Erster praktischer Transistor war der Kontakt-Transistor, der von den Ingenieuren Walter Houser Brattain und John Bardeen entworfen wurde und 1947 für William Schockley in Bell Labs arbeitet. Dies war ein Durchbruch, der den Grundstein für moderne Technologie gelegt hat. Schockleys Forschungsteam hat auch 1952 den bipolaren Interistor entwickelt. Die am häufigsten verwendete Art von Transistor ist der Metall-Oxide-Semiconduktor-Feld-Wirkungstransistor (MOSFET), der 1960 von Mohamed M. Atalla und Dawon Kahng in Bell Labs entwickelt wurde. Der  MOS (CMOS) wurde 1963 von Frank Wanlass und Chih-Tang Sah entwickelt. Computer Vor der Einführung von Elektronik wurden mechanische Computer wie der Analytical Engine in 1837 entwickelt, um routinemäßige mathematische Berechnungen und einfache Entscheidungsfähigkeiten bereitzustellen. Militärische Bedürfnisse während des Zweiten Weltkriegs haben die Entwicklung der ersten elektronischen Computer auf der Grundlage von Vakuumröhren, einschließlich der Z3, der Atanasoff-Berry Computer, Coverlustus Computer und ENIAC, vorangetrieben. Durch die Erfindung des transistor konnte die Ära der wichtigsten Rahmencomputer (1950s-1970s), die von der IBM 360 benannt wurde, erreicht werden. Diese großen, raumreichen Computer bieten Datenberechnung und -manipulation, die viel schneller als möglich war, aber teuer waren, um zu kaufen und zu halten, waren ursprünglich auf einige wissenschaftliche Einrichtungen, Großunternehmen und Regierungsstellen beschränkt. Jack Kilby wurde 1958 in Texas Instruments gegründet. Im Jahr 1959 wurde der integrierte Siliziumkreislauf von Robert Noyce bei Fairchild Semiconductor entwickelt, wobei der von Jean Hoerni entwickelte Planar-Prozess genutzt wurde, der wiederum auf der 1957 bei Bell Labs entwickelten Silizium-Grenzübergangsmethode von Mohamed Atalla basiert. Nach der Erfindung des MOS transistor von Mohamed Atalla und Dawon Kahng in Bell Labs im Jahr 1959 wurde der integrierte MOS-Prozess von Fred Heiman und Steven Hofstein auf RCA im Jahr 1962 entwickelt. später wurde das MOS IC von Federico Faggin bei Fairchild Semiconductor entwickelt. Mit dem Konvent des MOS-Transistors und des MOS IC hat sich die Transistor-Technologie rasch verbessert, und das Rechenleistungsverhältnis hat dramatisch zugenommen, was einen direkten Zugriff auf Computer auf immer kleinere Gruppen von Menschen ermöglicht. Der erste kommerzielle Monochip-Mikroprozessor startete 1971, der Intel 4004, der von Federico Faggin entwickelt wurde, der seine Silizium-Gate-Technologie MOS IC nutzte, sowie Marcian Hoff, Masatoshi Shima und Stan Mazor. In den siebziger Jahren hat die Entwicklung von Computern wie dem Commodore PET und Apple II (beide 1977) Einzelpersonen Zugang zum Computer gewährt. Datenaustausch zwischen einzelnen Computern war jedoch entweder nicht vorhanden oder weitgehend manuell, zunächst mit gestrichenenen Karten und Magnetbanden und späteren Floppy-Chips. Daten Die ersten Entwicklungen bei der Speicherung von Daten basieren zunächst auf Fotos, beginnend mit Mikrophotographie in 1851 und dann Mikroform in den 1920er Jahren, mit der Möglichkeit, Dokumente auf dem Film zu speichern, was sie viel besser macht. Frühinformationstheorie und Hamming-Codes wurden rund 1950 entwickelt, doch erwarteten technische Neuerungen in der Datenübermittlung und -speicherung, um voll zu nutzen. Magnetkernspeicher wurde 1947 aus der Forschung von Frederick W Viehe und An Wang an der Harvard University entwickelt. MOS transistor, MOS Halbleiterspeicher wurde 1964 von John Schmidt in Fairchild Semiconductor entwickelt. Im Jahr 1967 haben Dawon Kahng und Simon Sze in Bell Labs beschrieben, wie das schwimmende Tor eines MOS Halbleitergeräts für die Zelle einer reprogrammierbaren ROM genutzt werden könnte. Nach der Erfindung des Flashspeichers von Fujio Masuoka bei Toshiba im Jahr 1980 war Toshiba im Jahr 1987 auf dem Bildschirmspeicher NAND tätig. Während die Kabel, die digitale Daten an Computerterminals und Peripheriegeräte zu den wichtigsten Netzen übertragen, gemeinsam waren und in den 1960er Jahren mit ARPANET spezielle Nachrichtenverteilungssysteme entwickelt wurden, wurden im Jahr 1969 unabhängige Computer-to-Computer-Netzwerke entwickelt. Im Jahr 1974 wurde das Internet (im Jahr 1974) und dann das World Wide Web im Jahr 1991 erweitert. MOSFET-Skalation, die schnelle Miniaturisierung von MOSFETs in einer von den Gesetzen des Moore vorhergesagten Rate, führte zu geringeren und leistungsfähigeren Computern, zu dem Zeitpunkt, an dem sie durchgeführt werden könnten. In den 80er Jahren wurden Laptops als eine Form von tragbaren Computern entwickelt, und persönliche digitale Assistenten (PDAs) könnten während des Auf- oder Fußs eingesetzt werden. Seiten, die von den 80er Jahren weit verbreitet wurden, wurden weitgehend durch Mobiltelefone ersetzt, die in den späten 90er Jahren beginnen, und durch mobile Vernetzungsfunktionen für einige Computer. Inzwischen wird diese Technologie auf digitale Kameras und andere Einweggeräte ausgeweitet. Anfang der 90er Jahre, Tablets und dann Smartphones kombinierten und erweiterten diese Fähigkeiten von Computer, Mobilität und Informationsaustausch. Internet-Video wurde von YouTube, einer von Tschad Hurley, Jawed Karim und Steve Chen im Jahr 2005 gegründeten Online-Video-Plattform, die das Video-Streaming von MPEG-4 AVC (H.264) Nutzern aus allen Teilen des World Wide Web ermöglichte. Elektronisches Papier, das in den siebziger Jahren Ursprungs ist, ermöglicht die Aufnahme digitaler Informationen als Papierdokumente. Optics Optical Communication hat eine wichtige Rolle in Kommunikationsnetzen gespielt. optische Kommunikation lieferte die Hardware-Basis für die Internet-Technologie und schafft die Grundlagen für die digitale Revolution und das Informationszeitalter. 1953, Bram van Fußlicht hat die Bildübertragung durch Bündel optischer Fasern mit transparenter Gewichtung gezeigt. Mit mehr als 10 000 optischen Fasern gelang es der Kommission, das Bild-Vertriebspaket mit über 10 000 optischen Fasern zu gestalten und anschließend durch ein 75 cm langes Bündel, das mehrere tausend Fasern kombiniert. Metall–Oxide–Semiconduktor (MOS) Bildsensoren, die zunächst in den späten 60er Jahren erschienen sind, führten in den 80er- bis 90er Jahren zum Übergang vom analogen zur digitalen Bildgebung und von analogen zu digitalen Kameras. Die häufigsten Bildsensoren sind der entgeltentkoppelte Sensor (CCD) und die CMOS (). MOS) aktivem iPhone Sensor (CMOS). Siehe auch weitere Lesung Oliver Stengel et al.(2017). Digitalzeitalter - Digitale Gesellschaft, Springer-Harmon-Harmon-Harmone, Edward (Juni 2016). In den Tiefen des digitalen Zeitalters, der New Yorker Buchprüfung Bollacker, Kurt D. (2010) Vermeidung eines digitalen dunklen Zeitalters, des amerikanischen Wissenschaftlers, März-April 2010, Band 98, Nummer 2, S. 106ffCastells, Manuel.(1996-98). Informationszeit: Wirtschaft, Gesellschaft und Kultur, 3 Vols. Oxford: Blackwell.Gelbstein, E. (2006)Crossing the Executive Digital Divide.ISBN 99932-53-17-0 Externe Links zu den Artikeln über die Auswirkungen des Informationszeitalters auf die Wirtschaft – im Informationszeitalter über das Informationszeitalter von Dave Ulmer Information Age Anthology Vol I von Alberts und Papp (CCRP, 1997) (PDF) Information Age Anthology Vol II von Alberts und Papp (CCRP, 2000) (PDF) Information Age Anthology Vol III von Alberts und Papp (CCRP, 2001)(PDF) Alterskrieg von Alberts et al.(CCRP, 2001) (PDF) Information Age Transformation von Alberts (CCRP, 2002) (PDF)The Unintended Consequence of Information Age Technologies by Alberts (CCRP, 1996) Geschichte & Diskussion über das Information Age Science Museum - Information Age