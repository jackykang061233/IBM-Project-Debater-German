High-dynamic-range (HDR) ist eine Technologie für die Art und Weise Helligkeit und Farben sind in Videos und Bildern dargestellt. Es wird mit dem Standard-Dynamik-Bereich (SDR) kontrastiert, der zum Begriff der älteren Technologie geworden ist. HDR bietet die Möglichkeit, wesentlich hellere Highlights, dunklere Schatten, mehr Details in beiden Seiten und mehr bunte Farben als bisher möglich zu repräsentieren. HDR ermöglicht einen besseren Einsatz von Displays mit hoher Helligkeit, Kontrast und Farbfähigkeit. Es erhöht nicht die Fähigkeiten des Displays und nicht alle HDR-Displays haben die gleichen Fähigkeiten. HDR-Inhalte werden somit je nach verwendetem Display unterschiedlich aussehen. HDR10, HDR10,+ Dolby Vision und HLG sind gemeinsame HDR-Formate. Die HDR-Technologie im Zusammenhang mit Displays entstand 2014. Warenbezeichnung Andere Technologien vor der HDR verbesserten die Bildqualität durch Erhöhung der Pixelgröße (Auflösung und Bildrate). HDR verbessert die Pixelqualität. Während CRT nicht mehr verwendet wird und moderne Displays oft viel höher sind, basiert das SDR-Format immer noch und beschränkt sich auf die Eigenschaften des CRT. HDR überwindet diese Grenzen. SDR-Formate sind in der Lage, bis zu einem maximalen Helligkeitsgrad von etwa 100 nits zu repräsentieren, während es für HDR bis zu mindestens 1000 nits und in einigen Formaten bis zu 10.000 nits geht. HDR unterstützt auch die Darstellung von niedrigeren schwarzen Ebenen und gesättigteren Farben (d.h. buntere Farben). Die häufigsten SDR-Formate sind auf Rec.709/sRGB-Gamut beschränkt, während häufige HDR-Formate verwenden Rec. 2100 Farbprimries, die eine breite Farb-Gamut (WCG) ist. Das sind die technischen Grenzen der HDR-Formate. HDR-Inhalte sind oft auf eine Spitzenhelligkeit von 1000 oder 4000 nits und DCI-P3-Farben beschränkt, auch wenn sie in einem höherfähigen Format gespeichert sind. Die Funktionen des Displays variieren und kein aktuelles Display ist in der Lage, alle maximalen Helligkeits- und Farbenbereiche wiederzugeben, die in HDR-Formaten gespeichert werden können. HDR-Video beinhaltet Erfassung, Produktion, Inhalt/Kodierung und Anzeige. Leistungen Hauptleistungen: Highlights (d.h. die hellsten Teile des Bildes) können gleichzeitig wesentlich heller, bunter sein und mehr Details haben. Niedrige Lichter (d.h. die dunkelsten Teile des Bildes) können dunkler sein und mehr Details haben. Die bunten Teile des Bildes können noch bunter sein. ( Dies wird durch die Verwendung von WCG erreicht, die für SDR nicht üblich und für HDR üblich ist.) Sonstige Leistungen: Eine realistischere Helligkeitsvariation zwischen Szenen wie Sonnenlicht, Innen- und Nachtszenen. Bessere Oberflächenmaterialerkennung. Bessere tiefe Wahrnehmung, auch mit 2D-Bilder. Die erhöhte maximale Helligkeit kann verwendet werden, um die Helligkeit der kleinen Bereiche zu erhöhen, ohne die Helligkeit des Gesamtbildes zu erhöhen, was zum Beispiel helle Reflexionen von glänzenden Objekten, helle Sterne in einer dunklen Nachtszene, helles und buntes Feuer, oder Sonnenuntergang, helle und bunte helle Objekte. Content-Autor können die Art und Weise wählen, wie sie die erweiterten Fähigkeiten nutzen. Sie können auch wählen, sich an die Grenzen der SDR zu halten, auch wenn der Inhalt im HDR-Format geliefert wird. Kreative Absichten Erhaltung Für die kreativen Absichten, die erhalten werden sollen, benötigen Videoformate die Anzeige und Betrachtung der Inhalte nach den Standards. HDR-Formate, die dynamische Metadaten (wie Dolby Vision und HDR10)+ verwenden, können auf jedem kompatiblen Display angezeigt werden. Die Metadaten ermöglichen die Anpassung des Bildes an das Display entsprechend an die kreativen Absichten. Andere HDR-Formate (wie HDR10 und HLG) erfordern, dass die Verbraucheranzeige mindestens die gleiche Fähigkeit wie das Mastering-Display hat. Die kreativen Absichten sind nicht gewährleistet, auf unteren fähigen Displays zu erhalten. Für eine optimale Qualität sind Inhalte in einer relativ dunklen Umgebung zu betrachten. Dolby Vision IQ und HDR10+ Adaptive passen den Inhalt entsprechend dem Umgebungslicht an. Sonstige HDR-Technologien Die seit Jahren in der Fotografie verwendete HDR-Capture-Technik erhöht die Dynamik, die von Kameras erfasst wird. Die Fotos müssten dann zur SDR getönt werden. Jetzt konnten sie im HDR-Format (wie HDR10) gespeichert werden, mit dem die Fotos in einem höheren Helligkeitsbereich dargestellt werden können. Bisherige hochdynamische Bereichsformate wie Roh- und Logarithm-Formate wurden nur für die Speicherung verwendet. Vor dem Erreichen des Verbrauchers müssten sie in SDR (d.h. Gammakurve) umgewandelt werden. Sie können nun auch in ein HDR-Format (wie HDR10) umgewandelt werden und mit einem höheren Helligkeits- und Farbbereich angezeigt werden. Formate Seit 2014 sind mehrere HDR-Formate entstanden, darunter HDR10, HDR10,+ Dolby Vision und HLG.Einige Formate sind lizenzfrei, andere benötigen eine Lizenz und einige sind fähiger als andere. Dolby Vision und HDR10+ beinhalten dynamische Metadaten, während HDR10 und HLG nicht. Diese werden verwendet, um die Bildqualität auf begrenzten Displays zu verbessern, die nicht in der Lage sind, ein HDR-Video in der Art zu reproduzieren, wie es erstellt und geliefert wurde. Dynamische Metadaten erlauben Inhaltsschöpfer, die Art und Weise zu steuern und zu wählen, wie das Bild angepasst wird. Bei Verwendung von niedrig fähigen Displays und dynamischen Metadaten sind nicht verfügbar, das Ergebnis wird bei den Wahlen des Displays variieren und künstlerische Absichten können nicht erhalten werden. HDR10HDR10 Medien Profil, allgemein bekannt als HDR10, ist ein offener HDR-Standard, der am 27. August 2015 von der Consumer Technology Association bekannt gegeben wurde. Es ist die verbreitetste der HDR-Formate. HDR10 ist technisch auf maximal 10.000 nits Spitzenhelligkeit beschränkt, jedoch werden HDR10-Inhalte häufig mit Spitzenhelligkeit von 1.000 bis 4.000 nits gemeistert. HDR10 ist nicht rückwärts kompatibel mit SDR-Displays. HDR10 fehlt an dynamischen Metadaten. Auf HDR10-Displays, die ein geringeres Farbvolumen als der HDR10-Inhalt (z.B. eine geringere Peak-Helligkeit) aufweisen, geben die HDR10-Metadaten Informationen, um den Inhalt anzupassen. Die Metadaten sind jedoch statisch (für das gesamte Video gleich bleiben) und erzählen nicht, wie der Inhalt angepasst werden soll, so dass die Entscheidung bis zum Display liegt und die kreativen Absichten nicht erhalten bleiben. Dolby Vision Dolby Vision ist ein End-to-End-Ökosystem für HDR-Video. Es umfasst die Erstellung, Verteilung und Wiedergabe von Inhalten. Es ist eine proprietäre Lösung von Dolby Laboratories, die 2014 entstand. Es verwendet dynamische Metadaten und es ist technisch in der Lage, Helligkeitsstufen bis zu 10.000 nits zu repräsentieren. Dolby Vision erfordert, dass die Displays von Content-Autoren eine Spitzenhelligkeit von mindestens 1.000 nits haben. HDR10+ HDR10,+, auch HDR10 Plus genannt, ist ein am 20. April 2017 angekündigtes HDR-Videoformat. Es ist das gleiche wie HDR10but mit einigen dynamischen Metadaten entwickelt von Samsung hinzugefügt. Es ist kostenlos für Content-Autor zu verwenden und hat eine maximale $10.000 jährliche Lizenz für einige Hersteller. Es ist eine Alternative zu Dolby Vision ohne die Gebühren. HLG Format (HLG10) Das HLG-Format, das manchmal als HLG10 bezeichnet wird, ist ein HDR-Format mit der HLG-Transfer-Funktion, Rec. 2020-Farbprimries und eine Bittiefe von 10 Bit. Die HLG-Transfer-Funktion ist rückwärtskompatibel mit SDR-Video, aber der Rec. 2020-Farbraum ist nicht kompatibel mit SDR-Farbraum (Rec.709) Weitere Formate Technicolor Advanced HDR: Ein HDR-Format, das rückwärtskompatibel mit SDR sein soll. Ab dem 19. Dezember 2020 gibt es keinen Inhalt in diesem Format. SL-HDR1 (Single-Layer HDR System Part 1) ist ein HDR-Standard, der gemeinsam von STMicroelectronics, Philips International B.V und Technicolor R&D France entwickelt wurde. Es wurde im August 2016 als ETSI TS 103 433 standardisiert. SL-HDR1 bietet direkte Rückwärtskompatibilität mit statischen (SMPTE ST 2086) und dynamischen Metadaten (mit SMPTE ST 2094-20 Philips und 2094-30 Technicolor-Formaten) zur Rekonstruktion eines HDR-Signals aus einem SDR-Videostrom, der mit SDR-Verteilnetzen und bereits vorhandenen Diensten geliefert werden kann. SL-HDR1 ermöglicht das HDR-Rendern auf HDR-Geräten und SDR-Rendern auf SDR-Geräten mit einem einschichtigen Videostream. Die HDR-Rekonstruktions-Metadaten können entweder HEVC oder AVC mit einer ergänzenden Verbesserungsinformation (SEI)-Nachricht hinzugefügt werden. Version 1.3.1 wurde im März 2020 veröffentlicht.SL-HDR2 SL-HDR3 Vergleich von Videoformaten Hinweisanzeigen Display-Geräte, die in der Lage sind, ein größeres dynamisches Spektrum zu erreichen, wurden seit Jahrzehnten erforscht, vor allem mit Flachbildschirm-Technologien wie Plasma, SED/FED und OLED. Seit Anfang der 2000er Jahre sind TV-Sets mit verbesserter Dynamik und Upscaling bestehender SDR/LDR Video/Broadcast-Inhalte mit Reverse-Ton-Mapping erwartet worden. 2016 wurde die HDR-Konvertierung von SDR-Video als Samsungs HDR+ (in LCD-TV-Sets) und Technicolor SAs HDR Intelligent Tone Management veröffentlicht. Ab 2018 können High-End-Verbraucher-HDR-Anzeigen 1.000 cd/m2 Leuchtdichte, zumindest für eine kurze Dauer oder über einen kleinen Teil des Bildschirms, im Vergleich zu 250-300 cd/m2 für ein typisches SDR-Display erreichen. Videoschnittstellen, die mindestens ein HDR Format unterstützen, umfassen HDMI 2.0a, das im April 2015 veröffentlicht wurde und DisplayPort 1.4, das im März 2016 veröffentlicht wurde. Am 12. Dezember 2016 gab HDMI bekannt, dass Hybrid Log-Gamma (HLG)-Unterstützung zum HDMI 2.0b-Standard hinzugefügt wurde. HDMI 2.1 wurde am 4. Januar 2017 offiziell bekannt gegeben und unterstützt Dynamic HDR, die dynamische Metadaten, die Änderungen von Szene-by-Scene oder Frame-by-frame unterstützt.Vereinbarkeit Ab 2020 ist kein Display in der Lage, den vollen Bereich der Helligkeit und Farbe der HDR-Formate zu machen. Ein Display wird als HDR-Display bezeichnet, wenn es HDR-Inhalte akzeptieren und auf seine Anzeigeeigenschaften abbilden kann. So bietet das HDR-Logo nur Informationen zur Inhaltskompatibilität und nicht zur Anzeigefähigkeit. Zertifizierungen wurden durchgeführt, um den Verbrauchern Informationen über die Anzeigewiedergabefähigkeit eines Bildschirms zu geben. VESA DisplayHDR Der DisplayHDR-Standard von VESA ist ein Versuch, die Unterschiede in HDR-Spezifikationen für die Verbraucher leichter zu verstehen, mit Standards hauptsächlich in Computermonitoren und Laptops verwendet. VESA definiert eine Reihe von HDR-Spiegeln; alle müssen HDR10 unterstützen, aber nicht alle sind erforderlich, um 10-Bit-Anzeigen zu unterstützen. DisplayHDR ist kein HDR-Format, sondern ein Tool, um HDR-Formate und ihre Leistung auf einem bestimmten Monitor zu überprüfen. Der jüngste Standard ist DisplayHDR 1400, die im September 2019 eingeführt wurde, mit Monitoren, die ihn 2020 veröffentlichen. DisplayHDR 1000 und DisplayHDR 1400 werden in erster Linie in professionellen Arbeiten wie Videobearbeitung verwendet. Monitore mit DisplayHDR 500 oder DisplayHDR 600-Zertifizierung bieten eine deutliche Verbesserung gegenüber SDR-Displays und werden häufiger für allgemeines Computing und Gaming verwendet.*Wide Color Gamut, mindestens 90% von DCI-P3 in spezifiziertem Volumen (Spitzenluminanz) Weitere Zertifizierungen UHD Alliance: Ultra HD Premium Mobile HDR Premium: für mobile Geräte. Technische Details HDR wird hauptsächlich durch die Verwendung von PQ- oder HLG-Transferfunktion erreicht. Wide Color Gamut (WCG) wird auch häufig entlang der HDR verwendet. Rec.2020 Farbe Primaries. Ein Bit-Tief von 10 oder 12 Bit wird verwendet, um nicht über den erweiterten Helligkeitsbereich zu streifen. Einige zusätzliche Metadaten werden manchmal verwendet, um die Vielfalt in Displays Helligkeit, Kontrast und Farben zu handhaben. HDR-Video ist in Rec. 2100 definiert. Der Farbraum ITU-R Rec. 2100Rec. 2100 ist eine technische Empfehlung der ITU-R für die Produktion und Verteilung von HDR-Inhalten unter Verwendung von 1080p oder UHD-Auflösung, 10-Bit oder 12-Bit-Farbe, HLG- oder PQ-Transfer-Funktionen, der Rec.2020-Weitfarben-Gamut und YCBCR oder ICTCP als Farbraum. Die Übertragungsfunktion SDR verwendet eine Gamma-Kurvenübertragungsfunktion, die auf den Eigenschaften des CRT basiert und die zur Darstellung von Leuchtstärken bis zu etwa 100 Nits verwendet wird. HDR verwendet neu entwickelte PQ- oder HLG-Transferfunktionen anstelle der traditionellen Gammakurve. Wäre die Gammakurve auf 10.000 Nissen verlängert worden, hätte sie eine Bittiefe von 15 Bit benötigt, um ein Banden zu vermeiden. PQ und HLG sind effizienter. HDR-Transferfunktionen: Perceptual Quantizer (PQ,) oder SMPTE ST 2084 ist eine für HDR entwickelte Transferfunktion, die in der Lage ist, Helligkeitsniveau bis 10.000 cd/m2 darzustellen. Es ist die Basis von HDR-Videoformaten (wie Dolby Vision, HDR10 und HDR10)+ und wird auch für HDR-Bildformate verwendet. PQ ist nicht rückwärtskompatibel mit SDR. PQ kann in 12 Bit codiert werden, ohne eine Bandierung anzuzeigen. Hybrid Log-Gamma (HLG) ist eine Übertragungsfunktion, die vom NHK und BBC entwickelt wird. Es ist rückwärtskompatibel mit der Gammakurve von SDR. Es ist die Grundlage eines HDR-Formats, das auch HLG oder manchmal HLG10 genannt wird.( Das HLG10-Format verwendet Rec.2100 Farbprimries und ist daher nicht rückwärts kompatibel mit allen SDR-Displays). Die HLG-Transfer-Funktion wird auch von anderen Videoformaten wie Dolby Vision Profil 8.4 und für HDR noch Bildformate verwendet. Sowohl PQ als auch HLG sind lizenzfrei. Chromatizität SDR für HD-Video verwendet ein in Rec.709 (gleich als sRGB) spezifiziertes Systemchromatität (chromatizität der Farbprimer und weißer Punkt). SDR für SD verwendet viele verschiedene Primaries, wie in BT.601, SMPTE 170M. HDR ist häufig mit einem Wide Color Gamut verbunden (eine Systemchromatizität breiter als BT.709). Rec.2100 (HDR-TV) verwendet die gleiche System-Chromatizität, die in Rec. 2020 (UHDTV) verwendet wird. HDR-Formate wie HDR10, HDR10,+ Dolby Vision und HLG verwenden auch Rec. 2020-Chromatitäten. HDR-Inhalte werden häufig auf einem DCI-P3-Display eingestuft und dann in einem HDR-Format enthalten, das Rec. 2020-Farbprimries verwendet. Bittiefe Durch den erhöhten Dynamikbereich müssen HDR-Inhalte mehr Bittiefe als SDR verwenden, um ein Banden zu vermeiden. Während SDR eine Bittiefe von 8 oder 10 Bit verwendet, verwendet HDR 10 oder 12 Bit. Dies, kombiniert mit der Verwendung einer effizienteren Übertragungsfunktion (d.h. PQ oder HLG), reicht aus, um Banding zu vermeiden. Das Signalformat Rec. 2100 gibt die Verwendung des RGB, des YCbCr oder der ICTCP-Signalformate für HDR-TV an. ICTCP ist eine Farbdarstellung, die von Dolby für HDR und Wide Color gamut (WCG) entworfen und in Rec standardisiert wurde.2100. IPTPQc2 (oder IPTPQc2) mit Umformung ist ein proprietäres Format von Dolby und ist ähnlich ICTCP. Es wird von Dolby Vision Profil verwendet 5. Metadaten Statische Metadaten Statische HDR-Metadaten geben Informationen über das gesamte Video. SMPTE ST 2086 oder MDCV (Mastering Display Color Volume:) Es beschreibt das Farbvolumen des Mastering-Displays (d.h. die Farbe Primaries, der weiße Punkt und die maximale und minimale Luminanz). Es wurde durch SMPTE und auch in AVC- und HEVC-Standards definiert. MaxFALL (Maximal Frame Durchschnittliche Lichtstufe) MaxCLL (Maximal Content Licht Level) Diese Metadaten beschreiben nicht, wie der HDR-Gehalt an HDR-Verbraucherdisplays angepasst werden soll, die ein geringeres Farbvolumen (d.h. Peakhelligkeit, Kontrast und Farbgamut) aufweisen als der Inhalt. Die Werte von MaxFALL und MaxCLL sollten aus dem Videostream selbst berechnet werden (nicht inklusive schwarzer Grenzen für MaxFALL), basierend darauf, wie die Szenen auf dem Mastering-Display erscheinen. Es wird nicht empfohlen, sie willkürlich zu setzen. Dynamische Metadaten Dynamische Metadaten sind für jeden Frame oder jede Szene des Videos spezifisch. Dynamische Metadaten von Dolby Vision, HDR10+ und SMPTE ST 2094 beschreiben, welche Farbvolumentransformation auf Inhalten angewendet werden soll, die auf Displays gezeigt werden, die unterschiedliche Farbvolumen aus dem Mastering-Display aufweisen. Es ist für jede Szene und jedes Display optimiert. Es ermöglicht, dass die kreativen Absichten auch auf Verbraucher-Displays erhalten werden, die begrenzte Farbvolumen haben. SMPTE ST 2094 oder Dynamic Metadata for Color Volume Transform (DMCVT) ist ein Standard für dynamische Metadaten, die 2016 von SMPTE als sechs Teile veröffentlicht wurden. Es wird in HEVC SEI, ETSI TS 103 433, CTA 861-G getragen. Es umfasst vier Anwendungen: ST 2094-10 (von Dolby), die für Dolby Vision verwendet werden. ST 2094-20 (von Philips). Colour Volume Reconstruction Information (CVRI) basiert auf ST 2094-20.ST 2094-30 (von Technicolor). Colour Remapping Information (CRI) entspricht ST 2094-30 und ist in HEVC.ST 2094-40 (von Samsung) für HDR10+ standardisiert. ETSI TS 103 572:Eine technische Spezifikation, die am Oktober 2020 von ETSI für HDR-Signalisierung und Schlitten von ST 2094-10 (Dolby Vision) Metadaten veröffentlicht wurde. Zweischichtiges Video Einige Dolby Vision-Profile verwenden ein Dual-Layer-Video aus einer Basisschicht und einer Verstärkungsschicht. Je nach Dolby Vision-Profil (oder Kompatibilitätsstufe) kann die Basisschicht rückwärtskompatibel mit SDR, HDR10, HLG, UHD Blu-ray sein (dies gilt vor allem für bestimmte Aspekte der Videocodierung, das HDR-Format ist HDR10 und erfordert die entsprechenden Informationen vorhanden) oder kein anderes Format. ETSI GS CCM 001 beschreibt eine Compound Content Management-Funktionalität für ein zweischichtiges HDR-System. Adoption Richtlinien Ultra HD Forum Richtlinien UHD Phase A sind Richtlinien aus dem Ultra HD Forum für die Verteilung von SDR und HDR-Inhalte mit Full HD 1080p und 4K UHD Auflösungen. Es benötigt eine Farbtiefe von 10 Bit pro Probe, eine Farbskala von Rec.709 oder Rec.2020, eine Rahmenrate von bis zu 60 fps, eine Displayauflösung von 1080p oder 2160p und entweder einen Standard-Dynamikbereich (SDR) oder einen hohen Dynamikbereich, der Hybrid Log-Gamma (HLG) oder Perceptual Quantizer (PQ) Transferfunktionen verwendet. UHD Phase Ein definiert HDR als einen dynamischen Bereich von mindestens 13 Anschlägen (213=8192:1) und WCG als Farbwand, die breiter als Rec.709 ist. UHD Phase Ein Verbrauchergerät ist mit HDR10-Anforderungen kompatibel und kann den Farbraum Rec. 2020 und HLG oder PQ bei 10 Bit verarbeiten. UHD Phase B wird Unterstützung zu 120 fps (und 120/1.001 fps,) 12 Bit PQ in HEVC Main12 (das wird genug für 0,0001 bis 10000 Nits sein), Dolby AC-4 und MPEG-H 3D Audio, IMAX Sound in DTS:X (ohne LFE). Es wird auch ITU ICtCp und Color Remapping Information (CRI.) Videoindustrie Gaming-Branche Noch Bilder HDR-Bildformate Die folgenden Bildformate sind mit HDR kompatibel (Rec.2100 Farbraum, PQ und HLG Transferfunktionen, Rec.2100/Rec.2020 Farbe Primaries:) HEIC (HEVC-Codec im HEIF-Dateiformat) AVIF (AV1-Codec im HEIF-Dateiformat,) unterstützt auch ICTCP JPEG XL HSP (ein Format, das von Panasonic-Kameras für die Fotoerfassung in HDR mit der HLG-Transferfunktion verwendet wird) JPEG 2000, PNG, WebP,JPEG unterstützen es auch durch die Verwendung von ICC-Profil Adoption von HDR in stillen von Panasonic: Panasonic: Die erfassten HDR-Bilder können in HDR gesehen werden, indem die Kamera an ein HLG-konformes Display mit einem HDMI-Kabel angeschlossen wird. Canon: EOS-1D X Mark III und EOS R5 können mit der PQ-Transfer-Funktion, dem HEIC-Format (HEVC-Codec im HEIF-Dateiformat,) die Rec. 2020-Farbprimries, eine Bittiefe von 10 Bit und Subsampling 4:2 YCbCr erfassen.Die erfassten HDR-Bilder können in HDR angesehen werden, indem die Kamera mit einem HDMI-Kabel an ein HDR-Display angeschlossen wird. Gefangene HDR-Bilder können auch in SDR JPEG (sRGB-Farbraum) umgewandelt und dann auf jedem Standard-Display betrachtet werden. Canon bezieht sich auf die SDR-Bilder als "HDR PQ-like JPEG". Canons Digital Photo Professional Software ist in der Lage, die erfassten HDR-Bilder in HDR auf HDR-Displays oder in SDR auf SDR-Displays anzuzeigen. Es ist auch in der Lage, das HDR PQ in SDR sRGB JPEG zu konvertieren. Sony: Sony α7S III und α1 Kameras können HDR-Fotos im Rec.2100-Farbraum mit der HLG-Transfer-Funktion, dem HEIF-Format, Rec. 2020-Farbprimries, ein bisschen Tiefe von 10 Bit und ein 4:2:2 oder 4:2:0-Subsampling erfassen. Die erfassten HDR-Bilder können in HDR gesehen werden, indem die Kamera an ein HLG-konformes Display mit einem HDMI-Kabel angeschlossen wird. Qualcomm:Snapdragon 888 mobile SoC ermöglicht die Erfassung von 10-Bit HDR HEIF noch Fotos. Web Work ist bei W3C im Gange, um Web mit HDR kompatibel zu machen. Dazu gehören: HDR-Fähigkeitserkennung HDR in CSS History Andere HDR-Technologien Im Februar und April 1990 stellte Georges Cornuéjols die erste Echtzeit-HDR-Kamera vor, die zwei nacheinander oder gleichzeitig aufgenommene Bilder kombiniert. 1991 wurde die erste kommerzielle Videokamera mit Sensoren und Kameras von verbrauchergerechter Qualität eingeführt, die Echtzeit-Aufnahme von mehreren Bildern mit unterschiedlichen Belichtungen durchgeführt und ein HDR-Videobild von Hymatom, Lizenznehmer von Cornuéjols, produzierte. Auch 1991 führte Cornuéjols das Prinzip der nicht linearen Bildakkumulation HDR+ ein, um die Kameraempfindlichkeit zu erhöhen: In leichten Umgebungen werden mehrere aufeinanderfolgende Bilder angesammelt und das Signal-Rausch-Verhältnis erhöht. Später nutzten in den frühen 2000er Jahren mehrere wissenschaftliche Forschungsanstrengungen Sensoren und Kameras der Verbraucherklasse. Einige Unternehmen wie RED und Arri entwickeln digitale Sensoren, die zu einem höheren Dynamikbereich fähig sind. RED EPIC-X kann zeitlich aufeinanderfolgende HDRx-Bilder mit einem anwender selektierbaren 1–3 Stopps zusätzlicher Highlight-Länge im x-Kanal erfassen. Der x-Kanal kann in der Postproduktionssoftware mit dem normalen Kanal zusammengeführt werden. Die Arri Alexa Kamera nutzt eine Dual-Gang-Architektur, um ein HDR-Bild aus zwei gleichzeitig erfassten Belichtungen zu erzeugen. Mit dem Aufkommen von kostengünstigen Verbraucher-Digitalkameras begannen viele Amateure, Ton-mapped HDR Zeitraffer-Videos im Internet zu posten, im Wesentlichen eine Folge von immer noch Fotografien in kurzer Folge. Im Jahr 2010 produzierte die unabhängige Studio sowjetische Montage ein Beispiel von HDR-Video aus disparately exponierten Videostreams mit einem Strahlteiler und HD-Videokameras der Verbraucherklasse. Ähnliche Methoden wurden 2001 und 2007 in der akademischen Literatur beschrieben. Moderne Filme wurden oft mit Kameras mit einem höheren Dynamikbereich gefilmt, und ältere Filme können auch dann umgewandelt werden, wenn manuelle Eingriffe für einige Frames erforderlich wären (wie bei der Umwandlung von Schwarz-Weiß-Filmen in Farbe). Auch spezielle Effekte, insbesondere solche, die echte und synthetische Aufnahmen mischen, erfordern sowohl HDR-Shooting als auch Rendering. HDR-Video wird auch in Anwendungen benötigt, die eine hohe Genauigkeit erfordern, um zeitliche Aspekte von Veränderungen in der Szene zu erfassen. Dies ist wichtig bei der Überwachung einiger industrieller Prozesse wie Schweißen, in vorausschauenden Fahrerassistenzsystemen in der Automobilindustrie, in Überwachungsvideosystemen und anderen Anwendungen. HDR-Video kann auch als Geschwindigkeitsbilderfassung in Anwendungen angesehen werden, die eine Vielzahl statischer HDR-Bilder benötigen, beispielsweise in bildbasierten Methoden in Computergrafiken. OpenEXR wurde 1999 von Industrial Light & Magic (ILM) erstellt und 2003 als Open Source-Software-Bibliothek veröffentlicht. OpenEXR wird für die Film- und Fernsehproduktion verwendet. Academy Color Encoding System (ACES) wurde von der Academy of Motion Picture Arts and Sciences erstellt und im Dezember 2014 veröffentlicht. ACES ist ein komplettes Farb- und Dateimanagement-System, das mit fast jedem professionellen Workflow arbeitet und sowohl HDR als auch Wide Color gamut unterstützt. Weitere Informationen finden Sie unter https://www.ACESCentral.com (WCG.) HDR-Technologie im Zusammenhang mit HDR-Displays Am Mai 2003 hat BrightSide Technologies das erste HDR-Display auf dem Display Week Symposium der Society for Information Display gezeigt. Das Display verwendet eine Reihe von individuell gesteuerten LEDs hinter einem herkömmlichen LCD-Panel in einer heute als "lokales Dimmen" bekannten Konfiguration. BrightSide führte später eine Vielzahl von verwandten Display- und Videotechnologien ein, die die Visualisierung von HDR-Inhalten ermöglichen. Am April 2007 wurde BrightSide Technologies von Dolby Laboratories erworben und wurde die Grundlage für den Einstieg in Videotechnologien von Dolby Vision.Dolby Laboratories kündigte am Januar 2014 Dolby Vision an. Die HEVC Spezifikation enthält das Main 10 Profil auf ihrer ersten Version, die 10 Bit pro Probe unterstützt. Am 8. April 2015 veröffentlichte das HDMI Forum die Version 2.0a der HDMI-Spezifikation, um die Übertragung von HDR zu ermöglichen. Die Spezifikation verweist auf CEA-861.3, die wiederum auf den Perceptual Quantizer (PQ), der als SMPTE ST 2084 standardisiert wurde, verweist. Die vorherige HDMI 2.0 Version unterstützte bereits den Farbraum Rec. 2020. Am 24. Juni 2015 war Amazon Video der erste Streaming-Service, der HDR-Video mit HDR10 Media Profile Video anbietet. Am 27. August 2015 kündigte die Consumer Technology Association HDR10 an.Am 17. November 2015 gab Vudu bekannt, dass sie in Dolby Vision Titel anbieten konnten. Am 1. März 2016 veröffentlichte die Blu-ray Disc Association Ultra HD Blu-ray mit verbindlicher Unterstützung für HDR10 Media Profile Video und optionaler Unterstützung für Dolby Vision. Am 9. April 2016 startete Netflix sowohl HDR10 Media Profile Video als auch Dolby Vision. Am 6. Juli 2016 kündigte die International Telecommunication Union (ITU) Rec. 2100 an, die zwei HDR Transferfunktionen definiert –HLG und PQ.Am 29. Juli 2016, SKY Perfect JSAT Die Gruppe gab bekannt, dass sie am 4. Oktober die weltweit ersten 4K HDR-Übertragungen mit HLG starten werden. Am 9. September 2016 kündigte Google Android TV 7.0 an, die Dolby Vision, HDR10 und HLG unterstützt. Am 26. September 2016 gab Roku bekannt, dass die Roku Premiere+ und Roku Ultra HDR mit HDR10 unterstützen werden. Am 7. November 2016 kündigte Google an, dass YouTube HDR-Videos streamen würde, die mit HLG oder PQ codiert werden können. Am 17. November 2016 genehmigte das Digital Video Broadcasting (DVB) Steering Board UHD-1 Phase 2 mit einer HDR-Lösung, die Hybrid Log-Gamma (HLG) und Perceptual Quantizer (PQ) unterstützt. Die Spezifikation wurde als DVB Bluebook A157 veröffentlicht und wird von der ETSI als TS 101 154 v2.3.1. veröffentlicht. Am 2. Januar 2017 kündigte LG Electronics USA an, dass alle LG SUPER UHD TV-Modelle nun eine Vielzahl von HDR-Technologien unterstützen, darunter Dolby Vision, HDR10 und HLG (Hybrid Log Gamma), und sind bereit, Advanced HDR von Technicolor zu unterstützen. Am 20. April 2017 kündigten Samsung und Amazon HDR10+ an. Am 12. September 2017 kündigte Apple den Apple TV 4K mit Unterstützung für HDR10 und Dolby Vision an und dass der iTunes Store 4K HDR-Inhalte verkaufen und mieten würde. Am 13. Oktober 2020 kündigte Apple die iPhone 12 und iPhone 12 Pro Serie an, das erste Smartphone, das Video in Dolby Vision direkt in der Kamerarolle auf Frame-by-frame-Basis aufnehmen und bearbeiten kann. I Telefon verwendet HLG-kompatibles Profil 8 von Dolby Vision mit nur L1 Blende. Siehe auch Hochdynamischer Bereich Gammakorrektur Rec.2100 Weitere Informationen Wir müssen über HDR von Yoeri Geutskens Referenzen Externe Links ITU-R Rep.BT.2390 sprechen "High Dynamic Rang TV für Produktion und internationalen Programmaustausch", ein Bericht der ITU, der Hintergrundinformationen über HDR im Allgemeinen und für die perzeptuelle Quantisierung (PQ) und hybrid log–gamma (HLG)HDR Signalparameter in der Rec2100