Parallel Computing ist eine Art Berechnung, bei der viele Berechnungen oder Prozesse gleichzeitig durchgeführt werden. Große Probleme können oft in kleinere aufgeteilt werden, die dann gleichzeitig gelöst werden können. Es gibt mehrere verschiedene Formen des Parallel Computing: Bit-Level, Befehlsebene, Daten und Aufgabenparallelismus. Parallelismus ist seit langem im Hochleistungs-Computing eingesetzt, hat aber aufgrund der physikalischen Zwänge, die Frequenzskalierung verhindern, ein breiteres Interesse erlangt. Da der Stromverbrauch (und damit die Wärmeerzeugung) von Computern in den letzten Jahren zu einem Anliegen geworden ist, ist Parallel Computing zum dominanten Paradigma in der Computerarchitektur geworden, vor allem in Form von Multi-Core-Prozessoren. Parallel Computing ist eng mit dem gleichzeitigen Computing verbunden – sie werden häufig zusammen verwendet und oft konfilatiert, obwohl die beiden deutlich sind: Es ist möglich, Parallelismus ohne Konkurrenz (z.B. Bit-Level-Parallelismus) und Konkurrenz ohne Parallelismus (z.B. Multitasking by Timesharing on a singlecore CPU) zu haben. Bei der Parallel-Computing wird typischerweise eine Rechenaufgabe in mehrere, oft viele, sehr ähnliche Teilaufgaben zerlegt, die unabhängig verarbeitet werden können und deren Ergebnisse nach Fertigstellung nachträglich kombiniert werden. Im Gegensatz dazu adressieren die verschiedenen Prozesse bei der gleichzeitigen Berechnung häufig keine damit zusammenhängenden Aufgaben; wenn sie, wie bei der verteilten Berechnung üblich, die separaten Aufgaben unterschiedlicher Art sind und häufig eine interprozessbezogene Kommunikation während der Ausführung erfordern. Parallelrechner können grob nach dem Niveau klassifiziert werden, auf dem die Hardware Parallelität unterstützt, mit Multicore- und Multiprozessor-Computern mit mehreren Verarbeitungselementen innerhalb einer einzigen Maschine, während Cluster, MPPs und Gitter mehrere Computer zur Arbeit an derselben Aufgabe verwenden. Spezielle parallele Computerarchitekturen werden manchmal neben traditionellen Prozessoren verwendet, um spezifische Aufgaben zu beschleunigen. In manchen Fällen ist der Parallelismus für den Programmierer transparent, z.B. in Bit- oder Instruktionsebenenparallelismus, aber explizit parallele Algorithmen, insbesondere solche, die Koncurrenz verwenden, sind schwieriger zu schreiben als sequentielle, weil die Koncurrenz mehrere neue Klassen potenzieller Software-Bugs einführt, von denen die Race-Bedingungen am häufigsten sind. Kommunikation und Synchronisation zwischen den verschiedenen Subtasks sind in der Regel einige der größten Hindernisse, um eine optimale parallele Programmleistung zu erhalten. Eine theoretische Obergrenze, die durch Parallelisierung auf die Beschleunigung eines einzelnen Programms begrenzt wird, wird durch Amdahls Gesetz gegeben. Hintergrund Traditionell wurde Computersoftware für die serielle Berechnung geschrieben. Um ein Problem zu lösen, wird ein Algorithmus als serieller Befehlsstrom aufgebaut und implementiert. Diese Anweisungen werden auf einer zentralen Verarbeitungseinheit auf einem Computer ausgeführt. Nur eine Anweisung kann zu einem Zeitpunkt ausgeführt werden – nachdem diese Anweisung beendet ist, wird die nächste ausgeführt. Parallel Computing hingegen verwendet mehrere Bearbeitungselemente gleichzeitig, um ein Problem zu lösen. Dies wird dadurch erreicht, dass das Problem in unabhängige Teile zerlegt wird, so dass jedes Verarbeitungselement seinen Teil des Algorithmus gleichzeitig mit den anderen ausführen kann. Die Verarbeitungselemente können vielfältig sein und Ressourcen wie einen einzigen Computer mit mehreren Prozessoren, mehrere vernetzte Computer, spezialisierte Hardware oder jede Kombination der oben genannten umfassen. Historisch paralleles Computing wurde für die wissenschaftliche Berechnung und Simulation von wissenschaftlichen Problemen, insbesondere in den Natur- und Ingenieurwissenschaften, wie Meteorologie, verwendet. Dies führte zum Design von parallelen Hardware und Software sowie High Performance Computing. Die Frequenzskalierung war der Hauptgrund für Verbesserungen der Computerleistung von Mitte der 1980er bis 2004. Die Laufzeit eines Programms ist gleich der Anzahl der Anweisungen multipliziert mit der durchschnittlichen Zeit pro Anleitung. Alles andere konstant zu halten, erhöht die Taktfrequenz die durchschnittliche Zeit, die es braucht, um eine Anweisung auszuführen. Eine Frequenzerhöhung verringert somit die Laufzeit für alle rechnergebundenen Programme. Stromverbrauch P durch einen Chip wird durch die Gleichung P = C x V 2 × F gegeben, wobei C die Kapazität pro Takt (proportional zur Anzahl der Transistoren, deren Eingänge sich ändern,) V eine Spannung ist, und F die Prozessorfrequenz (Zyklen pro Sekunde) ist. Erhöht die Frequenz erhöhen die Menge der Leistung in einem Prozessor verwendet. Die zunehmende Leistungsaufnahme des Prozessors führte letztlich zu Intels 8. Mai 2004 Aufhebung seiner Tejas und Jayhawk Prozessoren, die im Allgemeinen als Ende der Frequenzskalierung als dominante Computerarchitektur Paradigma genannt wird. Um das Problem der Stromverbrauch und Überhitzung der großen zentralen Verarbeitungseinheit (CPU oder Prozessor) Hersteller begann, leistungseffiziente Prozessoren mit mehreren Kernen zu produzieren. Der Kern ist die Recheneinheit des Prozessors und in Multi-Core-Prozessoren ist jeder Kern unabhängig und kann gleichzeitig auf denselben Speicher zugreifen. Multi-Core-Prozessoren haben Parallel-Computing auf Desktop-Computer gebracht. So ist die Parallelisierung von seriellen Programmen zu einem Hauptprogrammierungsvorgang geworden. Im Jahr 2012 wurden Quad-Core-Prozessoren Standard für Desktop-Computer, während Server haben 10 und 12 Kern-Prozessoren. Aus Moore's Gesetz kann vorhergesagt werden, dass die Anzahl der Kerne pro Prozessor alle 18-24 Monate verdoppeln wird. Dies könnte bedeuten, dass nach 2020 ein typischer Prozessor Dutzende oder Hunderte von Kernen haben wird. Ein Betriebssystem kann sicherstellen, dass verschiedene Aufgaben und Benutzerprogramme parallel auf den verfügbaren Kernen laufen. Für ein serielles Softwareprogramm, um die Multicore-Architektur voll auszunutzen, muss der Programmierer den Code neu strukturieren und parallelisieren. Eine Beschleunigung der Anwendungssoftwarelaufzeit wird nicht mehr durch Frequenzskalierung erreicht, sondern Programmierer müssen ihren Softwarecode parallelisieren, um die zunehmende Rechenleistung von Multicore-Architekturen zu nutzen. Amdahls Gesetz und Gustafsons Gesetz Optimal wäre die Beschleunigung aus der Parallelisierung linear - die Verdoppelung der Anzahl der Bearbeitungselemente sollte die Laufzeit halbieren und ein zweites Mal die Laufzeit wieder verdoppeln. Allerdings erreichen sehr wenige parallele Algorithmen eine optimale Beschleunigung. Die meisten von ihnen haben eine nahezu lineare Beschleunigung für kleine Anzahl von Bearbeitungselementen, die für große Anzahl von Bearbeitungselementen in einen konstanten Wert abflacht. Die mögliche Beschleunigung eines Algorithmus auf einer parallelen Rechenplattform wird durch Amdahls Gesetz S latency (s ) = 1 - p + p s, {\displaystyle S_{\text{latency}}(s)={\frac 1}{1-p+{\frac p}{s, wobei Slatency die Potentialverzögerung bei der Ausführung der gesamten Aufgabe ist; s die Verlangsamung der Ausführung des parallelisierbaren Teils der Aufgabe; p ist der Prozentsatz der Ausführungszeit der gesamten Aufgabe über den parallelisierbaren Teil der Aufgabe vor der Parallelisierung. Da Slatency < 1/(1 - p) zeigt, daß ein kleiner Teil des Programms, der nicht parallelisiert werden kann, die Gesamtgeschwindigkeit der Parallelisierung begrenzt. Ein Programm, das ein großes mathematisches oder technisches Problem löst, besteht typischerweise aus mehreren parallelisierbaren Teilen und mehreren nicht-parallelisierbaren (serialen) Teilen. Wenn der nicht-parallelisierbare Teil eines Programms 10% der Laufzeit (p = 0,9) ausmacht, können wir nicht mehr als ein 10-faches Speedup bekommen, unabhängig davon, wie viele Prozessoren hinzugefügt werden. Dies setzt eine Obergrenze für die Nutzbarkeit der Addition von paralleleren Ausführungseinheiten. " Wenn eine Aufgabe nicht durch sequentielle Zwänge verteilt werden kann, hat die Anwendung von mehr Aufwand keinen Einfluss auf den Zeitplan. Das Lager eines Kindes dauert neun Monate, egal wie viele Frauen vergeben werden." Amdahls Gesetz gilt nur für Fälle, in denen die Problemgröße festgelegt ist. In der Praxis, da mehr Rechenressourcen zur Verfügung stehen, neigen sie dazu, sich auf größere Probleme (größere Datensätze) zu verwenden und die Zeit im parallelisierbaren Teil oft viel schneller wächst als die inhärent serielle Arbeit. In diesem Fall gibt Gustafsons Gesetz eine weniger pessimistische und realistischere Bewertung der Parallelleistung: S latency (s ) = 1 − p + s p . {\displaystyle S_{\text{latency}}(s)=1-p+sp. Sowohl Amdahls Gesetz als auch Gustafsons Gesetz gehen davon aus, dass die Laufzeit des seriellen Teils des Programms unabhängig von der Anzahl der Prozessoren ist. Amdahls Gesetz geht davon aus, dass das gesamte Problem von fester Größe ist, so dass die gesamte parallel zu leistende Arbeit auch unabhängig von der Anzahl der Prozessoren ist, während Gustafsons Gesetz davon ausgeht, dass die Gesamtarbeitsmenge parallel linear mit der Anzahl der Prozessoren variiert. Dependencies Das Verständnis von Datenabhängigkeiten ist grundlegend bei der Umsetzung von parallelen Algorithmen. Kein Programm kann schneller laufen als die längste Kette von abhängigen Berechnungen (bekannt als der kritische Pfad), da Berechnungen, die von vorherigen Berechnungen in der Kette abhängen, ausgeführt werden müssen, um. Die meisten Algorithmen bestehen jedoch nicht nur aus einer langen Kette von abhängigen Berechnungen; es gibt in der Regel Möglichkeiten, unabhängige Berechnungen parallel auszuführen. Lassen Sie Pi und Pj zwei Programmsegmente sein. Bernsteins Bedingungen beschreiben, wann die beiden unabhängig sind und parallel ausgeführt werden können. Für Pi, lass I i alle Eingangsvariablen und Oi die Ausgangsvariablen sein, und ebenso für Pj.Pi und Pj sind unabhängig, wenn sie I j ・ O i = Σ, {\displaystyle I_{j}\cap O_{i}=\varnothing ,} I i С O j = Σ Σ, {\displaystyle I_{i}\cap O_{j}=\varnothing } O i С O j = =0. {\displaystyle O O_{j}=\varnothing .} Eine Verletzung der ersten Bedingung führt eine Strömungsabhängigkeit ein, die dem ersten Segment entspricht, das ein Ergebnis des zweiten Segments erzeugt. Die zweite Bedingung stellt eine Antiabhängigkeit dar, wenn das zweite Segment eine vom ersten Segment benötigte Größe erzeugt. Die dritte und letzte Bedingung stellt eine Ausgangsabhängigkeit dar: Wenn zwei Segmente an dieselbe Stelle schreiben, kommt das Ergebnis aus dem logisch letzten ausgeführten Segment. Betrachten Sie die folgenden Funktionen, die mehrere Arten von Abhängigkeiten zeigen: 1: Funktion Dep(a, b) 2: c := a * b 3: d := 3 * c 4: Endfunktion In diesem Beispiel kann die Anweisung 3 vor (oder sogar parallel zu) der Anweisung 2 nicht ausgeführt werden, da die Anweisung 3 ein Ergebnis aus der Anweisung 2 verwendet. Sie verletzt den Zustand 1 und führt somit eine Strömungsabhängigkeit ein. 1: Funktion NoDep(a, b) 2: c := a * b 3: d := 3 * b 4: e := a + b 5: Endfunktion In diesem Beispiel gibt es keine Abhängigkeiten zwischen den Anweisungen, so dass sie alle parallel laufen können. Bernsteins Bedingungen erlauben es nicht, Speicher zwischen verschiedenen Prozessen zu teilen. Dazu sind einige Mittel zur Durchsetzung einer Bestellung zwischen Zugriffen notwendig, wie z.B. Semaphoren, Barrieren oder andere Synchronisationsverfahren. Race Bedingungen, gegenseitiger Ausschluss, Synchronisation und parallele Verlangsamung Subtasks in einem parallelen Programm werden oft Threads genannt. Einige parallele Computerarchitekturen verwenden kleinere, leichte Versionen von Fäden, die als Fasern bekannt sind, während andere größere Versionen als Prozesse verwenden. Fäden werden jedoch allgemein als allgemeiner Begriff für Subtasks akzeptiert. Threads benötigen häufig einen synchronisierten Zugriff auf ein Objekt oder eine andere Ressource, beispielsweise wenn sie eine Variable aktualisieren müssen, die zwischen ihnen geteilt wird. Ohne Synchronisation können die Anweisungen zwischen den beiden Fäden in beliebiger Reihenfolge vertauscht werden. Betrachten Sie beispielsweise das folgende Programm: Wird die Anweisung 1B zwischen 1A und 3A ausgeführt oder wird die Anweisung 1A zwischen 1B und 3B ausgeführt, so wird das Programm falsche Daten erzeugen. Dies ist als Rassenbedingung bekannt. Der Programmierer muss ein Schloss verwenden, um gegenseitigen Ausschluss zu ermöglichen. Ein Schloss ist ein Programmiersprachen-Konstrukt, das es einem Thread erlaubt, die Steuerung einer Variable zu übernehmen und das Lesen oder Schreiben anderer Threads zu verhindern, bis diese Variable entriegelt ist. Der Faden, der das Schloss hält, ist frei, seinen kritischen Abschnitt auszuführen (der Abschnitt eines Programms, der ausschließlichen Zugriff auf einige Variablen erfordert), und die Daten zu entsperren, wenn es fertig ist. Um eine korrekte Programmausführung zu gewährleisten, kann das obige Programm neu geschrieben werden, um Schlösser zu verwenden: Ein Faden wird die Variable V erfolgreich verriegeln, während der andere Faden verriegelt wird - bis V wieder entriegelt ist. Dies garantiert eine korrekte Ausführung des Programms. Schlösser können erforderlich sein, um eine korrekte Programmausführung zu gewährleisten, wenn Threads den Zugriff auf Ressourcen seriellisieren müssen, aber ihre Verwendung kann ein Programm stark verlangsamen und seine Zuverlässigkeit beeinträchtigen. Die Sperrung mehrerer Variablen mit nicht-atomischen Schlössern führt die Möglichkeit des Programms Totlock. Ein atomares Schloss sperrt mehrere Variablen auf einmal. Wenn sie nicht alle sperren können, sperrt sie keinen von ihnen. Wenn zwei Threads jeweils die gleichen beiden Variablen mit nicht-atomischen Schlössern verriegeln müssen, ist es möglich, dass ein Gewinde einen von ihnen verriegelt und das zweite Gewinde die zweite Variable verriegelt. In einem solchen Fall kann weder Faden vervollständigen, und Totlock Ergebnisse. Viele parallele Programme erfordern, dass ihre Subtasks synchron wirken. Dies erfordert die Verwendung einer Barriere. Barrieren werden typischerweise mit einem Schloss oder einem Semaphor realisiert. Eine Klasse von Algorithmen, bekannt als sperrfreie und wartungsfreie Algorithmen, vermeidet den Einsatz von Schlössern und Barrieren. Dieser Ansatz ist jedoch in der Regel schwierig zu implementieren und erfordert korrekt gestaltete Datenstrukturen. Nicht alle Parallelisierungen führen zu einer Beschleunigung. In der Regel, da eine Aufgabe in immer mehr Threads aufgeteilt wird, verbringen diese Threads einen immer größer werdenden Teil ihrer Zeit miteinander kommunizieren oder aufeinander warten, um Zugang zu Ressourcen zu erhalten. Sobald der Overhead aus Ressourceninhalt oder Kommunikation die Zeit für andere Berechnungen dominiert, erhöht sich die weitere Parallelisierung (d.h. die Aufteilung der Arbeitslast über noch mehr Threads) anstatt die Zeit, die erforderlich ist, um zu beenden. Dieses Problem, bekannt als Parallelverlangsamung, kann in einigen Fällen durch Softwareanalyse und Neugestaltung verbessert werden. Feinkörnige, grobkörnige und peinliche Parallelität Anwendungen werden oft so eingestuft, wie oft ihre Subtasks miteinander synchronisieren oder kommunizieren müssen. Eine Anwendung weist feinkörnige Parallelität auf, wenn ihre Subtasken oft pro Sekunde kommunizieren müssen; sie zeigt grobkörnige Parallelität, wenn sie nicht oft pro Sekunde kommunizieren, und sie zeigt peinliche Parallelität, wenn sie selten oder nie kommunizieren müssen. Als einfachste Parallelisierung gelten verblüffend parallele Anwendungen. Flynns Taxonomie Michael J. Flynn schuf eines der frühesten Klassifikationssysteme für parallele (und sequentielle) Computer und Programme, jetzt bekannt als Flynns Taxonomie. Flynn klassifizierte Programme und Computer, ob sie mit einem einzigen Satz oder mehreren Sätzen von Anweisungen betrieben wurden, und ob diese Anweisungen einen einzigen Satz oder mehrere Datensätze verwendet haben. Die Ein-Instruction-Single-data (SISD)-Klassifikation entspricht einem vollständig sequentiellen Programm. Die Ein-Instruction-multiple-data (SIMD)-Klassifikation ist analog, den gleichen Betrieb wiederholt über einen großen Datensatz zu tun. Dies geschieht üblicherweise in Signalverarbeitungsanwendungen. Multiple-Instruction-single-data (MISD) ist eine selten verwendete Klassifizierung. Während Computerarchitekturen dazu entwickelt wurden (wie z.B. systolische Arrays), wenige Anwendungen, die dieser Klasse passen materialisiert. Multiple-Instruction-multiple-data (MIMD) Programme sind bei weitem die häufigste Art von parallelen Programmen. Laut David A. Patterson und John L. Hennessy, "Einige Maschinen sind Hybriden dieser Kategorien, aber dieses klassische Modell hat überlebt, weil es einfach, leicht zu verstehen ist und gibt eine gute erste Annäherung. Es ist auch – durch seine Verständlichkeit – das am weitesten verbreitete Schema.“ Arten des Parallelismus Bit-Ebene Parallelismus Vom Erscheinen der sehr großen Integration (VLSI) Computerchip-Fertigungstechnologie in den 1970er-Jahren bis etwa 1986 wurde die Beschleunigung in der Computerarchitektur durch Verdoppelung der Computerwortgröße angesteuert – die Menge der Informationen, die der Prozessor pro Zyklus manipulieren kann. Die Erhöhung der Wortgröße verringert die Anzahl der Anweisungen, die der Prozessor ausführen muss, um eine Operation auf Variablen durchzuführen, deren Größen größer sind als die Länge des Wortes. Wenn beispielsweise ein 8-Bit-Prozessor zwei 16-Bit-Integer hinzufügen muss, muss der Prozessor zunächst die 8 niederen Ordnungs-Bits aus jeder Ganzzahl unter Verwendung der Standard-Additionsanweisung hinzufügen, dann die 8 höherwertigen Bits unter Verwendung einer Add-with-Instruktion und des Übertrags-Bits aus der unteren Reihenfolge hinzufügen; so benötigt ein 8-Bit-Prozessor zwei Anweisungen, um einen einzigen Vorgang abzuschließen, wo ein 16-Prozessor in der Operation abgeschlossen werden könnte. Historisch wurden 4-Bit-Mikroprozessoren durch 8-Bit, dann 16-Bit, dann 32-Bit-Mikroprozessoren ersetzt. Dieser Trend endete im Allgemeinen mit der Einführung von 32-Bit-Prozessoren, die seit zwei Jahrzehnten ein Standard im Universal-Computing war. Erst in den frühen 2000er Jahren, mit dem Aufkommen von x86-64 Architekturen, wurden 64-Bit Prozessoren gemeinsam. Anweisungsebene Parallelismus Ein Computerprogramm ist im Wesentlichen ein Befehlsstrom, der von einem Prozessor ausgeführt wird. Ohne Instruktionsebene kann ein Prozessor nur weniger als eine Instruktion pro Taktzyklus ausgeben (IPC < 1). Diese Prozessoren sind als Subscalar-Prozessoren bekannt. Diese Instruktionen können wieder bestellt und zu Gruppen zusammengefasst werden, die dann parallel ausgeführt werden, ohne das Programmergebnis zu ändern. Dies ist als Instruktionsebene Parallelismus bekannt. Die Fortschritte in der Lehrebene dominierten die Computerarchitektur von Mitte der 1980er bis Mitte der 1990er Jahre. Alle modernen Prozessoren verfügen über mehrstufige Anweisungspipelines. Jede Stufe in der Pipeline entspricht einer anderen Wirkung, die der Prozessor in dieser Stufe auf diese Weise durchführt; ein Prozessor mit einer N-Stufe-Pipeline kann bis zu N unterschiedliche Anweisungen in verschiedenen Stufen der Fertigstellung haben und somit eine Anweisung pro Taktzyklus ausgeben (IPC = 1). Diese Prozessoren sind als Skalarprozessoren bekannt. Das kanonische Beispiel eines Pipeline-Prozessors ist ein RISC-Prozessor, mit fünf Stufen: Befehls-Fetch (IF,) Befehlsdecodierung (ID,) ausführen (EX,) Speicherzugriff (MEM,) und registrieren Sie Zurückschreiben (WB). Der Pentium 4 Prozessor hatte eine 35-stufige Pipeline. Die meisten modernen Prozessoren haben auch mehrere Ausführungseinheiten. Sie kombinieren diese Funktion in der Regel mit Pipelining und können so mehr als eine Anweisung pro Taktzyklus ausgeben (IPC > ANHANG Diese Prozessoren sind als Superscalar-Prozessoren bekannt. Superscalar-Prozessoren unterscheiden sich von Multicore-Prozessoren dadurch, dass die mehreren Ausführungseinheiten nicht ganze Prozessoren (d.h. Verarbeitungseinheiten) sind. Anweisungen können nur dann zusammengeführt werden, wenn zwischen ihnen keine Datenabhängigkeit besteht. Scoreboarding und der Tomasulo-Algorithmus (der ähnlich ist wie Scoreboarding, aber nutzt die Registerumbenennung) sind zwei der häufigsten Techniken zur Implementierung von Out-of-order Ausführung und Instruktionsebene Parallelismus.Aufgabenparallelität Aufgabenparallelismen sind die charakteristischen Merkmale eines Parallelprogramms, das "in den gleichen oder verschiedenen Datensätzen sehr unterschiedliche Berechnungen durchgeführt werden können". Dies kontrastiert mit der Datenparallelität, wo die gleiche Berechnung auf denselben oder verschiedenen Datensätzen durchgeführt wird. Aufgabenparallelismus beinhaltet die Zersetzung einer Aufgabe in Subtasks und dann die Zuordnung jedes Teiltask zu einem Prozessor zur Ausführung. Die Prozessoren würden diese Teilaufgaben gleichzeitig und oft kooperativ ausführen. Aufgabenparallelismus skaliert in der Regel nicht mit der Größe eines Problems. Superword-Pegel-Pealismus Superword-Pegel-Pealismus ist eine Vektorisierungstechnik auf der Basis von Schleifenabrollung und grundlegender Blockvektorisierung. Es unterscheidet sich von Schleifenvektorisierungsalgorithmen, indem es Parallelismus des Inline-Codes ausnutzen kann, wie manipulierende Koordinaten, Farbkanäle oder in von Hand ungerollten Schleifen. Hardwarespeicher und Kommunikation Hauptspeicher in einem Parallelrechner ist entweder geteilter Speicher (geteilt zwischen allen Verarbeitungselementen in einem einzigen Adressraum), oder verteilter Speicher (in dem jedes Verarbeitungselement einen eigenen lokalen Adressraum aufweist). Verteilter Speicher bezieht sich auf die Tatsache, dass der Speicher logisch verteilt ist, aber oft impliziert, dass er auch physisch verteilt ist. Verteilte gemeinsame Speicher- und Speichervirtualisierung kombinieren die beiden Ansätze, wobei das Verarbeitungselement einen eigenen lokalen Speicher und Zugriff auf den Speicher auf nicht-lokalen Prozessoren aufweist. Zugriffe auf lokale Speicher sind typischerweise schneller als Zugriffe auf nicht-lokale Speicher. Auf den Supercomputern kann mittels des Programmiermodells wie PGAS verteilter gemeinsamer Speicherplatz realisiert werden. Mit diesem Modell können Prozesse an einem Rechenknoten transparent auf den Remote-Speicher eines anderen Rechenknotens zugreifen. Alle Rechenknoten sind auch über Hochgeschwindigkeitsverbindung, wie Infiniband, mit einem externen gemeinsamen Speichersystem verbunden, das als Burstpuffer bekannt ist, der typischerweise aus Arrays aus nichtflüchtigen Speichern aufgebaut ist, die über mehrere I/O-Knoten verteilt sind. Computerarchitekturen, bei denen jedes Element des Hauptspeichers mit gleicher Latenz und Bandbreite zugegriffen werden kann, sind als einheitliche Speicherzugriffssysteme (UMA) bekannt. Typischerweise kann dies nur durch ein gemeinsames Speichersystem erreicht werden, bei dem der Speicher nicht physikalisch verteilt ist. Ein System, das diese Eigenschaft nicht besitzt, ist als ungleichmäßige Speicherzugriff (NUMA) Architektur bekannt. verteilte Speichersysteme haben ungleichmäßigen Speicherzugriff. Computersysteme nutzen Caches – kleine und schnelle Speicher in der Nähe des Prozessors, die temporäre Kopien von Speicherwerten speichern (in der Nähe des physischen und logischen Sinnes). Parallele Computersysteme haben Schwierigkeiten mit Caches, die den gleichen Wert an mehr als einem Ort speichern können, mit der Möglichkeit einer fehlerhaften Programmausführung. Diese Computer benötigen ein Cache-Kohärenz-System, das die Cache-Werte verfolgt und strategisch reinigt und so eine korrekte Programmausführung gewährleistet. Bus-Snooping ist eine der häufigsten Methoden, um zu verfolgen, auf welche Werte zugegriffen werden (und daher zu reinigen). Die Entwicklung großer, leistungsstarker Cache-Kohärenzsysteme ist ein sehr schwieriges Problem in der Computerarchitektur. Dadurch skalieren gemeinsame Speichercomputerarchitekturen nicht sowie verteilte Speichersysteme. Prozessor-Prozessor und Prozessor-Speicher-Kommunikation kann in Hardware auf verschiedene Weise implementiert werden, einschließlich über geteilten (entweder mehr oder Multiplex-) Speicher, einen Crossbar-Schalter, einen gemeinsamen Bus oder ein Verbindungsnetz eines Myriads von Topologien einschließlich Stern, Ring, Baum, Hypercube, Fett Hypercube (ein Hypercube mit mehr als einem Prozessor an einem Knoten,) oder n-dimensionale Maschen. Parallelrechner auf Basis vernetzter Netzwerke müssen eine Art Routing haben, um das Senden von Nachrichten zwischen Knoten zu ermöglichen, die nicht direkt angeschlossen sind. Das für die Kommunikation zwischen den Prozessoren verwendete Medium ist in großen Mehrprozessormaschinen wahrscheinlich hierarchisch. Klassen paralleler Rechner Parallelrechner können grob nach dem Niveau klassifiziert werden, auf dem die Hardware Parallelität unterstützt. Diese Klassifikation ist weitgehend analog zum Abstand zwischen Basis-Computing-Knoten. Diese sind nicht gegenseitig ausschließend; beispielsweise sind Cluster symmetrischer Multiprozessoren relativ häufig. Multi-Core-Computing Ein Multi-Core-Prozessor ist ein Prozessor, der mehrere Verarbeitungseinheiten (Kerne) auf demselben Chip enthält. Dieser Prozessor unterscheidet sich von einem Superscalar-Prozessor, der mehrere Ausführungseinheiten umfasst und mehrere Anweisungen pro Taktzyklus von einem Befehlsstrom ausgeben kann (strichen;) dagegen kann ein Multi-Core-Prozessor mehrere Anweisungen pro Taktzyklus aus mehreren Befehlsströmen ausgeben. Der für den Einsatz in der Sony PlayStation 3 entwickelte Zellmikroprozessor von IBM ist ein prominenter Multi-Core-Prozessor. Jeder Kern in einem Multi-Core-Prozessor kann möglicherweise auch superskalar sein – das heißt, jeder Kern kann mehrere Anweisungen aus einem Thread ausgeben. Simultane Multithreading (von denen Intels Hyper-Threading die bekannteste ist) war eine frühe Form des Pseudo-Multi-Kerns. Ein Prozessor, der zur gleichzeitigen Multithreading fähig ist, umfasst mehrere Ausführungseinheiten in der gleichen Verarbeitungseinheit, d.h. es hat eine superscalare Architektur, und kann mehrere Anweisungen pro Taktzyklus aus mehreren Threads ausgeben. Das temporäre Multithreading hingegen umfasst eine einzige Ausführungseinheit in derselben Verarbeitungseinheit und kann eine Anweisung zu einem Zeitpunkt aus mehreren Threads ausgeben. Symmetrische Multiverarbeitung Ein symmetrischer Multiprozessor (SMP) ist ein Computersystem mit mehreren identischen Prozessoren, die Speicher teilen und über einen Bus verbinden. Businhalt verhindert, dass Busarchitekturen skalieren. Dadurch enthalten SMPs in der Regel nicht mehr als 32 Prozessoren. Aufgrund der geringen Größe der Prozessoren und der erheblichen Reduzierung der Anforderungen an die durch große Cache erreichte Busbandbreite sind solche symmetrischen Multiprozessoren äußerst kostengünstig, sofern eine ausreichende Speicherbandbreite vorliegt. Ein verteilter Rechner (auch als verteilter Speichermultiprozessor bekannt) ist ein verteiltes Speicherrechnersystem, in dem die Verarbeitungselemente über ein Netzwerk verbunden sind. Verteilte Computer sind sehr skalierbar. Die Begriffe "gleichzeitiges Computing", "paralleles Computing" und "distributed Computing" haben eine Menge Überschneidungen, und es besteht keine eindeutige Unterscheidung zwischen ihnen. Das gleiche System kann sowohl parallel als auch verteilt charakterisiert sein; die Prozessoren in einem typischen verteilten System laufen gleichzeitig parallel. Cluster Computing Ein Cluster ist eine Gruppe von lose gekoppelten Computern, die eng zusammenarbeiten, so dass sie in gewisser Hinsicht als ein einziger Computer angesehen werden können. Cluster bestehen aus mehreren eigenständigen Maschinen, die über ein Netzwerk verbunden sind. Während Maschinen in einem Cluster nicht symmetrisch sein müssen, ist Lastausgleich schwieriger, wenn sie nicht. Die häufigste Art von Cluster ist der Beowulf-Cluster, ein Cluster, der auf mehreren identischen kommerziellen Off-the-Shelf-Computern implementiert ist, die mit einem TCP/IP-Ethernet-Local Area Network verbunden sind. Die Beowulf-Technologie wurde ursprünglich von Thomas Sterling und Donald Becker entwickelt.87% aller Top500 Supercomputer sind Cluster. Die restlichen sind massiv parallele Prozessoren, nachstehend erläutert. Da Gitter-Computing-Systeme (im Folgenden beschrieben) leicht peinlich parallele Probleme bewältigen können, sind moderne Cluster typischerweise dazu ausgelegt, schwierigere Probleme zu bewältigen – Probleme, die Knoten benötigen, um Zwischenergebnisse häufiger miteinander zu teilen. Dies erfordert eine hohe Bandbreite und vor allem ein Low-Latency-Verbindungsnetz. Viele historische und aktuelle Supercomputer nutzen maßgeschneiderte High-Performance-Netzwerk-Hardware, die speziell für Cluster-Computing, wie das Cray Gemini-Netzwerk, entwickelt wurde. Ab 2014 verwenden die meisten aktuellen Supercomputer einige Off-the-Shelf Standard-Netzwerk Hardware, oft Myrinet, InfiniBand, oder Gigabit Ethernet. Massiv paralleles Computing Ein massiv paralleler Prozessor (MPP) ist ein einziger Computer mit vielen vernetzten Prozessoren. MPPs haben viele der gleichen Eigenschaften wie Cluster, aber MPPs haben spezialisierte Verbindungsnetze (wobei Cluster Waarenhardware für die Vernetzung verwenden). MPPs sind auch größer als Cluster, typischerweise mit "weit mehr" als 100 Prozessoren. In einem MPP enthält "jede CPU einen eigenen Speicher und Kopie des Betriebssystems und der Anwendung. Jedes Teilsystem kommuniziert mit den anderen über eine Hochgeschwindigkeitsverbindung. " IBMs Blue Gene/L, der fünftschnellste Supercomputer der Welt nach dem TOP500-Ranking vom Juni 2009, ist ein MPP. Grid Computing Grid Computing ist die am weitesten verbreitete Form des Parallel Computing. Es nutzt Computer, die über das Internet kommunizieren, um an einem bestimmten Problem zu arbeiten. Aufgrund der geringen Bandbreite und extrem hohen Latenz im Internet, verteiltes Computing beschäftigt sich typischerweise nur mit peinlich parallelen Problemen. Viele verteilte Rechenanwendungen wurden erstellt, von denen SETI@home und Folding@home die bekanntesten Beispiele sind. Die meisten Grid Computing-Anwendungen verwenden Middleware (Software, die zwischen dem Betriebssystem und der Anwendung sitzt, um Netzwerkressourcen zu verwalten und die Software-Schnittstelle zu standardisieren). Die am häufigsten verteilte Computing Middleware ist die Berkeley Open Infrastructure for Network Computing (BOINC). Oft verwendet die verteilte Computersoftware "spare-Zyklen", die Berechnungen zu Zeiten durchführen, in denen ein Computer Leerlauf ist. Spezialisierte Parallelrechner Innerhalb der Parallel-Computing gibt es spezialisierte Parallel-Geräte, die Nischenbereiche von Interesse bleiben. Obwohl sie nicht Domänenspezifisch sind, sind sie tendenziell auf wenige Klassen paralleler Probleme anwendbar. Rekonfigurierbares Computing mit feldprogrammierbaren Gate-ArraysRekonfigurierbares Computing ist die Verwendung eines feldprogrammierbaren Gate-Arrays (FPGA) als Coprozessor zu einem Universalrechner. Ein FPGA ist im Wesentlichen ein Computerchip, der sich für eine bestimmte Aufgabe neu verdrahten kann. FPGAs können mit Hardware-Beschreibungssprachen wie VHDL oder Verilog programmiert werden. Die Programmierung in diesen Sprachen kann jedoch mühsam sein. Mehrere Anbieter haben C-HDL-Sprachen erstellt, die versuchen, die Syntax und Semantik der C-Programmiersprache zu emulieren, mit denen die meisten Programmierer vertraut sind. Die bekanntesten C- bis HDL-Sprachen sind Mitrion-C, Impulse C, DIME-C und Händel-C. Dazu können auch bestimmte Teilmengen von SystemC auf Basis von C+ verwendet werden. Die Entscheidung von AMD, seine HyperTransport-Technologie an Drittanbieter zu öffnen, ist die Technologie für hochleistungsfähiges rekonfigurierbares Computing. Laut Michael R. D'Amour, Chief Operating Officer der DRC Computer Corporation, "wenn wir zuerst in AMD gingen, nannten sie uns "die Steckdosen-Stecker". Jetzt nennen sie uns ihre Partner." Allgemeines Anwendungs-Computing auf Grafik-Verarbeitungseinheiten (GPGPU) Allgemeines Anwendungs-Computing auf Grafik-Verarbeitungseinheiten (GPGPU) ist ein ziemlich neuer Trend in der Computer-Engineering-Forschung. GPUs sind Co-Prozessoren, die für die Verarbeitung von Computergrafiken stark optimiert wurden. Die Verarbeitung von Computergrafiken ist ein Feld, das durch parallele Datenoperationen dominiert wird – insbesondere lineare Algebra-Matrixoperationen. In den frühen Tagen, GPGPU-Programme verwendet die normalen Grafik-APIs für die Durchführung von Programmen. Es wurden jedoch mehrere neue Programmiersprachen und -plattformen gebaut, um die GPUs mit Nvidia- und AMD-Freigabeprogrammumgebungen mit CUDA- und Stream-SDK zu berechnen. Weitere GPU Programmiersprachen sind BrookGPU, PeakStream und RapidMind. Nvidia hat auch spezielle Produkte für die Berechnung in ihrer Tesla-Serie veröffentlicht. Das Technologie-Konsortium Khronos Group hat die OpenCL-Spezifikation veröffentlicht, die ein Rahmen für das Schreiben von Programmen ist, die über Plattformen aus CPUs und GPUs ausführen. AMD, Apple, Intel, Nvidia und andere unterstützen OpenCL. Anwendungsspezifische integrierte Schaltungen Mehrere anwendungsspezifische integrierte Schaltung (ASIC) Ansätze wurden für den Umgang mit parallelen Anwendungen entwickelt. Da ein ASIC (nach Definition) für eine bestimmte Anwendung spezifisch ist, kann es für diese Anwendung vollständig optimiert werden. Infolgedessen neigt ein ASIC für eine bestimmte Anwendung dazu, einen universellen Computer zu übertreffen. Jedoch werden ASICs durch UV-Photolithographie erzeugt. Dieser Vorgang erfordert einen Maskensatz, der extrem teuer sein kann. Ein Maskenset kann über eine Million US-Dollar kosten.( Je kleiner die für den Chip benötigten Transistoren sind, desto teurer wird die Maske.) Mittlerweile neigen Leistungssteigerungen im Rahmen der Zeit (wie durch Moore's Gesetz beschrieben) dazu, diese Gewinne in nur einer oder zwei Chip-Generationen auszulöschen. Hohe anfängliche Kosten und die Tendenz, von Moore's-law-driven General-purpose-Computing überholt zu werden, haben ASICs für die meisten parallelen Computing-Anwendungen unwahrscheinlich gemacht. Einige wurden jedoch gebaut. Ein Beispiel ist die PFLOPS RIKEN MDGRAPE-3 Maschine, die benutzerdefinierte ASICs zur Molekulardynamiksimulation verwendet. Vector Prozessoren Ein Vektorprozessor ist eine CPU oder ein Computersystem, das die gleiche Anweisung auf großen Datensätzen ausführen kann. Vektorprozessoren haben hochrangige Operationen, die an linearen Arrays von Zahlen oder Vektoren arbeiten. Ein Beispiel-Vektorbetrieb ist A = B × C, wobei A, B und C jeweils 64-Elemente-Vektoren mit 64-Bit-Schwebungspunktzahlen sind. Sie sind eng mit Flynns SIMD-Klassifikation verbunden. Cray Computer wurden berühmt für ihre vektorverarbeitenden Computer in den 1970er und 1980er Jahren. Allerdings sind Vektorprozessoren - genauso wie CPUs und als Vollrechnersysteme - generell verschwunden. Moderne Prozessor-Anweisungen enthalten einige vektorverarbeitende Anweisungen, wie zum Beispiel mit Freescale Semiconductors AltiVec und Intels Streaming SIMD Extensions (SSE.) Software Parallele Programmiersprachen Gleichzeitige Programmiersprachen, Bibliotheken, APIs und parallele Programmiermodelle (wie algorithmische Skeletts) wurden für die Programmierung paralleler Computer erstellt. Diese können in der Regel in Klassen unterteilt werden, basierend auf den Annahmen, die sie über die zugrunde liegende Speicherarchitektur machen - geteilter Speicher, verteilter Speicher oder geteilter verteilter Speicher. Geteilte Speicherprogrammiersprachen kommunizieren, indem gemeinsame Speichervariablen manipuliert werden. Verteilter Speicher verwendet Nachrichtenübermittlung. POSIX Threads und OpenMP sind zwei der am weitesten verbreiteten gemeinsamen Speicher-APIs, während Message Passing Interface (MPI) ist die am weitesten verbreitete Nachrichtenübermittlung System API. Ein Konzept, das in der Programmierung paralleler Programme verwendet wird, ist das zukünftige Konzept, bei dem ein Teil eines Programms verspricht, zu einem späteren Zeitpunkt ein erforderliches Datum an einen anderen Teil eines Programms zu liefern. CAPS-Entreprise und Pathscale koordinieren auch ihre Anstrengungen, um Hybrid-Multi-Core-parallele Programmierung (HMPP)-Richtlinien zu einem offenen Standard namens OpenHMPP zu machen. Das auf der OpenHMPP-Richtlinie basierende Programmiermodell bietet eine Syntax, um die Berechnungen auf Hardwarebeschleunigern effizient abzuladen und die Datenbewegung auf/aus dem Hardwarespeicher zu optimieren. OpenHMPP-Richtlinien beschreiben Remote Procedure Call (RPC) auf einem Beschleunigergerät (z.B. GPU) oder allgemein eine Reihe von Kernen. Die Richtlinien nennen C oder Fortran-Codes, um zwei Sätze von Funktionalitäten zu beschreiben: das Abladen von Prozeduren (denotierte Codelets) auf ein Remote-Gerät und die Optimierung von Datentransfers zwischen dem CPU-Hauptspeicher und dem Beschleunigerspeicher. Der Anstieg der Verbraucher-GPUs hat zur Unterstützung von Rechenkernen geführt, entweder in Grafik-APIs (bezogen als Rechen-Shader), in dedizierten APIs (wie OpenCL) oder in anderen Spracherweiterungen. Automatische Parallelisierung Automatische Parallelisierung eines sequentiellen Programms durch einen Compiler ist der "holy grail" des Parallel Computings, insbesondere mit der oben genannten Grenze der Prozessorfrequenz. Trotz jahrzehntelanger Arbeit von Compiler-Forschern hatte die automatische Parallelisierung nur einen begrenzten Erfolg. Die parallelen Mainstream-Programmiersprachen bleiben entweder explizit parallel oder (zumeist) teilweise implizit, wobei ein Programmierer die Compiler-Richtlinien zur Parallelisierung gibt. Es gibt einige implizite parallele Programmiersprachen – ISAL, Parallel Haskell, SequenceL, System C (für FPGAs), Mitrion-C, VHDL und Verilog. Anwendungsüberprüfung Da ein Computersystem in der Komplexität wächst, nimmt die mittlere Zeit zwischen Ausfällen in der Regel ab. Applikations-Checkpointing ist eine Technik, bei der das Computersystem einen Snapshot der Anwendung einnimmt – eine Aufzeichnung aller aktuellen Ressourcenzuordnungen und variablen Zustände, ähnlich einer Kern-Dump –; diese Informationen können verwendet werden, um das Programm wiederherzustellen, wenn der Computer ausfällt. Anwendungs-Checkpointing bedeutet, dass das Programm von nur seinem letzten Checkpoint statt vom Anfang neu gestartet werden muss. Während Checkpointing Vorteile in einer Vielzahl von Situationen bietet, ist es besonders nützlich in hochparallelen Systemen mit einer Vielzahl von Prozessoren, die in der Hochleistungs-Computing verwendet werden. Algorithmische Methoden Da parallele Computer größer und schneller werden, sind wir jetzt in der Lage, Probleme zu lösen, die zuvor zu lange gedauert hatten zu laufen. So vielfältig wie Bioinformatik (für die Proteinfalt- und Sequenzanalyse) und Ökonomie (für die mathematische Finanzierung) haben parallele Berechnungen genutzt. Häufige Arten von Problemen in parallelen Rechenanwendungen umfassen: Dense linear algebra Sparselinear algebraSpectral Methoden (wie Cooley–Tukey fast Fourier transform) N-Körperprobleme (z.B. Barnes-Hut-Simulation) strukturierte Netzprobleme (z.B. Lattice Boltzmann-Methoden) Unstrukturierte Netzprobleme (z.B. in der Finite-Elemente-Analyse gefunden) Monte Carlo-Methode Kombinationale Logik (z.B. brutal-force-cryptographic-Techniken) Graph-Traversal (wie Sortieralgorithmen) Dynamische Programmierung Branch und gebundene Methoden Grafische Modelle (z.B. Detektieren von versteckten Markov-Modellen und Konstruieren von Bayesischen Netzwerken) Fehlertoleranz Parallel Computing kann auch auf die Auslegung von fehlertoleranten Computersystemen angewendet werden, insbesondere über den gleichen Betrieb parallel durchführende Sperrstufensysteme. Dies bietet Redundanz bei Ausfall einer Komponente und ermöglicht auch eine automatische Fehlererkennung und Fehlerkorrektur, wenn sich die Ergebnisse unterscheiden. Diese Methoden können verwendet werden, um Ein-Ereignis-Erregungen durch transiente Fehler zu verhindern. Obwohl zusätzliche Maßnahmen in eingebetteten oder spezialisierten Systemen erforderlich sein können, kann dieses Verfahren einen kostengünstigen Ansatz zur Erzielung n-modularer Redundanz in kommerziellen Off-the-Shelf-Systemen bieten. Geschichte Die Ursprünge des wahren (MIMD) Parallelismus gehen zurück zu Luigi Federico Menabrea und seinem Sketch der von Charles Babbage erfundenen Analytic Engine. Im April 1958 diskutierte Stanley Gill (Ferranti) über die parallele Programmierung und den Bedarf an Verzweigung und Warten. Auch 1958 diskutierten IBM-Forscher John Cocke und Daniel Slotnick erstmals den Einsatz von Parallelismus in numerischen Berechnungen. Burroughs Corporation führte 1962 den D825 ein, einen Vierprozessor-Computer, der über einen Querlenker auf bis zu 16 Speichermodule zugreifen konnte. 1967 veröffentlichten Amdahl und Slotnick eine Debatte über die Machbarkeit der parallelen Verarbeitung auf der American Federation of Information Processing Societies Conference. Während dieser Debatte wurde Amdahls Gesetz geprägt, um die Geschwindigkeitsbegrenzung durch Parallelismus zu definieren. 1969 führte Honeywell sein erstes Multics-System ein, ein symmetrisches Multiprozessor-System, das in der Lage ist, bis zu acht Prozessoren parallel zu laufen. C.mmp, ein Mehrprozessorprojekt an der Carnegie Mellon University in den 1970er Jahren, gehörte zu den ersten Multiprozessoren mit mehr als wenigen Prozessoren. Der erste busgekoppelte Multiprozessor mit Schnüffeln war 1984 die Synapse N+1. SIMD Parallelrechner können auf die 1970er Jahre zurückverfolgt werden. Die Motivation hinter frühen SIMD-Computern war, die Gate-Verzögerung der Steuerung des Prozessors über mehrere Anweisungen zu amortisieren. 1964 hatte Slotnick den Aufbau eines massiv parallelen Computers für das Lawrence Livermore National Laboratory vorgeschlagen.Sein Design wurde von der US Air Force finanziert, die die früheste SIMD Parallel-Computing-Anstrengung war, ILLIAC IV. Der Schlüssel zu seiner Konstruktion war eine ziemlich hohe Parallelität, mit bis zu 256 Prozessoren, die es der Maschine erlaubt, an großen Datensätzen zu arbeiten, was später als Vektorverarbeitung bekannt wäre. ILLIAC IV wurde jedoch als "die berüchtigtste von Supercomputern" bezeichnet, weil das Projekt nur ein Viertel vollendet war, aber 11 Jahre dauerte und fast das Vierfache der ursprünglichen Schätzung kostete. Als es schließlich bereit war, seine erste reale Anwendung im Jahr 1976 zu betreiben, wurde es von bestehenden kommerziellen Supercomputern wie dem Cray-1 übertroffen. Biologisches Gehirn als massiv paralleler Computer In den frühen 1970er Jahren begannen Marvin Minsky und Seymour Papert am MIT Computer Science and Artificial Intelligence Laboratory, die Gesellschaft des Verstandes zu entwickeln, die das biologische Gehirn als massiv paralleler Computer betrachtet. 1986 veröffentlichte Minsky Die Gesellschaft des Verstandes, die behauptet, dass "mind ist gebildet aus vielen kleinen Agenten, jeder mindless von sich selbst". Die Theorie versucht zu erklären, wie das, was wir Intelligenz nennen, ein Produkt der Interaktion von nicht-intelligenten Teilen sein könnte. Minsky sagt, dass die größte Quelle von Ideen über die Theorie von seiner Arbeit kam, um eine Maschine zu schaffen, die einen Roboterarm, eine Videokamera und einen Computer verwendet, um mit Kinderblöcken zu bauen. Ähnliche Modelle (die auch das biologische Gehirn als massiv paralleler Computer betrachten, d.h. das Gehirn besteht aus einer Konstellation unabhängiger oder halbunabhängiger Agenten) wurden auch beschrieben von: Thomas R. Blakeslee, Michael S. Gazzaniga, Robert E. Ornstein, Ernest Hilgard, Michio Kaku, George Ivanovich Gurdjieff, Neurocluster Brain Model. Siehe auch Referenzen Weiter lesen Rodriguez, C.; Villagra, M.; Baran, B. (29. August 2008). " Asynchrone Teamalgorithmen für Boolean Zufriedenheit". Bio-Inspirierte Modelle von Netzwerk, Information und Computing Systems, 2007.Bionetics 2007.2nd: 66–69.doi:10.1109/BIMNICS.2007.4610083.S2CID 15185219.Sechin, A.; Parallel Computing in Photogrammetry.GIM International.#1, 2016, S.21–23 Externe Links Anleitungsvideos zum CAF im Fortran-Standard von John Reid (siehe Anlage B) Parallel Computing am Curlie Lawrence Livermore National Laboratory: Einführung in Parallel Computing Designing and Building Parallel Programs, von Ian Foster Internet Parallel Computing Archive Parallel Processing Topic Area bei IEEE Distributed Computing OnlineParallel Computing Works Free On-line Book Frontiers of SupercomputingFree Die Schwierigkeiten mit Multicore, von David Patterson, veröffentlichte 30 Jun 2010 Parallel Computing : A View From Techsevi Einführung in Parallel Computing Coursera: Parallel Programmierung Parallel Computing : A View From Gyan Grih