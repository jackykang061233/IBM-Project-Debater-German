In Statistiken ist ein erwartungs-maximization (EM)-Algorithmus eine iterative Methode, um (lokale) Höchstwahrscheinlichkeit oder ein Posteriori (MAP) Schätzungen von Parametern in statistischen Modellen zu finden, bei denen das Modell von unobservierten Variablen abhängt. EM iteration abwechselt zwischen der Ausführung eines erwarteten Schritts (E), der eine Funktion für die Erwartung der Log-likelihood schafft, die anhand der aktuellen Schätzung der Parameter bewertet wird, und einer Maximierung (M)-Phase, die Parameter berechnet, die eine Maximierung der erwarteten Log-likelihood auf dem E-Schritt ermöglichen. Diese Parameter werden dann verwendet, um die Verteilung der latenten Variablen im nächsten E-Schritt zu bestimmen. Geschichte Der EM-Algorithmus wurde in einem klassischen Papier von Arthur Dempster, Nan Laird und Donald Rubin erklärt. Sie wiesen darauf hin, dass die Methode von früheren Autoren viele Male unter besonderen Umständen angewandt wurde. Eines der frühestens ist die Genanerkennungsmethode für die Schätzung der Allele Frequenzen durch Cedric Smith. Nach seiner Zusammenarbeit mit Per Martin-Löf und Anders Martin-Löf wurde von Rolf Sundberg eine sehr detaillierte Behandlung der EM-Methode für exponentielle Familien veröffentlicht. Im Dempster-Laird-Rubin-Papier von 1977 wurde die Methode allgemeinisiert und eine Konvergenzanalyse für eine breitere Klasse von Problemen entworfen. Das Dempster-Laird-Rubin-Papier hat die EM-Methode als wichtiges Instrument der statistischen Analyse eingeführt. Die Konvergenzanalyse des Dempster-Laird-Rubin-Algorithmus wurde gestrichen und eine korrekte Konvergenzanalyse wurde von C. F veröffentlicht. Jeff Wu 1983. Wus Nachweis hat die Konvergenz der EM-Methode außerhalb der exponentiellen Familie festgestellt, die von Dempster-Laird-Rubin behauptet wurde. Einführung Der EM-Algorithmus wird verwendet, um (lokale) Höchstwahrscheinlichparameter eines statistischen Modells zu finden, wenn die Gleichungen nicht direkt gelöst werden können. In der Regel beinhalten diese Modelle latente Variablen neben unbekannten Parametern und bekannten Datenbeobachtungen. Es gibt entweder fehlende Werte unter den Daten, oder das Modell kann einfacher formuliert werden, wenn weitere nichtobservierte Datenpunkte vorliegen. Beispielsweise kann ein Mischungsmodell einfacher beschrieben werden, indem man bedenkt, dass jede beobachtete Datenstelle einen entsprechenden nichtobservierten Datenpunkt oder eine latente variable Größe hat, in der die Mischungskomponente angegeben wird, zu der jeder Datenpunkt gehört. Eine maximale Wahrscheinlichkeitslösung erfordert in der Regel, dass die Derivate die Wahrscheinlichkeitsfunktion in Bezug auf alle unbekannten Werte, Parameter und die latenten Variablen einnehmen und gleichzeitig die daraus resultierenden Gleichungen gelöst werden. statistische Modelle mit latenten Variablen sind in der Regel unmöglich. Stattdessen ist das Ergebnis in der Regel eine Reihe von Interlocking-Angleichungen, bei denen die Lösung der Parameter die Werte der latenten Variablen und umgekehrt verlangt, aber ein Satz von Gleichungen in die andere schafft eine undurchlässige Formel. Der EM-Algorithmus zieht aus der Beobachtung, dass es eine Möglichkeit gibt, diese beiden Formeln numerisch zu lösen. Man kann nur willkürliche Werte für eine der beiden Arten von unbekannten Personen ansammeln, sie verwenden sie, um das zweite Set zu schätzen, dann verwenden sie diese neuen Werte, um eine bessere Schätzung des ersten Satzes zu finden und dann zwischen den beiden zu wählen, bis sich die daraus resultierenden Werte an festen Stellen annähern. Es ist nicht offensichtlich, dass dies funktioniert, aber es kann in diesem Zusammenhang nachgewiesen werden. Darüber hinaus kann nachgewiesen werden, dass der Derivat der Wahrscheinlichkeit (schwellig nahe) Null an diesem Punkt ist, was wiederum bedeutet, dass der Punkt entweder einen maximalen oder einen Sattelpunkt ist. Insgesamt können mehrere Maxima auftreten, ohne dass sichergestellt wird, dass der globale Höchstwert erreicht wird. Manche Wahrscheinlichkeiten haben auch Unterschiede in ihnen, d. h. nichtsensischen Maxima. Zum Beispiel ist eine der Lösungen, die EM in einem Mischungsmodell gefunden werden können, mit der Festlegung eines der Komponenten, die Null aufweisen, und der mittlere Parameter für die gleiche Komponente, die einem der Datenpunkte entsprechen. Beschreibung {X} der beobachteten Daten, eine Reihe ungeschützter latenter Daten oder fehlender Werte Z \ Mathematik {Z} {Z} } und ein Vektor unbekannter Parameter  of    of X  of  of X  of X } } } X  L  L  L  L  L  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  L  L  L  L  L  L  L  L  of  L  L  L  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of  of Z Memedisplaystyle L(Ehebenzeichen Memetheta ;\} Mathematik {X} )=p(\ Mathematik {X} \mid fasersymbol livtheta )=\}int p(\ Mathematik) {X} ,\ Mathematik {Z} \mid faserzeichen ↓theta ),}d\ Mathematik {Z} \=int p(\ Mathematik) {Z} \mid \ Mathematik {X} {X} {X} , E-Mail: }p(\dl {X} \mid \\\mid faser olitheta ) } Diese Menge ist jedoch oft unüberwindbar, da Z Memedisplaystyle \ Mathematik {Z} unobserviert ist und die Verteilung von Z {\displaystyle \ Mathematik {Z} } vor Erreichen der {\ HANAdisplaystyle Memenzeichen HANAtheta }}} ist unbekannt. Der EM-Algorithmus strebt an, die MLE der marginalen Wahrscheinlichkeit zu finden, indem er diese beiden Schritte durchführt: Erwarteungsschritt (E-Phase): Konfine Q (      )  t  t  t ) {\ {\ {\ {\mid {\mid olitheta {t) als erwarteter Wert der Logwahrscheinlichkeitsfunktion von  to {\  to {\displaystyle HANAtheta }}}  to  to  to  to  to  to  to  to  to  to  to  to  to  of  of  of  of  of  of  of  of  of } X {\displaystyle \ Mathematik {X} } und die aktuellen Schätzungen der Parameter  of (T ) Memedisplaystyle Memetheta {(^t) : Q (θ θ θ θ ) ( t) ) ) = E Z  of X ,  of ( t)  [ [ Log θ L (  X ; X ) ] {\ ] {\ Q(   {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\                 ) ) ) ) ) ) ) ) ) ) ) {E} {Z} {X} , E-Mail-Symbol Memetheta {(^t)[[\log L(E-Marke olitheta ;\}po {X} ,\ Mathematik {Z} {Z} ] Maximierungsschritt (M-Phase): Kennen Sie die Parameter, die diese Menge maximieren: ) ( t + 1 ) = a r g x ) Q ( θ  t  t  t  t ) Memestyle HANAtheta (^t+1)}= livt } Q(E-Marke HANAtheta \}mid fasersymbol HANAtheta {(^t)\, Die typischen Modelle, auf die EM angewendet wird, verwenden Z Memedisplaystyle \ Mathematik {Z} als latente variable Angabe der Mitgliedschaft in einer Reihe von Gruppen: Die beobachteten Datenpunkte X {\displaystyle \ Mathematik {X} } können gesondert sein (Eigenwerte in einem finite oder zahlbar unbegrenzten Satz) oder kontinuierlich (mit Werten in einem unvoreingenommenen Satz). In Verbindung mit jedem Datenpunkt kann es sich um einen Vektor von Beobachtungen handeln. fehlende Werte (aka latent Variablen) Z Memedisplaystyle \ Mathematik {Z} } sind von einer festen Anzahl von Werten und mit einer latenten variablen je beobachteten Einheit getrennt. Die Parameter sind kontinuierlich und zwei Arten: Parameter, die mit allen Datenpunkten assoziiert sind, und diejenigen, die mit einem bestimmten Wert einer latenten variablen Variablen assoziiert sind (d. h. mit allen Datenpunkten, die eine entsprechende latente Variablen aufweisen). Jedoch ist es möglich, EM auf andere Arten von Modellen anzuwenden. Die Motivation ist wie folgt. Liegt der Wert der Parameter {\ {\displaydisplaystyle HANAtheta  of bekannt, in der Regel der Wert der latenten Variablen Z {\displaystyle \ Mathematik {Z} } kann gefunden werden, indem die Log-likelihood über alle möglichen Werte von Z {\displaystyle \ Mathematik {Z} } erreicht wird, entweder einfach durch die Erzielung über Z Memestyle \doc 1998 {Z} oder durch einen Algorithmus wie den Baum-Welch-Algorithmus für versteckte Markov-Modelle. Wenn wir den Wert der latenten Variablen Z {\displaydisplaystyle \ Mathematik {Z} } } kennen, können wir eine Schätzung der Parameter   {\displaystyle  cu handelstheta }}} ziemlich einfach finden, in der Regel indem wir die beobachteten Datenpunkte nach dem Wert der assoziierten Spätvariablen und der durchschnittlichen Werte oder einer Funktion der Werte in jeder Gruppe zusammengefasst werden. Dies schlägt einen iterativen Algorithmus vor, wenn sowohl θ {\displaystyle HANAtheta }}} als auch Z Memedisplaystyle \ Mathematik {Z} unbekannt sind: Erstens werden die Parameter   {\displaydisplaystyle fasersymbol Memetheta . auf einige zufällige Werte gelegt. Komputet die Wahrscheinlichkeit eines jeden möglichen Werts von Z Memedisplaystyle \ Mathematik {Z} } , da   faserzeichen Memetheta }}} .Then die gerechten Werte von Z Memedisplaystyle \docstyle \ Mathematik {Z } verwenden, um eine bessere Schätzung für die Parameter  of {\displaystyle olitheta }}} }}} Schritte 2 und 3 bis Konvergenz. Der Algorithmus, wie es gerade beschrieben ist, nähert sich auf ein lokales Minimum der Kostenfunktion. Eigenschaften, die auf einen erwarteten Schritt (E) sprechen, sind ein Teil eines Fehlnomen. Was werden im ersten Schritt berechnet, sind die festen, datenabhängigen Parameter der FunktionQ. Wenn die Parameter der Q bekannt sind, ist sie vollständig bestimmt und wird im zweiten Schritt des EM-Algorithmus maximiert. Obwohl eine EM-Erklärung die beobachteten Daten (d. h. marginale) Wahrscheinlichkeitsfunktion erhöht, besteht keine Garantie dafür, dass die Sequenz auf eine höchstwahrscheinliche Estimator angeglichen wird. Multimodaler Vertrieben bedeutet dies, dass ein EM-Algorithmus je nach Ausgangswerten auf eine lokale Höchstdauer der beobachteten Datenwahrscheinlichkeitsfunktion abgestimmt werden kann. Es gibt eine Vielzahl von touristischen oder metahe touristischen Ansätzen, um einen lokalen Höchststand zu entweichen, wie etwa die zufällige Bergstiegswelle (mit mehreren verschiedenen Zufallsvoranschlägen t(t) oder simulierte Anforstungsmethoden. EM ist besonders nützlich, wenn die Wahrscheinlichkeit eine exponentielle Familie ist: Der E-Schritt wird zur Summe der Erwartungen an ausreichende Statistiken, und der M-Schritt beinhaltet die Maximierung einer linearen Funktion. In einem solchen Fall ist es in der Regel möglich, für jeden Schritt die Sundberg Formel (veröffentlicht von Rolf Sundberg mit unveröffentlichten Ergebnissen von Per Martin-Löf und Anders Martin-Löf) zu ändern. Im Originalpapier von Dempster, Laird und Rubin wurde die EM-Methode geändert, um maximal ein Posteriori (MAP) zu berechnen. Andere Methoden sind vorhanden, um maximalen Wahrscheinlichkeitsschätzungen zu finden, wie z.B. Absterben, Verjüngung oder Varianten des Gausss-Neuton-Algorithmus. Anders als EM erfordern solche Methoden in der Regel die Bewertung der ersten und/oder zweiten Derivate der Wahrscheinlichkeitsfunktion. Nachweis der korrekten Erwartungs-maximisierung funktioniert, um Q (  θ  t  t ) ) faserstyle Q( ) faserzeichen Memetheta \}mid fasersymbol Memetheta {(^t) anstelle direkter Verbesserung der Log . p ( X θ ) 574 \log p(\log {X} \ \ \ \ \ \ \ \ \ \  fi  fi\  fismid olitheta {\) {\ . } ta . . Hier wird gezeigt, dass Verbesserungen gegenüber dem früheren mit Verbesserungen verbunden sind. Für alle Z Memedisplaystyle \ Mathematik {Z} mit nicht-zero- Wahrscheinlichkeit p ( Z  X X , ) ) Memedisplaystyle p(\ Mathematik) {Z} \mid \ Mathematik {X} {X} {X} , E-Mail-Marke Memetheta }}) können wir Log . p ( X θ   ) = Log  X p ( X, Zθ θ   ) ) ) ⁡  Z ) Log  Z (Z  Z  Z X  Z  Z  Z  Z  Z  Z X  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z .  Z  Z  Z  Z  Z  Z . .  Z  Z  Z  Z  Z  Z  7.8displaystyle \log p(\ Mathematik) {X} \mid faserzeichen SSOtheta )=\}log p(\dl Mathematik {X} ,\ Mathematikb {Z} \mid 574 } \mid ocet )-{\log p(\ Mathematikdl {Z} \mid \mid \dl {X}, varie olitheta }} Wir nehmen die Erwartung über mögliche Werte der unbekannten Daten Z Memedisplaystyle \ Mathematik {Z} } unter dem aktuellen Parametervoranschlag  t ( t) Memestyle \theta(^t)}, indem wir beide Seiten durch p ( Z  X X , . ( t) ) KINGstyle p(\dl {Z} \mid \ Mathematik {X} {X}, E-Mail-Symbol {\ {\ {t) {t) und {D) {Z ] \ } {Z} \mid {X} {X} } {X} {X} {X} {X} ] {X} {\X} {\X}, {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ Die linken Seite ist die Erwartung eines ständigen, so dass wir: Log  p p ( X   ) =  Z Z p ( Z  X X ,  t ( t ) Log  p p ( X , Z∣ θ θ θ  of )  of Z p ( Z θ X θ  X  X    X  X  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H  H \sum Meme_chino {Z}p(\ Mathematik {Z} \mid \ Mathematik {X} , E-Mail-Symbol Memetheta {(^t)})\log p(\klodl) {X} {Z} nemid {Z} \mid faserzeichen ↓theta ) {Z} {Z} {Z} {Z} \mid \mid \mid \mid {X} {X} {X} {X} , E-Mail: })\ p(Z} \\\\ Mathematik {X} {X} {X}, E-Marke ) } ) ) ) ) ) ) H H ) Diese letzte Formel gilt für jeden Wert von   WELLdisplaystyle HANA Stempel SSOtheta }}} einschließlich ) = ) ( t ) {\displaystyle faserzeichen fasertheta )  X ) ) ^ ^ ) ) ) )  H  H  H  H 7.8displaystyle \log p(\ Mathematik) {X} \mid faserzeichen HANAtheta )-\}log p(\dl Mathematik {X} \mid fasersymbol olitheta {(^t)})\geq Q(Ehebenzeichen {\mid  mid {\mid {\mid  fisolitheta ^t)} Mit Worten: Wählen Sie   HANAdisplaystyle HANAtheta }}}, um Q ( t θ )  t  t  t  t  t {\ . . {\ {\mid {\mid {\mid {\ {\ {\ {\ {\ {\ {\ . {\  X . ) ) ) {\ . {\ \log p(\log {X} \mid . {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . {\ . {\ {\ {\  Maximierung -maximierungsverfahren Der EM-Algorithmus kann als zwei sich abwechselnde Maximierungsschritte angesehen werden, die als Beispiel für die Koordinierung der Abwanderung dienen. Prüfung der Funktion: F ( q , ) ) := E q  [ [ Log  L L ( ; x , Z ) ] + H ( q ) , Memestyle F(q,\theta )\:=operator {E}[\log L(\theta ;x,Z)]+ H(q), wo q eine willkürliche Wahrscheinlichkeitsverteilung über die nichtobservierten Daten Z und H(q) ist, ist die Entropy der Verteilung q. Diese Funktion kann als F ( q ,   ) = − D K L ( q  Z p Z  X X (   x ;   ) + Log  L L (θ ; x ) , Memedisplaystyle F(q,\theta )-=D_Get Mathematikrm {KL} {\}big (}q\parallel p_{Z\mid X}(\cdot \mid x;\theta ) Haushaltsbig )+\}log L(\theta ;x), wo P Z  of X (⋅ ;   ;   ) {\ ) )  of  of  of  of  of  of  X  X  X  X  X X}(\c \mid x;\theta ) } ist die Bedingung, dass die Daten nicht erfasst werden. L WELLdisplaystyle D_{KL} ist der Kullback-Leibler Divergenz. Dann können die Schritte im EM-Algorithmus als erwarteter Schritt angesehen werden: Wählen Sie q KINGstyle q} zur Maximierung F {\displaystyle F} : q ( t ) = a r g m a x q ⁡ F ( q ,  t ) Memestyle q^{(t)}=\operatorname {arg\,max} {_q F F(q,\theta {t)} Maximization Schritt: θ } } } ) }, um F ) () + 1 ) )  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 Anwendungen EM wird häufig für die Parameterschätzung gemischter Modelle verwendet, insbesondere in quantitativen Genen. In Psychometrien ist EM ein wichtiges Instrument für die Schätzung von Punktparametern und latenten Fähigkeiten von Prüfungstheorien. Mit der Fähigkeit, fehlende Daten zu bearbeiten und unidentifizierte Variablen zu beobachten, wird EM zu einem nützlichen Instrument für Preis und Management von Risiken eines Portfolios. Der EM-Algorithmus (und seine schnellere Variante bestellte Subset-Erwartungsmaxisierung) wird auch in der medizinischen Bildverwertung, insbesondere in Positron Emission tomographie, Single-photon-Emissionen, die zu mographie berechnet werden, und x-ray berechneter Tomographie verwendet. siehe unten für weitere schnellere Varianten des EMV. In der Strukturtechnik ist die strukturelle Identifizierung mit dem Erwartungs- Maximization (STRIDE)-Algorithmus eine ausschließliche Methode zur Ermittlung natürlicher Vibrationseigenschaften eines Struktursystems mit Sensordaten (siehe operative Modal Analysis). EM wird auch für Datencluster verwendet. In der natürlichen Sprachverarbeitung sind zwei prominente Fälle des Algorithmus der Baum-Welch-Algorithmus für versteckte Markov-Modelle und der Intra-outside-Algorithmus für unüberwindbare Einführung probabilistischer Kontext-free-Läden. Filterung und Vereinfachung von EM-Algorithmen In der Regel wird ein Kalman-Filter für die Online-Staatsschätzung verwendet, und eine minimale Varianz kann für Off-line- oder Chargenstaatschätzung verwendet werden. Diese Mindestvarianzlösungen erfordern jedoch Schätzungen der Parameter des staatlichen Raummodells. EM-Algorithmen können zur Lösung gemeinsamer Staats- und Parameterschätzungsprobleme verwendet werden. Filterung und Einfachheit von EM-Algorithmen treten durch wiederholtes Verfahren auf: E-Schritt Operate ein Kalman-Filter oder ein mit aktuellen Parameterschätzungen konzipierter Mindestvarianzfilter. M-Schritt Verwenden Sie die gefilterten oder glatten staatlichen Schätzungen innerhalb von maximal ähnlichen Berechnungen, um aktualisierte Parameterschätzungen zu erhalten. Legen Sie fest, dass ein Kalman-Filter oder eine minimale Varianz-Verbesserung auf Messungen eines einheitlichen, einheitlichen Output-Systems, das einen zusätzlichen weißen Lärm besitzt, funktioniert. Eine aktualisierte Messlärmvarianzschätzung kann aus der maximalen Wahrscheinlichkeitsberechnung ^ ^ v 2 = 1 N  k k = 1 N ( z k − x ^ k ) 2 , Memedisplaystyle HANA 7.8sigma _v}^{2} 1 1N ksum k=1}^{N((z_{k}- x{_{k})}^{2, wo x ^ k {\displaystyle Memeallhat x}}_{k scalar Output-Schätzungen sind, die durch einen Filter oder einen reibungsloseren aus N scalar Messungen z k {\displaystyle z_{k} berechnet werden.Die obengenannte Aktualisierung kann auch zur Aktualisierung einer Poisson-Messeintensität angewendet werden.  first  for k = 1 N ( x ^ k + 1 − F ^ x ^ k ) 2 , JPY 7.8sigma _w}^{2} 1 1N _sum _k=1}{N((näufig) x{_{k+1}-Portedhat F}}{\allhat x}}_{k})}^{2, wo x ^ k {\displaystyle ggioallhat x{_{k und x ^ k + 1 KINGstyle x__{k+1 sind scalar State-Schätzungen, die auf einem Filter oder einem reibungsloseren berechnet werden. Der aktualisierte Modellkoeffizient-Schätzwert wird über F ^ = ) k = 1 N ( x ^ k + 1 − F ^ x ^ k ) ) k = 1 N x ^ k 2 . KINGstyle HANA F== CALfrac livsum _k=1}^{N}(n) x{_{k+1}-Emargen x__{k} _k=1}{\N}{\ x__{k}^{2. Die Konvergenz der Parameterschätzungen wie die oben genannten werden gut untersucht. Variants Eine Reihe von Methoden wurden vorgeschlagen, die manchmal langsame Konvergenz des EM-Algorithmus zu beschleunigen, wie z.B. diejenigen, die mit einem Verfall und geänderten Methoden von Newton (Newton-Raphson). EM kann auch mit eingeschränkten Schätzungsmethoden verwendet werden. Parameter-Erwarteung Maximierung (PX-EM)-Algorithmus beschleunigt oft den „us[ing]“-Anpassung, um die Analyse des M-Ansatzes zu korrigieren, indem zusätzliche Informationen, die in den streitigen vollständigen Daten erfasst werden, genutzt werden. Erwartungsbedingte Maximierung (ECM) ersetzt jeden M-Schritt mit einer Sequenz der bedingten Maximierung (CM) Schritte, in denen jeder Parameter ii individuell maximiert wird, wobei die übrigen Parameter, die noch festgelegt sind, zu beachten sind. Es selbst kann in den erhofften maximalen Maximierung entweder (ECME)-Algorithmus ausgeweitet werden. Diese Idee wird im Allgemeinen weiter ausgedehnt, wenn es darum geht, die Maximierung (GEM)-Algorithmus zu maximieren, wobei nur eine Erhöhung der objektiven Funktion F sowohl für den E-Schritt als auch für den M-Ansatz angestrebt wird, wie es im Abschnitt „maximization-Verfahren“ beschrieben ist. GEM wird in einem verteilten Umfeld weiter entwickelt und zeigt vielversprechende Ergebnisse. Es ist auch möglich, den EM-Algorithmus als Subklasse des MM (Majorize/Minimize oder Minorisierung/Maximize, je nach Kontext)gorithmus zu betrachten und somit alle im allgemeineren Fall entwickelten Maschinen zu verwenden. --EM-Algorithmus Die im EM-Algorithmus verwendete Funktion basiert auf der Logwahrscheinlichkeit. Es gilt daher als Log-EM-Algorithmus. Die Nutzung der Logwahrscheinlichkeit kann auf das Verhältnis der Wahrscheinlichkeit desα-logs ausgedehnt werden. In diesem Fall kann die Wahrscheinlichkeit desα-logs der beobachteten Daten durch die Nutzung der Q-Funktion desα-Log-Quote und derα-Dimension genau als Gleichstellung ausgedrückt werden. Bewahren Sie diese Q-Funktion ist ein allgemeiner E-schritt. Seine Maximierung ist ein allgemeiner M-Ansatz. Dieses Paar wird der EM-EM-Algorithmus genannt, der den Log-EM-Algorithmus als Subklasse enthält. So ist der EM-EM-Algorithmus von Yasuo Matsuyama eine genaue Generalisierung des Log-EM-Algorithmus. Keine Berechnung der Kluft oder der Hessischen Matrix ist erforderlich. Die EM-EM zeigt eine schnellere Konvergenz als der Log-EM-Algorithmus durch die Wahl einer geeigneten ..Der EM-EM-Algorithmus führt zu einer schnelleren Version des versteckten Markov-Modells Schätzungsgorithmus HM-HMM. Verhältnis zu den unterschiedlichen Methoden EM ist ein teilweise nicht-Bayernischer, höchstwahrscheinlicher Ansatz. Das Endergebnis gibt eine Wahrscheinlichkeitsverteilung über die latenten Variablen (im Bayesischen Stil) zusammen mit einer Punktschätzung für ). (entweder eine maximale Wahrscheinlichkeitsschätzung oder ein nachträglicher Modus). Eine vollständige Bayesische Version dieses Systems kann angestrebt werden, was eine Wahrscheinlichkeitsverteilung über θ und die latenten Variablen ermöglicht. Der Bayesian-Ansatz zur Gleichgültigkeit ist einfach, um die  another als eine andere latente Variablen zu behandeln. In diesem Paradigma verschwinden die Unterscheidung zwischen den Schritten von E und M. Wenn die oben beschriebene faktorisierte Q-Annähe (variational Bayes) verwendet wird, kann die Lösung über jede latente Variablen (jetzt einschließlich θ) abbauen und sie zu einer Zeit optimieren. Jetzt sind k Schritte pro Iteration erforderlich, wo k die Zahl der latenten Variablen ist. grafische Modelle sind leicht zu tun, da die neue Q der einzelnen Variablen nur von der Markov Decken abhängt, so dass die lokale Botschaft zur effizienten Auseinandersetzung genutzt werden kann. geometrische Auslegung In der Informationsgeflechtung werden der E-Schritt und der M-Schritt als Projektionen im Rahmen von Dual-Asse-Verbindungen ausgelegt, die e-Zusammenschaltung und die m-Kopplung genannt werden; die Kluft zwischen Kullback und Lektüre kann auch in diesem Sinne verstanden werden. Beispiele für Gausische Mischung Let x = ( x 1 , x 2 , ... , x n ) \ Mathematik {x} (\= Mathematik {x} {_1},\ Mathematik {x} {x} {x} {_2},\ldots ,\ Mathematik {x} {x} {n)} ist eine Stichprobe von n 574style n}, unabhängige Beobachtungen aus einer Mischung von zwei multivariate Verteilung der größen d-style, c) und {z · · · · · } X i ) ( Z i = 1 )  N N d ( μ 1 ,  1 1 ) 7.8style X_{i}\mid (Z_{i}=1)\sim liv mathematisch N}}_{d}(Ehebenzeichen {_1},\Sigma {_1)} und X i  i ( Z i = 2 } ) 2  2 2  2 2  2 2  2 2 ) 2 ) 2 ) 2 ) 2 ) 2 ) 2 ) 2 ) 2 ) 2 ) ) 2 ) ) ) ) ) ) ) ) ) )  Z 2  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z  Z {P} (Z_{i}=1)=\tau {_1,\} und P ) ( Z i = 2 ) = . 2 = 1 {\ 1 . KINGstyle \operator {P} (Z_{i}=2)=\tau {_2}=1-\tau {_1}. Ziel ist es, die unbekannten Parameter, die den Mischwert zwischen den Gausern und den Mitteln und Kovarien der einzelnen:  = = ( μ 1 , μ 2 ,  1 1 ,  2 2 ) 2 )  2  2 {\ tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau tau  2  2 tau tau  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 ) )  i  i )  i  i  i ) )  2 ) ) ) ) ) ) ) ) ) ) ) ) ) )  2 ) ) tau  2 tau  2  2 ) I (z i = j ) , Memedisplaystyle L(\theta ;\ Mathematik {x} {z} )=p(\holedl} {x} ,\doc {z} \mid \theta )\=prod _i=1}\prod _j=1}^{2\ [f\\\[x} {x} 7.8mu {_j},\Sigma {_j})\tau _j}]^{\ Mathematikbb {I} (z_{i}=j) oder L (θ ; x , z ) = ) {  i i = 1 n  1 = 2 I ( z i = j) [ Log  j  j 2 }  j 2 }  1  1  1  2 2 ( x  i  i  j  j  j  j  j  j  j  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  2  2  2  2  2  2  2  1  1  1  1  1  1  1  1  1  1  2  2  2  1  1  2  2  2  2  2  2  1  2  2  2  2  2  2  2  2  2  2  2  2  2 _j=1}\2}\bb {I} (z_{i}=j) cubig \[}log \tau _j}- 1}{2}}\log \|Sigma _j} - WELLtfrac 1 12((\ Mathematik {x} _i}-Schott Symbol 7.8mu _j}^{\top \}Sigma _j-1-1}(\ Mathematik {x} _i}-Getrzeichen Mememu _j})-Bartfrac d}{2}}\log(2\pi ) ]right, wo I {\displaystyle \ Mathematikbb {I} eine Indikatorfunktion ist und f Memestyle f} die Wahrscheinlichkeitsdichtefunktion einer multivariate Normalität ist. In der letzten Chancengleichheit entspricht jeder Indikator I (z i = j ) JPYstyle \ Mathematikbb {I} (z_{i}=j) Null, und ein Indikator entspricht einem. Die innere Summe verringert sich somit auf einen Begriff. In Anbetracht unserer aktuellen Schätzung der Parameter ((t) wird die bedingte Verteilung des Zi durch die Buchten bestimmt, die die proportionale Höhe der von  of gewichteten Normaldichte aufweisen: T j , i ( t) := P  Z ( Z i = j  X X i = x i;  i ( t)  j ( t) f) f ( x i ; μ j ;  j ( t) t)  j ( t) t)  j ( t)  j ( t)  1  1  1  1 ( t)  1 ( t)  1 ( t) t)  1 ( t) t)  1 ( t) t) t) t) t)  1 x i ; μ 1 ( t ) , Σ 1 ( t ) + τ 2 ( t ) f · i ; μ 2 ( t ) ,  2 2 ( t ) . . KINGstyle T_{j,i((t)}:=\operatorname {P} (Z_{i}=j\mid X_{i}=\ Mathematik {x} {_i};\theta (^t)})= cufrac livtau _j((t)\ f(t)\ f(t)\ k(x}; E-Mail-Symbol Mememu _j((t},\Sigma _(t})tau(t)}1(t)\ f f(t)\ fbfx {x {x} Diese werden als "Mitgliedschaftsprobabilities" bezeichnet, die in der Regel als Output des E-Schritts gelten (obwohl dies nicht die Q-Funktion unten). Dieser Schritt entspricht der Einrichtung dieser Funktion für Q: Q ( t    X ( t) ) = E Z  X X ,  t ( t)  [ [ Log  L L (θ ; x , Z ) ] = E Z  X X ,  [ ( t)  [ [ Log  = i = 1 n L ( Z ; x i, Z ) ] E Z X X  X X  X X  X ( t) ) [  i i = 1 n log  L L (  L ; x i , Z i )] =  i i = 1 n E Z i  X X ;  t ( t )  [ [ Log  L L (θ ; ; )i , Z i ) ] =  i i = 1 n  j j = 1 2 P ( Z i = j  i X i = x i; ) ( t ) Log  L L (θ j ; x i , j) =  i i = 1  i  i  j  j  1  1  1  1  1  1  1  i  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  i  1  1  1  1  1  1  1  1  1  1  1  1  1 {E} {Z} \mid \ Mathematik {X} ,\ Mathematik  Haushaltstheta } {(^t)[[\log L(\theta ;\ Mathematik {x} {x} \ Mathematik {Z} {Z})] {E} {Z} \mid \ Mathematik {X} ,\ Mathematik Memetheta } {(^t)[[\log \prod _i=1}^{n}L(\theta ;\theta ;\thek {x},Z_{i}]\\ &=operatornamename {E} {Z} {X} ,\ Mathematik 9.5theta } {(^t)[[\sum _i=1}\n Llog L(\theta ;\ Mathematik {x} i},Z_{i}]\\ &=\sum _i=1}^{n)n)atornameator {E} Z_{i}\mid \ Mathematik {X} ;\ Mathematik steuerliche 574 } {(^t)[[\log L(\theta ;\ Mathematik {x} i},Z_{i}]] &=\sum _i=1}^{n)sum j=1}^{2}P(Z_{i}=j\mid X_{i}=\ Mathematik {x} {_i};\theta {(3)})\log L(\theta {_j};\ Mathematik {x} {_i},j)\\ &=\sum _i=1}\sum j=1}^{2}T_{j,i((t)}{\big \[}log \tau _j}-7.8tfrac 1}{2}}\log \|Sigma _j} - WELLtfrac 1 12((\ Mathematik {x} _i}-Schott Symbol 7.8mu _j}^{\top \}Sigma _j-1-1}(\ Mathematik {x} _i}-Schottzeichen 7.8mu _j})- Memetfrac d}{2}}\log(2\pi ) ]\.end Log  L L (; ; x i , Z i ) {\displaystyle \log L(\theta ;\ Mathematik {x} i},Z_{i) innerhalb der Summe wird in Bezug auf die Wahrscheinlichkeitsdichtefunktion P ( Z i  i X i ; ) ( t) ) . KINGstyle P(Z_{i Xmid X_{i}=\cl {x} {_i};\theta {(^t)} , die für jeden x i KINGstyle \ Mathematik {x} {x} {_i} der Ausbildungseinrichtung unterscheiden könnten. Alles in der E-Phase ist bekannt, bevor der Schritt mit Ausnahme von T j , i Memestyle T_{j,i} , der nach der Formel zu Beginn der E-Phase berechnet wird. Diese vollständige Konditionierung muss nicht in einem Schritt berechnet werden, da τ und μ/. in getrennten linearen Bedingungen erscheinen und somit unabhängig maximiert werden können. M Schritt Q( |)  form(t) quadratisch in Form bedeutet, dass die Bestimmung der Maximierungswerte von . relativ einfach ist. ., (μ1,Σ1) und (μ2,Σ2) können alle unabhängig maximieren, da sie alle in unterschiedlichen linearen Bedingungen erscheinen. zu beginnen, ) zu betrachten, die den Druck 11 + τ2=1: τ ( t + 1 ) = ein r g m x ) Q (θ θ θ θ  t  t  t  t  t ) ) ) ) ) ) ) ) )  g  g  g [  i i = 1 n T 1 , i ( t )] Log )  1 1 + [  i i = 1 n T 2 , i ( t) ] Log . 2 }. 7.8displaystyle beginnt {aligned)print Symbol HANAtau (^t+1)} &=TONunderset  Handelsmarken HANAtau )operator {arg\,max} ) Q(\theta \mid \theta (^t)})& &=TONunderset  Binnenmarktzeichen HANAtau {\}operator {arg\,max} links i[\sum i=1}^{n}T_{1,i (t).(t).right]\ \logtau {1}+\links[\ i=1 in}T_2,i(t) ]\logtau2 Dies hat die gleiche Form wie die MLE für die verbindliche Verteilung, so  j j ( t + 1 ) =  T i = 1 n T j , i = 1  1 i = 1 n (T 1 , i ( t ) + T 2 , i ( t ) = 1 n  i i = 1 n T j, i ( t) . 7.8displaystyle \tau _j((t+1)}=9frac ggiosum i=1}^{n}T_{j,i i(t) isum i=1}^{n}(T_{1,i((t)}+T_{2,i((t)}) 1=1,0frac 1 in in in i=1 in}T_{j,i((t) Für die nächsten Schätzungen (μ1,1)1): ( μ 1 ( t + 1 ) ,  1 1 ( t + 1 ) = ein r g x μ 1 ,  1 1 Q (θ θ θ θ ) ) ) ) ) )  g ) ) ) ) 1  1 1  i  i 1  i  i 1  i  i 1  i } ) 1 } ) 1  1 1  |  i  |  i  2 1  i  i  i  i  i 1  i  i  2  i  i  i  i  i 1  i  i  i  i  i  i  i  i  i  i  i  1  1  1  1  1  i  i  i  i  i  i  i  i  i  i 1 12\log \|Sigma _1} _i}-Schnzeichen 7.8mu _1}^{\top  Sigma _1}^{-1} _i}-Schottzeichen HANAmu _1})\right\}\end{aligned. Dies hat die gleiche Form wie gewichtete MLE für eine normale Verteilung, so μ 1 ( t + 1 ) =  i i = 1 n T 1 , d. h.x i  i i = 1 n T 1 , i ( t ) {\displaystyle  steuerlicher Stempel Mememu _1((t+1)}=1,0frac {\sum i=1}^{n}T_{1,i((t)}\[x}i{n}T_{1}^{n}T_{1,i((t) und  t 1 ( t) = 1  1 1 n n 1 n 1 n 1 , i  1 1 n 1 , i ( x i − μ 1 ( t + 1 ) ) ( x i − μ 1 ( t + 1 ) ) i = 1 n T 1 , i ( t ) Memedisplaystyle \Sigma _1((t+1)}=1,0frac ggiosum i=1}^{n}T_{1,i((t)}(\ Mathematik) {x} _i}-Bargezeichen 7.8mu _1((t+1))(\ Mathematik {x _i}-Fit-Symbol Mememu _1((t+1)}^{\top sum=1}^{n}T_11{n}T_1(t)1,1(t+1) und  2 1 μg) i  i i = 1 n T 2 , d. h. ) {\displaystyle faserzeichen Mememu _2}^{(t+1)}=1,0frac SSOsum i=1}^{n}T_{2,i((t){(t){(t)} {x}i isum i=1}^{n}T_{2,i((t) und  2 2 ( t) = 1 n 2 n 2 , i ( t) x  2 2 ) ( t) ( x i − μ 2 ( t + 1 )  i i = 1 n T 2 , i ( t ) . KINGstyle \Sigma _2((t+1)}=1,0frac ggiosum i=1}^{n}T_{2,i((t)}(\ Mathematik) {x} _i}-Getränkesymbol {\mu _2((t+1))(\ Mathematikb= {x}-  Binnenmarktzeichen Mememu _2}^{(t+1)}^{\top =top =pi=1}^{n}T_2,  the  if  E bf  Z ) ( t ) , x [ Log  L L ( t ) ; x , Z ) ] ≤ E Z θ  1  1 ( t - 1 ) , x [ Log  L L (  t  1  1  1  1  1  1  1 } } }  E  E  E  E  E  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 )  1  1 ) ) . ) ) ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  Generalisierung Der oben dargestellte Algorithmus kann für Mischungen von mehr als zwei multivarialen normalen Vertriebenen allgemeinisiert werden. Trunziert und gedämpft Der EM-Algorithmus wurde in dem Fall umgesetzt, in dem ein zugrunde liegendes lineares Regressionsmodell existiert, das die Variationen einiger Mengen erläutert, aber wo die tatsächlich beobachteten Werte gedämpft oder gebremst werden. Sonderfälle dieses Modells umfassen censored oder trunge Beobachtungen eines normalen Vertriebs. Alternative EM passt in der Regel zu einer lokalen Optimierung, nicht unbedingt dem globalen optimalen, ohne dass die Konvergenzquote im Allgemeinen gebunden ist. Es ist möglich, dass es in hohen Dimensionen willkürlich schlecht sein kann und es kann eine exponentielle Anzahl lokaler Optiker geben. Man braucht daher alternative Methoden für garantiertes Lernen, vor allem in der hochdimensionalen Umgebung. Alternativen zu EM bestehen mit besseren Garantien für Kohärenz, die als zeitbasierte Ansätze oder sogenannte spektrale Techniken gelten. Impulsbasierte Ansätze, um die Parameter eines probabilistischen Modells zu lernen, sind in jüngster Zeit wachsendes Interesse, da sie Garantien wie die globale Konvergenz unter bestimmten Bedingungen im Gegensatz zu EM genießen, die oft durch die Frage der Festnahme in lokaler Optik bedroht sind. Algorithms mit Lerngarantien können für eine Reihe wichtiger Modelle wie Mischungsmodelle, HMM usw. abgeleitet werden. Für diese spektralen Methoden gibt es keine spekulative lokale Optik, und die wahren Parameter können unter bestimmten Bedingungen konsequent geschätzt werden. Siehe auch Mischungsverteilungsdichte Schätzung der Gesamtabsorptionsspektroskopie Der EM-Algorithmus kann als Sonderfall des Majorisierungs-minimization (MM)-Algorithmus angesehen werden. Referenzen Weitere Lesung Hogg, Robert; McKean, Joseph; Craig Allen (2005). Einführung in mathematische Statistiken. Oberstes Fluss, NJ: Pearson Prentice Hall.pp.359–364 Dellaert, Frank (2002). "Die Erwartung der Maximierung Algorithm". CiteSeerX 10,9.9735 gibt eine einfachere Erklärung des EM-Algorithmus zur Senkung der Maximierung. Christopher M. (2006). Mustererkennung und Maschinenbau.Springer.ISBN UV0-387-31073-2.Gupta, M. R. Chen, Y. (2010) Theorie und Verwendung des EM Algorithm. Stiftungen und Trends in der Signalverarbeitung.4 (3): 223–296.CiteSeerX 10.1.1.219.6830.doi:10.1561/2000000034.A gut geschriebenes kurzes Buch über EM, einschließlich detaillierter Ableitung von EM für GMMs, HMMs und Dirichlet. Bilmes, Jeff (1998)."Ein Gentle-Feed des EM Algorithm und seine Anwendung auf Parameter Estimation für Gaussian Mixture und versteckte Markov Modelle. CiteSeerX 10.1.1.28.613 umfasst eine vereinfachte Ableitung der EM-Angleichungen für Gausian Mixtures und Gausian Mixture versteckten Markov Modelle. McLachlan, Geoffrey J; Krishnan, Thriyambakam (2008). EM Algorithm und Verlängerungen (2. ed). Hoboken: Haas. [0-471-20170-0. Externe Links Verschiedene 1D, 2D- und 3D-Demonstrationen von EM zusammen mit Mixture Modelling werden im Rahmen der funktionstüchtigen SOCR-Tätigkeiten und -Appellen bereitgestellt. Diese Applets und Aktivitäten zeigen empirische Angaben zu den Eigenschaften des EM-Algorithmus für Parameterschätzungen in unterschiedlichen Einstellungen. k-MLE: Ein schneller Algorithmus für das Erlernen statistischer Mischung Modelle Klasse C+ (GPL) einschließlich Gaussian Mixtures Online-Textbuch: Informationstheorie, Gleichgültigkeit und Lernen Algorithms, von David J.C MacKay enthält einfache Beispiele des EM-Algorithms, wie die Bündelung des weichen k-means-Algorithms, und betont die unterschiedliche Ansicht des EM-Algorithms, wie in Kapitel 33.7 der Version 7.2 (v.) beschrieben. M. J. Beal umfasst Vergleiche von EM zu varialem Bayesian EM und deren Ursachen für mehrere Modelle, darunter die unterschiedlichen Bayesian HMMs (Kapitel). Maximization Algorithm: Kurzinformation, eine eigenständige Ableitung des EM Algorithm durch Sean Borman. EM Algorithm, von Xiaojin Zhu.EM Algorithmus und Varianten: ein informelles Lehrprogramm von Alexis Roche. Klare und klare Beschreibung von EM und vielen interessanten Varianten.