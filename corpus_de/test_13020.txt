Digitales Video ist eine elektronische Darstellung von bewegten visuellen Bildern (Video) in Form von codierten digitalen Daten. Dies ist im Gegensatz zu analogem Video, das bewegte visuelle Bilder in Form von analogen Signalen darstellt. Digitales Video umfasst eine Reihe von digitalen Bildern, die in schneller Folge angezeigt werden. Digitales Video wurde 1986 erstmals kommerziell mit dem Sony D1 Format eingeführt, das ein unkomprimiertes Standard-Definitions-Komponenten-Videosignal in digitaler Form aufgezeichnet hat. Neben unkomprimierten Formaten umfassen heute beliebte komprimierte digitale Videoformate H.264 und MPEG-4.Moderne Interconnect-Standards, die zur Wiedergabe von digitalem Video verwendet werden, umfassen HDMI, DisplayPort, Digital Visual Interface (DVI) und serielle digitale Schnittstelle (SDI). Digitales Video kann kopiert und ohne Qualitätsabbau wiedergegeben werden. Im Gegensatz dazu, wenn analoge Quellen kopiert werden, erleben sie Generationsverlust. Digitales Video kann auf digitalen Medien wie Blu-ray Disc, auf Computer-Datenspeicherung gespeichert oder über das Internet gestreamt werden, um Benutzer zu beenden, die Inhalte auf einem Desktop-Computerbildschirm oder einem digitalen Smart-TV sehen. Zu den digitalen Videoinhalten wie Fernsehsendungen und Filmen gehören heute auch ein digitaler Audio-Soundtrack. Geschichte Digitale Videokameras Basis für digitale Videokameras sind Metalloxid-Halbleiter-Bildsensoren (MOS). Der erste praktische Halbleiterbildsensor war das 1969 von Willard S. Boyle erfundene ladungsgekoppelte Gerät (CCD), das einen Nobelpreis für seine Arbeit in der Physik gewonnen hat. auf Basis der MOS-Kondensatortechnologie. Nach der Kommerzialisierung von CCD-Sensoren in den späten 1970er- bis Anfang der 1980er-Jahre begann die Unterhaltungsindustrie langsam, von analogem Video in die digitale Bildgebung und digitale Video überzugehen. Dem CCD folgte der in den 1990er Jahren entwickelte CMOS-Aktivpixel-Sensor (CMOS-Sensor). CMOS sind aufgrund ihrer geringen Größe, hohen Geschwindigkeit und geringen Stromverbrauch vorteilhaft. CMOS werden heute am häufigsten in den Digitalkameras in iPhones gefunden, die als Bildzeiger für das Gerät verwendet werden. Digitale Videocodierung Die frühesten Formen der digitalen Videocodierung begannen in den 1970er Jahren, mit unkomprimierten Puls-Code-Modulation (PCM) Video, die hohe Bitraten zwischen 45–140 Mbps für Standard-Definition (SD)-Inhalte erfordern. Praktische digitale Video-Codierung wurde schließlich mit diskreter Cosinus-Transformation (DCT) eine Form der verlustreichen Kompression ermöglicht. Die DCT-Verdichtung wurde von Nasir Ahmed 1972 erstmals vorgeschlagen und von Ahmed 1973 mit T. Natarajan und K. R. Rao an der University of Texas entwickelt. In den 1980er Jahren wurde DCT zum Standard für die digitale Videokompression. Der erste digitale Videocodierungsstandard war H.120, erstellt vom (International Telegraph and Telephone Consultative Committee) oder CCITT (jetzt ITU-T) im Jahr 1984. H.120 war aufgrund der schwachen Leistung nicht praktisch. H.120 basierte auf einer differentiellen Puls-Code-Modulation (DPCM), einem Kompressionsalgorithmus, der für die Videocodierung ineffizient war. In den späten 1980er Jahren begannen einige Unternehmen, mit DCT zu experimentieren, eine viel effizientere Form der Komprimierung für die Videocodierung. Die CCITT erhielt 14 Vorschläge für DCT-basierte Videokompressionsformate, im Gegensatz zu einem einzigen Vorschlag auf der Grundlage der Vektorquantisierung (VQ) Komprimierung. Der H.261 Standard wurde auf Basis der DCT-Kompression entwickelt und wurde zum ersten praktischen Video-Codierung Standard. Seit H.261 wurde die DCT-Kompression durch alle großen Video-Codierung Standards angenommen, die darauf folgten. MPEG-1, entwickelt von der Motion Picture Experts Group (MPEG), gefolgt im Jahr 1991, und es wurde entwickelt, um VHS-Qualität Video zu komprimieren. Es wurde 1994 von MPEG-2/H.262, die das Standard-Videoformat für DVD und SD-Digital-Fernseher. Es folgte 1999 MPEG-4/H.263 und danach 2003 H.264/MPEG-4 AVC, die zum am weitesten verbreiteten Videocodierungsstandard geworden ist. Digitale Videoproduktion In den späten 1970er- bis Anfang der 1980er-Jahre wurden Videoproduktionsanlagen vorgestellt, die in ihren internen Arbeiten digital waren. Diese beinhalteten Zeitbasiskorrekturen (TBC) und digitale Videoeffekte (DVE) Einheiten. Sie werden betrieben, indem sie einen Standard analogen Composite-Videoeingang einnehmen und intern digitalisieren. Dadurch wurde es einfacher, das Videosignal, wie bei einem TBC, zu korrigieren oder zu verbessern oder Effekte im Falle einer DVE-Einheit zu manipulieren und zu addieren. Die digitalisierte und verarbeitete Videoinformation wurde dann wieder in Standard-Analogvideo zur Ausgabe umgewandelt. Später in den 1970er Jahren entwickelten Hersteller von professionellen Video-Broadcast-Geräten, wie Bosch (durch ihre Fernsehabteilung) und Ampex Prototypen digitaler Videoband-Recorder (VTR) in ihren Forschungs- und Entwicklungslabors.Boschs Maschine nutzte einen modifizierten 1 Zoll Typ B Videoband Transport und verzeichnete eine frühe Form von CCIR 601 Digital Video. Der digitale Videorekorder von Ampex nutzte einen modifizierten 2-Zoll-Quadruplex-Videotape VTR (ein Ampex AVR-3) mit individueller Digital-Video-Elektronik und einem speziellen achteckigen 8-Kopf-Kopf-Kopf-Kopfrad (regelmäßige analoge 2" Quad-Maschinen verwendet nur 4 Köpfe). Wie Standard 2" Quad, die Audio auf der Ampex-Prototyp-Digitalmaschine, die von seinen Entwicklern als Annie benannt, noch aufgezeichnet das Audio in analoger als lineare Tracks auf dem Band. Keine dieser Maschinen von diesen Herstellern wurden jemals kommerziell vertrieben. Digitales Video wurde 1986 erstmals kommerziell mit dem Sony D1 Format eingeführt, das ein unkomprimiertes Standard-Definitions-Komponenten-Videosignal in digitaler Form aufgezeichnet hat. Komponenten-Video-Verbindungen benötigte 3 Kabel, aber die meisten Fernsehanlagen wurden für zusammengesetzte NTSC oder PAL-Video mit einem Kabel verdrahtet. Aufgrund dieser Unvereinbarkeit die Kosten des Recorders, D1 wurde hauptsächlich von großen Fernsehnetzwerken und anderen komponenten-videofähigen Videostudios verwendet. 1988 entwickelt und veröffentlichten Sony und Ampex das D2 digitale Videokassetten-Format, das Video digital ohne Kompression im ITU-601-Format aufgenommen hat, ähnlich wie D1. Im Vergleich dazu hatte D2 den großen Unterschied, das Video in Kompositform mit dem NTSC-Standard zu kodieren, was nur Einzelkabel-Verbund-Videoverbindungen zu und von einem D2 VCR erforderte. Dies machte es zu einer perfekten Passform für die Mehrheit der Fernseheinrichtungen zu der Zeit. D2 war in den späten 80er und 90er Jahren ein erfolgreiches Format in der Fernsehindustrie. D2 wurde auch in dieser Zeit als Master-Band-Format für die Mastering Laserdiscs weit verbreitet. D1 & D2 würde schließlich durch billigere Systeme durch Videokompression ersetzt werden, vor allem Sonys Digital Betacam, die in die Fernsehstudios des Netzwerks eingeführt wurden. Weitere Beispiele für digitale Videoformate unter Verwendung von Kompression waren Ampexs DCT (die ersten, die 1992 eingeführt werden), die Industrie-Standard DV und MiniDV und seine professionellen Variationen, Sony DVCAM und Panasonic DVCPRO und Betacam SX, eine kostengünstigere Variante von Digital Betacam mit MPEG-2 Kompression. Eines der ersten digitalen Video-Produkte, die auf persönlichen Computern laufen, war PACo: Der PICS Animation Compiler von The Company of Science & Art in Providence, RI. Sie wurde ab 1990 entwickelt und im Mai 1991 erstmals ausgeliefert. PACo konnte unbegrenzte Video mit synchronisiertem Sound aus einer einzigen Datei (mit der .CAV-Dateierweiterung) auf CD-ROM streamen. Die Erstellung erforderte einen Mac und die Wiedergabe war auf Macs, PCs und Sun SPARCstations möglich. QuickTime, das Multimedia-Framework von Apple Computer, wurde im Juni 1991 veröffentlicht. Audio Video Interleave von Microsoft folgte 1992. Die ersten Tools zur Erstellung von Inhalten auf Verbraucherebene waren roh und erfordern eine analoge Videoquelle, die auf ein computerlesbares Format digitalisiert werden muss. Während die Qualität des Verbrauchers zunächst schnell ansteigt, stieg das digitale Video schnell in der Qualität an, zunächst mit der Einführung von Wiedergabestandards wie MPEG-1 und MPEG-2 (für den Einsatz in Fernsehübertragungen und DVD-Medien gedacht), und der Einführung des DV-Bandformats, mit dem Aufnahmen im Format direkt auf digitale Videodateien über einen FireWire-Port auf einem Editiercomputer übertragen werden können. Dies vereinfachte den Prozess, so dass nicht-lineare Bearbeitungssysteme (NLE) auf Desktop-Computern ohne externe Wiedergabe- oder Aufnahmegeräte billig und breit eingesetzt werden können. Die weit verbreitete Übernahme von digitalen Video- und Begleitformaten hat die für ein hochauflösendes Videosignal benötigte Bandbreite reduziert (mit HDV und AVCHD sowie mehrere kommerzielle Varianten wie DVCPRO-HD, die alle weniger Bandbreite als ein Standard-Definitions-Analogsignal verwenden). Diese Einsparungen haben die Anzahl der Kanäle, die auf Kabelfernsehen und Direktsender-Satelliten-Systemen zur Verfügung stehen, erhöht, Möglichkeiten für die Frequenzumverteilung terrestrischen Fernsehfrequenzen geschaffen und bandlose Camcorder basierend auf Flash-Speicher möglich gemacht, unter anderem Innovationen und Effizienzen. Digitales Video und Kultur Kultur Kulturell, digitales Video erlaubt Video und Film weit verbreitet und populär zu werden, nützlich für Unterhaltung, Bildung und Forschung. Digitales Video ist in Schulen immer häufiger verbreitet, wobei Schüler und Lehrer Interesse daran haben, sie auf relevante Weise zu nutzen. Digitales Video hat auch Anwendungen im Gesundheitswesen, so dass Ärzte Baby Herzfrequenzen und Sauerstoffspiegel verfolgen.Darüber hinaus beeinflusste der Switch von analogen zu digitalen Videomedien auf verschiedene Weise, wie zum Beispiel, wie Unternehmen Kameras zur Überwachung verwenden. Geschlossene Schaltung Fernsehen (CCTV) auf die Verwendung von digitalen Videorekordern (DVR), die die Frage, wie man Aufnahmen für die Sammlung von Beweisen speichern. Heute kann digitales Video komprimiert werden, um Speicherplatz zu sparen. Digital Television Digital Television, auch bekannt als DTV, ist die Produktion und Übertragung von digitalen Video von Netzwerken zu Verbrauchern. Diese Technik verwendet die digitale Codierung anstelle von analogen Signalen, die vor den 1950er Jahren verwendet werden. Im Vergleich zu analogen Methoden ist DTV schneller und bietet mehr Möglichkeiten und Möglichkeiten für Daten zu übertragen und zu teilen. Überblick Digitales Video umfasst eine Reihe von digitalen Bildern, die in schneller Folge angezeigt werden. Im Kontext von Video werden diese Bilder Frames genannt. Die Rate, mit der Frames angezeigt werden, ist als Framerate bekannt und wird in Frames pro Sekunde (FPS) gemessen. Jeder Rahmen ist ein digitales Bild und umfasst somit eine Bildbildung von Pixeln. Pixel haben nur eine Eigenschaft, ihre Farbe. Die Farbe eines Pixels wird durch eine feste Anzahl von Bits dieser Farbe dargestellt. Je mehr Bits, desto feiner können die Farben wiedergegeben werden. Dies wird die Farbtiefe des Videos genannt. Interlacing Im verketteten Video besteht jeder Rahmen aus zwei Hälften eines Bildes. Die erste Hälfte enthält nur die ungeraden Linien eines Vollrahmens. Die zweite Hälfte enthält nur die geraden Linien. Diese Hälften werden einzeln als Felder bezeichnet. Zwei aufeinanderfolgende Felder komponieren einen Vollrahmen. Wenn ein interlaced Video eine Framerate von 30 Frames pro Sekunde hat, beträgt die Feldrate 60 Felder pro Sekunde, obwohl beide Teil von interlaced Video, Frames pro Sekunde und Felder pro Sekunde separate Zahlen sind. Bitrate und BPPBy Definition, Bitrate ist eine Messung der Rate von Informationsinhalten aus dem digitalen Videostream. Bei nicht komprimiertem Video entspricht die Bitrate direkt der Qualität des Videos, da die Bitrate proportional zu jeder Eigenschaft ist, die die Videoqualität beeinflusst. Die Bitrate ist eine wichtige Eigenschaft bei der Übertragung von Video, da die Übertragungsstrecke in der Lage sein muss, diese Bitrate zu unterstützen. Eine Bitrate ist auch wichtig, wenn es um die Speicherung von Video geht, da, wie oben gezeigt, die Videogröße proportional zur Bitrate und der Dauer ist. Die Videokompression wird verwendet, um die Bitrate bei geringem Qualitätseffekt stark zu reduzieren. Bits pro Pixel (BPP) ist ein Maß für die Effizienz der Kompression. Ein wahrfarbiges Video ohne Kompression kann ein BPP von 24 Bit/Pixel haben. Chroma Subsampling kann die BPP auf 16 oder 12 Bit/Pixel reduzieren. Durch die Anwendung von Jpeg-Verdichtung auf jedem Frame kann das BPP auf 8 oder sogar 1 Bit/Pixel reduziert werden. Die Anwendung von Videokompressionsalgorithmen wie MPEG1, MPEG2 oder MPEG4 ermöglicht fraktionierte BPP-Werte. Konstante Bitrate gegen variable Bitrate BPP stellt die mittleren Bits pro Pixel dar. Es gibt Kompressionsalgorithmen, die die BPP während der gesamten Dauer des Videos fast konstant halten. In diesem Fall erhalten wir auch Videoausgabe mit konstanter Bitrate (CBR). Dieses CBR-Video eignet sich zum Echtzeit-, nicht-gepufferten, festen Bandbreiten-Videostreaming (z.B. bei Videokonferenzen). Da nicht alle Frames auf der gleichen Ebene komprimiert werden können, weil Qualität für Szenen mit hoher Komplexität stärker beeinflusst wird, versuchen einige Algorithmen, das BPP ständig anzupassen. Sie halten die BPP hoch und komprimieren komplexe Szenen und niedrig für weniger anspruchsvolle Szenen. Auf diese Weise bietet es die beste Qualität bei der kleinsten durchschnittlichen Bitrate (und die kleinste Dateigröße entsprechend). Dieses Verfahren erzeugt eine variable Bitrate, da es die Variationen des BPP verfolgt. Technische Übersicht Standard-Filmbestände erfassen typischerweise bei 24 Bildern pro Sekunde. Für Video gibt es zwei Frame Rate Standards: NTSC, mit 30/1.001 (ca. 29.97) Frames pro Sekunde (ca. 59.94 Felder pro Sekunde,) und PAL, 25 Frames pro Sekunde (50 Felder pro Sekunde). Digitale Videokameras kommen in zwei verschiedenen Bildaufnahmeformaten: interlaced und progressive Scan. Interlaced Kameras erfassen das Bild in wechselnden Zeilensätzen: die ungeraden Linien werden gescannt, und dann werden die geradzahligen Zeilen gescannt, dann werden die ungeradzahligen Zeilen wieder gescannt und so weiter. Ein Satz von ungeraden oder sogar Linien wird als Feld bezeichnet, und eine aufeinanderfolgende Paarung von zwei Feldern entgegengesetzter Parität wird als Rahmen bezeichnet. Progressive Scan-Kameras erfassen alle Zeilen in jedem Frame als eine Einheit. So erfasst interlaced Video die Szenenbewegung doppelt so oft wie progressives Video für die gleiche Framerate.Progressive-scan erzeugt in der Regel ein etwas schärferes Bild, aber Bewegung kann nicht so glatt wie verkettetes Video sein. Digitales Video kann ohne Generationsverlust kopiert werden, was Qualität in analogen Systemen verschlechtert. Eine Änderung von Parametern wie Frame-Größe oder eine Änderung des digitalen Formats kann jedoch aufgrund von Bildskalierung und Transcodierungsverlusten die Qualität des Videos verringern. Digitales Video kann auf nichtlinearen Bearbeitungssystemen manipuliert und bearbeitet werden. Digitales Video hat deutlich niedrigere Kosten als 35 mm Film. Im Vergleich zu den hohen Kosten für Filmmaterial sind die für die digitale Videoaufnahme verwendeten digitalen Medien wie Flash-Speicher oder Festplattenlaufwerk sehr kostengünstig. Digitales Video ermöglicht es auch, Aufnahmen vor Ort ohne die teure und zeitaufwendige chemische Verarbeitung durch Film zu sehen. Netzwerk-Transfer von digitalen Video macht physische Lieferungen von Bändern und Filmrollen unnötig. Digitales Fernsehen (einschließlich hochwertiger HDTV) wurde Anfang 2000 in den meisten entwickelten Ländern eingeführt. Heute wird digitales Video in modernen Handys und Videokonferenzsystemen verwendet. Digitales Video wird für die Internet-Distribution von Medien verwendet, einschließlich Streaming-Video und Peer-to-Peer-Film-Distribution. Viele Arten von Videokompression existieren, um digitales Video über das Internet und auf optischen Festplatten zu bedienen. Die für die professionelle Bearbeitung verwendeten Dateigrößen von digitalem Video sind für diese Zwecke in der Regel nicht praktisch, und das Video erfordert eine weitere Kompression mit Codecs für Freizeitzwecke. Ab 2011 beträgt die höchste Auflösung für die digitale Video-Generation 35 Megapixel (8192 x 4320). Die höchste Geschwindigkeit wird in industriellen und wissenschaftlichen Hochgeschwindigkeitskameras erreicht, die in der Lage sind, 1024x1024 Video mit bis zu 1 Million Frames pro Sekunde für kurze Zeiträume der Aufnahme zu filmen. Technische Eigenschaften Live-Digital-Video verbraucht Bandbreite. Aufgenommenes digitales Video verbraucht Datenspeicher. Die erforderliche Bandbreite bzw. Speichermenge wird durch die Rahmengröße, Farbtiefe und Rahmenrate bestimmt. Jedes Pixel verbraucht eine Anzahl von durch die Farbtiefe bestimmten Bits. Die zur Darstellung eines Datenrahmens erforderlichen Daten werden durch Multiplikation mit der Anzahl der Pixel im Bild bestimmt. Die Bandbreite wird durch Multiplikation des Speicherbedarfs für einen Rahmen durch die Rahmenrate bestimmt. Die Gesamtspeicheranforderungen für ein Programm können dann durch Multiplizieren der Bandbreite durch die Programmdauer bestimmt werden. Diese Berechnungen sind für unkomprimiertes Video genau, aber aufgrund der relativ hohen Bitrate von unkomprimiertem Video wird die Videokompression weitgehend verwendet. Bei komprimiertem Video benötigt jeder Frame nur einen geringen Prozentsatz der ursprünglichen Bits. Beachten Sie, dass es nicht notwendig ist, dass alle Frames gleich um den gleichen Prozentsatz komprimiert werden. Betrachten Sie stattdessen den durchschnittlichen Kompressionsfaktor für alle zusammengenommenen Rahmen. Schnittstellen und Kabel Eingebaute digitale Videoschnittstellen Digitale Komponente Video Digitale visuelle Schnittstelle (DVI) DisplayPortHDBaseT High-Definition Multimedia Interface (HDMI)Serial Digital Interface (SDI)Unified Display InterfaceAllgemeine Anwendungsschnittstellen verwenden, um digitales Video FireWire (IEEE 1394)Universal Serial Bus (USBIP) zu transportieren. Dafür gibt es zwei Ansätze: Verwendung von RTP als Wrapper für Videopakete wie mit SMPTE 2022 1–7 MPEG Transportpakete werden direkt im UDP-Paket platziert Andere Methoden der Übertragung von Video über IP Network Device Interface SMPTE 2110 Speicherformate Encoding CCIR 601 verwendet für Rundfunksender MPEG-4 gut für die Online-Verteilung von großen Videos und Video aufgezeichnet auf Flash-Speicher MPEG-2 verwendet für DVDs, Super-VCDs, und viele Fernsehformate MPEG-1 für Video-CDs H.261 H.263DVCPRO50, DVCPROHD unterstützen höhere Bandbreiten im Vergleich zu Panasonics DVCPRO. HDCAM wurde von Sony als hochauflösende Alternative zu DigiBeta eingeführt. MicroMV — MPEG-2-Format Daten auf einer sehr kleinen, Matchbook-Skala aufgezeichnet; obsolete ProHD — Name von JVC für seine MPEG-2-basierten professionellen Camcorder Blu-ray Disc DVD VCD Siehe auch Hinweise Referenzen Externe Links Die DV, DVCAM, & DVCPRO Formate – Tech-Details, FAQ und Links Standard-Digital-TV- und Videoformate. Die Koinzidenz von Wünschen (oft als doppelte Koinzidenz von Wünschen bekannt) ist ein wirtschaftliches Phänomen, bei dem zwei Parteien jeweils einen Gegenstand halten, den die andere will, so dass sie diese Gegenstände direkt ohne Geldmittel austauschen. Diese Art des Austauschs ist die Grundlage einer schwindenden Wirtschaft. Doppelte Übereinstimmung der Wünsche bedeutet, dass beide Parteien zustimmen müssen, jede Ware zu verkaufen und zu kaufen. Unter diesem System entstehen Probleme durch die Unwahrscheinlichkeit der Wünsche, Bedürfnisse oder Ereignisse, die eine Transaktion verursachen oder motivieren, die gleichzeitig und an der gleichen Stelle auftritt. Ein Beispiel ist der Barmusiker, der mit Alkohol oder Essen bezahlt wird, Gegenstände, die sein Vermieter nicht als Mietzahlung akzeptieren wird, wenn der Musiker lieber einen Monat Schutz haben würde. Wenn stattdessen der Vermieter des Musikers eine Party werfen und Musik für sie wünschen würde, indem er den Musiker anheuert, es zu spielen, indem er die Miete des Monats im Austausch anbietet, dann wäre ein Zufall der Wünsche vorhanden. In-kind-Transaktionen haben mehrere Einschränkungen, da es nur effektiv funktioniert, wenn eine Partei tatsächlich den Artikel hat, oder ist bereit, diesen Artikel zu machen, dass die andere Partei sucht. Ein geldpolitisches Medium kann dieses Problem lösen, da es die Freiheit bietet, dass die Ehemaligen an anderen interessanten Dingen arbeiten oder weggeben, anstatt sich dafür zu belasten, einen bestimmten Gegenstand zu stellen. Dies kann die Innovation langfristig behindern, vor allem, wenn Barter in größerem Maßstab umgesetzt wurde. Sie können sich auch nur auf befriedigende Parteien konzentrieren, die Geldmittel haben. In der Zwischenzeit kann die letztere Partei ihr Mittel des Lohns verwenden, um zu warten und zu sehen, welche Partei ihnen das gewünschte Produkt liefern würde. Neben Barter, andere Arten von in-kind-Transaktionen leiden auch unter dem Zufall von will Problem in Abwesenheit eines Mediums des Austauschs. Romanze, zum Beispiel, setzt oft auf einen doppelten Zufall der Wünsche. Wenn Max Mallory mag, aber Mallory Max nicht mag, dann können die beiden die Vorteile von Romantik nicht sinnvoll austauschen. Nur wenn ein Willezusammenhang besteht, kann eine gegenseitig vorteilhafte Beziehung ohne Austauschmittel hergestellt werden. John Hickman argumentiert, dass Barter den zukünftigen interplanetarischen Handel charakterisieren kann, weil die viel geringeren Kosten der Kommunikation im Vergleich zum Transport eine gemeinsame Währung zwischen den Volkswirtschaften der beiden Welten unmöglich machen. Als ein weiteres Beispiel, wenn der Reichtum während der Ehe, Scheidung, Erbschaft und andere entscheidende Lebensereignisse, oder während der Erhebung von Steuern oder Tribut übertragen wird, ist es unwahrscheinlich, dass dieses Ereignis mit dem Wunsch des Empfängers nach den Waren zusammenfallen, die der Zahler leicht erhalten kann. Alle diese Transaktionen führen zu einem unwahrscheinlichen Zufall von Wünschen und Ereignissen, die durch das Vorhandensein eines Geldmittels gelöst werden können. William Stanley Jevons und Ross M. Starr verwenden den Begriff "doppelte Übereinstimmung der Wünsche" für das gleiche Konzept. Siehe auch Suchreferenzen W.S Jevons (1875,) Geld und der Mechanismus des Austausches, Kapitel 1, Absätze 5-6.London: Macmillan. Carl Menger, "On the Origin of Money" Nobuhiro Kiyotaki und Randall Wright (1989), "Über Geld als Medium des Austauschs", "Journal of Political Economy" 97, S. 927–54.