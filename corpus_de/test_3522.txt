In der Mathematik und Informatik ist ein Algorithmus (hören) eine endliche Sequenz von gut definierten, computerimplementierbaren Anweisungen, typischerweise eine Klasse von spezifischen Problemen zu lösen oder eine Berechnung durchzuführen. Algorithmen sind immer eindeutig und werden als Spezifikationen für die Durchführung von Berechnungen, Datenverarbeitung, automatisierte Argumentation und andere Aufgaben verwendet. Eine heuristische Technik ist dagegen eine Technik, die bei der Problemlösung eingesetzt wird, die praktische Methoden und/oder verschiedene Schätzwerte verwendet, um Lösungen herzustellen, die zwar nicht optimal, aber unter den Umständen ausreichend sind. Als effektives Verfahren kann ein Algorithmus innerhalb einer endlichen Menge von Raum und Zeit und in einer gut definierten formalen Sprache zur Berechnung einer Funktion ausgedrückt werden. Ausgehend von einem Anfangszustand und einem Anfangseingang (perhaps leer) beschreiben die Instruktionen eine Berechnung, die bei Ausführung durch eine endliche Anzahl von gut definierten aufeinanderfolgenden Zuständen verläuft, schließlich die Ausgabe erzeugt und an einem Endendzustand endet. Der Übergang von einem Zustand zum nächsten ist nicht unbedingt deterministisch; einige Algorithmen, die als randomisierte Algorithmen bekannt sind, enthalten zufällige Eingaben. Das Konzept des Algorithmus existiert seit der Antike. Arithmetische Algorithmen, wie ein Teilungsalgorithmus, wurden von alten babylonischen Mathematikern c. 2500 BC und ägyptische Mathematiker c. 1550 v. Chr. Griechische Mathematiker nutzten später Algorithmen in 240 BC im Sieb von Eratosthenes für die Suche nach Primzahlen, und der Euclidean Algorithmus für die Suche nach dem größten gemeinsamen Divisor von zwei Zahlen. Arabische Mathematiker wie al-Kindi im 9. Jahrhundert nutzten kryptographische Algorithmen für schlüsselbrechende, basierend auf der Frequenzanalyse. Der Wortalgorithmus selbst stammt aus dem Namen des 9. Jahrhunderts Mathematiker Muḥammad ibn Mūsā al-Khwārizmī, dessen nisba (erkennt ihn wie aus Khwarazm) war lateinisiert als Algoritmi. Eine teilweise Formalisierung des modernen Algorithmuskonzepts begann mit Versuchen, das Entscheidungsproblem (Entscheidungsproblem) von David Hilbert im Jahr 1928 zu lösen. Spätere Formalisierungen wurden als Versuche gerahmt, "effektive Kalkulation" oder "effektive Methode" zu definieren. Diese Formalisierungen umfassten die rekursive Funktion der Gödel-Herbrand-Kleene von 1930, 1934 und 1935, die Lambda-Kalk der Alonzo-Kirche von 1936, die Emil Post-Formulierung 1 von 1936 und Alan Turing's Turing Maschinen von 1936–37 und 1939. EtymologyDer Wortalgorithmus hat seine Wurzeln in der Lateinisierung der nisba, die seinen geographischen Ursprung anzeigt, des Namens des persischen Mathematikers Muhammad ibn Musa al-Khwarizmi zu Algorismus. Al-Khwārizmī (Arabized Persian الواری c.780–850) war ein Mathematiker, Astronom, Geograph und Gelehrter im Haus der Weisheit in Bagdad, dessen Name bedeutet "die Heimat von Khwarazm", eine Region, die Teil des größeren Iran war und ist jetzt in Usbekistan. Ca. 825 schrieb al-Khwarizmi ein arabisches Sprachabkommen über das hindu-arabische Ziffernsystem, das im 12. Jahrhundert ins lateinische übersetzt wurde. Das Manuskript beginnt mit der Phrase Dixit Algorizmi '(Thus spake Al-Khwarizmi'), wo Algorizmi die Lateinisierung des Übersetzers von Al-Khwarizmi war. Al-Khwarizmi war der am weitesten verbreitete Mathematiker in Europa im späten Mittelalter, vor allem durch ein anderes seiner Bücher, die Algebra. In lateinischen, algoristischen, englischen Algorismus, der Korruption seines Namens, bedeutete einfach das "dezimale Zahlensystem". Im 15. Jahrhundert wurde das lateinische Wort unter dem Einfluss des griechischen Wortes mercaptoριθμός (arithmos,) Nummer (vgl. arithmetic) auf algorithmus verändert und der entsprechende englische Begriffsalgorithmus erst im 17. Jahrhundert bezeugt; der moderne Sinn wurde im 19. Jahrhundert eingeführt. Auf Englisch wurde es zunächst in etwa 1230 und dann von Chaucer in 1391 verwendet. Englisch verabschiedete den französischen Begriff, aber erst im späten 19. Jahrhundert nahm der Algorithmus die Bedeutung, die er in modernem Englisch hat. Eine weitere frühe Verwendung des Wortes ist ab 1240, in einem Handbuch mit dem Titel Carmen de Algorismo komponiert von Alexandre de Villedieu. Es beginnt mit: Haec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris. was übersetzt zu: Algorismus ist die Kunst, mit der wir gegenwärtig diese indischen Figuren verwenden, die zwei mal fünf. Das Gedicht ist ein paar hundert Zeilen lang und fasst die Kunst der Berechnung mit dem neuen Stil indischen Würfel (Tali Indorum,) oder Hindu Ziffern zusammen. Informelle Definition Eine informelle Definition könnte "eine Reihe von Regeln sein, die genau eine Abfolge von Operationen definiert", die alle Computerprogramme (einschließlich Programme, die keine numerischen Berechnungen durchführen,) und (zum Beispiel) jede vorgeschriebene bürokratische Prozedur oder Kochbuchrezept enthalten würde. Im Allgemeinen ist ein Programm nur ein Algorithmus, wenn es schließlich aufhört – auch wenn unendliche Schleifen manchmal wünschenswert sein können. Ein prototypisches Beispiel eines Algorithmus ist der Euclidean-Algorithmus, der zur Bestimmung des maximalen gemeinsamen Divisors von zwei Ganzzahlen verwendet wird; ein Beispiel (es gibt andere) wird durch das Ablaufdiagramm oben und als Beispiel in einem späteren Abschnitt beschrieben. Boolos, Jeffrey & 1974, 1999 bieten eine informelle Bedeutung des Wortalgorithmus im folgenden Zitat: Kein Mensch kann schnell genug schreiben, oder lange genug, oder klein genug † ( †'smaller und kleiner ohne Limit ... Sie würden versuchen, auf Moleküle, auf Atomen, auf Elektronen zu schreiben"), um alle Mitglieder eines zahllosen unendlichen Satzes durch Ausschreiben ihrer Namen, nacheinander, in irgendeiner Notation. Aber Menschen können etwas Gleiches tun, bei bestimmten unzähligen Sätzen: Sie können ausdrückliche Anweisungen zur Bestimmung des neunten Teils des Satzes geben, für willkürliche endliche n.Such-Anweisungen sind ganz explizit zu geben, in einer Form, in der sie von einer Rechenmaschine gefolgt werden könnten, oder von einem Menschen, der in der Lage ist, nur sehr elementare Vorgänge auf Symbolen durchzuführen. Ein "enumerisch unendlicher Satz" ist eins, dessen Elemente in eine Übereinstimmung mit den Ganzzahlen gebracht werden können. So sagen Boolos und Jeffrey, dass ein Algorithmus Anweisungen für einen Prozess impliziert, der Ausgabe ganze Zahlen aus einer beliebigen Eingabe ganze oder ganze Zahlen erzeugt, die theoretisch beliebig groß sein können. Beispielsweise kann ein Algorithmus eine algebraische Gleichung wie y = m + n sein (d.h. zwei beliebige "Eingangsvariablen" m und n, die einen Ausgang y erzeugen), aber verschiedene Autoren Versuche, den Begriff zu definieren, zeigen, dass das Wort viel mehr impliziert, etwas in der Reihenfolge (für das Additionsbeispiel): Präzise Anweisungen (in einer von "Computer" verstandenen Sprache) für einen schnellen, effizienten, guten Prozess, der die Bewegungen von "Computer" (Maschine oder Mensch, ausgestattet mit den notwendigen intern enthaltenen Informationen und Fähigkeiten) spezifiziert, um zu finden, zu decodieren und dann willkürliche Eingabe ganze/Symbole m und n, Symbole + und = ... zu verarbeiten und effektiv produzieren, in einer angemessenen Zeit, Ausgabe-Integer y an einer bestimmten Stelle und in einem bestimmten Format. Das Konzept des Algorithmus wird auch verwendet, um den Begriff der Entwertbarkeit zu definieren – ein Begriff, der zentral ist, um zu erklären, wie formale Systeme von einem kleinen Satz von Axiomen und Regeln ausgehen. In der Logik kann die Zeit, die ein Algorithmus ausfüllen muss, nicht gemessen werden, da er offensichtlich nicht mit der üblichen physikalischen Dimension zusammenhängt. Aus solchen Ungewissheiten, die die laufende Arbeit charakterisieren, ergibt sich die Unverfügbarkeit einer Definition von Algorithmen, die sowohl konkreten (in gewissem Sinne) als auch abstrakten Gebrauch des Begriffs entspricht. Formalisierung Algorithmen sind essentiell, wie Computer Daten verarbeiten. Viele Computerprogramme enthalten Algorithmen, die die spezifischen Anweisungen, die ein Computer in einer bestimmten Reihenfolge ausführen sollte, detailliert angeben, um eine bestimmte Aufgabe durchzuführen, wie die Berechnung der Lohnkontrollen der Mitarbeiter oder das Drucken der Berichtskarten der Studenten. So kann ein Algorithmus als jede Folge von Operationen betrachtet werden, die durch ein Turing-komplete System simuliert werden können. Autoren, die diese These geltend machen, sind Minsky (1967,) Savage (1987) und Gurevich (2000): Minsky: "Aber wir werden bei Turing auch behaupten, dass jedes Verfahren, das natürlich als wirksam bezeichnet werden könnte, tatsächlich durch eine (einfache) Maschine realisiert werden kann. Obwohl dies extrem erscheint, sind die Argumente... zu ihren Gunsten schwer zu widerlegen." Gurevich: "... Turings informelles Argument zugunsten seiner These rechtfertigt eine stärkere These: Jeder Algorithmus kann von einer Turing-Maschine simuliert werden ... nach Savage [1987] ist ein Algorithmus ein rechnerischer Prozess, der von einer Turing-Maschine definiert wird". Turing-Maschinen können Rechenprozesse definieren, die nicht enden. Die informellen Definitionen von Algorithmen erfordern in der Regel, dass der Algorithmus immer beendet. Diese Anforderung stellt die Aufgabe, zu entscheiden, ob ein formales Verfahren ein im allgemeinen Fall unmöglicher Algorithmus ist – aufgrund eines großen Theorems der Rechenschaftstheorie, der als Stoppproblem bekannt ist. Typischerweise können bei Zuordnung eines Algorithmus zu Verarbeitungsinformationen Daten von einer Eingabequelle ausgelesen, an ein Ausgabegerät geschrieben und zur Weiterverarbeitung gespeichert werden. Gespeicherte Daten werden als Teil des internen Zustands der Einrichtung betrachtet, die den Algorithmus durchführt. In der Praxis wird der Zustand in einem oder mehreren Datenstrukturen gespeichert. Für einige dieser rechnerischen Prozesse muss der Algorithmus streng definiert werden: in der Weise, wie er unter allen möglichen Umständen angewendet wird, die entstehen könnten. Dies bedeutet, dass alle bedingten Schritte systematisch behandelt werden müssen, wenn auch die Kriterien für jeden Fall klar (und rechnerisch) sein müssen. Da ein Algorithmus eine genaue Liste von präzisen Schritten ist, ist die Reihenfolge der Berechnung immer entscheidend für die Funktion des Algorithmus. In der Regel werden Anweisungen angenommen, um explizit aufgeführt zu werden, und werden als Start "von oben" beschrieben und gehen "unten nach unten" - eine Idee, die formaler durch Steuerung beschrieben wird. Bisher hat die Diskussion über die Formalisierung eines Algorithmus die Räumlichkeiten der zwingenden Programmierung angenommen. Dies ist die häufigste Vorstellung – eine, die versucht, eine Aufgabe in diskreten, mechanischen Mitteln zu beschreiben. Einzigartig für diese Konzeption formalisierter Algorithmen ist der Zuordnungsvorgang, der den Wert einer Variablen festlegt. Es leitet sich von der Intuition des Gedächtnisses als Kratzer. Ein Beispiel einer solchen Zuordnung finden Sie unten. Für einige alternative Vorstellungen von dem, was einen Algorithmus darstellt, siehe funktionelle Programmierung und logische Programmierung. Algorithmen ausdrücken Algorithmen können in vielen Arten von Notation ausgedrückt werden, einschließlich natürlicher Sprachen, Pseudocode, Flussdiagramme, drakon-charts, Programmiersprachen oder Steuertabellen (verarbeitet von Dolmetschern). Natürliche Sprachausdrücke von Algorithmen neigen dazu, Verbose und mehrdeutig zu sein und werden selten für komplexe oder technische Algorithmen verwendet. Pseudocode, Flussdiagramme, drakon-Charts und Steuertabellen sind strukturierte Wege, Algorithmen auszudrücken, die viele der in den Aussagen basierend auf natürlicher Sprache gebräuchlichen Mehrdeutigkeiten vermeiden. Programmiersprachen sind in erster Linie dazu bestimmt, Algorithmen in einer Form auszudrücken, die von einem Computer ausgeführt werden kann, aber auch häufig als Möglichkeit zur Definition oder Dokumentierung von Algorithmen verwendet werden. Es gibt eine Vielzahl von Darstellungen möglich und man kann ein vorgegebenes Turing-Maschinenprogramm als Folge von Maschinentische (siehe Finite-State-Maschine, Zustand Übergangstabelle und Steuertabelle für mehr,) als Flussdiagramme und Drakon-Charts (siehe Zustandsdiagramm für mehr,) oder als Form von rudimentären Maschinencode oder Montagecode genannt "Sets of Quadruples" (siehe Turing-Maschine für mehr). Darstellungen von Algorithmen können wie folgt in drei akzeptierte Ebenen der Turing-Maschinenbeschreibung eingestuft werden: 1 High-Level-Beschreibung "...prose, um einen Algorithmus zu beschreiben, ignorieren die Implementierungsdetails. Auf dieser Ebene müssen wir nicht erwähnen, wie die Maschine ihr Band oder den Kopf verwaltet." 2 Ausführungsbeschreibung "...prose verwendet, um die Art zu definieren, wie die Turing-Maschine ihren Kopf und die Art, wie sie Daten auf seinem Band speichert. Auf dieser Ebene geben wir keine Angaben über Zustände oder Übergangsfunktion. "3 Formale Beschreibung Die detaillierteste, "niedrigste Ebene", gibt der Turing-Maschine "State Table". Ein Beispiel für den einfachen Algorithmus "Add m+n" beschrieben in allen drei Ebenen, siehe Algorithm#Beispiele. Design Algorithm Design bezieht sich auf ein Verfahren oder ein mathematisches Verfahren zur Problemlösung und Engineering Algorithmen. Das Design von Algorithmen ist Teil vieler Lösungstheorien der Betriebsforschung, wie dynamische Programmierung und Teil-und-Konquer. Techniken zur Gestaltung und Implementierung von Algorithmus-Designs werden auch Algorithmus-Design-Muster genannt, mit Beispielen einschließlich der Template-Methode Muster und das Dekorator-Muster. Einer der wichtigsten Aspekte der Algorithmus-Design ist Ressourcen (Laufzeit, Speichernutzung) Effizienz; die große O-Notation wird verwendet, um z.B. das Laufzeitwachstum eines Algorithmus mit der Größe seiner Eingabe zu beschreiben. Typische Schritte bei der Entwicklung von Algorithmen: Problemdefinition Entwicklung eines Modells Spezifikation des Algorithmus Überprüfung der Richtigkeit des Algorithmus Analyse des Algorithmus Implementierung des Algorithmus Programmtests Dokumentationsvorbereitung Implementierung Die meisten Algorithmen sollen als Computerprogramme implementiert werden. Es werden aber auch Algorithmen mit anderen Mitteln, wie beispielsweise in einem biologischen neuronalen Netz (z.B. das menschliche Gehirn, das arithmetische oder einen nach Nahrung suchenden Insekt implementiert), in einem elektrischen Stromkreis oder in einem mechanischen Gerät implementiert. Computeralgorithmen In Computersystemen ist ein Algorithmus grundsätzlich eine in Software von Software-Entwicklern geschriebene Logik, die für den/die beabsichtigten Zielrechner(e) wirksam ist, um die Ausgabe von gegebenem (perhaps null) Eingang zu erzeugen. Ein optimaler Algorithmus, auch in alten Hardware, würde schnellere Ergebnisse produzieren als ein nicht-optimaler (höhere Zeitkomplexität) Algorithmus für den gleichen Zweck, laufen in effizientere Hardware; deshalb werden Algorithmen, wie Computer Hardware, als Technologie betrachtet. " Elegante (kompakt) Programme, gute (schnelle) Programme: Der Begriff "Seinlichkeit und Eleganz" erscheint in Knuth und genau in Chaitin: Knuth: "... wir wollen gute Algorithmen in etwas lose definiertem ästhetischen Sinne. Ein Kriterium ... ist die Zeit, die für die Ausführung des Algorithmus.... Andere Kriterien sind Anpassungsfähigkeit des Algorithmus an Computer, seine Einfachheit und Eleganz, etc."Chaitin: "... ein Programm ist elegant, mit dem ich meine, dass es das kleinste mögliche Programm für die Produktion der Ausgabe, die es tut"Chaitin prefaces seine Definition mit: "Ich werde zeigen, dass Sie nicht beweisen können, dass ein Programm ist elegant" - ein solcher Beweis würde das Halting Problem lösen (ibid). Algorithm versus Funktion berechnet durch einen Algorithmus: Für eine bestimmte Funktion können mehrere Algorithmen existieren. Dies ist wahr, auch ohne die verfügbare Anleitung für den Programmierer zu erweitern. Rogers beobachtet, dass "Es ist ... wichtig, zwischen dem Begriff des Algorithmus zu unterscheiden, d.h. Prozedur und dem Begriff der Funktion, die durch Algorithmus berechnet wird, d.h. Kartierung nach Verfahren. Die gleiche Funktion kann mehrere verschiedene Algorithmen haben". Leider kann es einen Kompromiss zwischen Güte (Geschwindigkeit) und Eleganz (Kompaktheit) geben – ein elegantes Programm kann mehr Schritte unternehmen, um eine Berechnung zu vervollständigen als ein weniger elegant. Ein Beispiel, das Euclids Algorithmus verwendet, erscheint unten. Computer (und Rechen), Berechnungsmodelle: Ein Computer (oder menschlicher Rechner) ist eine eingeschränkte Maschine, ein "diskretes deterministisches mechanisches Gerät", das blind seinen Anweisungen folgt. Melzaks und Lambeks primitive Modelle reduzierten diesen Begriff auf vier Elemente: (i) diskrete, unterscheidbare Orte, (ii) diskrete, undistinguierbare Zähler (iii) ein Agent, und (iv) eine Liste von Anweisungen, die in Bezug auf die Fähigkeit des Agenten wirksam sind. Minsky beschreibt eine kongenere Variation von Lambeks Abacusmodell in seinem "Sehr einfache Grundlagen für die Rechenschaftspflicht". Minskys Maschine geht sequentiell durch seine fünf (oder sechs, je nachdem, wie man zählt) Anweisungen, es sei denn, entweder eine bedingte IF-THEN GOTO oder ein bedingungsloses GOTO-Änderungsprogramm fließen aus der Sequenz. Neben HALT umfasst Minskys Maschine drei Aufgaben (Ersatz, Substitution) Operationen: ZERO (z.B. der Ortsinhalt ersetzt durch 0:L ← 0,) SUCCESSOR (z.B. L ← L+1,) und DECREMENT (z.B. L ← L − 1). Selten muss ein Programmierer Schreibcode mit einem solchen begrenzten Befehlssatz. Aber Minsky zeigt (wie Melzak und Lambek), dass seine Maschine ist Turing mit nur vier allgemeinen Arten von Anweisungen: bedingt GOTO, bedingungslose GOTO, Zuordnung / Ersatz / Substitution, und HALT. Für die Turing-Komplettheit sind jedoch auch einige unterschiedliche Zuordnungsanweisungen (z.B. DECREMENT, INCREMENT und ZERO/CLEAR/EMPTY für eine Minsky-Maschine) erforderlich; ihre genaue Spezifikation liegt etwas bis zum Designer. Die bedingungslose GOTO ist eine Bequemlichkeit; sie kann durch Initialisierung eines dedizierten Ortes auf Null z.B. die Anweisung " Z ← 0 " konstruiert werden; danach ist die Anweisung IF Z=0 THEN GOTO xxx bedingungslos. Simulation eines Algorithmus: Computer (Kommando) Sprache: Knuth berät den Leser, dass "der beste Weg, um einen Algorithmus zu lernen, ist es, es zu versuchen .. sofort nehmen Stift und Papier und arbeiten durch ein Beispiel". Aber was ist mit einer Simulation oder Ausführung der realen Sache? Der Programmierer muss den Algorithmus in eine Sprache übersetzen, die der Simulator/Computer/Computor effektiv ausführen kann. Stone gibt ein Beispiel dafür: Bei der Berechnung der Wurzeln einer quadratischen Gleichung muss der Rechener wissen, wie man eine quadratische Wurzel nimmt. Wenn sie nicht, dann muss der Algorithmus, um effektiv zu sein, eine Reihe von Regeln für die Extraktion einer Quadratwurzel. Dies bedeutet, dass der Programmierer eine Sprache kennen muss, die in Bezug auf den Zielrechner (Computer/Komputor) wirksam ist. Aber welches Modell sollte für die Simulation verwendet werden? Van Emde Boas beobachtet "auch wenn wir die Komplexitätstheorie auf abstrakte anstatt konkrete Maschinen, Schiedsrichterschaft der Wahl eines Modells bleibt. Es ist an dieser Stelle, dass der Begriff der Simulation eingeht". Beim Messen der Geschwindigkeit zählt der Befehlssatz. Zum Beispiel würde das Unterprogramm in Euclids Algorithmus, um den Rest zu berechnen, viel schneller ausgeführt, wenn der Programmierer eine Modulanweisung zur Verfügung hatte, anstatt nur Subtraktion (oder schlechter: nur Minskys Dekrement"). Strukturierte Programmierung, kanonische Strukturen: Nach der Kirche-Turing-Thesis kann jeder Algorithmus von einem Modell berechnet werden, das bekannt ist, Turing vollständig, und nach Minskys Demonstrationen, Turing Vollständigkeit erfordert nur vier Unterrichtstypen - bedingungslose GOTO, bedingungslose GOTO, Zuordnung, HALT. Kemeny und Kurtz beobachten, dass, während undisziplinierte Verwendung von bedingungslosen GOTOs und bedingten IF-THEN GOTOs zu "Spaghetti-Code" führen kann, kann ein Programmierer strukturierte Programme nur mit diesen Anweisungen schreiben; auf der anderen Seite "es ist auch möglich, und nicht zu schwer, schlecht strukturierte Programme in einer strukturierten Sprache zu schreiben". Tausworthe erweitert die drei Böhm-Jacopini-Kanonstrukturen: SEQUENCE, IF-THEN-ELSE und WHILE-DO, mit zwei weiteren: DO-WHILE und CASE. Ein zusätzlicher Vorteil eines strukturierten Programms ist, dass es sich an Korrekturnachweise mit mathematischer Induktion leiht. Kanonische Flussdiagramm-Symbole: Der graphische Helfer, genannt Flussdiagramm, bietet eine Möglichkeit, einen Algorithmus (und ein Computerprogramm von einem) zu beschreiben und zu dokumentieren. Wie der Programmablauf einer Minsky-Maschine beginnt immer ein Flussdiagramm an der Spitze einer Seite und geht nach unten. Seine Hauptsymbole sind nur vier: der gerichtete Pfeil, der den Programmablauf zeigt, das Rechteck (SEQUENCE, GOTO), der Diamant (IF-THEN-ELSE) und der Punkt (OR-tie). Aus diesen primitiven Formen werden die kanonischen Strukturen Böhm–Jacopini hergestellt. Unterkonstruktionen können in Rechtecke verschachteln, aber nur, wenn ein einziger Austritt aus der Oberkonstruktion auftritt. Die Symbole und deren Verwendung zum Aufbau der kanonischen Strukturen sind im Diagramm dargestellt. BeispieleAlgorithm Beispiel Einer der einfachsten Algorithmen ist, die größte Zahl in einer Liste von Zahlen von zufälliger Reihenfolge zu finden. Die Lösung zu finden erfordert, jede Nummer in der Liste zu betrachten. Daraus folgt ein einfacher Algorithmus, der in einer hochrangigen Beschreibung in englischer Sprache angegeben werden kann, wie: Hochrangige Beschreibung: Wenn es keine Zahlen im Set gibt, gibt es keine höchste Zahl.Nehmen Sie an, die erste Nummer im Set ist die größte Anzahl im Set. Für jede verbleibende Zahl im Set: wenn diese Zahl größer als die aktuell größte Zahl ist, ist diese Zahl die größte Zahl im Set. Wenn im Satz keine Zahlen übrig sind, um zu iterieren, betrachten Sie die aktuell größte Zahl als die größte Anzahl des Satzes.(Quasi-)formale Beschreibung: Geschrieben in Prosa, aber viel näher an der hochrangigen Sprache eines Computerprogramms, ist die formale Kodierung des Algorithmus in Pseudocode oder Pidgin-Code: Euclids Algorithmus Euclids Algorithmus, um den größten gemeinsamen Divisor (GCD) zu zwei Zahlen zu berechnen erscheint als Proposition II in Buch VII ("Elementar Number Theory") seiner Elemente. Euclid stellt also das Problem dar: "Gegeben zwei Zahlen nicht zueinander, um ihre größte gemeinsame Maßnahme zu finden." Er definiert "Eine Zahl [zu sein] eine Vielzahl aus Einheiten": eine Zählnummer, eine positive ganze Zahl, die nicht Null umfasst. Zur Messung wird eine kürzere Messlänge s nacheinander (q-mal) über längere Länge l bis der verbleibende Teil r kleiner ist als die kürzere Länge s. In modernen Worten ist der Rest r = l - q x s, wobei q der Quotient ist, oder der Rest r der Modul, der nach der Division überlassene ganzzahlige Teil. Für die Erfolgsmethode von Euclid müssen die Anfangslängen zwei Anforderungen erfüllen: (i) die Längen dürfen nicht Null sein, UND (ii) die Subtraktion muss richtig sein; d.h. eine Prüfung muss sicherstellen, dass die kleinere der beiden Zahlen von der größeren subtrahiert wird (oder die beiden gleich sein können, so dass ihre Subtraktion Null ergibt). Der ursprüngliche Beweis von Euclid fügt eine dritte Anforderung hinzu: Die beiden Längen dürfen nicht aneinander anstoßen. Euclid hat dies so festgelegt, dass er einen reductio ad absurdum Beweis errichten könnte, dass die gemeinsame Maßnahme der beiden Zahlen tatsächlich die größte ist. Während Nicomachus' Algorithmus gleich ist wie Euclid's, wenn die Zahlen zueinander sind, ergibt er die Zahl 1 für ihre gemeinsame Maßnahme. Um genau zu sein, ist das Folgende wirklich Nicomachus' Algorithmus. Computersprache für Euclids Algorithmus Es sind nur wenige Befehlstypen erforderlich, um den Algorithmus von Euclid auszuführen – einige logische Tests (bedingungslose GOTO), bedingungslose GOTO, Zuordnung (Ersatz,) und Subtraktion. Ein Ort wird durch Oberbuchstaben, z.B. S, A usw. symbolisiert. Die unterschiedliche Menge (Anzahl) an einem Ort wird in den Buchstaben unten und (meist) in Verbindung mit dem Namen des Ortes geschrieben. Zum Beispiel Standort L am Anfang kann die Zahl l = 3009 enthalten. Ein inelegantes Programm für Euclids Algorithmus Der folgende Algorithmus wird als Knuth's vierstufige Version von Euclid's und Nicomachus' gerahmt, verwendet aber anstelle der Division, um den Rest zu finden, aufeinanderfolgende Subtraktionen der kürzeren Länge s von der Restlänge r bis r kleiner als s. Die in kühnem Gesicht gezeigte hochrangige Beschreibung wird von Knuth 1973:2–4 INPUT angepasst: 1 [An zwei Stellen L und S setzen die Zahlen l und s, die die beiden Längen darstellen]: INPUT L, S2 [Initialize R: die verbleibende Länge r gleich der Start-/Initial/Eingangslänge l]: R ← L E0:[Sicherung r ≥ s] 3 [Vergewissern Sie sich, dass die kleinere der beiden Zahlen in S und die größere in R ist]: IF R > S THEN der Inhalt von L ist die größere Anzahl so über die Austauschschritte 4, 5 und 6 hinausspringen: GOTO Schritt 7 ELSE schwankt den Inhalt von R und S. 4 L ← R (dieser erste Schritt ist redundant, aber ist für spätere Diskussion nützlich).5 R 6 S 6 S L E1:[D rest] Bis die Restlänge r in R kleiner als die kürzere Länge s in S ist, lenkt die Messzahl s in S von der Restlänge r in R. 7 IF S > R THEN wieder ab, so dass GOTO 10 ELSE-Messung wieder, 8 R ← R - S 9 [Remainder-loop]: GEMEINSCHAFT 7. E2:[ Ist der Rest Null]?: EITHER (i) die letzte Maßnahme war genau, der Rest in R Null ist, und das Programm kann stoppen, OR (ii) der Algorithmus muss fortfahren: die letzte Maßnahme links einen Rest in R weniger als die Messnummer in S. 10IF R = 0THEN getan so GOTO Schritt 15 ELSE CONTINUE TO Schritt 11, E3:[Interchange s and r]: Die Nüsse von Euclids Algorithmus. 11 L ← R 12 R ← S13 S ← L 14 [Repeat the Messprozess]: GOTO 7 OUTPUT: 15 [Done.S enthält den größten gemeinsamen Divisor]: PRINT S DONE: 16 HALT, END, STOP. Ein elegantes Programm für Euclids Algorithmus Die folgende Version von Euclids Algorithmus erfordert nur sechs Kernanweisungen, um zu tun, was dreizehn von Inelegant benötigt werden; schlimmer, Inelegant erfordert mehr Arten von Anweisungen. Das Flussdiagramm von Elegant befindet sich an der Spitze dieses Artikels. Im (unstrukturierten) Grundsprache, die Schritte sind nummeriert, und die Anweisung LET [] = [] ist die Zuordnungsanweisung symbolisiert durch ←. Wie Elegant funktioniert: Anstelle einer äußeren "Euklidschleife" verschiebt sich Elegant zwischen zwei Co-Plups hin und her, ein A > B-Schleife, die A ← A − B berechnet, und eine B ≤ A-Schleife, die B ← B −A berechnet. Dies funktioniert, weil, wenn endlich das Minuend M kleiner oder gleich dem Subtrahend S(Difference = Minuend - Subtrahend) ist, kann das Minuend s (die neue Messlänge) werden und das Subtrahend kann das neue r (die zu messende Länge) werden, mit anderen Worten das Gefühl der Subtraktion rückkehrt. Die folgende Version kann mit Programmiersprachen aus der C-Familie verwendet werden: Testen der Euclid Algorithmen Macht ein Algorithmus, was sein Autor will, dass er es tut? Einige Testfälle geben meist Vertrauen in die Kernfunktionalität. Aber Tests reichen nicht aus. Für Testfälle verwendet eine Quelle 3009 und 884. Knuth schlug 40902, 24140 vor. Ein weiterer interessanter Fall sind die beiden relativ großen Zahlen 14157 und 5950. Aber "außergewöhnliche Fälle" müssen identifiziert und getestet werden. Wird Inelegant ordnungsgemäß ausführen, wenn R > S, S > R, R = S?Ditto für Elegant: B > A, A > B, A = B?(Ja für alle). Was passiert, wenn eine Zahl Null ist, sind beide Zahlen Null?("Inelegant berechnet für immer in allen Fällen; Elegant berechnet für immer, wenn A = 0.) Was passiert, wenn negative Zahlen eingegeben werden? Fraktionsnummern? Sollen die Eingabenummern, d.h. die Domäne der durch den Algorithmus/Programm berechneten Funktion, nur positive ganze Zahlen einschließlich Null enthalten, so weisen die Fehler bei Null darauf hin, dass der Algorithmus (und das Programm, das ihn zeitpunktisiert) eine Teilfunktion anstatt eine Gesamtfunktion ist. Ein bemerkenswerter Ausfall aufgrund von Ausnahmen ist die Ariane 5 Flug 501 Raketenversagen (4. Juni 1996). Nachweis der Programmkorrektheit durch Verwendung von mathematischen Induktion: Knuth demonstriert die Anwendung der mathematischen Induktion auf eine erweiterte Version von Euclids Algorithmus, und er schlägt "eine allgemeine Methode, die für die Beweisführung der Gültigkeit eines jeden Algorithmus anwendbar ist". Tausworthe schlägt vor, dass ein Maß für die Komplexität eines Programms die Länge seines Korrekturnachweises ist. Messung und Verbesserung der Euclid Algorithmen Elegance (Kompaktheit) gegen Güte (Geschwindigkeit): Mit nur sechs Kernanweisungen ist Elegant der klare Gewinner, im Vergleich zu Inelegant bei dreizehn Anweisungen. Inelegant ist jedoch schneller (es kommt in weniger Schritten bei HALT an). Algorithm-Analyse zeigt, warum dies der Fall ist: Elegant macht zwei bedingte Tests in jeder Subtraktionsschleife, während Inelegant nur eine macht. Da der Algorithmus (in der Regel) viele Durchläufe erfordert, wird im Durchschnitt viel Zeit verschwendet, indem man einen "B = 0?"-Test macht, der nur nach der Berechnung des Rests benötigt wird. Können die Algorithmen verbessert werden?: Sobald der Programmierer ein Programm für fit und effektiv beurteilt" - das heißt, er berechnet die von seinem Autor beabsichtigte Funktion -, dann wird die Frage verbessert? Die Kompaktheit von Inelegant kann durch die Beseitigung von fünf Schritten verbessert werden. Chaitin bewies jedoch, dass die Verdichtung eines Algorithmus nicht durch einen verallgemeinerten Algorithmus automatisiert werden kann, sondern nur heuristisch, d.h. durch eine erschöpfende Suche (Beispiele zu finden bei Busy Biber,) Test und Fehler, Klugheit, Einblick, Anwendung induktiver Argumentation, etc. Beachten Sie, dass die Schritte 4, 5 und 6 in den Schritten 11, 12 und 13 wiederholt werden. Der Vergleich mit Elegant bietet einen Hinweis, dass diese Schritte zusammen mit den Schritten 2 und 3 eliminiert werden können. Dies reduziert die Anzahl der Kernanweisungen von dreizehn auf acht, was macht es " eleganter" als Elegant, auf neun Stufen. Die Geschwindigkeit von Elegant kann durch Bewegen des B=0?"tests außerhalb der beiden Subtraktionsschleifen verbessert werden. Diese Änderung erfordert die Hinzufügung von drei Anweisungen (B = 0?,A = 0?, GOTO). Elegant berechnet nun die Beispielzahlen schneller; ob dies immer für eine bestimmte A, B und R der Fall ist, würde S eine detaillierte Analyse erfordern. Algorithmenanalyse Es ist häufig wichtig zu wissen, wie viel einer bestimmten Ressource (wie Zeit oder Speicher) theoretisch für einen bestimmten Algorithmus benötigt wird. Für die Analyse von Algorithmen wurden Methoden entwickelt, um solche quantitativen Antworten zu erhalten (Schätzungen;) beispielsweise hat der Sortieralgorithmus oben einen Zeitbedarf von O(n,) unter Verwendung der großen O-Notation mit n als Länge der Liste. Der Algorithmus muss sich immer nur an zwei Werte erinnern: die bisher größte Zahl und seine aktuelle Position in der Eingabeliste. Es soll daher ein Raumbedarf von O(1,) aufweisen, wenn der zur Speicherung der Eingangszahlen erforderliche Raum nicht gezählt wird, oder O(n) wenn er gezählt wird. Verschiedene Algorithmen können die gleiche Aufgabe mit einem anderen Satz von Anweisungen in weniger oder mehr Zeit, Raum oder Aufwand als andere erledigen. Ein binärer Suchalgorithmus (mit Kosten O(log n) ) übergibt beispielsweise eine sequentielle Suche (Kosten O(n) ), wenn sie für Tabellen-Lookups auf sortierten Listen oder Arrays verwendet wird. Formal versus empirisch Die Analyse und das Studium von Algorithmen ist eine Disziplin der Informatik und wird oft abstrakt ohne Verwendung einer bestimmten Programmiersprache oder Implementierung praktiziert. In diesem Sinne ähnelt die Algorithmusanalyse anderen mathematischen Disziplinen, indem sie sich auf die zugrunde liegenden Eigenschaften des Algorithmus und nicht auf die Spezifik einer bestimmten Implementierung konzentriert. Üblicherweise wird zur Analyse Pseudocode verwendet, da es die einfachste und allgemeinste Darstellung ist. Schließlich werden die meisten Algorithmen jedoch in der Regel auf bestimmten Hardware-Software-Plattformen implementiert und ihre algorithmische Effizienz wird schließlich mit realem Code auf den Test gestellt. Für die Lösung eines "one off"-Problems kann die Effizienz eines bestimmten Algorithmus nicht signifikante Konsequenzen haben (wenn nicht n extrem groß ist), sondern für Algorithmen, die für eine schnelle interaktive, kommerzielle oder lange wissenschaftliche Nutzung konzipiert sind, kann es kritisch sein. Skalierung von klein n zu groß n zeigt häufig ineffiziente Algorithmen, die sonst gutartig sind. Empirische Tests sind nützlich, weil es unerwartete Interaktionen aufdecken kann, die die Leistung beeinflussen. Benchmarks können verwendet werden, um vor/nach potenziellen Verbesserungen an einem Algorithmus nach Programmoptimierung zu vergleichen. Empirische Tests können jedoch keine formale Analyse ersetzen und sind nicht trivial, um fair zu arbeiten. Effizienz der Ausführung Um die potenziellen Verbesserungen auch bei etablierten Algorithmen zu illustrieren, kann eine jüngste signifikante Innovation, die sich auf FFT-Algorithmen bezieht (die stark im Bereich der Bildverarbeitung eingesetzt werden), die Verarbeitungszeit bis zu 1.000 Mal für Anwendungen wie die medizinische Bildgebung verringern. Im allgemeinen hängen die Geschwindigkeitsverbesserungen von speziellen Eigenschaften des Problems ab, die in praktischen Anwendungen sehr häufig sind. Geschwindigkeiten dieser Größenordnung ermöglichen Recheneinrichtungen, die eine umfangreiche Nutzung der Bildverarbeitung (wie Digitalkameras und medizinische Geräte) zu weniger Strom zu verbrauchen. Einstufung Es gibt verschiedene Möglichkeiten, Algorithmen zu klassifizieren, jede mit eigenen Verdienste. Durch die Umsetzung Eine Möglichkeit, Algorithmen zu klassifizieren, ist durch Implementierungsmittel. Rekursion Ein rekursiver Algorithmus ist einer, der sich wiederholt (bezieht sich auf) selbst anruft, bis eine bestimmte Bedingung (auch als Kündigungsbedingung bezeichnet) übereinstimmt, was ein für die funktionelle Programmierung gemeinsames Verfahren ist. Iterative Algorithmen verwenden repetitive Konstrukte wie Schleifen und manchmal zusätzliche Datenstrukturen wie Stacks, um die gegebenen Probleme zu lösen. Einige Probleme sind natürlich für eine Implementierung oder die andere geeignet. Zum Beispiel sind Türme von Hanoi mit rekursiver Umsetzung gut verstanden. Jede rekursive Version hat eine gleichwertige (aber möglicherweise mehr oder weniger komplexe) iterative Version und umgekehrt. Logisch Ein Algorithmus kann als gesteuerte logische Ableitung betrachtet werden. Dieser Begriff kann ausgedrückt werden als: Algorithm = Logik + Steuerung. Die Logikkomponente drückt die bei der Berechnung verwendbaren Axiome aus und die Steuerkomponente bestimmt die Art und Weise, in der die Axiome mit der Ableitung beaufschlagt werden. Dies ist die Basis für das logische Programmierparadigma. In reinen logischen Programmiersprachen wird die Steuerkomponente fixiert und Algorithmen werden durch die Bereitstellung nur der Logikkomponente vorgegeben. Der Appell dieses Ansatzes ist die elegante Semantik: Eine Veränderung der Axiome bewirkt eine definierte Änderung des Algorithmus. Serienmäßig, parallel oder verteilt Algorithmen werden in der Regel mit der Annahme diskutiert, dass Computer eine Anweisung eines Algorithmus zu einer Zeit ausführen. Diese Computer werden manchmal serielle Computer genannt. Ein für eine solche Umgebung ausgelegter Algorithmus wird als serieller Algorithmus im Gegensatz zu parallelen Algorithmen oder verteilten Algorithmen bezeichnet. Parallelalgorithmen nutzen Computerarchitekturen, bei denen mehrere Prozessoren gleichzeitig an einem Problem arbeiten können, während verteilte Algorithmen mehrere mit einem Computernetzwerk verbundene Maschinen nutzen. Parallele oder verteilte Algorithmen teilen das Problem in symmetrischere oder asymmetrische Teilprobleme und sammeln die Ergebnisse wieder zusammen. Der Ressourcenverbrauch in solchen Algorithmen ist nicht nur Prozessorzyklen auf jedem Prozessor, sondern auch die Kommunikation über Kopf zwischen den Prozessoren. Einige Sortieralgorithmen können effizient parallelisiert werden, aber ihre Kommunikations-Overhead ist teuer. Iterative Algorithmen sind in der Regel parallelisierbar. Einige Probleme haben keine parallelen Algorithmen und werden inhärent serielle Probleme genannt. Deterministisch oder nicht-deterministisch Deterministische Algorithmen lösen das Problem mit exakter Entscheidung in jedem Schritt des Algorithmus, während nicht-deterministische Algorithmen Probleme lösen durch Erraten, obwohl typische Vermutungen durch die Verwendung von Heuristiken genauer gemacht werden. Genau oder annähernd Während viele Algorithmen eine genaue Lösung erreichen, suchen Annäherungsalgorithmen eine Annäherung, die näher an die wahre Lösung ist. Die Annäherung kann entweder mit einer deterministischen oder zufälligen Strategie erreicht werden. Solche Algorithmen haben praktischen Wert für viele harte Probleme. Eines der Beispiele für einen ungefähren Algorithmus ist das Knapsack-Problem, wo es eine Reihe von bestimmten Elementen gibt. Ziel ist es, den Rucksack zu packen, um den maximalen Gesamtwert zu erhalten. Jeder Artikel hat etwas Gewicht und etwas Wert. Das Gesamtgewicht, das getragen werden kann, ist nicht mehr als eine bestimmte Zahl X.So, die Lösung muss Gewichte von Gegenständen sowie ihren Wert berücksichtigen. Quantum-Algorithmus Sie laufen auf einem realistischen Modell der Quantenrechnung. Der Begriff wird in der Regel für diejenigen Algorithmen verwendet, die inhärent quantum scheinen, oder verwenden Sie ein wesentliches Merkmal der Quantenüberlagerung oder Quantenverschränkung. Durch das Design Paradigma Eine andere Möglichkeit, Algorithmen zu klassifizieren ist durch ihre Design-Methodik oder Paradigmen. Es gibt eine bestimmte Anzahl von Paradigmen, die sich voneinander unterscheiden. Darüber hinaus umfasst jede dieser Kategorien viele verschiedene Arten von Algorithmen. Einige häufige Paradigmen sind: Brute-force oder vollständige Suche Dies ist die naive Methode, jede mögliche Lösung zu versuchen, um zu sehen, was am besten ist. Tauchen und Erobern Ein Teilungs- und Eroberungsalgorithmus reduziert wiederholt eine Instanz eines Problems auf eine oder mehrere kleinere Instanzen desselben Problems (in der Regel rekursiv) bis die Instanzen klein genug sind, um leicht zu lösen. Ein solches Beispiel der Spaltung und der Eroberung ist die Zusammenführung der Sortierung. Die Sortierung kann auf jedem Datensegment erfolgen, nachdem die Daten in Segmente aufgeteilt werden und die Sortierung der gesamten Daten in der Eroberungsphase durch Verschmelzung der Segmente erreicht werden kann. Eine einfachere Variante von Teilung und Eroberung wird als Abnahme- und Eroberungsalgorithmus bezeichnet, der ein identisches Subproblem löst und die Lösung dieses Subproblems verwendet, um das größere Problem zu lösen. Tauchen und Erobern teilt das Problem in mehrere Subprobleme und so ist die Eroberungsphase komplexer als Abnehmen und Erobern Algorithmen. Ein Beispiel für einen Abnahme- und Eroberungsalgorithmus ist der binäre Suchalgorithmus. Suche und Aufzählung Viele Probleme (z.B. Schachspielen) können als Probleme auf Graphen modelliert werden. Ein Graphenexplorationsalgorithmus gibt Regeln für das Umfahren eines Diagramms an und ist für solche Probleme nützlich. Diese Kategorie umfasst auch Suchalgorithmen, Zweig und gebundene Aufzählung und Backtracking. Zufälliger Algorithmus Solche Algorithmen entscheiden zufällig (oder pseudo-random). Sie können sehr nützlich sein, um ungefähre Lösungen für Probleme zu finden, bei denen genaue Lösungen unpraktisch sein können (siehe heuristische Methode unten). Für einige dieser Probleme ist bekannt, dass die schnellsten Annäherungen eine gewisse Zufallskraft aufweisen müssen. Ob randomisierte Algorithmen mit Polynomzeitkomplexität die schnellsten Algorithmen für einige Probleme sein können, ist eine offene Frage, die als P gegen NP-Problem bekannt ist. Es gibt zwei große Klassen solcher Algorithmen: Monte Carlo Algorithmen geben eine richtige Antwort mit hoher Wahrscheinlichkeit. E.g. RP ist die Unterklasse dieser, die in polynomischer Zeit laufen. Las Vegas Algorithmen geben immer die richtige Antwort zurück, aber ihre Laufzeit ist nur probabilistisch gebunden, z.B. ZPP. Reduzierung der Komplexität Diese Technik beinhaltet die Lösung eines schwierigen Problems, indem sie es in ein besser bekanntes Problem verwandelt, für das wir (hoffentlich) asymptotisch optimale Algorithmen haben. Ziel ist es, einen Reduktionsalgorithmus zu finden, dessen Komplexität nicht von dem resultierenden reduzierten Algorithmus dominiert wird. Ein Auswahlalgorithmus zum Auffinden des Medians in einer ungebrochenen Liste beinhaltet zum Beispiel die erste Sortierung der Liste (den teuren Teil) und dann das Mittelelement in der sortierten Liste (den billigen Teil). Diese Technik ist auch als Transformation und Eroberung bekannt. Zurück nachverfolgung Dabei werden mehrere Lösungen inkremental aufgebaut und aufgegeben, wenn festgestellt wird, dass sie nicht zu einer gültigen Volllösung führen können. Optimierungsprobleme Für Optimierungsprobleme gibt es eine spezifischere Klassifizierung von Algorithmen; ein Algorithmus für solche Probleme kann in eine oder mehrere der oben beschriebenen allgemeinen Kategorien sowie in eine der folgenden Kategorien fallen: Lineare Programmierung Bei der Suche nach optimalen Lösungen für eine lineare Funktion, die an lineare Gleichheit und Ungleichheitszwänge gebunden ist, können die Zwänge des Problems direkt bei der Herstellung optimaler Lösungen eingesetzt werden. Es gibt Algorithmen, die jedes Problem in dieser Kategorie lösen können, wie der beliebte Simplex-Algorithmus. Probleme, die mit der linearen Programmierung gelöst werden können, sind das maximale Strömungsproblem für gerichtete Graphen. Wenn ein Problem zusätzlich erfordert, dass eines oder mehrere der Unbekannten eine ganze Zahl sein muss, dann wird es in die Ganzzahl-Programmierung klassifiziert. Ein linearer Programmieralgorithmus kann ein solches Problem lösen, wenn nachgewiesen werden kann, dass alle Einschränkungen für ganze Werte oberflächlich sind, d.h. die Lösungen erfüllen diese Einschränkungen ohnehin. Im allgemeinen Fall wird ein spezialisierter Algorithmus oder ein Algorithmus verwendet, der ungefähre Lösungen findet, je nach Schwierigkeit des Problems. Dynamische Programmierung Wenn ein Problem optimale Unterstrukturen zeigt - die optimale Lösung für ein Problem kann von optimalen Lösungen zu Unterproblemen aufgebaut werden - und überlappende Unterprobleme, d.h. die gleichen Unterprobleme werden verwendet, um viele verschiedene Problemfälle zu lösen, vermeidet ein schnellerer Ansatz als dynamische Programmierung Recomputing-Lösungen, die bereits berechnet wurden. So kann beispielsweise der Floyd–Warshall-Algorithmus, der kürzeste Weg zu einem Ziel von einem Scheitel in einem gewichteten Diagramm gefunden werden, indem man den kürzesten Weg zum Ziel von allen benachbarten Wirbeln nutzt. Dynamische Programmierung und Memoisation gehen zusammen.Der Hauptunterschied zwischen dynamischer Programmierung und Teilung und Eroberung besteht darin, dass Teilprobleme mehr oder weniger unabhängig voneinander sind und sich erobern, während die Teilprobleme in der dynamischen Programmierung überlappen. Der Unterschied zwischen dynamischer Programmierung und gerader Rekursion besteht in Cache oder Memoisation wiederkehrender Anrufe. Wenn Subprobleme unabhängig sind und es keine Wiederholung gibt, hilft Memoization nicht; daher ist die dynamische Programmierung keine Lösung für alle komplexen Probleme. Durch die Verwendung von Memoisation oder Aufrechterhaltung einer Tabelle von bereits gelösten Subproblemen reduziert die dynamische Programmierung die exponentielle Natur vieler Probleme der Polynomkomplexität. Die gierige Methode Ein gieriger Algorithmus ist ähnlich wie ein dynamischer Programmieralgorithmus, indem er Unterstrukturen untersucht, in diesem Fall nicht das Problem, sondern eine bestimmte Lösung. Solche Algorithmen beginnen mit einer Lösung, die gegeben oder in irgendeiner Weise aufgebaut werden kann, und verbessern sie durch kleine Modifikationen. Für einige Probleme können sie die optimale Lösung finden, während sie für andere an lokalem Optimum, d.h. an Lösungen, die durch den Algorithmus nicht verbessert werden können, aber nicht optimal sind. Die beliebteste Verwendung von gierigen Algorithmen ist die Suche nach dem minimalen Spannbaum, wo die optimale Lösung mit dieser Methode möglich ist. Huffman Tree, Kruskal, Prim, Sollin sind gierige Algorithmen, die dieses Optimierungsproblem lösen können. Die heuristische Methode Bei Optimierungsproblemen können heuristische Algorithmen verwendet werden, um eine Lösung in der Nähe der optimalen Lösung zu finden, wenn die optimale Lösung unpraktisch ist. Diese Algorithmen arbeiten, indem sie näher und näher an der optimalen Lösung, wie sie voranschreiten. Im Prinzip, wenn Sie für eine unendliche Zeit laufen, werden sie die optimale Lösung finden. Ihr Verdienst ist, dass sie eine Lösung in relativ kurzer Zeit sehr nahe an der optimalen Lösung finden können. Solche Algorithmen umfassen lokale Suche, Tabusuche, simulierte Glühung und genetische Algorithmen. Einige von ihnen, wie simulierte Glühung, sind nicht-deterministische Algorithmen, während andere, wie Tabu-Suche, deterministisch sind. Ist eine auf den Fehler der nicht-optimalen Lösung gebundene Grenze bekannt, so wird der Algorithmus weiter als Approximationsalgorithmus kategorisiert. Nach dem Studium Jeder Bereich der Wissenschaft hat eigene Probleme und benötigt effiziente Algorithmen. Ähnliche Probleme in einem Bereich werden häufig gemeinsam untersucht. Einige Beispielklassen sind Suchalgorithmen, Sortieralgorithmen, Zusammenführen von Algorithmen, numerische Algorithmen, Graphalgorithmen, Stringalgorithmen, rechnerische geometrische Algorithmen, kombinatorische Algorithmen, medizinische Algorithmen, maschinelles Lernen, Kryptographie, Datenkompressionsalgorithmen und Parsing-Techniken. Felder neigen dazu, einander zu überlappen, und Algorithmus Fortschritte in einem Feld kann die von anderen, manchmal völlig unbezogen, Felder verbessern. So wurde beispielsweise eine dynamische Programmierung zur Optimierung des Ressourcenverbrauchs in der Industrie erfunden, wird nun aber bei der Lösung einer breiten Palette von Problemen in vielen Bereichen eingesetzt. Durch Komplexität können Algorithmen nach der Zeit klassifiziert werden, die sie im Vergleich zu ihrer Eingangsgröße abschließen müssen: Konstante Zeit: wenn die vom Algorithmus benötigte Zeit gleich ist, unabhängig von der Eingangsgröße. Z.B. Zugriff auf ein Array-Element. Logarithmische Zeit: wenn die Zeit eine logarithmische Funktion der Eingangsgröße ist. z.B. binäre Suchalgorithmus. Lineare Zeit: wenn die Zeit proportional zur Eingangsgröße ist. Z.B. die Überschrift einer Liste. Polynomzeit: wenn die Zeit eine Leistung der Eingangsgröße ist. Z.B. hat der Blasensortalgorithmus quadratische Zeitkomplexität. Expositionszeit: wenn die Zeit eine exponentielle Funktion der Eingangsgröße ist. E.g Brute-force-Suche. Einige Probleme können mehrere Algorithmen unterschiedlicher Komplexität haben, während andere Probleme keine Algorithmen oder keine bekannten effizienten Algorithmen haben. Es gibt auch Kartierungen von einigen Problemen zu anderen Problemen. Dadurch hat es sich als besser geeignet erwiesen, die Probleme selbst anstelle der Algorithmen in Äquivalenzklassen zu klassifizieren, basierend auf der Komplexität der bestmöglichen Algorithmen. Kontinuierliche Algorithmen Das Adjektiv kontinuierlich, wenn es auf den Wortalgorithmus angewendet wird, kann bedeuten: Ein Algorithmus, der auf Daten arbeitet, die fortlaufende Größen darstellen, obwohl diese Daten durch diskrete Näherung dargestellt werden - solche Algorithmen werden in der numerischen Analyse untersucht; oder ein Algorithmus in Form einer Differentialgleichung, die kontinuierlich auf den Daten arbeitet, läuft auf einem analogen Computer. Rechtsfragen Algorithmen, von selbst, sind in der Regel nicht patentierbar. In den Vereinigten Staaten stellt ein Anspruch, der ausschließlich aus einfachen Manipulationen von abstrakten Konzepten, Zahlen oder Signalen besteht, keine Prozesse dar (USPTO 2006), und daher sind Algorithmen nicht patentierbar (wie in Gottschalk v. Benson). Jedoch sind praktische Anwendungen von Algorithmen manchmal patentierbar. Zum Beispiel in Diamond v. Diehr, die Anwendung eines einfachen Feedback-Algorithmus zur Unterstützung bei der Härtung von synthetischem Kautschuk wurde als patentierbar angesehen. Die Patentierung von Software ist sehr kontrovers, und es gibt hochkritikierte Patente mit Algorithmen, insbesondere Datenkompressionsalgorithmen, wie Unisys' LZW Patent. Zusätzlich haben einige kryptographische Algorithmen Exportbeschränkungen (siehe Export von Kryptographie.) Geschichte: Entwicklung der Vorstellung des Algorithmus Antike Naher Osten Die frühesten Beweise für Algorithmen finden sich in der babylonischen Mathematik der alten Mesopotamien (moderner Irak). Eine Sumerian Tontablette in Shuruppak in der Nähe von Baghdad gefunden und datiert etwa 2500 BC beschreibt den frühesten Teilungsalgorithmus. Während der Hammurabi Dynastie um 1800-1600 BC, Babylonische Tontabletten beschrieben Algorithmen für Computing Formeln. Algorithmen wurden auch in babylonischer Astronomie verwendet. Babylonische Tontabletten beschreiben und verwenden algorithmische Verfahren, um die Zeit und den Ort bedeutender astronomischer Ereignisse zu berechnen. Algorithmen für arithmetische finden sich auch in der alten ägyptischen Mathematik, Datierung zurück zum Rhind Mathematical Papyrus circa 1550 v. Chr. Algorithmen wurden später in der antiken hellenistischen Mathematik verwendet. Zwei Beispiele sind das Sieve von Eratosthenes, das in der Einführung in Arithmetik von Nicomachus beschrieben wurde, und der Euclidean-Algorithmus, der zunächst in Euclid's Elements (c. 300 BC) beschrieben wurde. Verschiedene und unterscheidbare Symbole Tally-Marken: Um ihre Flocks, ihre Körnersäcke und ihr Geld zu verfolgen, benutzten die Antike Taling: Ansammlung von Steinen oder Markierungen, die auf Stäbchen gekratzt sind oder diskrete Symbole in Ton machen. Durch die babylonische und ägyptische Verwendung von Zeichen und Symbolen, schließlich römische Ziffern und der Abacus entwickelt (Dilson, S. 16-41). Tally-Marken erscheinen prominent in unary number System arithmetic in Turing-Maschine und Post-Turing-Maschine Berechnungen verwendet. Manipulation von Symbolen als "Platzhalter" für Zahlen: Algebra Muhammad ibn Mūsā al-Khwārizmī, ein persischer Mathematiker, schrieb die Al-jabr im 9. Jahrhundert. Die Begriffe Algorismus und Algorithmus stammen aus dem Namen al-Khwārizmī, während der Begriff Algebra aus dem Buch Al-jabr abgeleitet wird. In Europa wurde der Wortalgorithmus ursprünglich verwendet, um auf die Sätze von Regeln und Techniken, die von Al-Khwarizmi verwendet werden, um algebraische Gleichungen zu lösen, bevor später verallgemeinert, um auf irgendwelche Regeln oder Techniken zu beziehen. Dies gipfelte schließlich in Leibnizs Vorstellung des Kalkulus-Verhältnisses (ca 1680): Ein gutes Jahrhundert und eine Hälfte vor seiner Zeit, Leibniz schlug eine Algebra der Logik, eine Algebra, die die Regeln für die Manipulation logischer Konzepte in der Weise, dass gewöhnliche Algebra die Regeln für die Manipulation von Zahlen angeben würde. Cryptographische Algorithmen Der erste kryptographische Algorithmus zur Entschlüsselung verschlüsselten Codes wurde von Al-Kindi, einem arabischen Mathematiker aus dem 9. Jahrhundert, in A Manuskript On Deciphering Cryptographic Messages entwickelt. Er gab die erste Beschreibung der Kryptanalyse durch Frequenzanalyse, den frühesten kodierenden Algorithmus. Mechanische Nachteile mit diskreten Zuständen Die Uhr: Bolter würdigt die Erfindung der gewichtsgetriebenen Uhr als "Die Schlüssel-Erfindung [von Europa im Mittelalter]", insbesondere die Verge-Rettung, die uns mit dem Zick und dem Zick einer mechanischen Uhr versorgt. "Die genaue automatische Maschine" führte sofort zu "mechanischen Automaten" beginnend im 13. Jahrhundert und schließlich zu "rechnenden Maschinen" – dem Differenzmotor und analytischen Motoren von Charles Babbage und Countess Ada Lovelace, Mitte des 19. Jahrhunderts. Lovelace wird mit der ersten Erstellung eines Algorithmus für die Verarbeitung auf einem Computer -Babbage Analyse-Engine, das erste Gerät betrachtete einen echten Turing-complete Computer anstelle nur eines Rechners - und wird manchmal als "historisches erster Programmierer" bezeichnet, obwohl eine vollständige Implementierung des zweiten Gerätes Babbage erst Jahrzehnte nach ihrem Leben realisiert werden würde. Logische Maschinen 1870: Stanley Jevons "logischer Abakus" und "logische Maschine": Das technische Problem war, die Booleschen Gleichungen zu reduzieren, wenn in einer Form dargestellt, ähnlich wie jetzt bekannt als Karnaugh Karten. Jevons (1880) beschreibt zunächst einen einfachen Abacus von "Rutschen aus Holz, die mit Stiften versehen sind, so dass jeder Teil oder Klasse der [logischen] Kombinationen mechanisch herausgegriffen werden kann. In jüngerer Zeit habe ich das System jedoch auf eine völlig mechanische Form reduziert, und habe damit den gesamten indirekten Prozess der Inferenz in der sogenannten Logical Machine verkörpert" Seine Maschine kam mit "sicheren beweglichen Holzstäben" und "am Fuß sind 21 Schlüssel wie die eines Klaviers [etc] ." Mit dieser Maschine konnte er einen "Syllogismus oder ein anderes einfaches logisches Argument" analysieren. Diese Maschine zeigte er 1870 vor den Fellows der Royal Society. Ein weiterer Logiker John Venn aber, in seiner 1881 Symbolic Logic, drehte ein Auge auf diese Anstrengung: "Ich habe keine hohe Schätzung mich von dem Interesse oder von Bedeutung von dem, was manchmal logische Maschinen genannt werden. Es scheint mir nicht, dass irgendwelche Nachteile derzeit bekannt oder wahrscheinlich entdeckt wirklich den Namen von logischen Maschinen verdient;" siehe mehr bei Algorithm Charakterisierungen. Aber nicht zu überbieten, präsentierte er auch "ein Plan etwas analog, ich schätze, an Prof. Jevon's abacus .[Und] [a]gain, entsprechend Prof. Jevons' logische Maschine, die folgende Kontrivanz kann beschrieben werden. Ich nenne es lieber nur eine logisch-Diagramm-Maschine. aber ich vermute, dass es sehr vollständig alles tun könnte, was rational von jeder logischen Maschine erwartet werden kann". Jacquardweber, Hollerith Stempelkarten, Telegrafie und Telefonie – das elektromechanische Relais: Bell und Newell (1971) zeigen, dass die Jacquard-Loom (1801,) Vorstufe zu Hollerith-Karten (Punch-Karten, 1887) und "Telefon-Schalttechnologien" die Wurzeln eines Baumes waren, der zur Entwicklung der ersten Computer führte. Bis Mitte des 19. Jahrhunderts war der Telegraph, der Vorläufer des Telefons, weltweit im Einsatz, seine diskrete und unterscheidbare Kodierung von Buchstaben als "Punkte und Bindestriche" einen gemeinsamen Klang. Bis Ende des 19. Jahrhunderts war das Tickerband (ca 1870s) im Einsatz, wie die Verwendung von Hollerith-Karten in der 1890 US-Zensus. Dann kam der Teleprinter (ca. 1910) mit seiner gestanzten Papiernutzung von Baudot Code auf Band. Telefonschaltnetze elektromechanischer Relais (erfindet 1835) hinter der Arbeit von George Stibitz (1937), dem Erfinder des digitalen Addierers. Als er in Bell Laboratories arbeitete, beobachtete er den "burdensome" Einsatz von mechanischen Taschenrechnern mit Zahnrädern. " Er ging 1937 einen Abend nach Hause, um seine Idee zu testen... Als die Tinkering vorbei war, hatte Stibitz eine binäre Addiereinrichtung aufgebaut." Davis (2000) beobachtet die besondere Bedeutung des elektromechanischen Relais (mit seinen beiden "binären Zuständen" offen und geschlossen): Es war nur mit der Entwicklung, beginnend in den 1930er Jahren, von elektromechanischen Rechnern mit elektrischen Relais, dass Maschinen gebaut wurden mit dem Umfang Babbage hatte gedacht." Mathematik im 19. Jahrhundert bis Mitte des 20. Jahrhunderts Symbole und Regeln: Die Mathematik von George Boole (1847, 1854,) Gottlob Frege (1879,) und Giuseppe Peano (1888–1889) reduzierten sich in schneller Folge arithmetisch auf eine Reihe von Symbolen, die durch Regeln manipuliert wurden. Peano's The Principles of arithmetic, präsentiert von einer neuen Methode (1888) war "der erste Versuch einer Axiomatisierung der Mathematik in einer symbolischen Sprache". Aber Heijenoort gibt Frege (1879) diese kudos: Frege's ist "die wichtigste Einzelarbeit, die jemals in Logik geschrieben wurde. .in der wir eine "Formelsprache" sehen, das ist eine Lingua-Zeichen, eine Sprache, die mit speziellen Symbolen geschrieben steht, "für reinen Gedanken", das heißt, frei von rhetorischen Verzierungen ... konstruiert aus bestimmten Symbolen, die nach bestimmten Regeln manipuliert werden". Die Arbeit von Frege wurde von Alfred North Whitehead und Bertrand Russell in ihrer Principia Mathematica (1910–1913) weiter vereinfacht und verstärkt. Die Paradoxe: Gleichzeitig erschien in der Literatur insbesondere das Burali-Forti paradox (1897), das Russell paradox (1902–03) und das Richard Paradox. Die sich daraus ergebenden Überlegungen führten zu Kurt Gödels Papier (1931) – er zitiert speziell das Paradox der Lügner –, das die Regeln der Rekursion auf Zahlen vollständig reduziert. Effektive Berechnungsfähigkeit: In dem Bemühen, das Entscheidungsproblem, das von Hilbert 1928 genau definiert wurde, zu lösen, haben die Mathematiker zunächst beschlossen, zu definieren, was mit einer "effektiven Methode" oder "effektive Berechnung" oder "effektive Kalkulationsfähigkeit" gemeint ist (d.h. eine Berechnung, die erfolgreich wäre). In schneller Folge erschien folgendes: Alonzo-Kirche, Stephen Kleene und J.B. Rossers λ-Calculus eine feine Definition der "allgemeinen Rekursion" aus der Arbeit von Gödel, die auf Vorschläge von Jacques Herbrand (vgl. Gödels Princeton-Vorträge von 1934) und nachfolgende Vereinfachungen von Kleene wirkt. Der Beweis der Kirche, dass das Entscheidungsproblem unlösbar war, Emil Posts Definition der effektiven Kalkulation als Arbeiter bewusst nach einer Liste von Anweisungen, um links oder rechts durch eine Reihe von Räumen zu bewegen, und während es entweder markieren oder löschen Sie ein Papier oder beobachten Sie das Papier und eine ja-ke Entscheidung über die nächste Anweisung. Alan Turings Beweis dafür, dass das Entscheidungsproblem durch die Verwendung seiner "a-[automatischen] Maschine" unlösbar war – in der Tat fast identisch mit Posts Formulierung, J. Barkley Rossers Definition der "effektiven Methode" in Bezug auf "eine Maschine". Kleenes Vorschlag eines Vorläufers der "Church Dissis", den er "Thesis I" nannte, und einige Jahre später Kleenes Umbenennung seiner These "Church's Thesis" und Vorschlag "Turing's Thesis". Emil Post (1936) und Alan Turing (1936–37, 1939)Emil Post (1936) beschrieb die Handlungen eines Computers (menschliches Wesen) wie folgt: "Zwei Konzepte sind beteiligt: das eines Symbolraums, in dem die von Problem zu beantwortende Arbeit durchgeführt werden soll, und ein fester, unveränderlicher Richtungssatz. Sein Symbol-Raum wäre "eine zwei-Wege unendliche Abfolge von Räumen oder Boxen... Der Problemlöser oder Arbeiter ist, in diesem Symbolraum zu bewegen und zu arbeiten, in der Lage zu sein, in, und in einer Box zu einer Zeit.... eine Box ist zuzugeben, aber zwei mögliche Bedingungen, d.h. leer oder unbemerkt, und mit einer einzigen Markierung in ihm, sagen einen vertikalen Schlag. " Eine Box ist auszuschalten und den Ausgangspunkt zu nennen. .ein spezifisches Problem ist in symbolischer Form durch eine endliche Anzahl von Boxen [d.h. INPUT] mit einem Schlaganfall gekennzeichnet. Ebenso ist die Antwort [d.h. OUTPUT] symbolisch durch eine solche Konfiguration markierter Boxen zu geben... "Eine Reihe von Richtungen, die auf ein allgemeines Problem anwendbar sind, stellt einen deterministischen Prozess ein, wenn er auf jedes spezifische Problem angewendet wird. Dieser Vorgang endet nur, wenn es um die Richtung des Typs (C) [d.h. STOP]" geht. Mehr auf der Post-Turing-Maschine Alan Turings Arbeit vor dem von Stibitz (1937;) es ist unbekannt, ob Stibitz von der Arbeit von Turing wusste. Turings Biograph glaubte, dass Turings Verwendung eines Schreibmaschinen-ähnlichen Modells aus einem jugendlichen Interesse hatte: "Alan hatte davon geträumt, Schreibmaschinen als Junge zu erfinden; Mrs. Turing hatte eine Schreibmaschine, und er hätte wohl damit begonnen, sich selbst zu fragen, was mit dem Aufruf einer Schreibmaschinenmechanik gemeint war". Angesichts der Prävalenz von Morse-Code und Telegraphie, Ticker-Band-Maschinen und Teletype-Writer könnten wir verurteilen, dass alle Einflüsse waren. Turing - sein Modell der Berechnung wird jetzt als Turing-Maschine bezeichnet - beginnt, wie Post, mit einer Analyse eines menschlichen Computers, dass er sich auf eine einfache Reihe von grundlegenden Bewegungen und "State of Mind". Aber er setzt einen Schritt weiter und schafft eine Maschine als Modell der Berechnung von Zahlen. " Die Eingabe erfolgt in der Regel durch Schreiben bestimmter Symbole auf Papier. Wir vermuten, dass diese Zeitung in Quadrate wie das arithmetische Buch eines Kindes unterteilt ist... Ich gehe davon aus, dass die Berechnung auf eindimensionalem Papier, d.h. auf einem in Quadrate unterteilten Band, durchgeführt wird. Ich nehme auch an, dass die Anzahl der Zeichen, die gedruckt werden können, endlich ist... "Das Verhalten des Computers in jedem Moment wird durch die Symbole bestimmt, die er beobachtet, und sein "Geistzustand" in diesem Moment. Wir können annehmen, dass es eine gebundene B an die Anzahl der Symbole oder Quadrate gibt, die der Computer zu einem Zeitpunkt beobachten kann. Wenn er mehr beobachten will, muss er aufeinanderfolgende Beobachtungen verwenden. Wir werden auch annehmen, dass die Anzahl der Geisteszustände, die berücksichtigt werden müssen, endlich ist... "Lass uns vorstellen, dass die von dem Computer durchgeführten Operationen in "einfache Operationen" aufgeteilt werden, die so elementar sind, dass es nicht leicht ist, sich vorzustellen, dass sie weiter geteilt werden. "Turings Reduktion ergibt folgendes: "Die einfachen Operationen müssen daher umfassen: ("a) Änderungen des Symbols auf einem der beobachteten Quadrate ("b) Änderungen eines der Quadrate, die auf einem anderen Quadrat innerhalb von L-Quadren eines der zuvor beobachteten Quadrate beobachtet werden. " Es kann sein, dass einige dieser Veränderungen notwendigerweise eine Veränderung des Geisteszustandes anrufen. Die allgemeinste Einzeloperation muss daher als eine der folgenden betrachtet werden: ("A)A mögliche Änderung (a) des Symbols zusammen mit einer möglichen Veränderung des Geisteszustandes. ("B) Eine mögliche Änderung (b) der beobachteten Quadrate, zusammen mit einer möglichen Änderung des Geisteszustandes""Wir können nun eine Maschine bauen, um die Arbeit dieses Computers zu tun. " Bereits Jahre später erweiterte Turing seine Analyse (Thesis, Definition) mit diesem kraftvollen Ausdruck: "Eine Funktion soll "effektiv kalkulierbar" sein, wenn ihre Werte durch einen rein mechanischen Prozess gefunden werden können. Obwohl es ziemlich einfach ist, ein intuitives Verständnis dieser Idee zu bekommen, ist es dennoch wünschenswert, eine bestimmte, mathematische ausdrückbare Definition zu haben.[Er diskutiert die Geschichte der Definition ziemlich, wie oben in Bezug auf Gödel, Herbrand, Kleene, Kirche, Turing und Post] dargestellt. Wir können diese Aussage buchstäblich, Verständnis durch einen rein mechanischen Prozess, der von einer Maschine durchgeführt werden könnte. Es ist möglich, die Strukturen dieser Maschinen in einer bestimmten Normalform mathematisch zu beschreiben. Die Entwicklung dieser Ideen führt zu der Definition des Autors einer Rechenfunktion und zu einer Identifikation der Rechenbarkeit † mit effektiver Rechenbarkeit ... . Wir werden den Ausdruck "komputierbare Funktion" verwenden, um eine von einer Maschine kalkulierbare Funktion zu bedeuten, und wir lassen "effektiv kalkulierbar" auf die intuitive Idee ohne besondere Identifikation mit einer dieser Definitionen verweisen." J.B Rosser (1939) und S.C Kleene (1943) J. Barkley Rosser definierte eine "effektive [mathematische] Methode" auf folgende Weise (Aktualisierung hinzugefügt): "Effective method" wird hier im eher speziellen Sinne einer Methode verwendet, deren Schritt genau bestimmt ist und die sicher ist, die Antwort in einer endlichen Anzahl von Schritten zu erzeugen. Mit dieser besonderen Bedeutung wurden bisher drei unterschiedliche genaue Definitionen gegeben. [seine Fußnote #5; siehe Diskussion sofort unten]. Die einfachste von ihnen zu sagen (durch Post und Turing) sagt im Wesentlichen, dass eine effektive Methode zur Lösung bestimmter Probleme besteht, wenn man eine Maschine bauen kann, die dann jedes Problem des Sets lösen wird, ohne menschliche Eingriffe, über die Einfügung der Frage hinaus und (später) die Antwort lesen.Alle drei Definitionen sind gleichwertig, also spielt es keine Rolle, welche verwendet wird. Darüber hinaus ist die Tatsache, dass alle drei gleichwertig sind, ein sehr starkes Argument für die Richtigkeit eines jeden."(Rosser 1939:225–226)Rossers Fußnote Nr. 5 verweist auf die Arbeit von (1) Kirche und Kleene und ihre Definition von λ-Definability, insbesondere auf die Verwendung der Kirche in seinem unlösbaren Problem der Elementarnummerntheorie (1936);) (2) Herbrand und Gödel und ihre Verwendung von Rekursion insbesondere Gödels Verwendung in seinem berühmten Papier Auf formal unvorhersehbaren Propositionen von Principia Mathematica und verwandten Systemen I (1931;) und (3) Post (1936) und Turing (1936–37) in ihren Mechanismus-Modellen der Berechnung. Stephen C. Kleene definierte als seine heute berühmte "Thesis I" als die kirchliche - Tournee-Thesis. Aber er tat dies im folgenden Kontext (Bolge im Original): "12.Algorithmische Theorien... Bei der Einrichtung einer kompletten algorithmischen Theorie, was wir tun, ist, ein Verfahren zu beschreiben, das für jede Menge von Werten der unabhängigen Variablen ausführbar ist, welches Verfahren notwendig endet und in der Weise, dass aus dem Ergebnis wir eine bestimmte Antwort lesen können, ja oder nein, zu der Frage, "ist der Prädikatswert wahr?" (Kleene 1943:273) Geschichte nach 1950 Eine Reihe von Bemühungen wurden auf eine weitere Verfeinerung der Definition des Algorithmus gerichtet, und Aktivität ist auf dem Laufenden wegen der Probleme, die insbesondere die Grundlagen der Mathematik (insbesondere die kirchliche - Tourenarbeit) und der Philosophie des Geistes (insbesondere Argumente über künstliche Intelligenz). Weitere Informationen finden Sie in Algorithm. Siehe auch Hinweise Bibliographie Weiter lesen Externe Links Algorithm, Encyclopedia of Mathematics, EMS Presse, 2001 [1994] Algorithmen bei Curlie Weisstein, Eric W."Algorithm". MathWorld. Wörterbuch der Algorithmen und Datenstrukturen – National Institute of Standards and TechnologyAlgorithm Repositories The Stony Brook Algorithm Repository – State University of New York bei Stony Brook Gesammelte Algorithmen der ACM – Association for Computing MachineryThe Stanford GraphBase – Stanford University