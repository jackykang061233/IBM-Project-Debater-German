Eine Meinungsumfrage, die oft einfach als Umfrage oder Umfrage bezeichnet wird, ist eine menschliche Untersuchung der öffentlichen Meinung aus einer bestimmten Stichprobe. Die Meinungsumfragen sind in der Regel dazu bestimmt, die Meinungen einer Bevölkerung durch eine Reihe von Fragen darzustellen und dann die allgemeinen Verhältnisse im Verhältnis oder innerhalb von Vertrauensintervallen zu extrapolieren. Eine Person, die Umfragen durchführt, wird als Verursacher bezeichnet. Geschichte Das erste bekannte Beispiel einer Meinungsumfrage war eine Größe von Wählerpräferenzen, die von der Raleigh Star und North Carolina State Gazette und dem Wilmington American Watchman und Delaware Advertiser vor den Präsidentschaftswahlen von 1824 berichtet wurden, wobei Andrew Jackson John Quincy Adams von 335 Stimmen zu 169 im Wettbewerb für die US-Präsidentschaft vorführte. Da Jackson die Volksabstimmung in diesem Staat und dem ganzen Land gewann, wurden solche Strohstimmen allmählich populärer, aber sie blieben lokal, in der Regel stadtweit Phänomene. 1916 startete The Literary Digest eine nationale Umfrage (teilweise als Zirkulationsübung) und stimmte Woodrow Wilsons Wahl als Präsident vorher. Das literarische Digest hat die Siege von Warren Harding 1920, Calvin Coolidge 1924, Herbert Hoover 1928 und Franklin Roosevelt 1932 richtig vorhergesagt. Dann, im Jahr 1936, seine Umfrage von 2,3 Millionen Wählern schlug vor, dass Alf Landon die Präsidentschaftswahl gewinnen würde, aber Roosevelt wurde stattdessen von einem Landslide wieder gewählt. Der Fehler wurde hauptsächlich durch die Beteiligungsvoreinschätzung verursacht; diejenigen, die Landon begünstigten, waren begeisterter über die Teilnahme an der Umfrage. Darüber hinaus hat die Umfrage überschätzt, dass die Amerikaner tendenziell republikanische Sympathien haben. Gleichzeitig führte George Gallup eine wesentlich kleinere (aber wissenschaftlich fundierte) Umfrage durch, in der er eine demografische repräsentative Stichprobe befragte. Die Gallup-Organisation hat Roosevelts Landslide-Sieg richtig vorhergesagt, ebenso wie ein weiterer bahnbrechender Bestatter Archibald Crossley. Das literarische Digest ging bald aus dem Geschäft, während die Umfrage begann zu starten. Elmo Roper war ein weiterer amerikanischer Pionier in der politischen Prognose mit wissenschaftlichen Umfragen. Er prophezeite die Wiederwahl von Präsident Franklin D. Roosevelt dreimal, 1936, 1940 und 1944. Louis Harris war seit 1947 im Bereich der öffentlichen Meinung, als er der Elmo Roper-Firma beitrat, dann später Partner geworden. Im September 1938 kreierte Jean Stoetzel, nachdem er Gallup getroffen hatte, IFOP, das Institut Français d'Opinion Publique, als erstes europäisches Erhebungsinstitut in Paris und begann im Sommer 1939 mit der Frage "Warum die für Danzig?" und suchte nach populärer Unterstützung oder Misshandlung mit dieser Frage, die von Appeasement Politiker und zukünftiger Kollaborationist Marcel Déat gestellt wurde. Gallup startete eine Tochtergesellschaft im Vereinigten Königreich, die fast allein den Sieg der Labour-Partei in der allgemeinen Wahl 1945 vorhergesagt hatte, im Gegensatz zu fast allen anderen Kommentatoren, die einen Sieg für die konservative Partei erwarteten, unter der Führung von Winston Churchill. Die alliierten Besatzungsmächte halfen, Erhebungsinstitute in allen westlichen Besatzungszonen Deutschlands 1947 und 1948 zu schaffen, um die Verweigerung besser zu steuern. In den 50er Jahren hatten sich verschiedene Arten von Bestäubungen auf die meisten Demokratien ausgebreitet. Langfristig war die Werbung in den frühen 1930er Jahren unter Druck geraten. Die Große Depression zwang Unternehmen, ihre Werbeausgaben drastisch zu reduzieren. Layoffs und Kürzungen waren bei allen Agenturen üblich. Der New Deal förderte zudem aggressiv den Konsumismus und minimierte den Wert der (oder Notwendigkeit) Werbung. Historiker Jackson Lears argumentiert, dass "In den späten 1930er Jahren hatten die Unternehmer jedoch einen erfolgreichen Gegenangriff gegen ihre Kritiker begonnen." Sie rehabilitierten das Konzept der Verbrauchersouveränität, indem sie wissenschaftliche Meinungsumfragen erfand und es zum Kernstück ihrer eigenen Marktforschung und zum Schlüssel zum Verständnis der Politik machte. George Gallup, der Vizepräsident von Young und Rubicam, und zahlreiche andere Werbeexperten, führte den Weg. In den 1940er Jahren spielte die Industrie eine führende Rolle bei der ideologischen Mobilisierung des amerikanischen Volkes zur Bekämpfung der Nazis und Japaner im Zweiten Weltkrieg. Im Rahmen dieser Bemühungen haben sie den "American Way of Life" in Bezug auf eine Verpflichtung zum freien Unternehmen neu definiert. Inserate, Lears schließt, "spielte eine entscheidende hegemoniale Rolle bei der Schaffung der Konsumkultur, die nach dem Zweiten Weltkrieg Amerikanische Gesellschaft dominierte." Stichproben- und Bestäubungsmethoden Die Meinungsumfragen für viele Jahre wurden durch Fernmelde- oder Personenkontakte aufrechterhalten. Methoden und Techniken variieren, obwohl sie in den meisten Bereichen weit verbreitet sind. Im Laufe der Jahre haben technologische Innovationen auch die Erhebungsmethoden wie die Verfügbarkeit elektronischer Clipboards und die Internet-basierte Umfrage beeinflusst. Verbale, Stimmzettel und verarbeitete Typen können effizient durchgeführt werden, im Gegensatz zu anderen Arten von Erhebungen, Systematiken und komplizierten Matrizen jenseits früherer orthodoxer Verfahren. Die Meinungsumfrage entwickelte sich zu beliebten Anwendungen durch populären Gedanken, obwohl die Antwortraten für einige Umfragen abgenommen. Auch folgendes hat zu differenzierenden Ergebnissen geführt: Einige Bestäubungsorganisationen, wie Angus Reid Public Opinion, YouGov und Zogby nutzen Internet-Befragungen, wo eine Probe von einem großen Panel von Freiwilligen gezogen wird, und die Ergebnisse werden gewichtet, um die Bevölkerung von Interesse zu reflektieren. Im Gegensatz dazu ziehen beliebte Web-Umfragen auf wen auch immer teilnehmen möchte, anstatt eine wissenschaftliche Stichprobe der Bevölkerung, und werden daher nicht allgemein als professionell angesehen. In jüngster Zeit wurden statistische Lernmethoden vorgeschlagen, um Social Media-Inhalte (wie Beiträge auf der Micro-Blogging-Plattform Twitter) für die Modellierung und Vorhersage von Abstimmungsabsichtsumfragen auszunutzen. Auch im Bereich der öffentlichen Beziehungen können Polls verwendet werden. In den frühen 1920er Jahren beschrieben Experten der Öffentlichkeit ihre Arbeit als Zwei-Wege-Straße. Ihre Aufgabe wäre es, die falschen Interessen der großen Institutionen der Öffentlichkeit zu präsentieren. Sie würden auch die typischerweise ignorierten Interessen der Öffentlichkeit durch Umfragen erfassen. Benchmark Umfragen Eine Benchmark Umfrage ist in der Regel die erste Umfrage in einer Kampagne. Es wird oft genommen, bevor ein Kandidat ihr Angebot für Büro kündigt, aber manchmal geschieht es sofort nach dieser Ankündigung, nachdem sie eine Gelegenheit hatten, Geld zu sammeln. Dies ist in der Regel eine kurze und einfache Umfrage von wahrscheinlichen Wählern. Eine Benchmark Umfrage dient einer Reihe von Zielen für eine Kampagne, sei es eine politische Kampagne oder eine andere Art von Kampagne. Zunächst gibt es dem Kandidat ein Bild davon, wo sie mit der Wählerschaft stehen, bevor eine Kampagne stattfindet. Wenn die Umfrage vor der Bekanntgabe des Amtes durchgeführt wird, kann der Kandidat die Umfrage verwenden, um zu entscheiden, ob sie sogar für das Amt laufen sollten. Zweitens zeigt sie, wo ihre Schwächen und Stärken in zwei Hauptbereichen liegen. Der erste ist die Wählerschaft. Eine Benchmark Umfrage zeigt ihnen, welche Arten von Wählern sie sicher zu gewinnen sind, die sie sicher zu verlieren sind, und alle zwischen diesen beiden Extremen. Dies lässt die Kampagne wissen, welche Wähler persuadable sind, damit sie ihre begrenzten Ressourcen in der effektivsten Weise ausgeben können. Zweitens kann sie ihnen eine Vorstellung davon geben, welche Botschaften, Ideen oder Slogans mit den Wählern am stärksten sind. Brushfire Umfragen Brushfire Umfragen werden während der Zeit zwischen der Benchmark Umfrage und Tracking Umfragen durchgeführt. Die Anzahl der von einer Kampagne getroffenen Brushfire-Umfragen wird bestimmt, wie wettbewerbsfähig das Rennen ist und wie viel Geld die Kampagne ausgeben muss. Diese Umfragen konzentrieren sich in der Regel auf wahrscheinliche Wähler und die Länge der Umfrage variiert auf die Anzahl der getesteten Nachrichten. Brushfire Umfragen werden für eine Reihe von Zwecken verwendet. Erstens lässt sie den Kandidat wissen, ob sie Fortschritte auf der Abstimmung gemacht haben, wie viel Fortschritt erzielt wurde, und in welchen Demografien sie gemacht oder verloren haben. Zweitens ist es ein Weg für die Kampagne, eine Vielzahl von Botschaften zu testen, sowohl positiv als auch negativ, auf sich selbst und ihren Gegner(n). Damit kann die Kampagne wissen, welche Nachrichten mit bestimmten Demografien am besten funktionieren und welche Botschaften vermieden werden sollen. Kampagnen verwenden diese Umfragen oft, um mögliche Angriffsnachrichten zu testen, die ihr Gegner verwenden kann und potenzielle Reaktionen auf diese Angriffe. Die Kampagne kann dann einige Zeit damit verbringen, eine effektive Reaktion auf eventuelle Angriffe vorzubereiten. Drittens kann diese Art von Umfrage von Kandidaten oder politischen Parteien verwendet werden, um primäre Herausfordererer zu überzeugen, aus einem Rennen zu fallen und einen stärkeren Kandidaten zu unterstützen. Umfragen verfolgen Bei einer Nachverfolgungs- oder Abrollbefragung handelt es sich um eine Umfrage, bei der Antworten in mehreren aufeinanderfolgenden Perioden, beispielsweise täglich, erhalten werden und dann die Ergebnisse anhand eines bewegten Mittels der Antworten berechnet werden, die über eine bestimmte Anzahl der letzten Zeiträume, beispielsweise der letzten fünf Tage, gesammelt wurden. In diesem Beispiel werden die nächsten berechneten Ergebnisse Daten für fünf Tage verwenden, die vom nächsten Tag zurückzählen, nämlich die gleichen Daten wie früher, aber mit den Daten vom nächsten Tag enthalten, und ohne die Daten vom sechsten Tag vor diesem Tag. Diese Umfragen unterliegen jedoch manchmal dramatischen Schwankungen, so dass politische Kampagnen und Kandidaten bei der Analyse ihrer Ergebnisse vorsichtig sind. Ein Beispiel für eine Tracking-Umfrage, die Kontroversen über seine Genauigkeit erzeugte, ist eine während der 2000 US-Präsidentschaftswahl, von der Gallup-Organisation durchgeführt. Die Ergebnisse für einen Tag zeigten den demokratischen Kandidaten Al Gore mit einer elf-Punkte-Leitung über den republikanischen Kandidaten George W. Bush. Dann zeigte eine anschließende Umfrage nur zwei Tage später Bush vor Gore um sieben Punkte. Es wurde bald festgestellt, dass die Volatilität der Ergebnisse zumindest teilweise auf eine ungleichmäßige Verteilung der demokratischen und republikanischen angeschlossenen Wähler in den Proben zurückzuführen war. Obwohl die Gallup-Organisation argumentierte, dass die Volatilität in der Umfrage eine echte Repräsentation der Wähler war, andere Bestäubungsorganisationen haben Schritte unternommen, um solche großen Variationen in ihren Ergebnissen zu reduzieren. Ein solcher Schritt beinhaltete die Manipulation des Anteils der Demokraten und Republikaner in einer bestimmten Probe, aber diese Methode ist Gegenstand Kontroversen. Im Laufe der Zeit wurden eine Reihe von Theorien und Mechanismen angeboten, um fehlerhafte Umfrageergebnisse zu erklären. Einige dieser spiegeln die Fehler der Umfrager wider; viele von ihnen sind statistisch. Andere beschuldigen die Befragten, keine kandierten Antworten zu geben (z.B. der Bradley-Effekt, der Shy Tory-Faktor); diese können kontroverser sein. Fehlerquote aufgrund der Probenahme Die auf Populationsproben basierenden Polls unterliegen einem Stichprobenfehler, der die Auswirkungen von Zufall und Unsicherheit im Probenahmeprozess widerspiegelt. Die Stichprobenerhebungen stützen sich auf das Gesetz der großen Zahlen, um die Meinungen der gesamten Bevölkerung nur auf einer Untermenge zu messen, und zu diesem Zweck ist die absolute Größe der Probe wichtig, aber der Prozentsatz der gesamten Bevölkerung ist nicht wichtig (sofern sie nicht in der Nähe der Stichprobengröße liegt). Der mögliche Unterschied zwischen der Probe und der Gesamtbevölkerung wird oft als Fehlermarge ausgedrückt - in der Regel definiert als der Radius eines 95 %-Konfidenzintervalls für eine bestimmte Statistik. Ein Beispiel sind die Prozent der Menschen, die Produkt A gegen Produkt B bevorzugen. Wenn eine einzige, globale Fehlermarge für eine Umfrage gemeldet wird, bezieht sie sich auf die maximale Fehlermarge für alle gemeldeten Prozente, die die vollständige Stichprobe der Umfrage verwenden. Ist die Statistik ein Prozentsatz, kann diese maximale Fehlermarge als Radius des Vertrauensintervalls für einen gemeldeten Prozentsatz von 50 % berechnet werden. Andere deuten darauf hin, dass eine Umfrage mit einer Zufallsstichprobe von 1.000 Personen einen Stichprobenfehler von ±3 % für den geschätzten Prozentsatz der gesamten Bevölkerung aufweist. Eine Fehlermarge von 3% bedeutet, dass, wenn das gleiche Verfahren eine große Anzahl von Zeiten verwendet wird, 95% der Zeit der tatsächliche Bevölkerungsdurchschnitt innerhalb der Stichprobenschätzung plus oder minus 3% sein wird. Die Fehlermarge kann durch die Verwendung einer größeren Probe reduziert werden, wenn jedoch ein Verursacher die Fehlermarge auf 1 % reduzieren möchte, würden sie eine Probe von etwa 10.000 Menschen benötigen. In der Praxis müssen die Verursacher die Kosten einer großen Stichprobe gegen die Verringerung des Stichprobenfehlers ausgleichen und eine Stichprobengröße von rund 500–1000 ist ein typischer Kompromiss für politische Umfragen. (Anmerkung, dass, um vollständige Antworten zu erhalten, kann es notwendig sein, Tausende von zusätzlichen Teilnehmern aufzunehmen.) Eine weitere Möglichkeit, die Fehlermarge zu reduzieren, besteht darin, sich auf die Umfragemittel zu verlassen. Dies macht die Annahme, dass das Verfahren zwischen vielen verschiedenen Umfragen ähnlich ist und die Stichprobengröße jeder Umfrage verwendet, um einen Umfragedurchschnitt zu erstellen. Ein Beispiel für einen Umfragedurchschnitt ist hier zu finden: 2008 Presidential Election polling Durchschnitt. Eine andere Fehlerquelle ergibt sich aus fehlerhaften demographischen Modellen von Verursachern, die ihre Proben nach bestimmten Variablen wie Parteiidentifikation bei einer Wahl wiegen. Wenn Sie beispielsweise davon ausgehen, dass sich die Aufschlüsselung der US-Bevölkerung durch Parteiidentifikation seit der vorherigen Präsidentschaftswahl nicht geändert hat, können Sie einen Sieg oder eine Niederlage eines bestimmten Parteikandidaten unterschätzen, die einen Anstieg oder Rückgang seiner Parteiregistrierung gegenüber dem vorherigen Präsidentschaftswahlzyklus gesehen haben. Eine Vorsicht ist, dass eine Schätzung eines Trends einem größeren Fehler unterliegt als eine Schätzung eines Niveaus. Dies liegt daran, dass, wenn man die Änderung, die Differenz zwischen zwei Zahlen X und Y, dann muss man mit Fehlern in sowohl X als auch Y konten. Eine grobe Führung ist, dass, wenn die Änderung der Messung außerhalb des Fehlerrandes fällt, die Aufmerksamkeit verdient. Nichtbeantwortung Da einige Leute keine Anrufe von Fremden beantworten oder sich weigern, die Umfrage zu beantworten, können Umfrageproben nicht repräsentative Proben von einer Bevölkerung aufgrund einer nicht reagierenden Vorspannung sein. Die Antwortquoten sind rückläufig und liegen in den letzten Jahren auf etwa 10%. Aufgrund dieser Selektionsvoreinschätzung können die Merkmale der Befragten, die sich einig sind, interviewt zu werden, deutlich von denen abweichen. Das heißt, die eigentliche Probe ist eine voreingenommene Version des Universums, das der Umfrager analysieren will. In diesen Fällen führt Bias neue Fehler ein, die eine oder andere Art sind, die neben Fehlern, die durch die Probengröße verursacht werden, sind. Fehler durch Bias wird bei größeren Probengrößen nicht kleiner, da die Größe einer größeren Probengröße einfach den gleichen Fehler in größerem Maßstab wiederholt. Wenn die Menschen, die sich weigern, zu antworten oder nie erreicht werden, die gleichen Eigenschaften haben wie die Menschen, die antworten, dann sollten die endgültigen Ergebnisse unvoreingenommen werden. Wenn die Menschen, die nicht antworten, verschiedene Meinungen haben, dann gibt es Vorurteile in den Ergebnissen. In Bezug auf Wahlabfragen legen Studien nahe, dass Bias-Effekte klein sind, aber jede Umfragefirma hat eigene Techniken zur Anpassung von Gewichten, um die Auswahl Bias zu minimieren. Die Ergebnisse der Antwort-Bias-Ergebnisse können von der Antwort-Bias beeinflusst werden, wo die Antworten der Befragten nicht ihren wahren Glauben widerspiegeln. Dies kann bewusst durch skrupellose Bestrebungen entwickelt werden, um ein bestimmtes Ergebnis zu erzeugen oder ihren Kunden zu gefallen, aber häufiger ist ein Ergebnis der ausführlichen Formulierung oder Bestellung von Fragen (siehe unten). Die Beklagten können bewusst versuchen, das Ergebnis einer Umfrage zu manipulieren, indem sie z.B. eine extremere Position als sie tatsächlich halten, um ihre Seite des Arguments zu stärken oder schnelle und unüberlegte Antworten zu geben, um das Ende ihrer Befragung zu beschleunigen. Die Befragten können sich auch unter sozialem Druck fühlen, keine unpopuläre Antwort zu geben. So können die Befragten nicht bereit sein, unpopuläre Einstellungen wie Rassismus oder Sexismus zuzuerkennen, und so können Umfragen die wahren Inzidenz dieser Einstellungen in der Bevölkerung nicht widerspiegeln. Im amerikanischen politischen Gleichgewicht wird dieses Phänomen oft als Bradley-Effekt bezeichnet. Wenn die Ergebnisse der Erhebungen weit verbreitet sind, kann diese Wirkung vergrößert werden - ein Phänomen, das allgemein als Spirale der Stille bezeichnet wird. Die Verwendung des Plättchenwahlsystems (nur einen Kandidaten auswählen) in einer Umfrage setzt eine unbeabsichtigte Vorspannung in die Umfrage, da Menschen, die mehr als einen Kandidaten bevorzugen, dies nicht angeben können. Die Tatsache, dass sie nur einen Kandidaten wählen müssen, belastet die Umfrage, wodurch es den Kandidaten am unterschiedlichsten von den anderen zu bevorzugen, während es Kandidaten, die ähnlich sind wie andere Kandidaten. Das Pluralitäts-Abstimmungssystem birgt auch Wahlen in gleicher Weise vor. Einige Leute, die darauf antworten, können die Worte nicht verstehen, die verwendet werden, aber können die Verlegenheit vermeiden, dies zuzulassen, oder der Umfragemechanismus kann keine Klarstellung zulassen, so dass sie eine willkürliche Wahl treffen können. Einige Prozent der Menschen beantworten auch whimsical oder aus Ärger, wenn sie befragt werden. Dies führt zu vielleicht 4% der Amerikaner, die sie persönlich enthauptet wurden. Formulierung von Fragen Unter den Faktoren, die die Ergebnisse der Stellungnahme Polls beeinflussen, sind die Formulierung und Reihenfolge der Fragen, die vom Befrager gestellt werden. Fragen, die sich bewusst auf eine Antwort der Befragten auswirken, werden als führende Fragen bezeichnet. Personen und/oder Gruppen nutzen diese Arten von Fragen in Umfragen, um auf ihre Interessen günstige Antworten zu finden. So wird die Öffentlichkeit eher die Unterstützung für eine Person angeben, die vom Vermessungsleiter als einer der "führenden Kandidaten" bezeichnet wird. Diese Beschreibung führt, wie sie eine subtile Vorspannung für diesen Kandidaten anzeigt, da sie impliziert, dass die anderen im Rennen keine ernsthaften Kandidaten sind. Darüber hinaus enthalten führende Fragen oft oder Mangel bestimmte Tatsachen, die die Antwort eines Befragten auslösen können. Argumentative Fragen können auch das Ergebnis einer Umfrage beeinflussen. Diese Art von Fragen, je nach Art, entweder positiv oder negativ, beeinflussen die Antworten der Befragten, um den Ton der Frage(n) zu reflektieren und eine bestimmte Antwort oder Reaktion zu erzeugen, anstatt Gefühl in unvoreingenommener Weise zu beurteilen. In der Meinungsumfrage gibt es auch "geladene Fragen", ansonsten als "Strickfragen" bekannt. " Diese Art von führender Frage kann eine unbequeme oder umstrittene Frage betreffen, und/oder automatisch davon ausgehen, dass das Thema der Frage mit dem/den Befragten in Zusammenhang steht oder dass sie darüber kundig sind. Ebenso werden die Fragen dann so formuliert, dass die möglichen Antworten, typischerweise auf Ja oder Nein, begrenzt werden. Eine andere Art von Frage, die ungenaue Ergebnisse produzieren kann, sind "Doppel-Negative Fragen. " Dies sind häufiger das Ergebnis menschlicher Fehler, anstatt vorsätzliche Manipulation. Ein solches Beispiel ist eine 1992 von der Roper-Organisation durchgeführte Erhebung über den Holocaust. Die Frage lautete: "Ist es dir möglich oder unmöglich, dass die Nazi-Vernichtung der Juden nie passiert ist? " Die verwirrende Formulierung dieser Frage führte zu ungenauen Ergebnissen, die darauf hindeuteten, dass 22 Prozent der Befragten glaubten, dass es möglich sei, dass der Holocaust nie passiert wäre. Als die Frage neu formuliert wurde, drückten deutlich weniger Befragten (nur 1 Prozent) diese Einschätzung aus. Vergleiche zwischen den Umfragen fallen daher oft auf die Formulierung der Frage. Bei einigen Fragen kann die Fragestellung zu deutlichen Unterschieden zwischen Erhebungen führen. Dies kann aber auch ein Ergebnis legitim widersprüchlicher Gefühle oder sich entwickelnder Einstellungen sein, anstatt einer schlecht konstruierten Umfrage. Eine gemeinsame Technik, um diese Vorspannung zu kontrollieren, ist, die Reihenfolge zu drehen, in der Fragen gestellt werden. Viele Pollen auch Split-Proben. Dabei handelt es sich um zwei verschiedene Versionen einer Frage, wobei jede Version der Hälfte der Befragten präsentiert wird. Die effektivsten Kontrollen, die von Einstellungsforschern verwendet werden, sind: genug Fragen zu stellen, um alle Aspekte eines Problems zu berücksichtigen und Effekte aufgrund der Form der Frage (wie positive oder negative Formulierung), die Angemessenheit der Zahl quantitativ mit psychometrischen Maßnahmen wie Zuverlässigkeitskoeffizienten und die Analyse der Ergebnisse mit psychometrischen Techniken, die die Antworten zu einigen zuverlässigen Punkten synthetisieren und unwirksame Fragen zu erkennen. Diese Kontrollen werden in der Umfrageindustrie nicht weit verbreitet.Da es jedoch wichtig ist, dass Fragen zur Prüfung des Produkts eine hohe Qualität haben, arbeiten Umfrage-Methoden an Methoden, um sie zu testen. Empirische Tests geben Einblick in die Qualität des Fragebogens, einige können komplexer als andere sein. So kann beispielsweise die Prüfung eines Fragebogens durch die Durchführung kognitiver Interviews erfolgen. Indem ein Forscher eine Stichprobe von potenziellen Teilnehmern über ihre Interpretation der Fragen und die Verwendung des Fragebogens stellt, kann ein Forscher einen kleinen Vortest des Fragebogens unter Verwendung einer kleinen Teilmenge von Zielbefragten durchführen. Die Ergebnisse können einen Forscher über Fehler wie fehlende Fragen oder logische und verfahrenstechnische Fehler informieren. Dies kann beispielsweise mit Test-Retest-, Quasi-Simplex- oder Mutlitrait-Multimethod-Modellen geschehen. Vorhersage der Messqualität der Frage. Dies kann mit dem Software Survey Quality Predictor (SQP) geschehen. Unfreiwillige Fassaden und falsche Korrelationen Eine der Kritiken an Meinungsumfragen ist, dass gesellschaftliche Annahmen, dass Meinungen, zwischen denen es keine logische Verbindung gibt, "korrelierte Haltungen" Menschen mit einer Meinung in eine Gruppe drängen können, die sie dazu zwingt, eine vermeintlich verknüpfte, aber tatsächlich nicht zusammenhängende Meinung zu haben. Das wiederum kann dazu führen, dass Menschen, die die erste Meinung haben, auf Umfragen behaupten, dass sie die zweite Meinung ohne sie haben, und dazu führen, dass Meinungsumfragen Teil der selbstvollenden Prophezeiungsprobleme werden. Es wurde vorgeschlagen, dass Versuche, unethische Meinungen entgegenzuwirken, indem vermeintliche verwandte Meinungen verurteilen, die Gruppen, die die tatsächlich unethischen Meinungen fördern, begünstigen können, indem Menschen mit vermeintlichen Meinungen in sie durch den Ostrakismus anderswo in der Gesellschaft zwingen, solche Bemühungen kontraproduktiv zu machen, die nicht zwischen Gruppen gesendet werden, die ulterior Motive von einander annehmen und nicht erlaubt, konsequent kritische Gedanken überall auszudrücken könnte, psychologische Stress zu verursachen, weil die Menschen sind sapis sind. In diesem Zusammenhang wird die Ablehnung der Annahme, dass Meinungsumfragen tatsächliche Zusammenhänge zwischen Meinungen zeigen, als wichtig angesehen. Eine andere Fehlerquelle ist die Verwendung von Proben, die nicht repräsentativ für die Bevölkerung als Folge der verwendeten Methodik sind, wie die Erfahrung von The Literary Digest im Jahr 1936. Zum Beispiel hat die Telefonprobenahme einen eingebauten Fehler, weil in vielen Zeiten und Orten die Telefone in der Regel reicher waren als die ohne. An manchen Stellen haben viele Menschen nur Mobiltelefone. Da Umfrager keine automatisierten Wahlmaschinen verwenden können, um Mobiltelefone in den Vereinigten Staaten zu rufen (weil der Besitzer des Telefons für eine Anrufbeantwortung berechnet werden kann), sind diese Individuen in der Regel von Umfrageproben ausgeschlossen. Es besteht Sorge, dass, wenn die Untermenge der Bevölkerung ohne Mobiltelefone deutlich von der übrigen Bevölkerung abweicht, diese Unterschiede können die Ergebnisse der Umfrage schief gehen. Polling Organisationen haben viele Gewichtungstechniken entwickelt, um diese Mängel zu überwinden, mit unterschiedlichen Erfolgsgraden. Studien von Mobilfunknutzern des Pew Research Center in den USA, im Jahr 2007, kam zu dem Schluss, dass "Zell-only-Angehörige sind von Landline-Angehörigen auf wichtige Weise verschieden, (aber) sie waren weder zahlreich noch verschieden genug auf die Fragen, die wir untersucht haben, um eine signifikante Änderung der allgemeinen Bevölkerungserhebung Schätzungen zu produzieren, wenn sie mit den Landline-Proben aufgenommen und gewichtet nach US-Parametern zu grundlegenden demografischen gewichtet." Diese Frage wurde 2004 erstmals identifiziert, kam aber erst während der US-Präsidentschaftswahl 2008 zum Vorschein. Bei den vorangegangenen Wahlen war der Anteil der allgemeinen Bevölkerung, die Mobiltelefone benutzte, gering, aber da dieser Anteil zugenommen hat, besteht die Sorge, dass die Abstimmung nur Landstriche nicht mehr repräsentativ für die allgemeine Bevölkerung ist. 2003 waren nur 2,9% der Haushalte kabellos (nur Mobiltelefone), verglichen mit 12,8% im Jahr 2006. Dies führt zu "Überdeckungsfehler". Viele Bestäubungsorganisationen wählen ihre Probe durch die Wahl von zufälligen Telefonnummern; aber im Jahr 2008 gab es eine klare Tendenz für Umfragen, die Handys in ihren Proben enthalten, um eine viel größere Führung für Obama zu zeigen, als Umfragen, die nicht. Die potentiellen Quellen der Vorspannung sind: Einige Haushalte verwenden nur Handys und haben keine Festnetz. Dies neigt dazu, Minderheiten und jüngere Wähler einzubeziehen und tritt häufiger in Ballungsräumen auf. Männer sind eher telefonisch nur im Vergleich zu Frauen. Einige Leute können von Montag bis Freitag nicht per Festnetz kontaktiert werden und können nur per Handy kontaktiert werden. Einige Leute nutzen ihre Landlinien nur, um auf das Internet zuzugreifen und Anrufe nur an ihre Handys zu beantworten. Einige Bestäubungsunternehmen haben versucht, um dieses Problem zu bekommen, indem ein "Telefonergänzung". Es gibt eine Reihe von Problemen mit der Aufnahme von Mobiltelefonen in einer Telefonabfrage: Es ist schwierig, die Zusammenarbeit von Handy-Nutzern zu bekommen, denn in vielen Teilen der USA werden die Nutzer sowohl für abgehende als auch eingehende Anrufe berechnet. Das bedeutet, dass die Verursacher einen finanziellen Ausgleich für die Zusammenarbeit bieten mussten. US-Bundesgesetz verbietet die Verwendung von automatischen Wählgeräten zum Anrufen von Mobiltelefonen (Telefon Consumer Protection Act von 1991). Zahlen müssen daher von Hand gewählt werden, was für Pollen zeitaufwendiger und teuerer ist. 1992 UK allgemeine Wahl Ein oft zitiertes Beispiel für Meinungsumfragen, die auf Fehler zurückzuführen sind, trat während der allgemeinen Wahlen 1992 in Großbritannien auf. Trotz der Wahlorganisationen, die unterschiedliche Methoden anwenden, zeigten praktisch alle Umfragen, die vor der Abstimmung getroffen wurden, und in geringerem Maße die am Abstimmungstag angenommenen Austrittsabstimmungen, eine Führung für die Oppositionspartei, aber die tatsächliche Abstimmung gab der herrschenden konservativen Partei einen klaren Sieg. In ihren Beratungen nach dieser Verlegenheit entwickelten die Umfrager mehrere Ideen, um ihre Fehler zu berücksichtigen, einschließlich: Late swing Voters, die ihre Meinung kurz vor der Abstimmung geändert haben, neigten dazu, die Konservativen zu befürworten, so dass der Fehler nicht so groß war, wie er zuerst erschien. Die konservativen Wähler waren weniger wahrscheinlich an Umfragen als in der Vergangenheit beteiligt und waren damit unterrepräsentiert. Der schüchterne Schamfaktor Die Konservativen hatten aufgrund wirtschaftlicher Schwierigkeiten und einer Reihe kleiner Skandale eine anhaltende Zeit der Unpopularität erlitten, was zu einer Spirale der Stille führte, in der einige konservative Unterstützer sich weigerten, ihre aufrichtigen Absichten zu Verursachern offenzulegen. Die relative Bedeutung dieser Faktoren war und bleibt eine Frage der Kontroverse, aber seitdem haben die Bestäubungsorganisationen ihre Methoden angepasst und in späteren Wahlkampagnen genauere Ergebnisse erzielt. Eine umfassende Diskussion über diese Vorurteile und wie sie verstanden und gemildert werden sollen, ist in mehreren Quellen enthalten, darunter Dillman und Salant (1994). Ausfälle Eine weit verbreitete Meinungsumfrage in den Vereinigten Staaten war die Vorhersage, dass Thomas Dewey Harry S. Truman in der US-Präsidentschaftswahl 1948 besiegen würde. Große Bestäubungsorganisationen, darunter Gallup und Roper, zeigten einen Landslide-Sieg für Dewey. Auch bei den Präsidentschaftswahlen von 1952, 1980, 1996, 2000 und 2016 gab es erhebliche Umfragefehler. Im Vereinigten Königreich konnten die meisten Umfragen die konservativen Wahlsiege von 1970 und 1992 und den Sieg von Labour im Februar 1974 nicht vorhersagen. Bei den Wahlen 2015 prognostizierte fast jede Umfrage ein aufgehängtes Parlament mit Arbeit und Konservativen Hals und Hals, als das tatsächliche Ergebnis eine klare konservative Mehrheit war. Andererseits scheint im Jahr 2017 das Gegenteil aufgetreten zu sein. Die meisten Umfragen prognostizierten eine verstärkte konservative Mehrheit, obwohl in Wirklichkeit die Wahl zu einem aufgehängten Parlament mit einer konservativen Mehrzahl führte. Allerdings haben einige Umfragen dieses Ergebnis korrekt vorhergesagt. In Neuseeland prognostizierten die Umfragen, die bis zur allgemeinen Wahl 1993 führten, einen angenehmen Sieg der Regierungspartei. Die vorläufigen Ergebnisse in der Wahlnacht zeigten jedoch ein aufgehängtes Parlament mit einem nationalen Sitz, kurz vor der Mehrheit, was zu Premierminister Jim Bolger führt, der im nationalen Fernsehen "die Bestrebungen" ausruft. Die offizielle Zählung sah die nationale Abholung von Waitaki, um eine einsitzige Mehrheit zu halten und die Regierung zu reformieren. Social Media als Meinungsquelle für Kandidaten Social Media ist heute ein beliebtes Medium für die Kandidatinnen und Kandidaten zur Kampagne und zur Glaubwürdigkeit der öffentlichen Reaktion auf die Kampagnen. Soziale Medien können auch als Indikator der Meinung der Wähler über die Umfrage verwendet werden. Einige Studien haben gezeigt, dass Vorhersagen, die mit Social Media-Signalen gemacht werden, mit traditionellen Meinungsumfragen übereinstimmen können. In Bezug auf die Präsidentschaftswahl 2016 war eine große Sorge, dass die Auswirkungen falscher Geschichten in den sozialen Medien verbreitet wurden. Evidence zeigt, dass soziale Medien eine große Rolle bei der Bereitstellung von Nachrichten spielen: 62 Prozent der US-Erwachsenen erhalten Nachrichten über soziale Medien. Diese Tatsache macht das Thema gefälschte Nachrichten in sozialen Medien mehr Bedeutung. Andere Beweise zeigen, dass die populärsten gefälschten Nachrichtengeschichten auf Facebook weit verbreitet wurden als die beliebtesten Mainstream-Nachrichtengeschichten; viele Menschen, die gefälschte Nachrichtengeschichten sehen, berichten, dass sie sie glauben; und die am meisten diskutierten gefälschten Nachrichtengeschichten neigten Donald Trump über Hillary Clinton zu bevorzugen. Infolge dieser Tatsachen haben einige der Schluss gezogen, dass Donald Trump, wenn nicht für diese Geschichten, die Wahl über Hillary Clinton nicht gewonnen haben. Einfluss Auswirkungen auf die Wähler Durch die Bereitstellung von Informationen über Abstimmungsabsichten können Meinungsumfragen manchmal das Verhalten der Wähler beeinflussen, und in seinem Buch The Broken Compass behauptet Peter Hitchens, dass Meinungsumfragen tatsächlich ein Gerät zur Beeinflussung der öffentlichen Meinung sind. Die verschiedenen Theorien, wie dies geschieht, können in zwei Gruppen aufgeteilt werden: Bandwagon / Underdog-Effekte und strategische (taktische) Abstimmung. Ein Bandwagon-Effekt tritt auf, wenn die Umfrage die Wähler dazu auffordert, den Kandidat zu unterstützen, der gezeigt wird, dass er in der Umfrage gewinnt. Die Idee, dass Wähler anfällig für solche Effekte ist alt, mindestens ab 1884; William Safire berichtet, dass der Begriff zuerst in einem politischen Cartoon in der Zeitschrift Puck in diesem Jahr verwendet. Es ist auch trotz der fehlenden empirischen Korroboration bis Ende des 20. Jahrhunderts anhaltend. George Gallup vergeblich versuchte, diese Theorie in seiner Zeit zu diskreditieren, indem er empirische Forschung präsentierte. Eine aktuelle Meta-Studie der wissenschaftlichen Forschung zu diesem Thema zeigt, dass ab den 1980er Jahren der Bandwagon-Effekt häufiger von Forschern gefunden wird. Das Gegenteil des Bandwagoneffektes ist der Underdog-Effekt. Es wird oft in den Medien erwähnt. Dies geschieht, wenn die Leute aus Mitgefühl wählen, denn die Partei sah aus, die Wahlen zu verlieren. Es gibt weniger empirische Beweise für die Existenz dieses Effekts, als es für die Existenz des Bandwagon-Effekts gibt. Die zweite Kategorie der Theorien, wie die Umfragen direkt die Abstimmung beeinflussen, wird als strategische oder taktische Abstimmung bezeichnet. Diese Theorie basiert auf der Idee, dass die Wähler den Rechtsakt der Wahl als Mittel zur Wahl einer Regierung betrachten. So werden sie manchmal nicht den Kandidat wählen, den sie vor Ort der Ideologie oder Sympathie bevorzugen, sondern einen anderen, weniger bevorzugten Kandidaten aus strategischen Erwägungen. Ein Beispiel ist die allgemeine Wahl des Vereinigten Königreichs 1997. Da er damals Kabinettsminister war, wurde Michael Portillos Wahlkreis von Enfield Southgate als sicherer Sitz geglaubt, aber Meinungsumfragen zeigten dem Arbeitskandidat Stephen Twigg stetig Unterstützung, die möglicherweise unentschlossene Wähler oder Unterstützer anderer Parteien dazu veranlasst haben, Twigg zu unterstützen, um Portillo zu entfernen. Ein weiteres Beispiel ist der Bumerang-Effekt, bei dem die wahrscheinlichen Anhänger des Kandidaten als gewinnendes Gefühl, dass Chancen schlank sind und dass ihre Stimme nicht erforderlich ist, so dass ein anderer Kandidaten zu gewinnen. Darüber hinaus erläutert Mark Pickup in Cameron Anderson und Laura Stephensons Voting Behaviour in Kanada drei zusätzliche Verhaltensreaktionen, die Wähler bei Umfragedaten zeigen können. Der erste wird als "Cue Take"-Effekt bezeichnet, der hält, dass Umfragedaten als Proxy für Informationen über die Kandidaten oder Parteien verwendet werden. Cue Take ist "auf der Grundlage des psychologischen Phänomens der Nutzung von Heuristiken, um eine komplexe Entscheidung zu vereinfachen" (243). Die zweite, zuerst von Petty und Cacioppo (1996,) beschrieben, ist als "kognitive Antwort" Theorie bekannt. Diese Theorie behauptet, dass die Reaktion eines Wählers auf eine Umfrage nicht mit ihrer ursprünglichen Vorstellung der Wahlwirklichkeit übereinstimmen kann. Als Antwort wird der Wähler wahrscheinlich eine "mentale Liste" erzeugen, in der sie Gründe für den Verlust oder Gewinn einer Partei in den Umfragen schaffen. Dies kann ihre Meinung des Kandidaten stärken oder ändern und somit das Abstimmungsverhalten beeinflussen. Drittens ist die letzte Möglichkeit eine "verhaltene Antwort", die einer kognitiven Antwort ähnlich ist. Der einzige entfremdende Unterschied ist, dass ein Wähler gehen und nach neuen Informationen suchen wird, um ihre "mentale Liste" zu bilden, so dass mehr über die Wahl informiert wird. Dies kann dann das Abstimmungsverhalten beeinflussen. Diese Auswirkungen zeigen, wie Meinungsumfragen direkt die politischen Entscheidungen der Wähler beeinflussen können. Aber direkt oder indirekt können andere Effekte auf alle politischen Parteien untersucht und analysiert werden. Auch die Form von Medien- und Parteiideologieverschiebungen muss berücksichtigt werden. Die Meinungsumfrage in einigen Fällen ist ein Maß für kognitive Bias, das in seinen verschiedenen Anwendungen variabel betrachtet und entsprechend behandelt wird. Die Auswirkungen auf Politiker, die in den 1980er Jahren begannen, Umfragen und verwandte Technologien zu verfolgen, begannen, spürbare Auswirkungen auf die politischen Führer der USA zu haben. Laut Douglas Bailey, einem Republikaner, der geholfen hatte, Gerald Fords Präsidentschaftskampagne von 1976 zu führen, "Es ist nicht mehr notwendig für einen politischen Kandidaten zu erraten, was ein Publikum denkt. Er kann mit einer nächtlichen Tracking-Befragung herausfinden. Es ist also nicht mehr wahrscheinlich, dass politische Führer führen werden. Stattdessen werden sie folgen." Verordnung Einige Gerichtsbarkeiten auf der ganzen Welt beschränken die Veröffentlichung der Ergebnisse der Meinungsumfragen, insbesondere während der Wahlperiode, um zu verhindern, dass die möglicherweise fehlerhaften Ergebnisse die Entscheidungen der Wähler beeinflussen. So ist es in Kanada untersagt, die Ergebnisse von Meinungsumfragen zu veröffentlichen, die in den letzten drei Tagen vor einer Umfrage bestimmte politische Parteien oder Kandidaten identifizieren würden. Die meisten westdemokratischen Nationen unterstützen jedoch nicht das gesamte Verbot der Veröffentlichung von Meinungsumfragen zur Vorwahl; die meisten von ihnen haben keine Verordnung und einige verbieten es nur in den letzten Tagen oder Stunden, bis die entsprechende Umfrage zu Ende geht. Eine Umfrage der kanadischen Royal Commission on Electoral Reform berichtete, dass die Verbotsfrist der Veröffentlichung der Erhebungsergebnisse in verschiedenen Ländern weitgehend unterschiedlich war. Aus den 20 untersuchten Ländern verbieten 3 die Veröffentlichung während der gesamten Laufzeit der Kampagnen, während andere es für eine kürzere Dauer wie die Umfragezeit oder die letzten 48 Stunden vor einer Umfrage verbieten. In Indien hat die Wahlkommission sie in den 48 Stunden vor Beginn der Umfrage untersagt. Siehe auch Fußnoten Referenzen Asher, Herbert: Polling und die Öffentlichkeit. Was jeder Bürger wissen sollte (4. ed.CQ Presse, 1998)Bourdieu, Pierre, "Public Opinion is not exist" in Sociology in Question, London, Sage (1995). Bradburn, Norman M. und Seymour Sudman. Umfragen: Verstehen, was sie uns sagen (1988). Cantril, Hadley. Public Opinion (1944) online. Cantril, Hadley und Mildred Strunk, eds.Public Opinion, 1935–1946 (1951), massive Zusammenstellung vieler Meinungsumfragen online Converse, Jean M. Survey Research in den USA: Roots and Emergence 1890-1960 (1987), die Standardgeschichte. Crespi, Irving. Public Opinion, Polls und Democracy (1989). Gallup, George. Öffentliche Meinung in einer Demokratie (1939). Gallup, Alec M. ed.The Gallup Poll Cumulative Index: Public Opinion, 1935-1997 (1999) listet 10.000+ Fragen auf, aber keine Ergebnisse. Gallup, George Horace, ed.The Gallup Poll; Public Opinion, 1935-1971 3 vol (1972) fasst Ergebnisse jeder Umfrage zusammen. Geer, John Gray. Öffentliche Meinung und Abstimmung auf der ganzen Welt: eine historische Enzyklopädie (2 Vol. Abc-clio, 2004)Glynn, Carroll J,. Susan Herbst, Garrett J. O'Keefe, und Robert Y. Shapiro.Public Opinion (1999) Lehrbuch Lavrakas, Paul J. et al.eds. Presidential Polls and the News Media (1995)Moore, David W. The Superpollsters: Wie sie öffentliche Meinung in Amerika messen und manipulieren (1995). Niemi, Richard G, John Mueller, Tom W. Smith, Eds. Entwicklung der öffentlichen Meinung: Ein Kompendium der Erhebungsdaten (1989). Oskamp, Stuart und P. Wesley Schultz; Standpunkte und Stellungnahmen (2004). Robinson, Claude E. Straw Votes (1932). Robinson, Matthew Mobocracy: Wie die Obsession der Medien mit Polling Twist die Nachrichten, Alterswahlen und untergräbt Demokratie (2002). Rogers, Lindsay. Die Pollsters: Öffentliche Meinung, Politik und demokratische Führung (1949). Traugott,Michael W.The Voter's Guide to Election Polls 3rd ed.(2004). James G. Webster, Patricia F. Phalen, Lawrence W. Lichty; Ratings Analysis: Theory and Practice of Audience Research Lawrence Erlbaum Associates, 2000. Young, Michael L. Wörterbuch Polling: The Language of Contemporary Opinion Research (1992). Weitere Quellen Brodie, Mollyann, et al. "Die Vergangenheit, Gegenwart, und mögliche Zukunft der öffentlichen Meinung über die ACA: Eine Überprüfung von 102 nationalen repräsentativen Umfragen zur öffentlichen Meinung über das Affordable Care Act, 2010 bis 2019." Gesundheitsangelegenheiten 39.3 (2020:) 462–470.Dyczok, Marta."Informationskriege: Hegemonie, Gegenhegemonie, Propaganda, Gewaltanwendung und Widerstand."Russisches Journal of Communication 6#2 (2014): 173–176. Eagly, Alice H. et al." Gender-Stereotypen haben sich geändert: Eine Cross-Temporal-Metaanalyse der US-amerikanischen Meinungsumfragen von 1946 bis 2018." Amerikanische Psychologe 75.3 (2020:) 301+.online Fernández-Prados, Juan Sebastián, Cristina Cuenca-Piqueras und María José González-Moreno."Internationale Meinungsumfragen und öffentliche Politik in den südeuropäischen Demokratien." Journal of International and Comparative Social Policy 35.2 (2019): 227–237.online Kang, Liu und Yun-Han Chu."Chinas Aufstieg durch die Weltöffentlichkeit: Editorial Einführung." Journal of Contemporary China 24.92 (2015): 197–202; Umfragen in den USA und China Kim So Young, Wolinsky-Nahmias Yael (2014). " Die grenzüberschreitende öffentliche Meinung zum Klimawandel: die Auswirkungen von Zufluss und Verletzlichkeit". Globale Umweltpolitik.14 (1): 79–106.doi:10.1162/glep_a_00215.S2CID 558738. Murphy, Joe, et al."Social Media in Public Opinion Research: Report of the AAPOR Task Force on Emerging Technologies in Public Opinion Research."American Association for Public Opinion Research (2014).online Externe Links Polls from UCB LibrariesGovPubs Das Pew Research Center nonpartisan "fact tank" bietet Informationen zu den Themen, Einstellungen und Trends, die Amerika und die Welt durch die öffentliche Meinungsumfrage und soziale Wissenschaft Forschung National Council on Public Polls Vereinigung von Wahlorganisationen in den Vereinigten Staaten gewidmet hohe professionelle Standards für Umfragen zu setzen