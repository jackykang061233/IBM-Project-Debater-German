Statistik: Einstufung ist das Problem, zu ermitteln, welche einer Reihe von Kategorien (Teilpopulationen) eine Beobachtung (oder Beobachtungen) gehört. Beispiele sind eine bestimmte E-Mail an die Spam- oder Nicht-Spam-Klasse und eine Diagnose an einen bestimmten Patienten auf der Grundlage der beobachteten Merkmale des Patienten (sex, Blutdruck, Vorhandensein oder Fehlen bestimmter Symptome usw.). Häufig werden die einzelnen Beobachtungen in eine Reihe quantifizierbarer Eigenschaften analysiert, die verschiedene als erläuternde Variablen oder Merkmale bekannt sind. Diese Eigenschaften können unterschiedlich kategorisch sein (z.B. A, B, AB oder O, für Bluttyp), ordinal (z.B. groß, mittel oder klein), numerisch (z.B. die Anzahl der Ereignisse eines bestimmten Wortes in einer E-Mail) oder real bewertet (z.B. eine Messung des Blutdrucks). Andere Klassenprüfer arbeiten durch Vergleich der Beobachtungen zu früheren Beobachtungen durch eine Ähnlichkeit oder Fernfunktion. Ein Algorithmus, der die Einstufung vor allem in einer konkreten Umsetzung durchführt, ist bekannt als Klasseerin. Er verweist manchmal auch auf die mathematische Funktion, die von einem Klassifikations-Algorithmus umgesetzt wird, die die Eingabedaten einer Kategorie enthält. Terminologie in verschiedenen Bereichen ist sehr unterschiedlich. Statistiken, in denen die Einstufung oft mit logistischer Regression oder einem ähnlichen Verfahren erfolgt, werden die Eigenschaften der Beobachtungen als erläuternde Variablen (oder unabhängige Variablen, Regressoren usw.) bezeichnet und die zu vorhersagenden Kategorien sind als Ergebnisse bekannt, die als mögliche Werte der abhängigen variablen Variablen gelten. In einem maschinenlesbaren Lernen sind die Beobachtungen häufig als Instanzen bekannt, die erläuternden Variablen werden als Merkmale bezeichnet (die in einen Merkmalsvektor zusammengefasst sind), und die möglichen Kategorien sind Klassen. Andere Felder können unterschiedliche Terminologie verwenden: z.B. in der gemeinschaftlichen Ökologie, die normalerweise auf die Clusteranalyse verweist. Zusammenhang mit anderen Problemen Klassifizierung und Clusterbildung sind Beispiele für das allgemeinere Problem der Mustererkennung, das die Zuordnung einiger Arten von Outputwert zu einem bestimmten Inputwert ist. Andere Beispiele sind Regression, die für jeden Input eine echte Wertschöpfung zugewiesen; Sequenzierung, die jedem Mitglied einer Reihe von Werten (z.B. ein Teil der Reden, die einen Teil der Rede zu jedem Wort in einem Vorstrafen eingibt); Parsing, der einen Parsebaum an einen Beitrag verleiht, in dem die Struktur der Strafe beschrieben wird; usw. Eine gemeinsame Subklasse der Klassifikation ist eine probabilistische Einstufung. Algorithms dieser Art verwenden statistische Unterschiede, um die beste Klasse für ein bestimmtes Beispiel zu finden. Anders als andere Algorithmen, die einfach eine beste Klasse produzieren, führen probabilistische Algorithmen zu einer Wahrscheinlichkeit, dass das Beispiel Mitglied jeder der möglichen Klassen ist. Die beste Klasse wird normalerweise als eine mit höchster Wahrscheinlichkeit ausgewählt. Jedoch hat ein solcher Algorithmus zahlreiche Vorteile gegenüber nicht-probabilistischen Klassentoren: Es kann einen Vertrauenswert im Zusammenhang mit seiner Wahl (im Allgemeinen, ein Klasseer, der dies tun kann, als vertrauensgewogenes Klassenzeichen bezeichnet werden). Entsprechend kann es sich bei der Auswahl eines bestimmten Outputs zu wenig halten. Durch die entstandenen Probstigkeiten können probabilistische Klassentoren wirksamer in größere maschinelle Lernaufgaben integriert werden, um das Problem der Fehler propagation teilweise oder vollständig zu vermeiden. Häufige Verfahren Frühzeitige Arbeiten zur statistischen Einstufung wurden von Fischer im Zusammenhang mit zwei Gruppenproblemen durchgeführt, was zu einer linearen Unterscheidungsfunktion der Fischer als Regel für die Zuordnung einer Gruppe zu einer neuen Beobachtung führte. In dieser frühen Arbeit wurde davon ausgegangen, dass Datenwerte in jedem der beiden Gruppen eine multivariate normale Verteilung haben. Die Verlängerung dieses gleichen Kontexts auf mehr als zwei Gruppen wurde ebenfalls mit einer Beschränkung in Betracht gezogen, dass die Klassifikationsregel linear sein sollte. Nach einer späteren Arbeit für die multivariate normale Verteilung konnte der Einstufungsempfänger nichtlinear sein: mehrere Klassifikationsregeln können auf der Grundlage unterschiedlicher Anpassungen der Razanobis Entfernung abgeleitet werden, wobei eine neue Beobachtung der Gruppe zugewiesen wird, deren Zentrum die niedrigste Entfernung von der Beobachtung aufweist. Bayesische Verfahren Im Gegensatz zu häufigen Verfahren bieten die Bayesischen Klassifikationsverfahren eine natürliche Möglichkeit, alle verfügbaren Informationen über die relative Größe der verschiedenen Gruppen innerhalb der Gesamtbevölkerung zu berücksichtigen. Bayesische Verfahren sind in der Regel rechnerisch teuer und wurden in den Tagen vor der Entwicklung der Markov-Ketten Monte Carlo entwickelt, die Angleichung der Regeln für die Clusterbildung von Bayesian. Manche Bayesische Verfahren umfassen die Berechnung der Gruppenmitgliedschaftsprobabilities: Diese bieten ein informativeres Ergebnis als eine einfache Zuteilung eines einzigen Gruppenzeichens für jede neue Beobachtung. Eindeutige und multiclassale Klassifikationen können als zwei getrennte Probleme betrachtet werden – eine binäre Klassifikation und eine multiclasse Klassifikation. In der binären Einstufung, einer besser verstandenen Aufgabe, sind nur zwei Klassen beteiligt, während die Multiclass-Klassifikation ein Gegenstand mehrerer Klassen ist. Da viele Klassifizierungsmethoden speziell für die binäre Einstufung entwickelt wurden, erfordert die Multiclass-Klassifikation oft den kombinierten Einsatz mehrerer binärer Klasseer. Bildträger Die meisten Algorithmen beschreiben ein einzelnes Beispiel, dessen Kategorie vorhergesagt werden soll, mit einem Merkmal des einzelnen, messbaren Eigenschaften des Beispiels. Jedes Eigentum wird als Merkmal bezeichnet, auch in Statistiken als eine erläuternde variable (oder unabhängige variable, obwohl Merkmale möglicherweise oder nicht statistisch unabhängig sein können). Eigenschaften können unterschiedlich sein (z.B. auf oder außerhalb); kategorisch (z.B. A, B, AB oder O, für Bluttyp); ordinal (z.B. groß, mittel oder klein); numerisch (z.B. die Anzahl der Ereignisse eines bestimmten Wortes in einer E-Mail); oder real bewertet (z.B. eine Messung des Blutdrucks). Wenn das Beispiel ein Bild ist, könnten die Merkmalswerte den Pixeln eines Bildes entsprechen; wenn das Beispiel ein Stück Text ist, könnten die Merkmalswerte unterschiedliche Worte darstellen. Manche Algorithmen arbeiten nur im Hinblick auf diskrete Daten und erfordern, dass reale oder zahlbare Daten in Gruppen (z.B. weniger als 5, zwischen 5 und 10 oder mehr als 10) zusammengefasst werden. Lineare Klassenstellen Eine große Zahl von Algorithmen für die Einstufung kann in Bezug auf eine lineare Funktion angegeben werden, die eine Anzeige für jede mögliche Kategorie k durch die Kombination des Merkmals einer Instanz mit einem Tonträger mit einem Punktprodukt vorgibt. Die vorhergesagte Kategorie ist das mit dem höchsten Wert. Diese Art der Leistung ist als lineare Vorhersehbarkeit bekannt und hat folgende allgemeine Form: Score  of ( X i , k ) = β k ⋅ X i , {\displaystyle \operatorname {score} (\ Mathematikdl {X} _i},k)=Getreide 7.8beta {_k}\cdot \ Mathematik {X} {_i,} Xi ist der Merkmalsvektor, z.B. i, βk, ist die Art der Gewichte, die der Kategorie k entsprechen, und Score(Xi, k) ist der mit der Kategorie k verbundene Fortschritt. In einer diskreten Auswahltheorie, in der Instanzen Personen und Kategorien wählen, wird der Wert als mit der Kategorie k verbundene Nutznießer angesehen. Algorithms mit dieser Grundanlage sind als lineare Klassenprüfer bekannt. Welche Unterscheidungen sind das Verfahren zur Bestimmung (Ausbildung) der optimalen Gewichte/Koeffizienten und der Art und Weise, wie der Wert interpretiert wird. Beispiele solcher Algorithmen sind Logistische Regression und Multinomial logistische Regression Probit Regression Der Perceptron-Algorithmus unterstützt Vektormaschinen lineare diskriminierende Analyse. Algorithmen Da keine einheitliche Einstufung für alle Datensets geeignet ist, wurde ein großes Werkzeugkit für Klassifikationsgorithmen entwickelt. Am häufigsten verwendet werden: lineare Klassentoren Fisher's linear diskriminant Logistic Regression Naive Bayes Klassenifier Perceptron Support-Systeme Least Quadrate unterstützen Vektor-Automatik-Klassenifiers Vector-Schätzung k-narest Nachbarn Höhere (meta-algorithm)Entscheidung Bäume Random Forest Neural Networks Learning Vektor Quantization Evaluation Classifier Leistung hängt stark von den Merkmalen der zu erfassenden Daten ab. Es gibt keine einzige Klasse, die am besten auf allen bestimmten Problemen arbeitet (ein Phänomen, das durch den no-free-lunch theorem erklärt werden kann). Verschiedene empirische Tests wurden durchgeführt, um die Leistung von Klassenprüfern zu vergleichen und die Merkmale der Daten zu ermitteln, die die Leistung von Klassenprüfern bestimmen. Klarstellung einer geeigneten Klasse für ein bestimmtes Problem ist jedoch immer noch mehr eine Art als eine Wissenschaft. Präzision und Rückruf sind beliebte Parameter, die zur Bewertung der Qualität eines Klassifikationssystems verwendet werden. Kürzlich wurden die charakteristischen (ROC) Kurveen des Empfängers verwendet, um die Abwägung zwischen wahren und falschen Einstufungsraten zu bewerten. Als Leistungsmessung hat der Unsicherheitskoeffizient den Vorteil über einfache Genauigkeit, da er nicht durch die relative Größe der einzelnen Klassen beeinträchtigt wird. Darüber hinaus wird es keinen Algorithmus für die bloße Aufzucht der Klassen bestrafen. Anwendungsgebiete Klassifikation hat viele Anwendungen. In einigen dieser Verfahren wird sie als Data Mining-Verfahren eingesetzt, während in anderen ein detaillierteres statistisches Modell durchgeführt wird. Computer Vision Medizinische Bildgebung und medizinische Bildanalyse optischer Charaktererkennung Video-Überwachung Drogenerkennung und Entwicklung Toxicogenomik quantitative Strukturbeziehungen Geostatistics Spracherkennung Biometrische Identifizierung Biological Statistischer Datenverarbeitungsdokument Klassifikation Internet-Suche-Tests Anerkennung von Kreditkartenanerkennung empfohlener System Micro-array Klassifikation Siehe auch