In den Bereichen Maschinenbau und mathematische Optimierung sind die Verlustfunktionen für die Einstufung rechnerisch machbar, was den für die Ungenauigkeit der Vorhersagen in Klassifikationsproblemen gezahlten Preis darstellt (Probleme, die eine bestimmte Beobachtungskategorie zu bestimmen). Lage X {\displaystyle {X} als Raum aller möglichen Inputs (normalerweise X  R R d {\displaystyle {X}}\subset \bb {R} {^d} ) und Y = { { − 1 , 1 } faserstyle 7.8 Mathematik Y==-1-1,1 als Set von Etiketten (mögliche Outputs), ein typisches Ziel von Klassifikationsgorithmen ist es, eine Funktion f zu finden: X {\ R {\displaystyle f: cu Mathematik {X}}\mapsto \bb {R} }, die am besten für einen bestimmten Input x → Memestyle Memevec {x} ein Label y KINGstyle y} vorhersagen. Aufgrund unvollständiger Informationen, Lärm in der Messung oder probabilistischer Komponenten im zugrunde liegenden Prozess ist es jedoch möglich, dass die gleiche x → {\displaystyle {x} unterschiedliche Yendisplaystyle y} erzeugen kann. Infolgedessen besteht das Ziel des Lernproblems darin, den erwarteten Verlust (auch bekannt als das Risiko), definiert als I [ f ] =  Y X × Y V ( x → ) , y ) p ( x → , y ) d x → d y KINGstyle I[f]=\displaystyle \int JPY_cal {X}}\times liv Mathematik Y{\V(f(Fix{\),y)p(Getvec x}},y)\,dggiovec {x}}\,dy, wo V ( x → ) , y ) ) Memedisplaystyle V(f) {xve {x}}), ist eine bestimmte Verlustfunktion und p ( x →, y  y) p) · · .  which  y {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\  y  y  y {\ {\  y  y  y  y  y  y {\ {\ {\ {\  y  y  y  y  y  y  y {\  y  y  y  y  y {\ {\ {\ {\ {\ {\ . . . .  Innerhalb der Einstufung werden mehrere häufig verwendete Verlustfunktionen ausschließlich in Bezug auf das Produkt des wahren Kennzeichens y displaystyle y} und des vorhergesagten Kennzeichens f ( x → ) Memestyle f(Getvec {x)} . Esfore können sie als Funktionen von nur einer variablen  of = y f ( x → ) \uROW =yf( fivec {x)} definiert werden, so dass V ( x → ·  V) · ·  Vf) · · · · · ) ( V) R → R KINGstyle \phi \: Mathematik {R} \to \bb {R} } . Diese werden als Marg-basierte Verlustfunktionen bezeichnet. Wahl einer Marg-basierten Verlustfunktion ist die Wahl der   Memedisplaystyle \phi } .Selektierung einer Verlustfunktion innerhalb dieses Rahmens beeinflusst die optimale f . {\ {\displaystyle f_ cuphi ***, die das erwartete Risiko minimieren. Kann die Berechnung des erwarteten Risikos aus dem oben genannten Bestandteil vereinfacht werden. I [ f ] =  X X × Y V ( f ( x → ) , y ) p ( x → , y ) d x → d y =  X X  X X ) Y ) ( y f ( x → ) ) p ( y ∣ x → ) p ( x → ) d y d x → X [ ) ( x → ) ) p ( 1 ∣ x → ) + ) ( x → ) p ( 1 x → ) ] p ( x → ) d x →  X X [ → ( x → ) ) p ( 1 ∣ x → ) +  x ( x →) → ( x → →) )  1 )  1 ) )  1  Y  Y  Y  Y  Y  Y  Y  1  1  1  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y Die zweite Gleichstellung folgt den oben beschriebenen Eigenschaften. Die dritte Gleichstellung folgt der Tatsache, dass 1 und −1 die einzigen möglichen Werte für y {\displaystyle y} und das vierte, weil p (- 1  1 x ) = 1 − p ( 1 ∣ x ) {\displaystyle p(-1\mid x)=1-p(1\mid x)}. Der Begriff in Klammern [  f ( x → ) ) p ( 1 ∣ x → ) +  x ( x → ) ) ( 1 − p ( 1 → x → ) ) ] {\ [ \[phi f( {x))])p(1\mid {x{\ {x{\ {x{\ {x}} {x}} {x}})] \phif(f) {f(f) {f) {f) {f) {f)] Jeder kann für den möglichst niedrigen I [ f ] Memedisplaystyle I[f}] lösen, indem er den funktionalen Derivat der letzten Gleichheit in Bezug auf f {\displaystyle f} und den Derivat auf 0 setzt.  This ) ( f ) ) f  +  + ∂ φ  f      1 f ( ) η f ( 1 η ) = 0 ( 1 ) Memestyle HANAfrac ggiof Racpartial \phi (f)}{\partial f}}\eta {+\frac casapartial \phi (f-f)}}partial f(f) =0\;\;\;\;\;\;(1}, was ebenfalls der Festsetzung des Derivaterisikos entspricht, der Null entspricht. Angesichts des binären Charakters der Einstufung wäre eine natürliche Auswahl für eine Verlustfunktion (bei gleicher Kosten für falsche positive und falsche negative Nebenwirkungen) die 0-1-Verlustfunktion (0–1 Indikator-Funktion), die den Wert von 0 trägt, wenn die vorhergesagte Einstufung dem der tatsächlichen Klasse entspricht oder 1, wenn die vorhergesagte Klassifizierung nicht der wahren Klasse entspricht. Diese Auswahl wird von V ( x → ) , y ) = H ( ‐ y f ( x → ) ) Memedisplaystyle V(f(Fieber) x}}),y)=H(-yf(Syf(Porta {x)} wo H Memedisplaystyle H} die Heaviside-Phase bezeichnet. Diese Verlustfunktion ist jedoch nicht-konvex und nicht-smooth, und die Lösung für die optimale Lösung ist ein  NP-hard Kombinierungsproblem. Infolgedessen ist es besser, Verlustfunktionen Ersatzstoffe zu ersetzen, die für allgemein verwendete Lernalgorithmen tragbar sind, da sie gute Eigenschaften wie Konvex und glatt haben. Neben ihrer Rechenfähigkeit kann man zeigen, dass die Lösungen für das Lernproblem mit diesen Verlustzuschlägen die Wiederherstellung der tatsächlichen Lösung des ursprünglichen Klassifizierungsproblems ermöglichen. Manche dieser Surrogate werden unten beschrieben. In der Praxis ist die Wahrscheinlichkeitsverteilung p ( x → , y ) {\displaystyle p(Getvec {x}},y) unbekannt. Aus diesem Grund wird ein Fortbildungsangebot von n Memedisplaystyle n} unabhängig und identisch verteilte Stichprobenpunkte S = { ( x → 1 , y 1 ) , ... ( x → n , y n ) } verwendet. KINGstyle S=\{ x{_{1},y_{1}),\dots ,{(\vec x}}_{n},y_{n)\ aus dem Datenstichfeld gezogen, ein Versuch, das empirische Risiko I S [ f] = 1 n  i i = 1 n V ( x → i) , y i) zu minimieren KINGstyle I_{S}[f]=Portfrac 1 1n _sum _i=1}^{n}V(f(Fii}),y_{i als Ersatz für erwartete Risiken. (Siehe statistische Lerntheorie für eine ausführlichere Beschreibung). Bayes Konsistenz Utilizing Bayes' theorem zeigt, dass die optimale F 0 / 1 {\ WELLstyle f_{0/1^*} , d. h. das, das mit dem Nullverlust verbundene Risiko minimiert, die Buchten optimal für ein binäres Einstufungsproblem umsetzen und in Form von F 0 / 1 ∗· → ) = { 1   x → ) ·  1 ( − 1 ∣ x → ) 0, wenn p ( 1 ∣ x → ) = p ( − 1 ∣ x → ) − 1, wenn p ( 1 → x → ) < p ( − 1 ∣ x → ) KINGstyle f_{0/1**}(Getvec x}})\;=\; cubegin{cases}\;\;\;1 & Logtext{if }p(1\mid Memevec {x}})}p(-1\mid 7.8vec x}})\\\;\;\;0 & Logtext{if }p(1\mid {x}})=p(-1\mid } Verlustfunktion wird gesagt, dass es sich um ein Klassifizierungssystem oder eine Buchtenkonsistent handelt, wenn ihr optimaler f_ {\ {\ {\ * so ist, dass f 0 / 1 ∗ ( x → ) = sgn ⁡ ( fφ ∗ → → → → → → → → → → → → → → → → → → ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) KINGstyle f_{0/1**}(Getvec {x}})=\operatorname {sgn} (f_ggiophi (* (*vec {x)} und ist somit optimal unter der Entscheidungsregel der Buchten. Eine in sich schlüssige Verlustfunktion ermöglicht es uns, die Bayes optimale Entscheidungsfunktion f {\ {\ WELLdisplaystyle f_ cuphi *** zu finden, indem wir das erwartete Risiko direkt minimieren und die Wahrscheinlichkeitsdichte nicht ausdrücklich modellieren müssen. ve     (  ) Memedisplaystyle \phi (\upsilon ) , kann nachgewiesen werden, dass . (υ ) \phi (\upsilon ) \phi (\upsilon ) } in der Bucht übereinstimmend ist, wenn und nur, wenn es auf 0 und . ′ ( 0 ) = 0 KING \phi=0} Yet, das Ergebnis schließt nicht das Bestehen von nicht-konsistenten Funktionen der Bucht aus. Ein allgemeineres Ergebnis ist, dass Bayes einheitliche Verlustfunktionen unter Verwendung der folgenden Formel  be ( v ) = C [ f − 1 ( v ) ] + ( 1 − 1 ( v ) ) ) C ́ [ f − 1 ( v ) ] ( 2 ) \phi v)=C[f-1-1}(v) }(v) }[f-1-1}(v)][fv-1}(v) }(v)  0-1,\, \, \ ist jede unvertible Funktion, die f − 1 ( − v ) = 1 − f − 1 ( v ) displaystyle f}-1}(v)=1-f-1-1}(v und C (   ) Memestyle C(\eta )} ist eine unterschiedliche, strikte Vermittlungsfunktion wie C ( ) ) = C ( 1 η )  C c(\ ) \ \ C) C C1 ^{  C  C  C  C  C  C  C1  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C -1  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C  C Solche nicht-konvex-Verlustfunktionen haben gezeigt, dass sie für den Umgang mit Ausbrüchen in der Klassifizierung nützlich sind. Bei allen Verlustfunktionen, die aus (2) hergestellt werden, kann die Posterior-wahrscheinlichkeit p ( y = 1 ... x → ) displaystyle p(y=1 · {x{\)} unter Verwendung der unvertierbaren Verbindungsfunktion als p ( y = 1 [ x → ]) = f  1 = f  = 1 ( v ) faserdisplaystyle p(y=1 · {x}}) {x-1)= .Diese Verlustfunktionen, bei denen die Wahrscheinlichkeit von Posterior durch den unvertiblen Link wiedereingezogen werden kann, werden als geeignete Verlustfunktionen bezeichnet. Einziger Minimierung des erwarteten Risikos, f   HANAdisplaystyle f_customphi ** , verbunden mit den oben genannten Verlustfunktionen, kann direkt aus der Formel (1) gefunden werden und zeigen, dass er dem entsprechenden f (η ) faserstilstyle f(\eta ) } entspricht. Dies gilt auch für die nichtkonvexen Verlustfunktionen, was bedeutet, dass ziehungsbasierte Algorithmen wie die Steigung des Bewegungsapparates verwendet werden können. Leistungsfähige Verlustfunktionen, Verlustmarge und Regularisierung Für ordnungsgemäße Verlustfunktionen kann die Verlustmarge als μ φ = φ ′ ( 0 )   ′′ ( 0 ) Memedisplaystyle \mu ggio_phi }-= cufrac ggiophi '(0) ' '(0)} phi} definiert werden und zeigen, dass sie direkt mit den Regularisierungseigenschaften des Klassenempfängers in Zusammenhang stehen. Konkret erhöht eine Verlustfunktion größerer Margen die Regularisierung und produziert bessere Schätzungen der Posterior Wahrscheinlichkeit. Zum Beispiel kann die Verlustmarge für den logistischen Verlust erhöht werden, indem ein γ \gamma } Parameter eingeführt und den logistischen Verlust als 1  be Log  be ( 1 + e −   v ) 7.8displaystyle Memefrac 1 1gamma }log(1+e^{-\gamma v)} angegeben wird, wo kleiner 0 <  1  1  0 amma ammagamma 11} erhöht den Schaden. Es wird gezeigt, dass dies direkt dem Rückgang der Lernrate in der Steigung F m ( x ) = F m − 1 ( x ) +  h h m ( x ) , Memestyle F_{m}(x)=F_{m-1}(x)+\gamma h_{m}(x), wo abnehmender   KINGstyle \gamma \gamma } die Regularisierung der gesteigerten Klasse verbessert. Die Theorie macht deutlich, dass die richtige Formel für die Rückführung der Posteriorwahrscheinlichkeit jetzt  = = f  1 F ( x ) ) . {\ \eta = feta-1} (\gamma F(x)} . Indem wir eine Verlustfunktion mit größerer Marge (kleiner   KINGstyle \gamma }) wählen, erhöhen wir die Regularisierung und verbessern unsere Schätzungen der posterioren Wahrscheinlichkeit, die wiederum die ROC-Kurve des Final Classifiers verbessert. Bewegungsverlust Mehr häufig in der Regression verwendet werden kann die Quadratverlustfunktion als Funktion . ( y f ( x → ) ) Memedisplaystyle \phi yf( cuvec {x)} und für die Einstufung verwendet werden. Sie kann unter Verwendung von (2) und Tabelle-I wie folgt ) ( v ) = C [ f  - 1 ( v ) ] + ( 1 − 1 ( v ) ) C ′ [ f − 1 ( v ) ] = 4 ( 1 2 ( v + 1 ) ) ) ( 1 − 1 2 ( v + 1 ) ) ) + ( 1  - 1 ) ) ) ) ) + ( 1  - 1 2 ( v + 1 ) 2 . 7.8displaystyle \phi v)=C[f-1-1}(v)]+(1-f-1-1}(v)C[f-1-1}(v)]=4(v) Fifrac 1 12v(v+1)))(1-Spafrac 1 12v(v+1))+(v)))+(1-Spafrac 1}{2v(v+1)(v))(4-8f1 12 1(v) 1)((v)()((v)))=v)2. Jedoch ist die Quadratverlustfunktion tendenziell zu benachteiligen und führt zu langsameren Konvergenzraten (im Hinblick auf die Probe Komplexität) als bei den logistischen Verlust- oder Absturzfunktionen. Funktionen, die hohe Werte f ( x → ) Memestyle f(Spavec {x)} für einige x ) X KINGstyle x\in X} wird in schlechtem Maße mit der Quadratverlustfunktion arbeiten, da hohe Werte von y f ( x → ) Memestyle yf (Spavec {x)} stark bestraft werden, unabhängig davon, ob die Zeichen von y KINGstyle y} und f ( x → ) KINGstyle f( {x)}. Nutzen der Quadratverlust-Funktion ist, dass sich ihre Struktur für eine einfache grenzübergreifende Validierung von Regularisierungsparametern einsetzt. Konkret für Tikhonov Regularisierung kann eine Lösung für den Normalisierungsparameter unter Verwendung einer einmaligen Cross-validierung in derselben Zeit wie die Lösung eines einzigen Problems sein. I [ f ] {\displaystyle I[f}] für die Quadratmeterverlustfunktion kann direkt aus der Formel (1) als F Square ∗ = 2  = − 1 = 2 p ( 1 ∣ x ) − 1. Memedisplaystyle f_ggiotextSquare**} -1=2p(1\mid x)-1}. Logistische Verluste Die logistische Verlustfunktion kann unter Verwendung von (2) und Tabelle-I wie folgt I ( v ) = C [ f  - 1 ( v) ] + ( 1 − 1 ( v ) ) C ́ [ f ) ] = 1 Log ) ( 2 ) [ − e v 1 + e v log  e e v 1 + e v  – ( 1 − e v 1 + e v ) Log ) ( 1 − e v 1 + e v ) ] + ( 1 − )e v 1 + e v ) [ − 1 Log . ( 2 ) Log . (e v 1 + e v 1 − e v 1 + e v ) ] = 1 Log . ( 2 ) Log . ( 1 + e − v ) . 7.8displaystyle beginnt {aligned}\phi v) &=C[f-1-1}(v)]+\left(1-f-1-1}(v)\right,C'\left[f-1-1}(v)\right] 1+{\=de -evv11+evv log HANAfrac e^{v11+evv(-\left(1-9)frac evv11+evv)right.\log links(1-9)frac evv11+evv)right)\right]+\left(1-Spafracfrac) evv11+evv)right.\left[8]frac -1}{\log(2)(log links(Badenfrac faserfrac) evv11+evv1-1-Granfrac evv11+evv}}}}}\right)\right]\\ &= Haushaltsfrac 1 1log(2)(2)log(1+e^{-v}.\end Der logistische Verlust ist konvex und wächst linear für negative Werte, die es weniger empfindlich machen. Der logistische Verlust wird im LogitBoost-Algorithmus verwendet. I [ f ] dampfdisplaystyle I[f}] für die logistische Verlustfunktion kann direkt aus der Formel (1) als f Logistic ∗ = Log  1 (  1 1 η   ) = Log ⁡ ( p ( 1 ∣ x ) 1 − p ( 1 ∣ x ) 1 . x ) . . Memestyle f_ {Logistic**}=\log linksfrac  fieta }  11\f) Diese Funktion ist nicht definiert, wenn p ( 1 ∣ x ) = 1 {\displaystyle p(1\mid x)=1} oder p ( 1 ) x ) = 0 {\displaystyle p(1\mid x)=0} (bis hin zu . und ),), sondern eine reibungslose Kurve, die wächst, wenn P ( 1 ∣ x ) ) Glühbirne p(1\mid x)} erhöht und 0, wenn p( 1 x  1 x) x  = = 0,5 ).) ).  2  2  2  2  2  2 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 Der Cross-entropy-Verlust ist eng mit dem Kullback-Leibler Divergenzen zwischen der empirischen Verteilung und der vorhergesagten Verteilung verbunden. Der Cross-entropy-Verlust ist in modernen tiefen Neuralnetzen allgegenwärtig. Exponeller Verlust Die exponentielle Verlustfunktion kann unter Verwendung von (2) und Tabelle-I wie folgt ) ( v ) = C [ f  - 1 ( v ) ] + ( 1 − 1 ( v ) ) C  [ [ f − 1 ( v ) ] = 2 ( e 2 v 1 + e 2 v ) ( 1 − 1 + 2 v ) + 2 v } } + 2 v) + ( 1 − 2 v 2 v)  1 2  2 2  2 1  2 1 v  2 2  2 1  2 1  2 2  1 1 v  2 2  2 1  2 1 v  1 1 v  2 2  2 1 v  2 1  2 1  2 2  2 1  2 2  2 2  2 2  2 1 v [ 1 v  2 1 v  1 2 C 2  2 1 v C 2  2 2  1 2  2 1 v  2 2  2 1  2 2 C 1  2 2  2 2 C 2  2 2  2 2  2 2  2 2  2 2  1 e22v11+e^{2v)+(1-Getfrac e^{2v11+e^{2v)1+e(2v)1+e^{2v11+e22v11+e 2v sqrt 7.8frac e^{2v11+e^{2v1 e22v11+e^{2v))= Der exponentielle Verlust ist konvex und wächst exponentiell auf negative Werte, die es empfindlicher machen. Der exponentielle Verlust wird im AdaBoost-Algorithmus verwendet. I [ f ] WELLdisplaystyle I[f}] für die exponentielle Verlustfunktion kann direkt aus der Formel (1) als F . = 1 2 Log . ( 1 1 −   ) = 1 2 Log . ( p ( 1 ∣ x ) 1  - p ( 1 ∣ x ) ) . KINGstyle f_7.8text{Exp**}=1,0frac 1 12(log links(1,0frac 574 {}1-\eta })= Fifrac 1 12(log links(1,0frac {p(1\mid x)}{1-p(1\mid x)}}\right. Haarausfall Der Haarausfall kann unter Verwendung von (2) und Tabelle-I wie folgt erzeugt werden: ) ( v ) = C [ f  - 1 ( v ) ] + ( 1 − 1 ( v ) ) C ′ [ f − 1 ( v ) ] = ( e v 1 + e v ) ( 1 − 1 + e v ) + e v ) + ( 1  = 1 } e v) } ( 1 − 2 e v 1 ) e v)  1 1  1 1  1 1  1 1  1 1  1 1  2 1  2 1 C 1 C 1 C 1 C 1 C C C C C 1 C 1 C 1 C C 1 C C C C C C C C C C C C C C C C C C C C C C C C C C C C C C C  2 C C C C C C C C evv11+evv}}})+(1-Getfrac) evv11+evv}}})(1-Getfrac 2e1v11+e1v 1)= Fifrac 1((1+e^{v}) The2. Der Haarausfall ist Quasi-convex und ist für große negative Werte gebunden, die es weniger empfindlich gegenüber Verlierern macht. Der verlorene Verlust wurde in einer Steigung und dem "Horwegen" verwendet. I [ f ] WELLdisplaystyle I[f}] für die verlorene Funktion kann direkt aus der Formel (1) als fetta ∗ = Log  1 (  1 1 η ) = Log . ( p ( 1 ∣ x ) 1 − p ( 1 ∣ x ) 1 . x ) . . . . . . {\ {\ {\ * * }=\log linksfrac * {\ {\ } }1 } Sachlicher Verlust Der greifbare Verlust kann unter Verwendung von (2) und Tabelle-I wie folgt ) ( v ) = C [ f  - 1 ( v ) ] + ( 1 − 1 ( v) ) C  [ [ ]  1 1 ( v ) ] = 4 (v)  2 2 ) ) (v) } 1 } ( }  2 2 } )  1 1  1 1  v (v)  v 1  v 2 ) 1 )  2 1  8  8  v 1  v 2  8  8  8 {\  8 2  8  8  8  8  8  8  8  8  8  8 2  8  8  8  8  8  8  8  8  8  8  8  8  8  8 Der greifbare Verlust ist Quasi-Konvex und ist für große negative Werte gebunden, die es weniger empfindlich machen. Interessanterweise erhält der greifbare Verlust auch eine gebundene Sanktion an Daten, die „zu korrekt“ eingestuft wurden. Dies kann dazu beitragen, eine übermäßige Schulung der Daten zu verhindern. Der greifbare Verlust wurde bei einer Steigung, dem GreiferBoost-Algorithmus und dem Altern der Wälder verwendet. I [ f ] WELLdisplaystyle I[f}] für die greifbare Verlustfunktion kann direkt aus der Formel (1) als f g. g.  = (  1 1 2 ) = Tan  1 ( p ( 1 ∣ x ) − 1 2 ) . . 7.8displaystyle f_customtextT*}=\tan(\t {-\frac 12}})=\tan(p)\tan(p) x 1 \f)f \f)f  1 2 ) .} Hingeverlust Die Gesichtsverlustfunktion ist mit ) (υ ) = max ( 0 , 1 − ) ) = [ 1 ] + Memestyle \phi (\upsilon )=max(0,1-\upsilon )[=1-\upsilon ]_{+] , wo [ a ] + = max ( 0 , a ) JPYstyle [a]_{+}=\max(0,a) ist die positive Rolle. V ( x → ) , y ) = max ( 0 , 1 − y f ( x → ) ) = [ 1 − y f ( x → ) ] + . 7.8displaystyle V(f(Fieber)),y)=\max(0,1-yf(ggiovec x}})))=[1-yf(Spavec x}+ Ein relativ straffer, konvexer oberen Teil der Indikatorfunktion 0–1. Konkret entspricht der Ausfall der Kapsel 0–1 der Indikatorfunktion, wenn sgn  f ( f ( x ) ) = y {\displaystyle \operator {sgn} f( cuvec {x}})))=y und # y f ( x → ) 1} . Darüber hinaus entspricht die empirische Risikominimierung dieses Verlustes der klassischen Formel für die Unterstützung von Vektormaschinen (SVM). Korrekte Punkte, die außerhalb der Margengrenzen der Fördervektoren liegen, werden nicht bestraft, während Punkte innerhalb der Margen oder auf der falschen Seite des Hyperflugzeugs linear im Vergleich zu ihrer Entfernung von der korrekten Grenze bestraft werden. Obwohl die Gesichtsverlustfunktion sowohl konvex als auch kontinuierlich ist, ist es nicht glatt (nicht anders) auf y f ( x → ) = 1 Kaffeestyle yf (Getvec {x}})=1 . Infolgedessen kann die Ableitungsfunktion nicht mit den Methoden zur Absterben oder mit blutigen Abrissmethoden verwendet werden, die auf unterschiedlichen Bedingungen im gesamten Bereich basieren. Jedoch gibt es bei y f ( x → ) eine Unterlage = 1 {\displaystyle yf (Spavec {x}})=1 , was die Verwendung von Sub-Rückgangmethoden erlaubt. SVMs, die die Basisverlustfunktion verwenden, können auch mit quadratischen Programmierung gelöst werden. I [ f ] WELLdisplaystyle I[f}] für die Absturzfunktion ist f Hinge ∗ ( x → ) = { 1 ) x → ) · ) ( − 1 ∣ x → ) − 1, wenn p ( 1 → x → ) < p ( − 1 ∣ x → ) 7.8displaydisplaystyle f_TONtext{Hinge}}^{*}(Getvec x}})\;=\; cubegin{cases}19.5text{if }p(1\mid  cuvec {x}})][x))][p(-1\mid 7.8vec x}})\\-1,2 \c }p(1\mid {x}}) {p-1\mid }p-1\mid occ x when)\Ende (p(p) x 1 .  which  which {\, {\ Diese Schlussfolgerung macht den Absturz recht attraktiv, da die Bindungen auf den Unterschied zwischen dem erwarteten Risiko und dem Zeichen der Absturzfunktion gelegt werden können. Der Hinge-Verlust kann nicht von (2) abgeleitet werden, da F Hinge ∗ KINGstyle f_customtextHinge^*} nicht invertierbar ist. Konstruktives, reibungsloses Abfangen Die allgemeine Funktion des glatten Absturzes mit Parameter   Memestyle \alpha } ist definiert als f ) ) ( z ) = { + + 1 − z wenn z ≤ 0 1 α + 1 z ) + 1 − z +    1 + 1, wenn 0  1  1 1 0, wenn z ≥ 1 , {\displaystyle f_ggioalpha (^*z)\;=\; budgetbegin{cases}{\fracggioalpha {\}alpha )alpha +1z-z & Logtext{if }z\leq 0\\{\frac 1}{\alpha +1}}zphaalpha 1}-z+ggiofrac ggioalpha {\}alpha +1& & Logtext }0 11&09.5text{if }z\geq 1\end{cases,} wo z = y f ( x → ) . KINGstyle z=yf(ggiovec {x)}. Es ist ein monotonischer Anstieg und erreicht 0 wann z = 1 Memedisplaystyle z=1}. Siehe auch die unterschiedliche Programmierung () Links