Datenvergrößerung in der Datenanalyse sind Techniken, mit denen die Datenmenge erhöht wird, indem man leicht veränderte Kopien bereits bestehender Daten oder neu erstellte synthetische Daten aus vorhandenen Daten hinzufügt. Es fungiert als Regularizer und hilft bei der Ausbildung eines Maschinenlernmodells die Überarbeitung zu reduzieren. Es ist eng mit der Übersampling in der Datenanalyse verbunden. Synthetische Oversampling-Techniken für traditionelles maschinelles Lernen Datenaugmentation für Bildklassifikation Transformationen von Bildern Geometrische Transformationen, Flipping, Farbmodifikation, Ernten, Rotation, Lärminjektion und zufälliges Löschen werden verwendet, um Bild im tiefen Lernen zu erweitern. Einführung neuer synthetischer Bilder Wenn die Frage der Datenknappheit konfrontiert ist, können die einfachen und dennoch effektiven Techniken wie Transformationen eine begrenzte Lösung darstellen. Ist ein Datensatz zu klein, so kann ein transformiertes Bild über Rotation und Spiegelung etc. für ein bestimmtes Problem noch zu klein sein. Eine weitere Lösung ist die Beschaffung von völlig neuen und synthetischen Bildern durch verschiedene Techniken, zum Beispiel die Verwendung von Generativen adversarialen Netzwerken, um neue synthetische Bilder für die Datenvergrößerung zu erstellen. Darüber hinaus zeigen Bilderkennungsalgorithmen eine Verbesserung bei der Übertragung von synthetischen Bildern, die von der Unity Game Engine erzeugt werden, d.h., um das Lernen von realen Weltdaten zu verbessern, indem der Trainingsprozess mit Rendered-Bildern aus virtuellen Umgebungen erweitert wird. Datenaugmentation für die Signalverarbeitung Biologische Signale Synthetische Datenaugmentation ist von größter Bedeutung für die Klassifizierung des maschinellen Lernens, insbesondere für biologische Daten, die tendenziell hochdimensional und knapp sind. Die Anwendungen der Robotersteuerung und Augmentation in behinderten und leistungsfähigen Subjekten setzen sich immer noch vor allem auf fachspezifische Analysen. Datenknappheit ist bei Signalverarbeitungsproblemen, wie z.B. bei Parkinson's Disease Electromyography Signals, die schwer zu quellen sind - Zanini, et al.noted, dass es möglich ist, ein Generatives adversariales Netzwerk (insbesondere ein DCGAN) zur Stilübertragung zu verwenden, um synthetische elektromyographische Signale zu erzeugen, die denen von Parkinsons Krankheit entsprechen. Die Ansätze sind auch bei der Elektroenzephalographie (Hirnwellen) wichtig. Wang, et al. erforschte die Idee der Verwendung von Deep Convolutional Neural Networks für EEG-basierte Emotion Recognition, Ergebnisse zeigen, dass die Emotionserkennung verbessert wurde, wenn Daten Augmentation verwendet wurde. Es wurde auch festgestellt, dass das GPT-2-Modell von OpenAI in der Lage ist, aus synthetischen biologischen Signalen wie EEG und EMG zu lernen und zu generieren. In dieser Studie wurde festgestellt, dass die Erkennung durch Datenvergrößerung verbessert wurde. Es wurde auch darauf hingewiesen, dass auf der synthetischen Domäne ausgebildete statistische maschinelle Lernmodelle die menschlichen Daten klassifizieren und umgekehrt. Im Bild wird ein Vergleich durch einige Beispiele von EEG gegeben, die vom GPT-2 Modell und einem menschlichen Gehirn produziert werden. Ein gemeinsamer Ansatz ist die Erzeugung von synthetischen Signalen durch Neuanordnung von Komponenten realer Daten. Lotte hat eine Methode der "Artificial Trial Generation Based on Analogy" vorgeschlagen, bei der drei Datenbeispiele x 1 , x 2 , x 3 {\displaystyle x_{1},x_{2},x_{3 Beispiele und eine künstliche x s y n t i\c\displaystyle x_{synthetic} bilden, die x 3\displaystyle x_{3}h e t i c {\displaystyle x_{synthetic} Dieser Ansatz wurde gezeigt, um die Leistung eines Linear Diskriminant Analysis Klassifikators auf drei verschiedenen Datensätzen zu verbessern. Aktuelle Forschung zeigt große Auswirkungen können aus relativ einfachen Techniken abgeleitet werden. Zum Beispiel Freer beobachtete, dass die Einführung von Rauschen in gesammelte Daten zu zusätzlichen Datenpunkten die Lernfähigkeit mehrerer Modelle, die sonst relativ schlecht durchgeführt. Tsinganos et al.studierte die Ansätze der Größe Warping, Wavelet Zersetzung und synthetische Oberflächen-EMG-Modelle (generative Ansätze) für die Handgestenerkennung, finden Klassifizierungsleistung steigt von bis zu +16%, wenn erweiterte Daten während des Trainings eingeführt wurden. In jüngster Zeit haben die Studien zur Datenvergrößerung begonnen, sich auf den Bereich des tiefen Lernens zu konzentrieren, insbesondere auf die Fähigkeit generativer Modelle, künstliche Daten zu erstellen, die dann während des Klassifikationsmodell-Trainingsprozesses eingeführt werden. 2018, Luo et al. beobachtet, dass nützliche EEG-Signaldaten von Conditional Wasserstein Generative Adversarial Networks (GANs) generiert werden konnten, die dann in einem klassischen Train-Test-Learning-Frame in das Trainingsset eingeführt wurden. Bei der Einführung solcher Techniken wurde die Klassifizierungsleistung der Autoren verbessert. Datenvergrößerung zur Spracherkennung Es wurde darauf hingewiesen, dass die synthetische Datenerzeugung von gesprochenen MFCCs die Erkennung eines Lautsprechers aus ihren Äußerungen durch Transfer-Erlernen von synthetischen Daten verbessern kann, die über ein Character-level Recurrent Neural Network (RNN) generiert wurden. Siehe auch Übersampling und Untersampling in der Datenanalyse Generatives adversariales Netzwerk Variational autoencoder Datenvorverarbeitung Convolutional neuronal network Regularization (mathematics)Data Preparation Data fusion == Referenzen ==