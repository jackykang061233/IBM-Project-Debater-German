Die mathematische Optimierung (alternativ buchstabierte Optimierung) oder die mathematische Programmierung ist die Auswahl eines besten Elements im Hinblick auf ein bestimmtes Kriterium aus einigen verfügbaren Alternativen. Optimierungsprobleme von Sorten entstehen in allen quantitativen Disziplinen von Informatik und Ingenieurwesen bis hin zu Betriebsforschung und Ökonomie, und die Entwicklung von Lösungsmethoden ist seit Jahrhunderten von Interesse an Mathematik. Im einfachsten Fall besteht ein Optimierungsproblem darin, eine reale Funktion zu maximieren oder zu minimieren, indem Eingabewerte innerhalb eines erlaubten Satzes systematisch ausgewählt und der Wert der Funktion berechnet werden. Die Verallgemeinerung der Optimierungstheorie und Techniken auf andere Formulierungen stellt eine große Fläche der angewandten Mathematik dar. Im Allgemeinen umfasst die Optimierung die Suche nach "besten verfügbaren" Werten irgendeiner objektiven Funktion bei einer definierten Domäne (oder Eingabe), einschließlich einer Vielzahl von verschiedenen Arten von objektiven Funktionen und verschiedenen Arten von Domänen. Optimierungsprobleme Ein Optimierungsproblem kann auf folgende Weise dargestellt werden: A → R von einem Satz A zu den realen Zahlen Sought: ein Element x0 εA derart, dass f(x0) ≤ f(x) für alle x ε A (Minimierung) oder so, dass f(x0) ≥ f(x) für alle x ε A (Maximierung)). Eine solche Formulierung nennt man ein Optimierungsproblem oder ein mathematisches Programmierproblem (ein Begriff, der nicht direkt mit der Computerprogrammierung in Verbindung steht, sondern noch zum Beispiel in der linearen Programmierung verwendet wird – siehe Geschichte unten). Viele reale und theoretische Probleme können in diesem allgemeinen Rahmen modelliert werden. Da folgendes gültig ist f ( x 0 ) ≥ f ( x ) ‰ f ~ ( x 0 ) ≤ f ~ ( x ) {\displaystyle f\left(\mathbf {x} {_0}\right)\geq f\left(\mathbf {x} rechts)\ Linkrightarrow {\tilde {f}\left(\mathbf {x} {_0}\right)\leq {\tilde {f}\left(\mathbf {x}\right}) mit f ~ (x) :=========================================================================================================== A\rightarrow \mathbb {R} Es ist bequemer, Minimierungsprobleme zu lösen. Die entgegengesetzte Perspektive wäre jedoch auch gültig. Probleme, die mit dieser Technik in den Bereichen der Physik formuliert werden, können sich auf die Technik als Energieminimierung beziehen, wobei der Wert der Funktion f als die Energie des zu modellierenden Systems dargestellt wird. Beim maschinellen Lernen ist es immer erforderlich, die Qualität eines Datenmodells durch eine Kostenfunktion kontinuierlich zu bewerten, bei der ein Minimum einen Satz von möglicherweise optimalen Parametern mit einem optimalen (niedrigsten) Fehler impliziert. Typischerweise ist A eine Teilmenge des Euclideanischen Raumes Rn, oft durch eine Reihe von Zwängen, Gleichheiten oder Ungleichheiten festgelegt, die die Mitglieder von A zu erfüllen haben. Die Domain A von f wird als Suchraum oder Wahlsatz bezeichnet, während die Elemente von A als Kandidatenlösungen oder durchführbare Lösungen bezeichnet werden. Die Funktion f wird verschiedentlich eine objektive Funktion, eine Verlustfunktion oder Kostenfunktion (Minimierung,) eine Dienstfunktion oder Fitnessfunktion (Maximierung,) oder in bestimmten Bereichen eine Energiefunktion oder Energiefunktion genannt. Eine machbare Lösung, die (oder maximiert, wenn das das Ziel ist) die Zielfunktion als eine optimale Lösung bezeichnet. In der Mathematik werden herkömmliche Optimierungsprobleme in der Regel im Hinblick auf die Minimierung angegeben. Ein lokales Minimum x* ist definiert als ein Element, für das es einige δ > 0 so, dassx ε A, in dem x - x χ χ ≤ δ δ, {\displaystyle \forall \mathbf {x} inA\;{\text{where}\;\left\ Vert \mathbf {x) - Ja. - Ja. Vert \leq \delta ,\,} der Ausdruck f(x*) ≤ f(x) hält; d.h. in einem Bereich um x* sind alle Funktionswerte größer oder gleich dem Wert an diesem Element. Lokale Maxima sind ähnlich definiert. Während ein lokales Minimum mindestens so gut ist wie alle naheliegenden Elemente, ein globales Minimum ist mindestens so gut wie jedes mögliche Element. In der Regel, wenn die Zielfunktion in einem Minimierungsproblem konvex ist, kann es mehrere lokale Minima geben. In einem konvexen Problem, wenn es ein lokales Minimum, das innen ist (nicht am Rand des Satzes der machbaren Elemente,) ist es auch das globale Minimum, aber ein nonconvex Problem kann mehr als ein lokales Minimum, nicht alle müssen globale Minima. Eine große Anzahl von Algorithmen, die zur Lösung der nichtkonvexen Probleme vorgeschlagen werden – einschließlich der Mehrheit der kommerziell erhältlichen Soldaten – sind nicht in der Lage, eine Unterscheidung zwischen lokal optimalen Lösungen und global optimalen Lösungen zu machen, und behandelt sie als tatsächliche Lösungen für das ursprüngliche Problem. Globale Optimierung ist der Zweig der angewandten Mathematik und numerische Analyse, die sich mit der Entwicklung von deterministischen Algorithmen beschäftigt, die in der Lage sind, Konvergenz in endlicher Zeit zu der tatsächlichen optimalen Lösung eines Nonconvex-Problems zu garantieren. Notation Optimierungsprobleme werden oft mit besonderer Notation ausgedrückt. Hier einige Beispiele: Mindest- und Maximalwert einer Funktion Berücksichtigen Sie die folgende Notation: min x ε R ( x 2 + 1 ) {\displaystyle \min {_x\in \mathbb ;links (x^{2}+1\right) Dies bezeichnet den Minimalwert der Objektivfunktion x2 +1, wenn x aus dem Satz der Realzahlen R gewählt wird. Der Minimalwert ist dabei 1 bei x = 0. Gleichfalls fragt die Notation max x ε R 2 x {\displaystyle \max {_x\in \mathbb {R};\2x nach dem Maximalwert der Objektivfunktion 2x, wobei x jede reale Zahl sein kann. In diesem Fall gibt es kein solches Maximum, da die Zielfunktion unbelastet ist, so dass die Antwort Unendlichkeit oder undefiniert ist. Optimale Eingabeargumente Betrachten Sie die folgende Notation: a r g m i n x ε ( − ∞, − 1 ] x 2 + 1 , {\displaystyle {\underset {x\in -(\infty -,1]}{\operatorname {arg\,min};\x^{2}+1 oder äquivalent a r g m i n x 2 + 1 , vorbehaltlich: x ∈ - {\displaystyle {\underset x}{\operatorname {arg\,min} x^{2}+1,\;{\text{subject to:}\;x\in -(\infty -,1}] Dies stellt den Wert (oder die Werte) des Arguments x im Intervall (-∞,-1] dar, der die Objektivfunktion x2 + 1 minimiert (der tatsächliche Minimalwert dieser Funktion ist nicht das, was das Problem verlangt). In diesem Fall ist die Antwort x = -1, da x = 0 undurchführbar ist, d.h. sie gehört nicht zum machbaren Satz.- 5 ε, 5 , 5 , y ε R x cos Dabei handelt es sich bei den Lösungen um die Paare der Form {5, 2kπ} und {-5, (2k + 1)π}, wobei k über alle ganze Zahlen reicht. Operatoren arg min und arg max werden manchmal auch als argmin und argmax geschrieben, und stehen für Argument des Minimums und Argument des Maximums. Geschichte Fermat und Lagrange fanden rechnergestützte Formeln für die Identifizierung von optima, während Newton und Gauss iterative Methoden für den Übergang zu einem Optimum vorgeschlagen. Der Begriff "lineare Programmierung" für bestimmte Optimierungsfälle war auf George B. Dantzig zurückzuführen, obwohl ein Großteil der Theorie von Leonid Kantorovich im Jahr 1939 eingeführt worden war.(Programmierung in diesem Zusammenhang bezieht sich nicht auf die Computerprogrammierung, sondern kommt von der Nutzung von Programm durch das US-Militär auf vorgeschlagene Trainings- und Logistikpläne, die die Probleme waren, die Dantzig damals untersuchte) Dantzig veröffentlichte 1947 den Simplex-Algorithmus, und John von Neumann entwickelte die Theorie der Dualität im gleichen Jahr. Andere bemerkenswerte Forscher in der mathematischen Optimierung umfassen: Hauptunterfelder Convex-Programmierung untersucht den Fall, wenn die objektive Funktion konvex (Minimierung) oder konkav (Maximierung) ist und das constraint-Set konvex ist. Dies kann als ein besonderer Fall der nichtlinearen Programmierung oder als Verallgemeinerung der linearen oder konvexen quadratischen Programmierung betrachtet werden. Lineare Programmierung (LP,) eine Art konvexe Programmierung, untersucht den Fall, dass die Zielfunktion f linear ist und die Zwänge mit nur linearen Gleichheiten und Ungleichheiten angegeben werden. Ein solcher Strengesatz wird als Polyeder oder Polytop bezeichnet, wenn er gebunden ist. Die Zweitbestellungskonus-Programmierung (SOCP) ist ein konvexes Programm und umfasst bestimmte Arten von quadratischen Programmen. Semidefinite Programmierung (SDP) ist ein Unterfeld der konvexen Optimierung, bei dem die zugrunde liegenden Variablen Halbdefinitmatrizen sind. Es ist eine Verallgemeinerung der linearen und konvexen quadratischen Programmierung. Konische Programmierung ist eine allgemeine Form der konvexen Programmierung. LP, SOCP und SDP können alle als konische Programme mit der entsprechenden Art von Kegel angesehen werden. Geometrische Programmierung ist eine Technik, bei der objektive und ungerechtfertigte Zwänge, die als Posynomials und Chancengleichheitszwänge ausgedrückt werden, als Monomials in ein konvexes Programm umgewandelt werden können. Integer-Programmierung Studien lineare Programme, in denen einige oder alle Variablen eingeschränkt sind, um ganze Werte zu übernehmen. Dies ist nicht konvex, und im Allgemeinen viel schwieriger als regelmäßige lineare Programmierung. Quadratische Programmierung ermöglicht es der Zielfunktion, quadratische Begriffe zu haben, während der machbare Satz mit linearen Gleichheiten und Ungleichheiten festgelegt werden muss. Für bestimmte Formen des quadratischen Begriffs handelt es sich um eine Art konvexer Programmierung. Fractional Programmierstudien Optimierung von Verhältnissen von zwei nichtlinearen Funktionen. Die spezielle Klasse der konkaven fraktionierten Programme kann zu einem konvexen Optimierungsproblem transformiert werden. Nichtlineare Programmierungsstudien der allgemeine Fall, bei dem die Zielfunktion oder die Zwänge oder beide nichtlineare Teile enthalten.Dies kann oder kann kein konvexes Programm sein. Im Allgemeinen, ob das Programm konvex ist, beeinflusst die Schwierigkeit, es zu lösen. Stochastic Programmierstudien der Fall, in dem einige der Zwänge oder Parameter von zufälligen Variablen abhängen. Eine robuste Optimierung ist, wie stochastische Programmierung, ein Versuch, Unsicherheit in den Daten zu erfassen, die dem Optimierungsproblem zugrunde liegen. Eine robuste Optimierung zielt darauf ab, Lösungen zu finden, die unter allen möglichen Erkenntnissen der Unsicherheiten, die durch einen Unsicherheitssatz definiert sind, gültig sind. Bei der Kombinationsoptimierung geht es um Probleme, bei denen der Satz von durchführbaren Lösungen diskret ist oder auf einen diskreten reduziert werden kann. Stochastic-Optimierung wird mit zufälligen (noisy) Funktionsmessungen oder zufälligen Eingaben im Suchprozess verwendet. Infinite-dimensionale Optimierungsstudien der Fall, wenn der Satz von durchführbaren Lösungen eine Untermenge eines unendlichen Raumes, wie einen Funktionsraum, ist. Heuristik und Metaheuristik machen nur wenige oder gar keine Annahmen über das zu optimierende Problem. Normalerweise garantieren Heuristiken nicht, dass eine optimale Lösung gefunden werden muss. Andererseits werden Heuristiken verwendet, um für viele komplizierte Optimierungsprobleme ungefähre Lösungen zu finden. Beschränken Sie die Zufriedenheitsstudien, wenn die objektive Funktion f konstant ist (dies wird in der künstlichen Intelligenz, insbesondere in der automatisierten Argumentation, verwendet). Die Constraint-Programmierung ist ein Programmierparadigma, in dem die Beziehungen zwischen Variablen in Form von Zwängen angegeben werden. Eine disjunktive Programmierung wird verwendet, wenn mindestens eine Grenze erfüllt sein muss, aber nicht alle. Es ist von besonderer Bedeutung bei der Planung. Die Raumkartierung ist ein Konzept zur Modellierung und Optimierung eines Engineering-Systems bis zur Hochsicherheit (Ende) Modellgenauigkeit, das ein geeignetes physikalisch sinnvolles Grob- oder Surrogatmodell ausnutzt. In einer Reihe von Unterfeldern sind die Techniken vor allem für die Optimierung in dynamischen Kontexten (d.h. Entscheidungsfindung über die Zeit:) Die Berechnung von Variationen versucht, ein Aktionsintegral über einen Raum zu einem Extremum zu optimieren, indem eine Funktion der Koordinaten variiert wird. Optimale Steuerungstheorie ist eine Verallgemeinerung des Kalküls von Variationen, die Kontrollpolitiken einführt. Dynamische Programmierung ist der Ansatz, das stochastische Optimierungsproblem mit stochastischen, zufälligen und unbekannten Modellparametern zu lösen. Es untersucht den Fall, dass die Optimierungsstrategie auf der Aufteilung des Problems in kleinere Teilprobleme basiert. Die Gleichung, die die Beziehung zwischen diesen Subproblemen beschreibt, wird als Bellman Gleichung bezeichnet. Die mathematische Programmierung mit Gleichgewichtszwängen ist, wo die Zwänge unterschiedliche Ungleichheiten oder Komplementaritäten beinhalten. Mehrobjektive Optimierung Das Hinzufügen von mehr als einem Ziel zu einem Optimierungsproblem fügt Komplexität hinzu. Um beispielsweise ein konstruktives Design zu optimieren, würde man ein Design wünschen, das sowohl leicht als auch starr ist. Wenn zwei Ziele widersprechen, muss ein Abhandeln geschaffen werden. Es kann ein leichtes Design, ein steifes Design und eine unendliche Anzahl von Designs, die einige Kompromisse von Gewicht und Steifigkeit sind. Der Satz von Abschlüssen, die sich auf ein Kriterium auf Kosten eines anderen verbessern, ist als Pareto-Set bekannt. Die erzeugte Kurve Plotgewicht gegen Steifigkeit der besten Designs ist als die Pareto Grenze bekannt. Ein Design wird als "Pareto optimal" beurteilt (entsprechend "Pareto effizient" oder im Pareto-Set), wenn es nicht von einem anderen Design dominiert wird: Ist es in irgendeiner Hinsicht schlechter als ein anderes Design und in keiner Hinsicht besser, dann wird es dominiert und ist nicht Pareto optimal. Die Wahl zwischen "Pareto optimalen" Lösungen zur Bestimmung der "favoriten Lösung" wird dem Entscheidungsträger übertragen. Mit anderen Worten, die Definition des Problems als multiobjektive Optimierungssignale, die einige Informationen fehlen: wünschenswerte Ziele werden gegeben, aber Kombinationen von ihnen werden nicht relativ zueinander bewertet. In einigen Fällen können die fehlenden Informationen durch interaktive Sitzungen mit dem Entscheidungsträger abgeleitet werden. Mehrobjektive Optimierungsprobleme wurden weiter zu Vektoroptimierungsproblemen verallgemeinert, bei denen die (Teil-)Bestellung durch die Pareto-Bestellung nicht mehr gegeben ist. Multimodale oder globale Optimierungsprobleme sind oft multimodal, d.h. sie besitzen mehrere gute Lösungen. Sie könnten alle global gut sein (gleicher Kostenfunktionswert) oder es könnte eine Mischung aus global guten und lokal guten Lösungen geben. Alle (oder zumindest einige) Lösungen zu erhalten, ist das Ziel eines multimodalen Optimierers.Klassische Optimierungstechniken aufgrund ihres iterativen Ansatzes führen nicht zufriedenstellend, wenn sie verwendet werden, um mehrere Lösungen zu erhalten, da es nicht gewährleistet ist, dass auch bei verschiedenen Startpunkten in mehreren Abläufen des Algorithmus unterschiedliche Lösungen erhalten werden. Häufige Ansätze zu globalen Optimierungsproblemen, bei denen mehrere lokale Extrema vorhanden sein können, sind evolutionäre Algorithmen, Bayesische Optimierung und simulierte Glühung. Klassifizierung kritischer Punkte und extrema Machbarkeitsproblem Das Problem der Befriedigung, auch das Problem der Machbarkeit genannt, ist nur das Problem, jede mögliche Lösung überhaupt zu finden, ohne den objektiven Wert zu berücksichtigen. Dies kann als Sonderfall der mathematischen Optimierung angesehen werden, bei der der Objektivwert für jede Lösung gleich ist und somit jede Lösung optimal ist. Viele Optimierungsalgorithmen müssen von einem möglichen Punkt beginnen. Eine Möglichkeit, einen solchen Punkt zu erhalten, ist, die Machbarkeitsbedingungen mit einer Schlupfvariable zu entspannen; mit genug Schlupf ist jeder Ausgangspunkt möglich. Dann minimieren Sie diese Slack-Variable, bis die Slack null oder negativ ist. Vorhanden Der Extremwert-Theorem von Karl Weierstrass gibt an, dass eine kontinuierliche reale Funktion auf einem kompakten Satz seinen maximalen und minimalen Wert erreicht. Im Allgemeinen erreicht eine untere halbkontinuierliche Funktion auf einem kompakten Satz sein Minimum; eine obere halbkontinuierliche Funktion auf einem kompakten Satz erreicht seinen maximalen Blick. Notwendige Bedingungen für die Optimität Einer der Theoreme von Fermat sagt, dass an stationären Stellen Opima von untrainierten Problemen gefunden werden, wo die erste Ableitung oder der Gradient der Objektivfunktion Null ist (siehe erste Ableitungsprüfung). In der Regel können sie an kritischen Punkten gefunden werden, wobei die erste Ableitung oder Steigung der Objektivfunktion Null oder undefiniert ist, oder an der Grenze der Wahlmenge. Eine Gleichung (oder Gleichungssatz), die besagt, dass die erste(n) Ableitung(en) gleich(en) Null bei einem inneren Optimum wird als "erste Ordnungsbedingung" oder als Satz von Erstbestellbedingungen bezeichnet. Optimale Gleichbehandlungsprobleme finden sich im Lagrange Multiplikator. Die Optima der Probleme mit Gleichheit und/oder Ungleichheitszwängen finden sich unter den "Karush-Kuhn-Tucker-Bedingungen". Für optimale Bedingungen Während der erste Derivattest Punkte identifiziert, die extrema sein könnten, unterscheidet dieser Test keinen Punkt, der ein Minimum von einem ist, der ein Maximum oder einer ist, der weder ist. Wenn die objektive Funktion zweimal differenzierbar ist, können diese Fälle dadurch unterschieden werden, dass das zweite Derivat oder die Matrix von zweiten Derivaten (die hessische Matrix genannt) in unkonstrainierten Problemen überprüft wird, oder die Matrix von zweiten Derivaten der objektiven Funktion und die Zwänge, die als Grenze Hessian bei eingeschränkten Problemen genannt werden. Die Bedingungen, die Maxima oder Minima von anderen stationären Punkten unterscheiden, werden als "zweite Ordnungsbedingungen" bezeichnet (siehe "Second-Derivate-Test"). Befriedigt eine Kandidatenlösung die Bedingungen der ersten Ordnung, so reicht auch die Zufriedenheit der Bedingungen der zweiten Ordnung aus, um zumindest lokale Optimität zu etablieren. Empfindlichkeit und Kontinuität von optima Das Hüllkurventheorem beschreibt, wie sich der Wert einer optimalen Lösung ändert, wenn sich ein zugrundeliegender Parameter ändert. Der Prozess der Berechnung dieser Änderung wird als vergleichende Statik bezeichnet. Das maximale Theorem von Claude Berge (1963) beschreibt die Kontinuität einer optimalen Lösung in Abhängigkeit von zugrunde liegenden Parametern. Berechnung der Optimierung Für untrainierte Probleme mit doppelt differenzierbaren Funktionen können einige kritische Punkte gefunden werden, indem die Punkte gefunden werden, an denen der Gradient der Objektivfunktion Null ist (d.h. die stationären Punkte). Im Allgemeinen bescheinigt ein Nullsubgradient, dass ein lokales Minimum zur Minimierung von Problemen mit konvexen Funktionen und anderen lokalen Lipschitz-Funktionen gefunden wurde. Ferner können kritische Punkte mit der Spezifität der hessischen Matrix klassifiziert werden: Wenn der Hessian an einem kritischen Punkt positiv ist, dann ist der Punkt ein lokales Minimum; wenn die hessische Matrix negativ definiert ist, dann ist der Punkt ein lokales Maximum; schließlich, wenn unbestimmt, dann ist der Punkt eine Art Sattelpunkt. Mit Hilfe von Lagrange-Multiplikatoren lassen sich häufig eingeschränkte Probleme in untrainierte Probleme transformieren. Lagrangian Entspannung kann auch ungefähre Lösungen für schwierige eingeschränkte Probleme bieten. Wenn die Zielfunktion eine konvexe Funktion ist, wird jedes lokale Minimum auch ein globales Minimum sein.Es gibt effiziente numerische Techniken zur Minimierung konvexer Funktionen, wie z.B. Innenpunkt-Methoden. Rechenoptimierungstechniken Um Probleme zu lösen, können Forscher Algorithmen verwenden, die in einer endlichen Anzahl von Schritten enden, oder iterative Methoden, die zu einer Lösung konvergieren (auf einigen bestimmten Klassen von Problemen,) oder Heuristiken, die ungefähre Lösungen für einige Probleme bieten kann (obwohl ihre Iterate nicht konvergieren müssen.) Optimierungsalgorithmen Simplex-Algorithmus von George Dantzig, entworfen für lineare Programmierung Erweiterungen des Simplex-Algorithmus, entworfen für quadratische Programmierung und für linear-fractional Programmierung Varianten des Simplex-Algorithmus, die besonders für die Netzwerkoptimierung geeignet sind. Kombinationsalgorithmen Quantum Optimierungsalgorithmen Iterative Methoden Die iterativen Methoden zur Lösung von Problemen der nichtlinearen Programmierung unterscheiden sich je nachdem, ob sie Hesser, Gradienten oder nur Funktionswerte auswerten. Während die Auswertung von Hessians (H) und Gradienten (G) die Konvergenzrate verbessert, für Funktionen, für die diese Mengen existieren und ausreichend glatt variieren, erhöhen diese Auswertungen die Rechenkomplexität (oder Rechenkosten) jeder Iteration. In einigen Fällen kann die rechnerische Komplexität zu hoch sein. Ein Hauptkriterium für Optimierer ist nur die Anzahl der benötigten Funktionsauswertungen, da dies oft bereits ein großer Rechenaufwand ist, meist viel mehr Aufwand als im Optimierer selbst, der hauptsächlich über die N-Variablen arbeiten muss. Die Derivate liefern detaillierte Informationen für solche Optimatoren, sind aber noch härter zu berechnen, z.B. eine Annäherung des Gradienten nimmt mindestens N+1 Funktionsauswertungen. Für Approximationen der 2. Derivate (gesammelt in der hessischen Matrix) liegt die Anzahl der Funktionsauswertungen in der Größenordnung von N2.Newtons Methode erfordert die 2. Ordnungsderivate, so dass für jede Iteration die Anzahl der Funktionsaufrufe in der Größenordnung von N2 ist, aber für einen einfacheren reinen Gradientenoptimierer ist es nur N.Allerdings benötigen Gradientenoptimatoren meist mehr Iterationen als Newtons. Welcher im Hinblick auf die Anzahl der Funktionsaufrufe am besten ist, hängt vom Problem selbst ab. Methoden, die Hesser (oder Hesser nähern, mit endlichen Unterschieden bewerten:) Newton's Methode Sequential quadratic Programmierung: Eine Newton-basierte Methode für kleine-Medium-Skala eingeschränkt Probleme. Einige Versionen können großdimensionale Probleme bewältigen. Innenpunkt Methoden: Dies ist eine große Klasse von Methoden zur eingeschränkten Optimierung. Einige Insider-Point-Methoden verwenden nur (sub)gradiente Informationen und andere davon erfordern die Bewertung von Hessians. Methoden, die Gradienten oder annähernde Gradienten in irgendeiner Weise auswerten (oder sogar Subgradienten:) Koordinatenabstiegsmethoden: Algorithmen, die eine einzelne Koordinaten in jeder Iteration aktualisieren Konjugate Gradientenmethoden: Iterative Methoden für große Probleme. ( In der Theorie enden diese Methoden in einer endlichen Anzahl von Schritten mit quadratischen Zielfunktionen, aber diese endliche Beendigung wird in der Praxis auf endlich-genauen Computern nicht beobachtet.) Gradientenabstieg (alternativ, "steepest descent" oder "steepest ascent:)" Eine (langsame) Methode des historischen und theoretischen Interesses, die sich erneut für die Suche nach ungefähr Lösungen von enormen Problemen interessiert. Subgradiente Methoden: Eine iterative Methode für große lokale Lipschitz-Funktionen unter Verwendung allgemeiner Gradienten. Nach Boris T. Polyak ähneln Subgradient-Projektionsverfahren den konjugat-gradienten Methoden. Abstiegsmethode: Eine iterative Methode für kleine und mittlere Probleme mit lokalen Lipschitz-Funktionen, insbesondere für konvexe Minimierungsprobleme (ähnlich konjugierten Gradientenmethoden). Ellipsoid Methode: Eine iterative Methode für kleine Probleme mit quasikonvexen Zielfunktionen und von großem theoretischem Interesse, insbesondere bei der Festlegung der Polynomzeitkomplexität einiger kombinatorischer Optimierungsprobleme. Es hat Ähnlichkeiten mit Quasi-Newton Methoden. Bedingte Gradientenmethode (Frank-Wolfe) zur ungefähren Minimierung speziell strukturierter Probleme mit linearen Zwängen, insbesondere bei Verkehrsnetzen. Bei allgemeinen untrainierten Problemen reduziert sich dieses Verfahren auf das Gradientenverfahren, das als obsolet angesehen wird (bei fast allen Problemen). Quasi-Newton Methoden: Iterative Methoden für mittelgroße Probleme (z.B. N<1000). Simultane Perturbation stochastische Approximation (SPSA) Methode zur stochastischen Optimierung; verwendet zufällige (effiziente) Gradienten Näherung.Methoden, die nur Funktionswerte auswerten: Ist ein Problem kontinuierlich differenzierbar, so können Gradienten mit endlichen Unterschieden angenähert werden, wobei ein Gradienten-basiertes Verfahren verwendet werden kann. Interpolation Methoden Muster-Suchmethoden, die bessere Konvergenzeigenschaften haben als die Nelder-Mead-Huristik (mit Simplices), die unten aufgeführt ist. Globale Konvergenz Im Allgemeinen, wenn die Zielfunktion nicht eine quadratische Funktion ist, verwenden viele Optimierungsmethoden andere Methoden, um sicherzustellen, dass eine gewisse Folge von Iterationen zu einer optimalen Lösung konvergiert. Die erste und immer noch beliebte Methode zur Sicherstellung der Konvergenz setzt auf Liniensuche, die eine Funktion entlang einer Dimension optimieren. Eine zweite und immer beliebtere Methode zur Sicherstellung der Konvergenz verwendet Treuhandregionen. Sowohl Liniensuche als auch Treuhandgebiete werden in modernen Methoden der nicht differenzierbaren Optimierung eingesetzt. In der Regel ist ein globaler Optimierer viel langsamer als fortgeschrittene lokale Optimierer (wie BFGS), so dass oft ein effizienter globaler Optimierer aufgebaut werden kann, indem der lokale Optimierer von verschiedenen Startpunkten aus gestartet wird. Heuristik Neben (endlich endenden) Algorithmen und (konvergenten) iterativen Methoden gibt es Heuristiken. Eine heuristische ist jeder Algorithmus, der nicht gewährleistet ist (mathematisch) die Lösung zu finden, aber dennoch nützlich in bestimmten praktischen Situationen. Liste einiger bekannter Heuristiken: Anwendungen Mechanics Probleme in der starren Körperdynamik (insbesondere artikulierte starre Körperdynamik) erfordern oft mathematische Programmiertechniken, da Sie starre Körperdynamik als Versuch, eine gewöhnliche Differentialgleichung an einem Strengekrümmer betrachten können; die Zwänge sind verschiedene nichtlineare geometrische Zwänge wie "diese beiden Punkte müssen immer zusammenfallen", "diese Oberfläche darf keine andere durchdringen" oder "diese Punkt muss immer irgendwo auf dieser Kurve liegen". Auch kann das Problem der Berechnung von Kontaktkräften durch Lösen eines linearen Komplementaritätsproblems gelöst werden, das auch als QP (quadratische Programmierung) Problem angesehen werden kann. Viele Designprobleme können auch als Optimierungsprogramme ausgedrückt werden. Diese Anwendung wird Designoptimierung genannt. Eine Teilmenge ist die Engineering-Optimierung, und eine weitere jüngste und wachsende Teilmenge dieses Bereichs ist multidisziplinäre Design-Optimierung, die, obwohl in vielen Problemen nützlich, insbesondere auf Probleme der Luft- und Raumfahrttechnik angewendet wurde. Dieser Ansatz kann in der Kosmologie und Astrophysik angewendet werden. Ökonomie und Finanzökonomie ist eng genug mit der Optimierung von Agenten verbunden, die eine einflussreiche Definition im Zusammenhang mit der Wirtschaftswissenschaften als die "Studie des menschlichen Verhaltens als Beziehung zwischen den Enden und knappen Mitteln" mit alternativen Anwendungen beschreibt. Moderne Optimierungstheorie umfasst traditionelle Optimierungstheorie, überschneidet sich aber auch mit der Spieltheorie und der Studie der wirtschaftlichen Gleichgewichte. Das Journal of Economic Literature kodiert mathematische Programmierung, Optimierungstechniken und verwandte Themen unter JEL:C61-C63. In der Mikroökonomie sind das Problem der Versorgungsmaximierung und sein doppeltes Problem, das Problem der Kostenminimierung, wirtschaftliche Optimierungsprobleme. Insofern sie sich konsequent verhalten, werden die Verbraucher angenommen, um ihr Nutzen zu maximieren, während die Unternehmen in der Regel angenommen werden, um ihren Gewinn zu maximieren. Auch werden Agenten oft als Risiko-Averse modelliert, wodurch es bevorzugt wird, Risiko zu vermeiden. Die Asset-Preise werden auch anhand der Optimierungstheorie modelliert, obwohl die zugrunde liegende Mathematik eher auf die Optimierung stochastischer Prozesse als auf statischer Optimierung beruht. Internationale Handelstheorie nutzt auch die Optimierung, um Handelsmuster zwischen Nationen zu erklären. Die Optimierung von Portfolios ist ein Beispiel einer multiobjektiven Optimierung in der Wirtschaft. Seit den 1970er-Jahren haben Ökonomen dynamische Entscheidungen im Laufe der Zeit anhand der Steuerungstheorie modelliert. Zum Beispiel werden dynamische Suchmodelle zur Untersuchung des Arbeitsmarktverhaltens verwendet. Eine entscheidende Unterscheidung ist zwischen deterministischen und stochastischen Modellen. Makroökonomisten bauen dynamische stochastische allgemeine Gleichgewichtsmodelle (DSGE) auf, die die Dynamik der gesamten Wirtschaft als Folge der interdependenten Entscheidungen der Arbeitnehmer, Verbraucher, Investoren und Regierungen beschreiben. Elektrotechnik Einige gängige Anwendungen von Optimierungstechniken in der Elektrotechnik umfassen aktives Filterdesign, Streufeldreduktion in supraleitenden magnetischen Energiespeichersystemen, Raum-Mapping-Design von Mikrowellenstrukturen, Handy-Antennen, elektromagnetisches Design.Die elektromagnetisch validierte Design-Optimierung von Mikrowellenkomponenten und -antennen hat seit der Entdeckung der Raumkartierung im Jahr 1993 einen umfangreichen Einsatz eines geeigneten physikalisch-basierten oder empirischen Surrogatmodells und Raumkartierungsmethoden ermöglicht. Die Optimierung des Bauwesens wurde im Bauwesen weit verbreitet. Baumanagement und Transporttechnik gehören zu den wichtigsten Zweigen der Bautechnik, die stark auf Optimierung angewiesen sind. Die gängigsten Probleme der Bauingenieurwesen, die durch Optimierung gelöst werden, sind das Abschneiden und Ausfüllen von Straßen, die Lebenszyklusanalyse von Strukturen und Infrastrukturen, die Ressourcenaufteilung, die Wasserressourcenzuweisung, das Verkehrsmanagement und die Zeitplanoptimierung. Operations Research Ein weiterer Bereich, der die Optimierungstechniken umfassend nutzt, ist die Betriebsforschung. Die Operationsforschung nutzt auch stochastische Modellierung und Simulation, um eine verbesserte Entscheidungsfindung zu unterstützen. Zunehmend nutzt die Betriebsforschung stochastische Programmierung, um dynamische Entscheidungen zu modellieren, die sich an Ereignisse anpassen; solche Probleme können mit großtechnischen Optimierungs- und stochastischen Optimierungsverfahren gelöst werden. Steuerungstechnik Mathematische Optimierung wird in viel modernem Controller-Design verwendet. Hochrangige Steuerungen wie Modell-Prädiktionssteuerung (MPC) oder Echtzeit-Optimierung (RTO) verwenden eine mathematische Optimierung. Diese Algorithmen laufen online und bestimmen immer wieder Werte für Entscheidungsvariablen, wie z.B. Drosselöffnungen in einer Prozessanlage, indem sie iterativ ein mathematisches Optimierungsproblem lösen, einschließlich Einschränkungen und ein Modell des zu steuernden Systems. Geophysik Optimierungstechniken werden regelmäßig in geophysikalischen Parameterschätzungsproblemen eingesetzt. Bei einer Reihe geophysikalischer Messungen, z.B. seismischen Aufnahmen, ist es üblich, für die physikalischen Eigenschaften und geometrischen Formen der darunterliegenden Gesteine und Flüssigkeiten zu lösen. Die meisten Probleme in der Geophysik sind nichtlinear, wobei sowohl deterministische als auch stochastische Methoden weit verbreitet sind. Molekulare Modellierung Nichtlineare Optimierungsverfahren werden in der Exterieuranalyse weit verbreitet. Rechensystembiologie Optimierungstechniken werden in vielen Facetten der Rechensystembiologie wie Modellbau, optimales experimentelles Design, Stoffwechseltechnik und synthetische Biologie eingesetzt. Zur Berechnung der maximal möglichen Ausbeuten an Fermentationsprodukten wurde eine lineare Programmierung angewendet, um Genregulationsnetzwerke aus mehreren Mikroarray-Datensätzen sowie transkriptionelle regulatorische Netzwerke aus High-Throughput-Daten zu unterziehen. Nichtlineare Programmierung wurde verwendet, um den Energiestoffwechsel zu analysieren und wurde auf die metabolische Technik und die Parameterschätzung in biochemischen Wegen angewendet. Siehe auch AnmerkungenWeiter lesen Boyd, Stephen P;. Vandenberghe, Lieven (2004). Convex Optimierung. Cambridge: Cambridge University Press.ISBN 0-521-83378-7.Gill, P. E;. Murray, W;. Wright, M. H. (1982). Praktische Optimierung. London: Academic Press.ISBN 0-12-283952-8.Lee, Jon (2004). Ein erster Kurs in Kombinationsoptimierung. Cambridge University Press.ISBN 0-521-01012-8.Nocedal, Jorge; Wright, Stephen J. (2006). Numerische Optimierung (2. ed.). Berlin: Springer.ISBN 0-387-30303-0.Snyman, J. A;. Wilke, D. N. (2018). Praktische mathematische Optimierung : Grundlagenoptimierungstheorie und gradientbasierte Algorithmen (2. ed.). Berlin: Springer.ISBN 978-3-319-77585-2. Externe Links "Beschlussbaum für Optimierungssoftware". Links zu Optimierungsquellencodes "Globale Optimierung". " EE364a: Convex Optimization I".Course von der Stanford University. Varoquaux, Gaël. "Mathematische Optimierung: Minima der Funktionen finden."