Ein verteiltes Dateisystem für Cloud ist ein Dateisystem, mit dem viele Clients Zugriff auf Daten haben und Operationen (Erstellen, Löschen, Ändern, Lesen, Schreiben) auf diese Daten unterstützt. Jede Datendatei kann in mehrere Teile unterteilt werden, die als Bruchstücke bezeichnet werden. Jedes Stück kann auf verschiedenen Fernmaschinen gespeichert werden, wodurch die parallele Ausführung von Anwendungen erleichtert wird. Typischerweise werden Daten in Dateien in einem hierarchischen Baum gespeichert, wo die Knoten Verzeichnisse darstellen. Es gibt verschiedene Möglichkeiten, Dateien in einer verteilten Architektur zu teilen: jede Lösung muss für eine bestimmte Art von Anwendung geeignet sein, je nachdem, wie komplex die Anwendung ist. Inzwischen muss die Sicherheit des Systems gewährleistet werden. Vertraulichkeit, Verfügbarkeit und Integrität sind die wichtigsten Schlüssel für ein sicheres System. Benutzer können Rechenressourcen über das Internet durch Cloud Computing teilen, die typischerweise durch skalierbare und elastische Ressourcen gekennzeichnet ist – wie physische Server, Anwendungen und alle Dienste, die dynamisch virtualisiert und zugewiesen werden. Die Synchronisation ist erforderlich, um sicherzustellen, dass alle Geräte aktuell sind. Verteilte Dateisysteme ermöglichen es vielen großen, mittleren und kleinen Unternehmen, ihre Remote-Daten zu speichern und zuzugreifen, da sie lokale Daten machen, wodurch die Verwendung variabler Ressourcen erleichtert wird. Überblick Geschichte Heute gibt es viele Implementierungen verteilter Dateisysteme. Die ersten Dateiserver wurden von Forschern in den 1970er Jahren entwickelt. Das Netzwerkdateisystem von Sun Microsystems wurde in den 1980er Jahren verfügbar. Vorher nutzten die Leute, die Dateien teilen wollten, die Sneakernet-Methode, physischen Transport von Dateien auf Speichermedien von Ort zu Ort. Sobald Computernetzwerke begannen, zu proliferieren, wurde deutlich, dass die vorhandenen Dateisysteme viele Einschränkungen hatten und für Multi-User-Umgebungen ungeeignet waren. Benutzer nutzten zunächst FTP, um Dateien zu teilen. FTP lief Ende 1973 zunächst auf der PDP-10. Auch bei FTP mussten Dateien vom Quellcomputer auf einen Server und dann vom Server auf den Zielrechner kopiert werden. Die Benutzer mussten die physischen Adressen aller Computer kennen, die mit der Dateifreigabe verbunden sind. Moderne Rechenzentren müssen große, heterogene Umgebungen unterstützen, die aus einer Vielzahl von Computern unterschiedlicher Kapazitäten bestehen. Cloud Computing koordiniert den Betrieb aller solchen Systeme, mit Techniken wie Datacenter Networking (DCN), dem MapReduce Framework, das Daten-intensive Rechenanwendungen in parallelen und verteilten Systemen unterstützt, und Virtualisierungstechniken, die dynamische Ressourcenallokation bieten, so dass mehrere Betriebssysteme auf demselben physischen Server koexistieren können. Anwendungen Cloud Computing bietet dank seiner Fähigkeit, dem Anwender die benötigten CPU- und Speicherressourcen mit vollständiger Transparenz bereitzustellen. Dies macht Cloud Computing besonders geeignet, um verschiedene Arten von Anwendungen zu unterstützen, die eine großflächig verteilte Verarbeitung erfordern. Dieses datenintensive Computing benötigt ein hochleistungsfähiges Dateisystem, das Daten zwischen virtuellen Maschinen (VM) teilen kann. Cloud Computing ordnet die benötigten Ressourcen dynamisch an und gibt sie frei, sobald eine Aufgabe erledigt ist, sodass die Nutzer nur für benötigte Dienste bezahlen müssen, oft über eine Service-Level-Vereinbarung. Cloud Computing- und Cluster Computing-Paradigmen werden immer wichtiger für industrielle Datenverarbeitung und wissenschaftliche Anwendungen wie Astronomie und Physik, die häufig die Verfügbarkeit großer Computer erfordern, um Experimente durchzuführen. Architektur Die meisten verteilten Dateisysteme sind auf der Client-Server-Architektur aufgebaut, aber auch andere dezentrale Lösungen existieren. Client-Server-Architektur Network File System (NFS) verwendet eine Client-Server-Architektur, die es ermöglicht, Dateien zwischen einer Reihe von Maschinen in einem Netzwerk zu teilen, als ob sie sich lokal befinden und eine standardisierte Ansicht bieten. Das NFS-Protokoll ermöglicht heterogene Client-Prozesse, die wahrscheinlich auf verschiedenen Maschinen und unter verschiedenen Betriebssystemen laufen, auf Dateien auf einem entfernten Server zuzugreifen und den tatsächlichen Speicherort von Dateien zu ignorieren. Die Wiederherstellung auf einem einzigen Server führt dazu, dass das NFS-Protokoll unter potenziell geringer Verfügbarkeit und schlechter Skalierbarkeit leidet. Die Verwendung mehrerer Server löst das Verfügbarkeitsproblem nicht, da jeder Server unabhängig arbeitet. Das Modell von NFS ist ein Remote-Dateidienst. Dieses Modell wird auch als Remote Access Model bezeichnet, das im Gegensatz zum Upload/Download-Modell steht: Fernzugriffsmodell: Bietet Transparenz, der Client hat Zugriff auf eine Datei. Er sendet Anfragen an die Remote-Datei (wenn die Datei auf dem Server bleibt). Upload/Download-Modell: Der Client kann nur lokal auf die Datei zugreifen. Es bedeutet, dass der Client die Datei herunterladen, Änderungen vornehmen und wieder hochladen muss, um von anderen Kunden verwendet werden. Das von NFS verwendete Dateisystem ist fast das gleiche wie das von Unix Systemen. Dateien werden hierarchisch in einem Namensdiagramm organisiert, in dem Verzeichnisse und Dateien durch Knoten dargestellt werden. Clusterbasierte Architekturen Eine Cluster-basierte Architektur verstärkt einige der Probleme in Client-Server-Architekturen und verbessert die Ausführung von Anwendungen parallel. Die hier verwendete Technik ist Datei-Striping: Eine Datei wird in mehrere Stücke aufgeteilt, die über mehrere Speicherserver gestreift werden. Ziel ist es, den Zugriff auf verschiedene Teile einer Datei parallel zu ermöglichen. Wenn die Anwendung nicht von dieser Technik profitiert, dann wäre es bequemer, verschiedene Dateien auf verschiedenen Servern zu speichern. Wenn es jedoch darum geht, ein verteiltes Dateisystem für große Rechenzentren zu organisieren, wie Amazon und Google, die Dienste für Web-Clients bieten, die mehrere Operationen (Lesen, Aktualisieren, Löschen) zu einer Vielzahl von Dateien auf eine Vielzahl von Computern verteilt, dann Cluster-basierte Lösungen werden vorteilhafter. Beachten Sie, dass mit einer großen Anzahl von Computern kann mehr Hardware-Ausfälle bedeuten. Zwei der am weitesten verbreiteten Dateisysteme (DFS) dieser Art sind das Google File System (GFS) und das Hadoop Distributed File System (HDFS). Die beiden Dateisysteme werden von Benutzerebenenprozessen implementiert, die auf einem Standard-Betriebssystem (Linux bei GFS) laufen. Design-Prinzips Goals Google File System (GFS) und Hadoop Distributed File System (HDFS) werden speziell für die Bearbeitung der Chargenverarbeitung auf sehr großen Datensätzen gebaut. Dazu müssen folgende Hypothesen berücksichtigt werden: Hohe Verfügbarkeit: der Cluster kann Tausende von Dateiservern enthalten und einige von ihnen können jederzeit nach unten sein Ein Server gehört zu einem Rack, einem Raum, einem Rechenzentrum, einem Land und einem Kontinent, um seine geographische Lage genau zu identifizieren Die Größe einer Datei kann von vielen Gigabyten zu vielen Terabyten variieren. Das Dateisystem sollte in der Lage sein, eine massive Anzahl von Dateien zu unterstützen Die Notwendigkeit, Operationen anzuhängen und Dateiinhalte sichtbar zu machen, auch während eine Datei geschrieben ist Kommunikation ist zuverlässig bei Arbeitsmaschinen: TCP/IP wird mit einem Remote-Prozedur RPC Kommunikationsabstraktion verwendet. TCP ermöglicht es dem Client, fast sofort zu wissen, wenn es ein Problem und eine Notwendigkeit, eine neue Verbindung zu machen. Lastausgleich Lastausgleich ist für einen effizienten Betrieb in verteilten Umgebungen unerlässlich. Es bedeutet, Arbeit unter verschiedenen Servern zu verteilen, fair, um mehr Arbeit in der gleichen Zeit und Kunden schneller zu bedienen. In einem System mit N-Chunkservern in einer Cloud (N mit 1000, 10000 oder mehr), bei dem eine bestimmte Anzahl von Dateien gespeichert sind, wird jede Datei in mehrere Teile oder Stücke fester Größe (z.B. 64 Megabyte) aufgeteilt, wobei die Last jedes Cunkservers proportional zur Anzahl der vom Server gehosteten Cunks ist. In einer lastausgeglichenen Cloud können Ressourcen effizient genutzt werden, um die Leistung von MapReduce-basierten Anwendungen zu maximieren. Last-Rebalancing In einer Cloud-Computing-Umgebung ist Ausfall die Norm, und chunkserver können aktualisiert, ersetzt und dem System hinzugefügt werden. Dateien können auch dynamisch erstellt, gelöscht und angehängt werden. Das führt zu Lastungleichgewicht in einem verteilten Dateisystem, d.h. dass die Datei-Chunks nicht äquivalent zwischen den Servern verteilt werden. Verteilte Dateisysteme in Wolken wie GFS und HDFS verlassen sich auf zentrale oder Master-Server oder Knoten (Master for GFS und NameNode for HDFS), um die Metadaten und den Lastausgleich zu verwalten. Der Master rebalances repliziert periodisch: Daten müssen von einem DataNode/chunkserver in einen anderen verschoben werden, wenn der freie Platz auf dem ersten Server unter eine bestimmte Schwelle fällt. Dieser zentralisierte Ansatz kann jedoch zu einem Engpass für diese Masterserver werden, wenn sie nicht in der Lage sind, eine Vielzahl von Dateizugriffen zu verwalten, da sie ihre bereits schweren Belastungen erhöht. Das Last-Rebalance-Problem ist NP-hard. Um eine große Anzahl von Chunkservern in Zusammenarbeit zu arbeiten und das Problem des Lastausgleichs in verteilten Dateisystemen zu lösen, wurden mehrere Ansätze vorgeschlagen, wie z.B. das Umsetzen von Datei-Chunks, so dass die Chunks möglichst gleichmäßig verteilt werden können, während die Bewegungskosten möglichst reduziert werden. Beschreibung Google, einer der größten Internet-Unternehmen, hat ein eigenes verteiltes Dateisystem namens Google File System (GFS) erstellt, um die schnell wachsenden Anforderungen an die Datenverarbeitung von Google zu erfüllen, und es wird für alle Cloud-Dienste verwendet. GFS ist ein skalierbares verteiltes Dateisystem für datenintensive Anwendungen. Es bietet fehlertolerante, leistungsfähige Datenspeicherung eine große Anzahl von Kunden, die gleichzeitig darauf zugreifen. GFS verwendet MapReduce, die es Benutzern ermöglicht, Programme zu erstellen und auf mehreren Maschinen zu betreiben, ohne an Parallelisierung und Load-Balancing-Probleme zu denken. GFS-Architektur basiert auf einem einzigen Masterserver für mehrere Cunkserver und mehrere Clients. Der Masterserver, der in dediziertem Knoten läuft, ist für die Koordination von Speicherressourcen und die Verwaltung von Metadaten von Dateien verantwortlich (das Äquivalent von beispielsweise Inoden in klassischen Dateisystemen). Jede Datei ist auf mehrere Stücke von 64 Megabyte aufgeteilt. Jedes Stück wird in einem chunk-Server gespeichert. Ein Stück wird durch einen Stückgriff identifiziert, der eine weltweit einzigartige 64-Bit-Nummer ist, die vom Master zugewiesen wird, wenn das Stück zuerst erstellt wird. Der Master unterhält alle Metadaten der Dateien, einschließlich Dateinamen, Verzeichnisse und das Mapping von Dateien auf die Liste der Blöcke, die die Daten jeder Datei enthalten. Die Metadaten werden im Hauptspeicher des Masterservers gespeichert, zusammen mit der Mapping von Dateien zu chunks. Aktualisierungen dieser Daten werden in einem Betriebsprotokoll auf der Festplatte gespeichert. Dieses Betriebsprotokoll wird auf entfernte Maschinen repliziert. Wenn das Protokoll zu groß wird, wird ein Kontrollpunkt gemacht und die Hauptspeicherdaten in einer B-Struktur gespeichert, um die Zuordnung in den Hauptspeicher zu erleichtern. Fehlertoleranz Um Fehlertoleranz zu erleichtern, wird jedes Stück auf mehrere (Standard, drei) chunk-Server repliziert. Ein Stück ist auf mindestens einem Chip-Server verfügbar. Der Vorteil dieses Schemas ist die Einfachheit. Der Master ist verantwortlich für die Zuordnung der chunk-Server für jeden chunk und wird nur für Metadateninformationen kontaktiert. Für alle anderen Daten muss der Client mit den chunk-Servern interagieren. Der Meister hält die Spur, wo sich ein Stück befindet. Es versucht jedoch nicht, die Einbauorte genau zu halten, sondern kontaktiert nur gelegentlich die Einbau-Server, um zu sehen, welche Bruchstücke sie gespeichert haben. Dies ermöglicht Skalierbarkeit und verhindert Engpässe durch erhöhte Arbeitsbelastung. In GFS werden die meisten Dateien durch Anwenden neuer Daten geändert und bestehende Daten nicht überschrieben. Einmal geschrieben, werden die Dateien in der Regel nur sequentiell gelesen, anstatt zufällig, und das macht diese DFS zum geeignetsten für Szenarien, in denen viele große Dateien einmal erstellt werden, aber viele Male lesen. Datenverarbeitung Wenn ein Client eine Datei schreiben-to/update will, wird der Master eine Replik zuordnen, die die primäre Replik ist, wenn es die erste Modifikation ist. Der Schreibvorgang besteht aus zwei Schritten: Senden: Zuerst und bei weitem das wichtigste, der Client kontaktiert den Master, um herauszufinden, welche chunk-Server die Daten halten. Der Client erhält eine Liste von Repliken, die die primären und sekundären chunk-Server identifizieren. Der Client kontaktiert dann den nächsten Replik-Chunk-Server und sendet die Daten an ihn. Dieser Server sendet die Daten an den nächsten, der sie dann an eine weitere Replik weiterleitet und so weiter. Die Daten werden dann propagiert und im Speicher geätzt, aber noch nicht in eine Datei geschrieben. Schreiben: Wenn alle Repliken die Daten erhalten haben, sendet der Client eine Schreibanfrage an den primären chunk-Server und identifiziert die Daten, die in der Sendephase gesendet wurden. Der primäre Server wird dann den empfangenen Schreibvorgängen eine Sequenznummer zuweisen, die Schreibvorgänge in Seriennummernauftrag an die Datei anlegen und die Schreibanfragen in dieser Reihenfolge an die Sektaren weiterleiten. Inzwischen wird der Meister aus der Schleife gehalten. Folglich können wir zwei Arten von Strömen unterscheiden: den Datenfluss und den Steuerstrom. Dem Datenfluss ist die Sendephase zugeordnet und der Schreibphase ist der Steuerstrom zugeordnet. Dadurch wird sichergestellt, dass der primäre chunk-Server die Steuerung der Schreibreihenfolge übernimmt. Beachten Sie, dass, wenn der Master die Schreiboperation einem Replikat zuordnet, es erhöht die chunk-Versionsnummer und informiert alle Repliken, die diesen chunk der neuen Versionsnummer enthalten. Chunk-Versionsnummern ermöglichen es, die Fehlererkennung zu aktualisieren, wenn eine Replik nicht aktualisiert wurde, weil ihr chunk-Server unten war. Einige neue Google-Anwendungen funktionierten nicht gut mit der 64-Megabyte-Chunk-Größe. Um dieses Problem zu lösen, begann GFS 2004, den Bigtable-Ansatz umzusetzen. Hadoop verteiltes Dateisystem HDFS, von der Apache Software Foundation entwickelt, ist ein verteiltes Dateisystem, das sehr große Mengen an Daten (Terabytes oder sogar Petabytes) halten soll. Seine Architektur ist ähnlich wie GFS, d.h. eine Master/Slave-Architektur. Die HDFS wird normalerweise auf einem Cluster von Computern installiert. Das Designkonzept von Hadoop wird von Googles, mit Google File System, Google MapReduce und Bigtable, durch Hadoop Distributed File System (HDFS), Hadoop MapReduce und Hadoop Base (HBase) implementiert. Wie GFS ist HDFS für Szenarien mit schreibgeschütztem Dateizugriff geeignet und unterstützt Dateianhänger und -angriffe anstelle von zufälligen Lesen und schreibt, um Datenkohärenzprobleme zu vereinfachen. Ein HDFS-Cluster besteht aus einer einzigen NameNode und mehreren DataNode-Maschinen. Der NameNode, ein Master-Server, verwaltet und unterhält die Metadaten von SpeicherdatenNodes in seinem RAM. DataNodes verwalten die Speicherung an den Knoten, die sie ausführen. NameNode und DataNode sind Software, die auf alltäglichen Maschinen laufen soll, die typischerweise unter einem Linux OS laufen. HDFS kann auf jeder Maschine ausgeführt werden, die Java unterstützt und somit entweder eine NameNode oder die Datanode Software ausführen kann. Auf einem HDFS-Cluster wird eine Datei in einen oder mehrere gleichgroße Blöcke aufgeteilt, außer dass der letzte Block kleiner ist. Jeder Block wird auf mehreren DataNodes gespeichert und jeder kann auf mehreren DataNodes repliziert werden, um die Verfügbarkeit zu gewährleisten. Standardmäßig wird jeder Block dreimal repliziert, ein Prozess namens "Block Level Replication". Der NameNode verwaltet die Dateisystemnamenspace-Operationen wie Öffnen, Schließen und Umbenennen von Dateien und Verzeichnissen und regelt den Dateizugriff. Es bestimmt auch die Zuordnung von Blöcken zu DataNodes. Die DataNodes sind verantwortlich für die Wartung von Lese- und Schreibanfragen der Clients des Dateisystems, die Verwaltung der Blockzuordnung oder Löschung und die Replikation von Blöcken. Wenn ein Client Daten lesen oder schreiben möchte, kontaktiert er den NameNode und den NameNode-Check, in dem die Daten gelesen oder geschrieben werden sollen. Danach hat der Client den Standort der DataNode und kann Lese- oder Schreibanfragen an ihn senden. Das HDFS zeichnet sich typischerweise durch seine Kompatibilität mit Datenrebalancing-Systemen aus. Generell ist die Verwaltung des Freiraums auf einem DataNode sehr wichtig. Die Daten müssen von einem DataNode in einen anderen verschoben werden, wenn der Freiraum nicht ausreichend ist; und bei der Erstellung zusätzlicher Repliken sollten Daten bewegt werden, um die Systembilanz zu gewährleisten. Andere Beispiele verteilte Dateisysteme können für verschiedene Zwecke optimiert werden. Einige, wie z.B. für Internet-Dienste, einschließlich GFS, sind für Skalierbarkeit optimiert. Andere Designs für verteilte Dateisysteme unterstützen leistungsintensive Anwendungen, die üblicherweise parallel ausgeführt werden. Einige Beispiele sind: MapR File System (MapR-FS), Ceph-FS, Fraunhofer File System (BeeGFS), Lustre File System, IBM General Parallel File System (GPFS) und Parallel Virtual File System. MapR-FS ist ein verteiltes Dateisystem, das die Grundlage der MapR Converged Platform ist, mit Funktionen für verteilte Dateispeicherung, eine NoSQL-Datenbank mit mehreren APIs und ein integriertes Nachrichtenstreaming-System. MapR-FS ist für Skalierbarkeit, Leistung, Zuverlässigkeit und Verfügbarkeit optimiert. Seine Dateispeicherfähigkeit ist kompatibel mit der Apache Hadoop Distributed File System (HDFS) API, aber mit mehreren Design-Eigenschaften, die es von HDFS unterscheiden. Zu den bemerkenswertesten Unterschieden zählen, dass MapR-FS ein vollständig gelesenes/schreibendes Dateisystem mit Metadaten für Dateien und Verzeichnisse ist, die über den Namensraum verteilt sind, so gibt es keine NameNode. Ceph-FS ist ein verteiltes Dateisystem, das hervorragende Leistung und Zuverlässigkeit bietet. Es antwortet den Herausforderungen des Umgangs mit riesigen Dateien und Verzeichnissen, koordiniert die Aktivität von Tausenden von Festplatten, bietet parallelen Zugriff auf Metadaten auf einem massiven Maßstab, manipuliert sowohl wissenschaftliche als auch allgemeine Arbeitslasten, Authentisierung und Verschlüsselung auf einem großen Maßstab, und erhöht oder abnimmt dynamisch durch häufige Gerätedekomierung, Geräteausfälle und Clustererweiterungen. BeeGFS ist das leistungsstarke Parallel-Dateisystem des Fraunhofer Competence Centre for High Performance Computing. Die verteilte Metadatenarchitektur von BeeGFS wurde entwickelt, um die Skalierbarkeit und Flexibilität zu gewährleisten, die für die Ausführung von HPC und ähnlichen Anwendungen mit hohen I/O-Anforderungen erforderlich ist. Lustre File System wurde entwickelt und implementiert, um die Frage der Engpässe, die traditionell in verteilten Systemen gefunden wurden, zu behandeln. Lustre zeichnet sich durch seine Effizienz, Skalierbarkeit und Redundanz aus. GPFS wurde auch mit dem Ziel entworfen, solche Engpässe zu entfernen. Kommunikation Hohe Leistung verteilter Dateisysteme erfordert eine effiziente Kommunikation zwischen Rechenknoten und schnellen Zugriff auf die Speichersysteme. Operationen wie offen, schließen, lesen, schreiben, senden und empfangen müssen schnell sein, um diese Leistung zu gewährleisten. Zum Beispiel greift jede Lese- oder Schreibanfrage auf die Festplattenspeicherung zu, die Such-, Dreh- und Netzwerklatanzen einführt. Die Datenkommunikation (send/receive) überträgt Daten vom Anwendungspuffer auf den Maschinenkernel, TCP, der den Prozess steuert und im Kernel implementiert wird. Bei Netzübernahme oder Fehlern kann TCP die Daten jedoch nicht direkt senden. Beim Übertragen von Daten von einem Puffer im Kernel auf die Anwendung liest die Maschine den Byte-Stream nicht von der entfernten Maschine. Tatsächlich ist TCP für die Pufferung der Daten für die Anwendung verantwortlich. Die Auswahl der Puffergröße, zum Lesen und Schreiben von Dateien oder zum Senden und Empfangen von Dateien erfolgt auf der Anwendungsebene. Der Puffer wird mit einer kreisförmigen verknüpften Liste gehalten. Es besteht aus einer Reihe von BufferNodes. Jeder BufferNode hat ein DataField. Das DataField enthält die Daten und einen Pointer namens NextBufferNode, der auf die nächste BufferNode verweist. Um die aktuelle Position zu finden, werden zwei Zeiger verwendet: CurrentBufferNode und EndBufferNode, die die Position im BufferNode für die letzten Schreib- und Lesepositionen darstellen. Wenn die BufferNode keinen Freiraum hat, sendet sie dem Client ein Wartesignal, bis es Platz gibt. Cloud-basierte Synchronisation von verteilten Dateisystem Mehr und mehr Benutzer haben mehrere Geräte mit Ad-hoc-Konnektivität. Die auf diesen Geräten replizierten Datensätze müssen unter einer beliebigen Anzahl von Servern synchronisiert werden. Dies ist nützlich für Backups und auch für Offline-Betrieb.Wenn Benutzernetzwerkbedingungen nicht gut sind, wird das Benutzergerät einen Teil der Daten selektiv nachbilden, die später und offline geändert werden. Sobald die Netzbedingungen gut werden, wird das Gerät synchronisiert. Es gibt zwei Ansätze zur Bewältigung des verteilten Synchronisationsproblems: nutzergesteuerte Peer-to-Peer-Synchronisation und Cloud-Master-Replica-Synchronisation.usergesteuerte Peer-to-Peer: Software wie rsync muss in allen Computern installiert werden, die ihre Daten enthalten. Die Dateien werden durch Peer-to-Peer-Synchronisation synchronisiert, wobei die Benutzer Netzwerkadressen und Synchronisationsparameter angeben müssen und somit ein manueller Prozess ist. Cloud-Master-Replica-Synchronisation: weit verbreitet von Cloud-Diensten, in denen ein Master-Replikator in der Cloud gehalten wird, und alle Aktualisierungen und Synchronisationsoperationen sind diese Master-Kopie, bietet eine hohe Verfügbarkeit und Zuverlässigkeit bei Ausfall. Sicherheitsschlüssel Im Cloud Computing sind die wichtigsten Sicherheitskonzepte Vertraulichkeit, Integrität und Verfügbarkeit (CIA). Vertraulichkeit wird unabdingbar, um private Daten nicht offen zu halten. Integrität sorgt dafür, dass Daten nicht beschädigt werden. Confidentiality Confidentiality bedeutet, dass Daten und Berechnungsaufgaben vertraulich sind: weder Cloud-Anbieter noch andere Clients können auf die Daten des Clients zugreifen. Viele Forschungen wurden über die Vertraulichkeit durchgeführt, denn es ist einer der entscheidenden Punkte, die immer noch Herausforderungen für Cloud Computing stellen. Ein Mangel an Vertrauen in die Cloud-Anbieter ist auch ein damit verbundenes Problem. Die Infrastruktur der Cloud muss sicherstellen, dass die Daten der Kunden nicht von unbefugten Parteien aufgerufen werden. Die Umgebung wird unsicher, wenn der Dienstleister alle folgenden Schritte unternehmen kann: die Daten des Verbrauchers im Cloud-Zugang lokalisieren und die Daten des Verbrauchers abrufen verstehen die Bedeutung der Daten (Datenarten, Funktionalitäten und Schnittstellen der Anwendung und Format der Daten). Die geographische Lage der Daten hilft, Privatsphäre und Vertraulichkeit zu bestimmen. Der Standort der Kunden sollte berücksichtigt werden. Zum Beispiel werden Kunden in Europa nicht daran interessiert sein, Rechenzentren in den Vereinigten Staaten zu verwenden, weil dies die Garantie der Vertraulichkeit der Daten betrifft. Um dieses Problem zu lösen, haben einige Cloud-Computing-Anbieter den geographischen Standort des Hosts als Parameter der Service-Level-Vereinbarung mit dem Kunden enthalten, so dass Benutzer sich selbst die Standorte der Server, die ihre Daten hosten. Ein weiterer Ansatz zur Vertraulichkeit beinhaltet die Datenverschlüsselung. Andernfalls wird es ernste Gefahr einer unbefugten Nutzung geben. Es gibt eine Vielzahl von Lösungen, wie die Verschlüsselung nur sensibler Daten und die Unterstützung nur einiger Operationen, um die Berechnung zu vereinfachen. Darüber hinaus werden kryptographische Techniken und Werkzeuge als FHE verwendet, um die Privatsphäre in der Cloud zu bewahren. Integrität Integrität Integrity in Cloud Computing impliziert Datenintegrität sowie Rechenintegrität. Eine solche Integrität bedeutet, dass Daten korrekt auf Cloud-Servern gespeichert werden müssen und im Falle von Fehlern oder fehlerhaften Berechnungen Probleme erkannt werden müssen. Die Datenintegrität kann durch schädliche Ereignisse oder durch Verwaltungsfehler (z.B. beim Backup und Wiederherstellen, Datenmigration oder Änderung von Mitgliedschaften in P2P-Systemen) beeinflusst werden. Integrität ist einfach mit Kryptographie (typischerweise durch Nachrichten-Authentifizierungscode oder MACs auf Datenblöcken) zu erreichen. Es gibt Kontrollmechanismen, die die Datenintegrität beeinflussen. Zum Beispiel: HAIL (High-Availability and Integrity Layer) ist ein verteiltes kryptographisches System, das es einem Client ermöglicht, zu beweisen, dass eine gespeicherte Datei intakt und abrufbar ist. Hach PORs (Retrievability für große Dateien) basiert auf einem symmetrischen kryptographischen System, wo es nur einen Verifikationsschlüssel gibt, der in einer Datei gespeichert werden muss, um seine Integrität zu verbessern. Diese Methode dient der Verschlüsselung einer Datei F und erzeugt dann einen zufälligen String namens sendinel, der am Ende der verschlüsselten Datei hinzugefügt werden muss. Der Server kann das gesendete Inel nicht lokalisieren, was sich nicht von anderen Blöcken unterscheidet, so dass eine kleine Änderung angeben würde, ob die Datei geändert wurde oder nicht. PDP (beweisbarer Datenbesitz) Überprüfung ist eine Klasse von effizienten und praktischen Methoden, die eine effiziente Möglichkeit zur Überprüfung der Datenintegrität auf nicht vertrauenswürdigen Servern bieten: PDP: Vor der Speicherung der Daten auf einem Server muss der Client lokal einige Metadaten speichern. Zu einem späteren Zeitpunkt und ohne Herunterladen von Daten kann der Client den Server fragen, ob die Daten nicht gefälscht wurden. Dieser Ansatz wird für statische Daten verwendet. Skalierbare PDP: Dieser Ansatz wird auf einem symmetrischen Schlüssel prämiert, der effizienter ist als die öffentliche Schlüsselverschlüsselung. Es unterstützt einige dynamische Operationen (Modifikation, Löschung und Anhängen), kann aber nicht zur öffentlichen Überprüfung verwendet werden. Dynamische PDP: Dieser Ansatz erweitert das PDP-Modell, um mehrere Update-Operationen zu unterstützen, wie z.B. Anlegen, Einfügen, Modifizieren und Löschen, die für eine intensive Berechnung gut geeignet sind. Die Verfügbarkeit wird im allgemeinen durch Replikation bewirkt. Inzwischen muss die Konsistenz garantiert werden. Konsistenz und Verfügbarkeit können jedoch nicht gleichzeitig erreicht werden; jeder wird zu einem Opfer des anderen priorisiert. Ein Gleichgewicht muss erreicht werden. Daten müssen über eine Identität zugänglich sein. Skute ist beispielsweise ein Mechanismus, der auf Schlüssel-/Wertspeicher basiert, der eine dynamische Datenzuordnung effizient ermöglicht. Jeder Server muss mit einem Label in Form eines kontinentalen Ländercenter-Raum-Rack-Servers identifiziert werden. Der Server kann mehrere virtuelle Knoten referenzieren, wobei jeder Knoten eine Auswahl von Daten (oder mehrere Partitionen mehrerer Daten) aufweist. Jedes Datenstück wird durch einen Schlüsselraum identifiziert, der von einer einwegigen kryptographischen Hashfunktion (z.B. MD5) erzeugt wird und durch den Hash-Funktionswert dieses Schlüssels lokalisiert wird. Der Schlüsselraum kann in mehrere Partitionen aufgeteilt werden, wobei jede Partition sich auf ein Stück Daten bezieht. Zur Replikation müssen virtuelle Knoten repliziert und von anderen Servern referiert werden. Um die Daten Haltbarkeit und Datenverfügbarkeit zu maximieren, müssen die Repliken auf verschiedenen Servern platziert werden und jeder Server sollte in einer anderen geografischen Lage sein, da die Datenverfügbarkeit mit der geografischen Vielfalt zunimmt. Der Prozess der Replikation umfasst eine Auswertung der Raumverfügbarkeit, die über einem bestimmten Mindestdresh-hold auf jedem chunk-Server liegen muss. Andernfalls werden Daten an einen anderen chunk-Server repliziert. Jede Partition, i, hat einen Verfügbarkeitswert repräsentiert durch die folgende Formel: a v a i l i = Σ i = 0 | s i ∑ Σ j = i + 1 | s i  . c o n f i . c o n f j . d i v e r s i t y ( s i , s j ) I=0^{i{s{i}}\sum j=i+1{|{|s_{i}}conf_{i}.conf_{j}.diversity(s_{i},s_{j) wobei s i {\displaystyle s_{i} die Server sind, die die Repliken hosten, c o n f i {\displaystyle conf_{i} und c o n f j {\displaystyle conf_{j} das Vertrauen von Servern i {\displaystyle {_i} und j\displaystyle {_j} sind, die auf technische Faktoren wie Hardwarekomponenten und nicht-technische .Replikation ist eine große Lösung, um die Datenverfügbarkeit zu gewährleisten, aber es kostet zu viel in Bezug auf Speicherplatz. DiskReduce ist eine modifizierte Version von HDFS, die auf RAID-Technologie (RAID-5 und RAID-6) basiert und eine asynchrone Kodierung von replizierten Daten ermöglicht. In der Tat gibt es einen Hintergrundprozess, der nach weit replizierten Daten sucht und zusätzliche Kopien nach der Kodierung entfernt. Ein weiterer Ansatz ist, die Replikation durch Löschen Codierung zu ersetzen. Um die Datenverfügbarkeit zu gewährleisten, gibt es viele Ansätze, die eine Datenrettung ermöglichen. In der Tat müssen die Daten kodiert werden, und wenn sie verloren ist, können sie aus Fragmenten zurückgewonnen werden, die während der Kodierungsphase aufgebaut wurden. Einige andere Ansätze, die verschiedene Mechanismen anwenden, um die Verfügbarkeit zu gewährleisten, sind: Reed-Solomon-Code von Microsoft Azure und RaidNode für HDFS. Auch Google arbeitet noch an einem neuen Ansatz basierend auf einem Lösch-Coding-Mechanismus. Es gibt keine RAID-Implementierung für Cloud-Speicher. Wirtschaftsaspekte Die Cloud Computing-Wirtschaft wächst rapide. Die US-Regierung hat beschlossen, 40 % ihrer jährlichen Wachstumsrate (CAGR) auszugeben, die voraussichtlich bis 2015 7 Milliarden Dollar betragen dürfte. Immer mehr Unternehmen nutzen Cloud Computing, um die massive Datenmenge zu verwalten und die fehlende Speicherkapazität zu überwinden, und weil es ihnen ermöglicht, solche Ressourcen wie einen Service zu nutzen, um sicherzustellen, dass ihre Rechenanforderungen erfüllt werden, ohne in Infrastruktur investieren zu müssen (Pay-as-you-go-Modell). Jeder Anwendungsanbieter muss regelmäßig die Kosten jedes Servers bezahlen, an dem Repliken von Daten gespeichert werden. Die Kosten eines Servers werden durch die Qualität der Hardware, der Speicherkapazitäten und deren Abfrage- und Kommunikations-Overhead bestimmt. Cloud Computing ermöglicht es Anbietern, ihre Dienste nach Kundenanforderungen zu skalieren. Das Pay-as-you-go-Modell hat auch die Belastung für Startup-Unternehmen, die von einem rechnerintensiven Geschäft profitieren möchten, erleichtert. Cloud Computing bietet auch eine Möglichkeit für viele Drittstaaten, die solche Computing-Ressourcen sonst nicht haben würden. Cloud Computing kann IT-Hardware für Innovation senken. Trotz der breiten Nutzung von Cloud Computing ist der effiziente Austausch großer Datenmengen in einer nicht vertrauenswürdigen Cloud immer noch eine Herausforderung. Referenzen Bibliographie Andrew, S.Tanenbaum; Maarten, Van Steen (2006). Verteilte Systemprinzipien und Paradigmen (PDF). Fabio Kon (1996)." Distributed File Systems, The State of the Art and concept of Ph.D Thesis". CiteSeerX 10.1.1.42.4609 Pavel Bžoch. "Distributed File Systems Past, Present and Future A Distributed File System for 2006 (1996") (PDF). Sonnen-Mikrosystem. "Verteilte Dateisysteme – eine Übersicht" (PDF). Jacobi, Tim-Daniel; Lingemann, Jan. "Evaluation of Distributed File Systems" (PDF). Architektur, Struktur und Design: Zhang, Qi-fei; Pan, Xue-zeng; Shen, Yan; Li, Wen-juan (2012)."Eine neuartige skalierbare Architektur des Cloud-Speichersystems für kleine Dateien basierend auf P2P".2012 IEEE International Conference on Cluster Computing Workshops.Coll.of Comput.Sci & Technol., Zhejiang Univ., Hangzhou, China.p 41.doi:10.1109/ClusterW.2012.27.ISBN 978-0-7695-4844-9. S2CID 12430485.Azzedin, Farag (2013). " Auf dem Weg zu einer skalierbaren HDFS-Architektur".2013 International Conference on Collaboration Technologies and Systems (CTS). Information und Informatik Abteilung King Fahd University of Petroleum and Minerals.pp.155–161 doi:10.1109/CTS.2013.6567222.ISBN 978-1-4673-6404-1.S2CID 45293053.Krzyzanowski, Paul (2012)."Verteilte Dateisysteme" (PDF). Kobayashi, K; Mikami, S; Kimura, H; Tatebe, O (2011). Das Gfarm Dateisystem auf Compute Clouds. Parallele und verteilte Bearbeitungsworkshops und Phd Forum (IPDPSW), 2011 IEEE International Symposium on. Grad.Sch.of Syst. & Inf.Eng, Univ. von Tsukuba, Tsukuba, Japan.doi:10.1109/IPDPS.2011.255.Humbetov, Shamil (2012)." Datenintensives Computing mit Map-Reduce und Hadoop".2012 6. Internationale Konferenz zur Anwendung von Informations- und Kommunikationstechnologien (AICT). Abteilung Informatik Qafqaz Universität Baku, Aserbaidschan.pp.1–5.doi:10.1109/ICAICT.2012.6398489.ISBN 978-1-4673-1740-5.S2CID 6113112.Hsiao, Hung-Chang; Chung, Hsueh-Yi; Shen, Haiying; Chao, Yu-Chang (2013). Nationale Cheng Kung University, Tainan. "Load Rebalancing for Distributed File Systems in Clouds". Parallele und verteilte Systeme, IEEE Transactions on.24 (5): 951–962.doi:10.1109/TPDS.2012.196 S2CID 11271386. Kai, Fan; Dayang, Zhang; Hui, Li; Yintang, Yang (2013). " An Adaptive Feedback Load Balancing Algorithm in HDFS".2013 5. Internationale Konferenz zu Intelligent Networking und Collaborative Systems. State Key Lab. of Integrated Service Networks, Xidian Univ., Xi'an, China.pp.23–29.doi:10.1109/INCoS.2013.14.ISBN 978-0-7695-4988-0.S2CID 14821266. Upadhyaya, B; Azimov, F; Doan, T.T; Choi, Eunmi; Kim, Sangbum; Kim, Pilsung (2008)." Distributed File System: Efficiency Experiments for Data Access and Communication".2008 Vierte Internationale Konferenz zum Netzwerk Computing und Advanced Information Management. Sch.of Bus.IT, Kookmin Univ., Seoul.pp.400–405.doi:10.1109/NCM.2008.164.ISBN 978-0-7695-3322-3.S2CID 18933772. Soares, Tiago S.; Dantas†, M.A.R; de Macedo, Douglas D.J; Bauer, Michael A (2013)."A Datenmanagement in einer privaten Cloud-Speicherumgebung unter Nutzung von hochleistungsverteilten Dateisystemen".2013 Workshops zu Enabling Technologies: Infrastruktur für Collaborative Enterprises.nf & Statistic Dept. (INE), Fed.Univ.of Santa Catarina (UFSC), Florianopolis, Brasilien.pp.158–163.doi:10.1109/WETICE.2013.12.ISBN 978-1-4799-0405-1.S2CID 6155753.Adamov, Abzetdin (2012)." Verteiltes Dateisystem als Grundlage für datenintensives Computing".2012 6. Internationale Konferenz zur Anwendung von Informations- und Kommunikationstechnologien (AICT). Comput.Eng.Dept, Qafqaz Univ., Baku, Azerbaijan.pp.1–3.doi:10.1109/ICAICT.2012.6398484.ISBN 978-1-4673-1740-5.S2CID 16674289.Schwan Philip (2003). Cluster File Systems, Inc."Lustre: Aufbau eines Dateisystems für 1.000-Node Cluster" (PDF). Proceedings of the 2003 Linux Symposium: 400–407.Jones, Terry; Koniges, Alice; Yates, R. Kim (2000). Lawrence Livermore National Laboratory."Performance des IBM General Parallel File Systems" (PDF). Paralleles und verteiltes Bearbeitungssymposium, 2000.IPDPS 2000.Proceedings.14. International. Weil, Sage A.; Brandt, Scott A.; Miller, Ethan L.; Long, Darrell D. E. (2006). "Ceph: Ein skalierbares, hochwirksames verteiltes Dateisystem" (PDF). University of California, Santa Cruz. Maltzahn, Carlos; Molina-Estolano, Esteban; Khurana, Amandeep; Nelson, Alex J.; Brandt, Scott A.; Weil, Sage (2010). "Ceph als skalierbare Alternative zum Hadoop Distributed FileSystem" (PDF.) S.A, Brandt; E.L, Miller; D.D.E, Long; Lan, Xue (2003). "Effiziente Metadatenverwaltung in großen verteilten Speichersystemen".20. IEEE/11. NASA Goddard Conference on Mass Storage Systems and Technologies, 2003.(MSST 2003). Proceedings. Storage Syst.Res Center, California Univ., Santa Cruz, CA, USA.pp.290–298.CiteSeerX 10.1.1.13.2537.doi:10.1109/MASS.2003.1194865.ISBN 978-0-7695-1914-2.S2CID 5548463. Garth A., Gibson; Rodney, MVan Meter (November 2000). " Network Attached Storage Architecture" (PDF). Kommunikation der ACM.43 (11): 37–45.doi:10.1145/353360.353362.S2CID 207644891.Yee, Tin; Thu Naing, Thinn (2011). "PC-Cluster-basierte Speichersystemarchitektur für Cloud-Speicher".arXiv:1112.2025 [cs.DC].Cho Cho, Khaing; Thinn Thu, Naing (2011). " Das effiziente Datenspeicher-Management-System auf Cluster-basiertem Private Cloud-Datenzentrum".2011 IEEE International Conference on Cloud Computing and Intelligence Systems.pp.235–239.doi:10.1109/CCIS.2011.6045066.ISBN 978-1-61284-203-5.S2CID 224635.S.A, Brandt; E.L, Miller; D.D.E, Long; Lan, Xue (2011). " Eine trägerorientierte serviceorientierte Dateispeicherarchitektur für Cloud Computing".2011 3. Symposium über Web Society.PCN&CAD Center, Beijing Univ.of Posts & Telecommun., Beijing, China.pp.16–20.doi:10.1109/SWS.2011.6101263.ISBN 978-1-4577-0211-2.S2CID 14791637.Ghemawat, Sanjay; Gobioff, Howard; Leung, Shun-Tak (2003). "Das Google-Dateisystem". Proceedings of the neunteenth ACM Symposium on Operating systems Principles – SOSP '03.pp.29–43.doi:10.1145/945445.945450.ISBN 978-1-58113-757-6.S2CID 221261373.Security Vecchiola, C; Pandey, S; Buyya, R (2009). " High-Performance Cloud Computing: Ein Blick auf wissenschaftliche Anwendungen".2009 10. Internationales Symposium über Pervasive Systeme, Algorithmen und Netzwerke. Dept of Comput.Sci & Software Eng., Univ.of Melbourne, Melbourne, VIC, Australia.pp.4–16.arXiv:0910.1979.doi:10.1109/I-SPAN.2009.150.ISBN 978-1-4244-5403-7. S2CID 1810240. Miranda, Mowbray; Siani, Pearson (2009). "Ein Client-basierter Datenschutzmanager für Cloud Computing". Verfahren der Vierten Internationalen ICST-Konferenz über das Kommunikationssystem softWAre und midwaRE – COMSWARE '09.p 1.doi:10.1145/1621890.1621897.ISBN 978-1-60558-353-2.S2CID 10130310.Naehrig, Michael; Lauter, Kristin (2013). "Kann homomorphe Verschlüsselung praktisch sein?". Proceedings of the 3. ACM Workshop on Cloud Computing Security Workshop – CCSW '11.pp.113–124.CiteSeerX 10.1.1.225.8007.doi:10.1145/2046660.2046682.ISBN 978-1-4503-1004-8.S2CID 12274859.Du, Hongtao; Li, Zhanhuai (2012). " PsFS: Ein hochdurchsatzparalleles Dateisystem für sicheres Cloud-Speichersystem".2012 Internationale Konferenz zum Messen, Information und Control (MIC).1.Comput.Coll, Northwestern Polytech. Univ, Xi'An, China.pp.327–331.doi:10.1109/MIC.2012.6273264.ISBN 978-1-4577-1604-1.S2CID 40685246.A.Brandt, Scott; L.Miller, Ethan; D.E.Long, Darrell; Xue, Lan (2003). Storage Systems Research Center University of California, Santa Cruz."Efficient Metadata Management in Large Distributed Storage Systems" (PDF).11. NASA Goddard Conference on Mass Storage Systems and Technologies, San Diego, CA. Lori M. Kaufman (2009). " Datensicherheit in der Welt der Cloud Computing". Sicherheit & Datenschutz, IEEE.7 (4): 161–64.doi:10.1109/MSP.2009.87.S2CID 16233643.Bowers, Kevin; Juels, Ari; Oprea, Alina (2009). HAIL: eine hochverfügbare und Integritätsschicht für Cloud-SpeicherComputing. Proceedings of the 16th ACM Conference on Computer and Communications Security.pp.187–198.doi:10.1145/1653662.1653686.ISBN 978-1-60558-894-0.S2CID 207176701. Juels, Ari; Oprea, Alina (Februar 2013)."Neue Ansätze zur Sicherheit und Verfügbarkeit von Cloud-Daten". Mitteilungen der ACM.56 (2): 64–73.doi:10.1145/2408776.2408793.S2CID 17596621. Zhang, Jing; Wu, Gongqing; Hu, Xuegang; Wu, Xindong (2012)."A Distributed Cache for Hadoop Distributed File System in Echtzeit Cloud Services".2012 ACM/IEEE 13.International Konferenz zu Grid Computing. Von Comput. Sci, Hefei Univ. von Technol., Hefei, China.pp.12–21.doi:10.1109/Grid.2012.17.ISBN 978-1-4673-2901-9.S2CID 10778240.A, Pan; J.P, Walters; V.S, Pai; D.-I.D, Kang; S.P, Crago (2012)." Integration von High Performance File Systems in eine Cloud Computing Environment.2012 SC Companion: High Performance Computing, Networking Storage und Analysis. Von Electr. & Comput.Eng., Purdue Univ., West Lafayette, IN, USA.pp.753–759.doi:10.1109/SC.Companion.2012.103.ISBN 978-0-7695-4956-9. S2CID 5554936. Fan-Hsun, Tseng; Chi-Yuan, Chen; Li-Der, Chou; Han-Chieh, Chao (2012). " Implementieren Sie ein zuverlässiges und sicheres Cloud verteiltes Dateisystem".2012 Internationales Symposium zu Intelligent Signal Processing and Communications Systems. Dept of Comput.Sci & Inf.Eng, Nat.Central Univ., Taoyuan, Taiwan.pp.227–232 doi:10.1109/ISPACS.2012.6473485.ISBN 978-1-4673-5082-2.S2CID 18260943. Di Sano, M; Di Stefano, A; Morana, G; Zito, D (2012). " Dateisystem As-a-Service: Bereitstellung von transienten und konsistenten Ansichten von Dateien, um Anwendungen in Clouds zu kooperieren."2012 IEEE 21st International Workshop on Enabling Technologies: Infrastruktur für kollaborative Unternehmen. Dept of Electr., Electron. & Comput.Eng, Univ. of Catania, Catania, Italy.pp.173–178.doi:10.1109/WETICE.2012.104.ISBN 978-1-4673-1888-4.S2CID 19798809. Zhifeng, Xiao; Yang, Xiao (2013). "Sicherheit und Datenschutz in Cloud Computing".IEEE Communications Surveys and Tutorials.15 (2): 843–859.CiteSeerX 10.1.1.707.3980.doi:10.1109/SURV.2012.060912.00182.S2CID 206583820.John B, Horrigan (2008). "Benutzung von Cloud Computing-Anwendungen und -Diensten" (PDF). Yau, Stephen; An, Ho (2010)." Vertraulichkeitsschutz in Cloud-Computing-Systemen". Int J Software Informatics: 351–365.Carnegie, Bin Fan; Tantisiriroj, Wittawat; Xiao, Lin; Gibson, Garth (2009). "Reduzieren". DiskReduce: RAID für datenintensive skalierbares Computing.pp.6–10.doi:10.1145/1713072.1713075.ISBN 978-1-60558-883-4. S2CID 15194567. Wang, Jianzong; Gong, Weijiao; P., Varman; Xie, Changsheng (2012). " Reducing Storage Overhead mit Small Write Bottleneck Vermeiden in Cloud RAID System".2012 ACM/IEEE 13.Internationale Konferenz zum Grid Computing.pp.174–183.doi:10.1109/Grid.2012.29.ISBN 978-1-4673-2901-9. S2CID 16827141. Abu-Libdeh, Hussam; Princehouse, Lonnie; Weatherspoon, Hakim (2010). RACS: ein Fall für die Vielfalt der Cloud-Speicher. SoCC '10 Proceedings of the 1. ACM Symposium on Cloud Computing.pp.229–240.doi:10.1145/1807128.1807165.ISBN 978-1-4503-0036-0.S2CID 1283873. Vogels, Werner (2009). " Letztendlich konsequent". Kommunikation der ACM.52 (1): 40–44.doi:10.1145/1435417.1435432.Cuong, Pham; Cao, Phuong; Kalbarczyk, Z; Iyer, R.K (2012). " Zu einer hohen Verfügbarkeitswolke: Techniken und Herausforderungen". IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN 2012).S.1–6.doi:10.1109/DSNW.2012.6264687.ISBN 978-1-4673-2266-9.S2CID 9920903.A, Undheim; A., Chilwan; P., Heegaard (2011.) "Differentiated Verfügbarkeit in Cloud Computing SLAs".2011 IEEE/ACM 12.International Konferenz zu Grid Computing.pp.129–136.doi:10.1109/Grid.2011.25.ISBN 978-1-4577-1904-2.S2CID 15047580. Qian, Haiyang; D., Medhi; T., Trivedi (2011). "Ein hierarchisches Modell, um die Qualität der Erfahrung von Online-Diensten, die von Cloud Computing gehostet werden, zu bewerten." Kommunikation der ACM.52 (1): 105–112.CiteSeerX 10.1.1.190.5148.doi:10.1109/INM.2011.5990680.S2CID 15912111. Ateniese, Giuseppe; Burns, Randal; Curtmola, Reza; Herring, Joseph; Kissner, Lea; Peterson, Zachary; Song, Dawn (2007)."Provable data ownership at untrusted stores". Verfahren der 14. ACM-Konferenz zur Sicherheit von Computern und Kommunikation – CCS '07.pp.598–609.doi:10.1145/1315245.1315318.ISBN 978-1-59593-703-2.S2CID 8010083.Ateniese, Giuseppe; Di Pietro, Roberto; V. Mancini, Luigi; Tsudik, Gene (2008). "Skalierbarer und effizienter nachweisbarer Datenbesitz". Proceedings der 4. internationalen Konferenz zum Thema Sicherheit und Datenschutz in Kommunikationsnetzen – Secure Comm '08.p 1.CiteSeerX 10.1.1.208.8270.doi:10.1145/1460877.1460889.ISBN 978-1-60558-241-2.S2CID 207170639.Erway, Chris; Küpçü, Alptekin; Tamassia, Roberto; Papamanthou, Charalampos (2009)."Dynamic nachweisbarer Datenbesitz". Proceedings of the 16th ACM Konferenz zum Thema Computer- und Kommunikationssicherheit – CCS '09.pp.213–222.doi:10.1145/1653662.1653688.ISBN 978-1-60558-894-0.S2CID 52856440. Juels, Ari; S. Kaliski, Burton (2007). Pors: Nachweise der Abrufbarkeit für große Dateien. Verfahren der 14. ACM-Konferenz über Computer und Kommunikation.pp.584–597.doi:10.1145/1315245.1315317.ISBN 978-1-59593-703-2.S2CID 6032317.Bonvin, Nicolas; Papaioannou, Thanasis; Aberer, Karl (2009). " Ein selbstorganisiertes, fehlertolerantes und skalierbares Replikationsschema für Cloud-Speicher". Verfahren des 1. ACM-Symposiums auf Cloud Computing – SoCC '10.pp.205–216.doi:10.1145/1807128.1807162.ISBN 978-1-4503-0036-0.S2CID 3261817.Tim, Kraska; Martin, Hentschel; Gustavo, Alonso; Donald, Kossma (2009). " Konsistenz Rationierung in der Cloud: zahlen nur, wenn es wichtig ist". 2 (1): 253–264. doi:10.14778/1687627.1687657.Daniel, J. Abadi (2009)." Datenmanagement in der Cloud: Einschränkungen und Chancen". CiteSeerX 10.1.1.178.200 Ari, Juels; S., Burton; Jr, Kaliski (2007)."Pors: Nachweise der Abrufbarkeit für große Dateien". Kommunikation der ACM.56 (2): 584–597.doi:10.1145/1315245.1315317.S2CID 6032317.Ari, Ateniese; Randal, Burns; Johns, Reza; Curtmola, Joseph; Herring, Burton; Lea, Kissner; Zachary, Peterson; Dawn, Song (2007)."Provable data stores at CCS '07 Proceedings of the 14. ACM Konferenz über Computer- und Kommunikationssicherheit.pp.598–609.doi:10.1145/1315245.1315318.ISBN 978-1-59593-703-2.S2CID 8010083.Synchronisation Uppoor, S; Flouris, M.D; Bilas, A (2010). "Cloud-basierte Synchronisation verteilter Dateisystemhierarchien".2010 IEEE International Conference on Cluster Computing Workshops and Posters (CLUSTER WORKSHOPS). Inst of Comput.Sci.(ICS), gefunden. for Res. & Technol. -Hellas (FORTH), Heraklion, Greece.pp.1–4.doi:10.1109/CLUSTERWKSP.2010.5613087.ISBN 978-1-4244-8395-2. S2CID 14577793. Wirtschaftsaspekte Lori M., Kaufman (2009). " Datensicherheit in der Welt der Cloud Computing". Sicherheit & Datenschutz, IEEE.7 (4): 161–64.doi:10.1109/MSP.2009.87.S2CID 16233643.Marston, Sean; Lia, Zhi; Bandyopadhyaya, Subhajyoti; Zhanga, Juheng; Ghalsasi, Anand (2011). Cloud Computing — Die Geschäftsperspektive. Entscheidungsunterstützungssysteme Band 51, Ausgabe 1.pp.176–189 doi:10.1016/j.dss.2010.12.006.Angabini, A; Yazdani, N; Mundt, T; Hassani, F (2011). " Eignung von Cloud Computing für wissenschaftliche Datenanalyse Anwendungen; eine empirische Studie.2011 Internationale Konferenz zu P2P, Parallel, Grid, Cloud und Internet Computing. Sch of Electr. & Comput.Eng, Univ. von Teheran, Teheran, Iran.pp.193–199.doi:10.1109/3PGCIC.2011.37.ISBN 978-1-4577-1448-1.S2CID 13393620. Die School of Names (chinesisch: ‡; pinyin: Míngjiā), manchmal genannt die School of Forms and Names (chinesisch: ός; pinyin: Xíngmíngjiā; Wade–Giles: Hsing2-ming2-chia1), war eine Schule der chinesischen Philosophie, die während der Warring-Staaten in 479–221 BCE aus dem Mohismus wuchs. Die Anhänger der Namensschule wurden manchmal als Logicians oder Disputers bezeichnet. Überblick Die Philosophie der Logicians gilt oft als ähnlich zu denen der Sophisten oder der Dialektiker. Joseph Needham stellt fest, dass ihre Werke verloren gegangen sind, mit Ausnahme der teilweise erhaltenen Gongsun Longzi und der Paradoxe von Kapitel 33 des Zhuangzi. Needham betrachtet das Verschwinden des größten Teils von Gongsun Longzi als einen der schlimmsten Verluste in den alten chinesischen Büchern, da das, was bleibt, den höchsten Punkt der alten chinesischen philosophischen Schrift erreichen soll. Eines der wenigen überlebenden Linien der Schule, "ein Ein-Fuß-Stick, jeden Tag nehmen Sie die Hälfte davon, in einem myriaden Alter wird es nicht erschöpft", ähnelt Zenos Paradoxen. Einige ihrer anderen Aphorismen scheinen jedoch widersprüchlich oder unklar zu sein, wenn sie aus dem Kontext genommen werden, zum Beispiel: "Dogs sind keine Hündinnen. " Sie waren gegen die späteren Mohisten wegen ihrer Paradoxen. Geschichte Krieger Staaten Ära Philosophen Den Haag Xi, Yin Wen, Hui Shi, Gongsun Lange waren alle mit der Schule der Namen verbunden. Siehe auch Geschichte der LogikMozi Referenzen Citations Sources Fraser, Chris (6. November 2015). In Zalta, Edward N. (Hrsg.). Stanford Encyclopedia of Philosophy.Graham, A.C (1993), Disputers of the Tao: Philosophisches Argument im alten China, Open Court, ISBN 0-8126-9087-7 Needham, Joseph (1956), Wissenschaft und Zivilisation in China, 2 Geschichte des wissenschaftlichen Denkens, ISBN 0-521-05800-7 Hansen, Chad (2000), "The School of Names: Linguo Analysis in China", A. Solomon, Bernard S. (2013), On the School of Names in Ancient China, Sankt Augustin: Institut Monumenta Serica, Steyler Verlag, ISBN 978-3-8050-0610-1 Reding, Jean-Paul (1985), Les fondements philosophiques de la rhetorique chez les sophistes grecs et chez les sophistes chinois, Berne: Lang Van Norden, Einleitung Externe Links Medien im Zusammenhang mit der Schule der Namen bei Wikimedia Commons