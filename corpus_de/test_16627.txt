Ein Arbeitsplatz ist ein spezieller Computer für technische oder wissenschaftliche Anwendungen. In erster Linie von einer Person zu einem Zeitpunkt verwendet werden, sind sie häufig mit einem lokalen Netzwerk verbunden und führen Multi-User-Betriebssysteme. Der Begriff Workstation wurde auch lose verwendet, um sich auf alles von einem Mainframe-Computer-Endgerät auf einen PC zu beziehen, der mit einem Netzwerk verbunden ist, aber die häufigste Form bezieht sich auf die Klasse der Hardware, die von mehreren aktuellen und defunct Unternehmen wie Sun Microsystems, Silicon Graphics, Apollo Computer, DEC, HP, NeXT und IBM angeboten wird, die die Tür für die 3D-Grafikenanimationsrevolution der späten der 1990er geöffnet. Workstations bieten eine höhere Leistung als Mainstream-Personalcomputer, insbesondere in Bezug auf CPU und Grafik, Speicherkapazität und Multitasking-Fähigkeit. Workstations sind optimiert für die Visualisierung und Manipulation verschiedener Arten komplexer Daten wie 3D-mechanisches Design, Engineering-Simulationen (z.B. Rechenflüssigkeitsdynamik), Animation und Rendering von Bildern und mathematischen Plots. Typischerweise ist der Formfaktor der eines Desktop-Computers, besteht aus einem hochauflösenden Display, einer Tastatur und einer Maus auf einem Minimum, bietet aber auch mehrere Displays, Grafik-Tabletten, 3D-Mäuse (Geräte zum Manipulieren von 3D-Objekten und Navigationsszenen), etc. Workstations waren das erste Segment des Computermarktes, um fortschrittliche Zubehör- und Kollaborationstools zu präsentieren. Die zunehmenden Fähigkeiten von Mainstream-PCs in den späten 1990er Jahren haben die Linien zwischen PCs und technischen/wissenschaftlichen Arbeitsplätzen verwischt. Typische Workstations setzten zuvor proprietäre Hardware ein, die sie von PCs unterscheidet; z.B. verwendete IBM RISC-basierte CPUs für seine Workstations und Intel x86 CPUs für seine Business/Consumer-PCs während der 1990er und 2000er Jahre. Jedoch, von den frühen 2000er Jahren dieser Unterschied weitgehend verschwunden, da Workstations jetzt hochkomoditierte Hardware von großen PC-Anbietern dominiert, wie Dell, Hewlett-Packard (später HP Inc. und Hewlett Packard Enterprise) und Fujitsu, Verkauf von Microsoft Windows- oder Linux-Systemen auf x86-64 Prozessoren. Geschichte Ursprung und Entwicklung Vielleicht war der erste Computer, der als Workstation qualifizieren könnte, der IBM 1620, ein kleiner wissenschaftlicher Computer, der von einer einzigen Person, die an der Konsole sitzt, interaktiv verwendet werden soll. Es wurde 1960 eingeführt. Eine Besonderheit der Maschine war, dass es keine tatsächliche arithmetische Schaltung fehlte. Um die Ergänzung durchzuführen, benötigte sie eine Memory-Resident-Tabelle von Dezimal Addition Regeln. Dies gespeichert auf den Kosten der Logikschaltung, so dass IBM es kostengünstig zu machen. Die Maschine wurde codiert CADET und zunächst für $1000 im Monat gemietet. Im Jahr 1965 führte IBM den IBM 1130 wissenschaftlichen Computer ein, der als Nachfolger des 1620. Beide Systeme haben die Möglichkeit, Programme in Fortran und anderen Sprachen zu führen. Sowohl die 1620 als auch die 1130 wurden in etwa Schreibtischschränke gebaut. Beide waren mit Add-On-Disk-Laufwerken, Druckern und sowohl Papier-Tape als auch Lochkarte I/O erhältlich. Ein Konsolenschreiber für direkte Interaktion war auf jedem Standard. Frühe Beispiele für Arbeitsplätze waren in der Regel dedizierte Minicomputer; ein System zur Unterstützung einer Reihe von Benutzern wäre stattdessen ausschließlich für eine Person reserviert. Ein bemerkenswertes Beispiel war der PDP-8 der Digital Equipment Corporation, der als erster kommerzieller Minicomputer angesehen wurde. Die Lisp-Maschinen, die Anfang der 1970er Jahre am MIT entwickelt wurden, haben einige der Prinzipien des Workstation-Computers hervorgebracht, da es sich um leistungsstarke, vernetzte Single-User-Systeme handelte, die für den stark interaktiven Einsatz bestimmt sind. Lisp Machines wurden Anfang 1980 von Unternehmen wie Symbolics, Lisp Machines, Texas Instruments (der TI Explorer) und Xerox (die Interlisp-D-Workstations) vertrieben. Der erste Computer, der für einen Single-User konzipiert wurde, mit hochauflösenden Grafikeinrichtungen (und so eine Workstation im modernen Sinne des Begriffs) war der 1973 bei Xerox PARC entwickelte Xerox Alto. Zu den weiteren frühen Arbeitsplätzen gehören der Terak 8510/a (1977) Three Rivers PERQ (1979) und der spätere Xerox Star (1981). In den frühen 1980er Jahren, mit dem Aufkommen von 32-Bit-Mikroprozessoren wie der Motorola 68000, erschien eine Reihe neuer Teilnehmer in diesem Bereich, darunter Apollo Computer und Sun Microsystems, die Unix-basierte Workstations auf Basis dieses Prozessors erstellt. Mittlerweile hat das VLSI-Projekt von DARPA mehrere Spinoff-Grafiken-Produkte erstellt, insbesondere das SGI 3130, und die darauffolgenden Maschinen von Silicon Graphics.Es war nicht ungewöhnlich, den Zielmarkt für die Produkte zu unterscheiden, mit Sun und Apollo betrachtete als Netzwerk-Workstations, während die SGI-Maschinen Grafik-Workstations waren. Da RISC-Mikroprozessoren Mitte der 1980er Jahre zur Verfügung standen, wurden diese von vielen Workstation-Anbietern übernommen. Workstations neigen dazu, sehr teuer zu sein, in der Regel mehrmals die Kosten eines Standard-PCs und manchmal Kosten so viel wie ein neues Auto. Allerdings kosten Minicomputer manchmal so viel wie ein Haus. Die hohen Kosten kamen in der Regel aus der Verwendung von kostspieligen Komponenten, die schneller lief als die im lokalen Computerspeicher gefunden, sowie die Einbeziehung von Funktionen, die nicht in PCs der Zeit gefunden wurden, wie High-Speed-Netzwerken und anspruchsvolle Grafiken. Workstation-Hersteller neigen auch dazu, einen ausgewogenen Ansatz für die Systemgestaltung zu treffen, um sicherzustellen, Engpässe zu vermeiden, so dass Daten ungehindert zwischen den vielen verschiedenen Subsystemen innerhalb eines Computers fließen können. Zusätzlich, Workstations, angesichts ihrer spezialisierteren Natur, neigen dazu, höhere Gewinnspannen zu haben als Waaren-getriebene PCs. Die Systeme, die aus Workstation-Unternehmen kommen, verfügen oft über SCSI- oder Fibre Channel-Speichersysteme, High-End 3D-Beschleuniger, einzelne oder mehrere 64-Bit-Prozessoren, große Mengen RAM und gut gestaltete Kühlung. Darüber hinaus haben die Unternehmen, die die Produkte machen, in der Regel umfangreiche Reparatur- / Ersatzpläne. Als Unterschied zwischen Workstation und PC Fades haben die Workstation-Hersteller jedoch zunehmend "off the Regal" PC-Komponenten und Grafiklösungen anstelle von proprietären Hardware oder Software eingesetzt. Einige kostengünstige Workstations sind nach PC-Standards noch teuer, bieten aber binäre Kompatibilität mit High-End-Workstations und Servern, die von demselben Anbieter hergestellt werden. Dies ermöglicht die Softwareentwicklung auf kostengünstigen (relativ zum Server) Desktop-Maschinen. Graphics Workstations Graphics Workstations (z.B. Maschinen von Silicon Graphics) werden oft mit Grafikbeschleunigern ausgeliefert. Dünne Clients und X Terminals Es gab mehrere Versuche, eine Workstation-ähnliche Maschine speziell für den niedrigsten Preispunkt im Gegensatz zur Leistung zu produzieren. Ein Ansatz ist die lokale Speicherung zu entfernen und die Maschine auf den Prozessor, Tastatur, Maus und Bildschirm zu reduzieren. In einigen Fällen würden diese  Diskless-Knoten noch ein traditionelles Betriebssystem ausführen und lokal Berechnungen durchführen, mit Speicherung auf einem Remote-Server. Diese Ansätze sollen nicht nur die anfänglichen System-Kaufkosten reduzieren, sondern die Gesamtbetriebskosten senken, indem der pro Benutzer benötigte Verwaltungsaufwand reduziert wird. Dieser Ansatz wurde ursprünglich als Ersatz für PCs in Office-Produktivitätsanwendungen versucht, mit der 3Station von 3Com als ein frühes Beispiel; in den 1990er Jahren erfüllten X-Terminals eine ähnliche Rolle für das technische Computing. Sun hat auch "dünne Kunden", vor allem seine Sun Ray Produktlinie eingeführt. Die traditionellen Arbeitsplätze und PCs sinken jedoch weiterhin im Preis, was dazu neigt, den Markt für Produkte dieser Art zu unterschneiden. "3M-Computer"In den frühen 1980er Jahren musste eine High-End-Workstation die drei Ms erfüllen. Der sogenannte "3M-Computer" hatte ein Megabyte-Speicher, ein Megapixel-Display (etwa 1000 x 1000) und eine MegaFLOPS-Compute-Performance (mindestens eine Million Floating-Point-Operationen pro Sekunde). Wie dies heute scheint, war es mindestens eine Größenordnung über die Kapazität des Personalcomputers der Zeit hinaus; das Original 1981 IBM Personal Computer hatte 16 KB Speicher, eine Text-only-Display und Floating-Point-Leistung rund 1 KiloFLOPS (30 KiloFLOPS mit dem optionalen 8087 Mathe Coprozessor). Andere wünschenswerte Merkmale, die in Desktop-Computern damals nicht gefunden wurden, umfassten Netzwerk-, Grafikbeschleunigung- und Hochgeschwindigkeits-interne und periphere Datenbusse. Ein weiteres Ziel war es, den Preis für ein solches System unter einem Megapenny, d.h. weniger als 10.000 zu bringen; dies wurde erst in den späten 1980er Jahren erreicht, obwohl viele Workstations, insbesondere Mid-Range oder High-End immer noch Kosten von $15.000 bis $100.000 und über die ganze Anfang bis Mitte der 1990er Jahre. Tendenzen zum Rückgang Die stärker verbreitete Einführung dieser Technologien in Mainstream-PCs war ein direkter Faktor für den Rückgang der Arbeitsplätze als separates Marktsegment: Hochleistungs-CPUs: Während RISC in seinen frühen Tagen (vor 1980er Jahren) etwa eine Auftrags-of-Magnitude-Leistungsverbesserung gegenüber CISC-Prozessoren mit vergleichbaren Kosten bot, hatte eine bestimmte Familie von CISC-Prozessoren, Intels x86, immer den Rand des Marktanteils und die Skaleneffekte, die dies implizierte.Bis Mitte der 1990er-Jahre hatten einige x86 CPUs in einigen Bereichen Performance mit RISC erzielt, wie z.B. Integer-Leistung (wenn auch zu den Kosten einer größeren Chip-Komplexität), die letztere auf noch höhere Märkte zum größten Teil überträgt. Hardware-Unterstützung für Floating-Point-Operationen: optional auf dem ursprünglichen IBM-PC; blieb auf einem separaten Chip für Intel-Systeme bis zum 80486DX-Prozessor. Auch damals lag die x86-Schwebungs-Punkt-Performance aufgrund von Einschränkungen in ihrer Architektur weiterhin hinter anderen Prozessoren. Heute haben sogar preiswerte PCs nun Leistung im GigaFLOPS-Bereich. Große Speicherkonfigurationen: PCs (d.h. IBM-kompatible) waren ursprünglich bis zur Einführung des 80286 Prozessors auf eine Speicherkapazität von 640 KB beschränkt (nicht börsengespeicherte "expanded Memory"); frühe Workstations haben Zugriff auf mehrere Megabyte Speicher. Auch nach dem Abbruch der 640 KB-Grenze mit dem 80286 wurden spezielle Programmiertechniken benötigt, um signifikante Speichermengen bis zum 80386 zu adressieren, im Gegensatz zu anderen 32-Bit-Prozessoren wie SPARC, die einen einfachen Zugriff auf fast ihren gesamten 4 GB Speicheradressenbereich ermöglichten. 64-Bit-Workstations und Server, die einen Adressbereich weit über 4 GB unterstützen, sind seit Anfang der 1990er-Jahre verfügbar, eine Technologie beginnt erst Mitte der 2000er-Jahre im PC-Desktop- und Servermarkt zu erscheinen. Betriebssystem: Frühe Workstations führten das Unix-Betriebssystem (OS), eine Unix-ähnliche Variante, oder ein nicht verwandten gleichwertiges Betriebssystem wie VMS. Die PC-CPUs der Zeit hatten Einschränkungen in Speicherkapazität und Speicherzugriffsschutz, so dass sie ungeeignet, um Betriebssysteme dieser Raffinesse laufen zu lassen, aber auch dies begann in den späten 1980er Jahren zu ändern, als PCs mit den 32-Bit 80386 mit integrierten ppaged MMUs wurde weitestgehend erschwinglich. Hochgeschwindigkeitsnetz (10 Mbit/s oder besser:) 10 Mbit/s Netzwerkschnittstellen waren für PCs bereits Anfang der 1990er Jahre allgemein verfügbar, obwohl die Workstations damals noch höhere Netzwerkgeschwindigkeiten verfolgten, sich auf 100 Mbit/s, 1 Gbit/s und 10 Gbit/s bewegten. Allerdings haben die Skaleneffekte und die Nachfrage nach Highspeed-Netzwerken in sogar nicht-technischen Gebieten die Zeit, die es braucht, um neuere Vernetzungstechnologien zu erreichen, drastisch verringert. Große Displays (17- bis 21-Zoll) mit hohen Auflösungen und hoher Erfrischungsrate, die in den späten 1980er- und frühen 1990er-Jahren unter PCs selten waren, aber bis Ende der 1990er-Jahre unter PCs verbreitet wurden. High-Performance 3D-Grafik-Hardware für computergestütztes Design (CAD) und computergenerierte Imagery (CGI)-Animation: Obwohl dies im PC-Markt um die Mitte der 1990er-Jahre immer beliebter wird, die meist von Computerspielen angetrieben werden. Für Nvidia hat die Integration der Transformations- und Beleuchtungshardware in die GPU selbst die GeForce 256 neben älteren 3D-Beschleunigern eingestellt, die auf die CPU angewiesen sind, um diese Berechnungen durchzuführen (auch als Software-Transformation und Beleuchtung bekannt). Diese Reduktion der 3D-Grafiklösungskomplexität brachte die Kosten solcher Hardware auf ein neues Low und machte es für billige Verbraucher-Grafikkarten zugänglich, anstatt auf die bisher teure, professionell ausgerichtete Nische für computergestütztes Design (CAD) beschränkt zu sein. Die T&L-Engine von NV10 ermöglichte Nvidia zum ersten Mal den Einstieg in den CAD-Markt, mit der Quadro-Linie, die die gleichen Siliziumchips wie die GeForce-Karten verwendet, aber verschiedene Fahrerunterstützung und Zertifizierungen, die auf die einzigartigen Anforderungen von CAD-Anwendungen zugeschnitten sind. Allerdings konnten die Benutzer das GeForce so weichmodieren, dass es viele der Aufgaben für den viel teureren Quadro durchführen könnte. Hochleistungs-/Hochleistungsdatenspeicher: Früharbeitsplätze neigen dazu, proprietäre Festplattenschnittstellen bis zum Erscheinen des SCSI-Standards Mitte der 1980er Jahre zu verwenden. Obwohl SCSI-Schnittstellen bald für PCs zur Verfügung standen, waren sie vergleichsweise teuer und tendenziell durch die Geschwindigkeit des PCs ISA Peripheriebus begrenzt (obwohl SCSI auf dem Apple Macintosh Standard wurde). SCSI ist eine fortschrittliche Controller-Schnittstelle, die besonders gut ist, wenn die Festplatte mehrere Anfragen auf einmal bewältigen muss. Dies macht es für den Einsatz in Servern geeignet, aber seine Vorteile für Desktop-PCs, die meist Einzelbenutzer-Betriebssysteme laufen, sind weniger klar. In diesen Tagen, mit Desktop-Systemen, die mehr Multi-User-Funktionen erwerben, ist die neue Festplatten-Schnittstelle der Wahl Serial ATA, die einen Durchsatz vergleichbar mit SCSI, aber zu einem geringeren Kosten. Extrem zuverlässige Komponenten: zusammen mit mehreren CPUs mit größerem Cache- und Fehlerkorrekturspeicher kann dies heute das Unterscheidungsmerkmal einer Workstation bleiben.Obwohl die meisten in modernen Arbeitsplätzen implementierten Technologien auch zu niedrigeren Kosten für den Verbrauchermarkt zur Verfügung stehen, gute Komponenten zu finden und sicherzustellen, dass sie miteinander kompatibel arbeiten, ist eine große Herausforderung im Workstation Building. Da Workstations für High-End-Aufgaben wie Wettervorhersagen, Video-Rendering und Spieldesign konzipiert sind, ist es selbstverständlich, dass diese Systeme unter Volllast laufen müssen, nicht-stop für mehrere Stunden oder sogar Tage ohne Probleme. Jegliche nicht-the-shelf Komponenten können verwendet werden, um eine Workstation zu bauen, aber die Zuverlässigkeit solcher Komponenten unter solchen strengen Bedingungen ist unsicher. Aus diesem Grund werden fast keine Arbeitsplätze vom Kunden selbst gebaut, sondern von einem Anbieter wie Hewlett-Packard / HP Inc., Fujitsu, IBM / Lenovo, Sun Microsystems, SGI, Apple oder Dell gekauft. Enge Integration zwischen dem Betriebssystem und der Hardware: Workstation-Anbieter entwerfen die Hardware und halten die Unix-Betriebssystemvariante, die darauf läuft. Dies ermöglicht viel strengere Tests als mit einem Betriebssystem wie Windows möglich ist. Windows erfordert, dass Drittanbieter von Hardware konforme Hardwaretreiber schreiben, die stabil und zuverlässig sind. Auch geringe Variation der Hardwarequalität wie Timing oder Build-Qualität kann die Zuverlässigkeit der gesamten Maschine beeinflussen. Workstation-Anbieter sind in der Lage, sowohl die Qualität der Hardware, als auch die Stabilität der Betriebssystemtreiber durch die Validierung dieser Dinge im eigenen Haus zu gewährleisten, was zu einer allgemein viel zuverlässigeren und stabileren Maschine führt. Platz auf dem Markt Seit der Wende des Jahrtausends hat sich die Definition der Arbeitsplätze in gewissem Maße verwischt. Viele der Komponenten, die in unteren Arbeitsstationen verwendet werden, sind jetzt die gleichen wie im Verbrauchermarkt, und die Preisdifferenz zwischen der unteren Arbeitsstation und den Verbraucher-PCs kann enger sein als einmal war (und in bestimmten Fällen im High-End-Verbrauchermarkt, wie der Enthusiasten-Spielmarkt, kann es schwierig sein, zu sagen, was als "Desktop-PC" und eine Workstation"). In einem anderen Fall hat die Grafikkarte Nvidia GeForce 256 den Quadro, der die gleiche GPU hatte, aber verschiedene Treiberunterstützung und Zertifizierungen, die auf die einzigartigen Anforderungen von CAD-Anwendungen zugeschnitten und für einen viel höheren Preis im Handel gehalten wurden, so dass viele die GeForce als arm-man's Workstation-Karte nutzten, da die Hardware weitgehend so fähig war und sie weich modifiziert werden konnte, um die Funktionen nominell exklusiv für den Quadro zu entsperren. Workstations waren in der Regel die Treiber von Fortschritten in der CPU-Technologie. Obwohl sowohl der Verbraucher-Desktop als auch die Workstation von CPUs profitieren, die um das Multicore-Konzept entwickelt wurden (im Wesentlichen, mehrere Prozessoren auf einer Düse, deren Anwendung IBMs POWER4 ein Pionier war), verwenden moderne Workstations typischerweise mehrere Multicore-CPUs, Fehlerkorrekturspeicher und viel größere On-die-Caches als die auf Consumer-Level-CPUs gefunden. Solche Leistung und Zuverlässigkeit sind normalerweise nicht auf einem allgemeinen Desktop-Computer erforderlich. IBMs POWER-basierte Prozessor-Boards und die Intel-basierten Xeon-Prozessor-Boards von Workstation-Level verfügen beispielsweise über mehrere CPUs, mehr On-die-Cache- und ECC-Speicher, die besser für anspruchsvolle Content-Creation, Engineering und wissenschaftliche Arbeit geeignet sind als für allgemeine Desktop-Computing. Einige Workstations sind für den Einsatz mit nur einer spezifischen Anwendung wie AutoCAD, Avid Xpress Studio HD, 3D Studio Max, etc. konzipiert. Um die Kompatibilität mit der Software zu gewährleisten, bitten Käufer gewöhnlich ein Zertifikat des Softwareanbieters. Der Zertifizierungsprozess macht den Preissprung der Workstation mehrere Einkerbungen, aber für professionelle Zwecke kann die Zuverlässigkeit wichtiger sein als die ersten Kaufkosten. Aktueller Arbeitsmarkt Decline von RISC-basierten Arbeitsplätzen Bis Januar 2009 wurden alle RISC-basierten Workstation-Produktlinien eingestellt: SGI beendete im Dezember 2006 die allgemeine Verfügbarkeit seiner MIPS-basierten SGI Fuel und SGI Tezro-Workstations. Hewlett-Packard hat im Januar 2008 die letzten HP 9000 PA-RISC-basierten Desktop-Produkte aus dem Markt gebracht. Sun Microsystems kündigte Ende-of-life für seine letzten Sun Ultra SPARC Workstations im Oktober 2008 an. IBM trat am 2. Januar 2009 in den Ruhestand des IntelliStation POWER. Anfang 2018 wurde die Wiedereinführung kommerziell erhältlicher RISC-basierter Arbeitsplätze in Form einer Reihe von IBM POWER9-basierten Systemen von Raptor Computing Systems eingeführt. Wechsel zu x86-64 Arbeitsplätzen Der aktuelle Arbeitsplatzmarkt verwendet x86-64 Mikroprozessoren.Zu den für diese Plattformen verfügbaren Betriebssystemen gehören Microsoft Windows, FreeBSD, verschiedene Linux-Distributionen, Apple macOS (früher OS X,) und Oracle Solaris. Einige Anbieter vermarkten auch Waren-Mono-Socket-Systeme als Workstations. Unter dem Dach der Arbeitsplätze werden drei Arten von Produkten vermarktet: Workstation Klingensysteme (IBM HC10 oder Hewlett-Packard xw460c. Sonnenvisualisierung System ist für diese Lösungen geeignet) Ultra High-End-Workstation (SGI Virtu VS3xx)Deskside-Systeme mit Server-Klasse-CPUs und Chipsätzen auf großen Server-Klasse Mainboards mit High-End-RAM (HP Z-Serie Workstations und Fujitsu CELSIUS Workstations) Definition von Arbeitsplätzen Ein bedeutendes Segment des Desktop-Marktes sind Computer, die als Workstations, aber mit PC-Betriebssystemen und Komponenten zu erwarten sind. Komponentenhersteller werden oft ihre Produktlinie segmentieren und Premium-Komponenten vermarkten, die den billigeren Verbrauchermodellen funktionell ähnlich sind, aber eine höhere Robustheit oder Leistung aufweisen. Ein Workstation-Class-PC kann einige der folgenden Funktionen haben: Unterstützung für ECC-SpeicherLarger Anzahl von Speichersteckdosen, die registrierte (gepufferte) Module Mehrere Prozessorsteckdosen verwenden, leistungsstarke CPUs Mehrere Displays Führen Sie zuverlässiges Betriebssystem mit erweiterten Funktionen Siehe auch Liste der Computersystemhersteller Musikarbeitsplatz Personal Supercomputer Remote Graphics Software Notes == Referenzen = Neue Deutsche Biographie (NDB; buchstäblich Neue deutsche Biographie) ist ein biografisches Referenzwerk. Es ist der Nachfolger der Allgemeinen Deutschen Biographie (ADB, Universal German Biography). Die bisher 26 veröffentlichten Bände umfassen mehr als 22.500 Personen und Familien, die im deutschen Sprachraum lebten. NDB wird in deutscher Sprache von der Historischen Kommission an der Bayerischen Akademie der Wissenschaften veröffentlicht und von Duncker & Humblot in Berlin gedruckt. Die Index- und Volltextartikel der ersten 25 Bände sind online über die Website Deutsche Biographie und das Biographische Portal frei verfügbar. Scope NDB ist ein umfassendes Referenzwerk, ähnlich dem Wörterbuch der National Biographie, Wörterbuch der American Biography, American National Biography, Dictionary of Canadian Biography, Dictionary of Australian Biography, Dictionary of New Zealand Biography, Diccionario Biográfico Español, Dictionary of Irish Biography, Svenskt biografiskt lexikon und Österreichisches Biographisches Lexikon 1815-1950 (ÖBL) (ÖBL. Sein erstes Band, das die Namen von Aachen nach Behaim alphabetisch abdeckt, wurde 1953 veröffentlicht. Ab 2016 ist das jüngste Band das 26., das Namen von Tecklenburg nach Vocke abdeckt, das im Oktober 2016 veröffentlicht wurde. Bisher wurden mehr als 22.500 Biographien von Individuen und Familien veröffentlicht, die im deutschen Sprachraum (Sprachraum) lebten. Etwa 1.600 weitere Artikel werden in zwei weiteren Bänden hinzugefügt, wobei die Fertigstellung im Jahr 2021 erwartet wird. Ein NDB-Artikel enthält in der Regel genealogische Informationen wie Datum und Ort der Geburt, Datum und Ort des Todes, Grab, Eltern, Großeltern, Ehen, Scheidungen, Anzahl der Kinder, Wechsel- und Geburtsnamen, akademische Grad, ein Lehrplan vitae in ganzen Sätzen, eine Bewertung der politischen, wirtschaftlichen, sozialen, wissenschaftlichen, technischen oder künstlerischen Leistungen, eine Bibliographie und Referenzen zu Porträts. Es werden nur verstorbene Personen mit einer engen Beziehung zum deutschen Sprachraum aufgenommen. Jeder Artikel wird von seinem Autor signiert. Zugang Ein Index, der alle Artikel und den vollständigen Text der Artikel in den ersten 26 Bänden katalogisiert und Namen von Aachen bis Vocke abdeckt, ist online frei verfügbar. Der Index ist auch Teil des Biographie-Portals (Biographical Portal). Dieses Kooperationsprojekt der Bayerischen Staatsbibliothek (Bayerische Staatsbibliothek,) der Historischen Kommission an der Bayerischen Akademie der Wissenschaften (Historische Kommission bei der Bayerischen Akademie der Wissenschaften), der Österreichischen Akademie der Wissenschaften (Österreichische Akademie der Wissenschaften) der Stiftung Historisches Wörterbuch der Schweiz, und der Slowenischen Akademie der Wissenschaften und Künste stellt auch Daten der Allgemeinen Deutschen Biographie (ADB,) Österreichisches Biographische Biographische Biographie Historique de la Suisse / Dizionario Storico della Svizzera (HLS / DHS / DSS,) Slovenska Biografija, Rheinland-Pfälzische Personendatenbank (RPPB,) Sächsische Biografie (Saxon Biography,) und Oesterreichisches Musiklexikon (OeML.)Bände Veröffentlichungsdetails Neue deutsche Biographie / herausgegeben von der Historischen Kommission bei der Bayerischen Akademie der Wissenschaften. Berlin: Duncker & Humblot, seit 1953.ISBN 3-428-00181-8. Siehe auch Allgemeine Deutsche Biographie Biographie Biographie Biographical Portal Referenzen Reinert, Matthias, Schrott, Maximilian, Ebneth, Bernhard, Rehbein, Malte, Team Deutsche Biographie et al., Von Biographien bis Data Curation: The Making of www.deutsche-biographie.de, in: BD2015. Biografische Daten in einer digitalen Welt. Proceedings of the First Conference on Biographical Data in a Digital World 2015. Amsterdam, Niederlande, 9. April 2015, ed.by. Serge ter Braake, Antske Fokkens, Ronald Sluijter, Thierry Declerck, Eveline Wandl-Vogt, CEUR Workshop Proceedings Vol-1399.pp.13–19 Deutsche Biographie (Deutsche Biographie) – Volltextartikel, Index und weitere Informationen Biographical Portal (Biographie-Portal) – Vollständiger Index Neue Deutsche Biographie Neue Deutsche Biographie (Duncker & Humblot)Historische Kommission bei der Bayerischen Akademie der Wissenschaften München Digitalisierungszentrum, Digitale Bibliothek der Bayerischen Staatsbibliothek