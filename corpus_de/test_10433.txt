Lern-Klassen-Systeme oder LCS sind ein Paradigma von regelbasierten maschinellen Lernmethoden, die eine Entdeckungskomponente (z.B. einen genetischen Algorithmus) mit einem Lernelement verbinden (Beaufsichtigung entweder Lernen, Stärkung des Lernens oder unüberwachtes Lernen). Lernklassifizierungssysteme versuchen, eine Reihe kontextabhängiger Regeln zu ermitteln, die gemeinsam das Wissen speichern und anwenden, um Vorhersagen (z.B. Verhaltensmuster, Klassifizierung, Data Mining, Regression, Funktionsangleichung oder Spielstrategie) zu erstellen. In diesem Ansatz können komplexe Lösungsräume in kleinere, einfachere Teile zerbrochen werden. Die Gründungskonzepte hinter Lern-Klassenifier-Systemen kamen aus Versuchen, komplexe Anpassungssysteme zu entwickeln, wobei auf Regelbasis ein künstliches kognitives System (d. h. künstliche Intelligenz) eingesetzt wird. Methodik Architektur und Komponenten eines bestimmten Lernklasse-Systems können sehr unterschiedlich sein. Es ist sinnvoll, eine LCS als eine Maschine zu betrachten, die aus verschiedenen Interaktionskomponenten besteht. Komponenten können hinzugefügt oder gestrichen werden, oder bestehende Komponenten, die entsprechend den Anforderungen eines bestimmten Problembereichs (wie z.B. Algorische Bausteine) geändert oder beseitigt werden oder den Algorithmus flexibel genug gestalten, um in vielen verschiedenen Problembereichen zu funktionieren. Infolgedessen kann das LCS- Paradigmen flexibel auf viele Problembereiche angewendet werden, die für das maschinelle Lernen werben. Die wichtigsten Abschnitte der LCS-Durchführung sind: (2) Stärkung des Lernprozesses gegen das kontrollierte Lernen, (3) Incremental Learning vs. Chargenlernen, (4) Online-Learning vs. offline Lernen, (5) stärkebasierte Fitness vs. Präzisions-Effizienz und (6) vollständige Aktionskartierung im Vergleich zu Best Action Mapping. Diese Spaltungen sind nicht unbedingt gegenseitig ausschließlich. XCS, der am besten bekannte und am besten untersuchte LCS-Algorithmus, wurde zum Ausbau des Lernens entwickelt, kann aber auch das beaufsichtigte Lernen durchführen, incrementales Lernen, das entweder online oder offline erfolgen kann, eine auf Genauigkeit basierende Fitness anwendet und eine vollständige Aktionskartierung angestrebt. Elemente eines generischen LCS-Algorithmus Denken Sie daran, dass LCS ein Paradigma für genetisches Maschinenbau und nicht eine spezifische Methode ist, die folgenden Schlüsselelemente eines generischen, modernen (d. h. post-XCS)LCS-Algorithmus skizziert. Lassen Sie uns einfach auf die Rechtsarchitektur in den USA mit überwachtem Lernen konzentrieren. Siehe die Abbildungen auf dem Recht, die auf diese Art von Generika ausgerichteten Folgeschritte festzulegen. Umwelt Umwelt ist die Quelle von Daten, bei denen ein LCS lernt. Es kann sich um eine Offline-, Finnit-Ausbildungsdatenset (Beschreibung eines Data Mining, Klassifizierung oder Regressionsproblem) oder ein Online-Sequentielles Straffung von Live-Trainings-Stellen handeln. Jede Schulung wird davon ausgegangen, dass eine Reihe von Merkmalen (auch als Eigenschaften oder unabhängige Variablen bezeichnet) und ein einheitlicher Endpunkt von Interesse (auch als Klasse, Maßnahme, Phenotyp, Vorhersage oder abhängige Variablen bezeichnet) enthalten. Teil des Lernens von LCS kann eine Merkmalsauswahl beinhalten, daher müssen nicht alle Merkmale der Schulungsdaten informativer sein. Kennzeichnende Werte eines Verfahrens werden häufig als Staat bezeichnet. Einfachheit lässt sich ein Beispiel für Problembereich mit den Merkmalen von Boolean/binary und einer Doppelklasse annehmen. In der Regel wird ein Beispiel aus der Umwelt auf jedem Lernzyklus (d. h. incrementalem Lernen) ausgebildet. Leistungsstarke Systeme in Pittsburgh führen das Chargenlernen durch, in denen die Regelsets jeweils über viel oder alle Ausbildungsdaten bewertet werden. Regel/Klassen/Bevölkerung Regel ist ein Kontext, der von den Staatswerten und einigen Vorhersagen abhängig ist. Regelmäßig werden Regeln in Form eines {IF:THEN} Ausdruck, (z.B. {IF Bedingung THEN-Maßnahmen,} oder als spezifisches Beispiel, {IF rot UND Octagon THEN-Stop-sign)}. Ein kritisches Konzept in LCS und regelbasiertes Maschinenlernen ist, dass eine individuelle Regel nicht in sich selbst ein Modell ist, da die Regel nur anwendbar ist, wenn ihre Bedingung erfüllt ist. Denken Sie an eine Regel als lokales Modell des Lösungsraums. Regeln können in vielen verschiedenen Arten von Daten (z.B. binäre, diskrete, ordinale, kontinuierliche Daten) vertreten werden. LCS gilt traditionell für eine terne Regelvertretung (d. h. die Vorschriften können entweder eine 0, 1 oder „#“ für jedes einzelne Merkmal in den Daten enthalten). Das Symbol „Nichtversorgung“ (d. h. „#“) dient als Wildkarte innerhalb eines Regelzustands, der Regeln und das System als Ganzes erlaubt, die Beziehungen zwischen den Merkmalen und dem angestrebten Ziel-Endpunkt zu allgemeinisieren. Erwägung der folgenden Regel (1#0 ~ 1) (d. h. Bedingung ~ Aktion). Diese Regel kann als: IF das zweite Merkmal = 1 und das sechste Merkmal = 0THEN die Klassenprognose = 1. Wir würden sagen, dass die zweiten und sechsten Merkmale in dieser Regel angegeben wurden, während die anderen allgemeinisiert wurden. Diese Regel und die entsprechende Vorhersage gelten nur dann, wenn die Bedingung der Regel vom Beispiel erfüllt ist. Dies wird häufiger als gleichgestellt. In der Regel hat LCS seine eigene Eignung sowie eine Reihe anderer mit ihm verknüpfter Regelparameter, die die Anzahl der Exemplare dieser Regel beschreiben können, die (d. h. die Nummernzahl), das Alter der Regel, ihre Richtigkeit oder die Richtigkeit der Belohnungsvorhersagen sowie andere beschreibende oder erfahrungsgemäße Statistiken. Häufig wird eine Regel in Verbindung mit ihren Parametern als Klassenprüfer bezeichnet. In den IT-Systemen sind die Klassenstellen in einer Bevölkerung [P] enthalten, die eine Benutzergruppe mit einer maximalen Anzahl von Klassenstellen hat. LCS-Bevölkerung beginnen nicht leer (d. h. es besteht keine Notwendigkeit, eine Regelbevölkerung zu paraphieren). Klassenstellen werden stattdessen zunächst an die Bevölkerung mit einem Abdeckungsmechanismus eingeführt. In jedem LCS ist das ausgebildete Modell eine Reihe von Regeln/Klassen und nicht jede einzelne Regel/Klassen. LCS ist der gesamte ausgebildete (und fakultative, kompakte) Klassenempfänger. Abstimmung Eines der kritischsten und oft zeitaufwendigen Elemente eines LCS ist der Vergleichsprozess. Der erste Schritt in einem LCS-Lernzyklus ist ein einziges Trainingsbeispiel aus der Umwelt und führt ihn in [P], wo die Abstimmung stattfindet. In Schritt 2 ist jede Regel in [P] nun im Vergleich zu der Ausbildungsmaßnahme, um zu sehen, welche Regeln entsprechen (d. h. im Kontext des aktuellen Verfahrens relevant sind). In Schritt 3 werden alle entsprechenden Regeln in ein Spiel gesetzt [M]. Eine Regel erfüllt ein Trainingsverfahren, wenn alle in der Regel angegebenen Merkmale dem entsprechenden Merkmalswert in der Ausbildung entsprechen. Unter der Voraussetzung, dass die Ausbildungsmaßnahme (001 ~ 0) ist, würden diese Regeln mit folgenden Punkten übereinstimmen: (0 ~ 0), (00##1 ~ 0), (#01001 ~ 1), aber diese Vorschriften würden nicht (1# ~ 0), (000#1 ~ 0), (0#1#0 ~ 1). Hinweis darauf, dass der in der Regel festgelegte Endpunkt/Aktion nicht berücksichtigt wird. Infolgedessen kann das Spiel Set Klassenstellen enthalten, die Konfliktmaßnahmen vorschlagen. Im vierten Schritt, da wir beaufsichtigtes Lernen durchführen, ist [M] in ein richtiges Set [C] und ein falsches Set [I] unterteilt. Es geht um eine entsprechende Regel, wenn sie die Korrekturmaßnahmen (auf der Grundlage der bekannten Maßnahme der Ausbildungsmaßnahme) vorschlägt, ansonsten geht es in [I]. LCS, ein Aktionsset [A], soll hier statt, da die Korrekturmaßnahmen nicht bekannt sind. Abdeckung In diesem Punkt im Lernzyklus, wenn keine Klassenstellen es entweder [M] oder [C] (wie wäre der Fall, wenn die Bevölkerung leer beginnt), wird der Erfassungsmechanismus angewendet. Abdeckung ist eine Form der Paraphierung der digitalen Bevölkerung. Ein Zufallsprinzip schafft eine Regel, die dem derzeitigen Trainingsfall (und im Falle des beaufsichtigten Lernens) entspricht, dass diese Regel auch mit der richtigen Maßnahme erzeugt wird. Unter der Bedingung, dass das Trainingsverfahren (001 ~ 0) eine der folgenden Regeln enthält: (0#0 ~ 0), (001 ~ 0), (010 ~ 0). Nicht nur gewährleistet, dass jeder Lernzyklus mindestens eine korrekte, stimmige Regel in [C] gibt, sondern dass jede in die Bevölkerung eingeführte Regel mindestens eine Ausbildung treffen wird. LCS verhindert, den Suchraum von Regeln zu erkunden, die nicht mit allen Ausbildungseinrichtungen übereinstimmen. Parameter Aktualisierungen/Kreditvergabe/Learning Im sechsten Schritt werden die Regelparameter jeder Regel in [M] aktualisiert, um die neuen Erfahrungen aus der aktuellen Ausbildung zu berücksichtigen. Je nach LCS-Algorithmus können in diesem Schritt eine Reihe von Aktualisierungen vorgenommen werden. Für die Überwachung des Lernens können wir einfach die Richtigkeit/Terrorisierung einer Regel aktualisieren. Genauigkeit/Terrorismus ist anders als die Modellgenauigkeit/Terrorismus, da sie nicht über die gesamten Ausbildungsdaten berechnet wird, sondern nur über alle Fälle, die es zusammenbringt. Die Richtigkeit der Rechtsstaatlichkeit wird berechnet, indem die Anzahl der Zeiten, die die Regel in einem korrekten Satz [C] durch die Zahl der Zeiten, die sie in einem Spiel gesetzt hat [M], aufgeteilt wurde. Regelgenauigkeit kann als „lokale Genauigkeit“ betrachtet werden. Qualität der Rechtsstaatlichkeit wird auch hier aktualisiert und wird allgemein als Funktion der Regelgenauigkeit berechnet. Das Konzept der Fitness wird direkt von klassischen genetischen Algorithmen übernommen. Kennen Sie, dass es viele Variationen gibt, wie LCS Parameter aktualisiert, um Kreditvergabe und Lernen durchzuführen. Vermutung Im siebten Schritt wird ein Subsumrationsmechanismus in der Regel angewendet. Subsumration ist ein expliziter allgemeiner Mechanismus, der Klassenaggregatoren zusammenbringt, die sich auf überflüssige Teile des Problems erstrecken. Der Subsuming-Klasserator nimmt effektiv den Subsumed-Klasser an (und hat seine Zahl erhöht). Dies kann nur passieren, wenn der Subsuming-Klasserator eher allgemein ist, genauso genau wie genau, und erstreckt sich auf den gesamten Problemraum des Subsums. Erkenntnis/genetical LCS nimmt im achten Schritt einen hoch elitistlichen genetischen Algorithmus (GA) an, der zwei Mutter-Klassen auf der Grundlage der Fitness (survival des Eignungstests) auswählen wird. Eltern werden in der Regel von [C] ausgewählt. Manche Systeme haben die Auswahl oder deterministische Auswahl von Porsche angewandt und haben unterschiedliche Elternregeln von [P] - Panmictic Auswahl oder von [M)] ausgewählt. Crossover und Mutation werden nun auf zwei neue Nachkommen angewandt. In diesem Punkt werden sowohl die Eltern- als auch die Nachkommen nach [P] zurückgekehrt. LCS-Gengorithmus ist hoch elitist, da jede Erlernung, die große Mehrheit der Bevölkerung erhalten bleibt. Man kann von einer anderen Methode, wie etwa einer Schätzung des Verteilungsgorithmus, eine GA hingegen bei weitem am häufigsten angewandt werden. Evolutionäre Algorithmen wie die GA beschäftigen eine katastrophale Suche, die LCS zu einem katastrophalen Algorithmus macht. LCS bemüht sich, den Suchraum sorgfältig zu erkunden, führt jedoch keine erschöpfende Suche nach Regelkombinationen durch und ist nicht garantiert, sich auf eine optimale Lösung zu verständigen. Streichung Letzter Schritt in einem generischen LCS Lernzyklus ist es, die maximale Bevölkerungsgröße beizubehalten. Der Streichungsmechanismus wird Klassenaggregatoren für die Streichung auswählen (häufig mit der Auswahl von Ersatzteilen). Die Wahrscheinlichkeit, dass ein für die Löschung ausgewählter Einstufungsempfänger im umgekehrten Verhältnis zu seiner Eignung steht. Wenn ein Klassenprüfer für die Löschung ausgewählt wird, wird sein numerischer Parameter um einen verringert. Wenn die Zahl der Klassenempfänger auf Null gesenkt wird, wird sie vollständig von der Bevölkerung entfernt. Schulung LCS wird durch diese Schritte wiederholt für einige Benutzer definierte Anzahl von Ausbildungsmaßnahmen oder bis einige Benutzer bestimmte Kündigungskriterien erfüllt haben. LCS wird für das Online-lernen ein völlig neues Trainingsbeispiel für jede Iteration aus der Umwelt erhalten. LCS wird für das Offline-lernen durch eine Finnit-Ausbildungsdatenset abstellen. Sobald es das letzte Beispiel im Datenset erreicht, wird es durch den Datenset wieder zum ersten Mal und Zyklus zurückkommen. Konsolidierungspakt Nach Abschluss der Ausbildung wird die Bevölkerung in der Regel unweigerlich einige arme, überflüssige und unerfahrene Regeln enthalten. Es ist üblich, eine Regel Compaction, oder eine Kondensation, die ertourismus als Nachverarbeitungsschritt anwendet. Diese konvergierte Regelbevölkerung ist bereit, als Vorhersagemodell (z.B. Vorhersagen zu Testfällen) anzuwenden und/oder für die Wissenserkennung zu interpretieren. Vorhersage Ob eine LCS-Algorithion angewendet wurde oder nicht, ist die Erzeugung eines LCS-Algorithmus eine Population von Klassenaggregaten, die für die Vorhersagen in bisher unangetasteten Fällen eingesetzt werden können. Der Vorhersagemechanismus ist nicht Teil des kontrollierten LCS-Lernzyklus selbst, aber es würde eine wichtige Rolle in einem verstärkten Lernzyklus von LCS spielen. Jetzt sind wir der Meinung, wie der Vorhersagemechanismus angewendet werden kann, um Vorhersagen für die Prüfung von Daten zu erstellen. Bei der Erstellung von Vorhersagen werden die LCS-Erklärungskomponenten so deaktiviert, dass die Bevölkerung nicht weiter von den neuen Testdaten lernen kann. Ein Testfall wird an [P] weitergegeben, wo ein Spielset [M] als üblich gebildet wird. In diesem Punkt wird das Spiel unterschiedlich auf eine Vorhersagebreite übertragen. Regeln in der Spielform können unterschiedliche Maßnahmen vorhersagen, weshalb eine Abstimmungsregelung angewendet wird. In einer einfachen Abstimmungsregelung gewinnt die Aktion mit der stärksten Unterstützung der Stimmen aus den entsprechenden Regeln und wird zur ausgewählten Vorhersage. Alle Regeln erhalten keine gleiche Abstimmung. Vielmehr ist die Stärke des Votums für eine einzige Regel im Verhältnis zu seiner Rechenleistung und Eignung. Diese Abstimmungsregelung und die Art der Speicherung von Wissen von LCS legen nahe, dass LCS-Algorithmen implizite Einschnitte enthalten. Interpretation einzelner LCS-Vorschriften sind in der Regel human lesbare IF: THEN Expression. Regeln, die das LCS-Prognosemodell bilden, können anhand unterschiedlicher Regelparameter und manuell überprüft werden. Globale Strategien zur Wissenserkennung mit statistischen und grafischen Daten wurden ebenfalls vorgeschlagen. In Bezug auf andere fortgeschrittene maschinelle Lernkonzepte, wie künstliche Neuralnetze, zufällige Wälder oder genetische Programmplanung, sind die Lernklassen-Systeme besonders gut geeignet, um Probleme zu lösen, die verdolmetschende Lösungen erfordern. Geschichte Frühjahre John Henry Holland war am besten bekannt für seine Arbeit, die genetischen Algorithmen (GA) durch sein bahnbrechendes Buch "Anpassung in natürlichen und künstlichen Systemen" im Jahr 1975 und seine formalisierung des Hollands Schemas. Holland entwickelte 1976 eine Erweiterung des GA-Konzepts auf das, was er als "kognitives System" bezeichnete, und stellte die erste ausführliche Beschreibung dessen vor, was als erstes Lern-Klassen-System im Papier "Cognitive Systeme auf der Grundlage von adaptiven Algorithmen" bekannt wird. Dieses erste System, das sogenannte Kognitive System One (CS-1), wurde als Modellinstrument konzipiert, mit dem ein echtes System (d.h. Umwelt) mit unbekannter zugrundeer Dynamik mit einer Population menschlicher lesbarer Regeln entwickelt werden soll. Ziel war eine Reihe von Regeln, um Online-Maschinenlernen durchzuführen, um sich an die Umwelt anpassen zu können, die auf einem seltenen Payoff/reward (d. h. einem verstärkten Lernen) basiert und diese Regeln für ein Verhalten anwenden, das dem realen System entspricht. Anfangs wurde eine ehrgeizige Umsetzung später als übermäßig komplex angesehen, was uneinheitliche Ergebnisse hervorbringt. Kenneth de Jong und sein Student Stephen Smith haben 1980 einen anderen Ansatz im Bereich der regelgestützten maschinellen Lernprozesse mit (LS-1), in dem das Lernen als Offline-Verbesserung und nicht als Online-Anpassung betrachtet wurde. Dieser neue Ansatz war ähnlich wie ein Standard-Gengorithmus, entwickelt aber unabhängige Regeln. LCS-Methoden, die durch den von Holland auf der University of Canada eingeführten Online- Lernrahmen inspiriert sind, wurden seit dieser Zeit als LCS bezeichnet, und diejenigen, die von Smith und De Jong an der Universität Pittsburgh inspiriert sind, wurden als LCS in Pittsburgh bezeichnet. Im Jahr 1986 entwickelte Holland das, was für das nächste Jahrzehnt als Standard-LKW in der Regel gilt. Andere wichtige Konzepte, die in den frühen Tagen der LCS-Forschung aufgetreten sind, umfassen (1) die formalisierung eines Ln Algorithmus (BBA) für die Kreditvergabe/Lernen, (2) die Auswahl der Elternregeln aus einer gemeinsamen „Environmentalen Nischen“ (d. h. der Spiellinie [M)] anstelle der gesamten Bevölkerung [P,] (3), die erste als Einrichtungsbetreiber eingeführt wurde, (4) die formalisierung eines Aktionsrahmens [A,] eine vereinfachte Architektur, (6)-basierte Fitness, (7) von Einzel- oder Lernprozessen (C) und die spätere Kombination von Fähigkeitssalgorithmen (8). Obwohl nicht alle diese Konzepte in modernen LCS-Algorithmen angewendet werden, waren die einzelnen Meilensteine bei der Entwicklung des LCS-Symptoms. Mitte der 90er Jahre wurde das revolutionäre Interesse an Lern-Klassenifier-Systemen weitgehend durch zwei Ereignisse gestärkt, die Entwicklung des Q-Learning-Algorithmus zur Stärkung des Lernens und die Einführung deutlich vereinfachter LCS-Architekturen von Stewart Wilson. Wilson's Zeroth-Level-Klasseifier System (ZCS) konzentrierte sich auf die Erhöhung der algorischen Verständlichkeit auf der Grundlage der Umsetzung von Hollands Standard LCS. Dies wurde zum Teil durch die Abschaffung von Regelversagen und der internen Botschaftsliste, die für die ursprüngliche BBA-Kreditvergabe unerlässlich ist, und durch eine Hybrid-BBA/Q-Learning-Strategie ersetzt. ZCS hat gezeigt, dass eine viel einfachere LCS-Architektur sowie die ursprünglichen, komplexeren Umsetzungen durchführen könnte. ZCS wurde jedoch immer noch von Leistungsrückschlägen gelitten, darunter die Verbreitung von Überallgemeinen Klassenstellen. Wilson veröffentlichte 1995 sein wegweisendes Papier, "Klassenifier Fitness basierend auf Genauigkeit", in dem er das System XCS eingeführt hat. XCS hat die vereinfachte Architektur von ZCS übernommen und eine auf Genauigkeit basierende Fitness hinzugefügt, eine Nischen GA (in der Aktion [A), eine explizite allgemeine Ausrichtungsmechanismus namens Subsumration und eine Anpassung der Q-Learning-Kreditvergabe. XCS wurde durch seine Fähigkeit, eine optimale Leistung zu erzielen, während sich genaue und maximale Allgemeinklasse sowie die beeindruckende Problemlösungsflexibilität (durch das verstärkte Lernen und das kontrollierte Lernen) entwickeln. XCS wurde später der am besten bekannte und am meisten untersuchte LCS-Algorithmus und definiert eine neue Familie von genaubasierten LCS. ZCS wurde alternativer als Synonym für leistungsfähiges LCS. XCS ist auch wichtig, weil es die Kluft zwischen LCS und dem Bereich des verstärkten Lernens erfolgreich überbrückt hat. Nach dem Erfolg von XCS wurde LCS später als Stärkung der Lernsysteme beschrieben, die mit einer allgemeinen Fähigkeit ausgestattet sind. Verstärktes Lernen soll in der Regel eine Wertfunktion erlernen, die eine vollständige Darstellung des staatlichen/aktionspolitischen Raums vorsieht. Desgleichen fördert das Design von XCS eine allumfassende und genaue Darstellung des Problemsraums (d. h. eine vollständige Karte) anstelle der Konzentration auf Hochrechnungs Nischen in der Umwelt (wie es mit dem starken LCS der Fall war). Konzepte, vollständige Karten lassen sich nicht nur erfassen, was Sie tun sollten, oder was richtig ist, sondern auch, was Sie nicht tun sollten oder was falsch ist. Unterschiedlich versuchen die leistungsstärksten LCSs oder ausschließlich kontrolliertes Lernen LCSs eine Regel für effiziente Generalisierungen in Form einer besten Aktionskarte (oder einer Teilkarte). Leistungsvergleiche zwischen Stärke und Genauigkeits-Effizienz und vollständigem Vergleich zu den besten Aktionskarten wurden inzwischen genauer untersucht. Nach dem XCS XCS XCS inspirierte die Entwicklung einer ganzen neuen Generation von LCS-Algorithmen und Anwendungen.Congdon war 1995 das erste Mal, LCS auf epidemiologische epidemiologische Untersuchungen anzuwenden, gefolgt von Holmes, der die BOOLE,+ EpiCS und später EpiXCS für die epidemiologische Einstufung entwickelt hat. Diese frühen Arbeiten haben später Interesse an der Anwendung von LCS-Algorithmen auf komplexe und groß angelegte Datengewinnungsaufgaben geweckt, die durch Bioinformatik-Anwendungen bestimmt sind. Stolzmann hat 1998 Antizipationssysteme (ACS) eingeführt, die Regeln in Form von „Einhaltungseffekten“ und nicht die klassische Bedingungsvertretung enthalten. ACS wurde so konzipiert, dass die Auswirkungen einer Maßnahme in allen möglichen Situationen in einem Umfeld vorhergesagt werden. In anderen Worten entwickelt das System ein Modell, das nicht nur das, was in einer bestimmten Situation zu tun ist, sondern auch Informationen darüber enthält, was nach einer bestimmten Maßnahme geschieht. Diese Familie von LCS-Algorithmen ist am besten geeignet für Multi-Level-Probleme, Planung, Beschleunigung des Lernens oder Verzweiflung per sektiver (d. h. wenn die gleiche Beobachtung in verschiedenen Staaten erzielt wird, aber unterschiedliche Maßnahmen erfordern). später verfolgte diese antizipatorische Familie von LCS eine Reihe von Verbesserungen an der ursprünglichen Methode. Wilson hat im Jahr 2002 XSF eingeführt, indem er eine kalkulierte Maßnahme einführte, um die Angleichung der Funktion zu gewährleisten. Im Jahr 2003 hat Bernado-Mansilla ein supervised Classifier System (UCS) eingeführt, das den XCS-Algorithmus auf die Aufgabe des kontrollierten Lernens, der Einzelprobleme und die Schaffung eines optimalen Maßnahmenpakets spezialisiert hat. UCS lehnte die verstärkte Lernstrategie zugunsten einer einfachen, präzisen Regeltauglichkeit sowie der Lernphasen für das Lernen ab, die von vielen verstärkten Lernenden geprägt sind. Bull hat ein einfaches, auf Genauigkeit basierendes LCS (YCS) und ein einfaches stärkebasiertes LCS-minitierungssystem (MCS) eingeführt, um ein besseres theoretisches Verständnis des LCS-Rahmens zu entwickeln. Bacardit führte GAssist und BioHEL, Pittsburgh-style LCSs zur Datengewinnung und -optimierung für große Datensets in Bioinformatikanwendungen ein. Im Jahr 2008 veröffentlichte Drogenowitsch das Buch mit dem Titel "Design and Analysis of Learning Classifier Systems" einschließlich einer theoretischen Prüfung von LCS-Algorithmen. Aberz hat die erste Regel für die Online-Abbildung im Rahmen eines LEONARDS eingeführt (siehe das Bild oben auf dieser Seite). Urbanowicz hat den UCS-Rahmen erweitert und ExSTraCS eingeführt, der ausdrücklich für die Überwachung des Lernens in lauten Problembereichen (z.B. Epidemiologie und Bioinformatik) konzipiert wurde. ExSTraCS integriert (1) Expertenwissen, um den genetischen Algorithmus auf wichtige Merkmale in den Daten auszuweiten, (2) eine Form des langfristigen Gedächtnisses, die als Attributverfolgung bezeichnet wird, die ein effizienteres Lernen und die Charakterisierung von heterogenen Datenmustern ermöglicht, und (3) eine flexible Regelvertretung, die der gemischten, getrennten Liste von Bacardit ähnelt. Sowohl Bacardit als auch Urbanowicz untersuchten statistische und visuelle Strategien zur Auslegung der LCS-Vorschriften und zur Kenntnisdeckung des Data Mining. Browne und Iqbal untersuchten das Konzept der Wiederverwendung von Bausteinen in Form von Code Fragmenten und waren das erste, um das 135-bit-Multixer-Benchmark-Problem durch erste nützliche Bausteine aus einfacheren Multiplexer-Problemen zu lösen. ExSTraCS 2.0 wurde später eingeführt, um die LCS-Schnittstelle in den USA zu verbessern und erstmals das 135-bit-Multixer-Benchmark-Problem zu lösen. Das n-bit-Multixer-Problem ist hoch epistatisch und heterogen, was es zu einer sehr anspruchsvollen maschinellen Lernaufgabe macht. Michigan Arizona-STAR-System für das Lernen LCSs zeichnen sich durch eine Bevölkerung von Regeln aus, in denen der genetische Algorithmus auf der Ebene der einzelnen Vorschriften tätig ist und die Lösung durch die gesamte Bevölkerung der Regel vertreten ist. Kanada-Stilllegungssysteme lernen auch incrementiv, was es ihnen ermöglicht, sowohl das verstärkte Lernen als auch das beaufsichtigte Lernen sowie das Online- und Offline-lernen durchzuführen. Kanada-style-Systeme haben den Vorteil, dass sie für eine größere Anzahl von Problembereichen gelten, und die einzigartigen Vorteile des inkrementellen Lernens. Pittsburgh-STAR-System Pittsburgh-STAR LCSs zeichnen sich durch eine Population variabler Länge-Reformen aus, in denen jede Regel eine Lösung ist. Der genetische Algorithmus ist in der Regel auf der Ebene einer ganzen Regel. Pittsburgh-style-Systeme können die bestellten Regellisten auch einzigartig entwickeln und eine Standardregel anwenden. Diese Systeme haben den natürlichen Vorteil, kleinere Regelsets zu ermitteln und diese Systeme im Hinblick auf die manuelle Überprüfung zu interpretieren. Hybridsysteme Systeme, die auf eine Kombination wichtiger Stärken beider Systeme abzielen, wurden ebenfalls vorgeschlagen. Leistungsfähigkeit: Sie können sich an ein sich veränderndes Umfeld im Falle des Online-Kurses aneignen. Modellfrei: Sie machen begrenzte Annahmen über die Umwelt oder die Formen der Vereinigung innerhalb der Daten. Sie können komplexe, epistatische, heterogene oder verteilte zugrunde liegende Muster ohne vorheriges Wissen modellieren. Sie machen keine Annahmen über die Anzahl der prädikativen oder nichtvorhersehbaren Merkmale in den Daten. Ensemble: Lernende Kein einziges Modell wird auf einen bestimmten Fall angewandt, der eine Vorhersage liefert. stattdessen trägt ein relevanter und oft widersprüchlicher Satz von Regeln zu einer Abstimmung bei, die als fuzzische Vorhersage interpretiert werden kann. Stochastic Learning: Non-deterministisches Lernen ist in großen oder komplexen Problemen vorteilhaft, in denen deterministische oder erschöpfende Lernprozesse untrennbar werden. implizite Multi-Ziele: Die Regeln entwickeln sich in Richtung Genauigkeit mit impliziten und expliziten Drucken, die eine größtmögliche Allgemeinheit/Vereinfachung fördern. Dieser implizite allgemeine Druck ist einzigartig für LCS. Mehr allgemeine Regeln werden in Spielsets häufiger erscheinen. wiederum haben sie häufiger die Möglichkeit, als Eltern ausgewählt zu werden, und über ihre allgemeineren (genome) Bestimmungen über die Nachkommen. Verdolmetschung: Im Interesse des Data-Mining und der Wissenssuche sind die einzelnen LCS-Vorschriften logisch und können als human interpretableIF dienen: THEN-Erklärungen. Wirksame Strategien wurden auch eingeführt, um eine globale Wissensdeckung zu ermöglichen, die wichtige Merkmale und Formen der Assoziierung von Bevölkerungsgruppen insgesamt beschreibt. flexible Anwendung Einzel- oder Multi-Level-Probleme Supervised, Verstärkung oder unüberwachtes Lernen bindet Klasse und Multi-Klassen-Regressionsdisziplin oder kontinuierliche Merkmale (oder eine Mischung beider Arten) saubere oder laute Problembereiche, die ausgeglichen oder unausgewogen sind. Keine Daten (d. h. fehlende Merkmalswerte in Ausbildungsfällen) Verfügbarkeit von Software-Software: Es gibt eine begrenzte Anzahl offener Quellen, zugängliche LCS-Durchführungen und sogar weniger, die für anwenderfreundliche oder zugängliche maschinenlesbare Lernende konzipiert sind. Interpretation: LCS-Algorithmen sind sicherlich mehr auszulegen als einige fortgeschrittene Maschinenlern, doch die Nutzer müssen eine Reihe von Regeln auslegen (etwa große Regelsätze für das LCS-Modell). Methoden zur Regel Compaction und Interpretationsstrategien sind nach wie vor ein Bereich der aktiven Forschung. Theorie/Konvergence Beweise: Es gibt eine relativ kleine theoretische Arbeit hinter LCS-Algorithmen. Wahrscheinlich ist dies aufgrund ihrer relativen algerischen Komplexität (in Anwendung einer Reihe von Interaktionskomponenten) sowie ihrer katastrophalen Natur. Nachrüstung: LCS kann wie jeder Werkzeugmaschinenlerner trotz impliziter und expliziter Generalisierungsdrucke unter einer Überrüstung leiden. Laufparameter: LCSs verfügen oft über viele Ausgangsparameter, um zu erwägen/optimisieren. In der Regel können die meisten Parameter in die Gemeinschaft festgelegte Standardfälle mit Ausnahme zweier kritischer Parameter fallen: Höchste Bevölkerungsgröße und die maximale Zahl der Lernerkenntnisse. Man kann diese Parameter wahrscheinlich sehr problematisch sein. Notorie: Trotz ihres Alters sind LCS-Algorithmen noch immer nicht weit verbreitet, auch in maschinenlesbaren Lerngemeinschaften. LCS-Algorithmen werden daher selten im Vergleich zu anderen etablierten maschinellen Lernkonzepten betrachtet. Dies ist wahrscheinlich auf die folgenden Faktoren zurückzuführen: (1) LCS ist ein relativ komplizierter Algorithmenansatz, (2) LCS, regelbasiertes Modelling ist ein anderes Modellmodell als fast alle anderen maschinenlesbaren Lernkonzepte. (3) LCS-Software-Durchführungen sind nicht so weit verbreitet. Kynly Expensive: LCS-Algorithmen können zwar realistischer sein als einige erschöpfende Ansätze. Für einfache, lineare Lernprobleme gibt es keine Notwendigkeit, ein LCS anzuwenden. LCS-Algorithmen eignen sich am besten für komplexe Problemräume oder Problemräume, in denen wenig vorheriges Wissen vorhanden ist. Problembereiche Data Mining Engineering Design-Produktauswahlfunktion Angleichung der Spiel-Play Image Klassifikation Knowledge Handling Medical Diagnosis Modell für Navigationsoptimierungsplanungsplanung für die Nutzung von LTE-Vorzugs-Strategie Terminologie „Learning Classifier System (LCS)“ ist ein wenig irreführend, da es viele maschinelle Lernalgorithmen gibt, die „LKW zur Einstufung“ (z.B. Entscheidungsbäume, künstliche Neuralnetze), aber nicht LCSs sind. Der Begriff „RBML“ ist nützlich, da er die wesentliche regelbasierte Komponente dieser Systeme genauer erfasst, aber auch allgemeinisiert Methoden, die nicht als LCS angesehen werden (z.B. das Assoziierungsgesetz oder künstliche Immunsystem). Mehr allgemeine Begriffe wie „genetikbasiertes Maschinenlernen,“ und sogar „genetischem Algorithmus“ wurden ebenfalls angewendet, um auf das zu verweisen, was charakteristischer als Lern-Klassen-System definiert würde. Infolge ihrer Ähnlichkeit mit genetischen Algorithmen werden in Pittsburgh-style-Systeme manchmal als „genetische Algorithmen“ bezeichnet. Darüber hinaus wurden einige LCS-Algorithmen oder eng damit zusammenhängende Methoden als „kognitive Systeme“, „angepasste Mittel“, „Produktionssysteme,“ oder allgemein als „classifier“-System bezeichnet. Diese Änderung der Terminologie trägt zu Verwirrung im Bereich bei. Bis zu den 2000er Jahren wurden fast alle Lern-Klassenifier-Systeme mit verstärkten Lernproblemen entwickelt. Infolgedessen wurde der Begriff „Lernklasseifier System“ allgemein als Kombination aus „Trial-and-Terror“ mit der globalen Suche nach einem genetischen Algorithmus definiert. Interesse an kontrollierten Lernanwendungen und sogar unüberwindbaren Lernprozessen haben die Nutzung und Definition dieses Begriffs inzwischen erweitert. Siehe auch regelbasierte Systeme für die maschinelle Lernproduktion von Computersystemen Gengorithmus Association erlernen künstliche Immunsystem Populationsbasierte Incremental Learning Werkzeugmaschinen Lernreferenzen Externe Links Video-Learning Klassenifier Systeme in einem Nutshell - (2016)Go innerhalb eines Basis-LCS-Algorithmus, um ihre Komponenten zu lernen und wie sie funktionieren. Webpages LCS & GBML Central UWE Learning Classifier Research Group Dynamics