In der Datenanalyse ist aomaly Aufdeckung (auch Aufspüren) die Identifizierung seltener Gegenstände, Ereignisse oder Beobachtungen, die den Verdacht deutlich erhöhen, indem sie deutlich von der Mehrheit der Daten abweichen. In der Regel werden die aomalischen Gegenstände zu einigen Problemen wie Bankbetrug, struktureller Mangel, medizinische Probleme oder Fehler in einem Text führen. Anomalien werden auch als Auslierer, Romane, Lärm, Abweichungen und Ausnahmen bezeichnet. Insbesondere im Zusammenhang mit der Erkennung von Missbrauch und Netzeingriffen sind die interessanten Objekte oft nicht selten, aber unerwartete Einbrüche in der Tätigkeit. Dieses Muster steht nicht im Einklang mit der gemeinsamen statistischen Definition von Auslierer als seltener Gegenstand, und viele außerbörsliche Nachweismethoden (insbesondere unkontrollierte Methoden) werden solche Daten nicht verlieren, es sei denn, sie wurden entsprechend zusammengefasst. stattdessen kann ein Clusteranalysegorithmus in der Lage sein, die von diesen Mustern gebildeten Mikrocluster aufzudecken. Drei große Kategorien von aomaly Erkennungstechniken bestehen. Unkontrollierte Anomaly-Erkennungstechniken erkennen Unregelmäßigkeiten in einer unlabelierten Testdaten an, die unter der Annahme festgelegt sind, dass die Mehrheit der Fälle in der Datenform normal sind, indem sie beispielsweise Fälle suchen, die mindestens den Rest der gesetzten Daten entsprechen. Supervised aomaly Aufdeckungstechniken erfordern ein Datenpaket, das als normal und anormal gekennzeichnet wurde und eine Ausbildung beinhaltet (der Schlüsselfaktor für viele andere statistische Klassifikationsprobleme ist die unausgewogene Natur der Aufdeckung). Halbkontrollierte aomaly Erkennungstechniken schaffen ein Modell, das das normale Verhalten aus einem bestimmten Standard-Ausbildungsdatensatz vertritt, und testen dann die Wahrscheinlichkeit eines Testfalls, das durch das verwendete Modell erzeugt wird. Anwendungen Einomaly-Erkennung ist in einer Vielzahl von Bereichen wie Intrusionserkennung, Betrugsdetektion, Systemgesundheitsüberwachung, Erkennung in Sensornetzen, Erkennung von Ökosystemstörungen und Fehlererkennung in Bildern mit Maschinensicht anwendbar. Es wird oft in der Vorverarbeitung verwendet, um aomalige Daten vom Datenset zu entfernen. In kontrolliertem Lernen führt die Entfernung der toxischen Daten aus dem Datenset häufig zu einer statistisch signifikanten Erhöhung der Genauigkeit. In der Literatur wurden mehrere aomaly Erkennungstechniken vorgeschlagen. Manche der populären Techniken sind: dichtebasierte Techniken (K-norest-Nachbar, lokaler Randfaktor, Isolationswälder und viele weitere Variationen dieses Konzepts). Subspace, kreisbasierte und auf Fremdbasis basierende Aufdeckung für hochdimensionale Daten. One-Klasse unterstützt Vektormaschinen. Bildung von Neuralnetzen, Autoencoders, unterschiedliche Autoencoders, langfristige Speicher-Neuralnetze Bayesian. versteckte Markov Modelle (HMMs). Clusteranalyse-basierte Aufdeckung. Abweichungen von den Assoziierungsregeln und den häufigen Punkten. Fuzzy Logik-basierte Aufdeckung. Ensemble-Methoden, die Verwendung von Merkmalsbeuteln, die Normalisierung und die verschiedenen Vielfaltsquellen. Die Leistung unterschiedlicher Methoden hängt stark von den Datensets und -parametern ab, und die Methoden verfügen über wenig systematische Vorteile gegenüber vielen Datensets und -parametern. Anwendung auf die Datensicherheit Anomaly wurde 1986 für Intrusionserkennungssysteme (IDS) von Grace Denning vorgeschlagen. IDS wird in der Regel mit Schwellenwerten und Statistiken erreicht, kann aber auch mit Soft Computing und induktiven Lernprozessen durchgeführt werden. Arten von Statistiken, die 1999 vorgeschlagen wurden, umfassen Profile von Nutzern, Arbeitsstationen, Netzen, abgelegenen Gastgebern, Gruppen von Nutzern und Programmen, die auf Frequenzen, Mitteln, Schwankungen, Kovariationen und Standardabweichungen basieren. Gegen die Unregelmäßigkeit der Erkennung von Intrusionen ist eine Missbrauchserkennung. In Daten vor der Verarbeitung in kontrolliertem Lernen ist eine unomaly Erkennung häufig ein wichtiger Schritt in der Datenvorverarbeitung, um den Lerngorithmus zu einem richtigen Datensatz zu machen. Dies ist auch als Datenreinigung bekannt. Nach der Erkennung von Aomalartigen Proben werden diese jedoch entfernt, in Zeiten beschädigter Daten können noch nützliche Proben für das Lernen liefern. Eine gemeinsame Methode, um geeignete Proben zu finden, ist die Identifizierung von Noisy-Daten. Ein Ansatz, um laute Werte zu finden, ist die Schaffung eines probabilistischen Modells aus Daten mit Modellen unkorrespondierter Daten und beschädigter Daten. Nachstehend ist ein Beispiel für die Iris Blumendaten, die mit einem aomaly hinzugefügt werden. Ein unomaler Bestandteil ist, kann ein Klassifikationsgorithmus Schwierigkeiten haben, die richtigen Muster zu finden oder Fehler zu verursachen. Durch die Abschaffung des Anomaliens wird es möglich sein, Muster in Klassifikationen leichter zu finden. Hochdimensionale Daten werden auch hohe Rechenherausforderungen mit stark großen Datenmengen vorschlagen. Durch die Entfernung zahlreicher Proben, die sich für einen Einstufungs- oder Erkennungsgorithmus entscheiden können, kann die Laufzeit auch bei den größten Datenmengen deutlich reduziert werden. Software ELKI ist ein offenes Java Data Mining-Toolkit, das mehrere anomaly Erkennungsgorithmen enthält, sowie Indexbeschleunigung für sie. Scikit-Pod ist eine Open-Source-Bibliothek, die Funktionalität aufgebaut hat, um unkontrollierte Aomaly-Erkennung zu gewährleisten. Datensets Anomaly Erkennung Benchmark-Datenspeicher der Ludwig-Maximilians-Universität München; Spiegel an der Universität São Paulo. ODDS – ODDS: Eine große Sammlung öffentlich zugänglicher Ausweisdatenblätter mit Bodenhaftung in verschiedenen Bereichen. Unüberwachter Anomaly Nachweis-Benchmark bei Harvard Dataverse: Datensets für unüberwachte Anomaly-Erkennung mit der Boden Wahrheit. Lesen Sie auch die Erfassung statistischer Verfahren kontrollieren Romanty-Erkennung Hierarchisches Gedächtnis Links