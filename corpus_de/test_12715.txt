Bei der Signalverarbeitung ist die Datenkompression, Quellcodierung oder Bitratenreduktion der Prozess der Codierung von Informationen mit weniger Bits als die ursprüngliche Darstellung. Jede bestimmte Kompression ist entweder verlustig oder verlustfrei. Verlorene Kompression reduziert Bits durch die Identifizierung und Beseitigung statistischer Redundanz. Keine Informationen sind in verlustfreier Kompression verloren. Lossy Kompression reduziert Bits durch Entfernen unnötiger oder weniger wichtiger Informationen. Typischerweise wird ein Gerät, das die Datenkompression durchführt, als Encoder bezeichnet, und ein Gerät, das die Umkehrung des Prozesses (Dekompression) als Decoder durchführt. Der Prozess der Verringerung der Größe einer Datendatei wird oft als Datenkompression bezeichnet. Im Rahmen der Datenübertragung wird sie als Quellcodierung bezeichnet; Kodierung erfolgt an der Quelle der Daten, bevor sie gespeichert oder übertragen wird. Die Quellcodierung sollte nicht mit der Kanalcodierung, zur Fehlererkennung und Korrektur oder Zeilencodierung, den Mitteln zum Abbilden von Daten auf ein Signal verwechselt werden. Die Komprimierung ist nützlich, weil sie die Ressourcen reduziert, die zur Speicherung und Übermittlung von Daten erforderlich sind. In den Kompressions- und Dekompressionsprozessen werden rechnerische Ressourcen verbraucht. Die Datenkompression unterliegt einem Raum-Zeit-Komplex-Austausch. So kann ein Kompressionsschema für Video teure Hardware erfordern, damit das Video schnell genug dekomprimiert wird, um als dekomprimiert angesehen zu werden, und die Möglichkeit, das Video vollständig zu dekomprimieren, bevor es beobachtet wird, kann unbequem sein oder zusätzliche Speicherung erfordern. Bei der Gestaltung von Datenkompressionssystemen handelt es sich um Kompromisse zwischen verschiedenen Faktoren, einschließlich des Grades der Komprimierung, der Menge der eingebrachten Verzerrung (bei der Verwendung von verlustbehafteten Datenkomprimierung), und der Rechenressourcen, die erforderlich sind, um die Daten zu komprimieren und zu dekomprimieren Verlustlose Datenkompressionsalgorithmen nutzen in der Regel statistische Redundanz, um Daten zu repräsentieren, ohne irgendwelche Informationen zu verlieren, so dass der Prozess reversibel ist. Verlustlose Kompression ist möglich, da die meisten realen Daten statistische Redundanz zeigen. Beispielsweise kann ein Bild Bereiche der Farbe aufweisen, die sich nicht über mehrere Pixel ändern; anstatt "rotes Pixel, rotes Pixel, ..." zu kodieren, können die Daten als "279 rote Pixel" kodiert werden. Dies ist ein grundlegendes Beispiel für die Laufzeitcodierung; es gibt viele Systeme, um Dateigröße zu reduzieren, indem Redundanz eliminiert wird. Die Kompressionsmethoden Lempel–Ziv (LZ) gehören zu den beliebtesten Algorithmen für verlustfreie Speicherung. DEFLATE ist eine Variation auf LZ optimiert für Dekompressionsgeschwindigkeit und Kompressionsverhältnis, aber Kompression kann langsam sein. Mitte der 1980er Jahre wurde der Algorithmus Lempel–Ziv–Welch (LZW) nach der Arbeit von Terry Welch schnell zur Wahl für die meisten universellen Kompressionssysteme. LZW wird in GIF-Bildern, Programmen wie PKZIP und Hardware-Geräten wie Modems verwendet. LZ-Methoden verwenden ein tabellenbasiertes Kompressionsmodell, bei dem Tabelleneinträge für wiederholte Datenstrings ersetzt werden. Für die meisten LZ-Methoden wird diese Tabelle dynamisch aus früheren Daten im Eingang erzeugt. Die Tabelle selbst ist oft Huffman codiert. Grammatik-basierte Codes wie diese können stark repetitive Input extrem effektiv komprimieren, zum Beispiel eine biologische Datensammlung der gleichen oder eng verwandten Arten, eine riesige versionierte Dokumentensammlung, Internet-Bogenival, etc. Die grundlegende Aufgabe der grammatikbasierten Codes ist es, eine kontextfreie Grammatik zu erstellen, die eine einzelne String ableitet. Weitere praktische Grammatikkompressionsalgorithmen umfassen Sequitur und Re-Pair. Die stärksten modernen verlustfreien Kompressoren verwenden probabilistische Modelle, wie Vorhersage durch partielle Anpassung. Die Burrows–Wheeler-Transformation kann auch als indirekte Form der statistischen Modellierung angesehen werden. In einer weiteren Ausgestaltung der direkten Verwendung der probabilistischen Modellierung können statistische Schätzungen an einen Algorithmus gekoppelt werden, der als arithmetische Codierung bezeichnet wird. Arithmetische Codierung ist eine modernere Codierung Technik, die die mathematischen Berechnungen einer Finite-State-Maschine verwendet, um eine Reihe von codierten Bits aus einer Reihe von Eingabedatensymbolen zu erzeugen. Es kann eine überlegene Kompression im Vergleich zu anderen Techniken wie dem bekannten Huffman-Algorithmus erreichen. Es verwendet einen internen Speicherzustand, um die Notwendigkeit zu vermeiden, eine ein-zu-ein-Mapping einzelner Eingabesymbole zu deutlichen Darstellungen durchzuführen, die eine ganze Anzahl von Bits verwenden, und es löscht den internen Speicher erst nach der Kodierung der gesamten Zeichenkette aus. Die arithmetische Codierung gilt besonders gut für adaptive Datenkompressionsaufgaben, bei denen die Statistiken variieren und kontextabhängig sind, da sie leicht mit einem adaptiven Modell der Wahrscheinlichkeitsverteilung der Eingangsdaten gekoppelt werden kann. Ein frühes Beispiel für die Verwendung der arithmetischen Codierung war in einem optionalen (aber nicht weit verbreiteten) Merkmal des JPEG-Bildkodierungsstandards. Es wurde seitdem in verschiedenen anderen Ausführungen angewendet, einschließlich H.263, H.264/MPEG-4 AVC und HEVC für Videocodierung. Los! In den späten 1980er Jahren wurden digitale Bilder häufiger, und Standards für verlustlose Bildkompression entstanden. Anfang der 1990er-Jahre begannen verlustbehaftete Kompressionsverfahren weit verbreitet zu sein. In diesen Systemen wird ein Verlust von Informationen akzeptiert, da fallende nonessential Detail kann Speicherplatz sparen. Es besteht ein entsprechender Kompromiss zwischen der Erhaltung von Informationen und der Verringerung der Größe. Verlorene Datenkompressionssysteme werden von der Forschung entwickelt, wie Menschen die betreffenden Daten wahrnehmen. Beispielsweise ist das menschliche Auge empfindlicher auf subtile Variationen der Leuchtkraft als auf die Farbvariationen. JPEG-Bildkompression funktioniert zum Teil durch Abrunden von nonessential bits of information. Eine Reihe von beliebten Kompressionsformaten nutzen diese Wahrnehmungsunterschiede, einschließlich der Psychoakustik für Sound und Psychovisuelle für Bilder und Video. Die meisten Formen der verlustfreien Kompression basieren auf der Transformationscodierung, insbesondere der diskreten Cosinustransformation (DCT). Es wurde zunächst 1972 von Nasir Ahmed vorgeschlagen, der 1973 einen Arbeitsalgorithmus mit T. Natarajan und K. R. Rao entwickelt hatte, bevor er im Januar 1974 einführte. DCT ist die am weitesten verbreitete verlustfreie Kompressionsmethode und wird in Multimedia-Formaten für Bilder (wie JPEG und HEIF), Video (wie MPEG, AVC und HEVC) und Audio (wie MP3, AAC und Vorbis) verwendet. Verlorene Bildkompression wird in digitalen Kameras verwendet, um Speicherkapazitäten zu erhöhen. Ebenso verwenden DVDs, Blu-ray und Streaming-Videos verlorene Video-Codierung Formate. Lossy Kompression wird in Video verwendet. Bei verlustiger Audiokompression werden Methoden der Psychoakustik verwendet, um nicht hörbare (oder weniger hörbare) Komponenten des Audiosignals zu entfernen. Die Kompression der menschlichen Sprache wird oft mit noch spezialisierteren Techniken durchgeführt; die Sprachcodierung zeichnet sich als eine separate Disziplin von der allgemeinen Audiokompression aus. Die Sprachcodierung wird in der Internet-Telefonie verwendet, beispielsweise wird Audiokompression zur CD-Reifung verwendet und von den Audio-Playern decodiert. Verlorene Kompression kann zu Generationsverlust führen. Theorie Die theoretische Basis für die Kompression wird durch die Informationstheorie und insbesondere algorithmische Informationstheorie für verlustfreie Kompressions- und Rate-Verzerrungstheorie für verlustfreie Kompression bereitgestellt. Diese Studienbereiche wurden im Wesentlichen von Claude Shannon geschaffen, der in den späten 1940er und frühen 1950er Jahren grundlegende Beiträge zum Thema veröffentlichte. Weitere Themen im Zusammenhang mit der Komprimierung sind die Kodierungstheorie und die statistische Inferenz. Lernen von Maschinen Es besteht eine enge Verbindung zwischen maschinellem Lernen und Kompression. Ein System, das die posterioren Wahrscheinlichkeiten einer Sequenz aufgrund ihrer gesamten Geschichte vorhersagt, kann für eine optimale Datenkompression (durch arithmetische Codierung auf der Ausgabeverteilung) verwendet werden. Ein optimaler Kompressor kann für die Vorhersage verwendet werden (durch das Symbol, das am besten komprimiert, angesichts der vorherigen Geschichte). Diese Gleichwertigkeit wurde als Rechtfertigung für die Verwendung der Datenkompression als Maßstab für "allgemeine Intelligenz" verwendet. Eine alternative Ansicht kann Kompressionsalgorithmen implizit anzeigen, Strings in implizite Merkmalsraumvektoren, und Kompressions-basierte Ähnlichkeitsmaßnahmen berechnen Ähnlichkeit innerhalb dieser Merkmalsräume. Für jeden Kompressor C.() definieren wir einen zugehörigen Vektorraum ≠, so dass C.() eine Eingabekette x abbildet, der Vektornorm ~x|| entspricht.Eine erschöpfende Untersuchung der Funktionsräume, die allen Kompressionsalgorithmen zugrunde liegen, ist durch den Raum ausgeschlossen; stattdessen werden Merkmalsvektoren drei repräsentative verlustlose Kompressionsverfahren, LZW, LZ77 und PPM untersuchen. Nach AIXI-Theorie ist eine im Hutter-Preis direkter erläuterte Verbindung die bestmögliche Kompression von x die kleinste mögliche Software, die x erzeugt. Zum Beispiel, in diesem Modell, eine Zip-Datei komprimierte Größe umfasst sowohl die Zip-Datei und die unzipping Software, da Sie es nicht ohne beide, aber es kann eine noch kleinere kombinierte Form. Datendifferenzierung Datenkomprimierung kann als Sonderfall der Datendifferenzierung angesehen werden. Die Datendifferenzierung besteht darin, eine Differenz bei einer Quelle und einem Ziel zu erzeugen, wobei das Ziel bei einer Quelle und einer Differenz reproduziert wird. Da bei der Datenkompression keine separate Quelle und ein Ziel vorhanden ist, kann man die Datenkomprimierung als mit leeren Quelldaten abweichende Daten betrachten, wobei die komprimierte Datei einem Unterschied von nichts entspricht. Dies ist die gleiche wie bei der Betrachtung absoluter Entropie (entsprechend der Datenkompression) als Sonderfall der relativen Entropie (entsprechend Datendifferenzierung) ohne Anfangsdaten. Der Begriff Differenzverdichtung wird verwendet, um die Datendifferenzierungsverbindung zu betonen. Verwendungen Image Entropy Codierung stammt aus den 1940er Jahren mit der Einführung von Shannon-Fano Codierung, die Basis für Huffman Codierung, die 1950 entwickelt wurde. Transform Codierung stammt aus den späten 1960er Jahren, mit der Einführung der schnellen Fourier-Transformation (FFT) Codierung im Jahr 1968 und der Hadamard-Transformation im Jahr 1969. Eine wichtige Bildkompressionstechnik ist die diskrete Cosinus-Transformation (DCT), die in den frühen 1970er Jahren entwickelt wurde. DCT ist die Basis für JPEG, ein verlustreiches Kompressionsformat, das 1992 von der Joint Photographic Experts Group (JPEG) eingeführt wurde. JPEG reduziert die Menge der Daten, die benötigt werden, um ein Bild zu den Kosten einer relativ geringen Verringerung der Bildqualität darzustellen und ist das am weitesten verbreitete Bilddateiformat geworden. Sein hocheffizienter DCT-basierter Kompressionsalgorithmus war weitgehend verantwortlich für die breite Verbreitung digitaler Bilder und digitaler Fotos. Lempel–Ziv–Welch (LZW) ist ein verlustfreier Kompressionsalgorithmus, der 1984 entwickelt wurde. Sie wird im GIF-Format verwendet, das 1987 eingeführt wurde. DEFLATE, ein 1996 spezifizierter verlustfreier Kompressionsalgorithmus, wird im Format Portable Network Graphics (PNG) verwendet. Wavelet Kompression, die Verwendung von Wavelets in Bildkompression, begann nach der Entwicklung von DCT-Codierung. Der JPEG 2000 Standard wurde im Jahr 2000 eingeführt. Im Gegensatz zum DCT-Algorithmus, der im Original JPEG-Format verwendet wird, verwendet JPEG 2000 stattdessen diskrete Wavelet-Transformationsalgorithmen (DWT). Die JPEG 2000-Technologie, die die Extension Motion JPEG 2000 umfasst, wurde 2004 als Video-Coding-Standard für das digitale Kino gewählt. Audio Audio-Datenkompression, nicht zu verwechseln mit dynamischer Reichweitenkompression, hat das Potenzial, die Übertragungsbandbreite und Speicheranforderungen von Audiodaten zu reduzieren. Audiokompressionsalgorithmen werden in Software als Audio-Codecs implementiert. Bei der verlustfreien und verlustfreien Kompression wird die Informationsredundanz reduziert, indem Methoden wie Codierung, Quantisierung, diskrete Cosinustransformation und lineare Vorhersage verwendet werden, um die Menge an Informationen zu reduzieren, die zur Darstellung der unkomprimierten Daten verwendet werden. Lossy Audiokompressionsalgorithmen bieten eine höhere Kompression und werden in zahlreichen Audio-Anwendungen wie Vorbis und MP3 verwendet. Diese Algorithmen verlassen sich fast alle auf die Psychoakustik, um die Treue von weniger hörbaren Geräuschen zu beseitigen oder zu reduzieren, wodurch der Raum, der benötigt wird, um sie zu speichern oder zu übertragen. Der akzeptable Kompromiss zwischen Verlust an Audioqualität und Übertragungs- oder Speichergröße hängt von der Anwendung ab. Beispielsweise hält eine 640 MB Compact Disc (CD) etwa eine Stunde unkomprimierte High-Fidelity-Musik, weniger als 2 Stunden Musik verlustlos komprimiert, oder 7 Stunden Musik im MP3-Format mit einer mittleren Bitrate komprimiert. Ein digitaler Schallschreiber kann in 640 MB typischerweise rund 200 Stunden klar verständlicher Sprache speichern. Verlustlose Audiokompression erzeugt eine Darstellung von digitalen Daten, die auf ein exaktes digitales Duplikat des Originals decodiert werden können. Die Kompressionsverhältnisse liegen bei etwa 50–60% der ursprünglichen Größe, die denen der generischen verlustfreien Datenkompression ähnlich ist. Lossless-Codecs verwenden Kurvenbeschlag oder lineare Vorhersage als Grundlage zur Schätzung des Signals. Parameter, die die Schätzung beschreiben, und die Differenz zwischen der Schätzung und dem Istsignal werden getrennt kodiert. Es gibt eine Reihe von verlustfreien Audiokompressionsformaten. Siehe Liste der verlustfreien Codecs für eine Liste. Einige Formate sind mit einem ausgeprägten System, wie Direct Stream Transfer, verwendet in Super Audio CD und Meridian Lossless Packing, verwendet in DVD-Audio, Dolby TrueHD, Blu-ray und HD DVD. Einige Audiodateiformate verfügen über eine Kombination aus einem verlustfreien Format und einer verlustfreien Korrektur; dies ermöglicht das Ablösen der Korrektur, um eine verlustfreie Datei zu erhalten. Solche Formate umfassen MPEG-4 SLS (Skalierbar zu Lossless,) WavPack und OptimFROG DualStream. Wenn Audiodateien verarbeitet werden sollen, entweder durch weitere Kompression oder zur Bearbeitung, ist es wünschenswert, aus einem unveränderten Original zu arbeiten (unkomprimiert oder verlustfrei komprimiert). Die Verarbeitung einer verlustbehafteten Datei zu einem bestimmten Zweck führt in der Regel zu einem Endergebnis, das die Erstellung der gleichen komprimierten Datei aus einem unkomprimierten Original beeinträchtigt. Neben der Klangbearbeitung oder -mischung wird die verlustfreie Audiokompression häufig für die Archivspeicherung oder als Masterkopien verwendet. Lossy Audio Kompression Lossy Audio Kompression wird in einer Vielzahl von Anwendungen verwendet. Neben eigenständigen Audio-only-Anwendungen der Dateiwiedergabe in MP3-Playern oder Computern werden in den meisten Video-DVDs, digitalem Fernsehen, Streaming-Medien im Internet, Satelliten- und Kabelfunk und zunehmend in terrestrischen Rundfunksendungen digital komprimierte Audiostreams verwendet. Verlorene Kompression erreicht typischerweise eine weit größere Kompression als verlustlose Kompression, indem weniger kritische Daten auf Basis psychoakustischer Optimierungen verworfen werden. Psychoakustik erkennt, dass nicht alle Daten in einem Audiostream durch das menschliche Hörsystem wahrgenommen werden können. Die verlustreichste Kompression reduziert Redundanz, indem man zunächst perzeptuell irrelevante Geräusche identifiziert, d.h. Geräusche, die sehr schwer zu hören sind. Typische Beispiele sind hohe Frequenzen oder Geräusche, die gleichzeitig auftreten wie lautere Geräusche. Diese irrelevanten Geräusche werden mit verminderter Genauigkeit kodiert oder gar nicht. Aufgrund der Art der verlustreichen Algorithmen leidet Audioqualität bei dekomprimierter und rekomprimierter Datei einen Verlust der digitalen Generation. Dies macht eine verlustfreie Kompression ungeeignet, um die Zwischenergebnisse in professionellen Audio-Engineering-Anwendungen wie Tonbearbeitung und Multitrack-Aufzeichnung zu speichern. Allerdings sind verlustige Formate wie MP3 bei Endbenutzern sehr beliebt, da die Dateigröße auf 5-20% der Originalgröße reduziert ist und ein Megabyte etwa eine Minute Musik wert in ausreichender Qualität speichern kann. Codierverfahren Um zu ermitteln, welche Informationen in einem Audiosignal wahrnehmbar irrelevant sind, verwenden die meisten verlustfreien Kompressionsalgorithmen Transformationen wie die modifizierte diskrete Cosinus-Transformation (MDCT) zur Umwandlung von zeitlichen Domänen abgetasteten Wellenformen in eine Transformationsdomäne, typischerweise die Frequenzdomäne. Sobald sie transformiert sind, können die Komponentenfrequenzen entsprechend dem, wie hörbar sie sind, priorisiert werden. Die Audibilität von spektralen Komponenten wird anhand der absoluten Hörschwelle und der Prinzipien der simultanen Maskierung - das Phänomen, bei dem ein Signal durch ein anderes, durch Frequenz getrenntes Signal - und in einigen Fällen auch zeitliche Maskierung - maskiert wird, wobei ein Signal durch ein anderes, zeitlich getrenntes Signal maskiert wird. Gleichlautheitskonturen können auch verwendet werden, um die wahrnehmbare Bedeutung von Bauteilen zu gewichten. Modelle der menschlichen Ohr-Hirn-Kombination mit solchen Effekten werden oft als psychoakustische Modelle bezeichnet. Andere Arten von verlustbehafteten Kompressoren, wie z.B. die lineare Prädiktivcodierung (LPC), die mit Sprache verwendet wird, sind quellenbasierte Kodierer. LPC verwendet ein Modell des menschlichen Gesangstrakts, um Sprachgeräusche zu analysieren und die Parameter, die das Modell verwendet, zu mindern, um sie Moment zu produzieren. Diese wechselnden Parameter werden übertragen oder gespeichert und verwendet, um ein anderes Modell im Decoder zu fahren, das den Klang wiedergibt. Lossy-Formate werden oft für die Verbreitung von Streaming-Audio oder interaktiver Kommunikation (wie z.B. in Mobilfunknetzen) verwendet. Bei solchen Anwendungen müssen die Daten als Datenströme dekomprimiert werden, anstatt nach dem gesamten Datenstrom zu übertragen. Nicht alle Audio-Codecs können für Streaming-Anwendungen verwendet werden. Die Latency wird durch die Methoden eingeführt, mit denen die Daten verschlüsselt und decodiert werden. Einige Codecs analysieren ein längeres Segment, ein Frame genannt, der Daten, um die Effizienz zu optimieren, und kodieren es dann in einer Weise, die ein größeres Segment von Daten zu einem Zeitpunkt zum Decodieren benötigt. Die inhärente Latenz des Codierungsalgorithmus kann kritisch sein; beispielsweise wenn es eine Zwei-Wege-Übertragung von Daten gibt, wie beispielsweise bei einem Telefongespräch, können signifikante Verzögerungen die wahrgenommene Qualität ernsthaft beeinträchtigen. Im Gegensatz zur Kompressionsgeschwindigkeit, die proportional zur Anzahl der vom Algorithmus benötigten Operationen ist, bezieht sich hier die Latenz auf die Anzahl der Proben, die vor der Verarbeitung eines Audioblocks analysiert werden müssen. Im Minimalfall ist die Latenz Null-Proben (z.B. wenn der Codierer/Decodierer einfach die Anzahl der Bits reduziert, die zur Quantisierung des Signals verwendet werden). Zeitdomänenalgorithmen wie LPC haben auch oft geringe Latenzen, daher ihre Popularität in der Sprachcodierung für die Telefonie. Bei Algorithmen wie MP3 müssen jedoch eine Vielzahl von Proben analysiert werden, um ein psychoakustisches Modell im Frequenzbereich zu implementieren, und die Latenz liegt in der Größenordnung von 23 ms. Sprachcodierung Die Sprachcodierung ist eine wichtige Kategorie der Audiodatenkompression. Die Wahrnehmungsmodelle, die verwendet werden, um abzuschätzen, welche Aspekte der Rede ein menschliches Ohr hören kann, sind in der Regel etwas anders als die für die Musik verwendeten. Die Frequenzen, die benötigt werden, um die Geräusche einer menschlichen Stimme zu vermitteln, sind in der Regel viel schmaler als die für die Musik benötigte, und der Klang ist normalerweise weniger komplex. Dadurch kann Sprache mit einer relativ geringen Bitrate bei hoher Qualität codiert werden. Dies geschieht im allgemeinen durch eine Kombination von zwei Ansätzen: Nur die Kodierung von Klängen, die von einer einzigen menschlichen Stimme gemacht werden könnten. Mehr der Daten im Signal wegwerfen – nur genug, um eine verständliche Stimme zu rekonstruieren, anstatt den vollen Frequenzbereich des menschlichen Hörvermögens. Die frühesten Algorithmen, die in der Sprachcodierung (und Audiodatenverdichtung im Allgemeinen) verwendet wurden, waren der A-law-Algorithmus und der μ-law-Algorithmus. Geschichte Frühe Audioforschung wurde in Bell Labs durchgeführt. Dort, 1950, C. Chapin Cutler eingereicht das Patent auf differentielle Puls-Code-Modulation (DPCM). 1973 wurde Adaptive DPCM (ADPCM) von P. Cummiskey, Nikil S. Jayant und James L. Flanagan eingeführt. Die Wahrnehmungscodierung wurde zunächst zur Sprachcodierung mit linearer Vorhersagecodierung (LPC) verwendet. Erste Konzepte für LPC gehen 1966 auf die Arbeit von Fumitada Itakura (Nagoya University) und Shuzo Saito (Nippon Telegraph und Telefon) zurück. In den 1970er-Jahren entwickelten Bishnu S. Atal und Manfred R. Schroeder bei Bell Labs eine Form von LPC, genannt adaptive Vorhersagecodierung (APC), einen wahrnehmbaren Codierungsalgorithmus, der die Maskierungseigenschaften des menschlichen Ohrs ausgenutzte, folgte Anfang der 1980er-Jahre mit dem codeerregten linearen Prädiktionsalgorithmus (CELP). Die Wahrnehmungscodierung wird durch moderne Audiokompressionsformate wie MP3 und AAC verwendet. Die von Nasir Ahmed, T. Natarajan und K. R. Rao 1974 entwickelte diskrete Cosinus-Transformation (DCT) bildete die Basis für die modifizierte diskrete Cosinus-Transformation (MDCT) mit modernen Audiokompressionsformaten wie MP3, Dolby Digital und AAC.MDCT wurde 1987 von J. P. Princen, A. W. Johnson und A. B. Bradley vorgeschlagen, nach früherer Arbeit von Princen und Bradley 1986. Das weltweit erste kommerzielle Audiokompressionssystem für Rundfunkautomation wurde von Oscar Bonello, einem Ingenieurprofessor an der Universität Buenos Aires, entwickelt. 1983 begann er mit dem psychoakustischen Prinzip der Maskierung kritischer Bands, das 1967 erstmals veröffentlicht wurde, eine praktische Anwendung auf Basis des kürzlich entwickelten IBM PC-Computers zu entwickeln, und das Rundfunkautomatisierungssystem wurde 1987 unter dem Namen Audicom gestartet. Zwanzig Jahre später nutzten fast alle Funkstationen der Welt ähnliche Technologien, die von mehreren Unternehmen hergestellt wurden. Im Februar 1988 wurde im IEEE's Journal on Selected Areas in Communications (JSAC) ein Literatur-Compendium für eine Vielzahl von Audio-Coding-Systemen veröffentlicht. Während es einige Papiere von früher gab, dokumentierte diese Sammlung eine ganze Vielzahl von fertigen, arbeitenden Audio-Codern, fast alle von ihnen perzeptual (d.h. masking) Techniken und eine Art von Frequenzanalyse und rückseitige geräuschlose Codierung. Einige dieser Papiere haben auf die Schwierigkeit hingewiesen, gute, saubere digitale Audio für Forschungszwecke zu erhalten. Die meisten, wenn nicht alle, der Autoren in der JSAC-Ausgabe waren auch im MPEG-1 Audio Committee aktiv, die das MP3-Format erstellt. Video Videokompression ist eine praktische Umsetzung der Quellcodierung in der Informationstheorie. In der Praxis werden die meisten Videocodecs neben Audiokompressionstechniken verwendet, um die separaten, aber komplementären Datenströme als ein kombiniertes Paket mit sogenannten Containerformaten zu speichern. Unkomprimiertes Video erfordert eine sehr hohe Datenrate. Obwohl verlustfreie Videokompressionscodecs mit einem Kompressionsfaktor von 5 bis 12 ausführen, hat ein typisches H.264 verlustfreies Kompressionsvideo einen Kompressionsfaktor zwischen 20 und 200. Die beiden wichtigsten Videokompressionstechniken, die in Video-Codierung Standards verwendet werden, sind die diskrete Cosinus-Transformation (DCT) und Bewegungskompensation (MC). Die meisten Videocodierungsstandards, wie die H.26x- und MPEG-Formate, verwenden typischerweise bewegungskompensierte DCT-Videocodierung (Block-Bewegungskompensation). Die Kodierungstheorie Videodaten können als eine Reihe von Bildrahmen dargestellt werden. Solche Daten enthalten in der Regel reichliche Mengen an räumlicher und zeitlicher Redundanz. Videokompressionsalgorithmen versuchen, Redundanz zu reduzieren und Informationen kompakter zu speichern. Die meisten Videokompressionsformate und Codecs nutzen sowohl räumliche als auch zeitliche Redundanz (z.B. durch Differenzcodierung mit Bewegungskompensation). Ähnlichkeiten können codiert werden, indem nur Unterschiede zwischen z.B. zeitlich benachbarten Frames (Interframe Codierung) oder räumlich benachbarten Pixeln (Intra-frame Codierung) gespeichert werden. Interframe-Kompression (eine zeitliche Delta-Kodierung) (wieder) verwendet Daten aus einem oder mehreren früheren oder späteren Frames in einer Sequenz, um den aktuellen Rahmen zu beschreiben. Die Intra-Frame-Codierung verwendet dagegen nur Daten innerhalb des aktuellen Rahmens, wobei die Bildkompression wirksam ist. Die in Camcordern verwendeten Intra-Frame-Video-Codierungsformate und Video-Editing verwenden einfachere Kompression, die nur Intra-Frame-Prädiktion verwendet. Dies vereinfacht die Videobearbeitungssoftware, da sie eine Situation verhindert, in der ein P- oder B-Rahmen auf Daten verweist, die der Editor gelöscht hat. Normalerweise verwendet Videokompression zusätzlich verlustige Kompressionstechniken wie Quantisierung, die Aspekte der Quelldaten, die (mehr oder weniger) irrelevant für die menschliche visuelle Wahrnehmung sind, durch die Nutzung wahrnehmbarer Merkmale der menschlichen Vision reduzieren. Beispielsweise sind kleine Farbunterschiede schwerer wahrnehmbar als Helligkeitsänderungen. Kompressionsalgorithmen können eine Farbe über diese ähnlichen Bereiche durchschnittlich, um Platz zu reduzieren, ähnlich wie bei JPEG-Bildkompression. Wie bei jeder verlustreichen Kompression gibt es einen Kompromiss zwischen Videoqualität und Bitrate, Kosten für die Verarbeitung der Kompression und Dekompression und Systemanforderungen. Hoch komprimiertes Video kann sichtbare oder ablenkende Artefakte enthalten. Andere Methoden als die vorherrschenden DCT-basierten Transformationsformate, wie fraktionierte Kompression, Matching-Tracking und die Verwendung einer diskreten Wavelet-Transformation (DWT), sind Gegenstand einiger Forschungen, werden aber typischerweise nicht in praktischen Produkten verwendet (außer bei der Verwendung von Wavelet-Codierungen als noch-Bild-Codeer ohne Bewegungsausgleich). Das Interesse an fraktaler Kompression scheint zu wecken, da die jüngste theoretische Analyse einen vergleichenden Mangel an Wirksamkeit solcher Methoden zeigt. Interframe-Codierung Inter-frame-Codierung funktioniert, indem jeder Frame im Video mit dem vorherigen verglichen wird. Einzelbilder einer Videosequenz werden von einem Frame zum nächsten verglichen und der Videokompressionscodec sendet nur die Unterschiede zum Referenzrahmen. Wenn der Rahmen Bereiche enthält, in denen nichts bewegt wurde, kann das System einfach einen kurzen Befehl ausgeben, der den Teil des vorherigen Rahmens in den nächsten kopiert. Bewegen sich Abschnitte des Rahmens auf einfache Weise, kann der Kompressor einen (leicht längeren) Befehl aussenden, der dem Kompressor sagt, die Kopie zu verschieben, zu drehen, zu beleuchten oder zu verdunkeln. Dieser längere Befehl bleibt noch viel kürzer als die intraframe Kompression. Üblicherweise wird der Encoder auch ein Restsignal übertragen, das die verbleibenden subtileren Unterschiede auf die Referenz-Bilder beschreibt. Mit Entropiecodierung weisen diese Restsignale eine kompaktere Darstellung als das volle Signal auf. In Bereichen von Video mit mehr Bewegung, muss die Komprimierung mehr Daten kodieren, um mit der größeren Anzahl von Pixeln, die sich ändern. Häufig bei Explosionen, Flammen, Herden von Tieren und bei einigen Panning-Schüssen führt das hochfrequente Detail zu Qualitätsabfallen oder zu Erhöhungen der variablen Bitrate. Hybrid-Block-basierte Transformationsformate Heute teilen fast alle allgemein verwendeten Videokompressionsmethoden (z.B. solche in Standards, die von der ITU-T oder ISO genehmigt wurden) die gleiche Grundarchitektur, die auf H.261 zurückgeht, die 1988 von der ITU-T standardisiert wurde. Sie verlassen sich meist auf die DCT, die auf rechteckige Blöcke benachbarter Pixel aufgebracht wird, und die zeitliche Vorhersage mit Bewegungsvektoren, sowie heutzutage auch einen In-Loop-Filterschritt. In der Prädiktionsphase werden verschiedene Deduplikations- und Differenzcodierungstechniken angewendet, die helfen, Daten zu dekorieren und neue Daten basierend auf bereits übertragenen Daten zu beschreiben. Dann werden rechteckige Blöcke von (Rest-)Pixeldaten in den Frequenzbereich transformiert, um irrelevante Informationen in der Quantisierung und für eine räumliche Redundanzreduktion zu erleichtern. Die in dieser Hinsicht weit verbreitete diskrete Cosin-Transformation (DCT) wurde 1974 von N. Ahmed, T. Natarajan und K. R. Rao eingeführt. In der verlustbehafteten Verarbeitungsstufe werden Daten quantisiert, um Informationen zu reduzieren, die für die menschliche visuelle Wahrnehmung irrelevant sind. In der letzten Phase wird die statistische Redundanz durch einen Entropiecoder weitgehend beseitigt, der oft eine Form der arithmetischen Codierung anwendet. In einer weiteren In-Loop-Filterstufe können verschiedene Filter auf das rekonstruierte Bildsignal aufgebracht werden. Durch die Berechnung dieser Filter auch innerhalb der Kodierschleife können sie zur Kompression beitragen, da sie auf Referenzmaterial aufgebracht werden können, bevor sie im Prädiktionsprozess eingesetzt wird und sie mit dem Originalsignal geführt werden können. Das beliebteste Beispiel sind die Entblockung von Filtern, die Blockierung von Artefakten aus Quantisierungsunfällen an Transformationsblockgrenzen verschwimmen. Geschichte Im Jahr 1967 schlugen A.H Robinson und C. Cherry eine Laufzeitcodierung der Bandbreitenkompression für die Übertragung analoger Fernsehsignale vor. Eine diskrete Cosine-Transformation (DCT), die grundlegend für die moderne Videokompression ist, wurde 1974 von Nasir Ahmed, T. Natarajan und K. R. Rao eingeführt. H.261, die 1988 debütierte, führte die vorherrschende Grundarchitektur der Videokompressionstechnologie im Handel ein. Es war das erste Video-Coding-Format auf Basis von DCT-Kompression, die dann der Standard für alle großen Video-Codierung Formate, die gefolgt. H.261 wurde von einer Reihe von Unternehmen entwickelt, darunter Hitachi, PictureTel, NTT, BT und Toshiba. Die beliebtesten Video-Codierung Standards für Codecs waren die MPEG-Standards. MPEG-1 wurde 1991 von der Motion Picture Experts Group (MPEG) entwickelt und entwickelt, um VHS-Qualitätsvideo zu komprimieren. Es wurde 1994 von MPEG-2/H.262, die von einer Reihe von Unternehmen entwickelt wurde, vor allem Sony, Thomson und Mitsubishi Electric. MPEG-2 wurde das Standard-Videoformat für DVD und SD-Digital-TV. Im Jahr 1999 folgte MPEG-4/H.263, ein großer Sprung nach vorne für die Videokompressionstechnologie. Es wurde von einer Reihe von Unternehmen entwickelt, vor allem Mitsubishi Electric, Hitachi und Panasonic. Das am weitesten verbreitete Videocodierformat ist H.264/MPEG-4 AVC. Es wurde 2003 von einer Reihe von Organisationen entwickelt, vor allem Panasonic, Godo Kaisha IP Bridge und LG Electronics. AVC führte die modernen kontextadaptiven binären arithmetischen Codierungen (CABAC) und kontextadaptiven Variable-Länge Codierung (CAVLC) Algorithmen kommerziell ein. AVC ist der Haupt-Video-Encoding-Standard für Blu-ray Discs und wird weit verbreitet durch Video-Sharing-Websites und Streaming-Internet-Dienste wie YouTube, Netflix, Vimeo und iTunes Store, Web-Software wie Adobe Flash Player und Microsoft Silverlight, und verschiedene HDTV-Übertragungen über terrestrische und Satellitenfernsehen. Genetics Genetics Kompressionsalgorithmen sind die neueste Generation von verlustlosen Algorithmen, die Daten (typischerweise Sequenzen von Nukleotiden) mit konventionellen Kompressionsalgorithmen und genetischen Algorithmen, die an den spezifischen Datentyp angepasst sind, komprimieren. 2012 veröffentlichte ein Team von Wissenschaftlern der Johns Hopkins University einen genetischen Kompressionsalgorithmus, der kein Referenzgenom zur Kompression verwendet. HAPZIPPER wurde auf HapMap-Daten zugeschnitten und erreicht eine über 20-fache Kompression (95% Reduzierung der Dateigröße), die eine 2- bis 4-fach bessere Kompression und in viel schnellerer Zeit als die führenden universellen Kompressionsprogramme bietet. Dazu führte Chanda, Elhaik und Bader die MAF-basierte Kodierung (MAFE) ein, die die Heterogenität des Datensatzes durch Sortieren von SNPs durch ihre geringe Allelfrequenz reduziert und so den Datensatz homogenisiert. Andere Algorithmen in den Jahren 2009 und 2013 (DNAZip und GenomeZip) haben Kompressionsverhältnisse von bis zu 1200-fach – wobei in 2,5 Megabyte (relativ zu einem Referenzgenom oder gemittelt über viele Genome) 6 Milliarden Basispaar-Diploid-Menschengenome gespeichert werden. Für einen Benchmark in Gen-/Genomdatenkompressoren siehe Outlook und aktuell ungenutztes Potenzial Es wird geschätzt, dass die gesamte Datenmenge, die auf den Speichergeräten der Welt gespeichert wird, mit vorhandenen Kompressionsalgorithmen um einen verbleibenden mittleren Faktor von 4,5:1 weiter komprimiert werden könnte. Es wird geschätzt, dass die kombinierte technologische Kapazität der Welt, um Informationen zu speichern, im Jahr 2007 1.300 Exemplare von Hardware-stelligen liefert, aber wenn der entsprechende Inhalt optimal komprimiert wird, stellt dies nur 295 Exabytes von Shannon-Informationen dar. Siehe auch Referenzen Externe Links Data Compression Basics (Video) Videokompression 4:2:2 10-Bit und seine Vorteile Warum speichert 10-Bit Bandbreite (auch wenn der Inhalt 8-Bit ist)? Welche Kompressionstechnologie sollte Wiley verwendet werden – Einführung in die Kompressionstheorie EBUsubjektive Hörtests auf Low-Bitrate-Audio-Codecs Audio Archiving Guide: Musikformate (Leitfaden für die Unterstützung eines Benutzers, den richtigen Codec zu holen) MPEG 1&2video Kompression intro (pdf-Format) auf der Wayback-Maschine (archiviert September 28, 2007) Wasserstoffaudio Wiki-Vergleich Einführung in Data Compression von Guy E Blelloch von CMU80 Unkomprimiertes Quellmaterial für Kompressionstests und Forschung Erläuterung der verlustlosen Signalkompressionsmethode, die von den meisten Codecs verwendet wird Interaktive Blindhörtests von Audiocodecs über das Internet TestVid – 2.000+ HD und andere unkomprimierte Quellvideoclips für Kompressionstests Videsignline – Intro zu Video Compression Data Footprint Reduction Technology Was ist Run Länge Coding in Videokompression.