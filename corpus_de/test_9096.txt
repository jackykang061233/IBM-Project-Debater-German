Ein Kommunikationsprotokoll ist ein Regelsystem, mit dem zwei oder mehr Einrichtungen eines Kommunikationssystems Informationen über jede Art von Variation einer physikalischen Größe übermitteln können. Das Protokoll definiert die Regeln, Syntax, Semantik und Synchronisation von Kommunikation und möglichen Fehlerwiederaufnahmemethoden. Protokolle können durch Hardware, Software oder eine Kombination beider implementiert werden. Kommunikationssysteme verwenden gut definierte Formate zum Austausch verschiedener Nachrichten. Jede Nachricht hat eine genaue Bedeutung, um eine Antwort aus einer Reihe von möglichen Antworten hervorzuheben, die für diese bestimmte Situation vorgegeben sind. Das angegebene Verhalten ist typischerweise unabhängig davon, wie es implementiert werden soll. Kommunikationsprotokolle müssen von den beteiligten Parteien vereinbart werden. Um eine Vereinbarung zu erreichen, kann ein Protokoll zu einem technischen Standard entwickelt werden. Eine Programmiersprache beschreibt das gleiche für Berechnungen, so gibt es eine enge Analogie zwischen Protokollen und Programmiersprachen: Protokolle sollen kommunizieren, welche Programmiersprachen zu Berechnungen gehören. Eine alternative Formulierung besagt, dass Protokolle zu kommunizieren, welche Algorithmen zu berechnen sind. Mehrere Protokolle beschreiben oft verschiedene Aspekte einer einzigen Kommunikation. Eine Gruppe von Protokollen, die zusammengearbeitet werden sollen, ist als Protokollsuite bekannt; bei der Software handelt es sich um einen Protokollstapel. Internet-Kommunikationsprotokolle werden von der Internet Engineering Task Force (IETF) veröffentlicht. Das IEEE (Institut für Elektro- und Elektronikingenieure) behandelt drahtgebundene und drahtlose Vernetzung und die Internationale Organisation für Normung (ISO) behandelt andere Typen. Die ITU-T übernimmt Telekommunikationsprotokolle und Formate für das öffentliche Telefonnetz (PSTN). Da die PSTN und das Internet konvergieren, werden die Standards auch auf Konvergenz ausgerichtet. Kommunikationssysteme Geschichte Eine der ersten Verwendungen des Begriffsprotokolls in einem Datenzusammenhang erfolgt in einem Memorandum mit dem Titel A Protocol for Use in the NPL Data Communications Network geschrieben von Roger Scantlebury und Keith Bartlett im April 1967. Auf dem ARPANET war der Ausgangspunkt für die Host-to-Host-Kommunikation 1969 das 1822-Protokoll, das die Übertragung von Nachrichten an ein IMP definierte. Das Network Control Program für das ARPANET wurde 1970 erstmals umgesetzt. Die NCP-Schnittstelle erlaubte der Applikationssoftware eine Verbindung über das ARPANET durch die Implementierung von hochrangigen Kommunikationsprotokollen, einem frühen Beispiel des Protokollschichtkonzepts. Die Vernetzungsforschung Anfang der 1970er Jahre von Robert E. Kahn und Vint Cerf führte zur Formulierung des Transmission Control Program (TCP). Seine RFC 675 Spezifikation wurde von Cerf mit Yogen Dalal und Carl Sunshine im Dezember 1974, noch ein monolithisches Design zu dieser Zeit geschrieben. Die International Networking Working Group vereinbarte einen verbindungslosen Datagram-Standard, der 1975 dem CCIT vorgelegt wurde, aber nicht von der ITU oder vom ARPANET übernommen wurde. Die internationale Forschung, insbesondere die Arbeit von Rémi Després, trug zur Entwicklung des X.25-Standards bei, basierend auf virtuellen Schaltungen der ITU-T im Jahr 1976. Computerhersteller entwickelten proprietäre Protokolle wie IBMs Systems Network Architecture (SNA), Digital Equipment Corporations DECnet und Xerox Network Systems. Die TCP-Software wurde als modularer Protokollstapel neu gestaltet. Ursprünglich als IP/TCP bezeichnet, wurde es 1982 auf SATNET und im Januar 1983 auf dem ARPANET installiert. Die Entwicklung einer vollständigen Protokollsuite bis 1989, wie in RFC 1122 und RFC 1123 dargelegt, legte den Grundstein für das Wachstum von TCP/IP als umfassende Protokollsuite als Kernkomponente des aufstrebenden Internets. Internationale Arbeiten an einem Referenzmodell für Kommunikationsstandards führten zu dem 1984 veröffentlichten OSI-Modell. Für einen Zeitraum in den späten 1980er und frühen 1990er Jahren wurden Ingenieure, Organisationen und Nationen darüber polarisiert, welche Standard, das OSI-Modell oder die Internet-Protokoll-Suite, zu den besten und robustesten Computernetzwerken führen würde. Konzept Die zwischen Geräten über ein Netzwerk oder andere Medien ausgetauschten Informationen unterliegen Regeln und Konventionen, die in Kommunikationsprotokollspezifikationen festgelegt werden können. Durch diese Spezifikationen wird die Art der Kommunikation, die eigentlichen Daten ausgetauscht und alle staatsabhängigen Verhaltensweisen definiert. In digitalen Rechensystemen können die Regeln durch Algorithmen und Datenstrukturen ausgedrückt werden. Protokolle sind zu kommunizieren, welche Algorithmen oder Programmiersprachen Berechnungen sind. Betriebssysteme enthalten in der Regel eine Reihe von kooperierenden Prozessen, die gemeinsame Daten manipulieren, um miteinander zu kommunizieren. Diese Kommunikation richtet sich nach gut verstandenen Protokollen, die in den Prozesscode selbst eingebettet werden können. Da dagegen kein gemeinsamer Speicher vorhanden ist, müssen Kommunikationssysteme mit einem gemeinsamen Übertragungsmedium miteinander kommunizieren. Die Übertragung ist nicht unbedingt zuverlässig, und einzelne Systeme können unterschiedliche Hardware oder Betriebssysteme verwenden. Zur Implementierung eines Netzwerkprotokolls werden die Protokoll-Software-Module mit einem auf dem Betriebssystem der Maschine implementierten Rahmen verknüpft. Dieses Framework implementiert die Netzwerkfunktionalität des Betriebssystems. Wenn Protokollalgorithmen in einer tragbaren Programmiersprache ausgedrückt werden, kann die Protokollsoftware das Betriebssystem unabhängig machen. Die bekanntesten Frameworks sind das TCP/IP-Modell und das OSI-Modell. Zum Zeitpunkt der Entwicklung des Internets hatte sich die Abstraktionsschichtung als gelungener Entwurfsansatz sowohl für die Compiler- als auch für das Betriebssystemdesign erwiesen und angesichts der Ähnlichkeiten zwischen Programmiersprachen und Kommunikationsprotokollen wurden die ursprünglich monolithischen Netzwerkprogramme in kooperierende Protokolle zerlegt. Dies führte zum Konzept von geschichteten Protokollen, die heute die Grundlage der Protokollgestaltung bilden. Systeme verwenden typischerweise kein einziges Protokoll, um eine Übertragung zu handhaben. Stattdessen verwenden sie eine Reihe von kooperierenden Protokollen, manchmal eine Protokoll-Suite genannt. Einige der bekanntesten Protokollsuiten sind TCP/IP, IPX/SPX, X.25, AX.25 und AppleTalk. Die Protokolle können basierend auf Funktionalität in Gruppen angeordnet werden, beispielsweise gibt es eine Gruppe von Transportprotokollen. Die Funktionalitäten werden auf die Schichten abgebildet, wobei jede Schicht eine eindeutige Klasse von Problemen in Bezug auf beispielsweise: Anwendung, Transport, Internet- und Netzwerkschnittstellenfunktionen löst. Zur Übertragung einer Nachricht muss aus jeder Schicht ein Protokoll ausgewählt werden. Die Auswahl des nächsten Protokolls erfolgt durch Verlängerung der Nachricht mit einem Protokollwähler für jede Schicht. Arten Es gibt zwei Arten von Kommunikationsprotokollen, basierend auf ihrer Darstellung des Inhalts: textbasiert und binär. Ein textbasiertes Protokoll oder ein Klartextprotokoll stellt seinen Inhalt im human lesbaren Format dar, oft im Klartext. Die unmittelbare menschliche Lesbarkeit steht im Gegensatz zu binären Protokollen, die inhärente Vorteile für den Einsatz in einer Computerumgebung haben (z.B. einfache mechanische Parsierung und verbesserte Bandbreitenauslastung). Verschiedene Netzwerkanwendungen haben verschiedene Methoden der Datenverkapselung. Ein mit Internet-Protokollen sehr häufiges Verfahren ist eine textorientierte Darstellung, die Anfragen und Antworten als Zeilen von ASCII-Text sendet, die durch einen neuen Liniencharakter (und in der Regel ein Wagenrückgabezeichen) beendet sind. Beispiele für Protokolle, die einen einfachen, human lesbaren Text für seine Befehle verwenden, sind FTP (File Transfer Protocol,) SMTP (Simple Mail Transfer Protocol,) und das Fingerprotokoll. Textbasierte Protokolle werden typischerweise für die menschliche Parsing und Interpretation optimiert und eignen sich daher, wenn eine menschliche Inspektion von Protokollinhalten erforderlich ist, wie z.B. beim Debuggen und bei frühen Protokollentwicklungsphasen. Binär Ein binäres Protokoll verwendet alle Werte eines Bytes, im Gegensatz zu einem textbasierten Protokoll, das nur Werte verwendet, die human lesbaren Zeichen in der ASCII-Kodierung entsprechen. Binäre Protokolle sollen von einer Maschine anstatt von einem Menschen gelesen werden. Binäre Protokolle haben den Vorteil der Terseness, die in Geschwindigkeit der Übertragung und Interpretation übersetzt. Binary wurde in den normativen Dokumenten verwendet, die moderne Standards wie EbXML, HTTP/2, HTTP/3 und EDOC beschreiben. Eine Schnittstelle in UML kann auch als binäres Protokoll angesehen werden. Grundanforderungen Die Daten über ein Netzwerk zu erhalten ist nur ein Teil des Problems für ein Protokoll. Die empfangenen Daten müssen im Kontext des Fortschritts des Gesprächs ausgewertet werden, so dass ein Protokoll Regeln enthalten muss, die den Kontext beschreiben. Diese Regeln sollen die Syntax der Kommunikation zum Ausdruck bringen. Andere Regeln bestimmen, ob die Daten für den Kontext aussagekräftig sind, in dem der Austausch stattfindet. Diese Art von Regeln sollen die Semantik der Kommunikation zum Ausdruck bringen. Nachrichten werden gesendet und über Kommunikationssysteme empfangen, um Kommunikation zu etablieren. Protokolle sollten daher Regeln für die Übermittlung festlegen. Im allgemeinen sollten viele der folgenden Punkte behandelt werden: Datenformate für den Datenaustausch Digitale Nachrichtenbitstrings werden ausgetauscht. Die Bitstrings sind in Felder unterteilt und jedes Feld trägt für das Protokoll relevante Informationen. Konzeptionell wird das Bitstring in zwei Teile unterteilt, die den Header und die Nutzlast genannt werden. Die eigentliche Nachricht wird in der Nutzlast getragen. Der Headerbereich enthält die für den Betrieb des Protokolls relevanten Felder. Bitstrings länger als die maximale Übertragungseinheit (MTU) sind in Stücke entsprechender Größe unterteilt. Adressformate für den Datenaustausch Adressen werden verwendet, um sowohl den Sender als auch den Empfänger zu identifizieren. Die Adressen werden im Headerbereich der Bitstrings geführt, so dass die Empfänger feststellen können, ob die Bitstrings von Interesse sind und bearbeitet oder ignoriert werden sollen. Eine Verbindung zwischen einem Sender und einem Empfänger kann mit einem Adresspaar (Senderadresse, Empfängeradresse) identifiziert werden. Normalerweise haben einige Adresswerte besondere Bedeutungen. Unter einer All-1-s-Adresse könnte eine Adressierung aller Stationen im Netzwerk verstanden werden, so dass ein Senden an diese Adresse zu einer Sendung im lokalen Netzwerk führen würde. Die Regeln, die die Bedeutungen des Adresswertes beschreiben, werden gemeinsam als Adressierungsschema bezeichnet. Adresse Mapping Manchmal müssen Protokolle Adressen eines Schemas auf Adressen eines anderen Schemas abbilden. Um beispielsweise eine logische IP-Adresse zu übersetzen, die von der Anwendung an eine Ethernet-MAC-Adresse angegeben wird. Dies wird als Adressmapping bezeichnet. Routing Wenn Systeme nicht direkt angeschlossen sind, müssen zwischengeschaltete Systeme entlang der Route zu den beabsichtigten Empfängern Nachrichten im Auftrag des Absenders weiterleiten. Im Internet werden die Netzwerke über Router verbunden. Die Vernetzung von Netzwerken durch Router wird Internetworking genannt. Erkennung von Übertragungsfehlern Eine Fehlererkennung ist in Netzwerken erforderlich, in denen eine Datenverfälschung möglich ist. In einem gemeinsamen Ansatz wird dem Ende der Pakete ein CRC des Datenbereichs hinzugefügt, so dass der Empfänger durch Korruption verursachte Unterschiede erkennen kann. Der Empfänger lehnt die Pakete auf CRC-Differenzen ab und arrangiert irgendwie für die Retransmission. Anerkennung Für die verbindungsorientierte Kommunikation ist eine Bestätigung des korrekten Empfanges von Paketen erforderlich. Bestätigungen werden von Empfängern zurück an ihre jeweiligen Sender gesendet. Informationsverluste - Timeouts und Retries Pakete können im Netz verloren gehen oder bei der Durchfahrt verzögert werden. Um dies zu bewältigen, kann ein Absender unter einigen Protokollen innerhalb einer bestimmten Zeit eine Bestätigung des korrekten Empfanges vom Empfänger erwarten. So muss der Absender bei Timeouts die Informationen wieder übertragen. Bei einem dauerhaft gebrochenen Link hat die Retransmission keinen Effekt, so dass die Anzahl der Retransmissionen begrenzt ist. Die Überschreitung der Retry-Grenze gilt als Fehler. Richtung des Informationsflusses Richtung muss angesprochen werden, wenn Übertragungen nur in einer Richtung auftreten können, wie auf halbduplexen Verbindungen oder von einem Sender zu einem Zeitpunkt wie auf einem gemeinsamen Medium. Dies ist als Media Access Control bekannt. Es müssen Vorkehrungen getroffen werden, um den Fall einer Kollision oder eines Inhalts beizubehalten, wenn zwei Parteien gleichzeitig übertragen bzw. übertragen möchten. Sequenzkontrolle Wenn lange Bitstrings in Stücke aufgeteilt werden und dann einzeln im Netz gesendet werden, können die Stücke verloren gehen oder verzögert werden oder, auf einigen Arten von Netzwerken, verschiedene Routen zu ihrem Ziel. Dadurch können Stücke aus der Reihenfolge gelangen. Retransmissionen können zu doppelten Stücken führen. Durch Markierung der Stücke mit Sequenzinformationen am Absender kann der Empfänger bestimmen, was verloren oder dupliziert wurde, um notwendige Retransmissionen zu verlangen und die ursprüngliche Nachricht wieder zusammenzustellen. Durchflussregelung Die Durchflussregelung wird benötigt, wenn der Sender schneller sendet, als die Empfänger- oder Zwischennetzgeräte die Übertragungen verarbeiten können. Die Durchflussregelung kann durch Messaging von Empfänger zu Sender realisiert werden. Queueing Communicating-Prozesse oder State-Maschinen verwenden Warteschlangen (oder Puffer), in der Regel FIFO Warteschlangen, um mit den Nachrichten in der Bestellung gesendet zu behandeln, und kann manchmal mehrere Warteschlangen mit verschiedenen Priorisierung Protokoll Design Systems Engineering Prinzipien angewandt wurden, um eine Reihe von gemeinsamen Netzwerkprotokoll-Design-Prinzipien zu schaffen. Die Konstruktion komplexer Protokolle beinhaltet oft eine Zersetzung in einfachere, kooperierende Protokolle. Ein solcher Satz kooperierender Protokolle wird manchmal innerhalb eines konzeptionellen Rahmens als Protokollfamilie oder Protokollsuite bezeichnet. Kommunikationssysteme arbeiten gleichzeitig. Ein wichtiger Aspekt der gleichzeitigen Programmierung ist die Synchronisation von Software zum Empfangen und Senden von Nachrichten der Kommunikation in der richtigen Sequenzierung. Die gleichzeitige Programmierung war traditionell ein Thema in den theoretischen Betriebssystemen. Die formale Verifikation scheint unabdingbar, weil gleichzeitige Programme für die versteckten und ausgeklügelten Fehler, die sie enthalten, bemerkenswert sind. Ein mathematischer Ansatz zur Untersuchung von Konkurs und Kommunikation wird als kommunikierende sequentielle Prozesse (CSP) bezeichnet. Konkurrenz kann auch mit endlichen Zustandsmaschinen, wie Mealy- und Moore-Maschinen, modelliert werden. Mealy- und Moore-Maschinen werden als Design-Tools in digitalen Elektronik-Systemen verwendet, die in Form von Hardware, die in Telekommunikations- oder elektronischen Geräten im Allgemeinen verwendet werden. Die Literatur präsentiert zahlreiche Analogien zwischen Computerkommunikation und Programmierung. Analog ist ein Übertragungsmechanismus eines Protokolls mit einer zentralen Verarbeitungseinheit (CPU) vergleichbar. Der Rahmen enthält Regeln, die es dem Programmierer ermöglichen, kooperierende Protokolle unabhängig voneinander zu gestalten. Schichtung Bei der modernen Protokollgestaltung werden Protokolle zu einem Protokollstapel geschichtet. Layering ist ein Konstruktionsprinzip, das die Protokoll-Design-Task in kleinere Schritte unterteilt, von denen jeder einen bestimmten Teil erreicht, der mit den anderen Teilen des Protokolls nur in einer kleinen Anzahl von gut definierten Weisen zusammenwirkt. Die Schichtung ermöglicht es, die Teile eines Protokolls ohne kombinatorische Explosion von Fällen zu konstruieren und zu testen, wobei jedes Design relativ einfach bleibt. Die im Internet verwendeten Kommunikationsprotokolle sollen in vielfältigen und komplexen Einstellungen funktionieren. Internetprotokolle sind für Einfachheit und Modularität konzipiert und passen in eine grobe Hierarchie von Funktionsschichten, die in der Internet Protocol Suite definiert sind. Die ersten beiden kooperierenden Protokolle, das Transmission Control Protocol (TCP) und das Internet Protocol (IP) resultierten aus der Zersetzung des ursprünglichen Transmission Control Program, eines monolithischen Kommunikationsprotokolls, in diese geschichtete Kommunikationssuite. Das OSI-Modell wurde international auf Basis von Erfahrungen mit Netzwerken entwickelt, die das Internet als Referenzmodell für die allgemeine Kommunikation mit viel strengeren Regeln der Protokoll-Interaktion und strengere Schichtung prädizierten. Typischerweise wird die Anwendungssoftware auf einer robusten Datentransportschicht aufgebaut. Unter Verwendung dieser Transportschicht ist ein Datengramm-Liefer- und Routing-Mechanismus, der typischerweise im Internet verbindungslos ist. Pakete, die über Netzwerke übertragen werden, geschieht über eine andere Schicht, die nur Netzwerk-Link-Technologien beinhaltet, die oft für bestimmte physikalische Schichttechnologien, wie Ethernet, spezifisch sind. Layering bietet Möglichkeiten, Technologien bei Bedarf auszutauschen, beispielsweise werden Protokolle oft in einer Tunnelanordnung gestapelt, um die Verbindung von unähnlichen Netzwerken aufzunehmen. Beispielsweise kann IP über ein Asynchronous Transfer Mode (ATM) Netzwerk getunnelt werden. Protokollschichtung Protokollschichtung bildet die Grundlage der Protokollgestaltung. Es ermöglicht die Zersetzung von einzelnen, komplexen Protokollen in einfachere, kooperierende Protokolle. Die Protokollschichten lösen jeweils eine bestimmte Klasse von Kommunikationsproblemen. Zusammen bilden die Schichten ein Schichtungssystem oder Modell. Computations behandeln Algorithmen und Daten; Kommunikation beinhaltet Protokolle und Nachrichten; So ist das Analoge eines Datenflussdiagramms eine Art Nachrichtenflussdiagramm. Zur Visualisierung von Protokollschicht- und Protokoll-Suiten fließt ein Diagramm der Nachricht zwischen zwei Systemen A und B ein. 3. Die Systeme A und B verwenden beide die gleiche Protokoll-Suite. Die vertikalen Ströme (und Protokolle) sind im System und die horizontalen Nachrichtenströme (und Protokolle) sind zwischen Systemen. Die Nachrichtenströme werden durch Regeln und durch Protokolle vorgegebene Datenformate geregelt. Die blauen Linien markieren die Grenzen der (horizontalen) Protokollschichten. Softwareschichtung Die Software-Unterstützungsprotokolle haben eine geschichtete Organisation und ihre Beziehung zu Protokollschichtung ist in Abbildung 5 dargestellt. Um eine Nachricht auf System A zu senden, interagiert das oberste Softwaremodul mit dem Modul direkt darunter und übergibt die zu verkapselnde Nachricht. Das untere Modul füllt die Headerdaten gemäß dem Protokoll aus, das es implementiert und mit dem unteren Modul interagiert, das die Nachricht über den Kommunikationskanal an das untere Modul des Systems B sendet. Am Empfangssystem B erfolgt das umgekehrt, so dass letztendlich die Nachricht in ihrer ursprünglichen Form an das obere Modul des Systems B geliefert wird. Die Übersetzung von Program ist in Unterprobleme unterteilt. Dadurch wird auch die Übersetzungssoftware geschichtet, so dass die Softwareschichten unabhängig gestaltet werden können. Der gleiche Ansatz ist bei der TCP/IP-Schichtung zu erkennen. Die Module unterhalb der Applikationsschicht werden im allgemeinen als Teil des Betriebssystems betrachtet. Die Daten zwischen diesen Modulen sind wesentlich kostengünstiger als die Datenübermittlung zwischen einem Applikationsprogramm und der Transportschicht. Die Grenze zwischen der Auftragsschicht und der Transportschicht wird als Betriebssystemgrenze bezeichnet. Strict Layering Strictly adhering an einem Schichtmodell, eine Praxis als strenge Schichtung, ist nicht immer der beste Ansatz zur Vernetzung. Strict Layering kann negative Auswirkungen auf die Leistung einer Implementierung haben. Während die Verwendung von Protokollschichtung heute über den Bereich der Computervernetzung ubiquit ist, wurde es von vielen Forschern historisch kritisiert, da die Abstraktion des Protokollstapels auf diese Weise dazu führen kann, dass eine höhere Schicht die Funktionalität einer unteren Schicht dupliziert, wobei es sich bei einem ersten Beispiel um eine Fehlerrückgewinnung sowohl auf per-Link-Basis als auch auf End-to-End-Basis handelt. Design-Muster Gemeinsam wiederkehrende Probleme bei der Gestaltung und Umsetzung von Kommunikationsprotokollen können durch Software-Design-Muster angesprochen werden. Formale Spezifikation Beliebte formale Methoden zur Beschreibung der Kommunikationssyntax sind Abstract Syntax Notation One (eine ISO-Norm) und Augmented Backus-Naur Form (eine IETF-Norm). Finite-state Maschinenmodelle werden verwendet, um die möglichen Wechselwirkungen des Protokolls formal zu beschreiben. und Kommunikation von endlichen Maschinen Entwicklung des Protokolls Zur Kommunikation müssen Protokolle ausgewählt werden. Die Regeln können durch Algorithmen und Datenstrukturen ausgedrückt werden. Die Unabhängigkeit der Hardware und des Betriebssystems wird durch den Ausdruck der Algorithmen in einer tragbaren Programmiersprache verbessert. Die Quellenunabhängigkeit der Spezifikation bietet eine größere Interoperabilität. Protokollnormen werden häufig durch die Genehmigung oder Unterstützung einer Normenorganisation geschaffen, die den Normungsprozess initiiert.Die Mitglieder der Normungsorganisation stimmen dem Arbeitsergebnis auf freiwilliger Basis zu. Oft sind die Mitglieder in der Kontrolle der großen Marktanteile, die für das Protokoll relevant sind, und in vielen Fällen werden Normen durch Gesetz oder die Regierung durchgesetzt, weil sie für ein wichtiges öffentliches Interesse gedacht sind, so dass die Zulassung für das Protokoll sehr wichtig sein kann. Die Notwendigkeit von Protokollnormen Die Notwendigkeit von Protokollstandards kann gezeigt werden, indem man untersucht, was mit dem von IBM erfundenen bi-sync-Protokoll (BSC) passiert ist. BSC ist ein frühes Link-Level-Protokoll, das verwendet wird, um zwei separate Knoten zu verbinden. Es war ursprünglich nicht beabsichtigt, in einem Multinode-Netzwerk verwendet werden, aber dies ergab mehrere Mängel des Protokolls. In Abwesenheit von Standardisierung fühlten sich Hersteller und Organisationen frei, das Protokoll zu verbessern und unvereinbare Versionen in ihren Netzwerken zu erstellen. In einigen Fällen wurde dies bewusst getan, um Benutzer von der Verwendung von Geräten anderer Hersteller zu entmutigen. Es gibt mehr als 50 Varianten des ursprünglichen bi-sync-Protokolls. Man kann annehmen, dass ein Standard zumindest ein Teil davon daran gehindert hätte. In einigen Fällen gewinnen Protokolle Marktherrschaft, ohne durch einen Standardisierungsprozess zu gehen. Solche Protokolle werden als de facto-Standards bezeichnet. De facto-Standards sind in Schwellenmärkten, Nischenmärkten oder Märkten üblich, die monopolisiert sind (oder oligopolisiert). Sie können einen Markt in einem sehr negativen Griff halten, vor allem, wenn sie verwendet, um den Wettbewerb zu erschrecken. Aus historischer Sicht sollte die Normung als Maß angesehen werden, um den schlechten Auswirkungen von de facto Standards entgegenzuwirken. Positive Ausnahmen bestehen; ein "de facto-Standard"-Betriebssystem wie Linux hat diesen negativen Grip auf seinem Markt nicht, weil die Quellen offen veröffentlicht und gepflegt werden und so den Wettbewerb einladen. Die Standardisierung ist daher nicht die einzige Lösung für die offene Systemverschaltung. Normenorganisationen Einige der für Kommunikationsprotokolle relevanten Normenorganisationen sind die Internationale Organisation für Normung (ISO), die Internationale Telekommunikationsunion (ITU), das Institut für Elektro- und Elektronikingenieure (IEEE) und die Internet Engineering Task Force (IETF). Der IETF hält die im Internet verwendeten Protokolle aufrecht. Der IEEE steuert viele Software- und Hardwareprotokolle in der Elektronikindustrie für kommerzielle und Consumer-Geräte. Die ITU ist eine Dachorganisation für Telekommunikationsingenieure, die das öffentliche Telefonnetz (PSTN) sowie viele Funkkommunikationssysteme entwerfen. Für die Meereselektronik werden die NMEA Standards verwendet. Das World Wide Web Consortium (W3C) produziert Protokolle und Standards für Webtechnologien. Internationale Normenorganisationen sollen unparteiischer sein als lokale Organisationen mit einem nationalen oder kommerziellen Selbstinteresse. Normenorganisationen forschen und entwickeln auch für Standards der Zukunft. In der Praxis kooperieren die genannten Normenorganisationen eng miteinander. Der Standardisierungsprozess Der Standardisierungsprozess beginnt mit der ISO Inbetriebnahme einer Unterkommissionsarbeitsgruppe. Die Arbeitsgruppe befasst sich mit Entwürfen und Diskussionsdokumenten an interessierte Parteien (einschließlich anderer Normengremien), um Diskussionen und Kommentare zu provozieren. Dies wird eine Menge von Fragen, viel Diskussion und in der Regel einige Meinungsverschiedenheiten über das, was der Standard bieten sollte und wenn es alle Bedürfnisse erfüllen kann (in der Regel nicht). Alle widersprüchlichen Ansichten sollten berücksichtigt werden, oft durch Kompromisse, um auf einen Vorschlag der Arbeitsgruppe voranzukommen. Der Entwurf des Vorschlags wird von den Standardgremien und anderen Organisationen der Mitgliedstaaten in jedem Land diskutiert. Kommentare und Vorschläge werden zusammengetragen und nationale Ansichten formuliert, bevor die Mitglieder der ISO über den Vorschlag abstimmen. Wenn der Entwurf abgelehnt wird, muss der Vorschlag die Einwände und Gegenmaßnahmen prüfen, um einen neuen Entwurf für eine weitere Abstimmung zu schaffen. Nach vielen Rückmeldungen, Änderungen und Kompromissen erreicht der Vorschlag den Status eines Entwurfs eines internationalen Standards und letztlich eines internationalen Standards. Der Prozess dauert in der Regel mehrere Jahre, um abzuschließen. Der vom Designer erstellte Original-Papierentwurf unterscheidet sich wesentlich vom Standard und enthält einige der folgenden Merkmale: Verschiedene optionale Betriebsarten, zum Beispiel, um die Einrichtung verschiedener Paketgrößen zu Startzeitpunkt zu ermöglichen, da die Parteien keinen Konsens über die optimale Paketgröße erreichen konnten. Parameter, die nach Ermessen des Implementierungsorgans undefiniert gelassen oder erlaubt sind, Werte eines definierten Satzes zu übernehmen. Dies spiegelt oft widersprüchliche Ansichten einiger Mitglieder wider. Parameter, die für die künftige Nutzung reserviert sind und die darauf hinweisen, dass die Mitglieder die Einrichtung vereinbart haben, aber keine Einigung darüber erzielen konnten, wie dies in der verfügbaren Zeit geschehen sollte. Bei der Umsetzung des Standards werden zwangsläufig verschiedene Unstimmigkeiten und Mehrdeutigkeiten festgestellt. Internationale Standards werden regelmäßig neu formuliert, um die Mängel zu bewältigen und wechselnde Ansichten zum Thema zu reflektieren. OSI Standardisierung Eine Lehre von ARPANET, dem Vorgänger des Internets, war, dass Protokolle einen Rahmen benötigen, um zu arbeiten. Es ist daher wichtig, ein für strukturierte Protokolle (wie geschichtete Protokolle) und deren Standardisierung geeignetes, universelles, zukunftssicheres Framework zu entwickeln. Dies würde Protokollstandards mit überlappender Funktionalität verhindern und eine klare Definition der Verantwortlichkeiten eines Protokolls auf den verschiedenen Ebenen (Schichten) ermöglichen. Dies führte zum OSI Open Systems Interconnection Referenzmodell (RM/OSI), das als Rahmen für die Gestaltung von Standardprotokollen und Diensten, die den verschiedenen Schichtspezifikationen entsprechen, verwendet wird. Im OSI-Modell werden Kommunikationssysteme angenommen, die durch ein zugrunde liegendes physikalisches Medium verbunden werden, das einen grundlegenden (und nicht spezifizierten) Übertragungsmechanismus bereitstellt. Die darüberliegenden Schichten sind nummeriert (von ein bis sieben); die n. Schicht wird als (n)-Schicht bezeichnet. Jede Schicht dient der darüber liegenden Schicht (oder oben auf den Applikationsprozess) unter Verwendung der Dienste der unmittelbar darunter liegenden Schicht. Die Schichten kommunizieren über eine Schnittstelle, genannt Service Access Point, miteinander. Entsprechende Schichten an jedem System werden als Peer-Entitäten bezeichnet. Zur Kommunikation verwenden zwei Peer-Einheiten auf einer bestimmten Schicht ein (n)-Protokoll, das durch die Verwendung von Diensten der (n-1)-Schicht durchgeführt wird. Wenn Systeme nicht direkt angeschlossen werden, werden zwischengeschaltete Peer-Einheiten (genannte Relais) verwendet. Eine Adresse identifiziert eindeutig einen Service Access Point. Die Adressnamendomänen müssen nicht auf eine Schicht beschränkt sein, so ist es möglich, nur eine Namensdomäne für alle Schichten zu verwenden. Für jede Schicht gibt es zwei Arten von Standards: Protokoll-Standards definieren, wie Peer-Einheiten auf einer bestimmten Schicht kommunizieren, und Service-Standards definieren, wie eine bestimmte Schicht mit der darüber liegenden Schicht kommuniziert. In der Originalversion von RM/OSI sind die Schichten und ihre Funktionalität (von höchster bis niedrigster Schicht): Die Anwendungsschicht kann den Anwendungsprozessen folgende Dienste anbieten: Identifizierung der beabsichtigten Kommunikationspartner, Einrichtung der erforderlichen Behörde, um die Verfügbarkeit und Authentisierung der Partner zu kommunizieren, Vereinbarung über Datenschutzmechanismen für die Kommunikation, Vereinbarung über die Verantwortung für die Fehlerrückgewinnung und Verfahren zur Sicherstellung der Datenintegrität, Synchronisation zwischen kooperierenden Anwendungsprozessen, Identifizierung von Einschränkungen auf Syntax (z.B. Zeichensätze und Datenstrukturen) Ermittlung der Kosten und akzeptable Qualität der Dienste, Auswahl der Dialogdisziplinen. Die Präsentationsschicht kann der Applikationsschicht folgende Dienste zur Verfügung stellen: eine Anfrage zur Einrichtung einer Sitzung, Datenübertragung, Aushandlung der zwischen den Applikationsschichten zu verwendenden Syntax, notwendige Syntaxtransformationen, Formatierung und spezielle Zwecktransformationen (z.B. Datenkompression und Datenverschlüsselung). Die Sitzungsschicht kann die folgenden Dienste der Präsentationsschicht zur Verfügung stellen: Einrichtung und Freigabe von Sitzungsverbindungen, normaler und beschleunigter Datenaustausch, ein Quarantänedienst, der es der sendenden Präsentationseinheit ermöglicht, die empfangende Sitzungsinstanz zu unterrichten, Daten nicht ohne Erlaubnis an ihre Präsentationsinstanz zu veröffentlichen, Interaktionsmanagement, so dass Präsentationsinstanzen kontrollieren können, deren Drehung es ist, bestimmte Steuerungsfunktionen durchzuführen, Resynchronisation einer Sitzungsverbindung, Berichterstattung von unwiederfassbaren Ausnahmen von der Präsentation der Präsentation der Präsentation der Präsentationsinstanz. Die Transportschicht bietet eine zuverlässige und transparente Datenübertragung in kostengünstiger Weise, wie sie durch die gewählte Servicequalität erforderlich ist. Sie kann das Multiplexen mehrerer Transportverbindungen an eine Netzwerkverbindung unterstützen oder eine Transportverbindung in mehrere Netzwerkverbindungen teilen. Die Netzwerkschicht führt die Einrichtung, Wartung und Freigabe von Netzwerkpfaden zwischen Transport-Peer-Einheiten. Wenn Relais benötigt werden, werden Routing- und Relaisfunktionen von dieser Schicht bereitgestellt. Die Qualität des Dienstes wird bei der Errichtung der Verbindung zwischen Netz- und Transporteinrichtungen ausgehandelt. Diese Schicht ist auch für die Netzüberlastungskontrolle verantwortlich. Die Daten-Link-Schicht macht das Setup, die Wartung und die Freigabe von Daten-Link-Verbindungen. In der physikalischen Schicht auftretende Fehler werden erkannt und können korrigiert werden. Fehler werden der Netzwerkschicht gemeldet. Durch diese Schicht wird der Austausch von Datenlinkeinheiten (einschließlich Durchflussregelung) definiert. Die physikalische Schicht beschreibt Details wie die elektrischen Eigenschaften der physikalischen Verbindung, die verwendeten Übertragungstechniken und die Einrichtung, Wartung und Reinigung physikalischer Verbindungen. Im Gegensatz zum TCP/IP-Schichtungssystem, das ein verbindungsloses Netzwerk annimmt, nahm RM/OSI ein verbindungsorientiertes Netzwerk an. Für Breitbandnetze sind verbindungsorientierte Netzwerke besser geeignet und verbindungslose Netzwerke eignen sich besser für lokale Netzwerke. Die Verwendung von Verbindungen zur Kommunikation impliziert einige Form von Sitzungen und (virtuellen) Schaltungen, daher die (im TCP/IP-Modell fehlt) Sitzungsschicht. Die Bestandteile der ISO waren vor allem mit weiten Netzen beschäftigt, so dass die Entwicklung von RM/OSI konzentriert auf verbindungsorientierte Netzwerke und verbindungslose Netzwerke nur in einem Addendum zu RM/OSI erwähnt wurde. Damals musste der IETF damit umgehen und die Tatsache, dass das Internet Protokolle brauchte, die einfach nicht da waren. Infolgedessen entwickelte die IETF einen eigenen Standardisierungsprozess basierend auf "rough Konsens and run code". Das Standardisierungsverfahren wird durch RFC2026 beschrieben. Der IETF ist heute zu einer Standardorganisation für die im Internet verwendeten Protokolle geworden. RM/OSI hat sein Modell auf verbindungslose Dienste erweitert und dadurch könnten sowohl TCP als auch IP zu internationalen Standards entwickelt werden. Taxonomies Klassifizierungssysteme für Protokolle konzentrieren sich in der Regel auf den Bereich der Nutzung und Funktion. Als Anwendungsgebiet werden verbindungsorientierte Protokolle bzw. verbindungslose Protokolle an verbindungsorientierten Netzwerken bzw. verbindungslosen Netzwerken verwendet. Ein Funktionsbeispiel ist ein Tunneling-Protokoll, mit dem Pakete in einem Hochebenen-Protokoll verkapselt werden können, so dass die Pakete über ein Transportsystem über das Hochebenen-Protokoll geleitet werden können. Ein Schichtungssystem kombiniert sowohl Funktion als auch Anwendungsbereich. Die dominanten Schichtsysteme sind diejenigen, die vom IETF und von ISO vorgeschlagen werden. Trotz der Tatsache, dass die zugrunde liegenden Annahmen der Schichtungssysteme unterschiedlich genug sind, um die beiden zu unterscheiden, ist es eine gemeinsame Praxis, die beiden durch gemeinsame Protokolle mit den Schichten der beiden Systeme zu vergleichen. Das Schichtungsschema der IETF wird als Internetschichtung oder TCP/IP-Schichtung bezeichnet. Das Schichtungssystem von ISO wird als OSI-Modell oder ISO-Schichtung bezeichnet. Bei der Konfiguration von Netzwerkgeräten wird oft unterschieden: Der Begriff Protokoll bezieht sich ausschließlich auf die Transportschicht, und der Begriff Dienst bezieht sich auf Protokolle, die ein Protokoll zum Transport verwenden. Im gemeinsamen Fall von TCP und UDP zeichnen sich die Dienste durch Portnummern aus. Die Konformität zu diesen Portnummern ist freiwillig, also bezieht sich der Begriff Dienst ausschließlich auf Portnummern, und der Begriff Anwendung wird oft verwendet, um auf Protokolle zu verweisen, die durch Inspektionssignaturen identifiziert werden. Siehe auch Listen der Netzwerkprotokolle Hinweise Referenzen Bibliographie Radia Perlman: Verbindungen: Brücken, Router, Switches und Internetworking Protocols.2nd Edition. Addison-Wesley 1999, ISBN 0-201-63448-1. Insbesondere Ch.18 über "network design folklore", die auch online unter http://www.informit.com/articles/article.aspx?p=20482 erhältlich ist. Gerard J. Holzmann: Gestaltung und Validierung von Computerprotokollen. Prentice Hall, 1991, ISBN 0-13-539925-4.Also online unter http://spinroot.com/spin/Doc/Book91.html Douglas E. Comer (2000). Internetarbeit mit TCP/IP - Prinzipien, Protokolle und Architektur (4. ed.). Prentice Hall. ISBN 0-13-018380-6. Insbesondere Ch.11 Protokollschichtung. Außerdem hat ein RFC-Führer und ein Glossar der Internet-Arbeitsbedingungen und Abkürzungen. Internet und Internet Task Force abbr.IETF (1989): RFC1122, Anforderungen an Internet-Hosts -- Kommunikationsschichten, R. Braden (ed,.) Online verfügbar unter http://tools.ietf.org/html/rfc1122.Beschreibt TCP/IP an die Implementierung von Protokollsoftware. Insbesondere die Einführung gibt einen Überblick über die Gestaltungsziele der Suite.M Ben-Ari (1982): Prinzipien der gleichzeitigen Programmierung 10. Druck. Prentice Hall International, ISBN 0-13-701078-8.C.A.R Hoare (1985):Kommunikation von Folgeprozessen 10. Druck. Prentice Hall International, ISBN 0-13-153271-5.Verfügbar online über http://www.usingcsp.com R.D. Tennent (1981): Prinzipien der Programmiersprachen 10. Druck. Prentice Hall International, ISBN 0-13-709873-1.Brian W Marsden (1986):Kommunikationsnetzwerk Protokolle 2. Auflage. Chartwell Bratt, ISBN 0-86238-106-1.Andrew S. Tanenbaum (1984): Strukturierte Computerorganisation 10. Druck. Prentice Hall International, ISBN 0-13-854605-3. Radia Perlman, Interconnections: Brücken, Router, Switches und Internetworking Protocols (2. Auflage).Addison-Wesley 1999.ISBN 0-201-63448-1. Insbesondere Ch.18 auf "Netzwerk Design Folklore". Gerard J. Holzmann, Design und Validierung von Computerprotokollen. Prentice Hall, 1991.ISBN 0-13-539925-4.Also online unter http://spinroot.com/spin/Doc/Book91.html Externe Links Javvin's Protocol Dictionary Übersicht über Protokolle im Telecontrol-Feld mit OSI Referenzmodell