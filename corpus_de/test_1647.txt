Hubert Dreyfus war ein Kritiker der künstlichen Intelligenzforschung. In einer Reihe von Papieren und Büchern, darunter Alchemy und AI (1965), What Computers Can't Do (1972; 1979; 1992) und Mind over Machine (1986), präsentierte er eine pessimistische Bewertung des Fortschritts von AI und eine Kritik an den philosophischen Grundlagen des Feldes. Die Einwände von Dreyfus werden in den meisten Einleitungen zur Philosophie der künstlichen Intelligenz diskutiert, darunter Russell & Norvig (2003), das Standard-KI-Schriftbuch und in Fearn (2007), eine Umfrage der zeitgenössischen Philosophie. Dreyfus argumentierte, dass menschliche Intelligenz und Know-how in erster Linie von unbewussten Prozessen abhängen, anstatt bewusste symbolische Manipulationen, und dass diese unbewussten Fähigkeiten niemals in formalen Regeln vollständig erfasst werden können. Seine Kritik basierte auf den Erkenntnissen moderner kontinentaler Philosophen wie Merleau-Ponty und Heidegger und richtete sich an die erste Welle der KI-Forschung, die hochrangige formale Symbole verwendet, um die Realität zu repräsentieren und versuchte, die Intelligenz auf Symbolmanipulation zu reduzieren. Als die Ideen von Dreyfus in der Mitte der 1960er-Jahre erstmals vorgestellt wurden, wurden sie mit lächerlicher und außergewöhnlicher Feindseligkeit getroffen. In den 1980er-Jahren wurden jedoch viele seiner Perspektiven von Forschern, die in der Robotik und dem neuen Bereich des Verbindungsismus arbeiten, wiederentdeckt – Aproaches, die jetzt Subsymbolik genannt wurden, weil sie die Schwerpunkte der frühen AI-Forschung auf hochrangige Symbole legen. Im 21. Jahrhundert simulieren statistikbasierte Ansätze zum maschinellen Lernen die Art und Weise, wie das Gehirn unbewussten Prozess verwendet, um Anomalien wahrzunehmen, aufzuspüren und schnelle Urteile zu treffen. Diese Techniken sind sehr erfolgreich und werden derzeit in Industrie und Wissenschaft weit verbreitet. Historiker und KI-Forscher Daniel Crevier schreibt: "Die Zeit hat die Genauigkeit und Wahrnehmung einiger Kommentare von Dreyfus bewiesen. " Dreyfus sagte 2007: "Ich glaube, ich habe gewonnen und es ist vorbei – sie haben aufgegeben." Dreyfus' Kritik Die grandiosen Versprechen der künstlichen Intelligenz In Alchemy und KI (1965) und What Computers Can't Do (1972), Dreyfus fasste die Geschichte der künstlichen Intelligenz zusammen und belästigte den ungezügelten Optimismus, der das Feld durchdrungen hat. Zum Beispiel, Herbert A. Simon, nach dem Erfolg seines Programms General Problem Solver (1957), vorhergesagt, dass bis 1967: Ein Computer wäre Weltmeister im Schach. Ein Computer würde ein wichtiges neues mathematisches Theorem entdecken und beweisen. Die meisten Theorien in der Psychologie werden die Form von Computerprogrammen. Die Presse berichtete diese Vorhersagen in glühenden Berichten über die bevorstehende Ankunft von Maschineninformationen. Dreyfus fühlte, dass dieser Optimismus völlig unberechtigt war. Er glaubte, dass sie auf falschen Annahmen über die Natur der menschlichen Intelligenz basieren. Pamela McCorduck erklärt Dreyfus Position: [A] große Missverständnisse für öffentliche Verwirrung über Denkmaschinen, ein Missverständnis, das von den unrealistischen Behauptungen, die Forscher in KI gemacht haben, begangen wurde, behauptet, dass Denkmaschinen bereits hier sind, oder jedenfalls, um die Ecke. Diese Vorhersagen basierten auf dem Erfolg eines "Informationsverarbeitungs" Modells des Geistes, artikuliert von Newell und Simon in ihrer physikalischen Symbolsysteme Hypothese, und erweiterte später in eine philosophische Position, die als Rechenschaft von Philosophen wie Jerry Fodor und Hilary Putnam bekannt ist. In der Überzeugung, dass sie den wesentlichen Prozess des menschlichen Denkens mit einfachen Programmen erfolgreich simuliert hatten, schien es ein kurzer Schritt, voll intelligente Maschinen zu produzieren. Dreyfus argumentierte jedoch, dass die Philosophie, insbesondere die Philosophie des 20. Jahrhunderts, ernsthafte Probleme mit diesem Standpunkt der Informationsverarbeitung entdeckt hatte. Der Geist, nach moderner Philosophie, ist nichts wie ein digitaler Computer. Dreyfus' vier Annahmen der künstlichen Intelligenzforschung In Alchemy und KI und What Computers Can't Do, Dreyfus identifiziert vier philosophische Annahmen, die den Glauben der frühen KI-Forscher unterstützten, dass menschliche Intelligenz von der Manipulation von Symbolen abhängig war. "In jedem Fall", schreibt Dreyfus, "die Annahme wird von Arbeitern in [AI] als Axiom genommen, die Ergebnisse garantieren, während es tatsächlich eine Hypothese unter anderem ist, durch den Erfolg dieser Arbeit getestet werden". Die biologische Annahme Das Gehirn verarbeitet Informationen in diskreten Operationen über ein biologisches Äquivalent von Ein-/Ausschaltern. In den frühen Tagen der Erforschung der Neurologie erkannten Wissenschaftler, dass Neuronen Feuer in all-oder-nothing-Pulsen. Mehrere Forscher, wie Walter Pitts und Warren McCulloch, argumentierten, dass Neuronen ähnlich wie Boolean Logik-Gatter funktionieren, und so könnte durch elektronische Schaltung auf der Ebene des Neurons nachgeahmt werden. Als digitale Computer in den frühen 50er Jahren weit verbreitet wurden, wurde dieses Argument erweitert, um zu vermuten, dass das Gehirn ein riesiges physisches Symbolsystem war, das die binären Symbole von Null und eines manipuliert. Dreyfus konnte die biologische Annahme widerlegen, indem er Forschung in der Neurologie zitierte, dass die Wirkung und das Timing der Neuronfeuerung analoge Komponenten hatte. Aber Daniel Crevier stellt fest, dass "diese Überzeugung in den frühen 1970er Jahren noch innehatte und niemand gegen Dreyfus argumentierte" über die biologische Annahme. Die psychologische Annahme Der Geist kann als Gerät angesehen werden, das auf Bits von Informationen nach formalen Regeln arbeitet. Er widerlegte diese Annahme, indem er zeigte, dass vieles von dem, was wir über die Welt wissen, aus komplexen Einstellungen oder Tendenzen besteht, die uns auf eine Interpretation über eine andere lehnen. Er argumentierte, dass, auch wenn wir explizite Symbole verwenden, verwenden wir sie vor einem unbewussten Hintergrund des Commonsense-Wissens und dass ohne diesen Hintergrund unsere Symbole nichts bedeuten. Dieser Hintergrund, in Dreyfus' Ansicht, wurde nicht in einzelnen Gehirnen als explizite Einzelsymbole mit expliziten individuellen Bedeutungen umgesetzt. Die epistemologische Annahme Alle Kenntnisse können formalisiert werden. Dies betrifft die philosophische Frage der Epistemologie oder die Untersuchung des Wissens. Selbst wenn wir zustimmen, dass die psychologische Annahme falsch ist, könnten KI-Forscher noch argumentieren (wie KI-Gründer John McCarthy hat), dass es möglich ist, dass eine Symbolverarbeitungsmaschine alle Kenntnisse repräsentiert, unabhängig davon, ob Menschen das Wissen auf dieselbe Weise darstellen. Dreyfus argumentierte, dass es für diese Annahme keine Rechtfertigung gibt, da so viel menschliches Wissen nicht symbolisch ist. Die onlogische Annahme Die Welt besteht aus unabhängigen Tatsachen, die durch unabhängige Symbole dargestellt werden können.Dreyfus identifizierte auch eine subtilere Annahme über die Welt. KI-Forscher (und Futuristen und Science-Fiction-Autoren) gehen oft davon aus, dass es keine Grenzen für formales, wissenschaftliches Wissen gibt, weil sie davon ausgehen, dass jedes Phänomen im Universum durch Symbole oder wissenschaftliche Theorien beschrieben werden kann. Dies geht davon aus, dass alles, was existiert, als Objekte, Eigenschaften von Objekten, Klassen von Objekten, Beziehungen von Objekten usw. verstanden werden kann: genau jene Dinge, die durch Logik, Sprache und Mathematik beschrieben werden können. Die Studie des Seins oder der Existenz wird zur Ontologie aufgerufen, und so nennt Dreyfus dies die ontologische Annahme. Wenn das falsch ist, dann hebt es Zweifel an dem, was wir letztlich wissen können und was intelligente Maschinen uns letztendlich helfen können. Knowing-how vs. knowing- that: the Primacy of intuition In Mind Over Machine (1986), geschrieben während der Blüte der Expertensysteme, Dreyfus analysierte den Unterschied zwischen menschlichem Know-how und den Programmen, die behauptet, es zu erfassen. Dies erweiterte sich auf Ideen von What Computers Can't Do, wo er ein ähnliches Argument kritisierte die "kognitive Simulation" Schule der AI-Forschung von Allen Newell und Herbert A. Simon in den 1960er Jahren praktiziert. Dreyfus argumentierte, dass die menschliche Problemlösung und das Know-how von unserem Hintergrundgefühl des Kontexts abhängen, von dem, was wichtig und interessant angesichts der Situation ist, anstatt von dem Prozess der Suche durch Kombinationen von Möglichkeiten zu finden, was wir brauchen. Dreyfus würde es 1986 als den Unterschied zwischen Know-how und Know-how beschreiben, basierend auf Heideggers Unterscheidung von Gegenwart und Hand. Wissen-das ist unser bewusstes, schrittweises Problem, Fähigkeiten zu lösen. Wir nutzen diese Fähigkeiten, wenn wir ein schwieriges Problem, das uns erfordert, zu stoppen, zurück zu gehen und durch Ideen zu suchen. In solchen Momenten werden die Ideen sehr präzise und einfach: Sie werden kontextfreie Symbole, die wir mit Logik und Sprache manipulieren. Dies sind die Fähigkeiten, die Newell und Simon mit psychologischen Experimenten und Computerprogrammen demonstrierten. Dreyfus stimmte zu, dass ihre Programme die Fähigkeiten, die er als Know-how bezeichnet, angemessen nachahmen."Wissen-wie ist auf der anderen Seite die Art, wie wir mit Dingen in der Regel umzugehen. Wir ergreifen Handlungen, ohne bewusste symbolische Argumentation überhaupt zu verwenden, als wenn wir ein Gesicht erkennen, uns zur Arbeit fahren oder das Richtige finden. Wir scheinen einfach auf die entsprechende Antwort zu springen, ohne irgendwelche Alternativen zu berücksichtigen. Das ist das Wesen der Kompetenz, Dreyfus argumentierte: Wenn unsere Intuitionen so ausgebildet wurden, dass wir die Regeln vergessen und einfach "die Situation vergrößern" und reagieren. Der menschliche Sinn der Situation, nach Dreyfus, basiert auf unseren Zielen, unseren Körpern und unserer Kultur – all unseren unbewussten Intuitionen, Einstellungen und Wissen über die Welt. Dieser „Kontext“ oder Hintergrund (bezogen auf Heideggers Dasein) ist eine Form von Wissen, die nicht in unserem Gehirn symbolisch, aber intuitiv in irgendeiner Weise gespeichert wird. Es wirkt sich auf das, was wir bemerken und was wir nicht bemerken, was wir erwarten und welche Möglichkeiten wir nicht berücksichtigen: wir unterscheiden zwischen dem Wesentlichen und Unwesentlichen. Die Dinge, die unwesentlich sind, werden in unser "Fringe-Bewusstsein" (mit einem Satz von William James:) die Millionen von Dingen, von denen wir uns bewusst sind, zurückgegeben, aber wir denken jetzt nicht wirklich darüber nach. Dreyfus glaubt nicht, dass KI-Programme, wie sie in den 70er und 80er Jahren umgesetzt wurden, diesen Hintergrund erfassen oder die Art der schnellen Problemlösung tun könnten, die es erlaubt. Er argumentierte, dass unser unbewusstes Wissen nie symbolisch erfasst werden könne. Wenn KI nicht einen Weg finden konnte, diese Probleme zu lösen, dann wurde es zum Scheitern verurteilt, eine Übung in "tree Klettern mit den Augen auf den Mond". Geschichte Dreyfus begann seine Kritik in den frühen 1960er Jahren zu formulieren, während er Professor am MIT war, dann ein Hotbed der künstlichen Intelligenz Forschung. Seine erste Veröffentlichung zu diesem Thema ist ein halber Widerspruch gegen ein Gespräch von Herbert A. Simon im Frühjahr 1961. Dreyfus war besonders beunruhigt, als Philosoph, dass KI-Forscher glaubten, dass sie am Rande der Lösung vieler langer philosophischer Probleme innerhalb weniger Jahre waren, mit Computern. Alchemy und Künstliche IntelligenzIm Jahr 1965 wurde Dreyfus von Paul Armer (mit Hilfe seines Bruders Stuart Dreyfus) angeheuert, um den Sommer in der Santa Monica-Anlage der RAND Corporation zu verbringen, wo er Alchemy und Künstliche Intelligenz, den ersten Salvo seines Angriffs schreiben würde. Armer hatte gedacht, dass er einen unparteiischen Kritiker eingestellt hat und war überrascht, als Dreyfus ein schwitzendes Papier produzierte, das die Grundlagen des Feldes zerstören soll. (Armer sagte, er sei sich der vorherigen Veröffentlichung von Dreyfus nicht bewusst.) Armer verzögerte die Veröffentlichung, aber letztlich erkannte, dass "nur weil es zu einer Schlussfolgerung kam, dass Sie nicht mögen war kein Grund, es nicht zu veröffentlichen". Es kam schließlich als RAND Memo heraus und wurde bald ein bester Verkäufer. Das Papier, das flach lächerliche AI-Forschung, Vergleich mit Alchemie: ein falscher Versuch, Metalle auf Gold basierend auf einer theoretischen Grundlage zu ändern, die nicht mehr als Mythologie und Wunschdenken war. Es hat die grandiosen Vorhersagen von führenden KI-Forschern belästigt und vorhergesagt, dass es Grenzen gab, über die KI nicht fortschreiten und intimieren würde, dass diese Grenzen bald erreicht werden. Reaktion Die Zeitung "verursacht einen Aufruhr", so Pamela McCorduck. Die Antwort der KI-Gemeinschaft war ableitend und persönlich. Seymour Papert entließ ein Drittel des Papiers als Klatsch und behauptete, jede Notierung sei bewusst aus dem Kontext genommen worden. Herbert A. Simon beschuldigte Dreyfus, Politik zu spielen, damit er den prestigeträchtigen RAND-Namen seinen Ideen anschließen konnte. Simon sagte: "Was ich davon erzählt habe, war der RAND-Name, der an diesem Müll angebracht war." Dreyfus, der am MIT gelehrt hat, erinnert sich daran, dass seine Kollegen in KI arbeiten "nicht gesehen werden, mit mir zu essen. "Joseph Weizenbaum, der Autor von ELIZA, fühlte, dass die Behandlung seiner Kollegen von Dreyfus unprofessionell und kindisch war. Obwohl er ein ausgesprochener Kritiker der Positionen von Dreyfus war, erinnert er sich: "Ich wurde das einzige Mitglied der KI-Gemeinschaft, um mit Dreyfus Mittagessen zu essen zu sehen. Und ich machte es bewusst klar, dass sie nicht der Weg waren, einen Menschen zu behandeln. " Die Zeitung war am 11. Juni 1966 in der Zeitschrift New Yorker kurz. Das Stück erwähnte Dreyfus' Behauptung, dass, während Computer in der Lage sein können, Schecker spielen, kein Computer könnte noch ein anständiges Spiel Schach spielen. Es berichtete mit wry humor (wie Dreyfus hatte) über den Sieg eines zehnjährigen über das führende Schachprogramm, mit "gerade mehr als seine übliche Schmugheit. " In der Hoffnung, den Ruf von AI wiederherzustellen, arrangierte Seymour Papert ein Schachspiel zwischen Dreyfus und Richard Greenblatts Mac Hack Programm. Dreyfus verloren, viel zu Paperts Zufriedenheit. Ein Verband für Computing Machinery-Bulletin verwendet die Schlagzeile: "Ein Zehnjähriger kann die Maschine schlagen – Dreyfus:Aber die Maschine kann Schlag Dreyfus"Dreyfus klagte im Druck, dass er nicht sagte, ein Computer wird nie Schach spielen, zu dem Herbert A. Simon antwortete: "Sie sollten erkennen, dass einige von denen, die von Ihrem scharfkantigen Prote gebissen werden wahrscheinlich, in ihrer menschlichen Schwäche zu sein... Vindicated Anfang der 1990er Jahre waren einige der radikalen Meinungen von Dreyfus zum Mainstream geworden. Verfehlte Vorhersagen. Wie Dreyfus vorhergesehen hatte, konnten die grandiosen Vorhersagen der frühen KI-Forscher nicht wahr werden. Volle intelligente Maschinen (jetzt bekannt als "starke KI") erschienen Mitte der 1970er Jahre nicht wie vorhergesagt. HAL 9000 (welche Fähigkeiten für natürliche Sprache, Wahrnehmung und Problemlösung auf der Grundlage der Ratschläge und Meinungen von Marvin Minsky) erschien im Jahr 2001 nicht."AI-Forscher", schreibt Nicolas Fearn, "klar haben einige erklären zu tun. "Heute sind Forscher viel zögerlicher, die Art von Vorhersagen zu machen, die in den frühen Tagen gemacht wurden.( Obwohl einige Futuristen wie Ray Kurzweil noch der gleichen Art von Optimismus unterworfen sind.) Die biologische Annahme, obwohl in den vierziger und frühen fünfziger Jahren üblich, wurde von den meisten KI-Forschern nicht mehr angenommen, als Dreyfus veröffentlichte What Computers Can't Do. Obwohl viele immer noch behaupten, dass es wichtig ist, das Gehirn durch die Simulation der Wirkung von Neuronen (wie Ray Kurzweil oder Jeff Hawkins) zu reversieren, nehmen sie nicht an, dass Neuronen im Wesentlichen digital sind, sondern dass die Wirkung von analogen Neuronen durch digitale Maschinen auf ein vernünftiges Maß an Genauigkeit simuliert werden kann. (Alan Turing hatte diese Beobachtung bereits 1950 gemacht.) Die psychologische Annahme und unbewusste Fähigkeiten. Viele KI-Forscher sind sich darin einig, dass menschliche Vernunft nicht primär aus hochrangiger Symbolmanipulation besteht. Da Dreyfus seine Kritiken in den 60er Jahren erstmals veröffentlichte, hat sich die AI-Forschung im Allgemeinen von der hochrangigen Symbolmanipulation oder GOFAI in Richtung neuer Modelle bewegt, die mehr von unserem unbewussten Denken erfassen sollen. Daniel Crevier schreibt, dass bis 1993, im Gegensatz zu 1965, KI-Forscher "nicht mehr die psychologische Annahme gemacht" und ohne sie fortgeführt hatte. In den 1980er Jahren waren diese neuen subsymbolischen Ansätze enthalten: Computational Intelligence Paradigmen, wie neuronale Netze, evolutionäre Algorithmen usw., werden meist auf simulierte unbewusste Argumentation gerichtet. Dreyfus selbst stimmt zu, dass diese subsymbolischen Methoden die Art von Tendenzen und Einstellungen erfassen können, die er für Intelligenz und Know-how als wesentlich erachtet. Die Erforschung des gemeinsamen Wissens hat sich darauf konzentriert, den Hintergrund oder den Kontext des Wissens zu reproduzieren. Robotik-Forscher wie Hans Moravec und Rodney Brooks waren unter den ersten, um zu erkennen, dass unbewusste Fähigkeiten sich als die schwierigste, rückgängige Ingenieur.(Siehe Moravec paradox). Brooks würde eine Bewegung in den späten 80er Jahren, die direktes Ziel auf die Verwendung von hochrangigen Symbolen, genannt Nouvelle AI. Die bewegte Bewegung in der Robotik-Forschung versucht, unsere unbewussten Fähigkeiten in Wahrnehmung und Aufmerksamkeit zu erfassen. In den 1990er Jahren und in den frühen Jahrzehnten des 21. Jahrhunderts nutzten statistikbasierte Ansätze zum maschinellen Lernen Techniken im Zusammenhang mit Wirtschaft und Statistik, um Maschinen zu erraten – ungenaue, probabilistische Entscheidungen und Vorhersagen auf Basis von Erfahrung und Lernen zu treffen. Diese Programme simulieren die Art und Weise, wie unsere unbewussten Instinkte in der Lage sind, die Anomalien wahrzunehmen, zu bemerken und schnelle Urteile zu machen, ähnlich dem, was Dreyfus "die Situation zu erkennen und zu reagieren" nannte, aber hier besteht die Situation aus riesigen Mengen von numerischen Daten. Diese Techniken sind sehr erfolgreich und werden derzeit in Industrie und Wissenschaft weit verbreitet. Diese Forschung ist ohne direkte Verbindung zu Dreyfus' Arbeit vorangegangen. Know-how und Know-how-das. Die Forschung in Psychologie und Ökonomie konnte zeigen, dass Dreyfus' (und Heideggers) Spekulation über die Art der menschlichen Problemlösung im Wesentlichen korrekt war. Daniel Kahnemann und Amos Tversky sammelten eine große Menge harter Beweise, dass Menschen zwei sehr unterschiedliche Methoden verwenden, um Probleme zu lösen, die sie "System 1" und "System 2" nannten. System eins, auch als adaptives Unbewusstes bekannt, ist schnell, intuitiv und unbewusst. System 2 ist langsam, logisch und bewusst. Ihre Forschung wurde im Buch Thinking, Fast and Slow gesammelt und inspirierte Malcolm Gladwells populäres Buch Blink. Wie bei KI war diese Forschung völlig unabhängig von Dreyfus und Heidegger. Ignoriert Obwohl klar die KI-Forschung mit Dreyfus einverstanden ist, sagte McCorduck: "Mein Eindruck ist, dass dieser Fortschritt stückweise und als Reaktion auf harte gegebene Probleme stattgefunden hat und Dreyfus nichts verdankt." Die AI-Gemeinschaft, mit einigen Ausnahmen, entschied sich nicht, auf Dreyfus direkt zu reagieren. " Er ist zu dumm, ernst zu nehmen" sagte ein Forscher Pamela McCorduck. Marvin Minsky sagte von Dreyfus (und den anderen Kritiken aus der Philosophie), dass "sie missverstehen, und sollten ignoriert werden. " Als Dreyfus Alchemy und AI erweiterte, um Länge zu buchen und veröffentlichte es als What Computers Can't Do 1972, niemand aus der KI-Gemeinschaft wählte zu antworten (mit Ausnahme von einigen kritischen Bewertungen). McCorduck fragt: "Wenn Dreyfus so falsch geköpft ist, warum haben sich die künstlichen Intelligenzen nicht mehr bemüht, ihm zu widersprechen?" Ein Teil des Problems war die Art der Philosophie, die Dreyfus in seiner Kritik verwendet. Dreyfus war Experte für moderne europäische Philosophen (wie Heidegger und Merleau-Ponty). KI-Forscher der 1960er Jahre hingegen basierten ihr Verständnis des menschlichen Verstandes auf Ingenieurprinzipien und effiziente Problemlösungstechniken im Zusammenhang mit der Managementwissenschaft. Auf fundamentaler Ebene sprachen sie eine andere Sprache. Edward Feigenbaum beschwerte sich: "Was bietet er uns an? Phänomenologie! Der Ball des Fluffs. Diese Süßigkeiten aus Baumwolle! "Im Jahr 1965 gab es einfach zu große Lücke zwischen europäischer Philosophie und künstlicher Intelligenz, eine Lücke, die seither von kognitiver Wissenschaft, Verbindungsismus und Robotikforschung erfüllt wurde. Es würde viele Jahre dauern, bis künstliche Intelligenz-Forscher in der Lage waren, die Fragen, die für die kontinentale Philosophie wichtig waren, wie Liegenschaft, Verkörperung, Wahrnehmung und Gestalt anzugehen. Ein weiteres Problem war, dass er behauptete (oder schien zu behaupten), dass KI nie in der Lage sein würde, die menschliche Fähigkeit zu erfassen, Kontext, Situation oder Zweck in Form von Regeln zu verstehen. Aber (wie Peter Norvig und Stuart Russell später erklären würden), kann ein Argument dieser Form nicht gewonnen werden: Nur weil man sich keine formalen Regeln vorstellen kann, die menschliche Intelligenz und Fachwissen regieren, bedeutet dies nicht, dass es keine solchen Regeln gibt.Sie zitieren Alan Turings Antwort auf alle Argumente wie Dreyfuss: "Wir können uns nicht so leicht von der Abwesenheit völliger Verhaltensgesetze überzeugen. Wir wissen nur, wie wir solche Gesetze finden, daß wir wissen, daß es keine Umstände gibt, unter denen wir sagen könnten: "Wir haben genug gesucht. Es gibt keine solchen Gesetze.'"Dreyfus hat nicht erwartet, dass KI-Forscher ihren Fehler erkennen und beginnen, auf neue Lösungen zu arbeiten, weg von den symbolischen Methoden, die Dreyfus kritisierte. 1965 stellte er sich nicht vor, dass solche Programme eines Tages erstellt werden würden, so dass er behauptete, KI sei unmöglich. Im Jahr 1965 haben sich KI-Forscher nicht vorgestellt, dass solche Programme notwendig seien, so dass sie behaupteten, KI sei fast vollständig. Beide waren falsch. Ein ernsteres Problem war der Eindruck, dass Dreyfus' Kritik unkorrigierbar feindselig war. McCorduck schrieb: "Seine Abscheulichkeit war so provozierend, dass er jemanden entfremdet hat, den er vielleicht erleuchtet hat. Und das ist schade. "Daniel Crevier sagte, "die Zeit hat die Genauigkeit und Wahrnehmung einiger der Kommentare von Dreyfus bewiesen. Hätte er sie weniger aggressiv formuliert, könnten konstruktive Handlungen, die sie vorgeschlagen haben, viel früher ergriffen worden sein." Weitere Informationen siehe Adaptive unbewusst Church–Turing thesis Computer chess Hubert Dreyfus MIT Philosophie der künstlichen Intelligenz Referenzen Brooks, Rodney (1990), "Elefanten spielen keine Schach" (PDF), Robotik und Autonomous Systems, 6 (1–2:) 3–15, CiteSeerX 10.1.1.588.7539, doi:10 2007/S0921-88(05 Presse, ISBN 978-0-06-090624-5.Dreyfus, Hubert; Dreyfus, Stuart (1986), Mind over Machine:The Power of Human Intuition and Expertise in the Era of the Computer, Oxford, U.K: Blackwell.Dreyfus, Hubert (1992), What Computers Still Can't Do, New York: MIT Press, ISBN 978-0-262-54067-4 Fearn, Nicholas Great York Gladwell, Malcolm (2005), Blink: The Power of Thinking without Thinking, Boston: Little, Brown, ISBN 978-0-316-17232-5.Hawkins, Jeff; Blakeslee, Sandra (2005), On Intelligence, New York, NY: Owl Books, ISBN 978-0-8050-7853-4. Höre, Marti A;. Hirsh, Haym; Bundy, A;. Berliner, H;. Feigenbaum, E.A; Buchanan, B.G; Selfridge, O;. Michie, D;. Nilsson, N. (Januar–Februar 2000), "AI's Greatest Trends and Controversies", IEEE Intelligent Systems, 15 (1:) 8–17, doi:10.1109/5254.820322. Horst, Steven (Fall 2005), "The Computational Theory of Mind", in Zalta, Edward N. (Hrsg.), The Stanford Encyclopedia of Philosophy. Kurzweil, Ray (2005), The Singularity is Near, New York: Viking Press, ISBN 978-0-670-03384-3.McCorduck, Pamela (2004), Machines Who Think (2. ed,). Natick, MA: A. K. Peters, Ltd., ISBN 1-56881-205-1 Moravec, Hans (1988), Mind Children, Harvard University Press, ISBN 978-0-674-57616-2.Newell, Allen; Simon, H. A. (1963), "GPS: A Program that Simulates Human Thought", in Feigenbaum, E.A; Feldman, J. (eds,). Computer und Gedanken, New York: McGraw-Hill Russell, Stuart J;. Norvig, Peter (2003), Künstliche Intelligenz: Ein moderner Ansatz (2. ed,). Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2.Turing, Alan (Oktober 1950), "Computing Machinery and Intelligence", Mind, LIX (236:) 433–460, doi:10.1093/mind/LIX.236.433, ISSN 0026-4423.