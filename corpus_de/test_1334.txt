Ein Autoencoder ist eine Art künstliches neuronales Netzwerk, das verwendet wird, um effiziente Codierungen von unmarkierten Daten zu lernen (unsupervised learning). Die Kodierung wird validiert und verfeinert, indem versucht wird, den Eingang aus der Kodierung zu regenerieren. Der Autoencoder erlernt eine Darstellung (Kodierung) für eine Reihe von Daten, typischerweise zur Dimensionsreduktion, indem er das Netzwerk ausbildet, um unbedeutende Daten zu ignorieren ("Rausch"). Es gibt Varianten, die darauf abzielen, die gelernten Darstellungen zu zwingen, nützliche Eigenschaften einzunehmen. Beispiele sind normierte Autoencoder (Sparse, Denoising und Contractive), die in Lerndarstellungen für nachfolgende Klassifikationsaufgaben und Variationsautoencoder mit Anwendungen als generative Modelle wirksam sind. Autoencoder werden auf viele Probleme angewendet, von der Gesichtserkennung, Merkmalserkennung, Anomalie-Erkennung, um die Bedeutung von Wörtern zu erwerben. Autoencoder sind auch generative Modelle: Sie können zufällig neue Daten generieren, die den Eingabedaten (Trainingsdaten) ähnlich sind. Grundarchitektur Ein Autoencoder hat zwei Hauptteile: einen Encoder, der die Eingabe in den Code abbildet, und einen Decoder, der den Code zu einer Rekonstruktion des Eingabes abbildet. Der einfachste Weg, die Kopieraufgabe perfekt auszuführen, wäre das Signal zu duplizieren. Stattdessen werden Autoencoder typischerweise gezwungen, die Eingabe näherungsweise zu rekonstruieren, wobei nur die relevanten Aspekte der Daten in der Kopie erhalten bleiben. Die Idee der Autoencoder ist seit Jahrzehnten beliebt. Die ersten Anträge stammen aus den 80er Jahren. Ihre traditionellste Anwendung war Dimensionsreduktion oder Feature-Learning, aber das Konzept wurde weit verbreitet für das Erlernen generativer Datenmodelle. Einige der mächtigsten KIs in den 2010er Jahren beteiligten Autoencoder in tiefen neuronalen Netzwerken gestapelt. Die einfachste Form eines Autoencoders ist ein zukunftsweisendes, nicht-rezidivierendes neuronales Netz ähnlich wie einschichtige Perceptronen, die an mehrschichtigen Perceptronen (MLP) teilnehmen – mit einer Eingangsschicht und einer von einer oder mehreren verdeckten Schichten verbundenen Ausgangsschicht. Die Ausgangsschicht hat die gleiche Anzahl von Knoten (neurons) wie die Eingangsschicht. Sein Ziel ist es, seine Inputs (Minimierung der Differenz zwischen dem Input und dem Output) zu rekonstruieren, anstatt einen Zielwert Y \{displaystyle Y} bei Eingängen X \{displaystyle X} vorherzusagen. Ein Autoencoder besteht aus zwei Teilen, dem Encoder und dem Decoder, der als Übergänge φ \{displaystyle \phi } und ψ, \{displaystyle \psi ,} definiert werden kann, so dass: φ : X → F \{displaystyle \phi :{\mathcal (X) ψ ψ : F → X \{displaystyle \psi :{\mathcal {F}}\rightarrow {\mathcal {X} φ φ, ψ = a r m i n φ φ , ψ ψ ψ φ φ φ , ψ = a r m i n φ φ φ , ψ ψ ψ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ  }{,|\mathcal {X}(\psi \circ \phi {)\mathcal X}\{2 Im einfachsten Fall, bei einer versteckten Schicht, nimmt die Encoder-Stufe eines Autoencoders den Eingang x ε R d = X \{displaystyle \mathbf {x} \in \mathbb {R} ^d}={\mathcal {X} und maps es zu h ε R p = F \{displaystyle \mathbf {h} \in \mathbb {R} ^p}={\mathcal {F}: h = σ (W x + b) \{displaystyle \mathbf {h}=\sigma (\mathbf {wx} +\mathbf {b}}}}}}}}} Dieses Bild h \{displaystyle \mathbf {h} wird in der Regel als Code, latente Variablen oder eine latente Darstellung bezeichnet. σ \{displaystyle \sigma } ist eine elementweise Aktivierungsfunktion wie eine Sigmoidfunktion oder eine gleichgerichtete Lineareinheit. W \{displaystyle \mathbf {W} ist eine Gewichtsmatrix und b \{displaystyle \mathbf {b} ist ein Biasvektor. Gewichte und Bias werden in der Regel zufällig initialisiert und dann iterativ während des Trainings durch Backpropagation aktualisiert. ii) ii) ii Autoencoder werden ausgebildet, um Rekonstruktionsfehler zu minimieren (z.B. quadratische Fehler), oft als Verlust bezeichnet: L ( x, x') = x - x' zusammengestellt 2 = x - σ' ( W' ( σ ( W x + b) \) + b') gebildet 2 \{displaystyle {\mathcal {L}}(\mathbf {x}} -\mathbf {x} -\sigma '(\mathbf {W'} (\sigma (\mathbf {Wx} +\mathbf {b} +)\mathbf {b'} {)^^\2} wobei x \{displaystyle \mathbf {x} } üblicherweise über das Trainingsset gemittelt wird. Wie bereits erwähnt, wird Autoencoder-Training durch die Rückverbreitung des Fehlers durchgeführt, wie auch andere Feedforward-Neural-Netzwerke. Sollte der Funktionsraum F \{displaystyle {\mathcal {F} eine geringere Dimensionalität aufweisen als der Eingangsraum X \{displaystyle {\mathcal {X}, so kann der Merkmalsvektor φ (x) \{displaystyle \phi (x}) als komprimierte Darstellung des Eingangs x \{displaystyle x} betrachtet werden. Dies ist der Fall von unvollständigen Autoencoder. Wenn die versteckten Schichten größer sind als (überkomplett) oder gleich, die Eingangsschicht oder die versteckten Einheiten genügend Kapazität erhalten, kann ein Autoencoder die Identitätsfunktion möglicherweise erlernen und nutzlos werden. Allerdings zeigten experimentelle Ergebnisse, dass überkomplete Autoencoder noch nützliche Features lernen könnten. In der idealen Einstellung könnte die Codedimension und die Modellkapazität auf der Grundlage der Komplexität der zu modellierenden Datenverteilung eingestellt werden. Eine Möglichkeit, dies zu tun, ist, die Modellvarianten zu nutzen, die als Regularized Autoencoders bekannt sind. Variationen Regelmäßige Autocodierer Es gibt verschiedene Techniken, um Autoencoder daran zu hindern, die Identitätsfunktion zu lernen und ihre Fähigkeit zu verbessern, wichtige Informationen zu erfassen und reichere Darstellungen zu lernen. Sparse Autoencoder (SAE)Erklärung in einer Weise, die Sparsity fördert, verbessert die Leistung bei Klassifizierungsaufgaben. Sparse Autoencoder können mehr (statt weniger) versteckte Einheiten enthalten als Eingänge, aber nur eine kleine Anzahl der versteckten Einheiten sind erlaubt, gleichzeitig aktiv zu sein (also, spärlich). Diese Einschränkung zwingt das Modell, auf die einzigartigen statistischen Merkmale der Trainingsdaten zu reagieren. Insbesondere ist ein Sparse Autoencoder ein Autoencoder, dessen Trainingskriterium eine Sparsity Strafe Ω (h ) \{displaystyle \Omega (\{boldsymbol {h}) auf der Codeschicht h \{displaystyle \{bold\h} . L ( x, x') + Ω (h ) \{displaystyle {\mathcal {m} Dass h = f (W x + b) \{displaystyle \{boldsymbol h}}=f({\boldsymbol) W}{\boldsymbol x}+{\boldsymbol {b}) , die Strafe ermutigt das Modell zu aktivieren (d.h. Ausgabewert in der Nähe von 1) spezifische Bereiche des Netzes auf Basis der Eingangsdaten, während inaktivieren alle anderen Neuronen (d.h. einen Ausgangswert in der Nähe von 0). Diese Sparsamkeit kann durch unterschiedliche Formulierung der Strafbedingungen erreicht werden. Eine Möglichkeit ist, die Kullback-Leibler (KL) Divergenz auszunutzen. ρ j ^ = 1 m Σ i = 1 m [ h j ( x i ) ] \{displaystyle \{hat \{rho _j}}={\frac 1}{m}\sum i=1}^{m}[h_{j}(x_{i)] die durchschnittliche Aktivierung der versteckten Einheit j \{displaystyle j} (gemittelt über die m \{displaystyle m} Trainingsbeispiele). Die Notation h j ( x i ) \{displaystyle h_{j}(x_{i) identifiziert den Eingangswert, der die Aktivierung ausgelöst hat. Um die meisten Neuronen zu ermutigen, inaktiv zu sein, muss ρ j ^ \{displaystyle \{hat \{rho _{j} in der Nähe von 0 sein. Daher erzwingt diese Methode die Beschränkung ρ j ^ = ρ \{displaystyle \{hat \{rho _{j}}=\rho } wobei ρ \{displaystyle \rho } der Sparsity-Parameter ist, ein Wert nahe Null. Der Strafbegriff Ω (h ) \{displaystyle \Omega (\{boldsymbol {h}) bildet ein Formular, das ρ j ^ \{displaystyle \{hat \{hat \{rho _{j} für eine deutliche Abweichung von ρ \{displaystyle \rho }, die Nutzung der KL Divergenz: Σ j = 1 s K L ( ρ | | ρ ρ j ^ ^ ) = Σ j = 1 s [ ρ log υ ρ ρ j ^ + ( 1 - ρ ρ ρ ) log = 1 - ρ 1 - ρ j ^ ^ _{j}}}=\sum _j=1}{\left[\rho \log \\frac \{rho  {hat \{rho ^^^^}+(1-\rho )\log {\frac {1-\rho }1-{\hat \{rho_{j}}}}}}\right], wo j \{displaystyle j} über die versteckten Knoten s \{displaystyle s} in der versteckten Schicht summiert, und K L ( ρ | | | ) .Anotherway, um Sparsity zu erreichen, ist durch die Anwendung von L1 oder L2 Regularisierungsbegriffen auf die Aktivierung, skaliert durch einen bestimmten Parameter λ \{displaystyle \lambda } . Zum Beispiel wird bei L1 die Verlustfunktion L ( x, x') + λ Σ i | h i | \{displaystyle {\mathcal {L}(\mathbf {x},\mathbf {x'} +) ) Eine weitere vorgeschlagene Strategie, die Sparsität zu zwingen, besteht darin, manuell alle, aber die stärkste versteckte Einheit Aktivierungen (k-sparse Autoencoder) zu Null. Der k-sparse Autoencoder basiert auf einem linearen Autoencoder (d.h. mit linearer Aktivierungsfunktion) und gebundenen Gewichten. Die Identifizierung der stärksten Aktivierungen kann erreicht werden, indem die Aktivitäten sortiert und nur die ersten k-Werte gehalten werden, oder durch die Verwendung von ReLU versteckten Einheiten mit Schwellen, die adaptiv angepasst werden, bis die k größten Aktivitäten identifiziert werden. Diese Selektion wirkt wie die zuvor genannten Regularisierungsbegriffe, indem sie verhindert, dass das Modell den Eingang mit zu vielen Neuronen rekonstruiert. Denoising autoencoder (DAE)Denoising autoencoder (DAE) versuchen, eine gute Darstellung durch Änderung des Rekonstruktionskriteriums zu erreichen. In der Tat, DAEs nehmen eine teilweise beschädigte Eingabe und sind ausgebildet, um die ursprüngliche unverfälschte Eingabe wiederherzustellen. In der Praxis ist das Ziel, Autoencoder zu verleugnen, die korrupte Eingabe zu reinigen oder zu verleugnen. Zwei Annahmen sind diesem Ansatz innewohnend: Höhere Darstellungen sind relativ stabil und robust gegenüber der Korruption der Eingabe; Um die Entzerrung gut durchzuführen, muss das Modell Merkmale, die nützliche Struktur in der Eingabeverteilung erfassen, extrahieren. Mit anderen Worten, Denoising wird als Ausbildungskriterium für das Lernen befürwortet, nützliche Merkmale zu extrahieren, die bessere Darstellungen auf höherer Ebene des Inputs darstellen. Die Ausbildung eines DAE funktioniert wie folgt: Der Anfangseingang x \{displaystyle x} wird durch stochastische Kartierung x ~  q q D ( x ~ | x | x ) \{displaystyle \{boldsymbol \{boldsymbol \{tilde {x}}}\thicksim q_{D}({\boldsymbol \{tilde x}}}}{\}}}}}\Der beschädigte Eingang x ~ \{displaystyle \{boldsymbol \{tilde {x} wird dann zu einer versteckten Darstellung mit dem gleichen Prozess des Standard-Autoncoders, h = f θ (rom ~ ) = s (W x ~ + b ) \{displaystyle \{boldsymbol h}}=f_{\theta }\({bold \{tilde x}}}}}}}}}} .Die Parameter des Modells θ \{displaystyle \theta } und θ' \{displaystyle \theta '} werden ausgebildet, um den durchschnittlichen Rekonstruktionsfehler über die Trainingsdaten zu minimieren, und zwar die Differenz zwischen z \{displaystyle \{bold} und dem ursprünglichen unkorrupten Eingang x \{displaystyle \{x}. Einige Beispiele können additiv isotropes Gausssches Rauschen, Maskierungsrauschen (ein für jedes Beispiel beliebig gewählter Anteil der Eingabe wird auf 0) oder Salz- und Pfefferrauschen (ein für jedes Beispiel beliebig gewählter Anteil der Eingabe wird auf seinen minimalen oder maximalen Wert mit gleichmäßiger Wahrscheinlichkeit eingestellt). Die Korruption der Eingabe wird nur während des Trainings durchgeführt. Nach dem Training wird keine Korruption hinzugefügt. Der Contractive Autoencoder (CAE)A Contractive Autoencoder fügt in seiner objektiven Funktion einen expliziten Regularizer hinzu, der das Modell dazu zwingt, eine Codierung zu lernen, die robust ist, um geringfügige Abweichungen von Eingangswerten zu erzielen. Dieser Regulator entspricht der Frobenius-Norm der Jacobian-Matrix der Encoder-Aktivierungen gegenüber dem Eingang. Da die Strafe nur auf Ausbildungsbeispiele angewendet wird, zwingt dieser Begriff das Modell, nützliche Informationen über die Ausbildungsverteilung zu erlernen. Die Endzielfunktion hat die folgende Form: L ( x , x') + λ Σ i ∇ ∇ ‡ ‡ x h i | | 2 \{displaystyle {\mathcal {L}(\mathbf {x},\mathbf {x'} +) \Lambda \sum _{i}||\nabla * Der Autoencoder wird als kontraktiv bezeichnet, weil er dazu ermutigt wird, eine Nachbarschaft von Eingabepunkten in eine kleinere Nachbarschaft von Ausgabepunkten zu ordnen. DAE ist mit CAE verbunden: In der Grenze des kleinen Gaussischen Eingangsrauschens machen DAEs die Rekonstruktionsfunktion kleinen, aber endlichen Eingangsstörungen widerstehen, während CAEs die extrahierten Funktionen unendlich simultanen Eingangsstörungen widerstehen. Konkreter Autoencoder Der Betonautoencoder ist für diskrete Merkmalsauswahl ausgelegt. Ein konkreter Autoencoder zwingt den latenten Raum, nur aus einer benutzerspezifischen Anzahl von Merkmalen zu bestehen. Der konkrete Autoencoder nutzt eine kontinuierliche Entspannung der kategorischen Verteilung, um Gradienten durch die Feature-Selektorschicht passieren zu lassen, die es ermöglicht, Standard-Backpropagation zu nutzen, um eine optimale Teilmenge von Eingabefunktionen zu lernen, die Rekonstruktionsverlust minimieren. Variationsautoencoder (VAE)Variationale Autoencoder (VAEs) gehören zu den Familien der variierenden Bayesischen Methoden. Trotz der architektonischen Ähnlichkeiten mit grundlegenden Autoencoder, VAEs sind Architektur mit verschiedenen Zielen und mit einer völlig anderen mathematischen Formulierung. Der latente Raum wird dabei durch eine Mischung von Verteilungen anstelle eines festen Vektors zusammengesetzt. Bei einem Eingabedatensatz x \{displaystyle \mathbf {x} }, der durch eine unbekannte Wahrscheinlichkeitsfunktion P (x) \{displaystyle P(\mathbf {x} } gekennzeichnet ist, und einem multivariate latent encodingvektor z \{displaystyle \mathbfz} , ist das Ziel, die Daten als Verteilung p θ zu modellieren Vorteile der Tiefe Autoencoder werden oft mit einem einzigen Schicht-Encoder und einem einzigen Schicht-Decoder trainiert, aber mit vielen (tiefe) Encoder und Decoder bietet viele Vorteile. Depth kann exponentiell die Rechenkosten der Darstellung einiger Funktionen reduzieren. Depth kann exponentiell die Menge der Trainingsdaten verringern, die benötigt werden, um einige Funktionen zu lernen. Experimentell ergeben tiefe Autoencoder eine bessere Kompression gegenüber flachen oder linearen Autoencodern. Training Geoffrey Hinton entwickelte die Deep-Glaube-Netzwerk-Technik für die Ausbildung von vielschichtigen tiefen Autocodierern. Seine Methode besteht darin, jeden benachbarten Satz von zwei Schichten als eingeschränkte Boltzmann-Maschine zu behandeln, so dass das Vortraining eine gute Lösung annähert, dann mit Rückangriff auf das Feintun der Ergebnisse. Forscher haben darüber diskutiert, ob die gemeinsame Ausbildung (d.h. die Ausbildung der gesamten Architektur zusammen mit einem einzigen globalen Rekonstruktionsziel zur Optimierung) für tiefe Auto-Encoder besser wäre. Eine Studie von 2015 zeigte, dass gemeinsame Schulungen bessere Datenmodelle erlernen, zusammen mit repräsentativeren Merkmalen für die Klassifizierung im Vergleich zur schichtweisen Methode. Ihre Experimente zeigten jedoch, dass der Erfolg der gemeinsamen Ausbildung stark von den angenommenen Regularisierungsstrategien abhängt. Anwendungen Die beiden Hauptanwendungen von Autoencoder sind Dimensionsreduktion und Informationsretrieval, aber moderne Variationen wurden auf andere Aufgaben angewendet. Dimensionsreduktion Dimensionsreduktion war eine der ersten Deep Learning Anwendungen. Für die Studie von Hinton im Jahr 2006 hat er einen mehrschichtigen Autoencoder mit einem Stapel von RBMs vortrainiert und dann ihre Gewichte verwendet, um einen tiefen Autoencoder mit allmählich kleineren versteckten Schichten zu initialisieren, bis er einen Engpass von 30 Neuronen erreichte. Die resultierenden 30 Dimensionen des Codes ergaben gegenüber den ersten 30 Komponenten einer Hauptkomponentenanalyse (PCA) einen geringeren Rekonstruktionsfehler und erlernte eine Darstellung, die qualitativ einfacher zu interpretieren war, deutliche Trennung von Datenclustern. Die Darstellung der Dimensionen kann die Leistung auf Aufgaben wie Klassifizierung verbessern. In der Tat ist das Kennzeichen der Dimensionsreduktion darin, semantisch verwandte Beispiele nebeneinander zu platzieren. Hauptkomponentenanalyse Werden lineare Aktivierungen oder nur eine einzige sigmoide versteckte Schicht verwendet, so ist die optimale Lösung für einen Autoencoder stark mit der Hauptkomponentenanalyse (PCA) verbunden. Die Gewichte eines Autoencoders mit einer einzigen versteckten Größe p \{displaystyle p} (wo p \{displaystyle p} kleiner als die Größe der Eingabe ist) überspannen den gleichen Vektor-Teilraum wie derjenige, der von den ersten p \{displaystyle p} Hauptkomponenten aufgespannt ist, und der Ausgang des Autoencoders ist eine orthogonale Projektion auf diesen Subraum. Die Autoencodergewichte sind nicht gleich den Hauptkomponenten und sind in der Regel nicht orthogonal, aber die Hauptkomponenten können aus ihnen unter Verwendung der Singularwertzersetzung gewonnen werden. Das Potential von Autoencodern liegt jedoch in ihrer Nichtlinearität, so dass das Modell im Vergleich zu PCA leistungsfähigere Verallgemeinerungen erlernen und die Eingabe mit deutlich geringerem Informationsverlust rekonstruieren kann. Information retrieval Information retrieval profitiert insbesondere von der Midialitätsreduktion, dass die Suche in bestimmten Arten von niedrigen Dimensionen effizienter werden kann. Autoencoder wurden in der Tat auf semantische Hashing angewendet, vorgeschlagen von Salakhutdinov und Hinton im Jahr 2007. Durch Schulung des Algorithmus zur Erzeugung eines niederdimensionalen Binärcodes konnten alle Datenbankeinträge in einer Hash-Tabelle gespeichert werden, die Binärcodevektoren zu Einträgen abbildet. Diese Tabelle würde dann den Informationsabruf unterstützen, indem alle Einträge mit dem gleichen Binärcode wie die Abfrage zurückgegeben werden, oder geringfügig weniger ähnliche Einträge durch Flipping einiger Bits aus der Abfragecodierung. Eine weitere Anwendung für Autoencoder ist die Anomalieerkennung. Durch das Erlernen der salientesten Merkmale in den Trainingsdaten unter einigen der zuvor beschriebenen Zwänge wird das Modell ermutigt, die am häufigsten beobachteten Merkmale genau wiederzugeben. Bei Anomaliesen sollte das Modell seine Rekonstruktionsleistung verschlechtern. In den meisten Fällen werden nur Daten mit normalen Instanzen verwendet, um den Autoencoder zu trainieren; in anderen ist die Häufigkeit der Anomalien im Vergleich zur Beobachtungsmenge gering, so dass ihr Beitrag zur erlernten Darstellung ignoriert werden konnte. Nach dem Training wird der Autoencoder normale Daten genau rekonstruieren, während er dies nicht mit unbekannten anomalen Daten zu tun hat. Rekonstruktionsfehler (der Fehler zwischen den ursprünglichen Daten und deren dimensionale Rekonstruktion) wird als Anomalien-Score verwendet, um Anomalien zu erkennen. Die jüngste Literatur hat jedoch gezeigt, dass bestimmte Autoencoding-Modelle gegenläufig sehr gut bei der Rekonstruktion von anomaleren Beispielen sein können und somit keine Anomalie-Erkennung zuverlässig durchführen können. Bildverarbeitung Die Eigenschaften von Autoencodern sind bei der Bildverarbeitung nützlich. Ein Beispiel ist die verlustige Bildkompression, bei der Autoencoder andere Ansätze übertrafen und sich gegen JPEG 2000 als wettbewerbsfähig erwiesen. Eine weitere nützliche Anwendung von Autoencodern in der Bildvorverarbeitung ist die Bildentzerrung. Autoencoder fanden Verwendung in anspruchsvolleren Kontexten wie der medizinischen Bildgebung, wo sie für Bildentzerrung sowie Super-Resolution verwendet wurden. In der bildgestützten Diagnose haben Experimente Autoencoder für Brustkrebs-Erkennung angewendet und die Beziehung zwischen dem kognitiven Rückgang der Alzheimer-Krankheit und den latenten Merkmalen eines mit MRT ausgebildeten Autoencoders modelliert. Entdeckung von Drogen Im Jahr 2019 wurden Moleküle mit variierenden Autoencodern experimentell in Mäusen validiert. Popularity Vorhersage Vor kurzem, ein gestapeltes Autoencoder-Framework erzeugt vielversprechende Ergebnisse in der Vorhersage Popularität von Social Media-Beiträgen, die für Online-Werbungsstrategien hilfreich ist. Autoencoder wurden auf maschinelle Übersetzung angewendet, die in der Regel als neurale maschinelle Übersetzung (NMT) bezeichnet wird. Im Gegensatz zu herkömmlichen Autoencodern entspricht die Ausgabe nicht der Eingabe - sie ist in einer anderen Sprache. Im NMT werden Texte als zu kodierende Sequenzen in das Lernverfahren behandelt, während auf der Decoder-Seite Sequenzen in der Zielsprache(n) erzeugt werden. Sprachspezifische Autoencoder enthalten weitere sprachliche Merkmale in das Lernverfahren, wie z.B. chinesische Zersetzungsmerkmale. Siehe auch Representation learning Sparse Wörterbuch Lernen Deep Learning Referenzen Externe Links Autoencoder