Statistische Lerntheorie ist ein Rahmen für das maschinenlesbare Lernen aus den Bereichen Statistik und funktionelle Analyse. Statistische Lerntheorie befasst sich mit dem Problem, eine prädiktive Funktion auf der Grundlage von Daten zu finden. Statistische Lerntheorie hat zu erfolgreichen Anwendungen in Bereichen wie Computervision, Spracherkennung und Bioinformatik geführt. Lernziele sind Verständnis und Vorhersage. Lernen fällt in viele Kategorien, darunter beaufsichtigtes Lernen, unüberwachtes Lernen, Online-Kurs und verstärktes Lernen. Aus Sicht der statistischen Lerntheorie ist die Überwachung am besten verstanden. Supervised Learning umfasst das Lernen aus einem Fortbildungsangebot von Daten. Jeder Punkt in der Ausbildung ist ein Input-Output- Paar, bei dem die Input-Karten zu einem Output verwendet werden. Das Lernproblem besteht darin, die Funktion, die Karten zwischen dem Input und dem Output, so dass die erworbene Funktion genutzt werden kann, um den Output von künftigen Inputs vorherzusagen. Je nach Outputtyp sind die überwachten Lernprobleme entweder durch Regression oder durch Klassifikationsprobleme bedingt. Wenn die Produktion eine kontinuierliche Bandbreite an Werten aufweist, ist es ein Regressionsproblem. Ein Beispiel dafür ist, dass eine Regression mit Spannung als Input und aktuellem Output durchgeführt werden könnte. Die Regression würde die funktionelle Beziehung zwischen Spannungs und derzeitigem R TONdisplaystyle R} finden, so dass V = I R displaystyle V=IR} Klassifikationsprobleme sind diejenigen, für die der Output ein Element aus einem separaten Kennzeichnungssatz sein wird. Klassifikation ist sehr üblich für Anwendungen des maschinenlesbaren Lernens. In der Gesichtserkennung beispielsweise wäre ein Bild von einem Gesicht der Person der Input, und das Output-Label wäre dieser Name. Der Input wäre durch einen großen multidimensionalen Vektor vertreten, dessen Elemente im Bild dargestellt werden. Nach dem Erlernen einer Funktion auf der Grundlage der vorgegebenen Daten wird diese Funktion auf einer Testreihe von Daten, Daten, die nicht in der Ausbildungseinrichtung erscheinen, validiert. Kurze Beschreibung Take X WELLdisplaystyle X} als Vektorraum aller möglichen Inputs und Y WELLdisplaystyle Y} ist der Vektorraum aller möglichen Outputs. Statistische Lerntheorie ist der Ansicht, dass es einige unbekannte Wahrscheinlichkeitsverteilung über den Produktraum Z = X × Y displaystyle Z=X\times Y} gibt, d. h. es gibt einige unbekannte P ( z ) = p ( x → , y ) ) Memestyle p(z)=p(Sec {x}},y) .Die Ausbildung besteht aus n OLstyle n} aus dieser Wahrscheinlichkeit, z.B. · · S = { x 1,  S, ), ) )  1  1  ...  ...  ...  ...  ...  ...  ...  ...  ...  1  1  1  1  1  ...  ...  ...  1  1  ...  1  1  1  1  1  1  1  ...  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  x{_{1},y_{1}),\dots ,{(\vec x}}_{n},y_{n})==\{{\vecc z__{1},\dots , cuvec z}}_{n\ Jedes x → i KINGstyle Memevec x__{i ist ein Beitragsvektor aus den Schulungsdaten, und y i KINGstyle y_{i} ist das Ergebnis, das dem entspricht. In diesem formalismus besteht das Problem der Gleichgültigkeit darin, eine Funktion f zu finden: X → Y KINGstyle f:X\to Y}, so dass f ( x → )  y y WELLdisplaystyle f(Getvec {x}})\sim y} .Let H {\displaystyle {H} ist ein Raum der Funktionen f: X → Y KINGstyle f:X\to Y} nannte den hypothesis-Raum. Der hypothesis-Raum ist der Raum der Funktionen, die der Algorithmus durchsucht. Let V ( f ( x → ) , y ) {\displaystyle V(f(Fix}}),y ist die Verlustfunktion, ein Parameter für den Unterschied zwischen dem vorhergesagten Wert f ( x → ) Memedisplaystyle f(Getvec {x)} und dem tatsächlichen Wert Yendisplaystyle y}. I [ f ] =  X X × Y V ( x → ) , y ) p ( x → , y ) d x → d y displaystyle I[f]=\displaystyle \int {_X\times Y}V(f(Fisc x}}),y)\,p(Getvec x}},y)\,d cuvec {x}}\,dy Die Zielfunktion, die beste mögliche Funktion f Memedisplaystyle f}, die gewählt werden kann, wird vom f Memestyle f}, der f = inf h  I H I [ h ] Memestyle f=\inf {_h\in haushaltcal Mathematik {HII[h] Da die Wahrscheinlichkeitsverteilung p ( x → , y ) Memedisplaystyle p(ggiovec {x}},y) unbekannt ist, muss eine Berichtigungsmaßnahme für das erwartete Risiko verwendet werden. Diese Maßnahme basiert auf der Ausbildungseinrichtung, einer Stichprobe dieser unbekannten Wahrscheinlichkeitsverteilung. Es ist das empirische Risiko I S [ f ] = 1 n  i i = 1 n V ( f ( x → i ) , y i . I_{S}[f]=1,0frac 1}{n),displaystyle \sum _i=1}^{n}V(f(Portvec x}}_{i}),y_{i Ein Lerngorithmus, der die Funktion f S Memestyle f_{S} wählt, die das empirische Risiko minimieren, wird als empirische Risikominimierung bezeichnet. Verlustfunktionen Die Wahl der Verlustfunktion ist ein entscheidender Faktor für die Funktion f S {\displaystyle f_{S}, die vom Lerngorithmus gewählt wird. Die Verlustfunktion beeinflusst auch die Konvergenzquote für einen Algorithmus. Es ist wichtig, dass die Verlustfunktion konvex ist. Je nachdem, ob das Problem einer Regression oder einer Klassifizierung ist, werden verschiedene Verlustfunktionen verwendet. Regression Die häufigste Verlustfunktion für Regression ist die Quadratverlustfunktion (auch bekannt als L2-Norm). Diese vertraute Verlustfunktion wird in Ordinary Least Squares Regression verwendet. Form: V ( x → ) , y ) = ( y − f ( x → ) ) 2 7.8displaystyle V(f(Fisoc x{\),y)=(y-f(Porta x}})22 Der absolute Wertverlust (auch bekannt als L1-Norm) wird manchmal verwendet: V ( x → ) , y ) = ( x → ) [ ][ ] ][ ] ]displaystyle V(f(Fi) x{\),y)=|y-f( {x} Klassifikation In gewisser Weise ist die 0-1-Indikator-Funktion die wichtigste natürliche Verlustfunktion für die Einstufung. Es ist der Wert 0, wenn die vorhergesagte Produktion die gleiche wie die tatsächliche Produktion ist und der Wert 1, wenn die vorhergesagte Produktion von der tatsächlichen Produktion unterscheidet. für binäre Klassifizierung mit Y = { ‐ 1 , 1 } displaystyle Y=-1-1,1} , das ist: V ( x → ) , y ) =  x ( − y f ( x → ) ) {\displaystyle V(f) cuvec {x}}),y)=\theta -yf( {x) {x)}, wo . Memestyle \theta } die Heaviside-Funktion ist. Regularisierung Probleme beim maschinenlesbaren Lernen, ein großes Problem, das sich aus der Überrüstung ergibt. Da das Lernen ein Vorhersageproblem ist, besteht das Ziel darin, keine Funktion zu finden, die den (vorhergesehenen) Daten am engsten entspricht, sondern eine zu finden, die die Ergebnisse künftiger Beiträge am besten vorhersagen wird. Empirische Risikominimierung birgt dieses Risiko einer Überrüstung: eine Funktion, die den Daten genau entspricht, aber keine Vorhersage für die künftige Leistung. Umrüstung ist symptomatisch von unwiderruflichen Lösungen; eine kleine Perturbation in den gesetzten Daten würde eine große Veränderung der gelernten Funktion verursachen. Man kann nachweisen, dass die Stabilität für die Lösung gewährleistet werden kann, dass die Generalisierung und Kohärenz ebenfalls gewährleistet sind. Regularisierung kann das Problem lösen und die Problemstabilität gewährleisten. Regularisierung kann durch Einschränkung des Hypothesis-Raums H HANAdisplaystyle {H} erreicht werden. Ein gemeinsames Beispiel würde H {\displaystyle {H} auf lineare Funktionen beschränken: Dies kann als Reduzierung des Standardproblems der linearen Regression angesehen werden. H {\displaystyle {H} könnte auch auf Polynomial des Grades p Memestyle p}, exponentielle oder gebundene Funktionen auf L1.Relimitierung des hypothesis-Raums beschränkt werden, weil die Form der möglichen Funktionen begrenzt ist und somit nicht die Wahl einer Funktion erlaubt, die empirischen Risiken nahe Null gibt. Ein Beispiel für die Regularisierung ist Tikhonov Regularisierung. Dies besteht aus einer Minimierung von 1 n  i i = 1 n V ( f ( x → i ) , y i) +  of F  H H 2 {\displaystyle \sum _i=1 n}V(f(f)vec x__{i}),y_{i} f\|_grocal H22 ist ein fester und positiver Parameter, der Normalisierungsparameter. Tikhonov Regularisierung sorgt für Existenz, Einzigartigkeit und Stabilität der Lösung. Siehe auch die Reproducing Kern Hilbert-Stellen sind eine nützliche Wahl für H {\displaystyle {H} .Proximal ziehungsmethoden für das Lernen (14) Links