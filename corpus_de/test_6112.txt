In der künstlichen Intelligenz ist ein Expertensystem ein Computersystem, das die Entscheidungsfähigkeit eines menschlichen Experten emuliert. Expertensysteme sind darauf ausgerichtet, komplexe Probleme zu lösen, indem sie durch Wissensgremien, die hauptsächlich als if-then-Regeln und nicht durch den konventionellen Verfahrenscode repräsentiert werden. Die ersten Expertensysteme wurden in den 1970er Jahren geschaffen und dann in den 1980er Jahren proliferiert. Expertensysteme gehörten zu den ersten wirklich erfolgreichen Formen der künstlichen Intelligenz (KI) Software. Ein Expertensystem ist in zwei Teilsysteme unterteilt: der Inferenzmotor und die Wissensbasis. Die Wissensbasis stellt Fakten und Regeln dar. Der Inferenzmotor wendet die Regeln auf die bekannten Tatsachen an, um neue Fakten abzuleiten. Inferenzmotoren können auch Erklärung und Debugging Fähigkeiten enthalten. Geschichte Bald nach der Morgendämmerung moderner Computer in den späten 1940er Jahren – Anfang der 1950er Jahre begannen Forscher, das immense Potenzial dieser Maschinen für die moderne Gesellschaft zu erkennen. Eines der ersten Herausforderungen war es, eine solche Maschine zu machen, die fähig ist, wie Menschen zu denken. Insbesondere, diese Maschinen in der Lage, wichtige Entscheidungen zu treffen, die Art und Weise, wie Menschen tun. Das medizinische / Gesundheitswesen stellte die tantalisierende Herausforderung dar, damit diese Maschinen medizinische diagnostische Entscheidungen treffen können. So begannen in den späten 1950er-Jahren, unmittelbar nach dem Ende des Informationszeitalters, die Forscher mit der Aussicht zu experimentieren, die Computertechnologie zur Emulierung menschlicher Entscheidungsfindung einzusetzen. Zum Beispiel begannen biomedizinische Forscher mit der Erstellung computergestützter Systeme für diagnostische Anwendungen in der Medizin und Biologie. Diese frühen Diagnosesysteme nutzten Patientensymptome und Labortestergebnisse als Eingaben, um ein diagnostisches Ergebnis zu erzeugen. Diese Systeme wurden oft als frühe Formen von Expertensystemen beschrieben. Die Forscher hatten jedoch erkannt, dass es erhebliche Einschränkungen bei der Verwendung traditioneller Methoden wie Flussdiagramme statistische Musteranpassung oder Wahrscheinlichkeitstheorie gab. Formale Einführung und spätere Entwicklungen Diese frühere Situation führte allmählich zur Entwicklung von Expertensystemen, die wissensbasierte Ansätze nutzten. Diese Expertensysteme in der Medizin waren das MYCIN-Expertensystem, das INTERNIST-I-Expertensystem und später, Mitte der 1980er Jahre, der CADUCEUS. Rund 1965 wurden Expertensysteme vom Stanford Heuristic Programming Project unter der Leitung von Edward Feigenbaum vorgestellt, der manchmal als "Vater von Expertensystemen" bezeichnet wird; weitere wichtige Frühvermittler waren Bruce Buchanan und Randall Davis. Die Stanford-Forscher versuchten, Domänen zu identifizieren, in denen die Expertise hoch geschätzt und komplex war, wie die Diagnose von Infektionskrankheiten (Mycin) und die Identifizierung unbekannter organischer Moleküle (Dendral). Die Idee, dass "intelligente Systeme ihre Macht von dem Wissen ableiten, das sie besitzen, anstatt von den spezifischen Formalismen und Inferenzsystemen, die sie verwenden" – wie Feigenbaum sagte – war damals ein bedeutender Schritt nach vorn, da die vergangene Forschung sich auf heuristische Rechenmethoden konzentrierte, die in Versuchen gipfelten, sehr allgemeine Problemlöser zu entwickeln (vor allem die konjunktive Arbeit von Allen Newell und Herbert Simon). Expertensysteme wurden einige der ersten wirklich erfolgreichen Formen der künstlichen Intelligenz (KI) Software. Auch in Frankreich war die Forschung über Expertensysteme aktiv. Während in den USA der Fokus eher auf regelbasierte Systeme, zuerst auf Systemen, die hart kodiert auf LISP Programmierumgebungen und dann auf Experten System Shells entwickelt von Anbietern wie Intellicorp, in Frankreich Forschung konzentrierte sich mehr auf Systeme in Prolog entwickelt. Der Vorteil von Experten-Systemschalen war, dass sie für Nichtprogrammierer etwas einfacher zu verwenden waren. Der Vorteil von Prolog-Umgebungen war, dass sie sich nicht nur auf if-then-Regeln konzentrierten; Prolog-Umgebungen lieferten eine viel bessere Realisierung einer kompletten ersten Ordnungslogik-Umgebung. In den 1980er Jahren wurden Expertensysteme proliferiert. Universitäten boten Experten-System-Kurse und zwei Drittel der Fortune 500 Unternehmen angewandt die Technologie in täglichen Geschäftsaktivitäten. Das Interesse war international mit dem Computersysteme-Projekt der Fünften Generation in Japan und einer verstärkten Forschungsförderung in Europa. 1981 wurde der erste IBM-PC mit dem PC DOS-Betriebssystem eingeführt. Das Ungleichgewicht zwischen der hohen Erreichbarkeit der relativ leistungsfähigen Chips im PC, verglichen mit den viel teureren Kosten für die Verarbeitungsleistung in den Mainframes, die die Corporate IT-Welt damals dominierten, hat eine neue Art von Architektur für Corporate Computing geschaffen, die das Client-Server-Modell nannte. Berechnungen und Begründungen könnten zu einem Bruchteil des Preises eines Mainframes mit einem PC durchgeführt werden. Dieses Modell ermöglichte auch Geschäftseinheiten, die IT-Abteilungen von Unternehmen zu umgehen und direkt eigene Anwendungen aufzubauen. Dadurch hatte der Client-Server enorme Auswirkungen auf den Markt der Expertensysteme. Expertensysteme waren bereits in viel der Geschäftswelt ausverkauft und erforderten neue Fähigkeiten, die viele IT-Abteilungen nicht hatten und nicht eifrig zu entwickeln waren. Sie waren eine natürliche Passform für neue PC-basierte Schalen, die versprochen, die Anwendungsentwicklung in die Hände von Endbenutzern und Experten zu setzen. Bis dahin war die Hauptentwicklungsumgebung für Expertensysteme High-End Lisp Maschinen von Xerox, Symbolics und Texas Instruments. Mit dem Anstieg des PC- und Client-Server-Computing haben Anbieter wie Intellicorp und Inference Corporation ihre Prioritäten auf die Entwicklung von PC-basierten Tools verschoben. Auch neue Anbieter, die oft von Venture Capital finanziert werden (wie Aion Corporation, Neuron Data, Exsys und viele andere), begann regelmäßig erscheinen. Das erste Expertensystem, das in einer Design-Kapazität für ein großformatiges Produkt verwendet werden sollte, war das 1982 entwickelte Softwareprogramm SID (Synthesis of Integral Design). Geschrieben in LISP, SID generiert 93% der VAX 9000 CPU-Logik-Gatter. Die Eingabe der Software war eine Reihe von Regeln, die von mehreren Experten-Logik-Designern erstellt wurden. SID erweiterte die Regeln und generierte Software-Logik-Synthese-Routinen oft die Größe der Regeln selbst. Überraschend führte die Kombination dieser Regeln zu einem Gesamtdesign, das die Fähigkeiten der Experten selbst übertraf und in vielen Fällen die menschlichen Gegenstücke übertraf. Während einige Regeln anderen widersprachen, lieferten Top-Level-Kontrollparameter für Geschwindigkeit und Bereich den Krawattenbrecher. Das Programm war sehr kontrovers, aber dennoch aufgrund von Projektbudgetzwängen verwendet. Sie wurde nach dem VAX 9000 Projektabschluss von Logikdesignern beendet. In den Jahren vor Mitte der 1970er Jahre waren die Erwartungen, was Expertensysteme in vielen Bereichen erreichen können, sehr optimistisch. Zu Beginn dieser frühen Studien hofften Forscher, völlig automatische (d.h. vollständig computergesteuerte) Expertensysteme zu entwickeln. Die Erwartungen der Menschen, was Computer tun können, waren häufig zu idealistisch. Diese Situation änderte sich radikal, nachdem Richard M. Karp Anfang der 1970er Jahre sein Durchbruchspapier veröffentlichte: „Reducibility unter Combinatorial Problems“. Dank Karps Arbeit wurde klar, dass es bestimmte Einschränkungen und Möglichkeiten gibt, wenn man Computeralgorithmen entwirft. Seine Ergebnisse beschreiben, was Computer tun können und was sie nicht tun können. Viele der rechnerischen Probleme im Zusammenhang mit dieser Art von Expertensystemen haben bestimmte pragmatische Einschränkungen. Diese Ergebnisse legten die Grundarbeit fest, die zu den nächsten Entwicklungen auf dem Gebiet führte. In den 1990er-Jahren und darüber hinaus ging der Begriff Expertensystem und die Idee eines eigenständigen KI-Systems meist vom IT-Lexikon zurück. Es gibt zwei Interpretationen davon. Eins ist, dass "Expertensysteme gescheitert": die IT-Welt zog weiter, weil Expertensysteme nicht über ihr überholtes Versprechen liefern. Der andere ist der Spiegel gegenüber, dass Expertensysteme einfach Opfer ihres Erfolgs waren: Da IT-Experten Konzepte wie Regelmotoren erfassten, wanderten solche Werkzeuge aus eigenständigen Werkzeugen für die Entwicklung von speziellen Zweck-Expertensystemen, um eines von vielen Standard-Tools zu sein. Viele der führenden großen Business-Applikations-Suite-Anbieter (wie SAP, Siebel und Oracle) integrierte Experten-Systemfähigkeiten in ihre Suite von Produkten als eine Möglichkeit, Business-Logik – Regelmotoren sind nicht mehr einfach, um die Regeln zu definieren, die ein Experte verwenden würde, sondern für jede Art von komplexen, volatilen und kritischen Geschäftslogik; sie gehen oft Hand in Hand in Hand mit Geschäftsprozessautomatisierung und Integration Umgebungen. Aktuelle Ansätze für Expertensysteme Die Einschränkungen der bisherigen Art von Expertensystemen haben Forscher aufgefordert, neue Ansätze zu entwickeln. Sie haben effizientere, flexible und leistungsfähige Ansätze entwickelt, um den menschlichen Entscheidungsprozess zu simulieren. Einige der Ansätze, die Forscher entwickelt haben, basieren auf neuen Methoden der künstlichen Intelligenz (KI), insbesondere in maschinellen Lern- und Datenabbauansätzen mit einem Feedback-Mechanismus. Derartige Mechanismen nutzen häufig wiederkehrende neuronale Netze. Im Zusammenhang steht die Diskussion über die Nachteile. Moderne Systeme können neues Wissen leichter integrieren und sich damit leicht aktualisieren. Solche Systeme können aus vorhandenen Kenntnissen besser verallgemeinern und mit großen Mengen komplexer Daten umgehen. Related ist hier das Thema Big Data. Manchmal werden diese Typen von Expertensystemen als „intelligente Systeme“ bezeichnet. Softwarearchitektur Ein Expertensystem ist ein Beispiel eines wissensbasierten Systems. Expertensysteme waren die ersten kommerziellen Systeme, um eine wissensbasierte Architektur zu verwenden. Ein wissensbasiertes System besteht im Wesentlichen aus zwei Teilsystemen: der Wissensbasis und dem Inferenzmotor. Die Wissensbasis stellt Fakten über die Welt dar. In frühen Expertensystemen wie Mycin und Dendral wurden diese Tatsachen hauptsächlich als flache Behauptungen über Variablen dargestellt. In späteren, mit kommerziellen Schalen entwickelten Expertensystemen nahm die Wissensbasis mehr Struktur auf und nutzte Konzepte aus objektorientierter Programmierung. Die Welt wurde als Klassen, Unterklassen, und Instanzen und Behauptungen wurden durch Werte von Objektinstanzen ersetzt. Die durch Abfrage und Geltendmachung von Werten der Objekte gearbeiteten Regeln. Der Inferenzmotor ist ein automatisiertes Argumentationssystem, das den aktuellen Zustand der Wissensbasis auswertet, relevante Regeln anwendet und dann neues Wissen in die Wissensbasis behauptet. Die Inferenz-Engine kann auch Erläuterungsfähigkeiten enthalten, so dass sie dem Benutzer die Kette der Argumentation erklären kann, die verwendet wurde, um zu einem bestimmten Schluss zu gelangen, indem sie zurück über die Abfeuerung von Regeln, die zur Behauptung führten. Es gibt hauptsächlich zwei Modi für einen Inferenzmotor: Vorwärtsketten und Rückwärtsketten. Die unterschiedlichen Ansätze werden dadurch diktiert, ob der Inferenzmotor von dem Vorgesetzten (linke Seite) oder der Folge (rechtse Seite) der Regel angetrieben wird. Bei der Weiterverkettung feuert und behauptet die Folge. Betrachten Sie beispielsweise die folgende Regel: Ein einfaches Beispiel für die Vorwärtsketten wäre es, Man(Socrates) an das System zu behaupten und dann den Inferenzmotor auszulösen. Es würde R1 passen und Mortal (Socrates) in die Wissensbasis geltend machen. Backward Chaining ist etwas weniger gerade nach vorne. In der Rückwärtskette betrachtet das System mögliche Schlussfolgerungen und arbeitet rückwärts, um zu sehen, ob sie wahr sein könnten. Wenn also das System versuchte zu bestimmen, ob Mortal(Socrates) wahr ist, würde es R1 finden und die Wissensbasis abfragen, um zu sehen, ob man (Socrates) wahr ist. Eine der frühen Innovationen von Expertensystemen Shells war die Integration von Inferenzmotoren mit einer Benutzeroberfläche. Dies könnte besonders leistungsstark mit Rückwärtsketten sein. Wenn das System eine bestimmte Tatsache kennen muss, aber nicht, dann kann es einfach einen Eingabebildschirm erzeugen und den Benutzer fragen, ob die Informationen bekannt sind. So könnte es in diesem Beispiel R1 verwenden, um den Benutzer zu fragen, ob Sokrates ein Mann war und dann diese neuen Informationen entsprechend verwenden. Die Verwendung von Regeln, um das Wissen explizit darzustellen, ermöglichte auch die Erklärungsfähigkeiten. In dem einfachen Beispiel oben, wenn das System R1 verwendet hatte, um zu behaupten, dass Sokrates war Mortal und ein Benutzer wollte verstehen, warum Sokrates sterblich war, könnten sie das System abfragen und das System würde die Regeln, die gefeuert, um die Behauptung zu verursachen und präsentieren diese Regeln dem Benutzer als Erklärung. In Englisch, wenn der Benutzer fragte "Warum ist Sokrates Mortal?" das System würde antworten "Weil alle Männer sterblich sind und Sokrates ist ein Mann." Ein bedeutender Bereich für die Forschung war die Erstellung von Erklärungen aus der Wissensbasis in natürlichen Englisch anstatt einfach durch die formaleren, aber weniger intuitiven Regeln. Als Expertensysteme entwickelt, wurden viele neue Techniken in verschiedene Arten von Inferenzmotoren integriert. Einige der wichtigsten davon waren: Wahrheitspflege. Diese Systeme erfassen die Abhängigkeiten in einer Wissensbasis, so dass bei einer Änderung der Fakten abhängiges Wissen entsprechend verändert werden kann. Zum Beispiel, wenn das System erfährt, dass Sokrates nicht mehr bekannt ist, ein Mann zu sein, wird es die Behauptung, Sokrates sei sterblich. Hypothetische Vernunft. Dabei kann die Wissensbasis in viele mögliche Ansichten, a.k.a. Welten unterteilt werden. Dadurch kann der Inferenzmotor mehrere Möglichkeiten parallel erkunden. Zum Beispiel möchte das System die Konsequenzen beider Behauptungen erforschen, was wird wahr sein, wenn Sokrates ein Mann ist und was wahr ist, wenn er nicht ist? Unsichere Systeme. Eine der ersten Erweiterungen der einfachen Verwendung von Regeln, um Wissen zu repräsentieren, war auch, eine Wahrscheinlichkeit mit jeder Regel zu verknüpfen. Also, nicht zu behaupten, dass Sokrates sterblich ist, sondern Sokrates kann mit einem gewissen Wahrscheinlichkeitswert sterblich sein. Einfache Wahrscheinlichkeiten wurden in einigen Systemen mit ausgeklügelten Mechanismen für unsichere Argumentation, wie Fuzzy Logik, und Kombination von Wahrscheinlichkeiten erweitert. Einstufung der Ontologie. Mit der Hinzufügung von Objektklassen an die Wissensbasis war eine neue Art der Argumentation möglich. Neben der einfachen Begründung von Objektwerten könnte das System auch über Objektstrukturen begründen. In diesem einfachen Beispiel kann man eine Objektklasse darstellen und R1 kann in der Regel neu definiert werden, die die Klasse aller Männer definiert. Diese Arten von speziellen Zweck Inferenzmotoren werden als Klassifikatoren bezeichnet. Obwohl sie nicht sehr in Expertensystemen eingesetzt wurden, sind Klassifikatoren sehr leistungsstark für unstrukturierte volatile Domains und sind eine Schlüsseltechnologie für das Internet und das aufstrebende Semantic Web. Vorteile Ziel der wissensbasierten Systeme ist es, die für das System erforderlichen kritischen Informationen explizit zu machen und nicht implizit zu arbeiten. In einem herkömmlichen Computerprogramm ist die Logik in Code eingebettet, der typischerweise nur von einem IT-Spezialisten überprüft werden kann. Mit einem Expertensystem war es das Ziel, die Regeln in einem Format anzugeben, das intuitiv und leicht verstanden, überprüft und sogar von Domain-Experten bearbeitet wurde, anstatt IT-Experten. Die Vorteile dieser expliziten Wissensdarstellung waren schnelle Entwicklung und einfache Wartung. Die Wartung ist der offensichtlichste Vorteil. Dies wurde auf zwei Wegen erreicht. Zunächst könnte durch das Entfernen der Notwendigkeit, konventionellen Code zu schreiben, viele der normalen Probleme vermieden werden, die durch sogar kleine Änderungen an einem System verursacht werden können. Im Wesentlichen war der logische Ablauf des Programms (mindestens auf höchstem Niveau) einfach für das System gegeben, rufen Sie einfach den Inferenzmotor an. Dies war auch ein Grund für den zweiten Vorteil: Rapid Prototyping. Mit einer Experten-Systemhülle war es möglich, einige Regeln einzugeben und einen Prototyp in Tagen entwickelt zu haben, anstatt die Monate oder das Jahr typischerweise mit komplexen IT-Projekten verbunden. Ein Anspruch auf Expertensystemschalen, der oft gemacht wurde, war, dass sie die Notwendigkeit für geschulte Programmierer entfernt haben und dass Experten Systeme selbst entwickeln könnten. In Wirklichkeit war dies selten, wenn überhaupt wahr. Während die Regeln für ein Expertensystem verständlicher waren als typischer Computercode, hatten sie immer noch eine formale Syntax, in der ein falscher Komma oder ein anderer Charakter wie bei jeder anderen Computersprache Chaos verursachen könnte. Auch, als Expertensysteme von Prototypen im Labor auf den Einsatz in der Geschäftswelt umzogen, wurden Probleme der Integration und Wartung viel kritischer. Unvermeidlich forderte die Integration und die Nutzung großer älterer Datenbanken und Systeme. Um dies zu erreichen, erforderte die Integration die gleichen Fähigkeiten wie jede andere Art von System. Nachteile Der am häufigsten für Expertensysteme in der akademischen Literatur zitierte Nachteil ist das Wissenserfassungsproblem. Die Einhaltung der Zeit von Domain-Experten für jede Software-Anwendung ist immer schwierig, aber für Experten-Systeme war es besonders schwierig, weil die Experten durch Definition hoch geschätzt und in konstanter Nachfrage durch die Organisation. Aufgrund dieses Problems konzentrierte sich in den späteren Jahren der Expertensysteme auf Werkzeuge zur Wissenserwerb, um den Prozess der Gestaltung, Debugging und Aufrechterhaltung von von von Experten definierten Regeln zu automatisieren. Bei der Betrachtung des Lebenszyklus von Expertensystemen in der tatsächlichen Nutzung scheinen jedoch andere Probleme – im Wesentlichen die gleichen Probleme wie bei jedem anderen großen System – zumindest so kritisch wie die Wissenserwerb: Integration, Zugang zu großen Datenbanken und Leistung. Die Leistung könnte besonders problematisch sein, weil frühe Expertensysteme mit Werkzeugen (wie früheren Lisp-Versionen) gebaut wurden, die Codeausdrücken interpretierten, ohne sie zuerst zu kompilieren. Dies lieferte eine leistungsfähige Entwicklungsumgebung, aber mit dem Nachteil, dass es praktisch unmöglich war, die Effizienz der am schnellsten kompilierten Sprachen (z.B. C) anzupassen. Die System- und Datenbankintegration war für frühe Expertensysteme schwierig, da die Werkzeuge meist in Sprachen und Plattformen waren, die in den meisten IT-Umgebungen der Unternehmen weder vertraut noch willkommen waren – Programmiersprachen wie Lisp und Prolog, und Hardware-Plattformen wie Lisp-Maschinen und Personalcomputer. Infolgedessen konzentrierte sich der Aufwand in den späteren Stadien der fachkundigen System-Tool-Entwicklung auf die Integration von Alt-Umgebungen wie COBOL und großen Datenbanksystemen sowie auf die Portierung von Standard-Plattformen. Diese Probleme wurden vor allem durch die Paradigmenverschiebung des Client-Servers behoben, da PCs allmählich in der IT-Umgebung als legitime Plattform für eine ernsthafte Geschäftssystementwicklung akzeptiert wurden und als erschwingliche Minicomputer-Server die für KI-Anwendungen benötigte Verarbeitungsleistung zur Verfügung stellten. Eine weitere große Herausforderung von Expertensystemen entsteht, wenn die Größe der Wissensbasis zunimmt. Dadurch erhöht sich die Verarbeitungskomplexität. Zum Beispiel, wenn ein Expertensystem mit 100 Millionen Regeln als das ultimative Expertensystem vorgesehen war, wurde offensichtlich, dass dieses System zu komplex wäre und es würde zu viele rechnerische Probleme konfrontiert. Ein Inferenzmotor müsste in der Lage sein, große Anzahl von Regeln zu bearbeiten, um eine Entscheidung zu erreichen. Wie zu überprüfen, ob die Entscheidungsregeln miteinander übereinstimmen, ist auch eine Herausforderung, wenn es zu viele Regeln gibt. Üblicherweise führt dieses Problem zu einer befriedigenden Formulierung (SAT). Dies ist ein bekanntes NP-komplete Problem Boolean Zufriedenheit Problem. Wenn wir nur binäre Variablen annehmen, sagen n von ihnen, und dann ist der entsprechende Suchraum von der Größe 2 n {\displaystyle {^n} . So kann der Suchraum exponentiell wachsen. Es gibt auch Fragen, wie man die Nutzung der Regeln priorisiert, um effizienter zu arbeiten, oder wie man Mehrdeutigkeiten (z.B. wenn es zu viele andere Unterstrukturen innerhalb einer einzigen Regel gibt) und so weiter zu lösen. Andere Probleme sind mit den Überarbeitungs- und Überallgemeinerungseffekten bei der Verwendung bekannter Tatsachen verbunden und versuchen, andere, nicht explizit in der Wissensbasis beschriebene Fälle zu verallgemeinern. Solche Probleme bestehen mit Methoden, die auch maschinelle Lernansätze einsetzen. Ein weiteres Problem im Zusammenhang mit der Wissensbasis ist, wie man Updates seines Wissens schnell und effektiv macht. Auch, wie man ein neues Stück Wissen (d.h. wo es unter vielen Regeln hinzufügen) ist herausfordernd.Moderne Ansätze, die sich auf maschinelle Lernmethoden verlassen, sind in dieser Hinsicht einfacher. Aufgrund der oben genannten Herausforderungen wurde deutlich, dass anstelle von regelbasierten Technologien neue KI-Ansätze erforderlich waren. Diese neuen Ansätze basieren auf der Verwendung von maschinellen Lerntechniken, zusammen mit der Nutzung von Feedback-Mechanismen. Die wichtigsten Herausforderungen, die Expertensysteme in der Medizin (wenn man computergestützte Diagnosesysteme als moderne Expertensysteme betrachtet), und vielleicht in anderen Anwendungsbereichen, umfassen Themen im Zusammenhang mit Aspekten wie: Big Data, bestehende Regelungen, Healthcare-Praxis, verschiedene algorithmische. Anwendungen Hayes-Roth teilt Expertensysteme Anwendungen in 10 Kategorien, die in der folgenden Tabelle dargestellt sind. Die Beispiel-Anwendungen waren nicht in der ursprünglichen Hayes-Roth-Tabelle, und einige von ihnen entstanden gut nachher. Jede Anwendung, die nicht gepunktet wird, wird im Hayes-Roth-Buch beschrieben. Auch wenn diese Kategorien einen intuitiven Rahmen bieten, um den Raum von Expertensystemen Anwendungen zu beschreiben, sind sie keine starren Kategorien, und in einigen Fällen kann eine Anwendung Merkmale von mehr als einer Kategorie zeigen. Hearsay war ein früher Versuch, die Spracherkennung durch einen Experten-Systemansatz zu lösen. Zum größten Teil war diese Kategorie von Expertensystemen nicht so erfolgreich. Hearsay und alle Interpretationssysteme sind im Wesentlichen Mustererkennungssysteme – auf Muster in lauten Daten. Im Falle des Hörsays, das Phoneme in einem Audiostream erkennt. Weitere frühe Beispiele waren die Analyse von Sonardaten, um russische U-Boote zu erkennen. Diese Art von Systemen erwies sich für ein neuronales Netzwerk AI-Lösung als ein regelbasiertes Konzept. CADUCEUS und MYCIN waren medizinische Diagnosesysteme. Der Benutzer beschreibt ihre Symptome auf dem Computer, wie sie an einen Arzt und der Computer eine medizinische Diagnose zurück. Dendral war ein Werkzeug zur Untersuchung der Hypothesenbildung bei der Identifizierung organischer Moleküle. Das allgemeine Problem, das es gelöst hat – die Gestaltung einer Lösung angesichts einer Reihe von Zwängen – war eines der erfolgreichsten Bereiche für frühe Expertensysteme, die sich auf Geschäftsbereiche wie Verkäufer, die die Digital Equipment Corporation (DEC) VAX-Computer und Hypothekenkreditanwendungsentwicklung konfigurieren, beziehen. SMH. PAL ist ein Expertensystem für die Bewertung von Studenten mit mehreren Behinderungen. Mistral ist ein Expertensystem zur Überwachung der Sicherheit der Mutter, das in den 1990er Jahren von Ismes (Italien) entwickelt wurde. Es erhält Daten von einem automatischen Überwachungssystem und führt eine Diagnose des Zustands des Staudamms durch. Sein erstes Exemplar, das 1992 auf dem Ridracoli Dam (Italien) installiert wurde, ist noch rund um die Uhr/365 funktionsfähig. Es wurde auf mehreren Dämmen in Italien und im Ausland (z.B. Itaipu Dam in Brasilien) und auf Landrutschen unter dem Namen Eydenet und auf Denkmälern unter dem Namen Kaleidos installiert. Mistral ist eine eingetragene Marke der CESI. Siehe auch KI Winter CLIPS Kontraint Logik-Programmierung Beschränken Zufriedenheit Wissens Engineering Lernen Klassifikatorsystem Regelbasiertes maschinelles Lernen Referenzen Externe Links Künstliche Intelligenz bei Curlie Expert System Tutorial on Code Project