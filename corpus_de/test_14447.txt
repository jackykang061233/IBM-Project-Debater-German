(Für eine Liste der mathematischen Logik, die in diesem Artikel verwendet wird, siehe Meldung in Wahrscheinlichkeit und Statistik und/oder Liste der Logiksymbole.) Ein Bayesian-Netzwerk (auch bekannt als Bayes-Netzwerk, Bayes-Netz, Glaubensnetzwerk oder Entscheidungsnetzwerk) ist ein probabilistisches grafisches Modell, das eine Reihe von Variablen und ihre bedingten Abhängigkeiten über eine gerichtete azyklische Graphik (DAG) darstellt. Bayesische Netzwerke sind ideal, um ein Ereignis zu nehmen, das aufgetreten ist und die Wahrscheinlichkeit vorherzusagen, dass eine von mehreren möglichen bekannten Ursachen der Beitrag war. Ein Bayesisches Netzwerk könnte beispielsweise die probabilistischen Zusammenhänge zwischen Krankheiten und Symptomen darstellen. Bei Symptomen kann das Netzwerk verwendet werden, um die Wahrscheinlichkeiten des Vorhandenseins verschiedener Krankheiten zu berechnen. Effiziente Algorithmen können in Bayesischen Netzwerken Inferenz und Lernen durchführen. Bayesische Netzwerke, die Modellsequenzen von Variablen (z.B. Sprachsignale oder Proteinsequenzen) nennen dynamische Bayesische Netzwerke. Als Einflussdiagramme werden Verallgemeinerungen von Bayesischen Netzwerken bezeichnet, die Entscheidungsprobleme unter Unsicherheit darstellen und lösen können. Formal werden Bayesische Netzwerke gerichtete acyclische Graphen (DAGs), deren Knoten Variablen im Bayesischen Sinne darstellen: sie können beobachtbare Mengen, latente Variablen, unbekannte Parameter oder Hypothesen sein. Kanten stellen bedingte Abhängigkeiten dar; Knoten, die nicht miteinander verbunden sind (kein Pfad verbindet einen Knoten mit einem anderen) stellen Variablen dar, die bedingt unabhängig voneinander sind. Jeder Knoten ist einer Wahrscheinlichkeitsfunktion zugeordnet, die als Eingabe einen bestimmten Wertsatz für die Stammvariablen des Knotens nimmt und (als Ausgang) die Wahrscheinlichkeit (oder Wahrscheinlichkeitsverteilung, gegebenenfalls) der vom Knoten repräsentierten Größe gibt. Wenn z.B. m \{displaystyle m} Elternknoten m \{displaystyle m} Boolesche Variablen darstellen, dann könnte die Wahrscheinlichkeitsfunktion durch eine Tabelle von 2 m \{displaystyle 2^{m} Einträgen dargestellt werden, ein Eintrag für jede der 2 m \{displaystyle 2^{m} mögliche Elternkombinationen. Ähnliche Ideen können auf ungeschützte und möglicherweise zyklische Graphen wie Markov-Netzwerke angewendet werden. Beispiel Zwei Ereignisse können dazu führen, dass Gras nass wird: ein aktiver Sprinkler oder Regen. Der Regen wirkt sich direkt auf die Verwendung des Sprinklers aus (dass bei Regen der Sprinkler normalerweise nicht aktiv ist). Diese Situation kann mit einem Bayesischen Netzwerk (rechts dargestellt) modelliert werden. Jede Variable hat zwei mögliche Werte, T (für true) und F (für false). Die gemeinsame Wahrscheinlichkeitsfunktion ist, nach der Kettenregel der Wahrscheinlichkeit, Pr (G, S, R ) = Pr (G ∣ S, R ) Pr (S ∣ R ) Pr (R ) \{displaystyle Pr(G,S,R)=\Pr(G\mid S,R)\Pr(S\mid R)\Pr(R} mit G = "Grass nass (true/false,") S "Sprinkler eingeschaltet (true/false,") und R = "Raining (true/false)". Das Modell kann Fragen über das Vorhandensein einer Ursache beantworten, wenn ein Effekt (sogenannte inverse Wahrscheinlichkeit) wie "Was ist die Wahrscheinlichkeit, dass es regnet, wenn das Gras nass ist?" durch die bedingte Wahrscheinlichkeit Formel und Summen über alle Störgrößen: Pr (R = T ∣ G = T ) = Pr (G = T , R = T ) Pr (G = T ) = Σ x ε ε , F } Pr (G = T , S = x , R = T ) Σ x , y ∈ T, F } Pr (G = T , S = x , R = y ) \{displaystyle Pr(R=T\midG=T)={\frac Pr(G=T,R=T)}{\Pr(G=T)}}={\frac \{sum _{x\in T,F\}\Pr(G=T,S=x,R=T)}{\sum_{x,y\in (T,F\}\Pr(G=T,S=x,R=y) Mit der Erweiterung für die gemeinsame Wahrscheinlichkeitsfunktion Pr (G, S, R ) \{displaystyle \Pr(G,S,R}) und den bedingten Wahrscheinlichkeitskennzahlen aus den im Diagramm angegebenen bedingten Wahrscheinlichkeitstabellen (CPTs) kann jeder Begriff in den Summen im Zähler und Nenner ausgewertet werden. Beispielsweise Pr (G = T, S = T, R = T ) = Pr (G = T ∣ S = T , R = T ) Pr (S = T ∣ R = T ) Pr (R = T ) = 0,99 × 0,01 × 0,2 = 0,00198 \{displaystyle start{aligned}\Pr(G=T,S=T,R=T)&=\Pr(G=T\mid S=T,R=T)\Pr(S=T\mid R=T)\Pr(R=T)\&=0,99\Zeiten 0.01\\\\&=0,00198\end{justed} Die Zahlenergebnisse (nach den zugehörigen Variablenwerten) sind dann Pr (R = T ∣ G = T ) = 0,00198 T T + 0,1584 T F T 0,00198 T T T T + 0,288 T T F + 0,1584 T F T + 0,0 T F F = 891 2491 ≈ 35.77 % . \{displaystyle Pr(R=T\mid G=T)={\frac ** ******************************************************************************************************************************************************************************************************************** 35,77% Um eine interventionelle Frage zu beantworten, wie "Was ist die Wahrscheinlichkeit, dass es regnet, wenn wir das Gras benetzen?", wird die Antwort von der post-intervention Gelenkverteilungsfunktion Pr (S, R ∣ do (G = T ) ) = Pr (S ∣ R ) Pr (R ) \{displaystyle Pr(S,R\mid text{}(G=T)=)=)=)= Der Do-Operator zwingt den Wert von G wahr zu sein. Die Regenwahrscheinlichkeit wird durch die Aktion nicht beeinflusst: Pr (R ∣ do (G = T ) = Pr (R ) . \r\displaystyle Pr(R\mid text{do}(G=T))=\Pr(R. Um die Auswirkungen des Faltens auf: Pr (R, G ∣ do (S = T ) ) zu vorherzusagen) = Pr (R ∣ R, S = T ) \{displaystyle Pr(R,G\mid text{}} Diese Vorhersagen können bei nicht beobachteten Variablen, wie bei den meisten politischen Bewertungsproblemen, nicht durchführbar sein. Die Wirkung der Aktion do ( x ) \{displaystyle \text{do}(x) kann jedoch immer noch prognostiziert werden, wenn das Hintertürkriterium erfüllt ist. Es heißt, dass, wenn ein Satz Z von Knoten beobachtet werden kann, dass d-separiert (oder Blöcke) alle Back-Tür-Pfade von X bis Y dann Pr (Y, Z ∣ do ( x ) ) = Pr (Y, Z, X = x ) Pr (X = x ∣ Z ) . ^displaystyle Pr(Y,Z\mid text{do}}(x))={\frac Pr(Y,Z,X=x)}{\Pr(X=x\mid Z}.) Ein Rücktürweg ist ein Weg, der mit einem Pfeil in X endet. Sets, die das Hintertürkriterium erfüllen, werden als ausreichend oder zulässig bezeichnet. " Beispielsweise ist der Satz Z = R für die Vorhersage der Wirkung von S = T auf G zulässig, da R d-separiert den (nur) Rückwärts-Türpfad S ← R →G. Wird jedoch S nicht beobachtet, so trennt kein anderer Satz d-separiert diesen Pfad und die Wirkung des Anschaltens des Sprinklers auf das Gras (G) kann nicht aus passiven Beobachtungen vorhergesagt werden. In diesem Fall wird P(G | do(S = T) nicht identifiziert". Dies spiegelt die Tatsache wider, dass die beobachtete Abhängigkeit zwischen S und G nicht durch eine ursächliche Verbindung oder durch eine anfällige Abhängigkeit verursacht wird (siehe Simpsons Paradox) Um zu ermitteln, ob aus einem beliebigen Bayesischen Netzwerk mit nicht beobachteten Variablen eine Kausalbeziehung ermittelt wird, können die drei Regeln von do-calculus verwendet werden und prüfen, ob alle Begriffe aus der Expression dieser Beziehung entfernt werden können, was bestätigt, dass die gewünschte Menge aus Frequenzdaten abschätzbar ist. Die Verwendung eines Bayesischen Netzwerks kann erhebliche Mengen an Speicher über erschöpfende Wahrscheinlichkeitstabellen speichern, wenn die Abhängigkeiten in der gemeinsamen Verteilung spärlich sind. Beispielsweise erfordert eine naive Art, die bedingten Wahrscheinlichkeiten von 10 zweiwertigen Variablen als Tabelle zu speichern, Speicherplatz für 2 10 = 1024 \{Displaystyle 2^{10}=1024 Werte. Wenn die lokale Verteilung der Variablen nicht von mehr als drei Elternvariablen abhängt, speichert die Bayesische Netzwerkrepräsentation höchstens 10 ∙ 2 3 = 80 \{displaystyle 10\cdot 2^{3}=80 Werte. Ein Vorteil der Bayesischen Netzwerke ist, dass es für einen Menschen intuitiv einfacher ist, direkte Abhängigkeiten und lokale Verteilungen zu verstehen (ein spärliches Set) als komplette gemeinsame Verteilungen. Inferenz und Lernen Bayesische Netzwerke erfüllen drei Hauptinterferenzaufgaben: Unerwartete Variablen mindern Da ein Bayesian-Netzwerk ein komplettes Modell für seine Variablen und ihre Beziehungen ist, kann es verwendet werden, um probabilistische Fragen über sie zu beantworten. Beispielsweise kann das Netzwerk verwendet werden, um Wissen über den Zustand einer Submenge von Variablen zu aktualisieren, wenn andere Variablen (die Belegvariablen) beobachtet werden. Dieser Prozess der Berechnung der posterior Verteilung von Variablen gegebenen Beweis wird als probabilistische Inferenz bezeichnet. Der Posterior gibt eine universelle ausreichende Statistik für Erkennungsanwendungen, bei der Auswahl von Werten für die variable Untermenge, die eine erwartete Verlustfunktion minimieren, beispielsweise die Wahrscheinlichkeit von Entscheidungsfehlern. Ein Bayesian-Netzwerk kann somit als Mechanismus für die automatische Anwendung von Bayes' Theorem auf komplexe Probleme angesehen werden. Die häufigsten exakten Inferenzverfahren sind: variable Beseitigung, die (durch Integration oder Summation) die nicht beobachteten nicht-query Variablen eins durch eine Verteilung der Summe über das Produkt eliminiert; clique tree propagation, die die Berechnung, so dass viele Variablen zu einem Zeitpunkt abgefragt werden können und neue Beweise können schnell propagiert werden; und wiederkehrende Konditionierung und AND/OR-Suche, die eine Raum-Zeit-Handelsvariable ermöglichen. Alle diese Methoden haben Komplexität, die exponentiell in der Baumwit des Netzwerks ist. Die häufigsten Inferenzalgorithmen sind wichtige Probenahmen, stochastische MCMC-Simulation, Mini-Bucket-Abspaltung, schlaufende Glaubensvermehrung, allgemeine Glaubensvermehrung und Variationsmethoden. Parameter-Erlernen Um das Bayesische Netzwerk vollständig anzugeben und damit die gemeinsame Wahrscheinlichkeitsverteilung vollständig darzustellen, ist es erforderlich, für jeden Knoten anzugeben X die Wahrscheinlichkeitsverteilung für X bedingt auf X's Eltern. Die Verteilung von X bedingt auf seine Eltern kann jede Form haben. Es ist üblich, mit diskreten oder Gaussian Distributionen zu arbeiten, da dies die Berechnungen vereinfacht. Manchmal sind nur Zwänge auf einer Verteilung bekannt; man kann dann das Prinzip der maximalen Entropie verwenden, um eine einzige Verteilung zu bestimmen, die mit der größten Entropie angesichts der Zwänge. (Analog wird im spezifischen Kontext eines dynamischen Bayesischen Netzwerks die bedingte Verteilung für die zeitliche Evolution des verborgenen Zustands häufig festgelegt, um die Entropierate des impliziten stochastischen Prozesses zu maximieren.) Diese bedingten Verteilungen umfassen oft unbekannte Parameter und müssen aus Daten, z.B. über den maximalen Wahrscheinlichkeitsansatz, geschätzt werden. Die direkte Maximierung der Wahrscheinlichkeit (bzw. der posterior Wahrscheinlichkeit) ist bei nicht beobachteten Variablen oft komplex. Ein klassischer Ansatz zu diesem Problem ist der Erwartungsmaximierungsalgorithmus, der die Berechnung der erwarteten Werte der unbeobachteten Variablen auf beobachtete Daten abwechselt, wobei die Gesamtwahrscheinlichkeit (oder Posterior) maximiert wird, vorausgesetzt, dass zuvor berechnete Erwartungswerte korrekt sind. Unter milden Regularitätsbedingungen konvergiert dieser Prozess auf maximale Wahrscheinlichkeit (oder maximale Posterior) Werte für Parameter. Ein vollständiger Bayesischer Ansatz für Parameter ist es, sie als zusätzliche unbeobachtete Variablen zu behandeln und eine vollständige posterior Verteilung über alle Knoten bedingt auf beobachtete Daten zu berechnen, um dann die Parameter zu integrieren. Dieser Ansatz kann teuer sein und zu großen Dimensionsmodellen führen, wodurch klassische Parameter-Setting-Ansätze attraktiver sind. Strukturerwerb Im einfachsten Fall wird ein Bayesisches Netzwerk von einem Experten spezifiziert und dann zur Inferenz verwendet. In anderen Anwendungen ist die Aufgabe, das Netzwerk zu definieren, für den Menschen zu komplex. In diesem Fall müssen die Netzwerkstruktur und die Parameter der lokalen Verteilungen aus Daten erlernt werden. Das automatische Erlernen der Graphenstruktur eines Bayesischen Netzwerks (BN) ist eine Herausforderung, die im maschinellen Lernen verfolgt wird. Die Grundidee geht zurück zu einem von Rebane und Pearl entwickelten Wiederherstellungsalgorithmus und beruht auf der Unterscheidung zwischen den drei möglichen Mustern, die in einem 3-Node DAG erlaubt sind: Die ersten 2 stellen die gleichen Abhängigkeiten dar ( X \{displaystyle X} und Z \{displaystyle Z} sind unabhängig mit Y \{displaystyle Y}) und sind daher unausweichlich. Der Kollider kann jedoch eindeutig identifiziert werden, da X \{displaystyle X} und Z \{displaystyle Z} marginal unabhängig sind und alle anderen Paare abhängig sind. Während also die Skeletts (die aus Pfeilen gestreiften Diagramme) dieser drei Triplets identisch sind, ist die Richtung der Pfeile teilweise erkennbar. Die gleiche Unterscheidung gilt, wenn X \{displaystyle X} und Z \{displaystyle Z} gemeinsame Eltern haben, außer dass man zuerst auf diese Eltern zu konditionieren hat. Algorithmen wurden entwickelt, um das Skelett des zugrunde liegenden Graphen systematisch zu bestimmen und dann alle Pfeile auszurichten, deren Richtunglichkeit durch die beobachteten bedingten Unabhängigkeiten diktiert wird. Eine alternative Methode des strukturellen Lernens nutzt eine optimierte Suche. Es erfordert eine Scoring-Funktion und eine Suchstrategie. Eine gemeinsame Scoring-Funktion ist die posteriore Wahrscheinlichkeit der Struktur bei den Trainingsdaten, wie die BIC oder die BDeu. Der Zeitbedarf einer erschöpfenden Suche, die eine Struktur zurückgibt, die die Partitur maximiert, ist in der Anzahl der Variablen überexponentiell. Eine lokale Suchstrategie macht inkrementelle Änderungen, die auf die Verbesserung der Punktzahl der Struktur abzielen. Ein globaler Suchalgorithmus wie Markov Kette Monte Carlo kann vermeiden, in lokalen Minima gefangen. Friedman et al.discuss verwendet gegenseitige Informationen zwischen Variablen und eine Struktur zu finden, die dies maximiert. Sie tun dies, indem sie den Stammkandidatensatz auf k-Knoten einschränken und darin vollständig suchen. Ein besonders schnelles Verfahren für das exakte BN-Lernen ist das Problem als Optimierungsproblem zu werfen und es mittels Ganzzahl-Programmierung zu lösen. Beim Lösen in Form von Schneidebenen werden dem Ganzzahlprogramm (IP) Azyklizitätszwänge hinzugefügt. Ein solches Verfahren kann Probleme mit bis zu 100 Variablen bewältigen. Um Probleme mit Tausenden von Variablen zu lösen, ist ein anderer Ansatz notwendig.Man soll zunächst eine Bestellung ausprobieren und dann die optimale BN-Struktur bezüglich dieser Bestellung finden. Dies bedeutet, am Suchraum der möglichen Bestellungen zu arbeiten, was praktisch ist, da es kleiner ist als der Raum der Netzwerkstrukturen. Mehrere Bestellungen werden dann abgetastet und ausgewertet. Diese Methode hat sich als die beste in der Literatur, wenn die Anzahl der Variablen ist enorm erwiesen. Eine weitere Methode besteht darin, die Unterklasse der zersetzbaren Modelle zu fokussieren, für die die MLE eine geschlossene Form haben. Es ist dann möglich, eine einheitliche Struktur für Hunderte von Variablen zu entdecken. Bayesische Netzwerke mit gebundener Baumbreite zu lernen ist notwendig, um genaue, traktable Inferenz zu ermöglichen, da die schlimmste Inferenzkomplexität exponentiell in der Baumwidth k (unter der exponentiellen Zeithypothese) ist. Doch als globales Eigentum des Graphen erhöht es die Schwierigkeit des Lernprozesses erheblich. In diesem Zusammenhang ist es möglich, K-tree für effektives Lernen zu verwenden. Statistische Einführung Vor Daten x \{displaystyle x},\! und Parameter θ \{displaystyle \theta }, eine einfache Bayesian-Analyse beginnt mit einer vorherigen Wahrscheinlichkeit (prior) p (θ ) \{displaystyle p(\theta )} und Wahrscheinlichkeit p ( x ∣ θ ) \{displaystyle p(x\mid \theta } um eine Posterior- Wahrscheinlichkeit p zu berechnen φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ π φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ φ Dies ist das einfachste Beispiel eines hierarchischen Bayes Modells. Der Vorgang kann wiederholt werden; z.B. können die Parameter φ \{displaystyle \varphi } wiederum von zusätzlichen Parametern ψ \{displaystyle \psi \,\!} abhängen, die ihren eigenen Vorzug benötigen. Schließlich muss der Prozess enden, mit Voranmeldungen, die nicht von ungenannten Parametern abhängen. Einführungsbeispiele Bei den gemessenen Größen x 1 , ... , x n \{displaystyle x_{1},\dots x_{n}\! jeder mit normal verteilten Fehlern bekannter Standardabweichung σ \{displaystyle \sigma \,\!}, x i ̃ N ( θ i, σ 2 ) \{displaystyle x_{i}\simN(\theta _{i},\sigma ^{2}) Angenommen, wir interessieren uns für die Schätzung der θ i \{displaystyle \theta _{i} . Ein Ansatz wäre die Schätzung der θ i \{displaystyle \theta _{i} mit einem maximalen Wahrscheinlichkeitsansatz; da die Beobachtungen unabhängig sind, die Wahrscheinlichkeitsfaktoren und die maximale Wahrscheinlichkeitsschätzung ist einfach θ i = x i . \{displaystyle \theta i}=x_{i. Wenn jedoch die Mengen verwandt sind, so daß z.B. die einzelnen θ i \{displaystyle \theta _{i} aus einer zugrunde liegenden Verteilung gezogen worden sind, dann zerstört diese Beziehung die Unabhängigkeit und schlägt ein komplexeres Modell vor, z.B. x i ∼ N (θ i, σ 2 ), \{displaystyle x_{i}\simN(\theta _{i},\sig _{i}\sim N(\varphi ,\tau ^^{2},) mit unsachgemäßen Vorkommnissen φ ο φ ο φ ο φ ο φ ο φ ο φ ο φ φ ο φ \{displaystyle \varphi \sim \text{flat}, τ ο ε ε (0, ∞ ) \{displaystyle \tau \sim text{ text{}}\in (0,\in (0,\in\in}}}}}}}}} . Wenn n ≥ 3 \{displaystyle n\geq 3}, ist dies ein identifiziertes Modell (d.h. es gibt eine einzigartige Lösung für die Parameter des Modells,) und die posterior Verteilungen der einzelnen θ i \{displaystyle \theta _{i} werden tendenziell zu bewegen oder von den maximalen Wahrscheinlichkeitsschätzungen zu ihrem gemeinsamen Mittelwert wegzuschrumpfen. Dieser Schrumpf ist ein typisches Verhalten in hierarchischen Bayes Modellen. Einschränkungen auf Voreinstellungen Einige Sorgfalt ist bei der Auswahl von Voreinstellungen in einem hierarchischen Modell erforderlich, insbesondere bei Skalenvariablen auf höheren Ebenen der Hierarchie, wie z.B. der Variablen τ \{displaystyle \tau \,\!} im Beispiel. Die üblichen Vorkommnisse wie die Jeffreys arbeiten oft nicht, weil die Posterior-Distribution nicht normalisierbar ist und Schätzungen, die durch die Minimierung des erwarteten Verlusts gemacht werden, unzulässig sind. Definitionen und Konzepte Mehrere gleichwertige Definitionen eines Bayesischen Netzwerks wurden angeboten. Für folgendes, lassen Sie G (= V, E) ein gerichtetes acyclisches Diagramm (DAG) sein und lassen X = (Xv,) v ε V ein Satz von zufälligen Variablen sein, die von V. Factorization definition X ein Bayesisches Netz gegenüber G ist, wenn seine gemeinsame Wahrscheinlichkeitsdichtefunktion (bezogen auf eine Produktmaßnahme) als Produkt der einzelnen Dichtefunktionen, bedingt auf ihre Elternvariablen geschrieben werden kann: p (x ∈ = Für beliebige Variablen können die Wahrscheinlichkeit eines Mitglieds einer gemeinsamen Verteilung aus bedingten Wahrscheinlichkeiten mit der Kettenregel (bei topologischer Ordnung von X) wie folgt berechnet werden: P ‡ (X 1 = x 1 , ... , X n = x n ) = ∏ v = 1 n P ≠ (X v = x v + 1style x v + 1 , ... , X nopername = (X_{1}=x_{1},\ldots ,X_{n}=x_{n})=\prod _v=1^{n}\Operatorname (P) links (X_{v}=x_{v}\mid X_{v+1}=x_{v+1},\ldots ,X_{n}=x_{n}\right) Unter Verwendung der oben genannten Definition kann dies wie folgt geschrieben werden: P ≠ (X 1 = x 1 , ..., X n = x n ) = ∏ v = 1 n P ‡ (X v = x v ∣ X j = x j für jedes X j, das ein Elternteil von X v ) \{displaystyle \operatorname ist (X_{1}=x_{1},\ldots ,X_{n}=x_{n})=\prod _v=1^{n}\Operatorname {P} (X_{v}=x_{v}\mid X_{j}=x_{j}{\text für jeden X_{j}\,{\text, der ein Elternteil von X_{v,\ ist) Der Unterschied zwischen den beiden Ausdrücken ist die bedingte Unabhängigkeit der Variablen von einer ihrer Nicht-Descendanten, gegeben durch die Werte ihrer Elternvariablen. Immobilien in Markov X ist ein Bayesisches Netzwerk in Bezug auf G, wenn es die lokale Markov-Eigenschaft erfüllt: jede Variable ist bedingt unabhängig von ihren Nicht-Descendants angesichts ihrer Elternvariablen: ⊥ X v ・ Þ X V ∖ de ‡ (v ) ∣ X pa ‡ (v ) für alle v ε V \{displaystyle X_{v}\perp \!perp X_{V\,\smallsetminus ,\operatorname {de} (v)}\mid X_{\operatorname {pa} (v)}\quad \text{für alle }v\in V}, wobei de(v) die Menge der Nachkommen ist und V \ de(v) die Menge der Nicht-Descendants von v. Dies kann in ähnlicher Weise wie die erste Definition ausgedrückt werden, wie z.B. P ‡ (X v = x v ∣ X i = x i für jede X i, das ist kein Nachkommen von X v ) = P (X v = x v ∣ X j = x j für jedes X j, das ein Elternteil von X v ) \{displaystyle begin{aligned}&\operatorname ist (X_{v}=x_{v}\mid X_{i}=x_{i}{\text für jeden X_{i}{\text, der kein Nachkommen von X_{v}\,)\\[6pt]={}&P(X_{v}=x_{v}\mid ist X_{j}=x_{j}{\text für jeden X_{j}{\text, der ein Elternteil von X_{v}\ ist,)\end{justed Der Satz der Eltern ist eine Untermenge der Gruppe der Nicht-Descendants, weil die Grafik azyklisch ist. Die Entwicklung Bayesischer Netzwerke Die Entwicklung eines Bayesischen Netzwerks beginnt oft mit der Schaffung einer DAG G, so dass X die lokale Markov-Eigenschaft in Bezug auf G.Sometimes erfüllt, dies ist eine ursächliche DAG. Die bedingten Wahrscheinlichkeitsverteilungen jeder Variablen bei ihren Eltern in G werden bewertet. In vielen Fällen, insbesondere in dem Fall, in dem die Variablen diskret sind, wenn die gemeinsame Verteilung von X das Produkt dieser bedingten Verteilungen ist, ist X ein Bayesisches Netz in Bezug auf G. Markov Decke Die Markov Decke eines Knotens ist das Set von Knoten, bestehend aus seinen Eltern, ihren Kindern und allen anderen Eltern seiner Kinder. Die Markov-Decke macht den Knoten unabhängig vom Rest des Netzes; die gemeinsame Verteilung der Variablen in der Markov-Decke eines Knotens ist ausreichend Wissen zur Berechnung der Verteilung des Knotens. X ist ein Bayesisches Netzwerk in Bezug auf G, wenn jeder Knoten bedingt unabhängig von allen anderen Knoten im Netzwerk ist, angesichts seiner Markov Decke. d-Separation Diese Definition kann durch Definition der d"-Separation zweier Knoten, wobei d für Richtung steht, allgemeiner gemacht werden. Wir definieren zunächst die d"-Separation eines Trails und dann definieren wir die d"-Separation von zwei Knoten in Bezug darauf. Lassen Sie P eine Spur von Knoten u zu v. Eine Spur ist ein schleifenfreier, nicht geschützter (d.h. alle Kantenrichtungen werden ignoriert) Pfad zwischen zwei Knoten. Dann soll P von einem Satz von Knoten Z d-separiert werden, wenn eine der folgenden Bedingungen hält: P enthält (aber muss nicht vollständig sein) eine gerichtete Kette, u ⋯ m ← ⋯ v \{displaystyle u\cdots \leftarrow m\leftarrow \cdots v} oder u ⋯ → m → ⋯ v \{displaystyle u\cdots \rightarrow m\rightarrow \cdots v}, so dass der mittlere Knoten m in Z ist, Pright Die Knoten u und v werden von Z d-separiert, wenn alle Wege zwischen ihnen d-separiert sind. Wenn u und v nicht d-separiert sind, werden sie d-verbunden. X ist ein Bayesian-Netzwerk in Bezug auf G, wenn für alle zwei Knoten u, v: X u Þ X v ∣ X Z \{displaystyle X_{u}\perp \!perp X_{v}\mid X_{Z}, wobei Z ein Set ist, das d-separates u und v. (Die Markov-Decke ist das minimale Set von Knoten, die d-separates. Causal-Netzwerke Obwohl Bayesische Netzwerke oft verwendet werden, um ursächliche Beziehungen zu repräsentieren, muss dies nicht der Fall sein: Eine gerichtete Kante von u bis v erfordert nicht, dass Xv ursächlich von Xu abhängig ist. Dies zeigt sich dadurch, dass Bayesische Netzwerke auf den Graphen: a → b → c und a ← b ← c \{displaystyle a\rightarrow b\rightarrow c\qquad text{and}}\qquad a\leftarrow b\leftarrow c} gleichwertig sind: das heißt, sie stellen genau die gleichen bedingten Unabhängigkeitsanforderungen auf. Ein ursächliches Netzwerk ist ein Bayesisches Netzwerk mit der Forderung, dass die Beziehungen ursächlich sind. Die zusätzliche Semantik von Kausalnetzen gibt an, dass, wenn ein Knoten X aktiv in einem bestimmten Zustand x (eine als do(X = x) geschriebene Aktion) verursacht wird, die Wahrscheinlichkeitsdichtefunktion auf diejenige des Netzwerks wechselt, das durch das Abschneiden der Links von den Eltern von X auf X und das Setzen von X auf den verursachten Wert x erhalten wird. Anhand dieser Semantik können die Auswirkungen externer Eingriffe aus vor der Intervention erhaltenen Daten vorhergesagt werden. Inferenzkomplexität und Approximationsalgorithmen Im Jahr 1990, während an der Stanford University an großen bioinformatischen Anwendungen, Cooper bewiesen, dass genaue Inferenz in Bayesian Netzwerken ist NP-hard. Dies führte zu einer Erforschung von Annäherungsalgorithmen mit dem Ziel, eine tragfähige Annäherung an die probabilistische Inferenz zu entwickeln. Im Jahr 1993 erwiesen Paul Dagum und Michael Luby zwei überraschende Ergebnisse zur Komplexität der Annäherung der probabilistischen Inferenz in Bayesischen Netzwerken.Zunächst haben sie bewiesen, dass kein traktabler deterministischer Algorithmus innerhalb eines absoluten Fehlers ≠ 1/2 eine probabilistische Inferenz annähern kann.Second, sie haben bewiesen, dass kein traktabler randomisierter Algorithmus innerhalb eines absoluten Fehlers ≠ 1/2 eine probabilistische Inferenz von mehr als 1/2 annähern kann. Zur gleichen Zeit hat Roth bewiesen, dass die genaue Inferenz in Bayesischen Netzwerken tatsächlich #P-komplete (und damit so schwer wie die Anzahl der befriedigenden Zuordnungen einer konjunktiven Normalformformformformformformformformformformel (CNF) zählt und dass ungefähre Inferenz innerhalb eines Faktors 2n1-Hyd für jeden Þ > 0, auch für Bayesische Netzwerke mit eingeschränkter Architektur, NP-Hy ist. In der Praxis schlugen diese Komplexitätsresultate vor, dass die Bayesischen Netzwerke zwar reiche Darstellungen für KI- und maschinelle Lernanwendungen waren, ihre Verwendung in großen realen Anwendungen jedoch durch topologische strukturelle Zwänge, wie z.B. naïve Bayes-Netzwerke oder durch Einschränkungen der bedingten Wahrscheinlichkeiten getempert werden müsste. Der von Dagum und Luby entwickelte gebundene Varianzalgorithmus war der erste nachweisbare schnelle Annäherungsalgorithmus, um die probabilistische Inferenz in Bayesischen Netzwerken mit Garantien für die Fehlernäherung effizient anzunähern. Dieser leistungsfähige Algorithmus erforderte die geringfügige Einschränkung der bedingten Wahrscheinlichkeiten des Bayesischen Netzes von Null und von 1/p(n), wobei p(n) ein Polynom auf der Anzahl der Knoten im Netzwerk n war. Software Notable Software für Bayesian-Netzwerke umfassen: Nur ein weiterer Gibbs Sampler (JAGS) – Open-Source-Alternative zu WinBUGS. Benutzt Gibbs Probenahme. OpenBUGS – Open-Source-Entwicklung von WinBUGS.SPSS Modeler – Handelssoftware, die eine Implementierung für Bayesische Netzwerke beinhaltet. Stan (Software) – Stan ist ein Open-Source-Paket zur Gewinnung Bayesischer Inferenz mit dem No-U-Turn Sampler (NUTS), einer Variante des Hamiltonian Monte Carlo. PyMC3 – Eine Python-Bibliothek, die eine eingebettete Domain-spezifische Sprache implementiert, um bayesische Netzwerke zu repräsentieren, und eine Vielzahl von Samplern (einschließlich NUTS)BNLearn - Eine Python-Bibliothek mit mehr Fähigkeiten und ermöglicht die Erweiterung eines regelmäßigen bayesischen Netzwerks. WinBUGS –Eine der ersten rechnerischen Implementierungen von MCMC-Probetern. Nicht mehr aufrechterhalten. Geschichte Der Begriff Bayesian-Netzwerk wurde 1985 von Judea Pearl geprägt, um zu betonen: die oft subjektive Natur der Eingabeinformationen die Abhängigkeit von Bayes' Konditionierung als Grundlage für die Aktualisierung von Informationen die Unterscheidung zwischen kausalen und offensichtlichen Moden der ArgumentationIn den späten 1980er Jahren Pearl's Probabilistic Reasoning in Intelligent Systems und Neapolitans probabilistic Reasoning in Expert Systems fassteten ihre Eigenschaften zusammen und etablierten sie als ein Feld der Studie. Siehe auch Anmerkungen ReferenzenWeiterlesen Conrady S, Jouffe L (2015-07-01). Bayesian Networks und BayesiaLab – Eine praktische Einführung für Forscher. Franklin, Tennessee: Bayesian USA.ISBN 978-0-9965333-0.Charniak E (Winter 1991). " Bayesische Netzwerke ohne Tränen" (PDF). AI Magazine. Kruse R, Borgelt C, Klawonn F, Moewes C, Steinbrecher M, Held P (2013). Eine methodische Einführung.London: Springer-Verlag.ISBN 978-1-4471-5012-1.Borgelt C, Steinbrecher M, Kruse R (2009). Grafische Modelle – Darstellungen zum Lernen, Denken und Data Mining (Second ed.). Chichester: Wiley. ISBN 978-0-470-74956-2. Externe Links Eine Einführung in Bayesian Networks und ihre zeitgenössischen Anwendungen On-line Tutorial auf Bayesischen Netzen und Wahrscheinlichkeit Web-App Bayesian Netze zu erstellen und es mit einer Monte Carlo Methode Continuous Time Bayesian Networks Bayesian Networks: Explanation und Analogy Ein Live-Tutorial zum Lernen Bayesischer Netzwerke Ein hierarchisches Bayes Modell zur Behandlung von Probenheterogenität in Klassifizierungsproblemen, bietet ein Klassifizierungsmodell unter Berücksichtigung der Unsicherheit, die mit der Messung von Replikatproben verbunden ist. Hierarchisches Naive Bayes Modell zur Handhabung von Probenunsicherheit Archived 2007-09-28 auf der Wayback-Maschine, zeigt, wie man Klassifizierung und Lernen mit kontinuierlichen und diskreten Variablen mit replizierten Messungen durchführt.