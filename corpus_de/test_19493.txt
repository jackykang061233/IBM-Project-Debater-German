New Keynesian Economics ist eine Schule von makroökonomischen Kräften, die sich um die Bereitstellung mikroökonomischer Grundlagen für die abonianischen Wirtschaft bemühen. Er entwickelte sich zum Teil als Reaktion auf Kritiken an den makroökonomischen Effekten von Keynes durch die Befolgung neuer klassischer Makroökonomien. Zwei Hauptannahmen legen den neuen haushaltspolitischen Ansatz in der Region fest. Wie der neue klassische Ansatz wird in der Regel davon ausgegangen, dass Haushalte und Unternehmen vernünftige Erwartungen haben. Jedoch unterscheiden sich die beiden Schulen in dieser New Keynesian Analyse in der Regel von einer Vielzahl von Marktversagen. Konkret erwarten New Keynesians, dass es unvollkommener Wettbewerb bei der Preis- und Lohnfestsetzung gibt, um zu erklären, warum Preise und Löhne sich verfestigen können, was bedeutet, dass sie sich nicht unmittelbar an Veränderungen der wirtschaftlichen Bedingungen anpassen. Wage und Preiskontinuität sowie die anderen Marktversagen, die in New Keynesian Modellen enthalten sind, bedeuten, dass die Wirtschaft keine Vollbeschäftigung erzielen kann. New Keynesians vertritt daher die Auffassung, dass die makroökonomische Stabilisierung durch die Regierung (Nutzung der Finanzpolitik) und die Zentralbank (Nutzung der Geldpolitik) zu einem effizienteren makroökonomischen Ergebnis führen kann als eine faire Politik. New Keynesianismus wurde Teil der neuen neoklassischen Synthese, die heute in der Regel nur als neue abonianische Wirtschaftszweige bezeichnet wird, die Teile dieser beiden und der neuen klassischen makroökonomischen Aspekte einbauen und heute die theoretische Grundlage der Mainstream-makroökonomischen Prinzipien bilden. Entwicklung der afrikanischen Wirtschaft 70er Jahre Anfang der siebziger Jahre entwickelte sich die erste Welle der Neuen Eisenerz. In seinem Artikel von 1977, Long-Term Contracts, Rationale Erwartungen und die optimale Geldversorgungsregel wurde das erste Modell der verdächtigten Informationen entwickelt. Er verabschiedete ein stabiles oder überlappendes Vertragsmodell. Legt fest, dass es zwei Gewerkschaften in der Wirtschaft gibt, die sich für Löhne entscheiden. Wenn es sich um eine Union handelt, wählt sie die Löhne aus, die sie für die nächsten beiden Zeiträume festlegen wird. Man unterscheidet sich mit dem Modell von John B. Taylor, in dem der Nominallohn im Laufe des Vertragslebens konstant ist, wie er später in seinen beiden Artikeln entwickelt wurde, einem im Jahr 1979 "Staggerierte Lohneinstellung in einem makroökonomischen Modell" und einem im Jahr 1980 "Asse Dynamics and Staggered Contracts". Sowohl Taylor als auch Fischer-Verträge teilen das Merkmal, dass nur die Gewerkschaften, die den Lohn in der jetzigen Zeit festlegen, die neuesten Informationen verwenden: Löhne in der Hälfte der Wirtschaft spiegeln immer noch alte Informationen wider. Das Taylor-Modell hatte neben den ständigen Informationen die nominalen Löhne festhalten: Die nominalen Löhne mussten über die Länge des Vertrags (zwei Zeiträume) konstant sein. In diesen frühen neuen Theorien wurden die Grundidee zugrunde gelegt, dass eine Geldbehörde (zentrale Bank) die Beschäftigungsquote kontrollieren kann. Da die Löhne auf einem nominalen Satz festgesetzt werden, kann die Geldbehörde die Reallöhne (die für die Inflation angepaßten Lohnwerte) durch eine Änderung der Geldmenge kontrollieren und somit die Beschäftigungsquote beeinflussen. 80er-Jahre-Getreidekosten und unvollkommener Wettbewerb In den 80er Jahren wurde das Schlüsselkonzept für die Nutzung der Menükosten im Rahmen des unvollkommenen Wettbewerbs entwickelt, um die Preisfestsetzung zu erklären. In ihrem Papier, das sich auf die Auswirkungen der Inflation auf die Häufigkeit der Preisänderungen stützte, wurde ursprünglich von Sheshinski und Weiss (1977) eingeführt. Die Idee, sie als allgemeine Theorie der nominalen Preisflexidität anzuwenden, wurde von mehreren Ökonomen in den Jahren 1985 bis 6 gleichzeitig vorgestellt. George Akerlof und Janet Yellen haben die Idee vorgebracht, dass Unternehmen aufgrund der gebundenen Rationalität ihren Preis nicht ändern wollen, es sei denn, der Nutzen ist mehr als ein kleiner Betrag. Diese gebundene Rationalität führt zu Unruhe bei nominalen Preisen und Löhnen, die zu einer Schwankungen der nominalen Preise und Löhne führen können. Gregory Mankiw nahm die Menü-Kosten-idee an und konzentrierte sich auf die Wohlfahrtseffekte von Veränderungen der Produktion infolge von Festpreisen. Michael Parkin legte auch die Idee vor. Obwohl sich der Ansatz zunächst hauptsächlich auf die Rigidität der nominalen Preise konzentrierte, wurde er auf Löhne und Preise von Olivier Blanchard und Nobuhiro Kiyotaki in ihrem einflussreichen Artikelmonopol Wettbewerb und den Auswirkungen der Gesamtnachfrage ausgeweitet. Huw Dixon und Claus Hansen zeigten, dass dies auch wenn die auf einen kleinen Sektor der Wirtschaft angewandten Menükosten den Rest der Wirtschaft beeinflussen und zu Preisen in der übrigen Wirtschaft führen würde, die weniger auf Veränderungen der Nachfrage reagieren. Manche Studien schlugen zwar vor, dass die Menükosten zu klein sind, um einen großen Gesamteffekt zu haben, aber Laurence Ball und David Romer zeigten 1990, dass echte Rigiditäten mit nominalen Rigiditäten interagieren könnten, um erhebliche Ungleichgewichte zu schaffen. Reale Rigiditäten entstehen, wenn ein Unternehmen seine realen Preise langsam anpasst, um auf ein sich veränderndes wirtschaftliches Umfeld zu reagieren. Beispielsweise kann ein Unternehmen mit echten Rigiditäten konfrontiert sein, wenn es über Marktmacht verfügt oder wenn seine Kosten für Inputs und Löhne durch einen Vertrag blockiert werden. Ball und Romer argumentierten, dass echte Rigiditäten auf dem Arbeitsmarkt die Kosten eines Unternehmens hoch halten, was Unternehmen erschwere, Preise zu senken und Einnahmen zu verlieren. Die durch reale Rigiditäten verursachten Kosten in Verbindung mit den Menükosten für sich verändernde Preise führen zu geringerer Wahrscheinlichkeit, dass das Unternehmen die Preise auf einem Marktclearing senken wird. Selbst wenn die Preise vollkommen flexibel sind, kann der unvollkommene Wettbewerb den Einfluss der Finanzpolitik auf den Multiplikator beeinflussen. Huw Dixon und Gregory Mankiw entwickelten unabhängige einfache allgemeine Gleichgewichtsmodelle, die zeigen, dass der fiskalische Multiplikator mit dem unvollkommenen Wettbewerb auf dem Outputmarkt zunimmt. Grund hierfür ist, dass der unvollkommene Wettbewerb auf dem Outputmarkt tendenziell dazu führt, den Reallohn zu senken, was dazu führt, dass der Haushalt weg vom Verbrauch bis hin zu Freizeit führt. Wenn die Staatsausgaben angestiegen sind, führt die entsprechende Erhöhung der Pauschalsteuer sowohl Freizeit als auch Verbrauch zu einem Rückgang ( vorausgesetzt, sie sind ein normaler Vorteil). Je größer der unvollkommene Wettbewerb auf dem Produktionsmarkt, des niedrigeren Reallohns und damit der höhere Rückgang der Freizeit (d. h. die Haushalte arbeiten mehr) und weniger auf dem Verbrauch. Der fiskalische Multiplikator ist also weniger als ein, aber im Ausmaß des unvollkommenen Wettbewerbs auf dem Outputmarkt. Das Calvo-Modell der Verträge Guillermo Calvo schrieb 1983 "Staggerierte Preise in einem Gebrauchs-Maximizing Framework". Der ursprüngliche Artikel wurde in einem kontinuierlichen mathematischen Rahmen geschrieben, wird aber heute meist in seiner diskreten Fassung verwendet. Das Calvo-Modell ist der häufigste Weg, um die nominale Sterblichkeit in den neuen Modellen zu modellieren. Es besteht die Wahrscheinlichkeit, dass das Unternehmen seinen Preis in einem Zeitraum h (Risikorate) oder in gleicher Weise wie die Wahrscheinlichkeit (1-h) neu festlegen kann, dass der Preis in diesem Zeitraum unverändert bleibt (Überschuss). Manchmal wird die Wahrscheinlichkeit h in diesem Zusammenhang genannt. Im Calvo-Modell ist das entscheidende Merkmal, dass der Preis-Aufzeichnung nicht weiß, wie lange der Nominalpreis im Gegensatz zum Taylor-Modell, in dem die Vertragslänge bekannt ist, nicht vorhanden ist. Koordinierungsversagen war ein weiteres wichtiges neues Konzept für die energische Politik, das als eine weitere mögliche Erklärung für Rezessionen und Arbeitslosigkeit entwickelt wurde. In Rezessionen kann eine Fabrik untätig bleiben, auch wenn es Menschen gibt, die bereit sind, in sie zu arbeiten, und Menschen, die bereit sind, ihre Produktion zu kaufen, wenn sie Jobs hatten. In einem solchen Szenario scheinen die wirtschaftlichen Abschwungs das Ergebnis eines Koordinationsversagens: Die unsichtbare Hand koordiniert nicht den üblichen, optimalen Produktions- und Konsumfluss. Luc Cooper und Andrew John's Papierkoordinierung von Koordinationsversagen in Keynesian Modellen gaben eine allgemeine Form der Koordinierung als Modelle mit multiplen Gleichgewichten an, bei denen die Agenten in jedem ihrer jeweiligen Situationen koordinieren könnten, um (oder zumindest nicht schaden) zu verbessern. Cooper und John basieren auf früheren Modellen, darunter Peter Diamonds Kokos Modell von 1982, das einen Fall von Koordinationsversagen bei der Suche und Abstimmung der Theorie bewiesen hat. In den Modellherstellern von Diamond werden wahrscheinlicher produziert, wenn sie andere sehen. Die Zunahme möglicher Handelspartner erhöht die Wahrscheinlichkeit eines bestimmten Herstellers, der eine Person für den Handel mit einer Person sucht. Wie in anderen Fällen von Koordinationsversagen hat das Modell von Diamond mehrere Gleichgewichte, und der Schutz eines Agenten hängt von den Entscheidungen anderer ab. Diamonds Modell ist ein Beispiel für ein "thick-market Externality", das die Märkte besser funktionieren kann, wenn mehr Menschen und Unternehmen an ihnen teilnehmen. Andere mögliche Quellen von Koordinationsversagen umfassen Selbstverlagerungen. Wenn ein Unternehmen einen Rückgang der Nachfrage erwartet, könnten sie auf die Einstellung zurückgehen. Mangel an Stellenangeboten könnten besorgniserregende Arbeitnehmer, die dann auf ihren Konsum zurückgehen. Dieser Nachfragerückgang erfüllt die Erwartungen des Unternehmens, aber es ist völlig auf die eigenen Maßnahmen des Unternehmens zurückzuführen. Marktversagen: Leistungsfähige Löhne New Keynesians boten Erläuterungen zum Ausfall des Arbeitsmarktes an. In einem Walrasischen Markt fordern arbeitslose Arbeitskräfte die Löhne herunter, bis die Nachfrage nach Arbeitskräften dem Angebot entspricht. Wenn die Märkte Walrasian sind, würde sich die Zahl der Arbeitslosen auf Arbeitnehmer beschränken, die zwischen Arbeitsplätzen und Arbeitnehmern wechseln, die sich nicht für Arbeit entscheiden, weil die Löhne zu niedrig sind, um sie anzulocken. Sie entwickelten mehrere Theorien, aus denen hervorgeht, warum die Märkte erwerbstätige Arbeitskräfte verlassen könnten. Kern dieser Theorien war die Effizienz der Lohntheorie, die dazu verwendet wurde, langfristige Auswirkungen früherer Arbeitslosigkeit zu erklären, wo kurzfristige Erhöhungen der Arbeitslosigkeit dauerhaft und langfristig zu höheren Arbeitslosigkeit führen. Leistungsfähige Lohnmodelle werden auf einem Niveau bezahlt, das die Produktivität maximiert, anstatt den Markt zu öffnen. Unternehmen können beispielsweise in Entwicklungsländern mehr als eine Marktrate zahlen, um sicherzustellen, dass ihre Arbeitnehmer genügend Ernährung liefern können, um produktiv zu sein. Firmen können auch höhere Löhne zahlen, um Loyalität und Moral zu erhöhen, möglicherweise zu einer besseren Produktivität. Firmen können auch höhere Löhne zahlen als die Marktlöhne für Holzschrott. Shirking Modelle waren besonders einflussreich. Carl Shapiro und Joseph Stiglitzs 1984 Papier Equilibrium Arbeitslosigkeit als Arbeitsperson Discipline-Gerät haben ein Modell geschaffen, bei dem die Arbeitnehmer tendenziell vermeiden, Arbeit zu vermeiden, es sei denn, die Unternehmen können den Arbeitskräfteaufwand überwachen und Arbeitnehmer mit Arbeitslosigkeit bedrohen. Wenn die Wirtschaft voll erwerbstätig ist, bewegt sich ein Feuerschmuggler einfach zu einem neuen Arbeitsplatz. Einzelunternehmen zahlen ihre Arbeitnehmer über den Marktpreis, um sicherzustellen, dass ihre Arbeitnehmer eher arbeiten und ihren aktuellen Job nicht verlieren, sondern dass sie in einen neuen Arbeitsplatz wechseln müssen. Da jedes Unternehmen mehr als marktbeherrschende Löhne zahlt, ist der aggregierte Arbeitsmarkt nicht klar. Dadurch entsteht ein Pool von Arbeitslosen und erhöht sich auf die Kosten, die erhofft. Arbeitnehmer riskieren nicht nur ein niedrigeres Löhne, sie laufen Gefahr, in den Pool von Arbeitslosen zu stecken. Löhne über marktbeherrschende Niveaus führen zu ernsthaften Negativanreizen, die Arbeitnehmer effizienter machen, auch wenn es einige erwerbstätige Arbeitskräfte gibt. 90er JahreDie neue neoklassische Synthese Anfang der 90er Jahre begannen die Ökonomen, die Elemente der in den 80er Jahren entwickelten und früher mit der Real Business-Zyklustheorie zu kombinieren. RBC-Modelle waren dynamisch, aber angenommen, perfekter Wettbewerb; neue Keynesian Modelle waren vor allem statische, aber auf unvollkommenem Wettbewerb beruhen. Die neue neoklassische Synthese kombiniert im Wesentlichen die dynamischen Aspekte von RBC mit unvollkommenem Wettbewerb und nominalen Rigiditäten der neuen Modelle von Keynes. Tack Yun war eines der ersten, um dies in einem Modell zu tun, das das Preismodell von Calvo nutzte. Gute Freunde und König schlugen eine Liste von vier Elementen vor, die für die neue Synthese von zentraler Bedeutung sind: Intertemporaloptimierung, rationale Erwartungen, unvollkommener Wettbewerb und kostspielige Preisanpassung (Menukosten). Gute Freunde und König finden auch, dass die Konsensmodelle bestimmte politische Auswirkungen hervorrufen: Während die Geldpolitik kurzfristig die tatsächliche Leistung beeinflussen kann, aber es gibt keine lange Laufzeit: Geld ist nicht in der kurzen Zeit neutral, aber es ist auf lange Sicht. Inflation hat negative Wohlfahrtseffekte. Es ist wichtig, dass Zentralbanken die Glaubwürdigkeit durch eine auf Regeln basierende Politik wie Inflationsziel erhalten. John B Taylor hat 1993 die Idee einer Taylor-Regelung formuliert, die eine geringere Form der Angleichung der Reaktionsfähigkeit des nominalen Zinssatzes darstellt, wie von der Zentralbank festgelegt, um Inflation, Output oder andere wirtschaftliche Bedingungen zu ändern. Insbesondere wird in der Regel beschrieben, wie die Zentralbank für jeden einprozentigen Anstieg der Inflation die nominale Zinssätze um mehr als einen Prozentpunkt erhöht. Dieser Aspekt der Regel wird oft als Taylor-Prinzip bezeichnet. Obwohl solche Vorschriften knappe, beschreibende Befürchtungen für die Zentralbankpolitik vorsehen, gelten sie in der Praxis nicht ausdrücklich als von Zentralbanken bei der Festsetzung der nominalen Tarife. Taylors ursprüngliche Fassung der Regel beschreibt, wie die nominale Zinssätze auf unterschiedliche tatsächliche Inflationsraten von der Zielinflationsrate und dem tatsächlichen Bruttoinlandsprodukt (BIP) des potenziellen BIP reagieren: i t =  + t + r t  + + a  ( ( ( t π t π t ∗  t  t          +  +  +  +  +  +  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y KINGstyle i_{t} t}+r_{t**}+a_ggiopi (\}pi {_t}-\pi t**})+a_{y}(y_{t}-y_{t. In dieser Gleichung, d. h. t {\displaystyle i_{t}, ist der kurzfristige Nominalzinssatz (z.B. der Bundesfondssatz in den USA, die Bank of England im Vereinigten Königreich), π t {\displaystyle ,\pi {t,\} ist die Inflationsrate, gemessen am BIP-Deflator,  t t \pi _^*} ist die gewünschte Inflationsrate, r {\ style_style {t,* {tari {t, y . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Die New Keynesian Phillips-Kurve Die New Keynesian Phillips-Kurve wurde 1995 von Roberts abgeleitet und wurde seitdem in den meisten modernen Modellen der Neuen Keynesian DSGE verwendet. Die neue Keynesian Phillips-Kurve sagt, dass die Inflation dieser Periode von der aktuellen Produktion und den Erwartungen der Inflation des nächsten Zeitraums abhängt. Die Kurve ist aus dem dynamischen Calvo-Modell der Preise abgeleitet und mathematisch: π t = β E t [ π t + 1 ] +  y y t KINGstyle \pi {_t}=\beta E_{t}[\pi {_t+1}]+\kappa y_{t} In der jetzigen Periode werden die Erwartungen der nächsten Inflation als β E t [  + t + 1 ] Memestyle \beta E_{t}[\pi {t+1]} , wo β KINGstyle \beta } der Rabattfaktor ist. Die konstante {\ \kappa } erfasst die Reaktion der Inflation auf die Produktion und wird weitgehend durch die Wahrscheinlichkeit eines Preiswechsels in einem beliebigen Zeitraum bestimmt, der h Memestyle h}:  = = h [ 1 − h ] β ] 1 − h   KINGstyle \kappa ggio=frac {h[1-h)\beta {]1-hammagamma } .Die unflexiblen nominalen Preise sind (die höher ist h displaystyle h}), die größere Wirkung der Produktion auf die derzeitige Inflation. Wissenschaftliche Währungspolitik Die in den 90er Jahren entwickelten Ideen wurden zusammengebracht, um das neue abonianische dynamische, allgemeine Gleichgewicht zu entwickeln, das zur Analyse der Geldpolitik verwendet wird. Das Ergebnis war das dreifache neue, in der Erhebung von Richard Clarida, Jordi Gali und Mark Gertler im Journal of Economic Liter gefundene Modell. Es kombiniert die beiden Gleichungen der neuen Libertyian Phillips-Kurve und der Taylor-Regel mit der dynamischen IS-Kurve, die sich aus der optimalen dynamischen Konsumgleichung (EU-Eisler-Angleichung) ergibt. y t = y t + 1 + 1 ) (i t − E t π t + 1 ) + v t {\displaystyle y_{t} 1s (i_{t}-E_{t}\pi t+1})+v_{t Diese drei Gleichungen bilden ein relativ einfaches Modell, das für die theoretische Analyse politischer Fragen verwendet werden könnte. In einigen Punkten wurde das Modell jedoch übermäßig vereinfacht (z.B. gibt es kein Kapital oder keine Investitionen). Ebenfalls führt sie nicht gut empirische Ergebnisse. 2000sIn dem neuen Jahrtausend gab es mehrere Fortschritte in den neuen schottischen Wirtschaften. Einführung unvollständiger Arbeitsmärkte Obwohl sich die Modelle der 90er Jahre auf die festigen Preise im Outputmarkt konzentrierten, verabschiedeten im Jahr 2000 Christopher Erceg das Blanchard- und Kiyotaki-Modell der gewerkschaftlichen Arbeitsmärkte, indem es ihn mit dem Calvo-Preiskonzept kombiniert und in ein neues Modell für die transetische DSGE einführte. Entwicklung komplexer DSGE-Modelle. Modelle, die gut mit den Daten zusammengearbeitet haben und für politische Simulationen verwendet werden könnten, wurden mit mehreren Merkmalen sehr komplizierte neue, sachgerechte Modelle entwickelt. Seminal Papers wurden von Frank Smets und Rafael Wouters sowie Lawrence J. Christiano, Martin Eichenbaum und Charles Evans veröffentlicht Die gemeinsamen Merkmale dieser Modelle waren: Gewohnheitserhaltung. Das marginale Konsumverhalten hängt vom Konsumverhalten der Vergangenheit ab.Calvo Preise sowohl auf den Produktions- als auch auf den Produktmärkten mit Indexierung, so dass Löhne und Preise nicht ausdrücklich neu angesiedelt sind, werden sie für die Inflation aktualisiert. Kapitalanpassungskosten und variable Kapitalnutzung. neue Schocks fordern Schocks, die den marginalen Nutzen von Konsumzeichenup-Schwellen beeinträchtigen, die die gewünschte Preisaufzeichnung über die Grenzkosten beeinflussen. Geldpolitik ist durch eine Taylor-Regelung vertreten. Methoden zur Schätzung der Buchten. Komplizierte Informationen Nach dem Vorbild von Gregory Mankiw und Ricardo Reis entwickelte sich die Idee von Zwangsinformationen. Das fügte ein neues Merkmal zum Fischermodell hinzu: Es gibt eine feste Wahrscheinlichkeit, dass Sie Ihre Löhne oder Preise jeden Zeitraum neu planen können. Mit vierteljährlichen Daten haben sie einen Wert von 25 % angenommen: Jedes Viertel 25% der randomisierten Unternehmen/Unionen können auf der Grundlage aktueller Informationen einen Pfad der aktuellen und künftigen Preise planen. Wenn wir den aktuellen Zeitraum in Erwägung ziehen: 25% der Preise werden auf den neuesten verfügbaren Informationen basieren; der Rest auf Informationen, die verfügbar waren, wenn sie zuletzt in der Lage waren, ihren Preispfad zu planen. Mankiw und Reis stellten fest, dass das Modell der ständigen Informationen einen guten Weg zur Erklärung der Inflation darstellt. Komplizierte Informationsmodelle haben keine nominale Rigidität: Unternehmen oder Gewerkschaften können für jeden Zeitraum unterschiedliche Preise oder Löhne wählen. Es sind die Informationen, die nicht die Preise sind. Wenn ein Unternehmen Glück erhält und seine aktuellen und künftigen Preise wieder planen kann, wird er sich für eine Richtung entscheiden, was er für die besten Preise für die Zukunft und die Zukunft hält. Insgesamt wird dies die Festsetzung eines anderen Preises je nach dem Plan umfassen. Dies steht im Widerspruch zu den empirischen Daten über die Preise. In verschiedenen Ländern gibt es jetzt viele Studien über Preisflexibilität: die Vereinigten Staaten, die Eurozone, das Vereinigte Königreich und andere. Diese Studien zeigen alle, dass es zwar einige Sektoren gibt, in denen die Preise häufig geändert werden, aber es gibt auch andere Sektoren, in denen die Preise im Laufe der Zeit feststehen. Mangelnde Preise im Aufkleber-Informationsmodell sind mit dem Preisverhalten in den meisten Volkswirtschaften nicht vereinbar. Dies hat dazu geführt, dass man versucht hat, ein "duale Haltbarkeit"-Modell zu formulieren, das verlässliche Informationen mit gleichbleibenden Preisen kombiniert. 2010sThe 2010s sahen die Entwicklung von Modellen, die die Heterogenität der privaten Haushalte in den Standard-Neutronenrahmen einbinden, der häufig als 'HANK'-Modelle (Heterogenes New Keynesian) bezeichnet wird. Neben den Festpreisen verfügt ein typisches HANK-Modell über ein unüberwindbares idiosynstisches Arbeitseinkommen, das zu einer unbestimmten Vermögensverteilung führt. In den ersten Modellen mit diesen beiden Merkmalen sind u. a. die Modelle Oh und Reis (2012), McKay und Reis (2016) und Guerrieri und Lorenzoni 2017. Laut dem Namen "HANK" wurde Greg Kaplan, Benjamin Moll und Gianluca gewaltsamante im Jahr 2018 in einem Papier zusammengefasst, in dem zusätzlich die Haushalte als Anrechnung zwei Arten von Vermögenswerten, eine Liquidation der anderen illiquide, dargestellt werden. Dies führt zu einer reichen Heterogenität der Portfoliozusammensetzung in Haushalten. Insbesondere passt das Modell empirische Beweise an, indem es einen großen Teil der Haushalte mit geringem liquiden Wohlstand aufweist: die Haushalte von ’hand-to-mouth. Laut empirischen Erkenntnissen halten etwa zwei Drittel dieser Haushalte trotz des geringen liquiden Reichtums nicht rückwirkend. Diese Haushalte sind bekannt als wohlhabende Hand-zu-Märkte, die 2014 in einer Studie über finanzpolitische Stimulierungsmaßnahmen von Kaplan und gewaltsam eingeführt wurden. Das Bestehen von wohlhabenden Hand-to-MKS-Haushalten in New Keynesian-Modellen betrifft die Auswirkungen der Geldpolitik, denn das Konsumverhalten dieser Haushalte ist stark auf Veränderungen des verfügbaren Einkommens und nicht auf die Zinsschwankungen (d. h. den Preis des künftigen Konsums im Verhältnis zum aktuellen Konsum). Direkt geht es darum, dass die Geldpolitik größtenteils über allgemeine Gleichgewichtseffekte übertragen wird, die durch das Einkommen der Haushaltsarbeit entstehen, statt durch die intertemporale Substitution, die der wichtigste Übertragungskanal in den Modellen des Vertreters New Keynesian (RANK) ist. Es gibt zwei wesentliche Auswirkungen auf die Geldpolitik. Erstens wechselt die Geldpolitik stark mit der Fiskalpolitik, weil es durch die Präsenz von Hand-to-MKS-Haushalten versäumt hat. Insbesondere Änderungen der Zinssätze ändern die Haushaltszwänge der Regierung und die steuerliche Reaktion auf diese Verlagerung beeinflussen das verfügbare Einkommen der Haushalte. Zweitens sind aggregierte Geldschocks nicht verteilungsneutral, da sie die Kapitalrendite beeinflussen, die Haushalte mit unterschiedlichen Wohlstands- und Vermögenswerten beeinträchtigt. Politikauswirkungen New Keynesian Ökonomen stimmen mit neuen klassischen Ökonomen überein, dass die klassische Dichomy langfristig: Änderungen der Geldversorgung sind neutral. Jedoch, weil die Preise im New Keynesian-Modell festhalten, führt eine Erhöhung der Geldversorgung (oder eine entsprechende Senkung der Zinssätze) kurzfristig zu einer Steigerung der Leistung und niedrigerer Arbeitslosigkeit. Darüber hinaus bestätigen einige neue Keynesian Modelle die Nichtneutralität von Geld unter mehreren Bedingungen. New Keynesian Economics plädiert jedoch nicht für die Nutzung einer expansiven Geldpolitik für kurzfristige Gewinne in Produktion und Beschäftigung, da sie Inflationserwartungen erhöhen und damit Probleme für die Zukunft speichern würde. stattdessen plädieren sie für die Anwendung der Geldpolitik zur Stabilisierung. Es wird nicht empfohlen, die erhöhten Inflationserwartungen zu beseitigen, ohne eine Rezession zu erzeugen. Wenn die Wirtschaft von einem unerwarteten externen Schock betroffen ist, kann es sich als gute Idee erweisen, die makroökonomischen Auswirkungen des Schocks mit der Geldpolitik auszugleichen. Dies gilt insbesondere, wenn der unerwartete Schock ein (wie ein Rückgang des Verbrauchervertrauens) ist, der sowohl die Produktion als auch die Inflation senkt; in diesem Fall trägt der Ausbau der Geldversorgung (niedrigere Zinssätze) dazu bei, die Produktion zu erhöhen und gleichzeitig Inflations- und Inflationserwartungen zu stabilisieren. Studien der optimalen Geldpolitik in New Keynesian DSGE-Modelle konzentrierten sich auf Zinsregeln (insbesondere „Taylor-Vorschriften“), in denen dargelegt wird, wie die Zentralbank die nominale Zinssätze an die Veränderungen in Inflation und Produktion anpassen sollte. () Genauere, optimale Regeln reagieren in der Regel auf Veränderungen in der Produktionslücke, statt Veränderungen in der Output pro se.) In einigen einfachen New Keynesian DSGE-Modellen stellt sich heraus, dass die Stabilisierung der Inflationsdefizite, da die Beibehaltung einer vollkommen stabilen Inflation auch die Produktion und die Beschäftigung auf dem höchst wünschenswerten Niveau stabilisiert. Blanchard und Galí haben diese Eigenschaft als „divine Zufall“ bezeichnet. Jedoch zeigen sie auch, dass in Modellen mit mehr als einem Marktungleichheit (z.B. bei der Anpassung des Beschäftigungsniveaus sowie bei den kontinuierlichen Preisen) kein „Didivin-Quartett“ mehr vorhanden ist und stattdessen zwischen der Stabilisierung der Inflation und der Stabilisierung der Beschäftigung besteht. Manche Makroökonomieer sind der Ansicht, dass die neuen Modelle von Indonesien auf der Grundlage einer vierteljährlichen quantitativen Beratung nützlich sind, es gibt Meinungsverschiedenheiten. Kürzlich wurde gezeigt, dass das göttliche Zufall nicht unbedingt in der nichtlinearen Form des Standard-Neu-Keynesischen Modells gehalten wird. Nur wenn die Geldbehörde verpflichtet ist, die Inflationsrate auf genau 0 % zu halten. In jedem anderen gewünschten Ziel für die Inflationsrate gibt es ein endogener Abstieg, auch wenn es keine wirklichen Unzulänglichkeiten wie z.B. die kontinuierlichen Löhne gibt, und das göttliche Zufall nicht mehr. Zusammenhang mit anderen makroökonomischen Schulen Im Laufe der Jahre wurde eine Reihe neuer makroökonomischer Theorien im Zusammenhang mit dem oder gegen den Keynesianismus beeinflusst. Nach dem Zweiten Weltkrieg nutzte Paul Samuelson den Begriff neoklassische Synthese, um auf die Integration der aeusserischen Wirtschaft mit neoklassischen Volkswirtschaften zu verweisen. Die Idee war, dass die Regierung und die Zentralbank die Vollbeschäftigung beibehalten würden, so dass neoklassische Notierungen, die auf dem axiom der Universalität der Knappheit ausgerichtet sind, in Anspruch nehmen. John Hicks' IS/LM war für die neoklassische Synthese von zentraler Bedeutung. Spätere Arbeit von Wirtschaftswissenschaftlern wie James Tobin und Franco Modigliani, die mehr Gewicht auf die Mikrofoundationen von Konsum und Investitionen haben, wurde manchmal als Neo-Keynesianismus bezeichnet. Man unterscheidet sich oft mit dem Post-Keynesianismus von Paul Davidson, der die Rolle der fundamentalen Unsicherheit im wirtschaftlichen Leben unterstreicht, insbesondere was Fragen der privaten Festinvestitionen betrifft. New Keynesianismus war eine Antwort auf Robert Lucas und die neue klassische Schule. Diese Schule kritisierte die Unstimmigkeiten von Keynesianismus im Lichte des Begriffs "rationale Erwartungen". Die neuen Klassischen kombinierten ein einzigartiges marktbeherrschendes Gleichgewicht (in Vollbeschäftigung) mit vernünftigen Erwartungen. Die New Keynesians nutzten Mikrofoundationen, um zu zeigen, dass die Preisklemmung die Märkte von der Clearing behindert. So muss das vernünftige, auf Erwartungen basierende Gleichgewicht nicht einzigartig sein. Während die neoklassische Synthese hofft, dass die Finanz- und Geldpolitik die volle Beschäftigung aufrechterhält, haben die neuen klassischen angenommen, dass die Preis- und Lohnanpassung diese Situation kurzfristig automatisch erreichen würde. Die neuen Keyneser sahen hingegen die Vollbeschäftigung, die nur auf lange Sicht automatisch erreicht wird, da die Preise kurzfristig eingehalten werden. Regierungs- und Zentralbankpolitik sind notwendig, weil die "langfristige" Politik sehr lang sein kann. Letztlich wurden die Unterschiede zwischen den neuen klassischen makroökonomischen und den Neuen haushaltspolitischen Faktoren in der neuen neoklassischen Synthese der 90er Jahre gelöst, die die Grundlage der wirtschaftlichen Grundzüge bilden, und dem energischen Beton auf die Bedeutung einer zentralisierten Koordinierung makroökonomischer Maßnahmen (z.B. Währungs- und Steueranreize), internationalen Wirtschaftsinstitutionen wie der Weltbank und des Internationalen Währungsfonds (IMF) und der Aufrechterhaltung eines kontrollierten Handelssystems während der globalen Finanz- und Wirtschaftskrise 2008 hervorgehoben. Dies spiegelt sich in der Arbeit von IMF-Wirtschaftern und Donald Markwell wider. Großherkunftswissenschaftler Jordi Galí Mark Gertler NobuhiroKiyotaki Michael Woodford Gregory Mankiw Siehe auch Calvo (stagniert) Verträge 2008–2009 Keynesian resurgence Neue neoklassische Synthesepreise Wohlfahrtskosten für Geschäftszyklen Taylor Verträge (Wirtschaft) Verweise auf weitere Lesung Clarida, Richard; Galí, Jordi; Gertler, Mark (1999). " Wirtschaftsliteratur.37 (4): 1661-1707.CiteSeerX 10.1.1.199.3912.doi:10.1257/jel.37.4.1661.JSTOR 2565488.S2CID 55045787 Robert J. Gordon Gordon, Robert (1990), Was ist New-Keynesian Economics? Journal of Economic Liter. Dixon, Huw (2008), New Keynesian Economics, New Palgrave Wörterbuch of Economics New Keynesian macros.doi:10.1057/9780230226203.1184.Mankiw, N. Gregory (2008)." David R. Col (ed. Koncise Veröffentlichung von Wirtschaft (2. ed). Bangladesch: Bibliothek of Economics and Liberty. ISBN: 0865976658.OCLC 237794267. Hacke, Nick."The Growth Step of the New Keynesian Modell. Machen Sie die kanadische Initiative. Juli 2014