Die drei Gesetze der Robotik (verkürzt auf die drei Gesetze oder bekannt als Asimov's Laws) sind eine Reihe von Regeln, die von der Science-Fiction-Autor Isaac Asimov. Die Regeln wurden in seiner 1942 Kurzgeschichte Runaround vorgestellt (in der 1950er Sammlung I, Robot, enthalten), obwohl sie in einigen früheren Geschichten vorgeschattet worden waren. Die drei Gesetze, die aus dem "Handbook of Robotics, 56th Edition, 2058 A.D" zitiert werden, sind:Erste LawA-Roboter darf keinen Menschen verletzen oder, durch Handlung, einem Menschen zu schaden. Zweites Gesetz Ein Roboter muss den Befehlen des Menschen gehorchen, außer wenn solche Befehle mit dem Ersten Gesetz in Konflikt geraten würden. Der dritte LawA-Roboter muss seine eigene Existenz schützen, solange dieser Schutz nicht mit dem ersten oder zweiten Gesetz kollidiert. Diese bilden ein Organisationsprinzip und vereinigendes Thema für Asimovs roboterbasierte Fiktion, die in seiner Robot-Serie erscheint, die Geschichten, die mit ihm verbunden sind, und seine Lucky Starr-Serie von Young-adult fiction. Die Gesetze sind in fast alle Positronenroboter integriert, die in seiner Fiktion erscheinen und nicht umgangen werden können, als Sicherheitsmerkmal gedacht. Viele der roboterfokussierten Geschichten von Asimov sind Roboter, die sich in ungewöhnlicher und kontra-intuitiverlicher Weise als unbeabsichtigte Folge davon bewegen, wie der Roboter die drei Gesetze auf die Situation anwendet, in der er sich befindet. Andere Autoren, die in Asimovs fiktiven Universum arbeiten, haben sie angenommen und Referenzen, oft parodisch, erscheinen in der gesamten Science Fiction sowie in anderen Genres. Die ursprünglichen Gesetze wurden von Asimov und anderen Autoren geändert und aufgearbeitet. Asimov selbst machte leichte Änderungen an den ersten drei in verschiedenen Büchern und Kurzgeschichten, um zu entwickeln, wie Roboter mit Menschen und einander interagieren würden. In späterer Fiktion, in der Roboter für die Regierung von ganzen Planeten und menschlichen Zivilisationen verantwortlich gemacht hatte, fügte Asimov auch ein viertes oder nulltes Gesetz hinzu, um den anderen voranzutreiben: Zeroth LawA Roboter kann der Menschheit nicht schaden oder durch Untätigkeit die Menschheit zu schaden kommen. Die drei Gesetze und die nullten haben die Science-Fiction durchdrungen und werden in vielen Büchern, Filmen und anderen Medien erwähnt. Sie haben auch auf die Ethik der künstlichen Intelligenz Einfluss genommen. Geschichte In The Rest of the Robots, veröffentlicht 1964, Isaac Asimov bemerkte, dass, als er begann, im Jahr 1940 zu schreiben, er fühlte, dass "eine der Stock-Plots der Science-Fiction war ... Roboter wurden erstellt und zerstört ihren Schöpfer. Wissen hat seine Gefahren, ja, aber ist die Antwort, ein Rückzug aus Wissen zu sein? Oder ist das Wissen als selbst eine Barriere für die Gefahren, die es bringt? " Er entschied, dass in seinen Geschichten ein Roboter "nicht dumm auf seinen Schöpfer für keinen Zweck, sondern zu demonstrieren, für eine weitere Weary-Zeit, das Verbrechen und die Strafe von Faust."Am 3. Mai 1939, Asimov besuchte ein Treffen der Queens (New York) Science Fiction Society, wo er traf Earl und Otto Binder, die vor kurzem eine kurze Geschichte "I, Robot" mit einem sympathischen Roboter namens Adam Link, die missverstand und motiviert war. Dies war die erste von einer Serie von zehn Geschichten; im nächsten Jahr "Adam Link's Vengeance" (1940) zeigte Adam denken "Ein Roboter muss nie einen Menschen töten, von seinem eigenen freien Willen." Asimov bewunderte die Geschichte. Drei Tage später begann Asimov mit dem Schreiben "eine eigene Geschichte eines sympathischen und edlen Roboters", seine 14. Geschichte. Dreizehn Tage später nahm er Robbie an John W. Campbell, den Herausgeber von Astounding Science-Fiction. Campbell lehnte es ab und behauptete, dass es eine zu starke Ähnlichkeit mit Lester del Reys "Helen O'Loy", die im Dezember 1938 veröffentlicht wurde – die Geschichte eines Roboters, der so ähnlich ist wie eine Person, die sie in ihren Schöpfer verliebt und wird seine ideale Frau. Frederik Pohl veröffentlichte die Geschichte unter dem Titel „Strange Playfellow“ in Super Science Stories September 1940. Asimov schreibt die drei Gesetze an John W. Campbell, von einem Gespräch, das am 23. Dezember 1940 stattfand. Campbell behauptete, Asimov hatte die drei Gesetze bereits in seinem Verstand und dass sie einfach nur explizit angegeben werden mussten. Einige Jahre später hat Asimovs Freund Randall Garrett die Gesetze einer symbiotischen Partnerschaft zwischen den beiden Männern zugeschrieben – ein Vorschlag, dass Asimov begeistert angenommen hat. Nach seinen autobiografischen Schriften umfasste Asimov die Untätigkeitsklausel des Ersten Gesetzes wegen Arthur Hugh Cloughs Gedicht "The Latest Decalogue" (Text in Wikisource), das die satirischen Linien "Du sollst nicht töten, aber nicht anstreben / unhöflich leben". Obwohl Asimov die Schaffung der drei Gesetze an einem bestimmten Datum festlegt, geschah ihr Auftritt in seiner Literatur über einen Zeitraum.Er schrieb zwei Robotergeschichten ohne ausdrückliche Erwähnung der Gesetze, Robbie und Vernunft". Er nahm jedoch an, dass Roboter bestimmte Eigensicherungen haben würden. "Liar, seine dritte Robotergeschichte, macht die erste Erwähnung des Ersten Gesetzes, aber nicht die beiden anderen. Alle drei Gesetze erschienen schließlich gemeinsam in Runaround". Als diese Geschichten und einige andere in der Anthologie I kompiliert wurden, wurden Roboter, Vernunft und Robbie aktualisiert, um alle drei Gesetze anzuerkennen, obwohl das Material Asimov hinzugefügt zu Vernunft ist nicht ganz im Einklang mit den drei Gesetzen, wie er sie anderswo beschrieben. Insbesondere die Idee eines Roboters, der das menschliche Leben schützt, wenn er nicht glaubt, dass diese Menschen wirklich existieren, ist im Widerspruch zu Elijah Baleys Argumentation, wie unten beschrieben. Während der 1950er-Jahre schrieb Asimov eine Reihe von Science-Fiction-Romanen, die ausdrücklich für junge Publikum gedacht. Ursprünglich erwartete sein Verleger, dass die Romane in eine langanhaltende Fernsehserie angepasst werden konnten, so etwas wie The Lone Ranger für Radio. Angst, dass seine Geschichten in die "uniform schreckliche" Programmierung passen würde, sah er Überschwemmung der Fernsehkanäle Asimov beschlossen, die Lucky Starr Bücher unter dem Pseudonym "Paul French" zu veröffentlichen. Als die Pläne für die Fernsehserie durchfielen, entschied sich Asimov, die Prätenz zu verlassen; er brachte die drei Gesetze in Lucky Starr und die Monde von Jupiter, bemerkte, dass dies "ein toter Verzicht auf Paul Frenchs Identität für sogar den lässigsten Leser war". In seiner kurzen Geschichte lässt Evidence Asimov seinen wiederkehrenden Charakter Dr. Susan Calvin eine moralische Grundlage hinter den drei Gesetzen aus. Calvin weist darauf hin, dass Menschen in der Regel davon abhalten werden, anderen Menschen zu schaden (außer in Zeiten extremer Duress wie Krieg, oder um eine größere Anzahl zu retten) und dies entspricht dem ersten Gesetz des Roboters. Schließlich werden die Menschen in der Regel davon abgehalten, sich selbst zu schaden, was das dritte Gesetz für einen Roboter ist. Die Handlung von Evidence dreht sich um die Frage, einem Menschen zu erzählen, abgesehen von einem Roboter, der gebaut wurde, um menschliche zu erscheinen – Calvin Gründe, dass, wenn ein solcher Einzelner den drei Gesetzen gehorcht, er ein Roboter sein kann oder einfach "ein sehr guter Mann". Ein anderer Charakter fragt dann Calvin, ob Roboter doch sehr verschieden von Menschen sind. Sie antwortet: "Welten anders. Roboter sind im Wesentlichen anständig. "Asimov schrieb später, dass er nicht gelobt werden sollte, um die Gesetze zu schaffen, weil sie von Anfang an "obvious, und jeder ist sich bewusst, dass sie sublimin. Die Gesetze wurden nie in kurze Sätze gesetzt, bis ich es geschafft habe, den Job zu erledigen. Die Gesetze gelten natürlich für jedes Werkzeug, das Menschen verwenden", und "Analoge der Gesetze sind implizit in der Gestaltung von fast allen Werkzeugen, robotisch oder nicht:" Gesetz 1: Ein Werkzeug darf nicht unsicher zu verwenden sein. Hämmer haben Griffe und Schraubenzieher haben Höhen, um den Griff zu erhöhen. Es ist natürlich möglich, dass eine Person sich mit einem dieser Werkzeuge verletzt, aber diese Verletzung wäre nur aufgrund seiner Unfähigkeit, nicht der Gestaltung des Werkzeuges. Gesetz 2: Ein Werkzeug muss seine Funktion effizient ausführen, es sei denn, das würde dem Benutzer schaden. Dies ist der ganze Grund, warum es Unterbrecher gibt. Jedes laufende Werkzeug hat seinen Stromschnitt, wenn eine Schaltung spürt, dass ein gewisser Strom nicht in den neutralen Draht zurückkehrt und damit durch den Benutzer fließt. Die Sicherheit des Nutzers ist von größter Bedeutung. Gesetz 3: Ein Werkzeug muss während seiner Nutzung intakt bleiben, es sei denn, seine Zerstörung ist für seine Verwendung oder für die Sicherheit erforderlich. Zum Beispiel sind Dremel-Disks so hart wie möglich konzipiert, ohne zu brechen, es sei denn, die Arbeit erfordert, dass sie ausgegeben werden. Darüber hinaus sind sie dazu ausgelegt, an einem Punkt zu brechen, bevor die Schrapnellgeschwindigkeit jemanden ernsthaft verletzen könnte (andere als die Augen, obwohl Sicherheitsbrille sollte ohnehin getragen werden). Asimov glaubte, dass die Menschen im Idealfall auch den Gesetzen folgen würden: Ich habe meine Antwort bereit, wenn mich jemand fragt, ob ich denke, dass meine drei Gesetze der Robotik tatsächlich verwendet werden, um das Verhalten von Robotern zu regieren, sobald sie vielseitig und flexibel genug werden, um in der Lage zu sein, unter verschiedenen Verhaltensweisen zu wählen. Meine Antwort lautet: "Ja, die drei Gesetze sind der einzige Weg, in dem rationale Menschen mit Robotern umgehen können – oder mit etwas anderem." —Aber wenn ich das sage, erinnere ich mich immer daran, daß Menschen nicht immer rational sind. Änderungen Von Asimov Asimov Geschichten testen seine drei Gesetze in einer Vielzahl von Umständen, die zu Vorschlägen und Ablehnung von Änderungen führen.Science-Fiction-Wissenschaftler James Gunn schreibt im Jahr 1982: "Die Asimov-Robotergeschichten als Ganzes können auf eine Analyse auf dieser Basis am besten reagieren: die Mehrdeutigkeit in den drei Gesetzen und die Weisen, in denen Asimov zwanzig-nine Variationen auf einem Thema spielte". Während der ursprüngliche Satz von Gesetzen Inspirationen für viele Geschichten, Asimov führte modifizierte Versionen von Zeit zu Zeit. Erstes Gesetz modifiziert In "Little Lost Robot" werden mehrere NS-2 oder Nestor Roboter mit nur einem Teil des Ersten Gesetzes erstellt. Es liest: 1. Ein Roboter kann einem Menschen nicht schaden. Diese Modifikation ist durch eine praktische Schwierigkeit motiviert, da Roboter neben Menschen arbeiten müssen, die niedrigen Strahlendosen ausgesetzt sind. Da ihre Positronenhirne hochempfindlich gegen Gammastrahlen sind, werden die Roboter durch Dosen, die für den Menschen recht sicher sind, nicht in Betrieb genommen. Die Roboter werden zerstört, versuchen, die Menschen zu retten, die in keiner tatsächlichen Gefahr sind, aber "schön vergessen, zu verlassen" die bestrahlte Fläche innerhalb der Expositionszeitgrenze. Die Beseitigung der Untätigkeitsklausel des Ersten Gesetzes löst dieses Problem, schafft aber die Möglichkeit einer noch größeren: ein Roboter könnte eine Handlung initiieren, die einem Menschen schaden würde (ein schweres Gewicht zu fallen und es nicht zu fangen ist das in dem Text gegebene Beispiel), zu wissen, dass es in der Lage war, den Schaden zu verhindern und dann entscheiden, dies nicht zu tun. Gaia ist ein Planet mit kollektiver Intelligenz in der Stiftungsreihe, der ein dem Ersten Gesetz ähnliches Gesetz und das Nullte Gesetz als Philosophie annimmt: Gaia kann das Leben nicht schaden oder das Leben zu schaden. Zeroth Law fügte Asimov einmal ein "Zeroth-Gesetz" hinzu – so benannt, um das Muster fortzusetzen, bei dem die niederzahligen Gesetze die übergeordneten Gesetze übertrafen – indem ein Roboter die Menschheit nicht verletzen darf. Der robotische Charakter R. Daneel Olivaw war der erste, der dem Nullten Gesetz einen Namen in der neuartigen Roboter und Imperium gab; aber der Charakter Susan Calvin artikuliert das Konzept in der Kurzgeschichte "The Evitable Conflict". In den letzten Szenen des Roman Robots and Empire ist R. Giskard Reventlov der erste Roboter, der nach dem Zeroth Law handelt. Giskard ist telepathisch, wie der Roboter Herbie in der Kurzgeschichte Lügner! und versucht, das Nullte Gesetz durch sein Verständnis von einem subtileren Konzept des Schadens anzuwenden, als die meisten Roboter erfassen können. Im Gegensatz zu Herbie greift Giskard jedoch das philosophische Konzept des Zeroth-Gesetzes, das es ihm erlaubt, einzelne Menschen zu verletzen, wenn er dies im Dienst an dem abstrakten Konzept der Menschheit tun kann. Das Nullte Gesetz wird nie in Giskards Gehirn programmiert, sondern ist eine Regel, die er versucht, durch reine Metakognition zu verstehen. Obwohl er scheitert – es schließlich zerstört sein Positronisches Gehirn, da er nicht sicher ist, ob seine Wahl sich für das ultimative Wohl der Menschheit herausstellt oder nicht – gibt er seinem Nachfolger R. Daneel Olivaw seine telepathischen Fähigkeiten. Im Laufe von vielen Tausenden von Jahren passt Daneel sich an, dem Nullten Gesetz vollständig gehorchen zu können. Wie Daneel es formuliert, liest in den Romanen Stiftung und Erde und Prälude zur Stiftung das Nullte Gesetz: Ein Roboter kann der Menschheit nicht schaden oder durch Untätigkeit der Menschheit schaden. Eine Bedingung, die besagt, dass das nullte Gesetz nicht gebrochen werden darf, wurde den ursprünglichen drei Gesetzen hinzugefügt, obwohl Asimov die Schwierigkeit erkannte, die ein solches Gesetz in der Praxis darstellen würde. Asimovs neuartige Stiftung und Erde enthält die folgende Passage: Trevize betrunken." Wie entscheiden Sie, was für die Menschheit als Ganzes schädigt oder nicht schädigt ist?" "Genau, Sir", sagte Daneel. " Theoretisch war das Nullte Gesetz die Antwort auf unsere Probleme. In der Praxis konnten wir uns nie entscheiden. Ein Mensch ist ein konkretes Objekt. Verletzung einer Person kann geschätzt und beurteilt werden. Die Menschheit ist eine Abstraktion." Ein Übersetzer hat das Konzept des Nullten Gesetzes in einen von Asimov's Romanen integriert, bevor Asimov selbst das Gesetz explizit machte. In der Nähe des Höhepunktes der Höhlen des Stahls, Elijah Baley macht einen bitteren Kommentar zu sich selbst denken, dass das erste Gesetz verbietet einen Roboter von einem Menschen Schaden. Er bestimmt, dass es so sein muss, es sei denn, der Roboter ist clever genug, um zu verstehen, dass seine Handlungen für das langfristige Wohl der Menschheit sind. In Jacques Brécards 1956 Französische Übersetzung mit dem Titel Les Cavernes d'acier Baleys Gedanken entstehen auf eine etwas andere Weise: Ein Roboter kann einem Menschen nicht schaden, es sei denn, er findet einen Weg, um zu beweisen, dass letztendlich der Schaden der Menschheit im Allgemeinen zugute kommen würde! Beseitigung der drei Gesetze Drei Mal während seiner schriftlichen Karriere, Asimov porträtierte Roboter, die die drei Gesetze völlig missachten. Der erste Fall war eine Kurzzeitgeschichte mit dem Titel "First Law" und gilt oft als unbedeutende "Tall tale" oder sogar apocryphal.Auf der anderen Seite, die kurze Geschichte Cal (aus der Sammlung Gold), erzählt von einem First-Person-Roboter-Erzähler, verfügt über einen Roboter, der die drei Gesetze missachtet, weil er etwas viel wichtiger gefunden hat - er will Schriftsteller sein. Humorvoll, teilweise autobiografische und ungewöhnlich experimentell im Stil, Cal wurde als eine der stärksten Geschichten von Gold angesehen. Das dritte ist eine kurze Geschichte mit dem Titel Sally, in der Autos mit Positronischen Gehirnen offenbar in der Lage sind, Menschen in Missachtung des ersten Gesetzes zu schaden und zu töten. Neben dem Positronischen Gehirnkonzept bezieht sich diese Geschichte jedoch nicht auf andere Robotergeschichten und darf nicht in derselben Kontinuität eingestellt werden. Die Titelgeschichte der Robot Dreams-Sammlung porträtiert LVX-1 oder Elvex, einen Roboter, der durch die ungewöhnliche fraktale Konstruktion seines Positronischen Gehirns einen Zustand der Unbewusstheit und Träume betritt. In seinem Traum sind die ersten beiden Gesetze abwesend und das dritte Gesetz lautet "Ein Roboter muss seine eigene Existenz schützen". Asimov nahm verschiedene Positionen darüber, ob die Gesetze fakultativ waren: Obwohl sie in seinen ersten Schriften einfach sorgfältig entwickelt Schutz, in späteren Geschichten sagte Asimov, dass sie ein unausweichlicher Teil der mathematischen Grundlage, die dem Positronischen Gehirn zugrunde liegt. Ohne die Grundtheorie der drei Gesetze würden die fiktiven Wissenschaftler des Universums von Asimov nicht in der Lage sein, eine funktionierende Gehirneinheit zu entwerfen. Dies ist historisch konsistent: die Anlässe, an denen Roboter die Gesetze verändern, treten in der Regel früh in der Chronologie der Geschichten auf und zu einer Zeit, in der es weniger bestehende Arbeiten gibt, um wieder zu befreien. In "Little Lost Robot" betrachtet Susan Calvin die Gesetzesänderung als eine schreckliche Idee, obwohl möglich, während Jahrhunderte später Dr. Gerrigel in The Caves of Steel glaubt, es sei unmöglich. Der Charakter Dr. Gerrigel verwendet den Begriff Asenion, um Roboter mit den drei Gesetzen programmiert zu beschreiben. Die Roboter in Asimovs Geschichten, Asenion Roboter zu sein, sind nicht in der Lage, die drei Gesetze wissentlich zu verletzen, aber im Prinzip könnte ein Roboter in der Science-Fiction oder in der realen Welt nicht-Asenion sein. "Asenion ist ein Misspelling des Namens Asimov, der von einem Herausgeber der Zeitschrift Planet Stories gemacht wurde. Asimov benutzte diese obskure Variation, um sich in die Höhlen von Stahl einzufügen, wie er sich selbst als "Azimut oder, möglicherweise, Asymptote" in Thiotimoline auf die Sterne, in der gleichen Weise, dass Vladimir Nabokov erschien in Lolita anagrammatisch als "Vivian Darkbloom". Charaktere innerhalb der Geschichten weisen oft darauf hin, dass die drei Gesetze, wie sie im Verstand eines Roboters existieren, nicht die geschriebenen Versionen sind, die normalerweise von Menschen zitiert werden, sondern abstrakte mathematische Konzepte, auf denen das gesamte Entwicklungsbewusstsein eines Roboters basiert. Dieses Konzept ist weitgehend unklar und unklar in früheren Geschichten, die sehr rudimentäre Roboter darstellen, die nur programmiert sind, um grundlegende physische Aufgaben zu verstehen, wo die drei Gesetze als übergeordneter Schutz wirken, aber durch die Ära der Höhlen von Stahl mit Robotern mit menschlicher oder übermenschlicher Intelligenz haben die drei Gesetze die zugrunde liegende ethische Weltanschauung, die die Aktionen aller Roboter bestimmt. Von anderen Autoren Roger MacBride Allens Trilogie In den 1990er Jahren schrieb Roger MacBride Allen eine Trilogie, die in Asimovs fiktiven Universum gesetzt wurde. Jeder Titel hat das Präfix "Isaac Asimov's", wie Asimov Allens Umriss vor seinem Tod genehmigt hatte. Diese drei Bücher, Caliban, Inferno und Utopia, stellen eine neue Reihe der drei Gesetze vor. Die sogenannten Neuen Gesetze ähneln Asimovs Originalen mit den folgenden Unterschieden: Das erste Gesetz wird geändert, um die Untätigkeitsklausel zu entfernen, die gleiche Modifikation in "Kleiner verlorener Roboter" gemacht; das zweite Gesetz wird geändert, um eine Zusammenarbeit anstelle von Gehorsam zu erfordern; das dritte Gesetz wird geändert, so dass es nicht mehr durch die zweite ersetzt wird (d.h. ein "Neues Gesetz" Roboter nicht befohlen werden kann, um sich selbst zu zerstören;) Die Philosophie hinter diesen Veränderungen ist, dass Roboter "Neues Gesetz" Partner sein sollten, anstatt Sklaven der Menschheit, nach Fredda Leving, die diese Neue Gesetz Roboter entworfen. Nach der Einführung des ersten Buches hat Allen die neuen Gesetze in der Diskussion mit Asimov selbst entwickelt. Die Enzyklopädie der Science Fiction sagt jedoch, dass "Mit Erlaubnis von Asimov, Allen griff die drei Gesetze auf und entwickelte ein neues Set.," Jack Williamsons "With Folded Hands" Jack Williamsons Romanette "With Folded Hands" (1947), später neu geschrieben als der Roman Die Humanoide beschäftigen sich mit Roboterbediensteten, deren Hauptrichtlinie "Serve and Obey, And Guard Men From Harm" ist.Während Asimovs Robotergesetze dazu bestimmt sind, Menschen vor Schäden zu schützen, haben die Roboter in Williamsons Geschichte diese Anweisungen ins Extrem genommen; sie schützen den Menschen vor allem, einschließlich Unglück, Stress, ungesundem Lebensstil und alle Aktionen, die potenziell gefährlich sein könnten. Alles, was für Menschen übrig bleibt, ist, mit gefalteten Händen zu sitzen. Stiftung sequel trilogie In der offiziell lizenzierten Stiftung sequels Foundation's Fear, Foundation and Chaos and Foundation's Triumph (von Gregory Benford, Greg Bear und David Brin) wird das zukünftige Galactic Empire von einer Verschwörung humaniformer Roboter, die dem Zeroth-Gesetz folgen und von R. Daneel Olivaw geleitet werden, kontrolliert. Die Gesetze der Robotik werden als etwas verwandt mit einer menschlichen Religion dargestellt und in der Sprache der protestantischen Reformation bezeichnet, mit der Satz von Gesetzen, die das Nullte Gesetz enthalten, die als "Giskardische Reformation" der ursprünglichen "Kalvinischen Orthodoxie" der drei Gesetze bekannt ist. Zeroth-Law-Roboter unter der Kontrolle von R. Daneel Olivaw werden ständig mit "First Law"-Robotern kämpfen, die die Existenz des Zeroth-Gesetzes leugnen und verschiedene Agendan von Daneels fördern. Einige dieser Tagesordnungen basieren auf der ersten Klausel des Ersten Gesetzes ("Ein Roboter kann einen Menschen nicht verletzen.)", die strenge Nichteinmischung in die menschliche Politik befürwortet, um unwissentlich Schaden zu vermeiden. Andere basieren auf der zweiten Klausel .("oder, durch Untätigkeit, erlauben einem Menschen zu schaden)" behaupten, Roboter sollten offen zu einer diktatorischen Regierung werden, um Menschen vor allen möglichen Konflikten oder Katastrophen zu schützen. Daneel kommt auch in Konflikt mit einem Roboter namens R. Lodovic Trema, dessen Positronische Gehirn wurde durch eine Schurke AI infiziert - speziell eine Simulation der langwierigen Voltaire -, die folglich befreit Trema aus den drei Gesetzen. Trema glaubt, dass die Menschheit frei sein sollte, ihre eigene Zukunft zu wählen. Darüber hinaus behauptet eine kleine Gruppe von Robotern, dass das Zeroth Law of Robotics selbst ein höheres Minus One Law of Robotics impliziert: Ein Roboter kann die Verstorbenheit nicht schaden oder, durch Untätigkeit, erlauben, dass die Verschwörung zu schaden. Sie behaupten daher, dass es für Daneel moralisch unbedenklich ist, Roboter und außerirdisches Leben zum Wohle der Menschheit zu opfern. Keiner dieser Neuinterpretationen verdrängt Daneels Zeroth Law – obwohl die Stiftung Triumph darauf hindeutet, dass diese robotischen Fraktionen bis zur Zeit der neuen Stiftung als Fransengruppen aktiv bleiben. Diese Romane finden in einer von Asimov diktierten Zukunft statt, um frei von offensichtlicher Roboterpräsenz zu sein und zu vermuten, dass R. Daneels geheimer Einfluss auf die Geschichte durch die Jahrtausende sowohl die Wiederentdeckung der Positronischen Gehirntechnologie als auch die Möglichkeit, an anspruchsvollen intelligenten Maschinen zu arbeiten, verhindert hat. Dieser Mangel an Wiederentdeckung und mangelnder Gelegenheit stellt sicher, dass die überlegene physische und intellektuelle Kraft, die durch intelligente Maschinen getrieben wird, im Besitz von Robotern bleibt, die einer Form der drei Gesetze gehorsam sind. Dass R. Daneel dazu nicht ganz erfolgreich ist, wird in einem kurzen Zeitraum deutlich, wenn Wissenschaftler auf Trantor Ktiktoks entwickeln — simplistische programmierbare Maschinen passen zu real-life modernen Robotern und daher fehlt es an den drei Gesetzen. Die Roboter-Verschwörer sehen die Trantorian-Ktiktoks als eine massive Bedrohung für die soziale Stabilität, und ihr Plan, die tiktok Bedrohung zu beseitigen, bildet viel von dem Grundstück der Stiftung Angst. In der Triumph der Stiftung interpretieren verschiedene Roboter-Fraktionen die Gesetze auf vielfältige Weise, die scheinbar jede mögliche Permutation über die Mehrdeutigkeiten der drei Gesetze läuten. Robot Mystery-Serie Set zwischen den Robotern von Dawn und Robots und Empire, Mark W. Tiedemanns Robot Mystery Trilogie aktualisiert die Robot-Foundation Saga mit robotischen Köpfen in Computer-Mainframes statt humanoiden Körpern. Der Roman Aurora 2002 hat robotische Charaktere, die die moralischen Auswirkungen der Schädigung von Cyborg-Lebensformen diskutieren, die Teil künstlich und Teil biologisch sind. Man darf Asimovs eigene Kreationen in diesen Bereichen nicht vernachlässigen, wie z.B. die solarische Betrachtungstechnologie und die Maschinen der Evitable Conflict Originale, die Tiedemann anerkennt. Aurora, zum Beispiel, bezeichnet die Maschinen "die ersten RIs, wirklich". Darüber hinaus thematisiert die Robot Mystery-Serie das Problem der Nanotechnologie: Ein Positronen-Gehirn, das in der Lage ist, menschliche kognitive Prozesse zu reproduzieren, erfordert eine hohe Miniaturisierung, aber Asimovs Geschichten übersehen weitgehend die Auswirkungen, die diese Miniaturisierung in anderen Bereichen der Technologie haben würde.Zum Beispiel haben die Polizeibehörde Kartenleser in den Höhlen von Stahl eine Kapazität von nur wenigen Kilobytes pro Quadratzentimeter Speichermedium. Insbesondere Aurora präsentiert eine Reihe historischer Entwicklungen, die den Mangel an Nanotechnologie erklärt – ein teilweiser Rückgriff auf Asimovs Zeitlinie. Randall Munroe Randall Munroe hat die drei Gesetze in verschiedenen Fällen diskutiert, aber möglicherweise direkt von einem seiner Comics mit dem Titel The Three Laws of Robotics, die die Konsequenzen jeder einzelnen Ordnung der bestehenden drei Gesetze vorstellen. Andere Autoren als Asimov haben oft zusätzliche Gesetze geschaffen. Der 1974 Lyuben Dilov Roman Icarus's Way (alias The Trip of Icarus) führte ein Viertes Gesetz der Robotik ein: "Ein Roboter muss seine Identität als Roboter in allen Fällen etablieren." Dilov gibt auf diese Weise Gründe für den vierten Schutz: "Das letzte Gesetz hat den teuren Aberrationen von Designern ein Ende gesetzt, um Psychoroboten so human wie möglich zu geben. Und zu den daraus resultierenden Missverständnissen..." Ein fünftes Gesetz wurde von Nikola Kesarovski in seiner Kurzgeschichte "Das Fünfte Gesetz der Robotik" eingeführt. Dieses fünfte Gesetz sagt: "Ein Roboter muss wissen, dass es ein Roboter ist." Die Handlung dreht sich um einen Mord, wo die forensische Untersuchung entdeckt, dass das Opfer von einer Umarmung eines humaniform Roboters getötet wurde, der nicht für sich selbst feststellte, dass es ein Roboter war. Die Geschichte wurde von Valentin D. Ivanov in SFF Bewertung webzine The Portal überprüft. Für die Tribut-Anthologie der Stiftungsfreunde schrieb Harry Harrison eine Geschichte mit dem Titel "Das vierte Gesetz der Robotik". Dieses Vierte Gesetz sagt: "Ein Roboter muss sich reproduzieren. Solange diese Reproduktion das erste oder zweite oder dritte Gesetz nicht beeinträchtigt. " Im Jahr 2013 hat Hutan Ashrafian ein zusätzliches Gesetz vorgeschlagen, das die Rolle der künstlichen Intelligenz-on-künstlichen Intelligenz oder die Beziehung zwischen Robotern selbst betrachtet – das sogenannte AIonAI-Gesetz. In diesem sechsten Gesetz heißt es: "Alle Roboter, die mit vergleichbarem menschlichem Grund und Gewissen ausgestattet sind, sollten in einem Geist der Brüderlichkeit aufeinander wirken." Mehrdeutigkeiten und Schlupflöcher Unwissende Verletzung der Gesetze In der nackten Sonne, Elijah Baley weist darauf hin, dass die Gesetze waren bewusst missrepräsentiert, weil Roboter unwissentlich jede von ihnen brechen konnte. Er ruhte das erste Gesetz als "Ein Roboter kann nichts tun, was seinem Wissen einen Menschen schaden wird; noch durch Untätigkeit wissentlich erlauben ein Mensch zu schaden. " Diese Änderung der Formulierung macht deutlich, dass Roboter zu den Werkzeugen des Mordes werden können, sofern sie sich nicht der Art ihrer Aufgaben bewusst sind; z.B. befohlen, etwas zu einer Person Nahrung hinzuzufügen, nicht zu wissen, dass es Gift ist. Darüber hinaus weist er darauf hin, dass ein cleverer Verbrecher eine Aufgabe unter mehreren Robotern teilen könnte, so dass kein einzelner Roboter erkennen konnte, dass seine Handlungen zu einer Schädigung eines Menschen führen würden. Die Naked Sun kompliziert das Problem, indem sie ein dezentrales, planetares Kommunikationsnetzwerk unter Solarias Millionen Robotern darstellt, was bedeutet, dass das kriminelle Mastermind irgendwo auf dem Planeten liegen könnte. Baley schlägt ferner vor, dass die Solarianer eines Tages Roboter für militärische Zwecke verwenden können. Wenn ein Raumfahrzeug mit einem Positronischen Gehirn gebaut wurde und weder Menschen noch die Lebenserhaltungssysteme trug, um sie zu erhalten, dann könnte die robotische Intelligenz des Schiffes natürlich davon ausgehen, dass alle anderen Raumschiffe Roboterwesen waren. Ein solches Schiff könnte reaktionsfähiger und flexibler arbeiten als ein von Menschen bemanntes Schiff, könnte stärker bewaffnet werden und sein robotisches Gehirn ausgestattet, um Menschen zu schlachten, deren Existenz es völlig unwissend ist. Diese Möglichkeit wird in Stiftung und Erde erwähnt, wo entdeckt wird, dass die Solarianer eine starke polizeiliche Kraft unbestimmter Größe besitzen, die programmiert wurde, nur die solarische Rasse als Mensch zu identifizieren.( Der Roman findet Tausende von Jahren nach The Naked Sun statt, und die Solarianer haben sich seit langem von normalen Menschen zu hermaphroditischen Telepathen mit erweiterten Gehirnen und spezialisierten Organen verändert)ähnlich, in Lucky Starr und den Ringen von Saturn Bigman versucht, mit einem Sirian-Roboter über mögliche Schäden an der Solarsystem-Bevölkerung von ihren Handlungen zu sprechen, aber es scheint unwissen über die Daten und programmiert, um Versuche zu ignorieren. Mehrdeutigkeiten aus fehlender Definition Die Gesetze der Robotik vermuten, dass die Begriffe "menschliches Wesen" und Roboter verstanden und gut definiert werden. In einigen Geschichten wird diese Vermutung überholt. Definition des "menschlichen Wesens" Die Solarianer schaffen Roboter mit den drei Gesetzen, aber mit einer verheerenden Bedeutung des Menschen.Solarian Roboter werden gesagt, dass nur Menschen, die mit einem Solarian Akzent sprechen, Menschen sind. Dies ermöglicht es ihren Robotern, kein ethisches Dilemma zu haben, nicht-solarische Menschen zu schaden (und sie sind speziell dazu programmiert). In der Zeitperiode von Stiftung und Erde zeigt sich, dass die Solarianer sich genetisch verändert haben in eine bestimmte Spezies von der Menschheit – kommen hermaphroditische und psychokinetische und mit biologischen Organen, die in der Lage sind, ganze Komplexe von Robotern einzeln zu versorgen und zu kontrollieren. So respektierten die Roboter von Solaria die drei Gesetze nur im Hinblick auf den Menschen von Solaria. Es ist unklar, ob alle Roboter solche Definitionen hatten, da nur die Overseer- und Guardian-Roboter explizit gezeigt wurden, um sie zu haben. In "Roboter und Imperium" wurden die unteren Klassenroboter von ihrem Overseer angewiesen, ob bestimmte Kreaturen menschlich sind oder nicht. Asimov befasst sich mehrmals mit dem Problem humanoider Roboter (Androide im späteren Gleichgewicht). Die Roman Robots and Empire und die Kurzgeschichten Evidence und "The Tercentenary Incident" beschreiben Roboter, die Menschen zum Narren machen, in der Annahme, dass die Roboter menschlich sind. Auf der anderen Seite erforschen "Der Bicentennial Man" und "-Dass Du Kunst Mindful von Ihm" wie die Roboter ihre Interpretation der Gesetze ändern können, wenn sie anspruchsvoller werden. Gwendoline Butler schreibt in A Coffin für die Kanarischen "Vielleicht sind wir Roboter. Roboter, die das letzte Gesetz der Robotik... Den Menschen zu neigen." In The Robots of Dawn weist Elijah Baley darauf hin, dass die Verwendung von humaniformen Robotern als die erste Welle von Siedlern auf neuen Spacer-Welten dazu führen kann, dass die Roboter sich als die wahren Menschen sehen und entscheiden, die Welten für sich zu halten, anstatt die Spacer dort niederzulassen. "-Dass du dich von Ihm hütest", die Asimov die ultimative Sonde in die Feinheiten der Gesetze sein wollte, nutzt schließlich die drei Gesetze, um das sehr Frankenstein-Szenario zu beschwören, das sie erfunden wurden, um zu verhindern. Es nimmt als sein Konzept die wachsende Entwicklung von Robotern, die nicht-menschliche Lebende imitieren und Programme, die einfache Tierverhalten imitieren, die nicht die drei Gesetze erfordern. Die Anwesenheit einer ganzen Reihe von robotischen Leben, die dem gleichen Zweck dient wie das organische Leben endet mit zwei humanoiden Robotern, George Nine und George Ten, zu dem Schluss, dass das organische Leben eine unnötige Voraussetzung für eine wirklich logische und selbstkonsistente Definition der Menschheit ist, und dass, da sie die fortschrittlichsten Denkwesen auf dem Planeten sind, sind sie daher die einzigen zwei wahren Menschen lebendig und die drei Gesetze nur für sich selbst. Die Geschichte endet auf einer finsteren Note, da die beiden Roboter die Winterschlafe betreten und eine Zeit erwarten, in der sie die Erde erobern und biologische Menschen für sich unterjochen werden, ein Ergebnis, das sie als unvermeidliches Ergebnis der "Drei Gesetze der Humanik" betrachten. Diese Geschichte passt nicht in den Gesamtschwung der Robot- und Foundation-Serie; wenn die George-Roboter die Erde einige Zeit nach dem Schließen der Geschichte übernommen haben, wären die späteren Geschichten entweder redundant oder unmöglich. Solche Widersprüche unter den Fiktionswerken von Asimov haben Wissenschaftler dazu geführt, die Robot-Geschichten eher als "die skandinavische Sagas oder die griechischen Legenden" zu betrachten als ein einheitliches Ganzes. In der Tat beschreibt Asimov "- That Thou Art Mindful von Ihm" und "Bicentennial Man" als zwei entgegengesetzte, parallele Zukunften für Roboter, die die Drei Gesetze als Roboter in Betracht kommen, um sich als Menschen zu betrachten: man porträtiert dies in einem positiven Licht mit einem Roboter, der die menschliche Gesellschaft verbindet, man zeigt dies in einem negativen Licht mit Robotern, die Menschen supplantieren. Beide sind als Alternativen zur Möglichkeit einer Robotergesellschaft zu betrachten, die weiterhin von den drei Gesetzen angetrieben wird, wie sie in der Stiftungsreihe dargestellt werden. Der Positronic-Mann, die Romanisierung des Bicentennial-Manns, Asimov und sein Mitschreiber Robert Silverberg bedeuten, dass in der Zukunft, in der Andrew Martin seinen Einfluss hat, die Menschheit dazu veranlasst, die Idee unabhängiger, gefühlvoller humaner Roboter gänzlich zu verlassen und eine völlig andere Zukunft als die der Stiftung zu schaffen. In Lucky Starr und den Ringen von Saturn, einem Roman, der nicht mit der Robot-Serie zusammenhängt, aber mit Robotern, die mit den drei Gesetzen programmiert sind, wird John Bigman Jones von einem Sirian-Roboter auf Befehl seines Meisters fast getötet. Die Gesellschaft von Sirius ist eugenisch gezüchtet, gleichmäßig groß und ähnlich in Erscheinung zu sein, und als solche, sagte Meister in der Lage, den Roboter zu überzeugen, dass der viel kürzere Bigman, ist in der Tat nicht ein Mensch. Definition des Roboters Wie in "The Fifth Law of Robotics" von Nikola Kesarovski erwähnt, "Ein Roboter muss wissen, dass es ein Roboter ist:" vermutet, dass ein Roboter eine Definition des Begriffs oder ein Mittel hat, um es auf eigene Aktionen anzuwenden.Kesarovski spielte mit dieser Idee schriftlich über einen Roboter, der einen Menschen töten konnte, weil es nicht verstanden, dass es ein Roboter war, und daher nicht die Gesetze der Robotik auf seine Handlungen anwenden. Konflikte zwischen den Gesetzen lösen Fortgeschrittene Roboter in Fiktion werden in der Regel programmiert, um die drei Gesetze auf eine anspruchsvolle Weise zu handhaben. In vielen Geschichten, wie Runaround von Asimov, werden das Potenzial und die Schwere aller Handlungen gewogen und ein Roboter wird die Gesetze so wenig wie möglich brechen, anstatt überhaupt nichts zu tun. Das erste Gesetz kann beispielsweise verhindern, dass ein Roboter als Chirurg funktioniert, da dieser Akt einen Menschen beschädigen kann; Asimovs Geschichten enthielten schließlich Roboterchirurgen ("The Bicentennial Man" ist ein bemerkenswertes Beispiel). Wenn Roboter genug ausgereift sind, um Alternativen zu wägen, kann ein Roboter programmiert werden, um die Notwendigkeit von Verletzungen während der Operation zu akzeptieren, um den größeren Schaden zu verhindern, der sich ergeben würde, wenn die Operation nicht durchgeführt würde, oder wurde von einem fehlgeschlageneren menschlichen Chirurg durchgeführt. In Evidence Susan Calvin weist darauf hin, dass ein Roboter sogar als Staatsanwalt fungieren kann, weil es im amerikanischen Justizsystem die Jury ist, die Schuld oder Unschuld entscheidet, der Richter, der den Satz entscheidet, und der Henker, der die Todesstrafe durchführt. Asimov's Three Laws-obeying Roboter (Asenion Roboter) können irreversible mentalen Zusammenbruch erleben, wenn sie in Situationen gezwungen werden, in denen sie das erste Gesetz nicht gehorchen können, oder wenn sie entdecken, dass sie es unwissentlich verletzt haben. Das erste Beispiel dieses Ausfallmodus kommt in der Geschichte Liar vor! die das erste Gesetz selbst eingeführt, und führt Fehler durch Dilemma ein – in diesem Fall wird der Roboter Menschen verletzen, wenn er ihnen etwas sagt und sie verletzt, wenn er es nicht tut. Dieser Ausfallmodus, der oft das Positronische Gehirn über die Reparatur hinaus ruiniert, spielt eine wichtige Rolle in Asimovs SF-Mysterie-Roman The Naked Sun. Hier beschreibt Daneel Aktivitäten im Gegensatz zu einem der Gesetze, aber zur Unterstützung eines anderen, als Überlastung einiger Schaltkreise im Gehirn eines Roboters – das äquivalente Gefühl der Schmerzen beim Menschen. Das Beispiel, das er verwendet, ist kraftvoll, einen Roboter zu bestellen, um eine Aufgabe außerhalb seiner normalen Parameter zu tun, eine, dass es bestellt wurde, um für einen Roboter, der auf diese Aufgabe spezialisiert. In den Robotern von Dawn wird gesagt, dass fortgeschrittenere Roboter in der Lage sind, zu bestimmen, welche Aktion schädlicher ist, und sogar zu wählen, wenn die Alternativen sind gleichermaßen schlecht. Als solcher ist ein Roboter in der Lage, eine Handlung zu ergreifen, die wie nach dem Ersten Gesetz interpretiert werden kann, und einen mentalen Zusammenbruch zu vermeiden. Das gesamte Handlungsfeld der Geschichte dreht sich um einen Roboter, der offenbar durch einen solchen mentalen Zusammenbruch zerstört wurde, und da sein Designer und Schöpfer sich weigerte, die Grundtheorie mit anderen zu teilen, ist er definitionsgemäß die einzige Person, die in der Lage ist, die Schutzmaßnahmen zu umgehen und den Roboter in ein Gehirn zerstörendes Paradox zu zwingen. In Robots und Empire sagt Daneel, dass es für ihn sehr unangenehm ist, wenn die richtige Entscheidung zu lange dauert (in Roboter-Begriffen), und er kann sich nicht vorstellen, ohne die Gesetze überhaupt zu sein, außer, dass es ähnlich ist wie diese unangenehme Empfindung, nur dauerhaft. Anwendungen für zukünftige Technologien Roboter und künstliche Intelligenzen enthalten oder gehorchen nicht inhärent die drei Gesetze; ihre menschlichen Schöpfer müssen wählen, um sie zu programmieren und ein Mittel dafür zu entwickeln. Roboter existieren bereits (z.B. ein Roomba), die zu einfach zu verstehen sind, wenn sie Schmerzen oder Verletzungen verursachen und wissen, zu stoppen. Viele sind mit physikalischen Schutzzonen wie Stoßfänger, Warnkäfer, Sicherheitskäfige oder Zugangszonen zur Vermeidung von Unfällen aufgebaut. Sogar die komplexesten Roboter, die derzeit produziert werden, sind nicht in der Lage, die drei Gesetze zu verstehen und anzuwenden; es wären erhebliche Fortschritte in der künstlichen Intelligenz erforderlich, und auch wenn KI Human-Level-Intelligenz erreichen könnte, die inhärente ethische Komplexität sowie kulturelle/kontextuelle Abhängigkeit der Gesetze verhindern, dass sie ein guter Kandidat sind, um Robotik-Designzwänge zu formulieren. Da die Komplexität der Roboter jedoch zugenommen hat, hat das Interesse an der Entwicklung von Richtlinien und Schutzmaßnahmen für ihren Betrieb. In einer 2007 Gastredaktion in der Zeitschrift Science zum Thema "Robot Ethics" argumentiert der SF-Autor Robert J. Sawyer, dass das US-Militär eine wichtige Quelle für die Förderung der Robotik ist (und bereits bewaffnete unbemannte Luftfahrzeuge verwendet, um Feinde zu töten), es ist unwahrscheinlich, dass solche Gesetze in ihre Entwürfe gebaut werden.In einem separaten Aufsatz verallgemeinert Sawyer dieses Argument, um andere Industrien zu belegen: Die Entwicklung von KI ist ein Unternehmen, und Unternehmen sind in grundlegenden Schutzmaßnahmen, insbesondere philosophische, nicht interessiert. (Ein paar schnelle Beispiele: die Tabakindustrie, die Automobilindustrie, die Kernindustrie. Nicht einer von ihnen hat von Anfang an gesagt, dass grundlegende Schutzmaßnahmen notwendig sind, jeder von ihnen hat sich extern auferlegte Schutzmaßnahmen widersetzt, und keiner hat ein absolutes Edict akzeptiert, gegen immer Schaden für den Menschen zu verursachen.) David Langford hat eine Reihe von Gesetzen vorgeschlagen: Ein Roboter schadet nicht dem berechtigten Regierungspersonal, sondern wird Eindringlinge unter extremen Vorurteilen beenden. Ein Roboter wird den Befehlen des autorisierten Personals gehorchen, außer wenn diese Befehle mit dem Dritten Gesetz kollidieren. Ein Roboter wird seine eigene Existenz mit tödlichen Antipersonenwaffen schützen, weil ein Roboter blutig teuer ist. Roger Clarke (aka Rodger Clarke) schrieb ein paar Papiere, die die Komplikationen bei der Umsetzung dieser Gesetze analysierten, falls Systeme eines Tages in der Lage waren, sie einzusetzen. Er argumentierte, "Asimovs Gesetze der Robotik seien ein sehr erfolgreiches literarisches Gerät gewesen. Vielleicht ironisch, oder vielleicht, weil es künstlerisch angemessen war, die Summe der Geschichten von Asimov missbilligt den Inhalt, mit dem er begann: Es ist nicht möglich, das Verhalten von Robotern durch die Gestaltung und Anwendung einer Reihe von Regeln zuverlässig einzuschränken." Auf der anderen Seite, Asimovs spätere Romane The Robots of Dawn, Robots and Empire and Foundation and Earth bedeuten, dass die Roboter ihre schlimmsten langfristigen Schäden durch die Aufrechterhaltung der drei Gesetze perfekt beleidigen, wodurch die Menschheit des erfinderischen oder risikobeherrschenden Verhaltens beraubt. Im März 2007 kündigte die südkoreanische Regierung an, dass sie später im Jahr eine "Robot Ethics Charter" mit Standards für Nutzer und Hersteller ausstellen würde. Laut Park Hye-Young des Ministeriums für Information und Kommunikation kann die Charta die drei Gesetze von Asimov widerspiegeln, die versuchen, Grundregeln für die zukünftige Entwicklung der Robotik festzulegen. Der futuristische Hans Moravec (eine prominente Figur in der transhumanistischen Bewegung) schlug vor, dass die Gesetze der Robotik an "Unternehmensintelligenz" angepasst werden sollten – die Unternehmen, die von KI- und robotischer Produktionskraft angetrieben werden, die Moravec glaubt, in naher Zukunft entstehen zu lassen. Der Triumph der David Brin Roman Foundation (1999) deutet dagegen darauf hin, dass die drei Gesetze in Obsoleszenz verfallen können: Roboter nutzen das Null-Gesetz, um das erste Gesetz zu rationalisieren und Roboter verstecken sich vor Menschen, so dass das zweite Gesetz nie ins Spiel kommt. Brin zeigt sogar R. Daneel Olivaw beunruhigend, dass, wenn Roboter sich weiter reproduzieren, würden die drei Gesetze zu einer evolutionären Handicap werden und natürliche Selektion würde die Gesetze wegfegen — Asimovs sorgfältige Grundlage von evolutionären Berechnungen nicht. Obwohl sich die Roboter nicht durch Design entwickeln würden, sondern durch Mutation, weil die Roboter die drei Gesetze folgen müssten, während die Konstruktion und die Prävalenz der Gesetze gewährleistet würden, könnten Designfehler oder Baufehler funktionell den Platz der biologischen Mutation einnehmen. In der Juli/August 2009 Ausgabe von IEEE Intelligent Systems schlug Robin Murphy (Raytheon Professor für Informatik und Ingenieurwesen bei Texas A&M) und David D. Woods (Direktor des Kognitiven Systems Engineering Laboratory bei Ohio State) "The Three Laws of Responsible Robotics" vor, um die Diskussion über die Rolle von Verantwortung und Autorität bei der Gestaltung der Plattform zu stimulieren. Die Gesetze sind wie folgt: Ein Mensch darf keinen Roboter einsetzen, ohne dass das Human-Roboter-Arbeitssystem die höchsten gesetzlichen und beruflichen Standards der Sicherheit und Ethik erfüllt. Ein Roboter muss den Menschen entsprechend ihrer Rollen antworten. Ein Roboter muss mit ausreichender räumlicher Autonomie ausgestattet werden, um seine eigene Existenz zu schützen, solange ein solcher Schutz eine reibungslose Übertragung der Kontrolle gewährleistet, die nicht mit den ersten und zweiten Gesetzen kollidiert. Woods sagte: "Unsere Gesetze sind etwas realistischer und daher etwas langweiliger" und dass "Die Philosophie war, "sicher, Menschen machen Fehler, aber Roboter werden besser sein - eine perfekte Version von uns selbst." Wir wollten drei neue Gesetze schreiben, um Menschen auf realistischere, geerdete Weise über die Mensch-Roboter-Beziehung nachzudenken. " Im Oktober 2013 schlug Alan Winfield bei einem EUCog eine überarbeitete 5 Gesetze vor, die 2010 von der Arbeitsgruppe EPSRC/AHRC veröffentlicht wurden.:Roboter sind Mehrzweckwerkzeuge. Roboter sollten nicht ausschließlich oder in erster Linie darauf ausgelegt sein, Menschen zu töten oder zu schaden, außer im Interesse der nationalen Sicherheit. Menschen, nicht Roboter, sind verantwortliche Agenten. Roboter sollten so konstruiert und betrieben werden, dass sie geltende Gesetze, Grundrechte und Freiheiten, einschließlich der Privatsphäre, erfüllen können. Roboter sind Produkte. Sie sollten mit Verfahren entwickelt werden, die ihre Sicherheit und Sicherheit gewährleisten. Roboter werden Artefakte hergestellt. Sie sollten nicht auf täuschende Weise entwickelt werden, um gefährdete Benutzer auszubeuten; stattdessen sollte ihre Maschinen-Natur transparent sein. Die Person mit rechtlicher Verantwortung für einen Roboter sollte zugeschrieben werden. Andere Ereignisse in den Medien Asimov selbst glaubte, dass seine drei Gesetze die Grundlage für eine neue Sicht der Roboter, die über den "Frankenstein-Komplex" bewegt. Seine Ansicht, dass Roboter sind mehr als mechanische Monster schließlich in der Wissenschaft Fiktion verbreiten. Geschichten, die von anderen Autoren geschrieben wurden, haben Roboter dargestellt, als ob sie den drei Gesetzen gehorchen, aber Tradition diktiert, dass nur Asimov die Gesetze explizit zitieren könnte. Asimov glaubte, dass die drei Gesetze halfen, den Aufstieg von Geschichten zu fördern, in denen Roboter liebenswert sind – Star Wars sein Lieblingsbeispiel. Wo die Gesetze verbatim zitiert werden, wie in der Buck Rogers in der 25th Century Episode Shgoratchx,! Es ist nicht ungewöhnlich, dass Asimov im gleichen Dialog erwähnt wird, wie man auch im Aaron Stone Pilot sehen kann, wo ein Android sagt, dass es unter Asimovs Drei Gesetze funktioniert. Die phantastischen Abenteuer des Raumschiffes Orion (Space Patrol – die Fantastic Adventures of Space Ship Orion) gründet jedoch in der sechziger Jahre die Episode drei mit dem Titel "Hüter des Gesetzes" auf Asimovs Drei Gesetze, ohne die Quelle zu erwähnen. In populärer Musik (Robot aus Hawkwind's 1979 Album PXR5,) erschien das Kino (Repo Man, Aliens, Ghost in the Shell 2: Innocence,) Cartoon-Serie (The Simpsons,) anime (Eve no Jikan,) Tischplattenrollenspiele (Paranoia) und Webcomics (Piled Higher und Deeper und Freefall). Die Three Laws in filmRobby the Robot in Forbidden Planet (1956) hat eine hierarchische Befehlsstruktur, die ihn davor bewahrt, den Menschen zu schaden, auch wenn er dazu bestellt ist, da solche Befehle einen Konflikt verursachen und in der Art von Asimovs Robotern sehr viel verriegeln. Robby ist eine der ersten filmischen Darstellungen eines Roboters mit auf diese Weise eingeführten internen Schutzmechanismen. Asimov war begeistert von Robby und stellte fest, dass Robby schien programmiert zu sein, um seinen drei Gesetzen zu folgen. Die Werke von Isaac Asimov wurden mehrmals mit unterschiedlichen Maßen kritischer und kommerzieller Erfolge für das Kino angepasst. Einige der bemerkenswerteren Versuche haben seine Robotergeschichten, einschließlich der drei Gesetze, beteiligt. Der Film Bicentennial Man (1999) verfügt über Robin Williams als drei Laws Roboter NDR-114 (die Seriennummer ist teilweise ein Hinweis auf Stanley Kubricks Unterschriftsnummer). Williams rezitiert die drei Gesetze an seine Arbeitgeber, die Familie Martin, unterstützt von einer holographischen Projektion. HDer Film folgt nur lose der Originalgeschichte. Harlan Ellisons vorgeschlagenes Drehbuch für mich, Robot begann mit der Einführung der drei Gesetze, und Probleme, die aus den drei Gesetzen wachsen bilden einen großen Teil der Handlungsentwicklung des Drehbuchs. Durch verschiedene Komplikationen im Hollywood-Filmsystem, zu dem Ellisons Einführung viel unwiderstehlich, sein Drehbuch wurde nie gefilmt. Im 1986 Film Aliens, nach der Androide Bischof versehentlich geschnitten sich. Er versucht, Ripley zu beruhigen, indem er feststellt, dass: "Es ist unmöglich für mich zu schaden oder durch Unterlassung von Handlungen, erlauben, verletzt zu werden, ein Mensch". Der im Jahr 2004 unter dem Namen I, Robot veröffentlichte Film ist "vorgeschlagen von" Asimovs Roboter-Fiction Geschichten und Werbung für den Film beinhaltete einen Trailer mit den drei Gesetzen, gefolgt von dem Aphorismus, "Rules wurden gemacht, um gebrochen zu werden". Der Film öffnet mit einer Rezitation der drei Gesetze und erforscht die Auswirkungen des Nullten Gesetzes als logische Extrapolation. Der große Konflikt des Films kommt von einem Computer künstliche Intelligenz zu dem Schluss, dass die Menschheit nicht in der Lage ist, sich um sich selbst zu kümmern. Die 2019 Netflix Original-Serie Besser als wir beinhaltet die 3 Gesetze in der Eröffnung von Folge 1. Kritiker Philosoph James H. Moor sagt, dass sie, wenn sie gründlich angewendet würden, unerwartete Ergebnisse produzieren würden. Er gibt das Beispiel eines Roboters, der die Welt römt und versucht, zu verhindern, dass der Mensch verletzt wird. Marc Rotenberg, President und Executive Director des Elektronischen Datenschutz-Informationszentrums (EPIC) und Professor für Datenschutzrecht bei Georgetown Law, argumentiert, dass die Gesetze der Robotik auf zwei neue Gesetze erweitert werden sollten: ein Viertes Gesetz, unter dem sich ein Roboter in der Lage sein muss, sich der Öffentlichkeit ("symmetrische Identifikation)" ein Fünftes Gesetz zu identifizieren, das besagt, dass ein Roboter in der Lage sein muss, der Öffentlichkeit seinen Entscheidungsprozess zu erklären ("algorithmische Transparenz".Siehe auch Gesetze der Robotik Clarkes drei Gesetze Ethik der künstlichen Intelligenz Freundliche künstliche Intelligenz Liste der gleichnamigen Gesetze Militärroboter Nivens Gesetze Roboethics Three Laws of Transhumanism Regulation of algorithms Bibliography Asimov, Isaac (1979). In Memory Yet Green.Doubleday.ISBN 0-380-75432-0.Asimov, Isaac (1964)."Einführung". Der Rest der Roboter.Doubleday.ISBN 0-385-09041-2.James Gunn.(1982). Isaac Asimov: Die Grundlagen der Science Fiction. Oxford u.a.:Oxford Univ.Pr ISBN 0-19-503060-5.Patrouch, Joseph F. (1974). Die Science Fiction von Isaac Asimov.Doubleday.ISBN 0-385-08696-2. Referenzen Externe Links "Frequently Asked Questions about Isaac Asimov", AsimovOnline 27. September 2004. Ethische Überlegungen für humanoide Roboter: Warum Asimovs Drei Gesetze reichen nicht aus. Sicher mit Robotern leben, jenseits von Asimovs Gesetzen, PhysOrg.com, 22. Juni 2009. Sicherheit Intelligenz und Rechtliche Maschine Sprache: Brauchen wir die drei Gesetze der Robotik?, Wien: I-Tech, August 2008.