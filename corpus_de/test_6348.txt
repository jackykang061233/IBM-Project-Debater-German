Das chinesische Raumargument hält fest, dass ein digitaler Computer, der ein Programm durchführt, keinen Verstand, Verständnis oder Bewusstsein haben kann, unabhängig davon, wie intelligent oder menschlich das Programm den Computer verhalten kann. Das Argument wurde von dem Philosophen John Searle in seiner Arbeit "Minds, Brains, and Programs", veröffentlicht in Behavioral und Brain Sciences im Jahr 1980. Ähnliche Argumente wurden von Gottfried Leibniz (1714,) Anatoly Dneprov (1961,) Lawrence Davis (1974) und Ned Block (1978) präsentiert. Searles Version ist seit den Jahren weit verbreitet. Das Herzstück von Searles Argument ist ein Gedankenexperiment, das als chinesisches Zimmer bekannt ist. Das Argument richtet sich gegen die philosophischen Positionen von Funktionalismus und Rechenschaft, die halten, dass der Geist als Informationsverarbeitungssystem angesehen werden kann, das auf formalen Symbolen arbeitet, und dass die Simulation eines gegebenen Geisteszustandes für seine Anwesenheit ausreicht. Konkret soll das Argument eine Position widerlegen, die Searle stark KI nennt: "Der entsprechend programmierte Computer mit den richtigen Eingängen und Ausgängen würde dadurch einen Geist in genau dem gleichen Sinne haben, wie Menschen Geist haben. " Obwohl es ursprünglich in Reaktion auf die Aussagen der künstlichen Intelligenz (KI) Forscher präsentiert wurde, ist es kein Argument gegen die Ziele der Mainstream-KI-Forschung, weil es keine Grenze in der Menge des intelligenten Verhaltens zeigt, das eine Maschine anzeigen kann. Das Argument gilt nur für digitale Computer mit Programmen und gilt nicht für Maschinen im Allgemeinen. Der chinesische Raum dachte Experiment Searles Gedankenexperiment beginnt mit dieser hypothetischen Prämisse: vermuten, dass künstliche Intelligenz Forschung gelungen ist, einen Computer zu konstruieren, der sich verhält, als ob er Chinesisch versteht. Es nimmt chinesische Zeichen als Eingabe und produziert durch die folgenden Anweisungen eines Computerprogramms andere chinesische Zeichen, die es als Ausgabe präsentiert. Angenommen, sagt Searle, dass dieser Computer seine Aufgabe so überzeugend erfüllt, dass er den Turing-Test bequem durchläuft: es überzeugt einen menschlichen chinesischen Lautsprecher, dass das Programm selbst ein live-chinesischer Lautsprecher ist. Für alle Fragen, die die Person stellt, stellt sie angemessene Antworten dar, so dass jeder chinesische Sprecher davon überzeugt wäre, dass er mit einem anderen chinesischsprachigen Menschen spricht. Die Frage, die Searle beantworten möchte, ist dies: versteht die Maschine buchstäblich Chinesisch? Oder ist es nur die Fähigkeit, Chinesisch zu verstehen? Searle nennt die erste Position "starke KI" und letztere "schwache KI". Searle nimmt dann an, dass er in einem geschlossenen Raum ist und ein Buch mit einer englischen Version des Computerprogramms hat, zusammen mit ausreichenden Papieren, Bleistiften, Radierern und Einlegeschränken. Searle könnte chinesische Zeichen durch einen Schlitz in der Tür erhalten, sie nach den Anweisungen des Programms bearbeiten und chinesische Zeichen als Ausgabe produzieren. Wenn der Computer auf diese Weise den Turing-Test bestanden hatte, folgt es, sagt Searle, dass er dies auch tun würde, einfach durch das Programm manuell laufen. Searle behauptet, dass es keinen wesentlichen Unterschied zwischen den Rollen des Computers und sich selbst im Experiment gibt. Jeder folgt einfach einem Programm, Schritt für Schritt, ein Verhalten zu erzeugen, das dann vom Benutzer als intelligentes Gespräch interpretiert wird. Searle selbst wäre jedoch nicht in der Lage, das Gespräch zu verstehen.("Ich spreche kein Wort von Chinesen", betont er.) Daher argumentiert er, es folgt, dass der Computer nicht in der Lage sein würde, das Gespräch auch zu verstehen. Searle argumentiert, dass wir ohne Verständnis (oder Intentionalität) nicht beschreiben können, was die Maschine als Denken tut und, da sie nicht denkt, es hat keinen Geist in irgendetwas wie den normalen Sinn des Wortes. Deshalb kommt er zu dem Schluss, dass die "starke AI" Hypothese falsch ist. Geschichte Gottfried Leibniz machte ein ähnliches Argument 1714 gegen Mechanismus (die Position, dass der Geist eine Maschine und nichts mehr ist). Leibniz nutzte das Gedankenexperiment, das Gehirn zu erweitern, bis es die Größe einer Mühle war. Leibniz fand es schwierig, sich vorzustellen, dass ein wahrnehmbarer Geist nur mit mechanischen Prozessen aufgebaut werden konnte. Russische Cybernetik Anatoly Dneprov machte 1961 ein im Wesentlichen identisches Argument in Form der Kurzgeschichte "Das Spiel". In ihm fungiert ein Stadion von Menschen als Schalter und Speicherzellen, die ein Programm implementieren, um einen Satz von Portugiesisch zu übersetzen, eine Sprache, die keiner von ihnen weiß. Das Spiel wurde von einem "Professor Zarubin" organisiert, um die Frage zu beantworten "Kann mathematische Maschinen denken?" Dneprov schreibt über Zarubin: "Der einzige Weg, um zu beweisen, dass Maschinen denken können, ist, sich in eine Maschine zu verwandeln und Ihren Denkprozess zu untersuchen."und er schließt, wie Searle es tut, "Wir haben bewiesen, dass selbst die perfektste Simulation des maschinellen Denkens nicht der Denkprozess selbst ist." 1974 stellte sich Lawrence Davis vor, das Gehirn mit Telefonleitungen und Büros zu duplizieren, die von Menschen besetzt wurden, und 1978 stellte Ned Block die gesamte Bevölkerung Chinas vor, die an einer solchen Gehirnsimulation beteiligt war. Dieses Gedankenexperiment nennt man das China Gehirn, auch die "chinesische Nation" oder das "chinesische Gym". Searle's Version erschien in seiner 1980er Zeitung "Minds, Brains, and Programs", veröffentlicht in Behavioral und Brain Sciences. Es wurde schließlich der "einflussreichste Zielartikel" der Zeitschrift, der in den folgenden Jahrzehnten eine enorme Anzahl von Kommentaren und Antworten hervorbrachte, und Searle hat das Argument in vielen Zeitungen, populären Artikeln und Büchern weiter verteidigt und verfeinert. David Cole schreibt, dass "das chinesische Raumargument wahrscheinlich das am weitesten diskutierte philosophische Argument in der kognitiven Wissenschaft war, in den letzten 25 Jahren zu erscheinen". Die meisten Diskussionen bestehen aus Versuchen, es zu widerlegen. "Die überwältigende Mehrheit", stellt BBS-Editor Stevan Harnad fest, "denk doch, dass das chinesische Zimmer Argument falsch ist". Das schiere Volumen der Literatur, die um sie aufgewachsen ist, inspirierte Pat Hayes zu kommentieren, dass der Bereich der kognitiven Wissenschaft als "das laufende Forschungsprogramm der Darstellung von Searles chinesischem Raum Argument als falsch" neu definiert werden sollte. Searles Argument wurde "ein Klassiker in der kognitiven Wissenschaft", so Harnad. Varol Akman stimmt zu und hat das Originalpapier als "ein Exemplar der philosophischen Klarheit und Reinheit" beschrieben. Philosophie Obwohl das chinesische Raumargument ursprünglich in Reaktion auf die Aussagen von künstlichen Intelligenz-Forschern präsentiert wurde, sind Philosophen gekommen, es als einen wichtigen Teil der Philosophie des Geistes zu betrachten. Es ist eine Herausforderung für den Funktionsismus und die rechnerische Theorie des Geistes, und ist mit solchen Fragen wie dem Geist-Körper-Problem, dem Problem anderer Geister, dem Symbol-Erde-Problem und dem harten Problem des Bewusstseins verbunden. Strong AI Searle identifizierte eine philosophische Position, die er "starke KI" nennt: Der entsprechend programmierte Computer mit den richtigen Eingängen und Ausgängen würde dadurch einen Geist in genau dem gleichen Sinne haben, dass Menschen Geist haben. Die Definition hängt von der Unterscheidung zwischen einem Geist zu simulieren und tatsächlich einen Geist zu haben. Searle schreibt, dass "nach der starken KI die richtige Simulation wirklich ein Geist ist. Laut Weak AI ist die richtige Simulation ein Modell des Geistes. " Der Anspruch ist implizit in einigen der Aussagen der frühen KI-Forscher und Analysten. Zum Beispiel erklärte KI-Gründer Herbert A. Simon 1955: "Es gibt jetzt in den Weltmaschinen, die denken, lernen und schaffen". Simon, zusammen mit Allen Newell und Cliff Shaw, nach Abschluss des ersten AI-Programms, behauptete der Logic Theorist, dass sie "das ehrwürdige Geist-Körper-Problem gelöst hatte, zu erklären, wie ein System aus Materie kann die Eigenschaften des Verstandes haben. " John Haugeland schrieb, dass "AI will nur den echten Artikel: Maschinen mit Geist, im vollen und wörtlichen Sinne. Dies ist keine Science-Fiction, sondern eine reale Wissenschaft, die auf einer theoretischen Vorstellung so tief basiert, wie sie es wagt: nämlich, wir sind, an der Wurzel, Computer selbst. " Searle beschreibt auch die folgenden Ansprüche an Befürworter von starker KI: KI-Systeme können verwendet werden, um den Verstand zu erklären; Die Studie des Gehirns ist für die Untersuchung des Geistes irrelevant; und der Turing-Test ist ausreichend, um die Existenz von Geisteszuständen zu etablieren. Starke KI als Rechenschaft oder Funktionsismus In neueren Präsentationen des chinesischen Raumarguments hat Searle "starke KI" als "Computerfunktionalismus" identifiziert (ein Begriff, den er Daniel Dennett zugeschrieben hat). Funktionalismus ist eine Position in der modernen Geistesphilosophie, die hält, dass wir geistige Phänomene (wie Überzeugungen, Wünsche und Wahrnehmungen) definieren können, indem wir ihre Funktionen in Bezug auf einander und auf die Außenwelt beschreiben. Da ein Computerprogramm funktionsbezogene Beziehungen als Beziehungen zwischen Symbolen genau darstellen kann, kann ein Computer geistige Phänomene haben, wenn es das richtige Programm betreibt, entsprechend der Funktionalität. Stevan Harnad argumentiert, dass Searles Darstellungen von starker KI als "erkennbare Tenets von Rechenschaftspflicht, eine Position (im Gegensatz zu "starker KI"), die tatsächlich von vielen Denkern gehalten wird, und damit eine refuting wert." Der Computationalismus ist die Position in der Philosophie des Geistes, die argumentiert, dass der Geist als Informationsverarbeitungssystem genau beschrieben werden kann. Jeder der folgenden, nach Harnad, ist ein Zehntel der Rechenschaft: Mentalzustände sind rechnerische Zustände (was der Grund ist, warum Computer mentale Zustände haben können und helfen, den Verstand zu erklären); Computational Zustände sind implementierungsunabhängig - das heißt, es ist die Software, die den rechnerischen Zustand bestimmt, nicht die Hardware (was das Gehirn ist, Hardware, ist irrelevant); und dass Da die Implementierung unwichtig ist, sind die einzigen empirischen Daten, die darauf zählen, wie das System funktioniert; daher der Turing-Test ist definitiv. Starke KI vs. biologischer Naturismus Searle hält eine philosophische Position, die er "biologischer Naturismus" nennt: dass Bewusstsein und Verständnis bestimmte biologische Maschinen erfordern, die im Gehirn gefunden werden. Er schreibt "Hirn verursachen Geister" und dass "wirkliche menschliche mentale Phänomene" von tatsächlichen physikalisch-chemischen Eigenschaften des menschlichen Gehirns abhängig sind". Searle argumentiert, dass diese Maschinerie (die Neurowissenschaften als die "Naturkorrelate des Bewusstseins" bekannt ist) einige ursächliche Kräfte haben muss, die die menschliche Erfahrung des Bewusstseins ermöglichen. Searles Glaube an die Existenz dieser Kräfte wurde kritisiert. Searle stimmt nicht mit dem Begriff, dass Maschinen Bewusstsein und Verständnis haben können, denn, wie er schreibt, "wir sind genau solche Maschinen". Searle hält, dass das Gehirn in der Tat eine Maschine ist, aber dass das Gehirn gibt Bewusstsein und Verständnis mit Maschinen, die nicht-computational. Wenn Neurowissenschaften in der Lage ist, den mechanischen Prozess zu isolieren, der das Bewusstsein verursacht, dann gewährt Searle, dass es möglich sein kann, Maschinen zu schaffen, die Bewusstsein und Verständnis haben. Ohne die speziellen Maschinen, die erforderlich sind, glaubt Searle jedoch nicht, dass Bewusstsein auftreten kann. Biologischer Naturismus bedeutet, dass man nicht bestimmen kann, ob die Erfahrung des Bewusstseins nur durch die Prüfung, wie ein System funktioniert, weil die spezifische Maschinerie des Gehirns wesentlich ist. So ist der biologische Naturalismus direkt gegen Verhaltenismus und Funktionismus (einschließlich "Computerfunktionalismus" oder "starke KI"). Der biologische Naturalismus ist ähnlich wie die Identitätstheorie (die Position, dass mentale Zustände "identisch" oder "zusammengefasst" neurologische Ereignisse sind); Searle hat jedoch spezifische technische Einwände gegen Identitätstheorie. Searle's biologischer Naturismus und starke KI sind beide gegen den kartesischen Dualismus, die klassische Idee, dass das Gehirn und Geist aus verschiedenen Substanzen hergestellt sind". In der Tat beschuldigt Searle starke KI des Dualismus und schreibt, dass "starke KI macht nur Sinn angesichts der dualistischen Annahme, dass, wo der Geist betroffen ist, das Gehirn keine Rolle spielt." Die ursprüngliche Präsentation von Consciousness Searle betonte das Verständnis" – d.h. mentale Zustände mit dem, was Philosophen Intentionalität nennen" – und sprach nicht direkt andere eng miteinander verbundene Ideen wie Bewusstsein an." In neueren Präsentationen Searle hat das Bewusstsein als das eigentliche Ziel des Arguments aufgenommen. Computational Modelle des Bewusstseins reichen für sich selbst nicht aus. Das rechnerische Modell für das Bewusstsein steht in gleicher Weise dem Bewusstsein, dass das rechnerische Modell von irgendetwas dem Modell der Domäne entspricht. Niemand vermutet, dass das rechnerische Modell der Regenstürme in London uns alle nass lässt. Aber sie machen den Fehler, zu beschwören, dass das Rechenmodell des Bewusstseins irgendwie bewusst ist. Es ist in beiden Fällen der gleiche Fehler. David Chalmers schreibt: "Es ist ziemlich klar, dass das Bewusstsein an der Wurzel der Materie liegt" des chinesischen Raumes. Colin McGinn argumentiert, dass der chinesische Raum starke Beweise dafür liefert, dass das harte Problem des Bewusstseins grundsätzlich unlöslich ist. Das Argument, um klar zu sein, geht nicht darum, ob eine Maschine bewusst sein kann, sondern darüber, ob sie (oder etwas anderes für diese Angelegenheit) bewusst sein kann. Es ist klar, dass jede andere Methode der Bewährung des Insassen eines chinesischen Raums im Prinzip dieselben Schwierigkeiten hat wie der Austausch von Fragen und Antworten auf Chinesisch. Es ist einfach nicht möglich, göttlich zu sein, ob eine bewusste Agentur oder eine clevere Simulation den Raum bewohnt. Searle argumentiert, dass dies nur für einen Beobachter außerhalb des Raumes gilt. Der ganze Punkt des Gedankenexperiments ist, jemanden in den Raum zu stellen, wo sie direkt die Operationen des Bewusstseins beobachten können. Searle behauptet, dass von seinem Aussichtspunkt innerhalb des Raumes nichts zu sehen ist, was imaginativ zu Bewusstsein führen könnte, außer sich selbst, und offensichtlich hat er keinen Geist, der Chinesisch sprechen kann. Angewandte Ethik Patrick Hew benutzte das chinesische Raumargument, um Anforderungen von militärischen Befehls- und Kontrollsystemen abzuleiten, wenn sie die moralische Autorität eines Kommandanten bewahren sollen. Er zeichnete eine Analogie zwischen einem Kommandanten in seinem Kommandozentrum und der Person im chinesischen Raum und analysierte sie unter einer Lesung von Aristoteles Vorstellungen von Pflicht und Unwissenheit". Informationen könnten von Bedeutung zu Symbolen "abgewandelt" werden und symbolisch manipuliert werden, aber moralische Agentur könnte unterminiert werden, wenn es unzureichende "up Konvertierung" in Bedeutung gab. Hew zitierte Beispiele aus dem USS Vincennes Vorfall. Informatik Das chinesische Raumargument ist in erster Linie ein Argument in der Philosophie des Geistes, und sowohl große Informatiker und künstliche Intelligenz Forscher betrachten es irrelevant für ihre Felder. Allerdings sind mehrere Konzepte, die von Informatikern entwickelt werden, wesentlich, um das Argument zu verstehen, einschließlich Symbolverarbeitung, Turing Maschinen, Turing Vollständigkeit, und der Turing Test. Die Argumente von Strong AI gegen AI Research Searle werden in der Regel nicht als ein Thema für die KI-Forschung betrachtet. Stuart Russell und Peter Norvig beobachten, dass die meisten KI-Forscher "die starke KI-Hypothese nicht interessieren – solange das Programm funktioniert, ist es ihnen egal, ob Sie es als Simulation von Intelligenz oder realer Intelligenz bezeichnen." Die Hauptaufgabe der künstlichen Intelligenzforschung ist es, nur nützliche Systeme zu schaffen, die intelligent handeln, und es spielt keine Rolle, ob die Intelligenz nur eine Simulation ist. Searle widerspricht nicht, dass KI-Forschung Maschinen schaffen kann, die in der Lage sind, sehr intelligentes Verhalten. Das chinesische Raumargument lässt die Möglichkeit offen, dass eine digitale Maschine gebaut werden könnte, die intelligenter wirkt als eine Person, aber keinen Geist oder Intentionalität in der gleichen Weise hat, wie Gehirne. Searles "starke KI" sollte nicht mit "starker KI" im Sinne von Ray Kurzweil und anderen Futuristen verwechselt werden, die den Begriff benutzen, maschinelle Intelligenz zu beschreiben, die die menschliche Intelligenz rivalisiert oder übertrifft. Kurzweil beschäftigt sich vor allem mit der von der Maschine angezeigten Intelligenz, während Searles Argument darauf keine Grenzen setzt. Searle argumentiert, dass selbst eine superintelligente Maschine nicht unbedingt einen Geist und Bewusstsein haben würde. Turing-Test Das chinesische Zimmer implementiert eine Version des Turing-Tests. Alan Turing führte den Test 1950 ein, um die Frage zu beantworten "kann Maschinen denken?" In der Standardversion beschäftigt sich ein menschlicher Richter mit einem natürlichen Sprachgespräch mit einem Menschen und einer Maschine, die darauf ausgelegt ist, Leistung zu erzeugen, die von der eines menschlichen Wesens unbestreitbar ist. Alle Teilnehmer sind voneinander getrennt. Wenn der Richter der Maschine vom Menschen nicht zuverlässig sagen kann, soll die Maschine den Test bestanden haben. Turing betrachtete dann jeden möglichen Einwand gegen den Vorschlag "Maschinen können denken", und stellte fest, dass es einfache, offensichtliche Antworten gibt, wenn die Frage auf diese Weise entmystifiziert wird. Er beabsichtigte jedoch nicht, den Test für die Anwesenheit von Bewußtsein oder Verständnis zu messen." Er glaubte nicht, dass dies für die Probleme relevant war, die er angesprochen hatte. Er schrieb: Ich möchte nicht den Eindruck geben, dass ich glaube, es gibt kein Geheimnis über das Bewusstsein. Es gibt zum Beispiel etwas von einem Paradox, das mit jedem Versuch verbunden ist, es zu lokalisieren. Aber ich glaube nicht, dass diese Geheimnisse notwendigerweise gelöst werden müssen, bevor wir die Frage beantworten können, mit der wir uns in diesem Papier beschäftigen. Für Searle, als Philosoph, der in die Natur von Verstand und Bewusstsein untersucht, sind dies die relevanten Geheimnisse. Der chinesische Raum soll zeigen, dass der Turing-Test nicht ausreicht, um die Anwesenheit von Bewusstsein zu erkennen, auch wenn der Raum sich verhalten oder als bewusster Geist funktionieren würde. Symbolverarbeitung Der chinesische Raum (und alle modernen Computer) manipulieren physische Objekte, um Berechnungen durchzuführen und Simulationen durchzuführen. AI-Forscher Allen Newell und Herbert A. Simon nannten diese Art von Maschine ein physisches Symbolsystem. Sie entspricht auch den im Bereich der mathematischen Logik verwendeten formalen Systemen. Searle betont die Tatsache, dass diese Art von Symbolmanipulation syntaktisch ist (auf der Grundlage eines Begriffs aus der Studie der Grammatik). Der Computer manipuliert die Symbole mit einer Form von Syntax-Regeln, ohne dass die semantik des Symbols (d.h. deren Bedeutung) bekannt ist. Newell und Simon hatten verworfen, dass ein physisches Symbolsystem (wie ein digitaler Computer) alle notwendigen Maschinen für "allgemein intelligente Aktion" oder, wie es heute bekannt ist, künstliche allgemeine Intelligenz hatte. Sie rahmen dies als philosophische Position, die physikalische Symbolsystemhypothese: "Ein physisches Symbolsystem hat die notwendigen und ausreichenden Mittel für allgemeine intelligente Handlungen. " Das chinesische Raumargument widerlegt dies nicht, weil es in Bezug auf "intelligente Handlung" gerahmt wird, d.h. das äußere Verhalten der Maschine, anstatt die Anwesenheit oder Abwesenheit von Verständnis, Bewusstsein und Geist. Chinesisches Zimmer und Turing Vollständigkeit Das chinesische Zimmer hat ein Design analog zu einem modernen Computer. Es verfügt über eine von Neumann Architektur, die aus einem Programm (das Buch der Anweisungen,) einige Speicher (die Papiere und Dateischränke,) eine CPU, die den Anweisungen folgt (der Mann,) und ein Mittel, Symbole in Erinnerung zu schreiben (der Bleistift und Radierer). Eine Maschine mit diesem Design ist in der theoretischen Informatik als "Turing complete" bekannt, weil es die notwendigen Maschinen hat, jede Berechnung durchzuführen, die eine Turing-Maschine tun kann, und daher ist es in der Lage, eine Schritt-für-Schritt-Simulation jeder anderen digitalen Maschine, gegeben genug Speicher und Zeit. Alan Turing schreibt: "Alle digitalen Computer sind in einem Sinne gleichwertig." Die weithin anerkannte Church-Turing-Thesis hält, dass jede Funktion, die durch ein effektives Verfahren berechnet wird, von einer Turing-Maschine berechnet wird. Die Turing Vollständigkeit des chinesischen Raumes bedeutet, dass es tun kann, was jeder andere digitale Computer tun kann (wenn auch viel, viel langsamer). Wenn also der chinesische Raum keinen chinesischsprachigen Geist enthält oder nicht, kann kein anderer digitaler Computer einen Geist enthalten. Einige Antworten auf Searle beginnen mit argumentieren, dass der Raum, wie beschrieben, keinen chinesisch sprechenden Geist haben kann.Argumente dieser Form, laut Stevan Harnad, sind "keine Widerlegung (aber eher eine Bestätigung) des chinesischen Raumarguments, weil diese Argumente tatsächlich bedeuten, dass keine digitalen Computer einen Verstand haben können. Es gibt einige Kritiker, wie Hanoch Ben-Yami, die argumentieren, dass der chinesische Raum nicht alle Fähigkeiten eines digitalen Computers simulieren kann, wie in der Lage, die aktuelle Zeit zu bestimmen. Vollständiges Argument Searle hat eine formalere Version des Arguments erstellt, zu dem das chinesische Zimmer gehört. Er präsentierte 1984 die erste Version. Die unten angegebene Fassung ist ab 1990. Der einzige Teil des Arguments, das kontrovers sein sollte, ist A3 und es ist dieser Punkt, dass das chinesische Raum dachte Experiment soll zu beweisen. Er beginnt mit drei Axiomen: (A1) "Programme sind formal (syntaktisch). Ein Programm verwendet Syntax, um Symbole zu manipulieren und achtet nicht auf die Semantik der Symbole. Es weiß, wo man die Symbole und wie man sie umgibt, aber es weiß nicht, wofür sie stehen oder was sie meinen. Für das Programm sind die Symbole nur physische Objekte wie andere.(A2) "Minden haben geistige Inhalte (Semantik). Im Gegensatz zu den Symbolen, die von einem Programm verwendet werden, haben unsere Gedanken Bedeutung: sie repräsentieren Dinge und wir wissen, was sie darstellen.(A3) "Syntax von selbst ist weder konstitutiv noch ausreichend für die Semantik." Das ist das, was das chinesische Raum-Denk-Experiment beweisen soll: Das chinesische Zimmer hat Syntax (weil es einen Mann gibt, der dort bewegte Symbole umgibt). Das chinesische Zimmer hat keine Semantik (denn nach Searle gibt es niemand oder nichts im Raum, das versteht, was die Symbole bedeuten). Die Syntax zu haben reicht daher nicht aus, um Semantik zu erzeugen. Searle stellt fest, dass diese direkt zu diesem Schluss führen: (C1) Programme sind weder konstitutiv noch ausreichend für Geister. Dies sollte ohne Kontroversen von den ersten drei folgen: Programme haben keine Semantik. Programme haben nur Syntax, und Syntax ist unzureichend für die Semantik. Jeder Geist hat Semantik. Deshalb sind keine Programme Gedanken. Dieser Großteil des Arguments soll zeigen, dass künstliche Intelligenz niemals eine Maschine mit einem Geist produzieren kann, indem sie Programme schreiben, die Symbole manipulieren. Der Rest des Arguments befasst sich mit einer anderen Frage. Ist das menschliche Gehirn ein Programm? Mit anderen Worten, ist die rechnerische Theorie des Verstandes richtig? Er beginnt mit einem Axiom, das den grundlegenden modernen wissenschaftlichen Konsens über Gehirn und Geist ausdrücken soll: (A4) Gehirne verursachen Geister. Searle behauptet, dass wir sofort und trivial ableiten können, dass: (C2) Ein anderes System, das in der Lage ist, Geister zu verursachen, würde ursächliche Kräfte (mindestens) haben müssen, die denen des Gehirns entsprechen. Gehirne müssen etwas haben, das dazu führt, dass ein Geist existiert. Die Wissenschaft muss noch genau bestimmen, was sie ist, aber sie muss existieren, weil Geister existieren. Searle nennt es "Kausalkräfte"."Causal Mächte" ist, was das Gehirn verwendet, um einen Geist zu schaffen. Wenn etwas anderes dazu führen kann, dass ein Geist existiert, muss es "gleichwertige Kausalbefugnisse" haben. Und daraus ergibt er die weiteren Schlussfolgerungen: (C3) Ein Artefakt, das geistige Phänomene, jedes künstliche Gehirn, erzeugt, müsste in der Lage sein, die spezifischen kausalen Kräfte des Gehirns zu duplizieren, und es konnte nicht tun, dass nur durch die Durchführung eines formalen Programms. Dies folgt aus C1 und C2: Da kein Programm einen Geist erzeugen kann und "gleichwertige Kausalkräfte" Geist erzeugen, folgt, dass Programme nicht "gleichwertige Kausalkräfte" haben.(C4)Die Art, wie menschliche Gehirne tatsächlich geistige Phänomene erzeugen, kann nicht allein durch die Durchführung eines Computerprogramms sein. Da Programme nicht "gleichwertige Kausalkräfte" haben, erzeugen "gleichwertige Kausalkräfte" Geister und Gehirne Geister, so folgt, dass Gehirne keine Programme verwenden, um Geister zu erzeugen. Antworten Antworten auf Searles Argument können nach dem klassifiziert werden, was sie behaupten zu zeigen: Diejenigen, die identifizieren, wer spricht Chinesisch Die, die zeigen, wie sinnlose Symbole aussagekräftig werden können Diejenigen, die vorschlagen, dass der chinesische Raum sollte in irgendeiner Weise neu gestaltet werden diejenigen, die behaupten, dass Searles Argument irreführen diejenigen, die argumentieren, dass das Argument falsche Annahmen über subjektive bewusste Erfahrung macht und daher beweist nichtsEinige der Argumente (Robot und Gehirnsimulation, zum Beispiel) fallen in mehrere Kategorien. Systeme und virtuelle Geist Antworten: den Verstand finden Diese Antworten versuchen, die Frage zu beantworten: Da der Mann im Raum nicht Chinesisch spricht, wo ist der Geist, der tut? Diese Antworten richten sich an die wichtigsten ontologischen Fragen von Geist vs. Körper und Simulation vs. Realität. Alle Antworten, die den Geist im Raum identifizieren, sind Versionen von "das System Antwort." Systemantwort Die grundlegende Version argumentiert, dass es das "Großsystem" ist, das Chinesisch versteht. Während der Mann nur Englisch versteht, wenn er mit dem Programm kombiniert wird, Kratzpapier, Bleistifte und Dateischränke, bilden sie ein System, das Chinesisch verstehen kann. "Hier wird das Verständnis nicht dem bloßen Individuum zugeschrieben, sondern es wird diesem ganzen System zugeschrieben, dessen Teil er ist", erklärt Searle. Die Tatsache, dass der Mensch China nicht versteht, ist irrelevant, denn es ist nur das gesamte System, das zählt. Searle stellt fest, dass (in dieser einfachen Version der Antwort) das System nichts anderes ist als eine Sammlung von gewöhnlichen physischen Objekten; es gibt die Macht des Verständnisses und des Bewusstseins zu "die Verbindung dieser Person und der Bits des Papiers" ohne jede Anstrengung zu erklären, wie dieser Stapel von Objekten ein bewusstes, denkendes Wesen geworden ist. Searle argumentiert, dass keine vernünftige Person mit der Antwort zufrieden sein sollte, es sei denn, sie seien "unter dem Griff einer Ideologie"; Damit diese Antwort aus der Ferne plausibel sein kann, muss man sie selbstverständlich annehmen, dass das Bewusstsein das Produkt eines Informationsverarbeitungssystems sein kann, und erfordert nichts, was der eigentlichen Biologie des Gehirns entspricht. Searle reagiert dann, indem er diese Liste der physischen Objekte vereinfacht: Er fragt, was passiert, wenn der Mann die Regeln einprägt und alles in seinem Kopf verfolgt? Dann besteht das ganze System aus nur einem Objekt: dem Mann selbst. Searle argumentiert, dass, wenn der Mann Chinesisch nicht versteht, das System Chinesen nicht versteht, entweder weil jetzt "das System" und "der Mann" beide genau das gleiche Objekt beschreiben. Kritik an Searles Antwort argumentieren, dass das Programm dem Mann erlaubt hat, zwei Köpfe in einem Kopf zu haben. Wenn wir annehmen, dass ein Geist eine Form der Informationsverarbeitung ist, dann kann die Berechnungstheorie zwei Berechnungen auf einmal, nämlich (1) die Berechnung für die universelle Programmierbarkeit (die die Funktion, die von der Person und Notizaufnahmematerialien unabhängig von bestimmten Programminhalten gelöst wird) und (2) die Berechnung der Turing-Maschine, die durch das Programm beschrieben wird (die von allem, einschließlich des spezifischen Programms, instantiiert wird). Die Berechnungstheorie erklärt somit formal die offene Möglichkeit, dass die zweite Berechnung im chinesischen Raum ein humanäquivalentes semantisches Verständnis der chinesischen Inputs mit sich bringen könnte. Der Fokus liegt eher auf der Turing-Maschine des Programms als auf der Person. Aus Searles Sicht ist dieses Argument jedoch kreisförmig. Die Frage ist, ob das Bewusstsein eine Form der Informationsverarbeitung ist, und diese Antwort erfordert, dass wir diese Annahme machen. Mehr anspruchsvolle Versionen der Systemantwort versuchen, genauer zu identifizieren, was "das System" ist und sie unterscheiden sich in genau, wie sie es beschreiben. Nach diesen Antworten könnte der "Geist, der Chinesisch spricht" solche Dinge sein, wie: die Software, ein Programm, ein "laufendes Programm", eine Simulation der "neuralen Korrelate des Bewusstseins", das "funktionelle System", ein "simulierter Geist", ein "emergentes Eigentum", oder "ein virtueller Geist" (Marvin Minskys Version der unten beschriebenen Systeme Antwort). Antwort auf die Antwort Der Begriff Virtual wird in der Informatik verwendet, um ein Objekt zu beschreiben, das in einem Computer (oder Computernetzwerk) nur existiert, weil Software es erscheinen lässt. Die Objekte innerhalb von Computern (einschließlich Dateien, Ordner usw.) sind alle virtuellen, außer den elektronischen Komponenten des Computers. Ebenso argumentiert Minsky, ein Computer kann einen Geist enthalten, der im gleichen Sinne wie virtuelle Maschinen, virtuelle Gemeinschaften und virtuelle Realität ist. Um die Unterscheidung zwischen der einfachen Antwort der Systeme und der virtuellen Antwort zu klären, stellt David Cole fest, dass zwei Simulationen gleichzeitig auf einem System laufen könnten: ein sprechender Chinese und ein sprechender Koreaner. Während es nur ein System gibt, kann es mehrere "virtuelle Köpfe", so kann das System nicht der Geist sein. Searle reagiert darauf, dass ein solcher Geist bestenfalls eine Simulation ist und schreibt: "Niemand vermutet, dass Computersimulationen eines fünfarmigen Feuers die Nachbarschaft niederbrennen oder dass eine Computersimulation eines Regensturms uns alle erschreckt. " Nicholas Fearn reagiert darauf, dass die Simulation für einige Dinge so gut ist wie die reale Sache. " Wenn wir die Taschenrechnerfunktion auf einem Desktop-Computer aufrufen, erscheint das Bild eines Taschenrechners auf dem Bildschirm. Wir beschweren uns nicht, dass "es nicht wirklich ein Taschenrechner ist", weil die physikalischen Eigenschaften des Gerätes keine Rolle spielen." Die Frage ist, ist der menschliche Geist wie der Taschenrechner, im Wesentlichen aus Informationen zusammengesetzt? Oder ist der Geist wie der Regensturm, etwas anderes als ein Computer und nicht durch eine Computersimulation vollständig realisierbar? Seit Jahrzehnten hat diese Frage der Simulation AI-Forscher und Philosophen dazu geführt, zu prüfen, ob der Begriff "synthetische Intelligenz" angemessener ist als die gemeinsame Beschreibung solcher Intelligenzen als künstlich. " Diese Antworten geben eine Erklärung von genau, wer es ist, die Chinesisch versteht. Wenn es neben dem Mann im Raum etwas gibt, das Chinesisch verstehen kann, kann Searle nicht argumentieren, dass (1) der Mann Chinesisch nicht versteht, also (2) nichts im Raum Chinesisch versteht. Dies zeigt, dass Searles Argument nicht beweist, dass "starke KI" falsch ist. Diese Antworten geben an sich keinen Beweis dafür, dass starke KI wahr ist. Sie zeigen nicht, dass das System (oder der virtuelle Geist) Chinesisch versteht, außer der hypothetischen Prämisse, dass es den Turing Test passiert. Searle argumentiert, dass, wenn wir eine starke KI aus der Ferne plausibel betrachten, der chinesische Raum ein Beispiel ist, das eine Erklärung erfordert, und es ist schwierig oder unmöglich zu erklären, wie das Bewusstsein aus dem Raum hervortreten könnte oder wie das System Bewußtsein haben würde. Wie Searle schreibt: "Die Systeme antworten einfach auf die Frage, indem sie darauf bestehen, dass das System Chinesisch verstehen muss" und damit die Frage oder hoffnungslos zirkular ist. Roboter und Semantik Antworten: die Bedeutung finden Was die Person im Raum betrifft, so sind die Symbole einfach bedeutungslos. Aber wenn der chinesische Raum wirklich versteht, was er sagt, dann müssen die Symbole ihre Bedeutung von irgendwo bekommen. Diese Argumente versuchen, die Symbole mit den Dingen zu verbinden, die sie symbolisieren. Diese Antworten richten sich an Searles Sorgen um Intentionalität, Symbolerdung und Syntax gegen Semantik. Roboter antworten Angenommen, dass anstelle eines Raumes das Programm in einen Roboter gelegt wurde, der herumlaufen und mit seiner Umgebung interagieren könnte. Dies würde eine "Kausalverbindung" zwischen den Symbolen und Dingen, die sie repräsentieren, ermöglichen. Hans Moravec kommentiert: "Wenn wir einen Roboter zu einem Vernunftsprogramm pfropfen könnten, brauchen wir keine Person mehr, um die Bedeutung zu geben: es würde aus der physischen Welt kommen. " Searles Antwort ist zu vermuten, dass, unbekannt für das Individuum im chinesischen Raum, einige der Eingänge direkt von einer Kamera auf einem Roboter montiert, und einige der Ausgänge wurden verwendet, um die Arme und Beine des Roboters zu manipulieren. Dennoch folgt die Person im Raum immer noch den Regeln und weiß nicht, was die Symbole bedeuten. Searle schreibt: "Er sieht nicht, was in die Augen des Roboters kommt." (Siehe Marys Zimmer für ein ähnliches Gedankenexperiment.) Abgeleitete Bedeutung Einige antworten, dass der Raum, wie Searle es beschreibt, mit der Welt verbunden ist: durch die chinesischen Sprecher, dass es mit und durch die Programmierer, die die Wissensbasis in seinem Dateischrank entworfen. Die Symbole Searle manipulieren schon aussagekräftig, sie sind ihm einfach nicht aussagekräftig. Searle sagt, dass die Symbole nur eine abgeleitete Bedeutung haben, wie die Bedeutung von Wörtern in Büchern. Die Bedeutung der Symbole hängt vom bewussten Verständnis der chinesischen Lautsprecher und der Programmierer außerhalb des Raumes ab. Der Raum, wie ein Buch, hat kein Verständnis von seinem eigenen. Commonsense Wissen / kontextualistische Antwort Einige haben argumentiert, dass die Bedeutungen der Symbole aus einem riesigen Hintergrund von Commonsense-Wissen, die im Programm und die Einreichung Schränke codiert. Dies würde einen Kontext bieten, der den Symbolen ihre Bedeutung geben würde. Searle stimmt zu, dass dieser Hintergrund existiert, aber er stimmt nicht zu, dass er in Programme gebaut werden kann. Hubert Dreyfus hat auch die Idee kritisiert, dass der Hintergrund symbolisch dargestellt werden kann. Für jeden dieser Vorschläge ist Searles Antwort gleich: Egal, wie viel Wissen in das Programm geschrieben wird und wie das Programm mit der Welt verbunden ist, er ist immer noch im Raum, der Symbole nach Regeln manipuliert. Seine Handlungen sind syntaktisch und das kann ihm nie erklären, wofür die Symbole stehen. Searle schreibt: "Syntax ist für die Semantik nicht ausreichend. "Doch, für diejenigen, die akzeptieren, dass Searles Handlungen einen Geist simulieren, getrennt von seinem eigenen, die wichtige Frage ist nicht, was die Symbole Searle bedeuten, was wichtig ist, ist, was sie für den virtuellen Geist bedeuten. Während Searle im Raum gefangen ist, ist der virtuelle Geist nicht: Er ist mit der Außenwelt durch die chinesischen Lautsprecher verbunden, mit denen er spricht, durch die Programmierer, die ihm Weltwissen gab, und durch die Kameras und andere Sensoren, die Roboter liefern können. Brain Simulation und Connectist Antworten: Neugestaltung des Raumes Diese Argumente sind alle Versionen der Systeme Antwort, die eine bestimmte Art von System als wichtig identifizieren; sie identifizieren einige spezielle Technologie, die bewusstes Verständnis in einer Maschine schaffen würde. ( Die oben genannten Antworten des Roboters und der "Commonsense Knowledge" geben auch eine bestimmte Art von System als wichtig an.) Gehirnsimulator Antwort Nehmen wir an, dass das Programm die Wirkung jedes Neurons im Gehirn eines chinesischen Lautsprechers im Detail simuliert. Dies verstärkt die Intuition, dass es keinen signifikanten Unterschied zwischen der Operation des Programms und der Operation eines lebenden menschlichen Gehirns geben würde. Searle antwortet, dass eine solche Simulation die wichtigen Eigenschaften des Gehirns nicht reproduziert – seine kausalen und absichtlichen Zustände. Searle ist beschämend, dass "menschliche mentale Phänomene [von tatsächlichen physikalisch-chemischen Eigenschaften des tatsächlichen menschlichen Gehirns abhängig sind." Darüber hinaus argumentiert er:[I]magine, dass anstelle eines einsprachigen Mannes in einem Raum schuffling Symbole haben wir den Mann eine aufwendige Reihe von Wasserleitungen mit Ventilen, die sie verbinden. Wenn der Mann die chinesischen Symbole erhält, schaut er im Programm auf, geschrieben in Englisch, welche Ventile er ein- und ausschalten muss. Jede Wasserverbindung entspricht einer Synapse im chinesischen Gehirn, und das gesamte System wird so aufgerichtet, dass nach dem richtigen Brennen, also nach dem Einschalten aller richtigen Wasserhahn, die chinesischen Antworten am Ausgang der Rohrreihe ausbrechen. Wo ist das Verständnis in diesem System? Es nimmt Chinesisch als Input, es simuliert die formale Struktur der Synapsen des chinesischen Gehirns, und es gibt Chinesisch als Output. Aber der Mann versteht sicherlich nicht Chinesisch, und auch nicht die Wasserrohre, und wenn wir versucht sind, zu übernehmen, was ich denke, ist die absurde Ansicht, dass irgendwie die Konjunktion von Mensch und Wasserrohre versteht, denken Sie daran, dass im Prinzip der Mann die formale Struktur der Wasserrohre verinnerlichen und alle "neuronen Feuer" in seiner Phantasie tun kann. Zwei Variationen der Antwort auf den Gehirnsimulator sind das China Gehirn und das Gehirn-Ersatz-Szenario. China Gehirn Was ist, wenn wir jeden Bürger von China bitten, ein Neuron zu simulieren, mit dem Telefonsystem die Verbindungen zwischen Axonen und Dendriten simulieren? In dieser Version scheint es offensichtlich, dass kein Individuum ein Verständnis dafür haben würde, was das Gehirn sagen könnte. Es ist auch offensichtlich, dass dieses System funktionell einem Gehirn gleichwertig wäre, also wenn Bewusstsein eine Funktion ist, wäre dieses System bewusst. Ersatzszenario für die Bremse Dabei werden wir uns vorstellen, dass Ingenieure einen winzigen Computer erfunden haben, der die Wirkung eines einzelnen Neurons simuliert. Was würde passieren, wenn wir zu einer Zeit ein Neuron ersetzen? Eine Wiederholung würde nichts tun, um bewusstes Bewusstsein zu ändern. Alle zu wiederholen würde einen digitalen Computer erstellen, der ein Gehirn simuliert. Wenn Searle richtig ist, muss während des Verfahrens bewusstes Bewusstsein verschwinden (entweder allmählich oder auf einmal). Searles Kritiker argumentieren, dass es während des Verfahrens keinen Punkt geben würde, wenn er behaupten kann, dass bewusstes Bewusstsein endet und sinnlose Simulation beginnt. Searle prognostiziert, dass, während Sie durch die Gehirnprothese gehen, "Sie finden, zu Ihrem totalen Erstaunen, dass Sie die Kontrolle über Ihr externes Verhalten verlieren. Sie finden zum Beispiel, dass, wenn Ärzte Ihre Vision testen, Sie hören, sie sagen: "Wir halten ein rotes Objekt vor Ihnen; bitte sagen Sie uns, was Sie sehen." Du willst weinen, ich kann nichts sehen. Ich werde total blind. Aber du hörst deine Stimme und sprichst in einer Weise, die völlig außerhalb deiner Kontrolle ist: "Ich sehe ein rotes Objekt vor mir." [Y] Unsere bewusste Erfahrung schrumpft langsam auf nichts, während Ihr extern beobachtbares Verhalten gleich bleibt."(Siehe Schiff von Theseus für ein ähnliches Gedankenexperiment.) Antworten auf den Link In engem Zusammenhang mit der Antwort des Gehirnsimulators behauptet dies, dass eine massiv parallele Verbindungsarchitektur fähig wäre, zu verstehen. Kombinationsantwort Diese Antwort kombiniert die Roboterantwort mit der Hirnsimulationsantwort und argumentiert, dass eine mit der Welt verbundene Gehirnsimulation durch einen Roboterkörper einen Geist haben könnte. Viele Villen / warten bis nächstes Jahr Antwort Eine bessere Technologie in der Zukunft ermöglicht es Computern zu verstehen. Searle stimmt zu, dass dies möglich ist, aber hält diesen Punkt irrelevant. Searle stimmt zu, dass es Designs geben kann, die dazu führen würden, dass eine Maschine bewusstes Verständnis hat. Diese Argumente (und der Roboter oder Commonsense-Wissensantworten) identifizieren eine spezielle Technologie, die dazu beitragen würde, bewusstes Verständnis in einer Maschine zu schaffen. Sie können auf zwei Arten interpretiert werden: entweder behaupten sie (1), diese Technologie ist für das Bewusstsein erforderlich, der chinesische Raum nicht oder kann diese Technologie nicht umsetzen, und daher kann der chinesische Raum nicht den Turing-Test passieren oder (auch wenn er es tat) es nicht bewusstes Verständnis haben. Oder sie behaupten vielleicht, dass (2) es einfacher ist zu sehen, dass der chinesische Raum einen Geist hat, wenn wir diese Technologie als verwendet, um sie zu schaffen visualisieren. Im ersten Fall, in dem Merkmale wie ein Roboterkörper oder eine Verbindungsarchitektur erforderlich sind, behauptet Searle, dass starke KI (wie er es versteht) aufgegeben wurde. Der chinesische Raum hat alle Elemente einer Turing Komplettmaschine und ist somit in der Lage, jede digitale Berechnung überhaupt zu simulieren. Wenn Searles Zimmer nicht den Turing Test passieren kann, gibt es keine andere digitale Technologie, die den Turing Test passieren könnte. Wenn Searles Zimmer den Turing-Test passieren könnte, aber immer noch keinen Geist hat, dann ist der Turing-Test nicht ausreichend, um festzustellen, ob der Raum einen Geist hat". So oder so, es leugnet eine oder andere der Positionen Searle denkt an "starke KI", was sein Argument beweist. Die Hirnargumente leugnen vor allem starke KI, wenn sie annehmen, dass es keinen einfacheren Weg gibt, den Verstand zu beschreiben, als ein Programm zu schaffen, das genauso geheimnisvoll ist wie das Gehirn. Er schreibt: "Ich dachte, die ganze Idee einer starken KI war, dass wir nicht wissen müssen, wie das Gehirn funktioniert, um zu wissen, wie der Geist funktioniert." Wenn die Berechnung keine Erklärung des menschlichen Verstandes liefert, dann hat starke KI gescheitert, so Searle. Andere Kritiker halten fest, dass der Raum wie Searle beschrieben, dass es tatsächlich einen Geist hat, aber sie argumentieren, dass es schwierig zu sehen ist – die Beschreibung von Searle ist richtig, aber irreführend. Indem sie den Raum realistischer gestalten, hoffen sie, dies deutlicher zu machen. In diesem Fall werden diese Argumente als Intuitionsbeschwerde verwendet (siehe nächste Abschnitt). In der Tat kann der Raum genauso einfach neu gestaltet werden, um unsere Intuitionen zu schwächen. Ned Blocks Blockhead Argument schlägt vor, dass das Programm theoretisch in eine einfache Lookup-Tabelle der Regeln des Formulars "wenn der Benutzer schreibt S, Antwort mit P und goto X" umgeschrieben werden könnte. Mindestens prinzipiell kann jedes Programm in diese Form umgeschrieben (oder refactored) werden, sogar eine Gehirnsimulation. Im Blockhead-Szenario wird der gesamte mentale Zustand im Buchstaben X versteckt, der eine Speicheradresse darstellt - eine der nächsten Regel zugeordnete Zahl. Es ist schwer zu visualisieren, dass ein Augenblick der bewussten Erfahrung in einer einzigen großen Zahl erfasst werden kann, aber das ist genau das, was "starke KI" behauptet. Auf der anderen Seite wäre ein solcher Lookup-Tisch lächerlich groß (zum Punkt physikalisch unmöglich zu sein), und die Staaten könnten daher äußerst spezifisch sein. Searle argumentiert, dass jedoch das Programm geschrieben wird oder aber die Maschine mit der Welt verbunden ist, wird der Geist durch eine einfache Schritt für Schritt digitale Maschine (oder Maschinen) simuliert. Diese Maschinen sind immer genau wie der Mann im Raum: sie verstehen nichts und sprechen nicht Chinesisch. Sie manipulieren nur Symbole, ohne zu wissen, was sie bedeuten. Searle schreibt: "Ich kann jedes formale Programm haben, das du magst, aber ich verstehe immer noch nichts." Geschwindigkeit und Komplexität: appelliert an Intuition Die folgenden Argumente (und die intuitiven Interpretationen der obigen Argumente) erklären nicht direkt, wie ein chinesischer sprechender Geist im Raum von Searle existieren könnte, oder wie die von ihm manipulierten Symbole sinnvoll werden könnten. Durch die Anhebung von Zweifeln an Searles Intuitionen unterstützen sie jedoch andere Positionen, wie das System und die Roboterantworten. Diese Argumente, wenn angenommen, verhindern Searle, dass seine Schlussfolgerung offensichtlich ist, indem er die Intuitionen untergraben, die seine Gewissheit erfordert. Mehrere Kritiker glauben, dass Searles Argument ausschließlich auf Intuitionen beruht. Ned Block schreibt "Searles Argument hängt für seine Kraft auf Intuitionen, dass bestimmte Wesen nicht denken. " Daniel Dennett beschreibt das chinesische Raumargument als irreführende "Intuitionspumpe" und schreibt "Searles Gedankenexperiment hängt unerlaubt davon ab, dass du einen Fall, einen irrelevanten Fall und die offensichtliche Schlussfolgerung daraus vorstellst. " Einige der oben genannten Argumente fungieren auch als Anreize für Intuition, vor allem diejenigen, die darauf abzielen, es plausibler zu machen, dass der chinesische Raum einen Geist enthält, der den Roboter, Commonsense-Wissen, Gehirnsimulation und verbindungsorientierte Antworten beinhalten kann. Einige der oben genannten Antworten richten sich auch an das spezifische Problem der Komplexität. Die verbindungistische Antwort betont, dass ein funktionierendes künstliches Intelligenzsystem so komplex und wie das menschliche Gehirn miteinander verbunden sein müsste. Die Commonsense-Wissensantwort betont, dass jedes Programm, das einen Turing-Test bestand, "ein außerordentlich geschmeidiges, ausgeklügeltes und mehrschichtiges System sein müsste, das mit "Weltwissen" und Meta-Wissen und Meta-Meta-Knowledge verblüfft", wie Daniel Dennett erklärt. Antworten auf Geschwindigkeit und Komplexität Die Geschwindigkeit, mit der menschliche Gehirne Informationen verarbeiten, ist (nach einigen Schätzungen) 100 Milliarden Operationen pro Sekunde. Mehrere Kritiker weisen darauf hin, dass der Mann im Raum wahrscheinlich Millionen von Jahren braucht, um auf eine einfache Frage zu reagieren, und würde "Schränke" astronomischer Proportionen erfordern. Dies bringt die Klarheit der Intuition von Searle in Zweifel. Eine besonders lebendige Version der Geschwindigkeit und Komplexität Antwort ist von Paul und Patricia Churchland. Sie schlagen dieses analoge Gedankenexperiment vor: Churchland Leuchtraum "Beinhalten Sie einen dunklen Raum mit einem Mann mit einem Barmagneten oder geladenen Objekt. Wenn der Mann den Magneten nach oben und unten pumpt, dann wird er nach Maxwells Theorie der künstlichen Luminanz (AL) einen Spreizkreis von elektromagnetischen Wellen initiieren und damit leuchtend sein. Aber wie wir alle, die mit Magneten oder aufgeladenen Kugeln gewusst haben, kennen ihre Kräfte (oder andere Kräfte für diese Angelegenheit), auch wenn sie in Bewegung gesetzt sind, überhaupt keine Leuchtkraft. Es ist unvorstellbar, dass Sie reale Leuchtkraft darstellen könnten, indem Sie Kräfte herum bewegen! "Das Problem ist, dass er den Magneten nach oben und unten etwas wie 450 Billionen mal pro Sekunde schwingen müsste, um etwas zu sehen. Stevan Harnad ist kritisch für Geschwindigkeit und Komplexität Antworten, wenn sie über unsere Intuitionen hinwegschichten. Er schreibt: "Einige haben einen Kult von Geschwindigkeit und Timing gemacht und halten, dass, wenn sie auf die richtige Geschwindigkeit beschleunigt, die Rechenschaft kann einen Phasenübergang in das Mental machen. Es sollte klar sein, dass es sich nicht um eine Gegenargumente, sondern lediglich um eine Ad-hoc-Spekulation handelt (wie die Ansicht ist, dass es sich nur um eine Frage der Ratschen bis zum richtigen Grad der Komplexität handelt." "Searle argumentiert, dass seine Kritiker auch auf Intuitionen vertrauen, aber die Intuitionen seiner Gegner haben keine empirische Grundlage. Er schreibt, dass, um die "Systemantwort" als abseits plausibel zu betrachten, eine Person "unter dem Griff einer Ideologie" sein muss. Die Systemantwort macht nur Sinn (an Searle), wenn man davon ausgeht, dass jedes System Bewusstsein haben kann, nur indem man ein System mit dem richtigen Verhalten und den Funktionsteilen ist. Diese Annahme, argumentiert er, ist angesichts unserer Erfahrung des Bewusstseins nicht annehmbar. Andere Geister und Zombies: Sinnlosigkeit Mehrere Antworten argumentieren, dass Searles Argument irrelevant ist, weil seine Annahmen über Geist und Bewusstsein fehlerhaft sind. Searle glaubt, dass die Menschen ihr Bewusstsein, die Intentionalität und die Natur des Verstandes jeden Tag direkt erleben, und dass diese Erfahrung des Bewusstseins nicht offen ist zu hinterfragen. Er schreibt, dass wir "die Realität und die Wissensfähigkeit des Geistes voraussetzen müssen. " Diese Antworten fragen, ob Searle mit seiner eigenen Erfahrung des Bewusstseins gerechtfertigt ist, um festzustellen, dass es mehr ist als mechanische Symbolverarbeitung. Insbesondere argumentiert die andere Antwort des Geistes, dass wir unsere Erfahrung des Bewusstseins nicht nutzen können, um Fragen über andere Köpfe zu beantworten (auch den Verstand eines Computers), und die Epiphenomena Antwort argumentiert, dass Searles Bewusstsein nicht in dem Sinne existiert, dass Searle denkt es tut. Andere Gedanken antworten Diese Antwort weist darauf hin, dass Searles Argument eine Version des Problems anderer Gedanken ist, angewendet auf Maschinen. Es gibt keine Möglichkeit, dass wir feststellen können, ob die subjektive Erfahrung anderer Menschen genauso ist wie unsere eigenen. Wir können nur ihr Verhalten studieren (d.h. indem wir ihnen einen eigenen Turing Test geben). Kritik an Searle argumentieren, dass er den chinesischen Raum auf einen höheren Standard hält, als wir eine gewöhnliche Person halten würden. Nils Nilsson schreibt "Wenn sich ein Programm verhält, als ob es sich vermehren würde, würden die meisten von uns sagen, dass es tatsächlich multipliziert. Für alles, was ich weiß, kann Searle nur beharren, als wenn er zutiefst über diese Dinge nachdenkt. Aber obwohl ich mit ihm nicht einverstanden bin, ist seine Simulation ziemlich gut, also bin ich bereit, ihn mit wirklichem Gedanken zu würdigen." AlanTuring erwartete Searle's Argumentlinie (die er "The Argument from Consciousness" genannt) im Jahr 1950 und macht die anderen Köpfe Antwort. Er bemerkte, dass die Menschen nie das Problem der anderen Gedanken betrachten, wenn sie miteinander zu tun. Er schreibt: "Anstatt sich ständig über diesen Punkt zu streiten, ist es üblich, die höfliche Konvention zu haben, die jeder denkt." Der Turing-Test erweitert diese "Politikkonvention" einfach auf Maschinen. Er beabsichtigt nicht, das Problem anderer Gedanken (für Maschinen oder Menschen) zu lösen, und er denkt nicht, dass wir es brauchen. Verschiedene Philosophen argumentieren, dass Bewusstsein, wie Searle es beschreibt, nicht existiert. Diese Position wird manchmal als eliminativer Materialismus bezeichnet: die Ansicht, dass Bewusstsein ein Eigentum ist, das auf eine streng mechanische Beschreibung reduziert werden kann und dass unsere Erfahrung des Bewusstseins, wie Daniel Dennett es beschreibt, eine "Benutzer-Illusion" ist. Andere geistige Eigenschaften, wie originelle Intentionalität (auch als "Bedeutung", "Content" und "semantische Charakter" bezeichnet), werden häufig auch als etwas Besonderes über Überzeugungen und andere propositionelle Einstellungen angesehen. Eliminativer Materialismus behauptet, dass propositionale Einstellungen wie Überzeugungen und Wünsche, unter anderen absichtlichen Geisteszuständen, die Inhalte haben, nicht existieren. Ist der eliminative Materialismus die korrekte wissenschaftliche Darstellung der menschlichen Wahrnehmung, so muss die Annahme des chinesischen Raumarguments, dass "Minds geistige Inhalte (Semantik) haben" abgelehnt werden. Stuart Russell und Peter Norvig argumentieren, dass, wenn wir Searles Beschreibung der Intentionalität, des Bewusstseins und des Geistes akzeptieren, wir gezwungen sind, dieses Bewusstsein zu akzeptieren, Epiphenomenal ist: dass es "kein Schatten geworfen", dass es in der Außenwelt nicht nachweisbar ist. Sie argumentieren, dass Searle sich über die "Wissenschaft des Geistes" irren muss, und in seinem Glauben, dass es in unseren Neuronen "Kausale Eigenschaften" gibt, die den Verstand hervorrufen. Sie weisen darauf hin, dass durch Searles eigene Beschreibung diese ursächlichen Eigenschaften von niemandem außerhalb des Verstandes nicht erkannt werden können, ansonsten der chinesische Raum den Turing-Test nicht passieren konnte – die Leute draußen könnten sagen, dass es keinen chinesischen Lautsprecher im Raum gab, indem sie ihre ursächlichen Eigenschaften erkennen. Da sie keine ursächlichen Eigenschaften erkennen können, können sie die Existenz des Geistes nicht erkennen. Kurz gesagt, Searles "Causal-Eigenschaften" und das Bewusstsein selbst sind nicht nachweisbar, und alles, was nicht erkannt werden kann, existiert nicht oder spielt keine Rolle. Daniel Dennett bietet diese Erweiterung zum Epiphenomena-Argument. Dennetts Antwort von der natürlichen Selektion Nehmen Sie an, dass durch eine Mutation ein Mensch geboren wird, der Searles "Kausaleigenschaften" nicht hat, aber dennoch genau wie ein Mensch wirkt.( Diese Art von Tier wird als Zombie in Gedankenexperimenten in der Philosophie des Geistes bezeichnet). Dieses neue Tier würde genauso wie jeder andere Mensch reproduzieren und schließlich gäbe es mehr dieser Zombies. Natürliche Auswahl würde die Zombies bevorzugen, da ihr Design (wir könnten annehmen) etwas einfacher ist. Schließlich würden die Menschen sterben. Wenn also Searle richtig ist, ist es wahrscheinlich, dass Menschen (wie wir sie heute sehen) tatsächlich Zombies sind, die dennoch darauf bestehen, dass sie sich bewusst sind. Es ist unmöglich zu wissen, ob wir alle Zombies sind oder nicht. Selbst wenn wir alle Zombies sind, würden wir immer noch glauben, dass wir nicht sind. Searle stimmt dieser Analyse nicht zu und argumentiert, dass "die Untersuchung des Geistes beginnt mit solchen Tatsachen, dass Menschen Glauben haben, während Thermostaten, Telefone und Hinzufügen von Maschinen nicht .was wir wissen wollten, ist, was den Geist von Thermostaten und Lebern unterscheidet. " Er nimmt es so offensichtlich an, dass wir die Anwesenheit des Bewusstseins erkennen und diese Antworten als vom Punkt wegweisen können. Newtons flaming laser Schwert Antwort Mike Alder argumentiert, dass das gesamte Argument frivol ist, weil es nicht verifiziert ist: nicht nur ist die Unterscheidung zwischen einem Geist zu simulieren und einen Geist undefiniert zu haben, sondern es ist auch irrelevant, weil keine Experimente waren oder gar sein können, um zwischen den beiden zu unterscheiden vorgeschlagen. Englisch reply Margaret Boden gab diese Antwort in ihrem Artikel "Escaping from the Chinese Room. " In ihr schlägt sie vor, dass selbst wenn die Person im Raum die Chinesen nicht versteht, es bedeutet nicht, dass es im Raum kein Verständnis gibt. Die Person im Raum versteht zumindest das Regelbuch, das verwendet wird, um Ausgabeantworten bereitzustellen. In der Volkskultur Das chinesische Raumargument ist ein zentrales Konzept in Peter Watts Romanen Blindsight und (in geringerem Maße) Echopraxie. Es ist auch ein zentrales Thema im Videospiel Virtue's Last Reward, und bindet in die Erzählung des Spiels. In Staffel 4 des amerikanischen Verbrechensdrama Numb3rs gibt es einen kurzen Hinweis auf den chinesischen Raum. Der chinesische Raum ist auch der Name eines britischen unabhängigen Videospiel-Entwicklungsstudios, das am besten für die Arbeit an experimentellen First-Person-Spielen bekannt ist, wie Jeder's Gone to the Rapture, oder Dear Esther. Im 2016 Videospiel The Turing Test wird dem Spieler das chinesische Raum-Denk-Experiment durch eine KI erklärt. Siehe auch Computational Modelle der Spracherwerb Emergent Verhalten Kein wahrer Scotsman Philosophischer Zombie Sorites paradox Synthetic Intelligence I Am a Strange Loop Notes Citations ReferenzenWeiter lesen Allgemeine Präsentationen des Arguments: "Chinese Room Argument". Internet Enzyklopädie der Philosophie. Das chinesische Zimmer Argument. Stanford Enzyklopädie der Philosophie Das chinesische Zimmer verstehen,Mark Rosenfelder Quellen von John Searle: Chinesisches Zimmerargument von John Searle auf Scholarpedia The Chinese Room Argument, Teil 4 des 2. September 1999 Interview mit Searle Philosophie und den Habits von kritischen Denken in den Konversationen mit Geschichte Serie John R. Searle, “Was Ihr Computer nicht wissen kann” (Review von Luciano Floridi, The Vierte Revolution: Wie die Infosphäre Reshaping Human Reality, Oxford University Press, 2014; und Nick Bostrom, Superintelligence: Paths, Oxford Kritik des Arguments: A Refutation of John Searle's "Chinese Room Argument" Archived 2010-02-03 at the Wayback Machine, von Bob Murphy Kugel, P. (2004). " Das chinesische Zimmer ist ein Trick". Behavioral and Brain Sciences.27.doi:10.1017/S0140525X04210044.S2CID 56032408,. PDF auf der Homepage des Autors, kritisches Papier, basierend auf der Annahme, dass der CR seine Inputs (die in Chinesisch sind) nicht verwenden kann, um sein Programm zu ändern (was in Englisch ist). Wolfram Schmied (2004)." Demolishing Searle's Chinese Room".arXiv:cs.AI/0403009. John Preston und Mark Bishop, "Ansichten in den chinesischen Raum", Oxford University Press, 2002. Enthält Kapitel von John Searle, Roger Penrose, Stevan Harnad und Kevin Warwick. Margaret Boden, "Escaping from the Chinese room", Cognitive Science Research Papers Nr. CSRP 092, University of Sussex, School of Cognitive Sciences, 1987, OCLC 19297071, online PDF, "ein Auszug aus einem Kapitel" im damals unveröffentlichten "Computer Models of Mind: 62 Computational Intelligence Approaches in Theoretical Psychology," ISBN 0-52148; Presse, 1989, Kapitel 6; reprinted in Heil, S.253–266 (1988) (möglicherweise verbrückt;) J. Heil (Hg.)"Philosophy of Mind: A Guide and Anthology", Oxford University Press, 2004, Seiten 253–266 (gleiche Version wie in "Künstliche Intelligenz in Psychologie")