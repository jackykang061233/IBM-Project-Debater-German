Ein Mainframe-Computer, informell als Mainframe oder Big Iron bezeichnet, ist ein Computer, der in erster Linie von großen Organisationen für kritische Anwendungen wie Massendatenverarbeitung für Aufgaben wie Censuses, Industrie- und Verbraucherstatistiken, Unternehmensressourcenplanung und Großtransaktionsverarbeitung verwendet wird. Ein Hauptrechner ist groß, aber nicht so groß wie ein Supercomputer und hat mehr Verarbeitungsleistung als einige andere Klassen von Computern, wie Minicomputer, Server, Workstations und Personal Computer. Die meisten großformatigen Computer-System-Architekturen wurden in den 1960er Jahren etabliert, aber sie entwickeln sich weiter. Mainframe-Computer werden oft als Server verwendet. Der Begriff Mainframe wurde aus dem großen Schrank abgeleitet, genannt ein Hauptrahmen, der die zentrale Verarbeitungseinheit und Hauptspeicher von frühen Computern beherbergt. Später wurde der Begriff Mainframe verwendet, um High-End-Handelscomputer von weniger leistungsstarken Maschinen zu unterscheiden. Design Modernes Mainframe-Design zeichnet sich weniger durch rohe Rechengeschwindigkeit und mehr durch: Redundantes internes Engineering, das zu hoher Zuverlässigkeit und Sicherheit führt Umfangreiche Input-Output (I/O)-Einrichtungen mit der Fähigkeit, zu separaten Motoren zu entladen. Hot-Swapping von Hardware, wie Prozessoren und Speicher. Ihre hohe Stabilität und Zuverlässigkeit ermöglichen es diesen Maschinen, über sehr lange Zeiträume ununterbrochen zu laufen, mit mittlerer Zeit zwischen Defekten (MTBF) gemessen in Jahrzehnten. Mainframes haben eine hohe Verfügbarkeit, einer der Hauptgründe für ihre Langlebigkeit, da sie typischerweise in Anwendungen verwendet werden, in denen Ausfallzeiten teuer oder katastrophal wären. Der Begriff Zuverlässigkeit, Verfügbarkeit und Serviceability (RAS) ist ein charakteristisches Merkmal von Mainframe-Computern. Um diese Funktionen zu realisieren, sind eine richtige Planung und Implementierung erforderlich. Darüber hinaus sind Mainframes sicherer als andere Computertypen: die NIST-Verwundbarkeitsdatenbank, US-CERT, bewertet traditionelle Mainframes wie IBM Z (früher z Systems, System z und zSeries) Unisys Dorado und Unisys Libra als eine der sichersten mit Schwachstellen in den niedrigen einzelnen Ziffern im Vergleich zu Tausenden für Windows, UNIX und Linux. Software-Upgrades erfordern in der Regel die Einrichtung des Betriebssystems oder Teile davon und sind nur bei Verwendung von Virtualisierungseinrichtungen wie IBM z/OS und Parallel Sysplex oder Unisys XPCL nicht diskriminierend, die den Workload-Sharing unterstützen, so dass ein System während der Aktualisierung eine andere Anwendung übernehmen kann. In den späten 1950er Jahren hatten Mainframes nur eine rudimentäre interaktive Schnittstelle (die Konsole) und verwendete Sätze von Stanzkarten, Papierband oder Magnetband, um Daten und Programme zu übertragen. Sie arbeiteten im Batch-Modus, um Back-Office-Funktionen wie Payroll und Kundenabrechnung zu unterstützen, von denen die meisten auf wiederholten bandbasierten Sortier- und Verschmelzvorgängen basierten, gefolgt von Liniendrucken bis hin zu vorgedruckten kontinuierlichen Schreibwaren. Als interaktive Benutzerterminals eingeführt wurden, wurden sie fast ausschließlich für Anwendungen (z.B. Airline-Buchung) verwendet, anstatt Programmentwicklung. Typewriter und Teletype-Geräte waren über die frühen 1970er-Jahre gemeinsame Steuerkonsolen für Systembetreiber, obwohl letztlich durch Tastatur/Display-Geräte supplantiert. In den frühen 1970er Jahren erwarb viele Mainframes interaktive Benutzerterminals, die als Timesharing-Computer arbeiten, und unterstützte Hunderte von Benutzern gleichzeitig zusammen mit der Batch-Verarbeitung. Benutzer erhielten Zugriff über Tastatur/Schreiber-Terminals und spezialisierte Text-Terminal CRT-Displays mit integralen Tastaturen, oder später von Personal Computern mit Terminal-Emulationssoftware ausgestattet. In den 1980er Jahren unterstützten viele Mainframes Grafik-Display-Terminals und Terminal-Emulation, aber nicht grafische Benutzeroberflächen. Diese Form der Endbenutzer-Computing wurde in den 1990er Jahren aufgrund des Aufkommens von Personalcomputern mit GUIs veraltet. Nach dem Jahr 2000 haben moderne Mainframes für Endbenutzer für Web-style-Benutzeroberflächen teilweise oder ganz klassische "Grünbildschirm" und Farbdisplay-Terminalzugriffe entwickelt. Die Infrastrukturanforderungen wurden Mitte der 1990er Jahre drastisch reduziert, als CMOS Mainframe-Designs die ältere bipolare Technologie ersetzten. IBM behauptete, dass seine neueren Mainframes die Energiekosten des Rechenzentrums für Strom und Kühlung reduzierten und die physischen Raumanforderungen im Vergleich zu Serverfarmen reduzierten. Eigenschaften Moderne Mainframes können mehrere verschiedene Instanzen von Betriebssystemen gleichzeitig ausführen. Diese Technik von virtuellen Maschinen erlaubt Anwendungen zu laufen, als ob sie auf physikalisch getrennten Computern waren. In dieser Rolle kann ein einziger Mainframe höher funktionierende Hardware-Dienste ersetzen, die konventionellen Servern zur Verfügung stehen. Während Mainframes diese Fähigkeit Pionierarbeit geleistet hat, ist die Virtualisierung jetzt auf den meisten Familien von Computersystemen verfügbar, jedoch nicht immer in gleichem Maße oder in gleichem Maß an Raffinesse. Mainframes können hinzufügen oder Hot-Swap-System-Kapazität, ohne die Systemfunktion zu stören, mit Spezifität und Granularität zu einem Niveau der Raffinesse nicht in der Regel mit den meisten Server-Lösungen zur Verfügung. Moderne Mainframes, insbesondere die IBM zSeries, System z9 und System z10-Server, bieten zwei Ebenen der Virtualisierung: logische Partitionen (LPARs, über die PR/SM-Anlage) und virtuelle Maschinen (über das z/VM-Betriebssystem). Viele Mainframe-Kunden betreiben zwei Maschinen: eine in ihrem primären Rechenzentrum und eine in ihrem Backup-Datenzentrum – voll aktiv, teilweise aktiv oder auf Standby –, falls eine Katastrophe das erste Gebäude beeinflusst. Test-, Entwicklungs-, Schulungs- und Produktionsaufwand für Anwendungen und Datenbanken kann auf einer einzigen Maschine laufen, mit Ausnahme von extrem großen Anforderungen, wo die Kapazität einer Maschine begrenzt sein könnte. Eine solche Zwei-Mainframe-Installation kann einen kontinuierlichen Business-Service unterstützen und sowohl geplante als auch nicht geplante Outages vermeiden. In der Praxis verwenden viele Kunden mehrere Mainframes, die entweder durch Parallel Sysplex und geteiltes DASD (im Fall von IBM) oder mit gemeinsamer, geografisch verteilter Lagerung von EMC oder Hitachi verbunden sind. Mainframes sind entworfen, um sehr hohe Volumeneingabe und -ausgabe (I/O) zu handhaben und Durchsatz-Computing zu betonen. Seit den späten 1950er Jahren haben Mainframe-Designs Tochterhardware (genannte Kanäle oder periphere Prozessoren) enthalten, die die I/O-Geräte verwalten, so dass die CPU frei ist, nur mit High-Speed-Speicher umzugehen. Es ist häufig in den Mainframe-Shops mit massiven Datenbanken und Dateien zu behandeln. Gigabyte to terabyte-size-Datensatzdateien sind nicht ungewöhnlich. Im Vergleich zu einem typischen PC, Mainframes häufig haben Hunderte bis Tausende von Mal so viel Datenspeicher online, und kann auf sie recht schnell zugreifen. Andere Serverfamilien laden auch die I/O-Verarbeitung aus und betonen den Durchsatz Computing. Die Rendite von Mainframe auf Investitionen (ROI), wie jede andere Rechenplattform, ist abhängig von ihrer Fähigkeit, gemischte Arbeitsbelastungen zu skalieren, zu unterstützen, Arbeitskosten zu reduzieren, ununterbrochenen Service für kritische Geschäftsanwendungen zu liefern und mehrere andere risikobereinigte Kostenfaktoren. Mainframes haben auch Ausführung Integrität Eigenschaften für Fehler tolerant Computing. Zum Beispiel führen z900, z990, System z9 und System z10-Server effektiv ergebnisorientierte Anweisungen zweimal aus, vergleichen Ergebnisse, Schieds zwischen irgendwelchen Unterschieden (durch Anleitung Retry und Fehlerisolation), dann verschieben Workloads "in Flug" auf funktionierende Prozessoren, einschließlich Ersatz, ohne Auswirkungen auf Betriebssysteme, Anwendungen oder Benutzer. Diese Hardware-Level-Funktion, auch in HPs NonStop-Systemen gefunden, ist als Lock-Stepping bekannt, weil beide Prozessoren ihre Schritte (d.h. Anweisungen) zusammen nehmen. Nicht alle Anwendungen brauchen unbedingt die gesicherte Integrität, die diese Systeme bieten, aber viele tun, wie die finanzielle Transaktionsverarbeitung. Der aktuelle Markt IBM mit z Systems ist weiterhin ein wichtiger Hersteller im Mainframe-Markt. Im Jahr 2000 entwickelte Hitachi die zSeries z900 mit IBM, um Kosten zu teilen, und die neuesten Hitachi AP10000 Modelle werden von IBM hergestellt. Unisys fertigt ClearPath Libra Mainframes, basierend auf früheren Burroughs MCP-Produkten und ClearPath Dorado Mainframes basierend auf Sperry Univac OS 1100 Produktlinien. Hewlett-Packard verkauft seine einzigartigen NonStop-Systeme, die es mit Tandem Computern erworben hat und die einige Analysten als Mainframes klassifizieren. GCOS, Stratus OpenVOS, Fujitsu (früher Siemens) BS2000 und Fujitsu-ICL VME Mainframes sind in Europa noch verfügbar und Fujitsu (früher Amdahl)GS21 Mainframes weltweit. NEC mit ACOS und Hitachi mit AP10000-VOS3 hält weiterhin Mainframe-Unternehmen auf dem japanischen Markt. Die Höhe der Anbieterinvestitionen in die Hauptrahmenentwicklung variiert mit dem Marktanteil. Fujitsu und Hitachi verwenden weiterhin kundenspezifische S/390-kompatible Prozessoren sowie andere CPUs (einschließlich POWER und Xeon) für Low-End-Systeme. Bull verwendet eine Mischung von Itanium und Xeon Prozessoren. NEC verwendet Xeon Prozessoren für seine Low-End ACOS-2 Linie, entwickelt aber den benutzerdefinierten NOAH-6 Prozessor für seine High-End ACOS-4 Serie. IBM entwickelt auch eigene Prozessoren in-house, wie zEC12. Unisys produziert codekompatibele Mainframe-Systeme, die von Laptops bis zu schrankgroßen Mainframes reichen, die homegrown CPUs sowie Xeon-Prozessoren verwenden. Darüber hinaus gibt es einen Markt für Software-Anwendungen, um die Leistung von Mainframe-Implementierungen zu verwalten. Neben IBM sind in diesem Markt auch BMC, Compuware und CA Technologies zu nennen. Geschichte Mehrere Hersteller und ihre Nachfolger produzierten Mainframe-Computer von den 1950er bis Anfang des 21. Jahrhunderts, mit allmählich abnehmenden Zahlen und einem allmählichen Übergang zur Simulation auf Intel-Chips statt proprietäre Hardware. Die US-Herstellergruppe wurde zunächst als "IBM und die sieben Zwerge" bezeichnet: in der Regel Burroughs, UNIVAC, NCR, Control Data, Honeywell, General Electric und RCA, obwohl einige Listen variierten. Später, mit dem Abgang von General Electric und RCA, wurde es als IBM und BUNCH bezeichnet. IBMs Dominanz wuchs aus ihrer 700/7000 Serie und später die Entwicklung der 360-Serie Mainframes. Letztere Architektur hat sich weiter zu ihren aktuellen zSeries Mainframes entwickelt, die zusammen mit den damals Burroughs und Sperry (jetzt Unisys) MCP-basierten und OS1100 Mainframes zu den wenigen noch extantigen Mainframe-Architekturen gehören, die ihre Wurzeln in dieser frühen Periode verfolgen können. Während IBMs zSeries noch 24 Bit System/360 Code ausführen kann, haben die 64-Bit zSeries und System z9 CMOS Server nichts physikalisch gemeinsam mit den älteren Systemen. Bemerkenswerte Hersteller außerhalb der USA waren Siemens und Telefunken in Deutschland, ICL in Großbritannien, Olivetti in Italien und Fujitsu, Hitachi, Oki und NEC in Japan. Die Länder der Sowjetunion und des Warschauer Paktes produzierten während des Kalten Krieges enge Kopien von IBM-Mainframes; die Serie BESM und Strela sind Beispiele für einen unabhängig gestalteten sowjetischen Computer. Die schrumpfende Nachfrage und der harte Wettbewerb begannen in den frühen 1970er-Jahren eine Ausschüttung auf dem Markt – RCA verkauft an UNIVAC und GE verkaufte sein Geschäft an Honeywell; zwischen 1986 und 1990 wurde Honeywell von Bull ausgekauft; UNIVAC wurde eine Division von Sperry, die später mit Burroughs zu Unisys Corporation im Jahr 1986 vereinigte. Im Jahr 1984 geschätzte Verkäufe von Desktop-Computern $(11.6 Milliarden) übertraf Mainframe-Computer $(11.4 Milliarden) zum ersten Mal. IBM erhielt die überwiegende Mehrheit der Mainframe-Umsätze. In den 1980er-Jahren wuchsen minicomputerbasierte Systeme anspruchsvoller und konnten den unteren Teil der Mainframes verschieben. Diese Computer, manchmal auch Fachcomputer genannt, wurden von der Digital Equipment Corporation VAX-Serie typisiert. 1991 besaß die AT&T Corporation kurz NCR. Während desselben Zeitraums fanden Unternehmen heraus, dass Server auf Basis von Mikrocomputer-Designs zu einem Bruchteil des Akquisitionspreises eingesetzt werden konnten und lokalen Nutzern aufgrund der IT-Richtlinien und -praktiken viel größere Kontrolle über ihre eigenen Systeme bieten. Terminals, die für die Interaktion mit Mainframe-Systemen verwendet wurden, wurden schrittweise durch Personal Computer ersetzt. Infolgedessen wurden die Nachfrage nach neuen Großrechnern vor allem auf Finanzdienstleistungen und Regierung beschränkt. In den frühen 1990er Jahren gab es einen groben Konsens zwischen Industrieanalysten, dass der Mainframe ein sterbender Markt war, da Mainframe-Plattformen zunehmend durch persönliche Computernetze ersetzt wurden. InfoWorld's Stewart Auchp hat berüchtigt vorhergesagt, dass der letzte Mainframe 1996 unplugged werden würde; 1993 zitierte er Cheryl Currid, einen Computer-Industrieanalyst, als er sagte, dass der letzte Mainframe "an Dezember 31, 1999 nicht mehr arbeiten wird", ein Hinweis auf das erwartete Jahr 2000 Problem (Y2K). Dieser Trend begann sich in den späten 1990er-Jahren zu drehen, da Unternehmen neue Nutzungen für ihre bestehenden Mainframes gefunden haben und der Preis der Datenvernetzung in den meisten Teilen der Welt zusammenbrach und die Tendenzen zu einem zentralisierten Computing erfreuen. Das Wachstum des E-Business steigerte auch die Anzahl der von der Mainframe-Software verarbeiteten Back-End-Transaktionen sowie die Größe und Durchsatz von Datenbanken dramatisch. Die Batch-Verarbeitung, wie Abrechnung, wurde noch wichtiger (und größer) mit dem Wachstum von E-Business, und Mainframes sind besonders bei großen Batch-Computing. Ein weiterer Faktor, der derzeit den Mainframe-Einsatz erhöht, ist die Entwicklung des Linux-Betriebssystems, das 1999 auf IBM-Mainframe-Systemen ankam und typischerweise in Scores oder bis zu c. 8.000 virtuelle Maschinen auf einem einzigen Mainframe läuft. Linux ermöglicht es Benutzern, Open Source Software kombiniert mit Mainframe Hardware RAS zu nutzen. Schnelle Expansion und Entwicklung in Schwellenländern, insbesondere in der Volksrepublik China, treibt auch große Mainframe-Investitionen an, um außergewöhnlich schwierige Rechenprobleme zu lösen, z.B. die Bereitstellung einheitlicher, extrem hoher Online-Transaktionsdatenbanken für 1 Milliarde Verbraucher in verschiedenen Branchen (Banking, Versicherung, Kreditberichterstattung, Regierungsdienstleistungen usw.) Ende 2000 führte IBM 64-Bit z/Architecture ein, erwarb zahlreiche Softwareunternehmen wie Cognos und stellte diese Softwareprodukte auf den Mainframe vor. Die vierteljährlichen und jährlichen Berichte von IBM in den 2000er Jahren berichteten in der Regel über steigende Hauptrahmeneinnahmen und Kapazitätsauslastungen. Das Mainframe-Hardwaregeschäft von IBM war jedoch nicht immun gegen den jüngsten Gesamtabschwung im Server-Hardware-Markt oder auf Modellzykluseffekte. Zum Beispiel verringerte sich der Hardwareumsatz von IBM im 4. Quartal 2009 im Vergleich zum Vorjahr um 27%. Aber MIPS (Millionen von Anweisungen pro Sekunde) die Sendungen stiegen in den letzten zwei Jahren um 4% pro Jahr. Auchp hatte sich im Jahr 2000 fotografiert und symbolisch seine eigenen Worte ("Tod des Mainframes") gegessen. 2012 hat die NASA ihren letzten Mainframe, ein IBM System z9, heruntergefahren. IBMs Nachfolger des z9, der z10, führte jedoch einen New York Times Reporter, um vier Jahre früher zu sagen, dass "Mainframe-Technologie – Hardware, Software und Dienstleistungen – ein großes und lukratives Geschäft für I.B.M bleibt, und Mainframes sind immer noch die Back-office-Motoren hinter den Finanzmärkten der Welt und ein Großteil des globalen Handels". Seit 2010, während Mainframe-Technologie weniger als 3% des Umsatzes von IBM, es "Continue[d] eine übergroße Rolle in Big Blues Ergebnissen spielen". Im Jahr 2015 startete IBM die IBM z13, im Juni 2017 die IBM z14 und im September 2019 IBM die neueste Version des Produktes, die IBM z15. Unterschiede von Supercomputern Ein Supercomputer ist ein Computer an der Vorderkante der Datenverarbeitungsfähigkeit, bezogen auf die Berechnungsgeschwindigkeit. Supercomputer werden für wissenschaftliche und technische Probleme (High-Performance Computing) verwendet, die Zahlen und Daten knacken, während Mainframes sich auf die Transaktionsverarbeitung konzentrieren. Die Unterschiede sind: Mainframes werden als zuverlässig für die Transaktionsverarbeitung (gemessen durch TPC-Metriken; nicht verwendet oder hilfreich für die meisten Supercomputing-Anwendungen) gebaut, wie es in der Geschäftswelt allgemein verstanden wird: der Handelsaustausch von Waren, Dienstleistungen oder Geld. Eine typische Transaktion, definiert durch den Transaction Processing Performance Council, aktualisiert ein Datenbanksystem zur Inventarsteuerung (Waren,) Fluggesellschaftenreservierungen (Services,) oder Banking (Geld) durch Hinzufügen eines Datensatzes. Eine Transaktion kann sich auf eine Reihe von Operationen beziehen, einschließlich Festplattenlese/Schreibe, Betriebssystemaufrufe oder eine Form der Datenübertragung von einem Teilsystem zu einem anderen, die nicht durch die Verarbeitungsgeschwindigkeit der CPU gemessen wird. Transaction Processing ist nicht exklusiv für Mainframes, sondern wird auch von Mikroprozessor-basierten Servern und Online-Netzwerken verwendet. Die Supercomputer-Leistung wird in Floating Point-Operationen pro Sekunde (FLOPS) oder in durchlaufenen Kanten pro Sekunde oder TEPS gemessen, Metriken, die für Mainframe-Anwendungen nicht sehr aussagekräftig sind, während Mainframes manchmal in Millionen von Anweisungen pro Sekunde (MIPS) gemessen werden, obwohl die Definition von dem gemessenen Befehlsmix abhängt. Beispiele für ganzzahlige Operationen, die von MIPS gemessen werden, sind das Hinzufügen von Zahlen zusammen, das Überprüfen von Werten oder das Bewegen von Daten um im Speicher (wobei das Bewegen von Informationen zu und von der Speicherung, so genannte I/O ist am hilfreichsten für Mainframes; und innerhalb des Speichers nur indirekt helfen). Floating Point Operationen sind meistens Addition, Subtraktion und Multiplikation (von binärem Floating Point in Supercomputern; gemessen von FLOPS) mit genügender Präzision, um kontinuierliche Phänomene wie Wettervorhersage und nukleare Simulationen (nur kürzlich standardisierte dezimale Floating Point, nicht in Supercomputern verwendet, sind für Geldwerte geeignet, wie sie für Mainframe-Anwendungen nützlich sind). In Bezug auf Rechengeschwindigkeit sind Supercomputer leistungsfähiger. Mainframes und Supercomputer können nicht immer deutlich unterschieden werden; bis Anfang der 1990er Jahre basierten viele Supercomputer auf einer Hauptrahmenarchitektur mit überkomputierenden Erweiterungen. Ein Beispiel für ein solches System ist das HITAC S-3800, das mit IBM System/370 Mainframes kompatibel war und das Hitachi VOS3 Betriebssystem (eine Gabel von IBM MVS) ausführen konnte. Der S-3800 ist daher sowohl gleichzeitig ein Supercomputer als auch ein IBM-kompatibler Mainframe zu erkennen. Im Jahr 2007 hat eine Amalgamation der verschiedenen Technologien und Architekturen für Supercomputer und Mainframes zu einem sogenannten Gameframe geführt. Siehe auch Channel I/OCloud Computing Computer Typen Failover Gameframe List of Transistorized Computers ReferenzenExterne Links Medien im Zusammenhang mit Mainframe-Computern bei Wikimedia Commons IBM Systems Mainframe Magazine IBM z Systems Mainframes IBM Mainframes Computer Support Forum seit 2003Univac 9400, ein Mainframe aus den 1960er Jahren, noch im Einsatz in einem deutschen Computermuseum Vorlesungen in der Geschichte der Computing: Mainframes (archiv)