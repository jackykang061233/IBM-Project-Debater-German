Rendering oder Bildsynthese ist der Prozess der Erzeugung eines photorealistischen oder nicht-photorealistischen Bildes aus einem 2D- oder 3D-Modell mittels eines Computerprogramms. Das resultierende Bild wird als Render bezeichnet. Mehrere Modelle können in einer Szenendatei definiert werden, die Objekte in einer streng definierten Sprache oder Datenstruktur enthält. Die Szenendatei enthält Geometrie-, Ansichts-, Textur-, Beleuchtungs- und Abschattungsinformationen, die die virtuelle Szene beschreiben. Die in der Szenendatei enthaltenen Daten werden dann an ein zu bearbeitendes Rendering-Programm übergeben und an eine digitale Bild- oder Rastergrafikbilddatei ausgegeben. Der Begriff Rendering ist analog zum Konzept eines Künstlers Eindruck einer Szene. Der Begriff Rendering wird auch verwendet, um den Prozess der Berechnung von Effekten in einem Videobearbeitungsprogramm zur Erstellung der endgültigen Videoausgabe zu beschreiben. Rendering ist eine der wichtigsten Subtopiken von 3D-Computergrafiken, und in der Praxis ist es immer mit den anderen verbunden. Es ist der letzte große Schritt in der Grafik-Pipeline, geben Modelle und Animation ihr endgültiges Aussehen. Mit der zunehmenden Raffinesse von Computergrafiken seit den 1970er-Jahren ist es zu einem deutlicheren Thema geworden. Rendering hat Verwendungen in Architektur, Videospiele, Simulatoren, Film- und TV-Visualisierung und Design-Visualisierung, die jeweils eine andere Balance von Funktionen und Techniken. Für den Einsatz stehen eine Vielzahl von Renderern zur Verfügung. Einige sind in größere Modellierungs- und Animationspakete integriert, einige sind eigenständig und einige sind freie Open-Source-Projekte. Im Inneren ist ein Renderer ein sorgfältig konstruiertes Programm, das auf mehreren Disziplinen basiert, einschließlich Lichtphysik, visuelle Wahrnehmung, Mathematik und Software-Entwicklung. Obwohl die technischen Details der Rendering-Methoden variieren, werden die allgemeinen Herausforderungen bei der Erstellung eines 2D-Bildes auf einem Bildschirm aus einer in einer Szenendatei gespeicherten 3D-Darstellung von der Grafikpipeline in einem Rendering-Gerät wie einer GPU behandelt. Eine GPU ist ein zielgerichtetes Gerät, das eine CPU bei der Durchführung komplexer Berechnungen unterstützt. Wenn eine Szene unter virtueller Beleuchtung relativ realistisch und vorhersehbar aussehen soll, muss die Rendering-Software die Rendering-Gleichung lösen. Die Rendering-Gleichung berücksichtigt nicht alle Lichterscheinungen, sondern fungiert als allgemeines Beleuchtungsmodell für computergenerierte Bilder. Im Falle von 3D-Grafiken können Szenen in Echtzeit vorveröffentlicht oder erzeugt werden. Pre-Rendering ist ein langsamer, rechnerisch intensiver Prozess, der typischerweise für die Film-Erstellung verwendet wird, wo Szenen vor der Zeit erzeugt werden können, während Echtzeit-Rendering oft für 3D-Videospiele und andere Anwendungen, die dynamisch Szenen erstellen müssen. 3D-Hardwarebeschleuniger können die Echtzeit-Rendering-Leistung verbessern. Verwendung Wenn das Vorbild (in der Regel eine Drahtrahmenskizze) abgeschlossen ist, wird das Rendern verwendet, das in Bitmap-Texturen oder Verfahrenstexturen, Lichtern, Stoßkartierungen und Relativposition zu anderen Objekten hinzufügt. Das Ergebnis ist ein abgeschlossenes Bild, das der Verbraucher oder der beabsichtigte Zuschauer sieht. Für Filmanimationen müssen mehrere Bilder (Frames) gemacht und in einem Programm zusammengenäht werden, das eine solche Animation machen kann. Die meisten 3D-Bildbearbeitungsprogramme können dies tun. Eigenschaften Unter einem Rendered-Bild kann eine Anzahl von sichtbaren Merkmalen verstanden werden. Die Rendering-Forschung und Entwicklung wurde größtenteils dadurch motiviert, Wege zu finden, diese effizient zu simulieren. Einige beziehen sich direkt auf bestimmte Algorithmen und Techniken, während andere zusammen hergestellt werden. Shading – wie die Farbe und die Helligkeit einer Oberfläche mit der Beleuchtung variiert Texture-Mapping – eine Methode der Anwendung von Detail auf Oberflächen Bump-Mapping – eine Methode der Simulation von kleinskaligen Stoßigkeit auf Oberflächen Fogging/participating Medium – wie Licht bei Durchgang durch unklare Atmosphäre oder Luft Schatten – die Wirkung von Licht behindern Weiche Schatten – variierende Dunkelheit durch teilweise verdeckte Lichtquellen Transluzenz – hoch gestreute Lichtübertragung durch feste Objekte Refraction – Biegung von Licht im Zusammenhang mit der Transparenz Diffraction – Biegung, Ausbreitung und Interferenz von Licht durch ein Objekt oder eine Blende, die die ray Indirect-Beleuchtung stört – Flächen, die durch Licht reflektiert werden, von anderen Oberflächen beleuchtet werden, anstatt direkt von einer Lichtquelle (auch als globale Beleuchtung bezeichnet) Jedes Teilchen des Lichts in einer Szene zu verfolgen ist fast immer völlig unpraktisch und würde eine unangenehme Zeit nehmen. Auch ein so großer Teil, um ein Bild zu erzeugen, verfolgt eine ingeordnete Zeit, wenn die Abtastung nicht intelligent eingeschränkt ist. Daher sind einige lose Familien mit effizienteren Lichttransport-Modellierungstechniken entstanden: Rasterung, einschließlich Scanline-Rendering, geometrisch Projekte Objekte in der Szene zu einer Bildebene, ohne fortgeschrittene optische Effekte; Strahlguss betrachtet die Szene aus einem bestimmten Blickwinkel, Berechnung des beobachteten Bildes nur auf Geometrie und sehr grundlegende optische Gesetze der Reflexionsintensität, und vielleicht mit Monte Carlo-Techniken, um Artefakte zu reduzieren. Die vierte Art der Lichttransporttechnik, Radiosität wird in der Regel nicht als Rendering-Technik ausgeführt, sondern berechnet den Durchgang des Lichts, da es die Lichtquelle verlässt und Oberflächen beleuchtet. Diese Oberflächen werden in der Regel mit einer der anderen drei Techniken zur Anzeige gebracht. Die fortschrittlichste Software kombiniert zwei oder mehr der Techniken, um gute Ergebnisse zu angemessenen Kosten zu erhalten. Eine weitere Unterscheidung ist zwischen Bildauftragsalgorithmen, die über Pixel der Bildebene iterieren, und Objektauftragsalgorithmen, die über Objekte in der Szene iterieren. Im Allgemeinen ist Objektauftrag effizienter, da es in der Regel weniger Objekte in einer Szene als Pixel gibt. Eine hochrangige Darstellung eines Bildes enthält zwangsläufig Elemente in einer anderen Domäne von Pixeln. Diese Elemente werden als Primitiven bezeichnet. In einer schematischen Zeichnung können beispielsweise Liniensegmente und Kurven primitiv sein. In einer grafischen Benutzeroberfläche können Fenster und Tasten die Primitiven sein. Beim Rendern von 3D-Modellen könnten Dreiecke und Polygone im Raum Primitiven sein. Ist ein Pixel-by-Pixel (Bildauftrag)-Ansatz zum Rendern für eine bestimmte Aufgabe unpraktisch oder zu langsam, so kann sich ein primitiv-by-primitive (Objektauftrag)-Ansatz zum Rendern als nützlich erweisen. Dabei wird durch jedes der Primitiven eine Schleife ermittelt, welche Pixel in dem von ihm beeinflussten Bild und diese Pixel entsprechend modifiziert werden. Dies wird als Rasterung bezeichnet und ist das Rendering-Verfahren, das von allen aktuellen Grafikkarten verwendet wird. Rasterung ist häufig schneller als Pixel-by-Pixel-Rendering. Erstens können große Bereiche des Bildes von Primitiven leer sein; die Rasterung ignoriert diese Bereiche, aber Pixel-by-Pixel-Rendering muss sie durch. Zweitens kann die Rasterung die Cache-Kohärenz verbessern und redundante Arbeit reduzieren, indem die Tatsache ausgenutzt wird, dass die von einem einzelnen Primitiv besetzten Pixel im Bild eher zusammenhängend sind. Aus diesen Gründen ist die Rasterung in der Regel der Ansatz der Wahl, wenn eine interaktive Wiedergabe erforderlich ist; der Pixel-by-Pixel-Ansatz kann jedoch oft hochwertige Bilder produzieren und ist vielseitiger, weil es nicht von so vielen Annahmen über das Bild als Rasterung abhängt. Die ältere Form der Rasterung zeichnet sich dadurch aus, dass ein ganzes Gesicht (primitive) als eine einzige Farbe dargestellt wird. Alternativ kann die Rasterung auf kompliziertere Weise erfolgen, indem zunächst die Vertikale eines Gesichts dargestellt und dann die Pixel dieses Gesichts als Blendung der Scheitelfarben dargestellt werden. Diese Version der Rasterung hat die alte Methode überholt, da sie es ermöglicht, die Grafiken ohne komplizierte Texturen zu fließen (ein rasterisiertes Bild, wenn Gesicht von Gesicht verwendet, neigt dazu, einen sehr blockartigen Effekt zu haben, wenn nicht in komplexen Texturen abgedeckt; die Gesichter sind nicht glatt, weil es keine allmähliche Farbänderung von einem primitiven zum nächsten gibt). Diese neuere Methode der Rasterung nutzt die mehr besteuernden Shading-Funktionen der Grafikkarte und erreicht immer noch eine bessere Leistung, da die einfacheren Texturen im Speicher gespeichert weniger Platz verwenden. Manchmal werden Designer auf einigen Gesichtern und der anderen Methode auf andere Weise eine Rasterungmethode verwenden, basierend auf dem Winkel, in dem dieses Gesicht auf andere gefügte Gesichter trifft, wodurch die Geschwindigkeit erhöht und die Gesamtwirkung nicht verletzt. Ray Casting Beim Strahlgießen wird die modellierte Geometrie durch Pixel, Zeile für Zeile, aus dem Blickwinkel nach außen, wie beim Ausgießen von Strahlen aus dem Blickwinkel gespart. Wird ein Objekt durchschnitten, kann der Farbwert an der Stelle anhand mehrerer Methoden ausgewertet werden. Im einfachsten wird der Farbwert des Objekts am Schnittpunkt zum Wert dieses Pixels. Die Farbe kann aus einer Texturkarte ermittelt werden. Ein ausgefeilteres Verfahren besteht darin, den Farbwert um einen Beleuchtungsfaktor zu ändern, ohne jedoch die Beziehung zu einer simulierten Lichtquelle zu berechnen. Um Artefakte zu reduzieren, kann eine Anzahl von Strahlen in leicht unterschiedlichen Richtungen gemittelt werden. Ray Casting beinhaltet die Berechnung der "Ansichtsrichtung" (aus der Kameraposition), und inkrementell darauf folgend entlang dieser "Strahlung" durch "feste 3d Objekte" in der Szene, während die Ansammlung des resultierenden Wertes von jedem Punkt in 3D Raum. Dies ist mit der "Strahlenverfolgung" verbunden, mit der Ausnahme, dass die Raycast wird in der Regel nicht abgestrahlt Oberflächen (wo die "Strahlenverfolgung" anzeigt, dass sie den Lichtpfad einschließlich Pratzen ausführt)."Ray Casting" bedeutet, dass der Lichtstrahl einem geraden Weg folgt (was auch das Fahren durch semitransparente Objekte umfassen kann). Der Strahl ist ein Vektor, der von der Kamera oder vom Szenenendpunkt ("Back to front", oder "Front nach hinten") stammen kann. Manchmal wird der Endlichtwert von einer "Übertragungsfunktion" abgeleitet und manchmal direkt verwendet. Auch rauhe Simulationen optischer Eigenschaften können eingesetzt werden: Es wird eine einfache Berechnung des Strahls vom Objekt zum Standpunkt vorgenommen. Eine weitere Berechnung erfolgt aus dem Einfallswinkel von Lichtstrahlen aus der Lichtquelle(n) und aus diesen sowie den angegebenen Intensitäten der Lichtquellen wird der Wert des Pixels berechnet. Eine andere Simulation verwendet die von einem Radiosity-Algorithmus aufgetragene Beleuchtung oder eine Kombination dieser beiden. Ray Tracing Ray Tracing zielt darauf ab, den natürlichen Lichtstrom zu simulieren, der als Partikel interpretiert wird. Oft werden Ray-Tracing-Methoden verwendet, um die Lösung auf die Rendering-Gleichung durch Anwendung von Monte Carlo-Methoden darauf anzunähern. Einige der am häufigsten verwendeten Methoden sind Pfadverfolgung, bidirektionale Wegverfolgung oder Metropolis Lichttransport, aber auch semi realistische Methoden sind im Einsatz, wie Whitted Style Ray Tracing oder Hybriden. Während die meisten Implementierungen Licht auf geraden Linien propagieren lassen, existieren Anwendungen, um relativistische Raumzeiteffekte zu simulieren. In einem abschließenden, produktionsgütigen Rendering eines ray-tracked-Arbeit werden in der Regel mehrere Strahlen für jeden Pixel erschossen und nicht nur auf das erste Objekt der Schnittlinie, sondern durch eine Reihe von sequentiellen Bounces, mit den bekannten Gesetzen der Optik wie "Winkel der Inzidenz gleich Winkel der Reflexion" und fortschrittlichere Gesetze, die mit Brechung und Oberflächenrauhigkeit umgehen. Wenn der Strahl entweder auf eine Lichtquelle trifft, oder wahrscheinlich erst einmal eine eingestellte Begrenzungszahl von Bounces ausgewertet wurde, wird die Oberflächenbeleuchtung an diesem Endpunkt anhand der oben beschriebenen Techniken ausgewertet und die Veränderungen entlang des Weges durch die verschiedenen Bounces ausgewertet, um einen am Standpunkt beobachteten Wert abzuschätzen. Dies wird für jede Probe für jedes Pixel wiederholt. Bei der Verteilungsstrahlenfolge können an jedem Kreuzungspunkt mehrere Strahlen ausgestrahlt werden. In der Pfadverfolgung wird jedoch nur ein einziger Strahl oder keiner an jeder Kreuzung gefeuert, wobei die statistische Natur der Monte Carlo-Experimente genutzt wird. Als Brute-Kraft-Methode ist die Ray-Tracing zu langsam gewesen, um für Echtzeit zu betrachten, und bis vor kurzem zu langsam sogar für kurze Filme jeglicher Qualität zu betrachten, obwohl es für spezielle Effekte Sequenzen verwendet wurde, und in der Werbung, wo ein kurzer Teil von hoher Qualität (perhaps sogar photorealistische) Aufnahmen erforderlich ist. Die Anstrengungen zur Optimierung der Anzahl der Berechnungen, die in Teilen eines Werkes benötigt werden, bei denen das Detail nicht hoch ist oder nicht von den Strahlverfolgungsmerkmalen abhängt, haben jedoch zu einer realistischen Möglichkeit der breiteren Anwendung der Strahlverfolgung geführt. Es gibt nun einige Hardware-beschleunigte Ray-Tracing-Geräte, zumindest in der Prototyp-Phase, und einige Spieldemos, die Verwendung von Echtzeit-Software oder Hardware-Ray-Tracing zeigen. Radiosity Radiosity ist ein Verfahren, das versucht, die Art zu simulieren, wie direkt beleuchtete Oberflächen als indirekte Lichtquellen wirken, die andere Oberflächen beleuchten. Dadurch entsteht eine realistischere Schattierung und scheint das Ambiente einer Indoor-Szene besser zu erfassen. Ein klassisches Beispiel ist die Art, wie Schatten die Ecken der Räume umarmen. Die optische Basis der Simulation ist, dass ein Teil diffuses Licht von einem bestimmten Punkt auf einer bestimmten Oberfläche in einem großen Spektrum von Richtungen reflektiert wird und den Bereich um sie leuchtet. Die Simulationstechnik kann in der Komplexität variieren. Viele Renderings haben eine sehr grobe Schätzung der Radiosität, einfach beleuchten eine ganze Szene sehr leicht mit einem Faktor als Ambiente bekannt. Wenn jedoch fortgeschrittene Radiosity-Schätzung mit einem hochwertigen Ray-Tracing-Algorithmus gekoppelt ist, können Bilder überzeugende Realismus, insbesondere für Indoor-Szenen, zeigen. Bei fortschrittlicher Radiosity-Simulation stoßen wiederkehrende, endliche Elementalgorithmen zwischen Oberflächen im Modell hin und her, bis eine gewisse Rekursionsgrenze erreicht ist. Die Färbung einer Oberfläche beeinflusst auf diese Weise die Färbung einer benachbarten Oberfläche und umgekehrt. Die resultierenden Beleuchtungswerte während des Modells (manchmal auch für Leerräume) werden gespeichert und bei Berechnungen in einem Strahl- oder Strahl-Tracing-Modell als zusätzliche Eingaben verwendet. Aufgrund der iterativen/rekursiven Natur der Technik sind komplexe Objekte besonders langsam nachempfunden. Vor der Standardisierung der schnellen Radiosity-Berechnung nutzten einige digitale Künstler eine Technik, die lose als falsche Radiosität bezeichnet wurde, indem sie Bereiche von Texturkarten entsprechend Ecken, Gelenken und Vertiefungen verdunkelten und über Selbstillumination oder diffuse Kartierung für Scanline-Rendering aufbringt. Selbst jetzt können fortschrittliche Radiosity-Berechnungen für die Berechnung des Ambientes des Raumes, von dem Licht, das von Wänden, Boden und Decke reflektiert wird, reserviert werden, ohne den Beitrag zu untersuchen, den komplexe Objekte zur Radiosität leisten – oder komplexe Objekte können in der Radiosity-Berechnung durch einfachere Objekte ähnlicher Größe und Textur ersetzt werden. Radiosity-Berechnungen sind ein unabhängiger Blickpunkt, der die beteiligten Berechnungen erhöht, aber sie nützlich für alle Standpunkte macht. Wenn es in der Szene wenig Umlagerung von Radiosity-Objekten gibt, können die gleichen Radiosity-Daten für eine Reihe von Frames wiederverwendet werden, so dass die Radiosität eine effektive Möglichkeit zur Verbesserung der Flachheit des Strahlgusses ist, ohne den gesamten Rendering-Zeit-per-Rahmen ernsthaft zu beeinflussen. Aus diesem Grund ist Radiosity eine Hauptkomponente führender Echtzeit-Rendering-Methoden und wurde von Anfang bis Ende verwendet, um eine große Anzahl bekannter neuer, animierter 3D-Cartoon-Filme zu erstellen. Probenahme und Filterung Ein Problem, mit dem sich jedes Rendering-System beschäftigen muss, egal welcher Ansatz es nimmt, ist das Probenahmeproblem. Im Wesentlichen versucht der Rendervorgang, eine kontinuierliche Funktion von Bildraum zu Farben durch eine endliche Anzahl von Pixeln darzustellen. Als Folge des Nyquist–Shannon-Samplingtheorem (oder Kotelnikov Theorem) muss jede räumliche Wellenform, die angezeigt werden kann, aus mindestens zwei Pixeln bestehen, die proportional zur Bildauflösung ist. Einfacher ausgedrückt, drückt dies die Idee aus, dass ein Bild keine Details, Peaks oder Mulden in Farbe oder Intensität anzeigen kann, die kleiner als ein Pixel sind. Wenn ein naiver Rendering-Algorithmus ohne Filterung verwendet wird, werden hohe Frequenzen in der Bildfunktion zu hässlichen Aliasings im Endbild führen. Aliasing manifestiert sich typischerweise als Jaggies, oder geklemmte Kanten an Objekten, an denen das Pixelraster sichtbar ist. Um Aliasing zu entfernen, müssen alle Rendering-Algorithmen (wenn sie gut aussehende Bilder erzeugen sollen) eine Art Tiefpassfilter auf der Bildfunktion verwenden, um hohe Frequenzen zu entfernen, ein Prozess namens Antialiasing. Optimierung Durch die Vielzahl von Berechnungen wird in der Regel nur eine Arbeit im Gange gemacht, die dem Teil der Arbeit entspricht, der zu einem bestimmten Zeitpunkt entwickelt wird, so dass in den Anfangsstadien der Modellierung, des Drahtrahmens und des Strahlgusses verwendet werden kann, auch wenn die Zielleistung mit Funkfrequenz verfolgt wird. Es ist auch üblich, nur Teile der Szene in hohem Detail zu machen und Objekte zu entfernen, die für das, was derzeit entwickelt wird, nicht wichtig sind. Für Echtzeit ist es angebracht, eine oder mehrere häufige Approximationen zu vereinfachen und auf die genauen Parameter der betreffenden Szenerie abzustimmen, die auch auf die vereinbarten Parameter abgestimmt ist, um den „Bang für den Buck“ zu erhalten. Wissenschaftlicher Kern Die Implementierung eines realistischen Renderers hat immer einige grundlegende Elemente der physikalischen Simulation oder Emulation – einige Berechnung, die einem realen physikalischen Prozess ähnelt oder abstrahiert. Der Begriff "physikalisch basiert" bezeichnet die Verwendung von physikalischen Modellen und Approximationen, die allgemeiner und allgemeiner außerhalb des Renderings akzeptiert sind. In der Rendering-Gemeinschaft sind nach und nach eine bestimmte Reihe von verwandten Techniken etabliert. Die Grundkonzepte sind mäßig einfach, aber unzugänglich zu berechnen; und ein einziger eleganter Algorithmus oder Ansatz wurde für allgemeinere Zwecke Renderer eluiert. Um Anforderungen an Robustheit, Genauigkeit und Praxis zu erfüllen, wird eine Implementierung eine komplexe Kombination verschiedener Techniken sein. Die Rendering-Forschung befasst sich sowohl mit der Anpassung von wissenschaftlichen Modellen als auch mit ihrer effizienten Anwendung. Die Rendering-Gleichung Dies ist das zentrale akademische/theoretische Konzept im Rendering. Es dient als die abstraktste formale Ausdrucksform des nicht wahrnehmbaren Aspekts des Renderns. Alle vollständigeren Algorithmen sind als Lösungen für bestimmte Formulierungen dieser Gleichung zu erkennen. L o ( x , w → ) = L e ( x , w → ) Ω f r ( x , w → ', w → ) L i ( x , w → ' ) ( w → ')) - Ja. Bedeutung: Das ausgehende Licht (Lo) ist an einer bestimmten Position und Richtung die Summe des emittierten Lichts (Le) und des reflektierten Lichts. Das reflektierte Licht ist die Summe des ankommenden Lichts (Li) aus allen Richtungen, multipliziert mit der Oberflächenreflexion und dem ankommenden Winkel. Durch die Verbindung von Licht nach Licht nach innen, über einen Interaktionspunkt, steht diese Gleichung für den gesamten "Lichttransport" – all die Bewegung des Lichts – in einer Szene. Die bidirektionale Reflexionsverteilungsfunktion Die bidirektionale Reflexionsverteilungsfunktion (BRDF) drückt ein einfaches Modell der Lichtinteraktion mit einer Oberfläche wie folgt aus: f r ( x , w → , w → ) = d L r ( x , w → ) L i ( x , w → ) - Ja. Lichtinteraktion wird oft von den noch einfacheren Modellen angenähert: diffuse Reflexion und spekulative Reflexion, obwohl beide ALSO BRDFs sein können. Geometrische Optik Rendering beschäftigt sich praktisch ausschließlich mit dem Teilchenaspekt der Lichtphysik – bekannt als geometrische Optik. Das Behandeln von Licht auf seiner Grundebene, da sich Partikel umwerfen, ist eine Vereinfachung, aber zweckmäßig: Die Wellenaspekte des Lichts sind in den meisten Szenen vernachlässigbar und sind wesentlich schwieriger zu simulieren. Bemerkenswerte Wellenaspektphänomene umfassen Beugung (wie in den Farben von CDs und DVDs) und Polarisation (wie in LCDs gesehen). Beide Wirkungsarten werden, falls erforderlich, durch bildorientierte Anpassung des Reflexionsmodells bewirkt. Visuelle Wahrnehmung Obwohl sie weniger Aufmerksamkeit erhält, ist ein Verständnis der menschlichen visuellen Wahrnehmung wertvoll für das Rendern. Dies liegt vor allem daran, dass Bilddarstellungen und menschliche Wahrnehmung eingeschränkte Reichweiten haben. Ein Renderer kann eine breite Palette von Lichthelligkeit und Farbe simulieren, aber aktuelle Displays – Filmbildschirm, Computermonitor usw. – können nicht so viel handhaben, und etwas muss verworfen oder komprimiert werden. Die menschliche Wahrnehmung hat auch Grenzen, und so muss man nicht großformatige Bilder zur Verwirklichung des Realismus geben. Dies kann dazu beitragen, das Problem des Anpassens von Bildern in Displays zu lösen, und darüber hinaus vorschlagen, welche Kurzschnitte in der Rendering-Simulation verwendet werden könnten, da gewisse Feinheiten nicht spürbar werden. Dieses verwandten Thema ist Ton Mapping. Die für das Rendern verwendete Mathematik umfasst: lineare Algebra, Kalkül, numerische Mathematik, Signalverarbeitung und Monte Carlo Methoden. Die Renderung von Filmen erfolgt oft auf einem Netzwerk von eng verbundenen Computern, die als Renderfarm bekannt sind. Der aktuelle Stand der Technik in der 3-D-Bildbeschreibung für die Filmerstellung ist die Mental Ray Szenenbeschreibungssprache, die auf Mental Images und RenderMan Shading Language entwickelt wurde, die auf Pixar (vergleiche mit einfacheren 3D-Dateiformaten wie VRML oder APIs wie OpenGL und DirectX, die auf 3D-Hardwarebeschleuniger zugeschnitten sind). Andere Renderer (einschließlich proprietäre) können und werden manchmal verwendet, aber die meisten anderen Renderer neigen dazu, eine oder mehrere der oft benötigten Eigenschaften wie gute Texturfilterung, Textur-Caching, programmierbare Shader, Highend-Geometrietypen wie Haare, Unterteilung oder Pflegeflächen mit Tesselung auf Anfrage, Geometrie-Caching, Raytracing mit Geometrie-Caching, hochwertige Schatten-Karten, Geschwindigkeit oder patentfreie Implementierungen zu verpassen. Andere hochbegehrte Features in diesen Tagen können interaktive photorealistische Rendering (IPR) und Hardware Rendering/Shading enthalten. Chronologie wichtiger veröffentlichter Ideen Siehe auch Referenzen Weiter lesen Externe Links GPU Rendering Magazine, online CGI Magazin über Vorteile von GPU Rendering SIGGRAPH – die ACMs spezielle Interessengruppe in Grafiken – die größte akademische und professionelle Vereinigung und Konferenz Liste der Links zu (anständig, ab 2004) siggraph papers (und einige andere) im Web