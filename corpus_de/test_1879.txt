In der Informatik- und Betriebsforschung ist ein memetischer Algorithmus (MA) eine Erweiterung des traditionellen genetischen Algorithmus. Es verwendet eine lokale Suchtechnik, um die Wahrscheinlichkeit der vorzeitigen Konvergenz zu reduzieren. Memetische Algorithmen stellen einen der jüngsten wachsenden Forschungsgebiete in der evolutionären Berechnung dar. Der Begriff MA wird heute weit verbreitet als Synergie der evolutionären oder jeder bevölkerungsbasierten Ansatz mit separaten individuellen Lern- oder lokalen Verbesserungsverfahren für die Problemsuche verwendet. Oft werden auch MAs in der Literatur als Baldwinische evolutionäre Algorithmen (EAs,) Lamarckian EAs, kulturelle Algorithmen oder genetische lokale Suche bezeichnet. Einführung Inspiriert von beiden Darwinischen Prinzipien der natürlichen Evolution und Dawkins' Vorstellung einer Meme, wurde der Begriff memetische Algorithmus (MA) von Pablo Moscato in seinem technischen Bericht 1989 eingeführt, in dem er MA als nahe an einer Form von bevölkerungsbasierten hybriden genetischen Algorithmus (GA) betrachtete, die mit einem individuellen Lernverfahren in der Lage ist, lokale Verfeinerungen durchzuführen. Die metaphorischen Parallelen einerseits zur Darwinischen Evolution und andererseits zwischen Memes und Domänen-spezifischen (lokalen Suche) Heuristiken werden in memetischen Algorithmen erfasst und stellen somit eine Methodik dar, die sich gut zwischen Allgemeinheit und Problemspezifität ausgleicht. Diese zweistufige Natur macht sie zu einem besonderen Fall der zweiphasigen Evolution. In einem vielfältigeren Kontext werden nun memetische Algorithmen unter verschiedenen Namen verwendet, darunter hybride evolutionäre Algorithmen, Baldwinische evolutionäre Algorithmen, lamarckische evolutionäre Algorithmen, kulturelle Algorithmen oder genetische lokale Suche. Im Rahmen einer komplexen Optimierung wurden viele unterschiedliche Momentiationen von memetischen Algorithmen über eine Vielzahl von Anwendungsdomänen berichtet, im Allgemeinen konvergieren zu qualitativ hochwertigen Lösungen effizienter als ihre herkömmlichen evolutionären Gegenstücke. Im Allgemeinen wird die Verwendung der Ideen der Memetik in einem rechnerischen Rahmen als memetic Computing oder memetic Computation (MC) bezeichnet. Mit MC werden die Eigenschaften des universellen Darwinismus besser erfasst. In dieser Perspektive betrachtet, ist MA ein eingeschränkter Begriff von MC. Insbesondere deckt MA einen Bereich von MC ab, insbesondere mit Bereichen evolutionärer Algorithmen, die andere deterministische Verfeinerungstechniken zur Lösung von Optimierungsproblemen heiraten. MC erweitert den Begriff der Meme um konzeptionelle Entitäten von wissensverstärkten Verfahren oder Repräsentationen. Die Entwicklung der MAs 1. Generation Die erste Generation von MA bezieht sich auf Hybridalgorithmen, eine Ehe zwischen einer bevölkerungsbasierten globalen Suche (oft in Form eines evolutionären Algorithmus) und einer kulturellen evolutionären Phase. Diese erste Generation von MA umfasst zwar Merkmale der kulturellen Evolution (in Form der lokalen Verfeinerung) im Suchzyklus, kann es nicht als echtes weiterentwickelndes System nach universellem Darwinismus qualifizieren, da alle Kernprinzipien der Vererbung/memetischen Übertragung, Variation und Auswahl fehlen. Dies deutet darauf hin, warum der Begriff MA bei der ersten Einführung Kritiken und Kontroversen unter den Forschern aufwies. Pseudocode Prozedur Memetic Algorithm Initialize: Generieren Sie eine anfängliche Bevölkerung; während die Stoppbedingungen nicht zufrieden sind, bewerten Sie alle Individuen in der Bevölkerung. Entwickeln Sie eine neue Bevölkerung mit stochastischen Suchoperatoren. Wählen Sie die Untermenge von Individuen, Ω i l {\displaystyle \Omega _{il}, die das individuelle Verbesserungsverfahren durchlaufen sollte. für jedes Individuum in Ω i l {\displaystyle \Omega _{il} Individuelles Lernen mit Meme(en) mit Frequenz oder Wahrscheinlichkeit von f i l {\displaystyle f_{il} ausführen, für einen Zeitraum von t i l {\displaystyle t_{il} . Fahren Sie mit Lamarckian oder Baldwinian lernen. Ende für Ende während 2. Generation Multi-Meme, hyper-heuristische und meta-Lamarckian MA werden als zweite Generation MA bezeichnet, die die Prinzipien der memetischen Übertragung und Auswahl in ihrem Design zeigt. Bei Multi-Meme MA wird das memetische Material als Teil des Genotyps kodiert. Anschließend wird dann die decodierte Meme jedes einzelnen/Chromosoms zur Durchführung einer lokalen Ausgestaltung verwendet. Das memetische Material wird dann durch einen einfachen Vererbungsmechanismus von Eltern zu Nachkommen übertragen. Auf der anderen Seite, in hyper-heuristischen und meta-Lamarckian MA, wird der Pool von Kandidaten-Memes betrachtet konkurrieren, basierend auf ihren früheren Verdienste bei der Erzeugung von lokalen Verbesserungen durch einen Belohnungsmechanismus, entscheiden, auf welcher Meme ausgewählt werden, um für zukünftige lokale Verfeinerungsprozesse. Memes mit einer höheren Belohnung haben eine größere Chance, repliziert oder kopiert zu werden. Für eine Überprüfung der zweiten Generation MA, d.h. MA in Anbetracht mehrerer individueller Lernmethoden innerhalb eines evolutionären Systems, wird der Leser angesprochen. 3. Generation Co-Evolution und selbsterzeugende MAs können als 3. Generation MA angesehen werden, wenn alle drei Prinzipien berücksichtigt wurden, die die Definitionen eines zugrundeliegenden Systems erfüllen. Im Gegensatz zur 2. Generation MA, die davon ausgeht, dass die zu verwendenden Meme a priori bekannt sind, nutzt die 3. Generation MA eine regelbasierte lokale Suche, um Kandidatenlösungen innerhalb des evolutionären Systems zu ergänzen, so dass regelmäßig wiederholte Merkmale oder Muster im Problemraum erfasst werden. Einige Designhinweise Die Häufigkeit und Intensität des einzelnen Lernens definieren unmittelbar den Grad der Evolution (Exploration) gegen individuelles Lernen (Exploitation) in der MA-Suche, nach einem bestimmten festen begrenzten Rechenbudget. Offensichtlich bietet ein intensiveres individuelles Lernen eine größere Chance auf Konvergenz der lokalen Optima, begrenzt jedoch die Höhe der Evolution, die ohne übermäßige Rechenressourcen beschleunigt werden kann. Daher sollte bei der Einstellung dieser beiden Parameter darauf geachtet werden, den zur Erreichung der maximalen Suchleistung verfügbaren Rechenbudget auszugleichen. Wenn nur ein Teil der Bevölkerung Individuen lernen, die Frage, welche Teilmenge von Individuen zu verbessern, muss berücksichtigt werden, um das Nutzen von MA-Suche zu maximieren. Letztens aber nicht zuletzt begünstigt auch die verwendete individuelle Lernprozedur/Meme eine andere Nachbarschaftsstruktur, so dass die Notwendigkeit zu entscheiden, welche Meme oder Memes für ein gegebenes Optimierungsproblem zur Hand benötigt werden. Wie oft sollte individuelles Lernen angewendet werden? Eines der ersten Probleme im Zusammenhang mit der memetischen Algorithmus-Design ist, zu prüfen, wie oft das individuelle Lernen angewendet werden sollte, d.h. individuelle Lernfrequenz. In einem Fall wurde die Wirkung der einzelnen Lernfrequenz auf die MA-Suchleistung in Betracht gezogen, wo verschiedene Konfigurationen der einzelnen Lernfrequenz bei unterschiedlichen Stadien der MA-Suche untersucht wurden. Umgekehrt wurde an anderer Stelle gezeigt, dass es sinnvoll sein kann, jedes einzelne Lernen anzuwenden, wenn die rechnerische Komplexität des einzelnen Lernens relativ gering ist. Auf welchen Lösungen sollte individuelles Lernen angewendet werden? Zur Frage der Auswahl geeigneter Individuen unter der EA-Bevölkerung, die individuelle Lern-, Fitness- und Distributions-basierte Strategien unterziehen sollten, wurden untersucht, um die Wahrscheinlichkeit der Anwendung des individuellen Lernens auf die Population von Chromosomen in ständigen parametrischen Suchproblemen mit Land erweitert die Arbeit auf kombinatorische Optimierungsprobleme. Bambha et al. führte eine simulierte Heiztechnik ein, um parametrisiertes individuelles Lernen systematisch in evolutionäre Algorithmen zu integrieren, um eine maximale Lösungsqualität zu erreichen. Wie lange sollte individuelles Lernen laufen? Individuelle Lernintensität, t i l '\displaystyle t_{il}, ist der Betrag des Rechenbudgets, der einer Iteration des individuellen Lernens zugewiesen wird; d.h. der maximale Rechenbudget, der dem individuellen Lernen ermöglicht wird, die Verbesserung einer einzigen Lösung auszuschließen. Welche individuelle Lernmethode oder Meme sollte für ein bestimmtes Problem oder Einzelperson verwendet werden? Im Rahmen einer kontinuierlichen Optimierung besteht individuelles Lernen in Form von lokalen Heuristiken oder konventionellen exakten enumerativen Methoden. Beispiele für individuelle Lernstrategien sind das Bergsteigen, Simplex-Verfahren, Newton/Quasi-Newton-Verfahren, Innenpunkt-Methoden, Konjugate-Gradienten-Methode, Liniensuche und andere lokale Heuristiken. Beachten Sie, dass die meisten gemeinsamen individuellen Lernmethoden deterministisch sind. Bei der kombinatorischen Optimierung existieren dagegen häufig einzelne Lernmethoden in Form von Heuristiken (die deterministisch oder stochastisch sein können), die auf ein bestimmtes Interessesproblem zugeschnitten sind. Typische heuristische Verfahren und Schemata umfassen den k-Gen-Austausch, den Kantenaustausch, die Erstverbesserung und viele andere. Anwendungen Memetische Algorithmen wurden erfolgreich auf eine Vielzahl von realen Problemen angewendet. Obwohl viele Menschen Techniken eng mit memetischen Algorithmen beschäftigen, werden auch alternative Namen wie hybride genetische Algorithmen verwendet. Darüber hinaus bezeichnen viele Menschen ihre memetischen Techniken als genetische Algorithmen. Forscher haben memetische Algorithmen verwendet, um viele klassische NP-Probleme anzugehen. Einige von ihnen zu zitieren: Graph-Partitionierung, mehrdimensionale knapsack, Reiseverkäufer-Problem, quadratische Zuordnung Problem, setzen Abdeckung Problem, minimale Graph-Färbung, max unabhängige Set Problem, bin Pack Problem, und allgemeine Zuordnung Problem. Neuere Anwendungen umfassen (aber nicht beschränkt auf) Business-Analysen und Datenwissenschaft, Ausbildung von künstlichen neuronalen Netzwerken, Mustererkennung, Roboterbewegungsplanung, Strahlorientierung, Schaltungsgestaltung, elektrische Service-Restaurierung, medizinische Experten-Systeme, Ein-Maschinen-Scheduling, automatische Zeiterfassung (vor allem der Zeitplan für die NHL,) Manpower-Scheduling, Krankenschwester-Optimierung, Prozessor-Zuordnung, Wartungsplanung, Wartungsplanung Aktuelle Aktivitäten in memetischen Algorithmen IEEE Workshop zu Memetic Algorithms (WOMA 2009). Program Chairs: Jim Smith, University of the West of England, U.K; Yew-Soon Ong, Nanyang Technological University, Singapore; Gustafson Steven, University of Nottingham; U.K.;Meng Hiot Lim, Nanyang Technological University, Singapore; Natalio Krasnogor, University of Nottingham, U.K. Besonderes Thema "Emerging Trends in Soft Computing - Memetic Algorithm", Soft Computing Journal, abgeschlossen & In Press, 2008.IEEE Computational Intelligence Society Emergent Technologies Task Force on Memetic Computing IEEE Congress on Evolutionary Computation (CEC 2007,) Singapur, Special Session on Memetic Algorithms. "Memetic Computing" von Thomson Scientific's Essential Science Indicators als aufstrebender Front Research Area. Sonderausgabe zu Memetic Algorithms, IEEE Transactions on Systems, Man und Cybernetics - Teil B: Cybernetics, Vol.37, No. 1, Februar 2007. Aktuelle Fortschritte in den Memetischen Algorithmen, Reihe: Studien in Fuzziness und Soft Computing, Vol.166, ISBN 978-3-540-22904-9, 2005.Special Issue on Memetic Algorithms, Evolutionary Computation Fall 2004, Vol.12, No. 3: v-vi. =References ===