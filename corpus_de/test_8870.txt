Textbergbau, auch Textdatenbergbau genannt, ähnlich Textanalyse, ist der Prozess der Ableitung hochwertiger Informationen aus Text. Es beinhaltet "die Entdeckung durch Computer neuer, bisher unbekannter Informationen, indem automatisch Informationen aus verschiedenen schriftlichen Ressourcen extrahiert werden. "Geschriebene Ressourcen können Webseiten, Bücher, E-Mails, Bewertungen und Artikel enthalten. Qualitativ hochwertige Informationen werden typischerweise durch die Gestaltung von Mustern und Trends mittels statistischem Musterlernen gewonnen. Laut Hotho et al.(2005) können wir drei verschiedene Perspektiven des Textbergbaus unterscheiden: Informationsgewinnung, Datenbergbau und KDD (Knowledge Discovery in Databases) Prozess. Der Textbergbau umfasst in der Regel den Prozess der Strukturierung des Eingabetextes (in der Regel Parsing, zusammen mit der Hinzufügung einiger abgeleiteter sprachlicher Merkmale und der Entfernung anderer, und anschließende Einfügung in eine Datenbank), der Muster innerhalb der strukturierten Daten abgibt, und schließlich die Auswertung und Interpretation der Ausgabe. "High Quality" im Textbergbau bezieht sich in der Regel auf eine Kombination von Relevanz, Neuheit und Interesse. Typische Textabbauaufgaben umfassen Textkategorisierung, Text-Clustering, Konzept/Tentity-Extraktion, Produktion von körnigen Taxonomien, Stimmungsanalyse, Dokumentenzusammenfassung und Entitätsrelationsmodellierung (d.h. Lernbeziehungen zwischen benannten Einheiten). Textanalyse beinhaltet Informationsabruf, lexische Analyse zur Untersuchung von Wortfrequenzverteilungen, Mustererkennung, Tagging/Annotation, Informationsextraktion, Datenabbautechniken einschließlich Link- und Assoziationsanalyse, Visualisierung und Vorhersageanalyse. Das übergeordnete Ziel ist es im Wesentlichen, Text in Daten für die Analyse zu verwandeln, über die Anwendung der natürlichen Sprachverarbeitung (NLP), verschiedene Arten von Algorithmen und analytische Methoden. Eine wichtige Phase dieses Prozesses ist die Interpretation der gesammelten Informationen. Eine typische Anwendung ist es, eine Reihe von Dokumenten zu scannen, die in einer natürlichen Sprache geschrieben wurden und entweder das Dokument, das für prädiktive Klassifikationszwecke festgelegt wurde, modellieren oder eine Datenbank oder einen Suchindex mit den extrahierten Informationen bevölkern. Das Dokument ist das Grundelement beim Starten mit Textabbau. Hier definieren wir ein Dokument als eine Einheit von Textdaten, die normalerweise in vielen Arten von Sammlungen existiert. Textanalyse Der Begriff Textanalyse beschreibt eine Reihe von linguistischen, statistischen und maschinellen Lerntechniken, die den Informationsinhalt von Textquellen für Business Intelligence, explorative Datenanalyse, Forschung oder Untersuchung modellieren und strukturieren. Der Begriff ist etwa gleichbedeutend mit dem Textbergbau; in der Tat hat Ronen Feldman im Jahr 2004 eine 2000-Beschreibung von "Textbergbau" geändert, um "Textanalysen" zu beschreiben. Der letztgenannte Begriff wird nun häufiger in den Geschäftsfeldern verwendet, während "Textabbau" in einigen der frühesten Anwendungsgebiete verwendet wird, die aus den 1980er Jahren stammen, insbesondere Life-Sciences-Forschung und staatliche Intelligenz. Der Begriff Textanalyse beschreibt auch, dass die Anwendung von Textanalysen auf geschäftliche Probleme, unabhängig oder in Verbindung mit Abfrage und Analyse von feldierten, numerischen Daten, reagieren. Es ist ein Truismus, dass 80 Prozent der geschäftsrelevanten Informationen in unstrukturierter Form, vor allem Text, stammen. Diese Techniken und Prozesse entdecken und präsentieren Wissen – Fakten, Geschäftsregeln und Beziehungen – das ist ansonsten in Textform gesperrt, undurchführbar für die automatisierte Verarbeitung. Textanalyseverfahren Subtasks-Komponenten eines größeren Text-Analytik-Anstrengungs-typisch umfassen: Dimensionsreduktion ist eine wichtige Technik zur Vorverarbeitung von Daten. Die Technik wird verwendet, um das Wurzelwort für tatsächliche Wörter zu identifizieren und die Größe der Textdaten zu reduzieren. Eine Informationsabrufung oder Identifizierung eines Korpus ist ein Vorbereitungsschritt: Sammeln oder Erkennen eines Satzes von Textmaterialien, im Web oder in einem Dateisystem, Datenbank oder Inhalt corpus Manager, zur Analyse. Obwohl einige Textanalytiksysteme ausschließlich fortschrittliche statistische Methoden anwenden, wenden viele andere eine umfassendere natürliche Sprachverarbeitung an, wie zum Beispiel im Rahmen der Sprachfassung, der syntaktischen Parsierung und anderer sprachlicher Analysen. Namenserkennung ist die Verwendung von Gazetteern oder statistischen Techniken, um benannte Textmerkmale zu identifizieren: Menschen, Organisationen, Ortsnamen, Stock-Ticker-Symbole, bestimmte Abkürzungen usw. Disambiguation – die Verwendung kontextueller Hinweise – kann erforderlich sein, um zu entscheiden, wo sich beispielsweise Ford auf einen ehemaligen US-Präsidenten, einen Fahrzeughersteller, einen Filmstar, einen Flussübergang oder eine andere Einheit beziehen kann. Erkennung von Musteridentifikationen: Merkmale wie Telefonnummern, E-Mail-Adressen, Mengen (mit Einheiten) können über regelmäßige Ausdrücke oder andere Musterspiele aufgeklärt werden. Dokument-Clustering: Identifizierung von Sätzen ähnlicher Textdokumente. Coreference: Identifizierung von Noun-Sätzen und anderen Begriffen, die sich auf dasselbe Objekt beziehen. Beziehung, Tatsache und Ereignis Extraktion: Identifizierung von Assoziationen zwischen Organisationen und anderen Informationen in Text Sentiment Analyse beinhaltet die Unterscheidung subjektiver (im Gegensatz zu faktischen) Material und Extraktion verschiedener Formen von attitudinalen Informationen: Stimmung, Meinung, Stimmung und Emotion. Textanalysetechniken sind hilfreich bei der Analyse von Gefühlen auf der Ebene von Unternehmen, Konzepten oder Themen und bei der Unterscheidung von Meinungsinhaber und Meinungsobjekten. Quantitative Textanalyse ist eine Reihe von Techniken, die aus den Sozialwissenschaften stammen, in denen entweder ein menschlicher Richter oder ein Computer semantische oder grammatische Beziehungen zwischen Wörtern extrahiert, um die Bedeutung oder stilistische Muster von, in der Regel, einen lässigen persönlichen Text zum Zweck der psychologischen Profilierung usw. herauszufinden. Anwendungen Textbergbautechnik wird nun auf eine Vielzahl von Regierungs-, Forschungs- und Geschäftsbedürfnissen ausgedehnt angewandt. Alle diese Gruppen können Textabbau für die Plattenverwaltung und die Suche von Dokumenten verwenden, die für ihre täglichen Aktivitäten relevant sind. Juristische Fachleute können beispielsweise Textbergbau für die E-Entdeckung nutzen. Regierungen und Militärgruppen nutzen Textbergbau für nationale Sicherheits- und Geheimdienste. Wissenschaftliche Forscherinnen und Forscherinnen und Wissenschaftlerinnen setzen sich mit Textbergbauansätzen auseinander, um große Textdatensätze (d.h. das Problem unstrukturierter Daten) zu organisieren, um über Text kommunizierte Ideen (z.B. Stimmungsanalyse in sozialen Medien) zu bestimmen und wissenschaftliche Erkenntnisse in Bereichen wie Life Sciences und Bioinformatik zu unterstützen. Im Geschäft werden Anwendungen verwendet, um wettbewerbsfähige Intelligenz und automatisierte Werbeplatzierung zu unterstützen, unter vielen anderen Aktivitäten. Sicherheitsanwendungen Viele Text-Mining-Software-Pakete werden für Sicherheitsanwendungen vermarktet, insbesondere die Überwachung und Analyse von Online-Textquellen wie Internet-News, Blogs usw. für nationale Sicherheitszwecke. Es ist auch an der Studie der Textverschlüsselung / Entschlüsselung beteiligt. Biomedizinische Anwendungen Es wurde eine Reihe von Textbergbau-Anwendungen in der biomedizinischen Literatur beschrieben, darunter rechnerische Ansätze zur Unterstützung von Studien in Proteindocken, Protein-Interaktionen und Protein-Disease-Verbanden. Darüber hinaus können mit großen geduldig textuellen Datensätzen im klinischen Bereich Datensätze von demographischen Informationen in Bevölkerungsstudien und negative Ereignisberichte, Textbergbau klinische Studien und Präzisionsmedizin erleichtern. Textbergbau-Algorithmen können die Schichtung und Indexierung von spezifischen klinischen Ereignissen in großen geduldigen Textdatensätzen von Symptomen, Nebenwirkungen und Komorbiditäten aus elektronischen Gesundheitsakten, Ereignisberichten und Berichten von spezifischen Diagnosetests erleichtern. Eine Online-Textabbau-Anwendung in der biomedizinischen Literatur ist PubGene, eine öffentlich zugängliche Suchmaschine, die biomedizinische Textabbau mit Netzwerkvisualisierung kombiniert. GoPubMed ist eine wissensbasierte Suchmaschine für biomedizinische Texte. Textbergbautechniken ermöglichen es uns auch, unbekanntes Wissen aus unstrukturierten Dokumenten im klinischen Bereich zu extrahieren Software-Anwendungen Textbergbaumethoden und Software werden auch von großen Unternehmen, einschließlich IBM und Microsoft, erforscht und entwickelt, um die Bergbau- und Analyseprozesse weiter zu automatisieren, und von verschiedenen Firmen, die im Bereich der Suche und Indexierung im Allgemeinen arbeiten, um ihre Ergebnisse zu verbessern. Innerhalb des öffentlichen Sektors konzentrierte sich viel auf die Schaffung von Software zur Verfolgung und Überwachung terroristischer Aktivitäten. Für Studienzwecke ist Weka Software eine der beliebtesten Optionen in der wissenschaftlichen Welt, als ausgezeichneter Einstiegspunkt für Anfänger. Für Python Programmierer gibt es ein ausgezeichnetes Toolkit namens NLTK für allgemeinere Zwecke. Für fortgeschrittene Programmierer gibt es auch die Gensim-Bibliothek, die sich auf Worteinbettungsbasierte Textdarstellungen konzentriert. Online-Medien-Anwendungen Textbergbau wird von großen Medienunternehmen wie der Tribune Company verwendet, um Informationen zu klären und den Lesern größere Sucherfahrungen zu bieten, was wiederum die Seitenauffälligkeit und den Umsatz erhöht. Darüber hinaus profitieren die Redakteure von der Möglichkeit, Nachrichten über Immobilien zu teilen, zu verknüpfen und zu verpacken, was die Möglichkeiten zur Monetarisierung von Inhalten deutlich erhöht. Business- und Marketinganwendungen Textanalytik wird im Geschäft, insbesondere im Marketing, wie im Kundenbeziehungsmanagement eingesetzt. Coussement und Van den Poel (2008) wenden es an, um prädiktive Analysemodelle für Kundenbetreuung (Kundenbetreuung) zu verbessern. Der Textbergbau wird auch in der Vorhersage der Vorräte der Vorräte angewendet. Sentiment Analyse Sentiment Analyse kann eine Analyse von Filmrezensionen zur Schätzung, wie günstig eine Bewertung für einen Film ist. Eine solche Analyse kann einen markierten Datensatz oder eine Kennzeichnung der Beeinflussung von Wörtern benötigen. Für WordNet bzw. ConceptNet wurden Ressourcen für die Beeinträchtigung von Wörtern und Konzepten geschaffen. Text wurde verwendet, um Emotionen im verwandten Bereich der affektiven Computing zu erkennen. Textbasierte Ansätze für affektives Computing wurden auf mehreren Unternehmensgruppen wie Studentenbewertungen, Kindergeschichten und Nachrichtengeschichten verwendet. Wissenschaftliche Literatur Bergbau und akademische Anwendungen Die Frage des Textbergbaus ist für Verleger von Bedeutung, die große Datenbanken von Informationen, die eine Indexierung für die Retrieval erfordern, besitzen. Dies gilt insbesondere für wissenschaftliche Disziplinen, in denen sehr spezifische Informationen oft im schriftlichen Text enthalten sind. Daher wurden Initiativen ergriffen, wie z.B. Nature's Vorschlag für eine Open Text Mining Interface (OTMI) und die National Institutes of Health's Common Journal Publishing Document Type Definition (DTD), die semantische Aufgaben an Maschinen zur Beantwortung spezifischer im Text enthaltener Fragen stellen würden, ohne die Verlegerbarrieren des öffentlichen Zugangs zu beseitigen. Akademische Institutionen sind auch an der Textbergbauinitiative beteiligt: Das National Centre for Text Mining (NaCTeM) ist das erste öffentlich geförderte Textbergbauzentrum der Welt. NaCTeM wird von der Universität Manchester in enger Zusammenarbeit mit dem Tsujii Lab der Universität Tokio betrieben. NaCTeM bietet maßgeschneiderte Werkzeuge, Forschungseinrichtungen und bietet Beratung für die akademische Gemeinschaft. Sie werden vom Gemischten Informationssystemausschuss (JISC) und zwei der britischen Forschungsräte (EPSRC & BBSRC) gefördert. Mit einem ersten Fokus auf den Textbergbau in den biologischen und biomedizinischen Wissenschaften hat sich die Forschung seither in die Bereiche der Sozialwissenschaften erweitert. In den Vereinigten Staaten, der School of Information an der University of California, entwickelt Berkeley ein Programm namens BioText, um Biologie-Forscher in Textbergbau und -analyse zu unterstützen. Das Textanalyseportal für Forschung (TAPoR), das derzeit an der Universität Alberta untergebracht ist, ist ein wissenschaftliches Projekt, um Textanalyseanwendungen zu katalogisieren und ein Tor für Forscher zu schaffen, die neu in der Praxis sind. Methoden für den wissenschaftlichen Literaturbergbau Die rechnerischen Methoden wurden entwickelt, um den Informationsabruf aus der wissenschaftlichen Literatur zu unterstützen. Veröffentlichte Ansätze sind Methoden zur Suche, Bestimmung von Neuheit und Klärung von Homonymen unter technischen Berichten. Digitale Geistes- und Rechensoziologie Die automatische Analyse von umfangreichen Text-Corporate hat die Möglichkeit für Wissenschaftler geschaffen, Millionen von Dokumenten in mehreren Sprachen mit sehr begrenztem manuellen Eingriff zu analysieren. Schlüsseltechnologien sind Parsing, maschinelle Übersetzung, Thema Kategorisierung und maschinelles Lernen. Die automatische Parsierung von textuellen Körperschaften hat die Gewinnung von Akteuren und deren relationalen Netzwerken in großem Umfang ermöglicht und Textdaten in Netzwerkdaten verwandelt. Die resultierenden Netzwerke, die Tausende von Knoten enthalten können, werden dann analysiert, indem Tools aus der Netzwerktheorie verwendet werden, um die Schlüsselakteure, die Schlüsselgemeinschaften oder -parteien und allgemeine Eigenschaften wie Robustheit oder strukturelle Stabilität des Gesamtnetzes oder Zentralität bestimmter Knoten zu identifizieren. Dies automatisiert den Ansatz, der durch quantitative narrative Analyse eingeführt wird, wobei Subjekt-Verb-Objekt-Triplets mit Paaren von Schauspielern identifiziert werden, die durch eine Aktion verknüpft sind, oder Paare, die durch Schauspieler-Objekt gebildet werden. Inhaltsanalyse ist seit langem ein traditioneller Teil der Sozialwissenschaften und Medienstudien. Die Automatisierung der Inhaltsanalyse ermöglichte eine "große Daten"-Revolution in diesem Bereich, mit Studien in sozialen Medien und Zeitungsinhalten, die Millionen von Nachrichten enthalten. Gender-Bias, Lesbarkeit, inhaltliche Ähnlichkeit, Leserpräferenzen und sogar Stimmung wurden anhand von Textabbaumethoden über Millionen von Dokumenten analysiert. Die Analyse von Lesbarkeit, Gender-Bias und Thema-Bias wurde in Flaounas et al. gezeigt, wie unterschiedliche Themen unterschiedliche Geschlechter-Bias und Lesbarkeit aufweisen; die Möglichkeit, Stimmungsmuster in einer riesigen Bevölkerung durch die Analyse von Twitter-Inhalte zu erkennen, wurde ebenfalls demonstriert. Software Text Bergbau Computerprogramme sind von vielen kommerziellen und Open Source-Unternehmen und Quellen verfügbar. Siehe Liste der Textbergbausoftware. Das geistige Eigentumsrecht Situation in Europa Unter europäischen Urheberrechten und Datenbankgesetzen ist der Abbau von unkopierbaren Werken (z.B. durch Web-Mining) ohne Erlaubnis des Urheberrechtsinhabers illegal. Im Vereinigten Königreich im Jahr 2014 hat die Regierung auf Empfehlung der Hargreaves-Bewertung das Urheberrecht geändert, um den Textabbau als Einschränkung und Ausnahme zu ermöglichen. Es war das zweite Land der Welt, nach Japan, das 2009 eine bergbauspezifische Ausnahme eingeführt hat. Aufgrund der Einschränkung der Informationsgesellschaftsrichtlinie (2001) erlaubt die britische Ausnahme jedoch nur den Content Mining für nichtkommerzielle Zwecke. Das Urheberrecht des Vereinigten Königreichs erlaubt es nicht, diese Bestimmung durch vertragliche Bedingungen zu überschreiben. Die Europäische Kommission unterstützte 2013 die Stakeholder-Diskussion zum Text- und Datenbergbau unter dem Titel Lizenzen für Europa. Die Tatsache, dass der Fokus auf die Lösung dieser rechtlichen Frage war Lizenzen, und nicht Einschränkungen und Ausnahmen des Urheberrechts, führte Vertreter von Universitäten, Forschern, Bibliotheken, Zivilgesellschaftsgruppen und Open Access-Verlegern, den Stakeholder-Dialog im Mai 2013 zu verlassen. Die Situation im US-amerikanischen Urheberrecht und insbesondere seine fairen Nutzungsbestimmungen bedeutet, dass Textbergbau in Amerika sowie andere faire Nutzungsländer wie Israel, Taiwan und Südkorea als legal angesehen werden. Da Textbergbau transformativ ist, was bedeutet, dass es die ursprüngliche Arbeit nicht supplant, wird es als rechtmäßig unter fairem Gebrauch angesehen. Zum Beispiel, im Rahmen der Google-Buch-Berechnung der Präsidierende Richter auf dem Fall entschieden, dass Googles Digitalisierungsprojekt von in-copyright-Büchsen rechtmäßig war, zum Teil aufgrund der transformativen Verwendungen, die das Digitalisierungsprojekt gezeigt hat - eine solche Verwendung ist Text- und Datenabbau. Implikationen Bis vor kurzem verwendeten Webseiten am häufigsten textbasierte Suchanfragen, die nur Dokumente mit bestimmten benutzerdefinierten Wörtern oder Phrasen gefunden haben. Nun kann durch die Nutzung eines semantischen Webs Textberging Inhalte basierend auf Bedeutung und Kontext finden (nicht nur durch ein bestimmtes Wort). Darüber hinaus können Text-Mining-Software verwendet werden, um große Dossiers von Informationen über bestimmte Personen und Veranstaltungen zu erstellen. So können beispielsweise große Datensätze auf Basis von aus Nachrichtenberichten gewonnenen Daten aufgebaut werden, um die Analyse von sozialen Netzwerken oder die Konterintelligenz zu erleichtern. In der Tat kann die Textberging-Software in einer Kapazität ähnlich wie ein Geheimanalyse- oder Forschungsbibliothekar handeln, wenn auch mit einem begrenzten Umfang der Analyse. Textberging wird auch in einigen E-Mail-Spam-Filtern verwendet, um die Eigenschaften von Nachrichten zu bestimmen, die wahrscheinlich Werbung oder andere unerwünschte Material sein. Textbergbau spielt eine wichtige Rolle bei der Festlegung der Einschätzung des Finanzmarktes. Zunehmendes Interesse wird an den mehrsprachigen Datenabbau gezahlt: die Fähigkeit, Informationen über Sprachen zu gewinnen und ähnliche Elemente aus verschiedenen sprachlichen Quellen nach ihrer Bedeutung zu bündeln. Die Herausforderung, den großen Teil der Unternehmensinformationen zu nutzen, die in unstrukturierter Form entstehen, ist seit Jahrzehnten anerkannt. Es wird in der frühesten Definition von Business Intelligence (BI,) in einem Oktober 1958 IBM Journal Artikel von H.P Luhn, A Business Intelligence System, die ein System beschreibt, das wird: "gebrauchen Sie Datenverarbeitungsmaschinen für auto-abstracting und auto-encoding von Dokumenten und für die Erstellung von Interessenprofilen für jeden der "Aktionspunkte" in einer Organisation. Beide eingehenden und intern generierten Dokumente werden automatisch abstrahiert, durch ein Wortmuster gekennzeichnet und automatisch an entsprechende Aktionspunkte gesendet." Doch als Management-Informationssysteme, die ab den 1960er Jahren entwickelt wurden, und als BI in den 80er und 90er Jahren als Softwarekategorie und Praxisfeld hervorging, lag der Schwerpunkt auf numerischen Daten, die in relationalen Datenbanken gespeichert wurden. Dies ist nicht überraschend: Text in unstrukturierten Dokumenten ist schwer zu verarbeiten. Die Entstehung von Textanalysen in ihrer aktuellen Form beruht auf einer Neuorientierung der Forschung in den späten 1990er Jahren von der Algorithmusentwicklung bis zur Anwendung, wie von Prof. Marti A. Hearst in der Zeitung Untangling Textdaten Bergbau: Seit fast einem Jahrzehnt hat die rechnerische Sprachgemeinschaft große Textsammlungen als eine Ressource betrachtet, die man tippt, um bessere Textanalysealgorithmen zu produzieren. In diesem Papier habe ich versucht, eine neue Betonung vorzuschlagen: die Verwendung großer Online-Textsammlungen, um neue Fakten und Trends über die Welt selbst zu entdecken. Um Fortschritte zu erzielen, brauchen wir keine voll künstliche intelligente Textanalyse; vielmehr kann eine Mischung aus rechnerisch angesteuerter und benutzergeführter Analyse die Tür öffnen, um neue Ergebnisse zu erregen. Die Bedürftigkeitserklärung von Hearst von 1999 beschreibt den Zustand der Textanalysetechnologie und praktiziert ein Jahrzehnt später. Siehe auch Referenzen Zitate Quellen Ananiadou, S. und McNaught, J. (Editors) (2006). Text Bergbau für Biologie und Biomedizin. Artech House Books.ISBN 978-1-58053-984-5 Bilisoly, R. (2008). Praktische Text-Mining mit Perl. New York: John Wiley & Sons.ISBN 978-0-470-17643-6 Feldman, R. and Sanger, J. (2006). Das Text-Mining-Handbuch. New York: Cambridge University Press.ISBN 978-0-521-83657-9 Hotho, A,. Nürnberger, A. und Paaß, G. (2005). "Eine kurze Übersicht über den Textbergbau". Im Ldv Forum, Vol.20(1,) S. 19-62 Indurkhya, N, und Damerau, F. (2010). Handbuch der Natural Language Processing, 2. Auflage. Boca Raton, FL: CRC Press.ISBN 978-1-4200-8592-1 Kao, A, und Poteet, S. (Editoren). Natural Language Processing and Text Mining.Springer.ISBN 1-84628-175-X Konchady, M. Text Mining Application Programming (Programming Series). Charles River Media.ISBN 1-58450-460-9 Manning, C,. and Schutze, H. (1999). Grundlagen der Statistischen natürlichen Sprachverarbeitung. Cambridge, MA: MIT Press.ISBN 978-0-262-13360-9 Miner, G,. Elder, J,. Hill.T, Nisbet, R,. Delen, D. and Fast, A. (2012). Praktische Text Bergbau und statistische Analyse für nicht strukturierte Textdatenanwendungen. Elsevier Academic Press.ISBN 978-0-12-386979-1 Mc Knight, W. (2005). "Gebäudeinformationen erstellen: Textdaten Bergbau in der Business Intelligence."DM Review, 21-22.Srivastava, A, und Sahami.M (2009). Textminierung: Klassifizierung, Clustering und Anwendungen. Boca Raton, FL: CRC Press. ISBN 978-1-4200-5940-3 Zanasi, A. (Editor) (2007). Textberging und seine Anwendungen für Intelligenz, CRM und Wissensmanagement. WIT Press.ISBN 978-1-84564-131-3 Externe Links Marti Hearst: Was ist Textminierung?(Oktober, 2003)Automatische Inhaltsextraktion, Linguistische Datenkonsortium Automatische Inhaltsextraktion, NIST