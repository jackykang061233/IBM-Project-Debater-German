Computergrafik beschäftigt sich mit der Erstellung von Bildern mit Hilfe von Computern. Heute ist Computergrafik eine Kerntechnologie in der digitalen Fotografie, Film, Videospiele, Handy und Computer-Displays und vielen spezialisierten Anwendungen. Viele spezialisierte Hardware und Software wurden entwickelt, wobei die Displays der meisten Geräte von Computergrafik-Hardware angetrieben werden. Es ist ein riesiges und kürzlich entwickeltes Gebiet der Informatik. Der Satz wurde 1960 von Computergrafik-Forschern Verne Hudson und William Fetter von Boeing geprägt. Es wird oft als CG abgekürzt, oder typischerweise im Kontext von Film als Computer erzeugte Bilder (CGI). Die nicht-künstlerischen Aspekte der Computergrafik sind Gegenstand der Informatikforschung. Einige Themen in Computergrafiken umfassen Benutzeroberflächendesign, Spritgrafiken, Rendering, Strahlverfolgung, Geometrieverarbeitung, Computeranimation, Vektorgrafiken, 3D-Modellierung, Shaker, GPU-Design, implizite Oberflächen, Visualisierung, Bildverarbeitung, Computerfotografie, wissenschaftliche Visualisierung, Computergeometrie und Computervision. Die Gesamtmethodik hängt stark von den zugrunde liegenden Wissenschaften von Geometrie, Optik, Physik und Wahrnehmung ab. Computergrafiken sind dafür verantwortlich, Kunst- und Bilddaten dem Verbraucher effektiv und sinnvoll anzuzeigen. Es wird auch für die Verarbeitung von Bilddaten aus der physischen Welt, wie Foto- und Videoinhalt, verwendet. Computer-Grafiken-Entwicklung hatte einen erheblichen Einfluss auf viele Arten von Medien und hat Animation, Filme, Werbung, Videospiele, im Allgemeinen revolutioniert. Überblick Der Begriff Computergrafik wurde in einem weiten Sinne verwendet, um "fast alles auf Computern zu beschreiben, die nicht Text oder Ton sind. Typischerweise bezieht sich der Begriff Computergrafik auf mehrere verschiedene Dinge: die Darstellung und Manipulation von Bilddaten durch einen Computer die verschiedenen Technologien, die verwendet werden, um Bilder Methoden zu erstellen und zu manipulieren, um visuelle Inhalte digital zu synthetisieren und zu manipulieren, siehe Studie der Computergrafik Heute ist Computergrafik weit verbreitet. Solche Bilder finden sich in und im Fernsehen, Zeitungen, Wetterberichte und in einer Vielzahl von medizinischen Untersuchungen und chirurgischen Verfahren. Ein gut strukturiertes Diagramm kann komplexe Statistiken in einer Form präsentieren, die einfacher zu verstehen und zu interpretieren ist. In den Medien werden solche Grafiken verwendet, um Papiere, Berichte, Thesen und andere Präsentationsmaterialien zu illustrieren. Viele Tools wurden entwickelt, um Daten zu visualisieren. Computergenerierte Bilder können in verschiedene Arten unterteilt werden: zweidimensionale (2D,) dreidimensionale (3D,) und animierte Grafiken. Wie die Technologie verbessert hat, 3D-Computergrafiken sind häufiger geworden, aber 2D-Computergrafiken sind noch weit verbreitet. Computergrafiken sind als Teilgebiet der Informatik entstanden, die Methoden zur digitalen Synthesisierung und Manipulation von visuellen Inhalten untersucht. In den letzten zehn Jahren wurden andere Fachgebiete wie die Informationsvisualisierung und die wissenschaftliche Visualisierung mehr mit der "Visualisierung von dreidimensionalen Phänomenen (architectural, meteorologische, medizinische, biologische usw.) entwickelt, wo die Betonung auf realistische Renderings von Volumen, Oberflächen, Beleuchtungsquellen und so weiter, vielleicht mit einer dynamischen (Zeit-)Komponente" liegt. Geschichte Die Vorläuferwissenschaften zur Entwicklung moderner Computergrafiken waren die Fortschritte in der Elektrotechnik, Elektronik und Fernsehen, die in der ersten Hälfte des zwanzigsten Jahrhunderts stattfanden. Seit der Verwendung von Matten der Lumiere-Brüder konnten Bildschirme Kunst darstellen, um für die frühesten Filme aus dem Jahr 1895 besondere Effekte zu erzielen, aber solche Displays waren begrenzt und nicht interaktiv. Die erste Kathodenstrahlröhre, die Braun-Röhre, wurde 1897 erfunden – sie wiederum würde das Oszilloskop und das militärische Bedienfeld erlauben – die direkteren Vorläufer des Feldes, da sie die ersten zweidimensionalen elektronischen Displays zur Verfügung stellten, die auf die programmmatische oder Benutzereingabe reagierten. Dennoch blieben Computergrafiken bis in die 1950er und die Zeit nach dem Zweiten Weltkrieg als Disziplin relativ unbekannt – währenddessen entstand die Disziplin aus einer Kombination von reiner Universität und Labor-Akademikerforschung zu fortschrittlicheren Computern und der Weiterentwicklung von Technologien wie Radar, fortgeschrittener Luftfahrt und Rocketry im Krieg. Neue Arten von Displays wurden benötigt, um den Reichtum an Informationen aus solchen Projekten zu verarbeiten, was zur Entwicklung von Computergrafiken als Disziplin führt. 1950er Jahre Projekte wie die Whirlwind- und SAGE-Projekte stellten die CRT als eine tragfähige Anzeige- und Interaktionsschnittstelle vor und führten den Leuchtenschreiber als Eingabegerät ein. Douglas T. Ross des Whirlwind SAGE-Systems führte ein persönliches Experiment durch, in dem er ein kleines Programm schrieb, das die Bewegung seines Fingers erfasste und seinen Vektor (seinen Spurennamen) auf einem Display-Bereich zeigte. Eines der ersten interaktiven Videospiele mit erkennbaren, interaktiven Grafiken – Tennis for Two – wurde für ein Oszilloskop von William Higinbotham geschaffen, um Besucher im Jahr 1958 im Brookhaven National Laboratory zu unterhalten und ein Tennisspiel zu simulieren. 1959, Douglas T. Ross innoviert wieder während der Arbeit am MIT, um mathematische Aussagen in Computer erzeugt 3D Werkzeug-Vektoren, indem die Gelegenheit, ein Display-Bereich Bild eines Disney Cartoon Charakters zu erstellen. Der Elektronik-Pionier Hewlett-Packard ging 1957 nach der Aufnahme des Jahrzehnts vor, und etablierte starke Verbindungen mit der Stanford University durch ihre Gründer, die Alumni waren. Dies begann mit der jahrzehntelangen Transformation des südlichen San Francisco Bay Area in den weltweit führenden Computertechnologie-Hub – heute bekannt als Silicon Valley. Das Feld der Computer-Grafik entwickelt mit der Entstehung von Computer-Grafik-Hardware. Weitere Fortschritte beim Computing führten zu größeren Fortschritten in interaktiven Computergrafiken. 1959 wurde der TX-2 Computer am MIT's Lincoln Laboratory entwickelt. Die TX-2 integrierte eine Reihe neuer Mensch-Maschine-Schnittstellen. Mit der revolutionären Sketchpad-Software von Ivan Sutherland konnte ein Leuchtstift Skizzen auf dem Computer zeichnen. Mit einem Leuchtstift erlaubte Sketchpad, einfache Formen auf dem Computerbildschirm zu zeichnen, zu speichern und sogar später zu erinnern. Der Leuchtstift selbst hatte eine kleine photoelektrische Zelle in seiner Spitze. Diese Zelle emittiert einen elektronischen Impuls, wenn sie vor einem Computerbildschirm platziert wurde und die Elektronenkanone des Bildschirms direkt darauf geschossen wurde. Durch einfaches Timing des elektronischen Pulses mit der aktuellen Position der Elektronenkanone war es einfach, genau dort zu bestimmen, wo der Stift zu jedem bestimmten Zeitpunkt auf dem Bildschirm war. Sobald das festgestellt wurde, könnte der Computer dann einen Cursor an dieser Stelle zeichnen. Sutherland schien die perfekte Lösung für viele der Grafikprobleme zu finden, die er konfrontiert. Auch heute haben viele Standards von Computer-Grafik-Schnittstellen ihren Start mit diesem frühen Sketchpad-Programm. Ein Beispiel hierfür sind die Zwänge. Wenn man z.B. ein Quadrat zeichnen will, muss man sich nicht darum sorgen, vier Linien perfekt zu zeichnen, um die Ränder der Box zu bilden. Man kann einfach angeben, dass sie eine Box zeichnen möchten, und dann die Position und Größe der Box angeben. Die Software wird dann eine perfekte Box mit den richtigen Abmessungen und an der richtigen Stelle konstruieren. Ein weiteres Beispiel ist, dass Sutherlands Software Objekte modeled – nicht nur ein Bild von Objekten. Mit anderen Worten, mit einem Modell eines Autos könnte man die Größe der Reifen ändern, ohne den Rest des Autos zu beeinflussen. Es könnte den Körper des Autos strecken, ohne die Reifen zu verformen. 1960sDer Satz "Computergrafiken" selbst wurde 1960 von William Fetter, einem Grafiker für Boeing, geprägt. Dieses alte Zitat in vielen Sekundärquellen wird mit folgendem Satz ergänzt: Fetter hat gesagt, dass ihm die Bedingungen tatsächlich von Verne Hudson der Wichita Division von Boeing gegeben wurden. 1961 hat ein anderer Student am MIT, Steve Russell, einen weiteren wichtigen Titel in der Geschichte der Videospiele, Spacewar! Geschrieben für die DEC PDP-1, Spacewar war ein sofortiger Erfolg und Kopien begann zu anderen PDP-1 Besitzer und schließlich DEC bekam eine Kopie. Die Ingenieure der DEC nutzten es als Diagnoseprogramm auf jedem neuen PDP-1, bevor es verschifft wurde. Die Verkaufskraft nahm dies schnell genug auf und bei der Installation neuer Einheiten würde das "Welt erste Videospiel" für ihre neuen Kunden führen.( Higginbotham's Tennis For Two hatte Spacewar um fast drei Jahre geschlagen; aber es war fast unbekannt außerhalb einer Forschung oder akademischen Umgebung.) Um die gleiche Zeit (1961-1962) in der Universität von Cambridge, Elizabeth Waldram schrieb Code, um Radio-Aastronomie-Karten auf einer Kathodenstrahlröhre anzuzeigen. E. Zajac, ein Wissenschaftler am Bell Telephone Laboratory (BTL), hat 1963 einen Film mit dem Titel "Simulation eines Zwei-Giro-Schwerkrafteinstellungssystems" geschaffen. In diesem computergenerierten Film zeigte Zajac, wie die Einstellung eines Satelliten verändert werden könnte, da er die Erde umkreist. Er erstellte die Animation auf einem IBM 7090 Mainframe-Computer. Auch bei BTL, Ken Knowlton, Frank Sinden, Ruth A. Weiss und Michael Noll begannen im Bereich Computergrafiken zu arbeiten. Sinden schuf einen Film namens Force, Mass and Motion, der Newtons Bewegungsgesetze im Einsatz illustriert. Zur gleichen Zeit erstellten andere Wissenschaftler Computergrafiken, um ihre Forschung zu veranschaulichen. Im Lawrence Radiation Laboratory hat Nelson Max die Filme Flow of a Viscous Fluid und Propagation of Shock Waves in einer soliden Form erstellt. Boeing Aircraft erstellte einen Film namens Vibration eines Flugzeugs. Auch in den frühen 1960er-Jahren würden die Automobile durch die frühe Arbeit von Pierre Bézier bei Renault, der Paul de Casteljau Kurven benutzte – jetzt Bézier Kurven nach Béziers Arbeit auf dem Feld genannt – 3D-Modellierungstechniken für Renault Karosserien entwickeln. Diese Kurven würden die Grundlage für viel kurvenbildende Arbeit im Feld bilden, da Kurven – im Gegensatz zu Polygonen – mathematisch komplexe Wesen zeichnen und gut modellieren. Es war nicht lange, bevor große Unternehmen begann ein Interesse an Computergrafiken. TRW, Lockheed-Georgia, General Electric und Sperry Rand gehören zu den vielen Unternehmen, die bis Mitte der 1960er Jahre in Computergrafiken gestartet wurden. IBM war schnell auf dieses Interesse zu reagieren, indem das IBM 2250 Grafik-Terminal, der erste kommerziell verfügbare Grafik-Computer. Ralph Baer, ein leitender Ingenieur bei Sanders Associates, kam 1966 mit einem Heimvideospiel, das später Magnavox lizenziert und Odyssey genannt wurde. Während sehr vereinfachend und recht kostengünstige elektronische Teile erforderte, erlaubte es dem Spieler, Lichtpunkte auf einem Bildschirm herumzubewegen. Es war das erste Consumer-Computer-Grafiken-Produkt. David C. Evans war von 1953 bis 1962 Leiter des Engineerings der Bendix Corporation, danach arbeitete er in den nächsten fünf Jahren als Gastprofessor bei Berkeley. Dort setzte er sein Interesse an Computern fort und wie sie mit Menschen verbunden waren. 1966 rekrutiert die Universität von Utah Evans zu einem Informatikprogramm, und Computergrafiken wurden schnell sein Hauptinteresse. Diese neue Abteilung würde durch die 1970er Jahre zum weltweit primären Forschungszentrum für Computergrafiken werden. Auch im Jahr 1966, Ivan Sutherland innovate am MIT, als er das erste computergesteuerte Head-mounted Display (HMD) erfunden. Es zeigt zwei separate Drahtrahmenbilder, eine für jedes Auge. Dies erlaubte dem Betrachter, die Computerszene in stereoskopischer 3D zu sehen. Die schwere Hardware, die für die Unterstützung von Display und Tracker benötigt wurde, wurde wegen der möglichen Gefahr als Schwert von Damocles bezeichnet, wenn es auf den Träger fallen würde. Nachdem er seinen Doktortitel vom MIT erhalten hatte, wurde Sutherland Leiter der Informationsverarbeitung bei ARPA (Advanced Research Projects Agency) und später Professor an Harvard. 1967 wurde Sutherland von Evans rekrutiert, um dem Informatikprogramm an der Universität von Utah beizutreten – eine Entwicklung, die diese Abteilung zu einem der wichtigsten Forschungszentren in Grafiken für fast ein Jahrzehnt später machen würde und schließlich einige der wichtigsten Pioniere auf dem Gebiet produziert. Dort perfektionierte Sutherland seine HMD; zwanzig Jahre später würde die NASA seine Techniken in ihrer virtuellen Realitätsforschung wiederentdecken. Bei Utah, Sutherland und Evans waren sehr gefragte Berater von großen Unternehmen, aber sie wurden frustriert bei der fehlenden Grafik-Hardware zur Verfügung zur Zeit, so begannen sie einen Plan zu formulieren, ihr eigenes Unternehmen zu starten. 1968 gründeten Dave Evans und Ivan Sutherland das erste Computergrafik-Hardwareunternehmen Evans & Sutherland. Während Sutherland ursprünglich wollte, dass das Unternehmen in Cambridge, Massachusetts, Salt Lake City wurde stattdessen aufgrund seiner Nähe zur Professoren-Forschungsgruppe an der Universität von Utah gewählt. Auch 1968 beschrieb Arthur Appel den ersten Strahlgussalgorithmus, den ersten einer Klasse von strahlverfolgungsbasierten Rendering-Algorithmen, die seither grundlegend geworden sind, um Photorealismus in Grafiken zu erreichen, indem die Pfade, die Strahlen von einer Lichtquelle, zu Oberflächen in einer Szene und in die Kamera nehmen, modelliert werden. 1969 initiierte die ACM eine Special Interest Group on Graphics (SIGGRAPH), die Konferenzen, Grafikstandards und Publikationen im Bereich Computergrafiken organisiert. Bis 1973 fand die erste jährliche SIGGRAPH-Konferenz statt, die zu einem der Schwerpunkte der Organisation geworden ist. SIGGRAPH ist in Größe und Bedeutung gewachsen, da sich das Feld der Computergrafik im Laufe der Zeit erweitert hat. 1970sEin wichtiger technologischer Fortschritt, der die praktische Computer-Grafiken-Technologie ermöglichte, war die Entstehung der Metall-Oxid-Halbleiter-Technologie (MOS) in den frühen 1970er Jahren. Die MOS LSI-Technologie ermöglichte große Mengen an Rechenfähigkeit in kleinen MOS-integrierten Schaltungschips, die 1972 zur Entwicklung des Computergrafikterminals Tektronix 4010 sowie des Mikroprozessors 1971 führten. Der MOS-Speicher, insbesondere der 1970 eingeführte dynamische Zufalls-Zugriffs-Speicher (DRAM)-Chip, war auch in der Lage, Kilobits von Daten auf einem einzigen High-Density-Speicher-Chip zu halten, so dass es möglich ist, ein gesamtes Standard-Definition (SD)-Raster-Grafikbild in einem digitalen Frame-Puffer zu halten, der von Xerox PARC zur Entwicklung von SuperPaint verwendet wurde, dem ersten video-basierten, raster-basierten Computergrafiksystem auf Raster basiert. Anschließend traten an der Universität Utah in den 1970er-Jahren, die Ivan Sutherland angeheuert hatte, einige Durchbrüche auf dem Gebiet auf – besonders wichtige frühe Durchbrüche bei der Transformation von Grafiken von utilitaristisch zu realistisch. Er wurde mit David C. Evans gepaart, um eine fortschrittliche Computer-Grafiken-Klasse zu lehren, die viel von der Gründung der Forschung auf dem Gebiet beigetragen und mehrere Studenten, die wachsen würde, um mehrere der wichtigsten Unternehmen der Branche zu finden – nämlich Pixar, Silicon Graphics, und Adobe Systems. Tom Stockham führte die Bildverarbeitungsgruppe an der UU, die eng mit dem Computergrafiklabor arbeitete. Einer dieser Studenten war Edwin Catmull. Catmull war gerade von The Boeing Company gekommen und arbeitete an seinem Grad in Physik. Catmull liebte Animation auf Disney, entdeckte aber schnell, dass er nicht das Talent zum Zeichnen hatte. Nun sah Catmull (zusammen mit vielen anderen) Computer als den natürlichen Fortschritt der Animation und sie wollten Teil der Revolution sein. Die erste Computeranimation, die Catmull sah, war seine eigene. Er schuf eine Animation seiner Handöffnung und Schließung. 1974 war er auch Pionier der Texturkartierung, um Texturen auf dreidimensionalen Modellen zu malen, nun als eine der grundlegenden Techniken in der 3D-Modellierung. Es wurde eines seiner Ziele, ein Feature-Länge-Bewegungsbild mit Computergrafiken zu produzieren – ein Ziel, das er zwei Jahrzehnte später nach seiner Gründungsrolle in Pixar erreichen würde. In derselben Klasse schuf Fred Parke eine Animation des Gesichts seiner Frau. Die beiden Animationen wurden im Spielfilm Futureworld 1976 aufgenommen. Als das UU-Computergrafiklabor Menschen aus aller Welt anzog, war John Warnock ein weiterer dieser frühen Pioniere; später gründete er Adobe Systems und erstellte eine Revolution in der Verlagswelt mit seiner PostScript-Seitenbeschreibungssprache, und Adobe würde später die Industrie Standard-Fotobearbeitungssoftware in Adobe Photoshop und ein prominentes Filmindustrie-Sondereffektprogramm in Adobe After Effects erstellen. James Clark war auch dort; später gründete er Silicon Graphics, ein Hersteller von fortschrittlichen Rendering-Systemen, die das Feld der High-End-Grafiken bis Anfang der 1990er Jahre beherrschen würden. Ein großer Fortschritt in 3D-Computergrafiken wurde bei UU von diesen frühen Pionieren – versteckte Oberflächenbestimmung erstellt. Um eine Darstellung eines 3D-Objekts auf dem Bildschirm zu zeichnen, muss der Computer festlegen, welche Oberflächen aus der Sicht des Betrachters hinter dem Objekt liegen und somit beim Erstellen (oder Rendern) des Bildes versteckt werden. Das 3D Core Graphics System (oder Core) war der erste grafische Standard, der entwickelt wurde. Eine Gruppe von 25 Experten der ACM Special Interest Group SIGGRAPH entwickelte diesen "Konzeptual Framework". Die Spezifikationen wurden 1977 veröffentlicht, und es wurde eine Grundlage für viele zukünftige Entwicklungen auf dem Gebiet. Auch in den 1970er Jahren trugen Henri Gouraud, Jim Blinn und Bui Tuong Phong über die Entwicklung der Gouraud Shading- und Blinn-Phong Shading-Modelle zu den Grundlagen des Shadings in CGI bei, so dass Grafiken über einen flachen Look hinausgehen, um eine genauere Darstellung der Tiefe zu ermöglichen. Jim Blinn hat 1978 auch durch die Einführung von Stoßkartierungen, eine Technik zur Simulation von unebenen Oberflächen und der Vorgänger zu vielen fortschrittlicheren Arten von Kartierungen, die heute verwendet werden, weiterentwickelt. Die moderne Videospiel-Arkade, wie heute bekannt ist, wurde in den 1970er Jahren geboren, mit den ersten Arcade-Spielen mit Echtzeit 2D-Sprite-Grafik. Pong 1972 war eines der ersten Hit Arcade-Schrankspiele. Das Speed Race im Jahr 1974 hatte Sprite, die sich entlang einer vertikal skalierten Straße bewegten. Gun Fight im Jahr 1975 verfügte über menschliche animierte Zeichen, während Space Invaders im Jahr 1978 eine große Anzahl von animierten Figuren auf dem Bildschirm zeigten; beide benutzten eine spezialisierte Barrel Shifter-Schaltung aus diskreten Chips, um ihren Intel 8080 Mikroprozessor zu helfen, ihre Framebuffer-Grafik anzuimieren. Die 1980er Jahre begannen, die Modernisierung und Kommerzialisierung von Computergrafiken zu sehen. Als der Heimcomputer proliferierte, wurde ein Thema, das zuvor eine akademische Disziplin war, von einem viel größeren Publikum angenommen, und die Anzahl der Computer-Grafiken-Entwickler stieg deutlich. In den frühen 1980er Jahren führte die Metall-Oxid-Halbleiter-Technologie (MOS) sehr große Integration (VLSI) zur Verfügbarkeit von 16-Bit-Zentralprozessor (CPU) Mikroprozessoren und der ersten Grafikprozessoreinheit (GPU) Chips, die die Computergrafik revolutionieren begannen, wodurch hochauflösende Grafiken für Computergrafikterminals sowie PC-Systeme ermöglicht wurden. Die μPD7220 von NEC war die erste GPU, die auf einem vollständig integrierten NMOS VLSI-Chip hergestellt wurde. Es unterstützte bis zu 1024x1024 Auflösung und legte die Grundlagen für den aufstrebenden PC-Grafikenmarkt. Es wurde in einer Reihe von Grafikkarten verwendet und für Klone wie die Intel 82720, die erste der Intel Grafikverarbeitungseinheiten lizenziert. MOS-Speicher wurde auch in den frühen 1980er Jahren billiger, so dass die Entwicklung von erschwinglichen Framebuffer-Speicher, insbesondere Video RAM (VRAM) von Texas Instruments (TI) in den Mitte der 1980er Jahre eingeführt. 1984 veröffentlichte Hitachi die ARTC HD63484, die erste komplementäre MOS (CMOS) GPU. Es war in der Lage, hochauflösend im Farbmodus und bis zu 4K Auflösung im monochromen Modus anzuzeigen, und es wurde in einer Reihe von Grafikkarten und Terminals in den späten 1980er Jahren verwendet. Im Jahr 1986 stellte TI den TMS34010, den ersten voll programmierbaren MOS-Grafikprozessor vor. Computer-Grafik-Terminals in diesem Jahrzehnt wurden immer intelligenter, semi-standalone und eigenständige Arbeitsplätze. Die Verarbeitung von Grafiken und Anwendungen wurde zunehmend auf die Intelligenz in der Workstation migriert, anstatt sich weiterhin auf zentrale Mainframes und Minicomputer zu verlassen.Typisch für den frühen Übergang zu hochauflösenden Computergrafiken waren intelligente Workstations für den computergestützten Engineering-Markt die Orca 1000, 2000 und 3000 Workstations, entwickelt von Orcatech von Ottawa, ein Spin-off von Bell-Northern Research, und geleitet von David Pearson, einem frühen Workstation Pionier. Die Orca 3000 basierte auf dem 16-Bit Motorola 68000 Mikroprozessor und AMD Bit-Slice Prozessoren und hatte Unix als Betriebssystem. Sie wurde am ausgeklügelten Ende der Konstruktionsbranche zielgerichtet. Künstler und Grafikdesigner begannen, den persönlichen Computer zu sehen, vor allem die Commodore Amiga und Macintosh, als ein ernstes Design-Tool, das Zeit sparen und genauer zeichnen könnte als andere Methoden. Der Macintosh bleibt ein beliebtes Werkzeug für Computergrafiken unter grafischen Designstudios und Unternehmen. Moderne Computer aus den 1980er Jahren verwenden oft grafische Benutzeroberflächen (GUI), um Daten und Informationen mit Symbolen, Symbolen und Bildern, anstatt Text zu präsentieren. Grafiken sind eines der fünf Schlüsselelemente der Multimedia-Technologie. Im Bereich des realistischen Renderings entwickelte die japanische Osaka University das LINKS-1 Computer Graphics System, einen Supercomputer, der 1982 bis zu 257 Zilog Z8001 Mikroprozessoren verwendet, um realistische 3D-Computergrafiken zu machen. Laut der Informationsverarbeitungsgesellschaft von Japan: "Der Kern der 3D-Bildwiedergabe berechnet die Helligkeit jedes Pixels, das aus der jeweiligen Sicht, Lichtquelle und Objektposition eine Rendered-Oberfläche bildet. Das LINKS-1-System wurde entwickelt, um eine Bildwiedergabemethodik zu realisieren, bei der jedes Pixel unabhängig mit der Strahlverfolgung parallel verarbeitet werden könnte. Durch die Entwicklung einer neuen Softwaremethodik speziell für die Hochgeschwindigkeits-Bildwiedergabe konnte LINKS-1 schnell sehr realistische Bilder machen. Es wurde verwendet, um das weltweit erste 3D-Planetarium-ähnliche Video des gesamten Himmels zu erstellen, das komplett mit Computergrafiken hergestellt wurde. Das Video wurde im Fujitsu-Pavillon auf der Internationalen Ausstellung von 1985 in Tsukuba präsentiert." Der LINKS-1 war ab 1984 der mächtigste Computer der Welt. Auch im Bereich der realistischen Rendering wurde 1986 die allgemeine Rendering-Gleichung von David Immel und James Kajiya entwickelt – ein wichtiger Schritt zur Umsetzung der globalen Beleuchtung, die notwendig ist, um Photorealismus in Computergrafiken zu verfolgen. Die anhaltende Popularität von Star Wars und anderen Science-Fiction-Franchsen waren in der filmischen CGI zu dieser Zeit relevant, da Lucasfilm und Industrial Light & Magic von vielen anderen Studios als Go-to-Haus für topnotch Computergrafiken im Film bekannt wurde. Für die späteren Filme der ursprünglichen Trilogie wurden wichtige Fortschritte bei der Chroma-Schlüssel (Blauscreening usw.) erzielt. Zwei weitere Videostücke würden auch die Ära als historisch relevant überwältigen: Dire Straits' legendäres, fast-CGI-Video für ihren Song "Money for Nothing" im Jahr 1985, das CGI unter den Musikfans dieser Ära populär machte, und eine Szene von Young Sherlock Holmes im selben Jahr mit dem ersten voll CGI-Zeichen in einem Spielfilm (ein animierter Buntglas-Ritter). 1988 wurden die ersten Shader – kleine Programme, die speziell als separater Algorithmus entworfen wurden – von Pixar entwickelt, die bereits als eigenständige Einheit von Industrial Light & Magic abgesponnen waren – obwohl die Öffentlichkeit die Ergebnisse dieses technologischen Fortschritts bis ins nächste Jahrzehnt nicht sehen würde. In den späten 1980er Jahren, Silicon Graphics (SGI) Computer wurden verwendet, um einige der ersten vollständig computergenerierten Kurzfilme auf Pixar zu erstellen, und Silicon Graphics Maschinen wurden als eine High-Wasser-Marke für das Feld während des Jahrzehnts betrachtet. Die 1980er Jahre werden auch die goldene Ära von Videospielen genannt; Millionen-Selling-Systeme von Atari, Nintendo und Sega, unter anderem Unternehmen, exponierte Computergrafiken zum ersten Mal einem neuen, jungen und impressionablen Publikum – ebenso wie MS-DOS-basierte Personalcomputer, Apple IIs, Macs, und Amigas, die es den Anwendern erlaubten, ihre eigenen Spiele zu programmieren, wenn sie gut genug sind. Für die Arkaden wurden Fortschritte in kommerziellen, Echtzeit 3D-Grafik gemacht. 1988 wurden mit dem Namco System 21 und dem Taito Air System die ersten dedizierten 3D-Grafikkarten für Arkaden eingeführt. Auf der professionellen Seite entwickelten Evans & Sutherland und SGI 3D-Raster-Grafik-Hardware, die die spätere Single-Chip-Grafik-Verarbeitungseinheit (GPU) direkt beeinflusste, eine Technologie, in der ein separater und sehr leistungsstarker Chip in der parallelen Verarbeitung mit einer CPU zur Optimierung von Grafiken verwendet wird. Im Jahrzehnt wurden auch Computergrafiken auf viele weitere professionelle Märkte angewendet, darunter standortbasierte Unterhaltung und Bildung mit dem E&S Digistar, Fahrzeugdesign, Fahrzeugsimulation und Chemie. 1990sDie überwältigende Note der 1990er Jahre war die Entstehung von 3D-Modellierungen im Massenmaßstab und ein beeindruckender Anstieg der Qualität von CGI im Allgemeinen. Home-Computer wurden in der Lage, auf Rendering-Aufgaben zu nehmen, die zuvor auf Workstations, die Tausende von Dollar kosten beschränkt waren; als 3D-Modeller für Heimsysteme zur Verfügung wurden, die Popularität von Silicon Graphics Workstations abgelehnt und mächtige Microsoft Windows und Apple Macintosh-Maschinen, die Autodesk-Produkte wie 3D Studio oder andere Heim Rendering-Software in Bedeutung aufgestiegen. Bis zum Ende des Jahrzehnts würde die GPU ihren Aufstieg auf die noch heute genießende Prominenz beginnen. Das Feld fing an, die ersten gemachten Grafiken zu sehen, die wirklich als photorealistisch an das untrainierte Auge übergeben könnten (obwohl sie dies noch nicht mit einem geschulten CGI-Künstler tun konnten) und 3D-Grafiken wurden viel populärer in Spielen, Multimedia und Animation. Ende der 1980er Jahre und Anfang der neunziger Jahre wurden in Frankreich die erste Computergrafik-TV-Serie erstellt: La Vie des bêtes by studio Mac Guff Ligne (1988) Les Fables Géométriques (1989–1991) by studio Fantôme und Quarxs, die erste HDTV-Computergrafikserie von Maurice Benayoun und François Schuiten (Studio Z-A Produktion, 1990–1993). Im Film begann Pixar in dieser Zeit unter Edwin Catmull mit seiner ersten großen Filmrelease 1995 – Toy Story – einem kritischen und kommerziellen Erfolg von neunstelliger Größe. Das Studio, um den programmierbaren Shader zu erfinden, würde weiter gehen, um viele animierte Hits zu haben, und seine Arbeit an prerendered Video-Animation gilt immer noch als Branchenführer und Research Trail Breaker. In Videospielen, 1992, Virtua Racing, auf dem Sega Model 1 Arcade System Board, legte die Grundlagen für voll 3D-Rennspiele und populäre Echtzeit 3D-polygonalgrafiken unter einem breiteren Publikum in der Videospielindustrie. Das Sega Modell 2 im Jahr 1993 und Sega Model 3 im Jahr 1996 drängten anschließend die Grenzen kommerzieller, Echtzeit-3D-Grafiken. Zurück auf dem PC, Wolfenstein 3D, Doom und Quake, drei der ersten massiv populären 3D-First-Personen-Shooter-Spiele, wurden von id Software zur kritischen und beliebten Akclaim in diesem Jahrzehnt mit einem Rendering-Engine innoviert vor allem von John Carmack veröffentlicht. Die Sony PlayStation, Sega Saturn und Nintendo 64, unter anderem Konsolen, verkauft in den Millionen und populär gemacht 3D Grafiken für Heimspieler. Bestimmte 3D-Titel der späten 1990er-Jahre wurden als einflussreich bei der Popularisierung von 3D-Grafik unter den Konsolennutzern gesehen, wie Plattformspiele Super Mario 64 und The Legend Of Zelda:Ocarina Of Time und frühen 3D-Kampfspiele wie Virtua Fighter, Battle Arena Toshinden und Tekken. Technologie und Algorithmen für Rendering haben sich weiter stark verbessert. Im Jahr 1996 erfand Krishnamurty und Levoy eine normale Kartierung – eine Verbesserung der Stoßkartierung von Jim Blinn.1999 veröffentlichte Nvidia das Halbnal GeForce 256, die erste Home-Videokarte, die als Grafik-Verarbeitungseinheit oder GPU abgerechnet wurde, die in eigenen Worten "integrierte Transformation, Beleuchtung, Dreieck-Setup/Clipping und Rendering Engines" enthielt. Bis Ende des Jahrzehnts haben Computer gemeinsame Rahmenbedingungen für die grafische Verarbeitung wie DirectX und OpenGL übernommen. Seitdem sind Computergrafiken aufgrund leistungsfähiger Grafikhardware und 3D-Modellierungssoftware nur noch detaillierter und realistischer geworden. AMD wurde auch in diesem Jahrzehnt ein führender Entwickler von Grafikkarten und schaffte ein Duopoly auf dem Gebiet, das heute existiert. 2000er Jahre CGI wurde in dieser Zeit allgegenwärtig im Ernst. Videospiele und CGI-Kino hatten die Reichweite von Computergrafiken bis Ende der 1990er Jahre auf den Mainstream ausgeweitet und in den 2000er Jahren weiter beschleunigt. CGI wurde auch in den späten 1990er und 2000er Jahren für Fernsehwerbungen in großem Umfang angenommen und so einem massiven Publikum bekannt. Der anhaltende Anstieg und die zunehmende Raffinesse der Grafik-Verarbeitungseinheit waren für dieses Jahrzehnt von entscheidender Bedeutung, und 3D-Rendering-Funktionen wurden zu einem Standard-Feature, da 3D-Grafiken GPUs als eine Notwendigkeit für Desktop-Computerhersteller zu bieten. Die Nvidia GeForce Linie der Grafikkarten dominierte den Markt in den frühen Jahrzehnten mit gelegentlichem bedeutenden konkurrierenden Präsenz von ATI. Wie die Jahrzehnte vorangingen, enthielten auch Low-End-Maschinen in der Regel eine 3D-fähige GPU von irgendeiner Art, wie Nvidia und AMD sowohl Low-Preis-Chipsätze eingeführt und weiterhin den Markt dominieren. Shaders, die in den 1980er Jahren eingeführt worden waren, um spezialisierte Verarbeitung auf der GPU durchzuführen, würde bis Ende des Jahrzehnts auf die meisten Verbraucherhardware unterstützt, beschleunigt die Grafik erheblich und ermöglicht eine deutlich verbesserte Textur und Schattierung in Computergrafiken über die weit verbreitete Annahme von normalen Mapping, Stoß Mapping und eine Vielzahl von anderen Techniken, die die Simulation einer großen Menge Detail ermöglichen. Computergrafiken, die in Filmen und Videospielen verwendet werden, begannen nach und nach realistisch zu dem Punkt, in das unheimliche Tal zu gelangen. CGI-Filme proliferiert, mit traditionellen animierten Cartoon-Filmen wie Ice Age und Madagaskar sowie zahlreiche Pixar-Angebote wie Finding Nemo dominieren die Box Büro in diesem Bereich. Die Final Fantasy: The Spirits Inside, veröffentlicht im Jahr 2001, war der erste vollständig computergenerierte Feature-Film, um photorealistische CGI-Zeichen zu verwenden und vollständig mit Motion Capture gemacht werden. Der Film war jedoch kein Box-Office-Erfolg. Einige Kommentatoren haben vorgeschlagen, dies kann teilweise sein, weil die führenden CGI-Zeichen Gesichtszüge hatten, die in das "unheimische Tal" fielen. Auch andere animierte Filme wie The Polar Express haben zu dieser Zeit aufmerksam gemacht. Star Wars hat sich auch mit seiner präquel Trilogie wiedergefunden und die Effekte setzten eine Bar für CGI in Film. In Videospielen, die Sony PlayStation 2 und 3, die Microsoft Xbox-Linie von Konsolen, und Angebote von Nintendo wie das GameCube eine große Folge, wie auch der Windows-PC. Marquee CGI-heavy Titel wie die Serie von Grand Theft Auto, Assassin's Creed, Final Fantasy, BioShock, Kingdom Hearts, Mirror's Edge und Dutzende von anderen ging weiterhin auf Photorealismus, wachsen die Videospielindustrie und beeindrucken, bis die Einnahmen der Branche mit denen von Filmen vergleichbar wurden. Microsoft hat eine Entscheidung getroffen, Direct auszusetzen X leichter zur unabhängigen Entwicklerwelt mit dem XNA-Programm, aber es war kein Erfolg. Direkt X selbst blieb jedoch ein kommerzieller Erfolg. Auch OpenGL reifte weiter, und es und Direct X hat sich stark verbessert; in diesem Jahrzehnt begannen die Shadersprachen der zweiten Generation HLSL und GLSL populär zu sein. In der wissenschaftlichen Berechnung wurde die GPGPU-Technik entwickelt, um große Mengen von Daten bidirektional zwischen einer GPU und CPU zu passieren; beschleunigte Analyse auf vielen Arten von Bioinformatik und Molekularbiologie Experimente. Die Technik wurde auch für Bitcoin Bergbau verwendet und hat Anwendungen in der Computer-Vision. 2010sIn den 2010er Jahren, CGI war fast allgegenwärtig in Video, vor-Rendered-Grafik sind fast wissenschaftlich photorealistisch, und Echtzeit-Grafik auf einem geeignet High-End-System kann Photorealismus zu dem untrainierten Auge simulieren. Texture Mapping ist in einen mehrstufigen Prozess mit vielen Schichten gereift; in der Regel ist es nicht ungewöhnlich, Textur Mapping, Stoß Mapping oder Iso-Oberflächen oder normale Mapping, Beleuchtungskarten einschließlich spekulären Highlights und Reflexionstechniken, und Schattenvolumina in einem Rendering-Engine mit Shadern durchzuführen, die stark widerstanden. Shaders sind jetzt sehr fast eine Notwendigkeit für fortgeschrittene Arbeit im Feld, bieten erhebliche Komplexität in der Manipulation von Pixeln, Vertiken und Texturen auf einer per-Element-Basis, und unzählige mögliche Effekte. Ihre Schattensprachen HLSL und GLSL sind aktive Bereiche der Forschung und Entwicklung. Physikalisch basiertes Rendering oder PBR, das viele Karten implementiert und erweiterte Berechnung durchführt, um realen optischen Lichtstrom zu simulieren, ist ein aktives Forschungsgebiet sowie fortgeschrittene Bereiche wie Umgebungs-Okclusion, Untergrund-Streuung, Rayleigh-Streuung, Photonen-Mapping und viele andere. Experimente in die Verarbeitungsleistung, die erforderlich ist, um Grafiken in Echtzeit in Ultra-High-Resolution-Modi wie 4K Ultra HD zu liefern, beginnen jedoch über die Reichweite aller, aber die höchste Hardware. Im Kino sind die meisten animierten Filme jetzt CGI; viele animierte CGI-Filme werden pro Jahr hergestellt, aber nur wenige, wenn überhaupt, versuchen Photorealismus durch anhaltende Angst vor dem unheimlichen Tal. Die meisten sind 3D Cartoons. In Videospielen dominieren die Microsoft Xbox One, Sony PlayStation 4 und Nintendo Switch derzeit den Heimraum und sind alle in der Lage, hochmoderne 3D-Grafiken; der Windows PC ist noch eine der aktivsten Gaming-Plattformen. Bildtypen Zweidimensionale 2D-Computergrafiken sind die computergestützte Generierung digitaler Bilder – vor allem von Modellen wie digitalem Bild und von ihnen spezifischen Techniken. 2D-Computergrafiken werden hauptsächlich in Anwendungen verwendet, die ursprünglich auf traditionellen Druck- und Zeichentechnologien wie Typografie entwickelt wurden. In diesen Anwendungen ist das zweidimensionale Bild nicht nur eine Darstellung eines realen Objekts, sondern ein eigenständiges Artefakt mit einem zusätzlichen semantischen Wert; zweidimensionale Modelle sind daher bevorzugt, weil sie eine direktere Steuerung des Bildes als 3D-Computergrafiken geben, deren Ansatz eher fotografisch als typographieähnlich ist. Pixel artEine große Form der digitalen Kunst, Pixel-Kunst wird durch die Verwendung von Rastergrafik-Software erstellt, wo Bilder auf der Pixelebene bearbeitet werden. Grafiken in den meisten alten (oder relativ begrenzten) Computer- und Videospielen, Grafikrechnerspiele und viele Handyspiele sind meist Pixelkunst. Sprite Grafiken Ein Sprit ist ein zweidimensionales Bild oder eine Animation, die in eine größere Szene integriert ist. Zunächst nur graphische Objekte, die getrennt von der Speicher-Bitmap eines Videodisplays bearbeitet werden, umfasst dies nun verschiedene Arten von grafischen Overlays. Ursprünglich waren Sprite eine Methode zur Integration von unabhängigen Bitmaps, so dass sie Teil der normalen Bitmap auf einem Bildschirm zu sein schienen, wie zum Beispiel ein animiertes Zeichen, das auf einem Bildschirm bewegt werden kann, ohne die Daten zu ändern, die den gesamten Bildschirm definieren. Solche Sprite können entweder durch elektronische Schaltung oder Software erzeugt werden. In der Schaltung ist ein Hardware-Sprit ein Hardware-Konstrukt, das benutzerdefinierte DMA-Kanäle verwendet, um visuelle Elemente mit dem Hauptbildschirm zu integrieren, indem es zwei diskrete Videoquellen übertrifft. Software kann dies durch spezialisierte Rendering-Methoden simulieren. Vektorgrafiken Vektorgrafikformate sind komplementär zu Rastergrafiken. Rastergrafik ist die Darstellung von Bildern als Pixel-Array und wird typischerweise für die Darstellung fotografischer Bilder verwendet. Vektorgrafiken bestehen in der Codierung von Informationen über Formen und Farben, die das Bild enthalten, was eine größere Flexibilität beim Rendern ermöglichen kann. Es gibt Instanzen, wenn die Arbeit mit Vektor-Tools und Formaten ist beste Praxis, und Instanzen, wenn die Arbeit mit Raster-Tools und Formate ist beste Praxis. Es gibt Zeiten, in denen beide Formate zusammenkommen. Ein Verständnis der Vorteile und Einschränkungen jeder Technologie und der Beziehung zwischen ihnen ist wahrscheinlich zu einer effizienten und effektiven Verwendung von Werkzeugen führen. Dreidimensionale 3D-Grafiken im Vergleich zu 2D-Grafiken sind Grafiken, die eine dreidimensionale Darstellung geometrischer Daten verwenden. Diese wird zum Zwecke der Leistung im Computer gespeichert. Dies umfasst Bilder, die für eine spätere Anzeige oder für Echtzeit-Anzeige sein können. Trotz dieser Unterschiede verlassen sich 3D-Computergrafiken auf ähnliche Algorithmen, wie 2D-Computergrafiken im Rahmen und Rastergrafiken (wie in 2D) im letzten Rendered-Display. In der Computer-Grafiken-Software ist die Unterscheidung zwischen 2D und 3D gelegentlich verwischt; 2D-Anwendungen können 3D-Techniken verwenden, um Effekte wie Beleuchtung zu erzielen, und in erster Linie 3D kann 2D-Rendering-Techniken verwenden. 3D-Computergrafiken sind die gleichen wie 3D-Modelle. Das Modell ist in der grafischen Datendatei enthalten, abgesehen von der Wiedergabe. Es gibt jedoch Unterschiede, die das 3D-Modell beinhalten, die Darstellung eines beliebigen 3D-Objekts. Bis visuell ein Modell angezeigt wird, ist keine Grafik. Aufgrund des Drucks sind 3D-Modelle nicht nur auf virtuellen Raum beschränkt. 3D-Rendering ist, wie ein Modell angezeigt werden kann. Auch können in nicht-graphischen Computersimulationen und Berechnungen verwendet werden. Computeranimation Computeranimation ist die Kunst, bewegte Bilder über die Verwendung von Computern zu erstellen. Es ist ein Unterfeld von Computergrafiken und Animation. Zunehmend wird es durch 3D-Computergrafiken erstellt, obwohl 2D-Computergrafiken noch weit verbreitet für stilistische, geringe Bandbreite und schnellere Echtzeit-Rendering-Anforderungen verwendet werden. Manchmal ist das Ziel der Animation der Computer selbst, aber manchmal ist das Ziel ein anderes Medium, wie Film. Es wird auch als CGI (Computergenerierte Bildsprache oder computergenerierte Bildgebung) insbesondere bei der Verwendung in Filmen bezeichnet. Virtuelle Einheiten können in der Transformationsmatrix eines Objekts gespeicherte, sortierte Attribute wie Transformationswerte (Position, Orientierung und Skala) enthalten und kontrolliert werden. Animation ist die Änderung eines Attributs über die Zeit. Es gibt mehrere Methoden, um Animationen zu erreichen; die rudimentäre Form basiert auf der Erstellung und Bearbeitung von Keyframes, die jeweils einen Wert zu einem bestimmten Zeitpunkt speichern, pro Attribut animiert werden. Die 2D/3D-Grafiksoftware wird sich mit jedem Keyframe ändern, wodurch eine bearbeitbare Kurve eines im Laufe der Zeit abgebildeten Wertes entsteht, in dem Animationen entstehen. Andere Methoden der Animation umfassen verfahrens- und ausdrucksbasierte Techniken: die ehemaligen konsolidieren verwandte Elemente von animierten Einheiten in Sätze von Attributen, nützlich für die Erstellung von Partikeleffekten und Massensimulationen; Letztere erlaubt ein aus einem benutzerdefinierten logischen Ausdruck zurückgegebenes Ergebnis, gekoppelt mit Mathematik, um die Animation in vorhersehbarer Weise zu automatisieren (bequem für die Steuerung des Knochenverhaltens über das, was eine Hierarchie im skele System eingerichtet bietet). Um die Illusion der Bewegung zu erzeugen, wird auf dem Computerbildschirm ein Bild angezeigt, das dann schnell durch ein neues Bild ersetzt wird, das dem vorherigen Bild ähnlich ist, aber leicht verschoben wird. Diese Technik ist identisch mit der Illusion der Bewegung in Fernseh- und Bewegungsbildern. Konzepte und Prinzipien Bilder werden typischerweise von Geräten wie Kameras, Spiegeln, Objektiven, Teleskopen, Mikroskopen usw. erstellt. Digitale Bilder umfassen sowohl Vektorbilder als auch Rasterbilder, aber Rasterbilder werden häufiger verwendet. Pixel Bei der digitalen Bildgebung ist ein Pixel (oder Bildelement) ein einziger Punkt in einem Rasterbild. Pixel werden auf einem regelmäßigen 2-dimensionalen Raster platziert und oft mit Punkten oder Quadraten dargestellt. Jedes Pixel ist eine Probe eines Originalbildes, wobei mehr Proben typischerweise eine genauere Darstellung des Originals liefern. Die Intensität jedes Pixels ist variabel; in Farbsystemen weist jedes Pixel typischerweise drei Komponenten wie Rot, Grün und Blau auf. Grafiken sind visuelle Präsentationen auf einer Oberfläche, wie ein Computerbildschirm. Beispiele sind Fotografien, Zeichnungen, Grafikdesigns, Karten, technische Zeichnungen oder andere Bilder. Grafiken kombinieren oft Text und Illustration. Grafikdesign kann aus der bewussten Auswahl, Erstellung oder Anordnung von Typografie allein bestehen, wie in einer Broschüre, Flyer, Plakat, Website oder Buch ohne andere Elemente. Klarheit oder effektive Kommunikation kann das Ziel sein, die Vereinigung mit anderen kulturellen Elementen kann gesucht werden, oder nur die Schaffung eines unverwechselbaren Stils.Primitives Primitives sind grundlegende Einheiten, die ein Grafiksystem kombinieren kann, um komplexere Bilder oder Modelle zu erstellen. Beispiele wären Sprite und Zeichenkarten in 2D-Videospielen, geometrische Primitiven in CAD oder Polygonen oder Dreiecken in 3D-Rendering. Primitiven können in Hardware für effizientes Rendern oder die von einer Grafikanwendung bereitgestellten Bausteine unterstützt werden. Rendering Rendering ist die Erzeugung eines 2D-Bildes aus einem 3D-Modell mittels Computerprogrammen. Eine Szenendatei enthält Objekte in einer streng definierten Sprache oder Datenstruktur; sie würde Geometrie, Aussichtspunkt, Textur, Beleuchtung und Abschattungsinformationen als Beschreibung der virtuellen Szene enthalten. Die in der Szenendatei enthaltenen Daten werden dann an ein zu bearbeitendes Rendering-Programm übergeben und an eine digitale Bild- oder Rastergrafikbilddatei ausgegeben. Das Rendering-Programm wird in der Regel in die Computer-Grafik-Software integriert, obwohl andere als Plug-In oder ganz separate Programme verfügbar sind. Der Begriff Rendering kann analog zu einem "Künstler-Rendering" einer Szene sein. Obwohl die technischen Details der Rendering-Methoden variieren, werden die allgemeinen Herausforderungen, bei der Erstellung eines 2D-Bildes aus einer in einer Szenendatei gespeicherten 3D-Darstellung zu überwinden, als Grafikpipeline entlang eines Rendering-Geräts, wie einer GPU, skizziert. Eine GPU ist ein Gerät, das die CPU bei Berechnungen unterstützen kann. Wenn eine Szene unter virtueller Beleuchtung relativ realistisch und vorhersehbar aussehen soll, sollte die Rendering-Software die Rendering-Gleichung lösen. Die Rendering-Gleichung berücksichtigt nicht alle Lichterscheinungen, sondern ist ein allgemeines Beleuchtungsmodell für computergenerierte Bildgebung. Rendering wird auch verwendet, um den Prozess der Berechnung von Effekten in einer Videobearbeitungsdatei zu beschreiben, um endgültige Videoausgabe zu erstellen. 3D-Projektion 3D-Projektion ist ein Verfahren zur Abbildung von dreidimensionalen Punkten auf eine zweidimensionale Ebene. Da die meisten aktuellen Methoden zur Darstellung von grafischen Daten auf planaren zweidimensionalen Medien basieren, ist die Verwendung dieser Art von Projektion weit verbreitet. Dieses Verfahren wird in den meisten Echtzeit-3D-Anwendungen verwendet und verwendet typischerweise eine Rasterung, um das endgültige Bild zu erzeugen. Ray-Tracing Ray-Tracing ist eine Technik aus der Familie der Bildauftragsalgorithmen zur Erzeugung eines Bildes, indem man den Pfad des Lichts durch Pixel in einer Bildebene verfolgt. Die Technik ist in der Lage, einen hohen Photorealismus zu erzeugen; in der Regel höher als die der typischen Scanline-Rendering-Methoden, aber mit einem größeren Rechenaufwand. Shading Shading bezieht sich auf die Darstellung der Tiefe in 3D-Modellen oder Abbildungen durch unterschiedliche Ebenen der Dunkelheit. Es ist ein Verfahren, das in der Zeichnung zur Darstellung von Ebenen der Dunkelheit auf Papier verwendet wird, indem Medien stärker dicht oder mit einem dunkleren Schatten für dunklere Bereiche, und weniger dicht oder mit einem helleren Schatten für hellere Bereiche. Es gibt verschiedene Techniken der Schattierung einschließlich Kreuzschraffur, wo senkrechte Linien unterschiedlicher Nähe in einem Rastermuster gezogen werden, um eine Fläche zu schattieren. Je näher die Linien zusammen sind, desto dunkler erscheint die Fläche. Ebenso, je weiter die Linien sind, desto leichter erscheint die Fläche. Der Begriff wurde kürzlich verallgemeinert, so dass Shader angewendet werden. Textur Mapping Texture Mapping ist ein Verfahren zum Hinzufügen von Detail, Oberflächentextur oder Farbe zu einem computergenerierten Grafik- oder 3D-Modell. Seine Anwendung auf 3D-Grafiken wurde 1974 von Dr. Edwin Catmull Pionier. Eine Texturkarte wird auf die Oberfläche einer Form oder Polygon aufgetragen. Dieser Prozess ist akin, um gemustertes Papier auf eine glatte weiße Box anzuwenden. Multitexturierung ist die Verwendung von mehr als einer Textur zu einer Zeit auf einem Polygon. Procedural Texturen (aus Stellparametern eines zugrunde liegenden Algorithmus, der eine Ausgangstextur, erzeugt) und Bitmap-Texturen (in einer Bildbearbeitungsapplikation erstellt oder aus einer Digitalkamera importiert) sind in der Regel gemeinsame Methoden der Implementierung von Texturdefinition auf 3D-Modellen in Computergrafiksoftware, während die beabsichtigte Platzierung von Texturen auf die Oberfläche eines Modells oft erfordert eine Technik, die als UV-Mapping (arbitrary, manuelle Layout von Oberflächen verwendet wird, Texture Mapping als Disziplin umfasst auch Techniken für die Erstellung von normalen Karten und Stoßkarten, die einer Textur entsprechen, um Höhen- und Spekularkarten zu simulieren, um Glanz und Lichtreflexe zu simulieren, sowie Umwelt Mapping, um Spiegelreflexivität zu simulieren, auch Gloss genannt. Anti-aliasing Rendering lösungsunabhängige Entitäten (wie 3D-Modelle) zum Betrachten auf einem Raster (pixel-based) Gerät wie einem Flüssigkristall-Display oder CRT-Fernseher verursachen zwangsläufig Aliasing Artefakte meist entlang geometrischer Kanten und Grenzen von Texturdetails; diese Artefakte werden informell als Jaggies bezeichnet". Anti-Aliasing-Methoden beheben solche Probleme, was zu einer Bildsprache, die dem Betrachter angenehmer ist, aber etwas rechnerisch teuer sein kann. Verschiedene Anti-Aliasing-Algorithmen (wie Supersampling) sind in der Lage, verwendet werden, dann auf die effizienteste Rendering-Performance im Vergleich zur Qualität der resultierenden Bilder angepasst; ein Grafik-Künstler sollte dieses Trade-off betrachten, wenn Anti-Aliasing-Methoden verwendet werden sollen. Eine vor-Anti-Aliased-Bitmap-Textur, die auf einem Bildschirm (oder Bildschirmort) mit einer anders als die Auflösung der Textur selbst (wie ein texturiertes Modell im Abstand zur virtuellen Kamera) angezeigt wird, zeigt Aliasing Artefakte, während jede verfahrensdefinierte Textur immer Aliasing Artefakte zeigt, wie sie lösungsunabhängig sind; Techniken wie Mipmapping und Texturfilterung helfen, texturbedingte Alias zu lösen. Volume Rendering Volume Rendering ist eine Technik, mit der eine 2D Projektion eines 3D diskret abgetasteten Datensatzes angezeigt wird. Ein typischer 3D-Datensatz ist eine Gruppe von 2D-Scheibenbildern, die von einem CT- oder MRT-Scanner erfasst werden. Üblicherweise werden diese in einem regelmäßigen Muster (z.B. je Millimeter eine Schicht) erfasst und weisen in der Regel eine regelmäßige Anzahl von Bildpixeln in einem regelmäßigen Muster auf. Dies ist ein Beispiel für ein regelmäßiges Volumengitter, wobei jedes Volumenelement oder Voxel durch einen einzigen Wert repräsentiert wird, der durch Abtastung der unmittelbaren Umgebung des Voxels gewonnen wird. 3D-Modellierung 3D-Modellierung ist der Prozess der Entwicklung einer mathematischen, drahtgebundenen Darstellung jedes dreidimensionalen Objekts, genannt "3D-Modell", über spezialisierte Software. Modelle können automatisch oder manuell erstellt werden; der manuelle Modellierungsprozess der Erstellung von geometrischen Daten für 3D-Computergrafiken ist ähnlich wie plastische Kunst wie Bildhauer. 3D-Modelle können mit mehreren Ansätzen erstellt werden: Verwendung von NURBs zur Erzeugung von genauen und glatten Oberflächenpatches, polygonalen Mesh-Modellierung (Manipulation von facettenförmiger Geometrie) oder polygonalen Mesh-Unterteilung (fortgeschrittene Tessellation von Polygonen, was zu glatten Oberflächen ähnlich NURB-Modellen führt). Ein 3D-Modell kann als zweidimensionales Bild durch ein Verfahren mit dem Namen 3D-Rendering dargestellt werden, das in einer Computersimulation von physikalischen Phänomenen verwendet wird oder direkt zu anderen Zwecken animiert wird. Das Modell kann auch mit 3D-Druckgeräten physisch erstellt werden. Die Pioniere der Computergrafik Charles Csuri Charles Csuri ist ein Pionier in der Computeranimation und der digitalen bildenden Kunst und schuf 1964 die erste Computerkunst. Csuri wurde von Smithsonian als Vater der digitalen Kunst und Computeranimation anerkannt, und als Pionier der Computeranimation durch das Museum of Modern Art (MoMA) und Association for Computing Machinery-SIGGRAPH. Donald P. Greenberg Donald P. Greenberg ist ein führender Innovator in Computergrafiken. Greenberg hat Hunderte von Artikeln geschrieben und diente als Lehrer und Mentor für viele prominente Computer-Grafik-Künstler, Animatoren und Forscher wie Robert L. Cook, Marc Levoy, Brian A. Barsky und Wayne Lytle. Viele seiner ehemaligen Studenten haben Academy Awards für technische Leistungen gewonnen und mehrere haben den SIGGRAPH Achievement Award gewonnen. Greenberg war Gründungsdirektor des NSF Centers für Computergrafik und wissenschaftliche Visualisierung. A Michael Noll Noll war einer der ersten Forscher, der einen digitalen Computer nutzt, um künstlerische Muster zu schaffen und den Einsatz von zufälligen Prozessen bei der Schaffung von bildenden Künsten zu formalisieren. 1962 begann er, digitale Kunst zu schaffen und machte ihn zu einem der frühesten digitalen Künstler. Im Jahr 1965 waren Noll zusammen mit Frieder Nake und Georg Nees die ersten, die ihre Computerkunst öffentlich ausstellen. Im April 1965 stellte die Howard Wise Gallery Nolls Computerkunst zusammen mit zufälligen Mustern von Bela Julesz aus. Weitere Pioniere Pierre Bézier Jim Blinn Jack Bresenham John Carmack Paul de CasteljauEd Catmull Frank Crow James D. Foley William Fetter Henry Fuchs Henri Gouraud Charles Loop Nadia Magnenat Thalmann Benoit MandelbrotMartin Newell Fred Parken Sie Bui Tuong Phong David Pearson Steve Russell Daniel J. Sandin Alvy Ray Smith Bob Sproull Ivan Sutherland Daniel Thalmann Andries van Dam John Warnock J. Turner Whitted Lance Williams Jim Kajiya Organisationen GDC Bell Telephone Laboratories United States Armed Forces, insbesondere der Whirlwind Computer und SAGE Projekt Boeing IBM Renault Die Informatikabteilung der Universität Utah Lucasfilm und Industrial Light & Magic Autodesk Adobe Systems Pixar Silicon Graphics, Khronos Group & Open GLThe Direct X Division bei Microsoft Nvidia AMD Studie von Computergrafiken Die Studie der Computergrafiken ist ein Teilgebiet der Informatik, das Methoden zur digitalen Synthesisierung und Manipulation visueller Inhalte untersucht. Obwohl der Begriff oft auf dreidimensionale Computergrafiken verweist, umfasst er auch zweidimensionale Grafiken und Bildverarbeitung. Als akademische Disziplin, Computergrafiken studiert die Manipulation von visuellen und geometrischen Informationen mit computergestützten Techniken. Es konzentriert sich auf die mathematischen und rechnerischen Grundlagen der Bilderzeugung und -verarbeitung statt auf rein ästhetische Fragen. Computergrafiken werden oft vom Bereich der Visualisierung unterschieden, obwohl die beiden Felder viele Ähnlichkeiten haben. Anwendungen Computergrafiken können in den folgenden Bereichen verwendet werden: Computational biology Computational Photography Computational Physics Computer-aided design Computersimulation Design Digitale Kunst Ausbildung Grafikdesign Infografik Visualisierung Rational Drug Design Wissenschaftliche Visualisierung Spezialeffekte für Kino Videospiele Virtuelle Realität Webdesign Siehe auch Computer-Darstellung von Oberflächen Glossar von Computer-Grafik Hinweis ReferenzenWeiter lesen L. Ammeraal und K. Zhang (2007). Computergrafik für Java Programmierer, Second Edition, John-Wiley & Sons, ISBN 978-0-470-03160-5.David Rogers (1998). Procedural Elemente für Computer Graphics.McGraw-Hill. James D. Foley, Andries Van Dam, Steven K. Feiner und John F. Hughes (1995). Computer Graphics: Prinzipien und Praxis. Addison-Wesley.Donald Hearn und M. Pauline Baker (1994). Computergrafiken. Prentice-Hall. Francis S. Hill (2001). Computergrafiken. Prentice Hall. John Lewell (1985). Computer Graphics: Eine Übersicht über aktuelle Techniken und Anwendungen. Van Nostrand Reinhold. Jeffrey J. McConnell (2006). Computer Graphics: Theorie in Praxis. Jones und Bartlett Publishers.R D. Parslow, R. W. Prowse, Richard Elliot Green (1969). Computergrafik: Techniken und Anwendungen. Peter Shirley und andere.(2005). Grundlagen der Computergrafik. A.K Peters, Ltd. M. Slater, A. Steed, Y. Chrysantho (2002). Computergrafiken und virtuelle Umgebungen: vom Realismus bis zur Echtzeit. Addison-Wesley. Wolfgang Höhl (2008): Interaktive Umgebungen mit Open-Source-Software, Springer Wien New York, ISBN 3-211-79169-8 Externe Links A Critical History of Computer Graphics and Animation History of Computer Graphics series of article Computer Graphics research at UC Berkeley Thomas Dreher: History of Computer Art, chap. IV.2 Computer Animation Geschichte der Computer-Grafik auf RUS