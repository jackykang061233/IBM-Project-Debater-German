Bei der Berechnung ist der Speicher ein Gerät oder System, das verwendet wird, um Informationen zur sofortigen Verwendung in einem Computer oder verwandten Computerhardware und digitalen elektronischen Geräten zu speichern. Der Begriff Speicher ist oft gleichbedeutend mit dem Begriff Primärspeicher oder Hauptspeicher. Ein archaisches Synonym für Erinnerung ist Speicher. Computerspeicher arbeitet mit einer hohen Geschwindigkeit im Vergleich zu Speicher, die langsamer ist, aber bietet höhere Kapazitäten. Falls erforderlich, können Inhalte des Computerspeichers auf die Speicherung übertragen werden; ein gemeinsamer Weg ist dies durch eine Speicherverwaltungstechnik namens virtuellem Speicher. Der moderne Speicher ist als Halbleiterspeicher ausgeführt, wobei Daten in Speicherzellen gespeichert werden, die aus MOS-Transistoren auf einer integrierten Schaltung aufgebaut sind. Es gibt zwei Haupttypen von Halbleiterspeicher, flüchtig und nicht flüchtig. Beispiele für nichtflüchtige Speicher sind Flash-Speicher und ROM, PROM, EPROM und EEPROM-Speicher. Beispiele für flüchtigen Speicher sind Primärspeicher, der typischerweise dynamischer Zufalls-Zugriffsspeicher (DRAM) und schneller CPU-Cache-Speicher ist, der typischerweise statischer Zufalls-Zugriffsspeicher (SRAM) ist, der schnell, aber energieaufwendig ist und eine geringere Speicherarealdichte als DRAM bietet. Die meisten Halbleiterspeicher werden in Speicherzellen oder bistabile Flipflops organisiert, die jeweils ein Bit (0 oder 1) speichern. Flash-Speicherorganisation umfasst sowohl ein Bit pro Speicherzelle und Multi-Level-Zelle, die mehrere Bits pro Zelle speichern können. Die Speicherzellen werden in Wörter fester Wortlänge, beispielsweise 1, 2, 4, 8, 16, 32, 64 oder 128 Bit, gruppiert. Jedes Wort kann durch eine binäre Adresse von N Bits aufgerufen werden, wodurch es möglich ist, 2N Wörter im Speicher zu speichern. Geschichte In den frühen 1940er Jahren erlaubte die Speichertechnologie oft eine Kapazität von einigen Bytes. Der erste elektronische programmierbare digitale Computer, der ENIAC, mit Tausenden von Vakuumröhren, könnte einfache Berechnungen durchführen, die 20 Zahlen von zehn Dezimalstellen beinhalten, die in den Vakuumröhren gespeichert sind. Der nächste signifikante Fortschritt im Computerspeicher kam mit akustischem Verzögerungsleitungsspeicher, entwickelt von J. Presper Eckert in den frühen 1940er Jahren. Durch den Aufbau eines mit Quecksilber gefüllten und an jedem Ende mit einem Quarzkristall verstopften Glasrohres könnten Verzögerungsleitungen Informationen in Form von Schallwellen speichern, die sich durch das Quecksilber ausbreiten, wobei die Quarzkristalle als Wandler dienen, um Bits zu lesen und zu schreiben. Der Delay-Line-Speicher war auf eine Kapazität von bis zu einigen tausend Bits begrenzt. Zwei Alternativen zur Verzögerungsleitung, dem Williams-Rohr und dem Selectron-Rohr, entstanden 1946, beide mit Elektronenstrahlen in Glasrohren als Speichermittel. Mit Kathodenstrahlröhren erfand Fred Williams die Williams-Röhre, die der erste zufällige Computerspeicher war. Die Williams-Röhre konnte mehr Informationen speichern als die Selectron-Röhre (der Selectron war auf 256 Bit begrenzt, während die Williams-Röhre Tausende speichern konnte) und weniger teuer. Die Williams-Röhre war dennoch frustrierend empfindlich auf Umweltstörungen. In den späten 1940er Jahren begannen Bemühungen, nichtflüchtige Erinnerungen zu finden. Magnetic-Core-Speicher erlaubt für die Erinnerung nach Stromausfall. Es wurde von Frederick W. Viehe und An Wang in den späten 1940er Jahren entwickelt und von Jay Forrester und Jan A. Rajchman in den frühen 1950er-Jahren verbessert, bevor sie 1953 mit dem Whirlwind-Computer vertrieben wurden. Magnetkernspeicher war die dominante Form des Speichers bis zur Entwicklung des MOS-Halbleiterspeichers in den 1960er Jahren. Der Halbleiterspeicher begann in den frühen 1960er Jahren mit bipolarem Speicher, der bipolare Transistoren verwendet. Bipolarer Halbleiterspeicher aus diskreten Geräten wurde erstmals 1961 von Texas Instruments an die United States Air Force geliefert. Im selben Jahr wurde das Konzept des Festkörperspeichers auf einem integrierten Schaltkreis (IC) Chip von dem Anwendungsingenieur Bob Norman auf Fairchild Semiconductor vorgeschlagen. Der erste bipolare Halbleiterspeicher IC Chip war der von IBM 1965 eingeführte SP95. Während bipolarer Speicher verbesserte Leistung über Magnetkernspeicher bot, konnte er nicht mit dem niedrigeren Preis von Magnetkern konkurrieren, die bis Ende der 1960er Jahre dominant blieb. Bipolarer Speicher konnte den Magnetkernspeicher nicht ersetzen, da bipolare Flipflop-Schaltungen zu groß und teuer waren. MOS-Speicher Die Erfindung des MOSFET (Metall-Oxid-Halbleiter-Feldeffekttransistor oder MOS-Transistors) von Mohamed M. Atalla und Dawon Kahng bei Bell Labs ermöglichte 1959 den praktischen Einsatz von Metall-Oxid-Halbleiter-Transistoren als Speicherzellenspeicherelemente. MOS-Speicher wurde 1964 von John Schmidt auf Fairchild Semiconductor entwickelt. Neben einer höheren Leistung war der MOS-Halbleiterspeicher billiger und verbrauchte weniger Leistung als der magnetische Kernspeicher. Im Jahr 1965 schlugen J. Wood und R. Ball des Royal Radar Establishment digitale Speichersysteme vor, die CMOS (komplementäre MOS) Speicherzellen verwenden, zusätzlich zu MOSFET-Leistungsgeräten für die Stromversorgung, geschaltete Querkopplung, Schalter und Verzögerungsleitungsspeicher. Die Entwicklung der Silizium-Gate MOS integrierten Schaltung (MOS IC) von Federico Faggin auf Fairchild im Jahr 1968 ermöglichte die Herstellung von MOS-Speicherchips. NMOS-Speicher wurde von IBM in den frühen 1970er Jahren vertrieben. MOS-Speicher übernahm Magnetkernspeicher als dominante Speichertechnologie in den frühen 1970er Jahren. Die beiden Haupttypen des flüchtigen Zutrittsspeichers (RAM) sind statischer Zutrittsspeicher (SRAM) und dynamischer Zutrittsspeicher (DRAM). Bipolar SRAM wurde 1963 von Robert Norman auf Fairchild Semiconductor erfunden, gefolgt von der Entwicklung von MOS SRAM von John Schmidt auf Fairchild 1964. SRAM wurde eine Alternative zum Magnetkernspeicher, erforderte aber sechs MOS-Transistoren für jedes Bit von Daten. Die kommerzielle Nutzung von SRAM begann 1965, als IBM ihren SP95 SRAM Chip für das System/360 Modell 95 einführte. Toshiba führte im Jahr 1965 bipolare DRAM-Speicherzellen für seinen Toscal BC-1411 elektronischen Rechner ein. Während es eine verbesserte Leistung gegenüber Magnetkernspeicher bot, konnte bipolare DRAM nicht mit dem niedrigeren Preis des dann dominanten Magnetkernspeichers konkurrieren. Die MOS-Technologie ist die Basis für das moderne DRAM. 1966 arbeitete Dr. Robert H. Dennard im IBM Thomas J. Watson Research Center an MOS-Speicher. Während er die Eigenschaften der MOS-Technologie untersuchte, stellte er fest, dass es in der Lage war, Kondensatoren aufzubauen, und dass die Speicherung einer Ladung oder keiner Ladung auf dem MOS-Kondensator die 1 und 0 eines Bits darstellen könnte, während der MOS-Transistor das Schreiben der Ladung an den Kondensator steuern könnte. Dies führte zu seiner Entwicklung einer Eintransistor-DRAM-Speicherzelle. 1967 reichte Dennard ein Patent unter IBM für eine Eintransistor-DRAM-Speicherzelle auf Basis der MOS-Technologie ein. Dies führte zum ersten kommerziellen DRAM IC-Chip, dem Intel 1103, im Oktober 1970. Synchroner dynamischer Zufalls-Zugriffsspeicher (SDRAM) wurde 1992 mit dem Samsung KM48SL2000-Chip debütiert. Der Begriff Speicher wird auch häufig verwendet, um auf nichtflüchtige Speicher, speziell Flash-Speicher zu beziehen. Es hat Ursprünge im Nurlesespeicher (ROM). Der programmierbare Lesespeicher (PROM) wurde 1956 von Wen Tsing Chow erfunden, während er für die Arma Division der American Bosch Arma Corporation arbeitete. 1967 schlugen Dawon Kahng und Simon Sze von Bell Labs vor, dass das schwimmende Gate eines MOS-Halbleitergerätes für die Zelle eines reprogrammierbaren Nurlesespeichers (ROM) verwendet werden konnte, der 1971 zu Dov Frohman von Intel inventing EPROM (erasable PROM) führte. EEPROM (elektrisch löschbarer PROM) wurde 1972 von Yasuo Tarui, Yutaka Hayashi und Kiyoko Naga am Elektrotechnischen Labor entwickelt. Flash-Speicher wurde von Fujio Masuoka in Toshiba in den frühen 1980er Jahren erfunden. Masuoka und Kollegen präsentierten die Erfindung von NOR Flash im Jahr 1984 und dann NAND Flash im Jahr 1987. Toshiba kommerziellisierte NAND Flash-Speicher im Jahr 1987. Entwicklungen in der Technologie und der Skalenwirtschaft haben so genannte Very Large Memory (VLM) Computer ermöglicht. Volatile Memory Volatile Memory ist Computerspeicher, der Energie benötigt, um die gespeicherten Informationen zu erhalten. Der modernste Halbleiterspeicher ist entweder statisches RAM (SRAM) oder dynamisches RAM (DRAM). SRAM behält seinen Inhalt solange, wie die Leistung angeschlossen ist und ist einfacher für die Einschaltung, verwendet jedoch sechs Transistoren pro Bit. Dynamisches RAM ist komplizierter für die Verschaltung und Steuerung, erfordert regelmäßige Refresh-Zyklen, um seinen Inhalt zu verlieren, aber verwendet nur einen Transistor und einen Kondensator pro Bit, so dass es viel höhere Dichten und viel billigere Per-Bit-Kosten zu erreichen. SRAM ist nicht lohnend für Desktop-Systemspeicher, wo DRAM dominiert, sondern wird für ihre Cache-Speicher verwendet. SRAM ist häufig in kleinen eingebetteten Systemen, die nur zehn Kilobytes oder weniger benötigen. Volatile Memory-Technologien, die versucht haben, SRAM und DRAM zu konkurrieren oder zu ersetzen, umfassen Z-RAM und A-RAM. Nichtflüchtige Speicher Nichtflüchtiger Speicher ist ein Computerspeicher, der die gespeicherten Informationen auch bei Nichtbetrieb behalten kann. Beispiele für nichtflüchtige Speicher sind Lese-only-Speicher (siehe ROM,) Flash-Speicher, die meisten Arten von magnetischen Computer-Speicher (z.B. Festplatten, Disketten und Magnetband,) optische Scheiben, und frühen Computer-Speichermethoden wie Papierband und gestanzte Karten. Zu den nichtflüchtigen Speichertechnologien zählen FERAM, CBRAM, PRAM, STT-RAM, SONOS, RRAM, Rennstreckenspeicher, NRAM, 3D XPoint und Millipede-Speicher. Halbflüchtiger Speicher Eine dritte Speicherkategorie ist halbflüchtig. Der Begriff wird verwendet, um einen Speicher zu beschreiben, der eine begrenzte nichtflüchtige Dauer nach der Stromabnahme aufweist, dann aber letztendlich Daten verloren geht. Ein typisches Ziel bei der Verwendung eines halbflüchtigen Speichers ist es, eine hohe Leistung/Verdaulichkeit/Etc, die mit flüchtigen Speichern verbunden ist, zu bieten und einige Vorteile eines echten nichtflüchtigen Speichers zu bieten. Beispielsweise können einige nichtflüchtige Speichertypen abgenutzt werden, bei denen eine abgenutzte Zelle eine erhöhte Flüchtigkeit aufweist, ansonsten aber weiter arbeitet. Häufig geschriebene Datenstellen können somit auf abgenutzte Schaltungen gerichtet werden. Solange der Standort innerhalb einer bekannten Aufbewahrungszeit aktualisiert wird, bleiben die Daten gültig. Fällt die Retentionszeit ohne Update ab, so wird der Wert mit längerer Retention auf eine weniger geworbene Schaltung kopiert. Das Schreiben zuerst auf den abgenutzten Bereich ermöglicht eine hohe Schreibrate bei Vermeidung von Verschleiß an den nicht geworbenen Schaltungen. Als zweites Beispiel kann ein STT-RAM durch den Aufbau großer Zellen nichtflüchtig gemacht werden, aber die Kosten pro Bit und Schreibleistung gehen hoch, während die Schreibgeschwindigkeit sinkt. Die Verwendung kleiner Zellen verbessert Kosten, Leistung und Geschwindigkeit, führt aber zu halbflüchtigen Verhalten. In einigen Anwendungen kann die erhöhte Flüchtigkeit dazu führen, viele Vorteile eines nichtflüchtigen Speichers zu bieten, z.B. durch das Entfernen von Leistung, aber das Verzwingen eines Aufwachens, bevor Daten verloren gehen; oder durch das Kaschieren von Nur-Daten und das Verwerfen der Cached-Daten, wenn die Abschaltzeit die nichtflüchtige Schwelle überschreitet. Der Begriff Halbflüchtling wird auch verwendet, um halbflüchtiges Verhalten aus anderen Speichertypen zu beschreiben. Beispielsweise kann ein flüchtiger und ein nichtflüchtiger Speicher kombiniert werden, wobei ein externes Signal Daten aus dem flüchtigen Speicher in den nichtflüchtigen Speicher kopiert, aber wenn Strom ohne Kopieren entfernt wird, werden die Daten verloren. Oder, ein batteriegestützter flüchtiger Speicher, und wenn externe Leistung verloren geht, gibt es einige bekannte Zeit, in der die Batterie den flüchtigen Speicher weiter antreiben kann, aber wenn Strom für eine längere Zeit ausgeschaltet ist, läuft die Batterie ab und Daten werden verloren. Management Die richtige Verwaltung des Speichers ist wichtig für ein Computersystem ordnungsgemäß zu bedienen. Moderne Betriebssysteme haben komplexe Systeme, um Speicher richtig zu verwalten. Nicht zu tun, kann zu Fehlern führen, langsame Leistung, und im schlimmsten Fall, Übernahme durch Viren und bösartige Software. Fehler falsche Verwaltung des Speichers ist eine häufige Ursache von Fehlern, einschließlich der folgenden Arten: Eine Berechnung ergibt bei einem arithmetischen Überlauf eine Zahl, die größer ist als die zugeordneten Speichergenehmigungen. Beispielsweise erlaubt eine signierte 8-Bit-Integer die Zahlen -128 bis +127. Ist sein Wert 127 und wird angewiesen, einen hinzuzufügen, kann der Computer die Zahl 128 in diesem Raum nicht speichern. Ein solcher Fall führt zu einem unerwünschten Betrieb, wie zum Beispiel einer Änderung des Zahlenwertes auf -128 statt +128. Ein Speicherleck tritt auf, wenn ein Programm Speicher aus dem Betriebssystem fordert und nie den Speicher zurückgibt, wenn es damit fertig ist. Ein Programm mit diesem Bug erfordert allmählich immer mehr Speicher, bis das Programm ausfällt, wie es ausläuft. Ein Segmentierungsfehler ergibt sich, wenn ein Programm versucht, auf den Speicher zuzugreifen, dass es keine Zugriffsberechtigung hat. Im Allgemeinen wird ein Programm damit durch das Betriebssystem beendet. Ein Pufferüberlauf bedeutet, dass ein Programm Daten an das Ende seines zugewiesenen Raumes schreibt und dann weiterhin Daten an Speicher, der für andere Zwecke zugewiesen wurde, schreibt. Dies kann zu einem fehlerhaften Programmverhalten führen, einschließlich Speicherzugriffsfehlern, fehlerhaften Ergebnissen, einem Crash oder einem Verstoß gegen die Systemsicherheit. Sie sind somit die Basis vieler Software-Schwachstellen und können schädlich ausgenutzt werden. Frühe Computersysteme In frühen Computer-Systemen, Programme in der Regel den Speicher zu schreiben und welche Daten dort setzen. Dieser Ort war ein physikalischer Ort auf der eigentlichen Speicherhardware. Die langsame Verarbeitung solcher Computer erlaubte die heute verwendeten komplexen Speicherverwaltungssysteme nicht. Auch, da die meisten solcher Systeme Single-Task waren, wurden anspruchsvolle Systeme nicht so viel benötigt. Dieser Ansatz hat seine Fallstricke. Wenn der angegebene Ort falsch ist, wird dies dazu führen, dass der Computer die Daten an einen anderen Teil des Programms schreibt. Die Ergebnisse eines solchen Fehlers sind unvorhersehbar. In einigen Fällen können die falschen Daten den vom Betriebssystem verwendeten Speicher überschreiben. Computer-Cracker können nutzen, um Viren und Malware zu erstellen. Virtual Memory Virtual Memory ist ein System, in dem alle physischen Speicher vom Betriebssystem gesteuert wird. Wenn ein Programm Speicher benötigt, fordert es es vom Betriebssystem. Das Betriebssystem entscheidet dann in welchem physikalischen Ort der Programmcode und Daten gesetzt werden. Dies bietet mehrere Vorteile. Computerprogrammierer müssen sich nicht mehr darum sorgen, wo ihre Daten physisch gespeichert sind oder ob der Computer des Benutzers genügend Speicher hat. Es ermöglicht auch mehrere Arten von Speicher verwendet werden. Beispielsweise können einige Daten in physikalischen RAM-Chips gespeichert werden, während andere Daten auf einer Festplatte (z.B. in einer Swapfile) gespeichert werden, die als Erweiterung der Cache-Hierarchie fungiert. Dies erhöht drastisch die Menge des Speichers für Programme zur Verfügung. Das Betriebssystem wird aktiv genutzte Daten in physischem RAM platzieren, was viel schneller ist als Festplatten. Wenn die RAM-Menge nicht ausreicht, um alle aktuellen Programme auszuführen, kann es zu einer Situation führen, in der der Computer mehr Zeit verbringt, Daten von RAM auf Festplatte und zurück zu bewegen, als es die Aufgaben erfüllt; dies ist als Thrashing bekannt. Geschützter Speicher Geschützter Speicher ist ein System, in dem jedes Programm einen Bereich des Speichers zur Verwendung gegeben wird und ist nicht erlaubt, außerhalb dieses Bereichs zu gehen. Die Verwendung des geschützten Speichers erhöht sowohl die Zuverlässigkeit als auch die Sicherheit eines Computersystems. Ohne geschützten Speicher ist es möglich, dass ein Fehler in einem Programm den Speicher eines anderen Programms verändert. Dies wird dazu führen, dass andere Programme von beschädigten Speicher mit unvorhersehbaren Ergebnissen auslaufen. Wenn der Speicher des Betriebssystems beschädigt ist, kann das gesamte Computersystem abstürzen und neu gestartet werden müssen. Manchmal ändern Programme absichtlich den Speicher, der von anderen Programmen verwendet wird. Dies geschieht durch Viren und Malware, um Computer zu übernehmen. Es kann auch von wünschenswerten Programmen, die andere Programme modifizieren sollen, gut verwendet werden; im modernen Zeitalter wird dies in der Regel als schlechte Programmierpraxis für Anwendungsprogramme angesehen, aber es kann von Systementwicklungswerkzeugen wie Debuggern verwendet werden, zum Beispiel zum Einfügen von Breakpoints oder Haken. Geschützter Speicher zugewiesen Programme ihre eigenen Bereiche des Speichers. Erkennt das Betriebssystem, dass ein Programm versucht hat, Speicher zu ändern, der nicht zu ihm gehört, wird das Programm beendet (oder anderweitig eingeschränkt oder umgeleitet). Auf diese Weise stürzt nur das abgehende Programm ab, und andere Programme werden nicht vom Fehlverhalten betroffen (ob versehentlich oder absichtlich). Geschützte Speichersysteme umfassen fast immer auch virtuellen Speicher. Siehe auch Speichergeometrie Speicherhierarchie Speicherorganisation Prozessor registriert Speicherdaten, werden normalerweise aber nicht als Speicher betrachtet, da sie nur ein Wort speichern und keinen Adressierungsmechanismus enthalten. Halbleiterspeicher Informationseinheiten Referenzen Weiter lesen Miller, Stephen W. (1977), Speicher- und Speichertechnologie, Montvale:. AFIPS PressMemory and Storage Technology, Alexandria, Virginia:. Time Life Books, 1988