Die Wirkung künstlicher Intelligenz auf die Arbeitnehmer umfasst sowohl Anwendungen zur Verbesserung der Sicherheit und Gesundheit der Arbeitnehmer als auch mögliche Gefahren, die kontrolliert werden müssen. Ein potenzieller Antrag verwendet die AI, um Gefahren zu beseitigen, indem sie Menschen aus gefährlichen Situationen, die mit Stress, Überarbeitung oder Schleimhautverletzten verbunden sind, ausschalten. Prädikative Analyse kann auch dazu verwendet werden, Bedingungen zu ermitteln, die zu Gefahren wie Müdigkeit, wiederholte Stämme oder giftige Substanzexposition führen können, die zu früheren Eingriffen führen. Ein weiteres Ziel ist es, die Arbeitssicherheit und die Gesundheitsabläufe durch die Automatisierung wiederholter Aufgaben zu straffen, Programme für Sicherheitsschulungen durch virtuelle Realität zu verbessern oder in der Nähe von Missständen zu erkennen und zu melden. AI stellt bei der Verwendung am Arbeitsplatz auch die Möglichkeit neuer Gefahren vor. Diese können sich aus maschinenlesbaren Lerntechniken ergeben, die zu unvorhersehbarem Verhalten und Unkontrollierbarkeit in ihrer Entscheidungsfindung oder aus Fragen der Cybersicherheit und der Privatsphäre führen. Viele Risiken von AI sind psychosozial, da sie Veränderungen in der Arbeitsorganisation verursachen können. Dazu gehören Änderungen der Fähigkeiten der Arbeitnehmer, eine verstärkte Überwachung, die zum Mikromanagement führt, Algorithmen, die unabsichtlich oder absichtlich unerwünschte menschliche Verzerrungen eliminieren, und die Schuld für Maschinenfehler an den menschlichen Unternehmer. AI kann auch zu physischen Gefahren in Form von menschlicher –robot-Konflikten und ergonomischen Risiken von Kontrollschnittstellen und Mensch-Maschine-Interaktionen führen. Gefahrenkontrollen umfassen Cybersicherheits- und Informationssicherheitsmaßnahmen, Kommunikation und Transparenz mit Arbeitnehmern über die Nutzung von Daten und Grenzen für gemeinsame Roboter. Nur schwache oder enge AI, die auf eine bestimmte Aufgabe zugeschnitten ist, ist von einem Arbeitsplatzsicherheits- und Gesundheitsschutzaspekt betroffen, da es in naher Zukunft viele Beispiele gibt, die derzeit in Gebrauch sind oder in Anspruch nehmen. Starke oder allgemeine AI dürfte in naher Zukunft nicht machbar sein, und die Diskussion über ihre Risiken liegt in den Händen von Futuristen und Philosophen statt industrieller Hygienisten. Gesundheit und Sicherheit Zur Annahme eines möglichen Antrags auf Sicherheit und Gesundheitsschutz von AI müssen sowohl Führungskräfte als auch Arbeitnehmer akzeptiert werden. Zum Beispiel kann die Akzeptanz der Arbeitnehmer durch Bedenken in Bezug auf die Privatsphäre der Information oder durch mangelndes Vertrauen und die Akzeptanz der neuen Technologie verringert werden, die sich aus unzureichender Transparenz oder Ausbildung ergeben können. Außerdem können die Manager bei der Umsetzung von AI-basierten Systemen die Steigerung der wirtschaftlichen Produktivität hervorheben, anstatt die Sicherheit und Gesundheit der Arbeitnehmer zu erhöhen. Beseitigung gefährlicher Aufgaben kann die AI den Umfang der Arbeitsaufgaben erhöhen, wenn ein Arbeitnehmer aus einer Situation entfernt werden kann, die Risiken birgt. In einem Sinne kann die traditionelle Automatisierung die Funktionen eines Arbeitnehmerkörpers mit einem Roboter ersetzen, die AI ersetzt die Funktionen ihres Gehirns mit einem Computer. Gefahren, die vermieden werden können, umfassen Stress, Überarbeitung, Muskel- und Skelettverletzungen und Langem. Dies kann die Palette der betroffenen Stellensektoren in den Bereichen Weiß- und Dienstleistungssektor, wie in Medizin, Finanzen und Informationstechnologie, erweitern. Als Beispiel sind die Mitarbeiter des Callcenters aufgrund seiner wiederholten und anspruchsvollen Natur und seiner hohen Mikro-Überwachungsraten mit erheblichen Gesundheits- und Sicherheitsrisiken konfrontiert. AI-fähige Chatbots mindern die Notwendigkeit, die grundlegenden Aufgaben des Callcenters zu erfüllen. Analytics zur Verringerung des Risiko-Fernenlernens wird für die Analyse von Menschen verwendet, um Vorhersagen über das Verhalten der Arbeitnehmer zu machen, um Managemententscheidungen wie Einstellung und Leistungsbeurteilung zu unterstützen. Diese könnten auch genutzt werden, um die Gesundheit der Arbeitnehmer zu verbessern. Die Analyse kann auf Inputs wie Online-Aktivitäten, Überwachung der Kommunikation, Ortsverfolgung und Sprachanalyse und Körperspracheanalyse von Filmgesprächen basieren. Man kann beispielsweise dazu verwendet werden, Ermüdung aufzuspüren, um Überarbeitung zu verhindern. Entscheidungsunterstützungssysteme haben eine ähnliche Fähigkeit, zum Beispiel Industriekatastrophen zu verhindern oder Katastrophenreaktion effizienter zu machen. Für manuelle Materialabfertigungskräfte können prädiktive Analysen und künstliche Intelligenz verwendet werden, um Muskel- und Skelettschäden zu verringern. Traditionelle Leitlinien basieren auf statistischen Durchschnittswerten und sind auf anthropometrisch typischem Menschen ausgerichtet. Die Analyse großer Datenmengen von tragbaren Sensoren kann eine Echtzeit-, personalisierte Berechnung des ergonomischen Risiko- und Müdigkeitsmanagements sowie eine bessere Analyse des Risikos im Zusammenhang mit bestimmten Jobfunktionen ermöglichen. tragbare Sensoren können auch frühere Eingriffe gegen die Exposition gegenüber giftigen Stoffen ermöglichen als mit Feld- oder Atemzonestests auf periodischer Basis möglich. Darüber hinaus könnten die großen Datensets die Gesundheit am Arbeitsplatz, die Risikobewertung und die Forschung verbessern. Straffung der Sicherheits- und Gesundheitsabläufe kann auch verwendet werden, um die Sicherheit am Arbeitsplatz und den Gesundheitsablauf effizienter zu gestalten. Ein Beispiel ist die Kodierung von Entschädigungsansprüchen von Arbeitnehmern, die in einer prosematischen Form eingereicht werden und manuell standardisierte Codes zugewiesen werden müssen. AI wird untersucht, um diese Aufgabe schneller, günstiger und mit weniger Fehlern zu erfüllen. AI-fähige virtuelle Realitätssysteme können für Sicherheitsschulungen zur Gefahrenerkennung von Nutzen sein. Künstliche Intelligenz kann genutzt werden, um in der Nähe von Verfehlungen effizienter zu erkennen. Meldung und Analyse in der Nähe von Missbräuchen sind wichtig bei der Senkung der Unfallraten, aber sie werden häufig gemeldet, weil sie vom Menschen nicht erkannt werden oder von den Arbeitnehmern aufgrund sozialer Faktoren nicht gemeldet werden. Gefahren Es gibt mehrere breite Aspekte von AI, die spezifische Gefahren verursachen können. Die Risiken hängen von der Umsetzung ab und nicht von der bloßen Präsenz von AI. Systeme, die sub-symbolische AI wie maschinelles Lernen verwenden, können sich unvorhersehbar verhalten und in ihrer Entscheidungsfindung eher unkontrollierbar sein. Dies gilt insbesondere, wenn eine Situation aufgetreten ist, die nicht Teil der Ausbildungsdaten der AI war und in weniger strukturierten Umgebungen verschlimmert wird. Unerwünschtes Verhalten kann auch aus Mängeln in der Wahrnehmung des Systems (der sich entweder aus der Software oder aus der sensorischen Schädigung ergibt), der Wissensvertretung und der Begründung oder aus Softwarefehlern ergeben. Sie können aus einer unlauteren Ausbildung kommen, wie z.B. ein Nutzer, der denselben Algorithmus an zwei Probleme wendet, die nicht die gleichen Anforderungen haben. während der Entwurfsphase angewandtes Maschinenlernen kann unterschiedliche Auswirkungen haben als bei der Laufzeit. Systeme mit symbolischer AI sind weniger anfällig für unvorhersehbares Verhalten. Die Verwendung von AI erhöht auch die Cybersicherheitsrisiken im Vergleich zu Plattformen, die nicht von AI Gebrauch machen, und die Bedenken hinsichtlich der Privatsphäre bei gesammelten Daten können für die Arbeitnehmer eine Gefahr darstellen. Psychosoziale Psychosoziale Gefahren sind solche, die sich aus der Gestaltung, Organisation und Verwaltung oder ihren wirtschaftlichen und sozialen Kontexten ergeben, anstatt sich aus einem physikalischen Stoff oder Gegenstand ergeben. Sie verursachen nicht nur psychiatrische und psychologische Ergebnisse wie Betriebsverbrennung, Angststörungen und Depressionen, sondern können auch körperliche Verletzungen oder Erkrankungen wie Herz-Kreislauf-Erkrankungen oder Muskelschäden verursachen. Viele Risiken von AI sind psychosoziale Natur aufgrund ihres Potenzials, Veränderungen in der Arbeitsorganisation zu verursachen, im Hinblick auf die zunehmende Komplexität und Interaktion zwischen verschiedenen organisatorischen Faktoren. Psychosoziale Risiken werden jedoch oft von Designern fortgeschrittener Fertigungssysteme übersehen. Änderungen der Arbeitspraktiken AI werden voraussichtlich zu Veränderungen der Qualifikationen der Arbeitnehmer führen, die Ausbildung bestehender Arbeitnehmer, Flexibilität und Offenheit für Veränderungen erfordern. Die Notwendigkeit, konventionelles Fachwissen mit Computerkenntnissen zu kombinieren, kann für bestehende Arbeitnehmer problematisch sein. Mehr Informationen über AI-Werkzeuge können dazu führen, dass bestimmte Berufe entwogen werden. Eine verstärkte Überwachung kann zu Mikromanagement führen und damit zu Stress und Angst führen. Eine Wahrnehmung der Überwachung kann auch zu Stress führen. Kontrollen für diese Bereiche umfassen Konsultationen mit Arbeitnehmergruppen, umfassende Tests und Aufmerksamkeit auf eingeführte Verzerrungen. Leistungsfähige Sensoren, Bewegungspfade und eine erweiterte Realität können auch zu Stress von Mikromanagement führen, sowohl für die Montagekräfte als auch für die Mitarbeiter von Gruppen. Nichtbeachtung der gesetzlichen Schutzbestimmungen und Rechte der formalen Arbeitnehmer. Es besteht auch die Gefahr, dass Menschen gezwungen werden, auf dem Tempo eines Roboters zu arbeiten oder die Leistung von Robotern in nicht konformen Stunden zu überwachen. Bias Algorithms, die in früheren Entscheidungen ausgebildet wurden, können unerwünschte menschliche Unparteien z.B. in der Vergangenheit diskriminierende Einstellungs- und Firingpraktiken umführen. Informationsasymmetrie zwischen Management und Arbeitnehmern kann zu Stress führen, wenn Arbeitnehmer keinen Zugang zu den Daten oder Algorithmen haben, die die Grundlage für die Entscheidungsfindung sind. Neben dem Aufbau eines Modells mit unentschlossenen diskriminierenden Merkmalen kann eine vorsätzliche Diskriminierung durch Konzipierungsparameter auftreten, die eine Diskriminierung durch korrelierte Variablen auf unmissverständliche Weise bewirken. In komplexen Wechselwirkungen zwischen Mensch und Maschine können einige Ansätze zur Unfallanalyse unvoreingenommen werden, um ein technisches System und seine Entwickler zu gewährleisten, indem sie dem einzelnen Personalbetreiber stattgeben. physikalische Gefahren in Form von human-robot-Konflikten können von Robotern auftreten, die AI verwenden, insbesondere kollaborative Roboter (Kabotage). Kobots sollen in unmittelbarer Nähe zum Menschen betrieben werden, was die gemeinsame Gefahrenkontrolle unmöglich macht, den Roboter mit Zäugern oder anderen Barrieren zu isolieren, die für traditionelle industrielle Roboter weit verbreitet sind. automatisierte Lenkfahrzeuge sind eine Art von Kobot, die ab 2019 gemeinsam genutzt werden, oft als Gabelstapler oder Palettengelenke in Lagern oder Fabriken. Für Kobots, sensorische Funktionsstörungen oder unerwartete Arbeitsbedingungen können unvorhersehbares Roboterverhalten und damit zu menschlichen –robot-Konflikten führen. Selbstdrehwagen sind ein weiteres Beispiel für AI-fähige Roboter. Außerdem können die ergonomischen Kontrollschnittstellen und die Interaktion zwischen Mensch und Maschine zu Gefahren führen. Risikokontrollen von AI, gemeinsam mit anderen rechnerischen Technologien, erfordern Cybersicherheitsmaßnahmen, um Verletzungen und Eindringen von Software zu stoppen sowie Maßnahmen zur Privatsphäre. Kommunikation und Transparenz mit Arbeitnehmern über die Datennutzung sind eine Kontrolle für psychosoziale Risiken, die sich aus Sicherheits- und Datenschutzfragen ergeben. Vorschläge für bewährte Verfahren zur Überwachung von Arbeitgebern umfassen ausschließlich validierte Sensortechnologien, die freiwillige Beteiligung der Arbeitnehmer gewährleisten, die Datenerhebung außerhalb des Arbeitsplatzes abschaffen, alle Daten verwenden und die sichere Datenspeicherung gewährleisten. Für industrielle Kobote, die mit AI-fähigen Sensoren ausgestattet sind, empfahl die Internationale Organisation für Normung (ISO): (a) sicherheitsrelevante Überwachungskontrollen; b) Personal-Leitung des Kokbots; (c) Geschwindigkeits- und Trennungskontrollen und (d) Beschränkungen für Kraft- und Gewalt. vernetzte AI-fähige Kobots können die Sicherheit verbessern. Menschliche Aufsicht ist eine weitere allgemeine Gefahrenkontrolle für AI. Risikomanagement sowohl Anwendungen als auch Gefahren, die sich aus der AI ergeben, können als Teil bestehender Rahmenbedingungen für das Gesundheits- und Sicherheitsrisikomanagement gelten. Wie bei allen Gefahren ist die Risikokennzeichnung am wirksamsten und kostengünstigste, wenn sie in der Entwurfsphase durchgeführt wird. Gesundheitsüberwachung am Arbeitsplatz, Erfassung und Analyse von Gesundheitsdaten an den Arbeitnehmern, ist eine Herausforderung für die AI, weil Arbeitsdaten häufig in der Gesamtheit gemeldet werden und keine Aufschlüsselungen zwischen verschiedenen Arbeitsformen vorsehen, und konzentriert sich auf wirtschaftliche Daten wie Löhne und Beschäftigungsraten anstatt Arbeitsinhalte. Mangelnde Kompetenzinhalte umfassen Bildungsvorschriften und Klassifizierungen von Routine gegenüber Nichtroutine und kognitiven versus physische Arbeitsplätze. Diese können jedoch noch nicht spezifisch genug sein, um bestimmte Berufe zu unterscheiden, die besondere Auswirkungen von AI haben. The United States Department of Labor's Occupational Information Network ist ein Beispiel für eine Datenbank mit einer detaillierten Taxonomy der Fähigkeiten. Außerdem werden häufig Daten auf nationaler Ebene gemeldet, während es große geografische Unterschiede gibt, insbesondere zwischen städtischen und ländlichen Gebieten. Normen und Regulierung ISO entwickelt seit 2019 einen Standard für die Verwendung von Messgeräten und Armaturenbrettern, Informationsbildschirme, die Unternehmensparameter für Führungskräfte am Arbeitsplatz präsentieren. Es ist vorgesehen, Leitlinien für die Erhebung von Daten und die Anzeige dieser Daten auf eine sinnvolle und sinnvolle Weise aufzunehmen. In der Europäischen Union ist die allgemeine Datenschutzverordnung, die sich auf Verbraucherdaten orientiert, auch für die Sammlung von Arbeitsdaten relevant. Personen, einschließlich Arbeitnehmern, haben "das Recht, einer ausschließlich auf automatisierte Verarbeitung basierenden Entscheidung nicht unterliegen zu lassen". Andere einschlägige EU-Richtlinien umfassen die Maschinenrichtlinie (2006/42/EG), die Richtlinie über Funkanlagen (2014/53/EU) und die Richtlinie über die allgemeine Produktsicherheit (2001/95/EG). Luxemburg Links