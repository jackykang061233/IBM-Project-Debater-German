Ein intelligenter virtueller Assistent (IVA) oder intelligenter persönlicher Assistent (IPA) ist ein Software-Agent, der Aufgaben oder Dienste für eine Person auf Befehlen oder Fragen ausführen kann. Der Begriff Chatbot wird manchmal verwendet, um virtuelle Assistenten in der Regel oder speziell durch Online-Chat aufgerufen zu verweisen. In einigen Fällen sind Online-Chat-Programme ausschließlich für Unterhaltungszwecke. Einige virtuelle Assistenten können menschliche Sprache interpretieren und über synthetisierte Stimmen reagieren. Benutzer können ihre Assistenten Fragen stellen, Heimautomatisierungsgeräte und Medienwiedergabe per Stimme steuern und andere grundlegende Aufgaben wie E-Mail, To-Do-Listen und Kalender mit mündlichen (spoken?) Befehlen verwalten. Ein ähnliches Konzept, jedoch mit Unterschieden, liegt unter den Dialogsystemen. Ab 2017 erweitern sich die Fähigkeiten und die Nutzung von virtuellen Assistenten rasch, wobei neue Produkte in den Markt gelangen und sowohl E-Mail- als auch Sprachanwenderschnittstellen stark betonen. Apple und Google haben große installierte Basen von Benutzern auf Smartphones. Microsoft verfügt über eine große installierte Basis von Windows-basierten Personalcomputern, Smartphones und intelligenten Lautsprechern. Amazon hat eine große Installationsbasis für intelligente Lautsprecher. Conversica hat über 100 Millionen Engagements über seine E-Mail- und sms-Schnittstelle Intelligent Virtual Assistants for business. Geschichte Experimentelle Jahrzehnte: 1910-1980 Radio Rex war das erste, 1922 veröffentlichte, stimmbetätigte Spielzeug. Es war ein Holzspielzeug in der Form eines Hundes, das aus seinem Haus kommen würde, wenn sein Name genannt wird. 1952 präsentierten Bell Labs „Audrey“, die automatische Digit Recognitionsmaschine. Es besetzte ein Sechs-Fuß-High-Relais-Rack, verbrauchte erhebliche Leistung, hatte Ströme von Kabeln und zeigten die unzähligen Wartungsprobleme mit komplexen Vakuum-Röhre-Schaltungen. Es könnte die grundlegenden Einheiten der Rede, Phoneme erkennen. Es beschränkte sich auf eine genaue Erkennung der von bestimmten Gesprächspartnern gesprochenen Ziffern. Es könnte daher für die Stimmwahl verwendet werden, aber in den meisten Fällen war die Tastenwahl billiger und schneller, anstatt die aufeinanderfolgenden Ziffern zu sprechen. Ein weiteres frühes Tool, das die digitale Spracherkennung ermöglichte, war der IBM Shoebox-Sprachrechner, der der Öffentlichkeit nach seinem ersten Marktstart im Jahr 1961 auf der Seattle World's Fair präsentiert wurde. Dieser frühe Computer, fast 20 Jahre vor der Einführung des ersten IBM Personal Computers im Jahre 1981, konnte 16 gesprochene Wörter und die Ziffern 0 bis 9 erkennen. Das erste natürliche Sprachverarbeitungs-Computerprogramm oder das Chatbot ELIZA wurde von MIT Professor Joseph Weizenbaum in den 1960er Jahren entwickelt. Es wurde geschaffen, um "die Kommunikation zwischen Mensch und Maschine oberflächlich zu erklären". ELIZA nutzte Musteranpassungs- und Substitutionsmethodik in Scripted Responses, um das Gespräch zu simulieren, was eine Illusion des Verständnisses seitens des Programms gab. Weizenbaums eigene Sekretärin bat Weizenbaum, den Raum zu verlassen, damit sie und ELIZA ein echtes Gespräch führen können. Weizenbaum war überrascht von diesem, späteren Schreiben: "Ich hatte nicht erkannt... dass extrem kurze Expositionen mit einem relativ einfachen Computerprogramm in ziemlich normalen Menschen starkes delusionales Denken hervorrufen könnte. Dies gab dem ELIZA-Effekt Namen, die Tendenz, unbewußt anzunehmen Computerverhalten sind analog zu menschlichen Verhaltensweisen, d.h. Anthropomorphisation, ein Phänomen, das in menschlichen Interaktionen mit virtuellen Assistenten vorhanden ist. Der nächste Meilenstein in der Entwicklung der Spracherkennungstechnologie wurde in den 1970er Jahren an der Carnegie Mellon University in Pittsburgh, Pennsylvania mit beträchtlicher Unterstützung des United States Department of Defense und seiner DARPA-Agentur, finanzierte fünf Jahre eines Speech Understanding Research-Programms, um ein Minimum Vokabeln von 1.000 Wörtern zu erreichen. Unternehmen und Wissenschaften wie IBM, Carnegie Mellon University (CMU) und Stanford Research Institute nahmen an dem Programm teil. Das Ergebnis war Harpy, es beherrschte etwa 1000 Wörter, das Vokabular eines dreijährigen und es konnte Sätze verstehen. Es könnte Sprache verarbeiten, die vorprogrammierten Wortschatz-, Aussprache- und Grammatikstrukturen folgte, um zu bestimmen, welche Sequenzen von Wörtern zusammen Sinn gemacht haben und so Spracherkennungsfehler reduzierten. 1986 war Tangora ein Upgrade der Shoebox, es war eine Stimme, die Schreibmaschine erkannte. Nach dem damals schnellsten Schreiber der Welt benannt, hatte es einen Vokabeln von 20.000 Wörtern und nutzte Vorhersage, um das wahrscheinlichste Ergebnis basierend auf dem, was in der Vergangenheit gesagt wurde, zu entscheiden. IBMs Ansatz basierte auf einem Hidden Markov-Modell, das Statistiken zu digitalen Signalverarbeitungstechniken hinzufügt.Die Methode ermöglicht es, die wahrscheinlichsten Phoneme vorherzusagen, um einem bestimmten Phonem zu folgen. Dennoch musste jeder Lautsprecher den Schreiber individuell trainieren, um seine Stimme zu erkennen und zwischen jedem Wort zu halten. Geburt intelligenter virtueller Assistenten: 1990er-Präsentate Die digitale Spracherkennungstechnologie der 1990er Jahre wurde ein Merkmal des Personalcomputers mit IBM, Philips und Lemout & Hauspie für Kunden. Viel später legte die Markteinführung des ersten Smartphones IBM Simon 1994 die Grundlage für intelligente virtuelle Assistenten, wie wir sie heute kennen. Im Jahr 1997 konnte die natürlich sprechende Software von Dragon natürliche menschliche Sprache erkennen und durchschreiben, ohne Pausen zwischen jedem Wort in ein Dokument mit einer Rate von 100 Wörtern pro Minute. Eine Version von Naturally Speaking steht noch zum Download zur Verfügung und wird heute noch verwendet, zum Beispiel von vielen Ärzten in den USA und Großbritannien, um ihre medizinischen Aufzeichnungen zu dokumentieren. 2001 startete Colloquis öffentlich SmarterChild auf Plattformen wie AIM und MSN Messenger. Während völlig textbasierte SmarterChild in der Lage war, Spiele zu spielen, überprüfen Sie das Wetter, suchen Fakten und umgekehrt mit Benutzern in einem Ausmaß. Der erste moderne digitale virtuelle Assistent auf einem Smartphone installiert war Siri, die als Funktion des iPhone 4S am 4. Oktober 2011 eingeführt wurde. Apple Inc. entwickelte Siri nach der Übernahme von Siri Inc., einem Spin-off von SRI International, einem Forschungsinstitut, das von DARPA und dem United States Department of Defense finanziert wird. Ziel war es, bei Aufgaben wie Senden einer Textnachricht, Telefonanrufe, Überprüfung des Wetters oder Alarmierung zu helfen. Im Laufe der Zeit hat es sich entwickelt, um Restaurants Empfehlungen, suchen Sie das Internet, und bieten Fahrtrichtungen. Im November 2014 kündigte Amazon Alexa neben dem Echo an. Im April 2017 veröffentlichte Amazon einen Dienst für den Aufbau von Gesprächsschnittstellen für jede Art von virtuellem Assistent oder Schnittstelle. Methode der Interaktion Virtuelle Assistenten arbeiten über: Text, einschließlich: Online-Chat (insbesondere in einer Instant-Messaging-App oder anderen App), SMS Text, E-Mail oder anderen textbasierten Kommunikationskanal, zum Beispiel Conversica's Intelligent Virtual Assistants for business. Stimme, zum Beispiel mit Amazon Alexa auf dem Amazon Echo Gerät, Siri auf einem iPhone, oder Google Assistant auf Google-enabled/Android mobilen Geräten Durch die Aufnahme und/oder das Hochladen von Bildern, wie im Fall von Samsung Bixby auf dem Samsung Galaxy S8Some virtuellen Assistenten sind über mehrere Methoden, wie Google Assistant über Chat auf der Google Allo und Google Messages App und über die Stimme auf Google Home intelligente Lautsprecher zugänglich. Virtuelle Assistenten verwenden die natürliche Sprachverarbeitung (NLP), um Benutzertext oder Spracheingabe an ausführbare Befehle anzupassen. Viele lernen kontinuierlich mit künstlichen Intelligenz-Techniken, einschließlich maschinelles Lernen. Einige dieser Assistenten wie Google Assistant (die Google Lens enthält) und Samsung Bixby haben auch die zusätzliche Fähigkeit, Bildverarbeitung zu tun, um Objekte im Bild zu erkennen, um den Benutzern zu helfen, bessere Ergebnisse aus den geklickten Bildern zu erhalten. Um einen virtuellen Assistenten mit der Stimme zu aktivieren, kann ein Weckwort verwendet werden. Dies ist ein Wort oder Gruppen von Wörtern wie "Hey Siri", "OK Google" oder "Hey Google", Alexa und "Hey Microsoft". Da virtuelle Assistenten beliebter werden, gibt es zunehmend rechtliche Risiken. Geräte und Objekte, in denen virtuelle Assistenten gefunden werden können in viele Arten von Plattformen oder, wie Amazon Alexa, über mehrere von ihnen integriert werden: In Geräte wie Smart-Lautsprecher wie Amazon Echo, Google Home und Apple HomePodIn Instant Messaging-Apps auf beiden Smartphones und über das Web, z.B. Facebooks M (virtuelle Assistentin) auf Facebook und Facebook Messenger-Apps oder über das Web In ein mobiles Betriebssystem (OS,) eingebaut, wie Apples Siri auf iOS-Geräten und BlackBerry Assistant auf BlackBerry 10 Geräten, oder in ein Desktop-Betriebssystem wie Cortana Innerhalb von Instant Messaging-Plattformen, Assistenten von bestimmten Organisationen, wie Aeromexico Aerobot auf Facebook Messenger oder Wechat Sekretär auf WeChat Innerhalb von mobilen Apps von bestimmten Unternehmen und anderen Organisationen, wie Dom aus Dominos Pizza In Geräten, Autos und Wearable-Technologie. Frühere Generationen von virtuellen Assistenten arbeiteten oft auf Websites, wie Alaska Airlines' Ask Jenn, oder auf interaktiven Sprachantwortsystemen (IVR) wie American Airlines' IVR von Nuance. Services Virtuelle Assistenten können eine Vielzahl von Dienstleistungen bieten.Dazu gehören: Informationen wie Wetter, Fakten von z.B. Wikipedia oder IMDb, Alarm setzen, Listen und Einkaufslisten erstellen Spielen Sie Musik von Streaming-Diensten wie Spotify und Pandora; spielen Radiosender; lesen Sie Audiobücher Spielen Sie Videos, TV-Shows oder Filme im Fernsehen, Streaming von z.B. Netflix Conversational Commerce (siehe unten)Assist Public Interaktionen mit Regierung (siehe Künstliche Intelligenz in der Regierung) Ergänzen und/oder ersetzen Sie den Kundenservice durch Menschen. Ein Bericht schätzte, dass ein automatisierter Online-Assistent eine Abnahme der Arbeitsbelastung für ein menschlich bereitgestelltes Callcenter um 30% bewirkte. Conversational Commerce Conversational Commerce ist E-Commerce über verschiedene Mittel der Messaging, einschließlich über Sprachassistenten, aber auch Live-Chat auf E-Commerce-Websites, Live-Chat auf Messaging-Apps wie WeChat, Facebook Messenger und WhatsApp und Chatbots auf Messaging-Apps oder Websites. Customer Support Virtual Assistant kann mit Kundenunterstützungsteam eines Unternehmens zusammenarbeiten, um Kunden 24x7 zu unterstützen. Es bietet schnelle Antworten, die die Erfahrung eines Kunden verbessert. Amazon ermöglicht Alexa Skills und Google Actions, im Wesentlichen Apps, die auf den Assistenzplattformen laufen. Virtuelle Assistentin Datenschutz Virtuelle Assistenten haben eine Vielzahl von Datenschutzbedenken, die mit ihnen verbunden sind. Funktionen wie die Aktivierung durch die Stimme stellen eine Bedrohung dar, da solche Funktionen das Gerät immer hören müssen. Es wurden Datenschutzmodi wie die virtuelle Sicherheitstaste vorgeschlagen, um eine mehrschichtige Authentifizierung für virtuelle Assistenten zu erstellen. Datenschutzrichtlinie prominenter virtueller Assistenten Google Assistant Google Assistant speichert die Daten der Nutzer nicht ohne ihre Erlaubnis. Um den Audio zu speichern, kann der Benutzer auf Voice & Audio Activity (VAA) gehen und diese Funktion aktivieren. Audiodateien werden in die Cloud gesendet und von Google verwendet, um die Leistung von Google Assistant zu verbessern, aber nur, wenn die VAA Funktion aktiviert ist. Amazons virtueller Assistent Alexa Amazon Alexa hört nur Gespräche, wenn sein Wake-Wort (wie Alexa, Amazon, Echo) verwendet wird. Es fängt an, das Gespräch nach dem Aufruf eines Weckwortes aufzunehmen. Es hört auf nach 8 Sekunden Stille zu hören. Es sendet das aufgezeichnete Gespräch in die Cloud. Es ist möglich, die Aufnahme aus der Cloud zu löschen, indem Sie „Alexa Privacy“ in „Alexa“ besuchen. Es gibt eine Funktion, Alexa davon abzuhalten, Ihre Gespräche zu hören, indem sie ‘mute’ Funktion von Alexa. Nach dem Stummen des Geräts kann es nicht zuhören, auch wenn die Wake-Worte (wie Alexa) verwendet wurden. Apples Siri Apple nimmt keine Audio auf, um Siri zu verbessern, sondern verwendet Transkripte. Es sendet nur Daten, die für die Analyse wichtig sind, zum Beispiel, wenn der Benutzer Siri auffordert, ihre Nachricht zu lesen, es wird nicht die Nachricht an die Cloud senden, wird die Maschine direkt die Nachricht ohne Server-Interferenz lesen. Benutzer können jederzeit ausschalten, wenn sie nicht wollen, dass Siri die Transkripte in der Cloud sendet. Vermutetes und beobachtetes Interesse für den Verbraucher Vermutete Mehrwert, da eine neue Art von Interaktionen möglich ist. Sprachkommunikation kann manchmal die optimale Mensch-Maschine-Kommunikation darstellen : Es ist bequem: Es gibt einige Sektoren, in denen Stimme die einzige Möglichkeit der Kommunikation ist, und allgemeiner, es erlaubt, sowohl Hände und Vision potenziell für eine andere Tätigkeit parallel zu tun, oder hilft auch behinderten Menschen. Es ist schneller: Die Stimme ist effizienter als das Schreiben auf einer Tastatur: wir können bis zu 200 Wörter pro Minute sprechen, gegen 60 im Falle des Schreibens auf einer Tastatur. Es ist auch natürlicher und erfordert daher weniger Anstrengung (ein Text kann jedoch 700 Wörter pro Minute erreichen). Virtuelle Assistenten sparen viel Zeit durch Automatisierung: Sie können Termine nehmen oder die Nachrichten lesen, während der Verbraucher etwas anderes tut. Es ist auch möglich, den virtuellen Assistenten zu den Sitzungen zu fragen, und damit zu helfen, Zeit zu organisieren. Die Designer von neuen digitalen Schedulern erklärten den Ehrgeiz, dass diese Kalender Leben planen, um den Verbraucher seine Zeit effizienter zu nutzen, durch maschinelle Lernprozesse und vollständige Organisation von Arbeitszeit und Freizeit. Als Beispiel, wenn der Verbraucher den Wunsch äußert, eine Pause zu planen, wird die VA sie zu einem optimalen Moment für diesen Zweck (z.B. zu einer Zeit der Woche, wo sie weniger produktiv sind) mit dem zusätzlichen langfristigen Ziel, die freie Zeit des Verbrauchers zu planen und zu organisieren, um ihnen eine optimale Arbeitseffizienz zu gewährleisten.Zinssatz Laut einer aktuellen Studie (2019) werden die beiden Gründe für die Verwendung von Virtual Assistants für Verbraucher als nützlich und wahrgenommene Freude wahrgenommen. Das erste Ergebnis dieser Studie ist, dass sowohl wahrgenommene Nützlichkeit als auch wahrgenommene Freude einen ähnlichen sehr starken Einfluss für die Verbraucherbereitschaft haben, einen Virtual Assistant zu verwenden. Das zweite Ergebnis dieser Studie ist, dass :Gelieferte Inhaltsqualität einen sehr starken Einfluss auf wahrgenommene Nützlichkeit und einen starken Einfluss auf wahrgenommene Freude hat. Visuelle Attraktivität hat einen sehr starken Einfluss auf wahrgenommene Freude. Automatisierung hat einen starken Einfluss auf wahrgenommene Nützlichkeit. Kontroversen Künstliche Intelligenz Kontroversen Virtuelle Assistenten sporen die Filterblase: Die Algorithmen von Virtual Assistants werden für soziale Medien ausgebildet, um relevante Daten zu zeigen und andere auf der Grundlage früherer Aktivitäten des Verbrauchers zu verwerfen: Die relevanten Daten sind die, die den Verbraucher interessieren oder bitte. Infolgedessen werden sie von Daten isoliert, die mit ihren Standpunkten nicht übereinstimmen, sie effektiv in ihre eigene intellektuelle Blase isolieren und ihre Meinungen verstärken. Dieses Phänomen war bekannt, gefälschte Nachrichten und Echokammern zu verstärken. Virtuelle Assistenten werden manchmal auch kritisiert, dass sie überbewertet werden. Insbesondere weist A. Casilli darauf hin, dass die KI der virtuellen Assistenten aus zwei Gründen weder intelligent noch künstlich ist:Nicht intelligent, weil sie nur die Assistentin des Menschen sind, und nur durch Aufgaben, die ein Mensch leicht tun könnte, und in einem sehr begrenzten Handlungsspektrum: Suchen, Unterricht und Präsentation von Informationen, Angeboten oder Dokumenten. Außerdem sind Virtual Assistants weder in der Lage, Entscheidungen selbst zu treffen, noch Dinge vorwegzunehmen. Und nicht künstlich, weil sie ohne menschliche Beschriftung durch Mikroarbeit unmöglich wären. Im Jahr 2019 Antonio A. Casilli, ein französischer Soziologe, kritisierte künstliche Intelligenz und virtuelle Assistenten insbesondere auf folgende Weise: Auf einer ersten Ebene ist die Tatsache, dass der Verbraucher kostenlose Daten für die Ausbildung und Verbesserung des virtuellen Assistenten liefert, oft ohne es zu wissen, ethisch störend. Aber auf einer zweiten Ebene könnte es noch ethisch beunruhigender sein, zu wissen, wie diese KI mit diesen Daten trainiert werden. Diese künstliche Intelligenz wird über neuronale Netzwerke trainiert, die eine große Menge an markierten Daten erfordern. Diese Daten müssen jedoch durch einen menschlichen Prozess gekennzeichnet werden, der den Anstieg der Mikroarbeit im letzten Jahrzehnt erklärt. Das heißt, Ferngebrauch einiger Menschen weltweit tun einige repetitive und sehr einfache Aufgaben für ein paar Cent, wie das Zuhören von Virtual Assistant Sprachdaten und das Schreiben, was gesagt wurde. Mikroarbeit wurde wegen der Arbeitsunsicherheit kritisiert, die sie verursacht, und wegen des völligen Mangels an Regulierung: Das durchschnittliche Gehalt betrug 1,38 Dollar/Stunde im Jahr 2010, und es bietet weder Gesundheits- noch Altersversorgung, Krankengeld, Mindestlohn. Virtuelle Assistenten und ihre Designer sind daher umstritten, um die Arbeitsplatzunsicherheit zu stören, und die KIs, die sie vorschlagen, sind immer noch Menschen in der Weise, dass sie ohne die Mikroarbeit von Millionen menschlicher Arbeiter unmöglich wären. Datenschutzbedenken werden dadurch angesprochen, dass Sprachbefehle den Anbietern von virtuellen Assistenten in unverschlüsselter Form zur Verfügung stehen und damit an Dritte weitergegeben und unautorisiert oder unerwartet verarbeitet werden können. Zusätzlich zu den sprachlichen Inhalten der aufgezeichneten Rede können die Ausdrucks- und Spracheigenschaften eines Benutzers implizit Informationen über seine biometrische Identität, Persönlichkeitsmerkmale, Körperform, körperliche und geistige Gesundheitszustand, Sex, Geschlecht, Stimmungen und Emotionen, sozioökonomischen Status und geographische Herkunft enthalten. Entwicklerplattformen Wichtige Entwicklerplattformen für virtuelle Assistenten sind: Amazon Lex wurde im April 2017 für Entwickler geöffnet. Es umfasst die Technologie des natürlichen Sprachverständnisses in Verbindung mit der automatischen Spracherkennung und wurde im November 2016 eingeführt. Google bietet die Aktionen auf Google und Dialogflow-Plattformen für Entwickler, um Aktionen für Google Assistant Apple zu erstellen, SiriKit für Entwickler, Erweiterungen für Siri IBM's Watson zu erstellen, während manchmal als virtueller Assistent gesprochen wird in der Tat eine ganze künstliche Intelligenz Plattform und Gemeinschaft, die einige virtuelle Assistenten, Chatbots. und viele andere Arten von Lösungen. Vorherige Generationen In früheren Generationen von text-chat-basierten virtuellen Assistenten wurde der Assistent oft durch einen Avatar repräsentiert (a.k.ainteraktiver Online-Charakter oder automatisierter Charakter) — das war als verkörperter Agent bekannt. Vergleich bemerkenswerter Assistenten Wirtschaftliche Relevanz Für Einzelpersonen Digitale Erfahrungen, die von virtuellen Assistenten ermöglicht werden, gelten als eine der wichtigsten jüngsten technologischen Fortschritte und vielversprechendsten Konsumtrends. Experten behaupten, dass digitale Erfahrungen ein mit „realen“ Erfahrungen vergleichbares Status-Gewicht erreichen, wenn sie nicht gefragter und geschätzt werden. Der Trend wird durch eine hohe Anzahl von häufigen Benutzern und das beträchtliche Wachstum der weltweiten Nutzerzahlen von virtuellen digitalen Assistenten überprüft. Mitte 2017 wird die Zahl der häufigen Nutzer digitaler virtueller Assistenten weltweit auf rund 1 Mrd geschätzt. Darüber hinaus kann beobachtet werden, dass die virtuelle digitale Assistenztechnologie nicht mehr auf Smartphone-Anwendungen beschränkt ist, sondern in vielen Branchen (inkl. Automotive, Telekommunikation, Einzelhandel, Gesundheitswesen und Bildung) vorhanden ist. Als Reaktion auf die erheblichen FuE-Aufwendungen von Unternehmen in allen Sektoren und die zunehmende Umsetzung mobiler Geräte wird erwartet, dass der Markt für Spracherkennungstechnologie im Zeitraum 2016 bis 2024 weltweit bei einem CAGR von 34,9% wächst und damit eine globale Marktgröße von 7,5 Milliarden US-Dollar bis 2024 übertrifft. Laut einer Ovum-Studie wird die "native digitale Assistentin installiert Basis" projiziert, um die Weltbevölkerung bis 2021 zu überschreiten, mit 7,5 Milliarden aktiven Stimme AI-fähigen Geräten. Laut Ovum dominiert "Google Assistant die Stimme KI-fähigen Gerätemarkt mit 23,3% Marktanteil, gefolgt von Samsungs Bixby (14.5,%) Apples Siri (13.1,%) Amazons Alexa (3.9,%) und Microsofts Cortana (2.3%). "Unter Berücksichtigung der regionalen Verteilung der Marktführer werden die nordamerikanischen Unternehmen (z.B. Nuance Communications, IBM, eGain) in den nächsten Jahren aufgrund der erheblichen Auswirkungen von BYOD (Bring Your Own Device) und Unternehmensmobilitätsgeschäftsmodellen die Industrie dominieren. Darüber hinaus soll die steigende Nachfrage nach Smartphone-gestützten Plattformen das Wachstum der nordamerikanischen Intelligent Virtual Assistant (IVA)-Branche weiter steigern. Trotz ihrer geringeren Größe im Vergleich zum nordamerikanischen Markt wird die intelligente virtuelle Assistenzindustrie aus der Region Asien-Pazifik mit ihren Hauptakteuren in Indien und China voraussichtlich im Zeitraum 2016-2024 mit einer jährlichen Wachstumsrate von 40% (über dem globalen Durchschnitt) wachsen. Wirtschaftliche Gelegenheit für Unternehmen Virtuelle Assistenten sollten nicht nur als Gadget für Einzelpersonen betrachtet werden, da sie eine echte wirtschaftliche Nutzen für Unternehmen haben könnten. Als Beispiel kann ein virtueller Assistent die Rolle eines immer verfügbaren Assistenten mit einem enzyklopädischen Wissen übernehmen. Und welche Meetings, Check-Inseln organisieren, Informationen überprüfen können. Virtuelle Assistenten sind umso wichtiger, dass ihre Integration in kleine und mittlere Unternehmen oft in einem einfachen ersten Schritt durch die globale Anpassung und Nutzung von Internet of Things (IoT) besteht. In der Tat werden IoT-Technologien von kleinen und mittleren Unternehmen zunächst als Technologien von entscheidender Bedeutung wahrgenommen, aber zu kompliziert, riskant oder teuer zu verwenden. Sicherheit Im Mai 2018 veröffentlichten Forscher der University of California, Berkeley, ein Papier, das Audio-Befehle, die für das menschliche Ohr nicht nachweisbar waren, direkt in Musik oder gesprochenen Text eingebettet werden konnte, wodurch virtuelle Assistenten in bestimmte Aktionen manipuliert werden, ohne dass der Benutzer davon Kenntnis nimmt. Die Forscher haben kleine Änderungen an Audiodateien vorgenommen, die die Klangmuster auslöschen, die Spracherkennungssysteme erkennen sollen. Diese wurden durch Geräusche ersetzt, die durch das System anders interpretiert werden und es an die Rufnummern, die offenen Websites oder sogar das Geld übertragen. Die Möglichkeit dazu ist seit 2016 bekannt und betrifft Geräte von Apple, Amazon und Google. Neben unbeabsichtigten Handlungen und Sprachaufnahmen ist ein weiteres Sicherheits- und Datenschutzrisiko, das mit intelligenten virtuellen Assistenten verbunden ist, schädliche Sprachbefehle: Ein Angreifer, der einen Benutzer aufgibt und schädliche Sprachbefehle ausgibt, um zum Beispiel eine intelligente Tür zu entsperren, um einen unbefugten Eintrag in ein Haus oder eine Garage zu erhalten oder Gegenstände online ohne das Wissen des Benutzers zu bestellen. Obwohl einige IVAs eine Sprach-Training-Funktion bieten, um eine solche Verkörperung zu verhindern, kann es schwierig sein, das System zwischen ähnlichen Stimmen zu unterscheiden. So könnte eine bösartige Person, die auf ein IVA-fähiges Gerät zugreifen kann, in der Lage sein, das System in das Denken zu täuschen, dass sie der echte Eigentümer sind und kriminelle oder spitzbübische Handlungen ausführen.Siehe auch Anwendungen der künstlichen Intelligenz Chatbot Conversational Benutzeroberfläche Computer Gesichtsanimation Expert System Home Network Intelligent Agent Knowledge Navigator Microsoft Office Assistant Natürliche Sprachverarbeitung Simulated Reality Software Agent Wizard (Software) == Referenzen ==