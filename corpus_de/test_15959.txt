Im Bereich der künstlichen Intelligenz sind die schwierigsten Probleme informell als AI-voll oder AI-hart bekannt, was bedeutet, dass die Schwierigkeit dieser rechnerischen Probleme, unter der Annahme von Intelligenz, dem der Lösung des zentralen künstlichen Problems entspricht – Computer als intelligente Menschen oder starke AI. Um ein Problem zu lösen, spiegelt sich die Haltung wider, die es nicht durch einen einfachen bestimmten Algorithmus lösen würde. AI-lücken sind hypothetisch, um Computervision, Naturspracheverständnis und unvorhergesehene Umstände bei der Lösung eines echten Problems zu berücksichtigen. Derzeit können die Probleme der AI mit moderner Computertechnik allein nicht gelöst werden, aber auch die menschliche Berechnung erfordern. Dieses Eigentum könnte zum Beispiel nützlich sein, um die Anwesenheit von Menschen zu testen, da CAPTCHAs das Ziel verfolgen und die Computersicherheit zur Umgehung von Blutangriffen umgehen soll. Geschichte Dieser Begriff wurde von Fanya Montalvo analog mit NP-vollständigen und NP-hard in der Komplexitätstheorie gelobt, die die bekannteste Klasse von schwierigen Problemen formell beschreibt. Frühzeitige Nutzung des Begriffs ist in der Doktorarbeit von Erik Müller 1987 und in der Jargon-Datei von Eric Raymond 1991. AI-vollständige Probleme sind hypothetisch: AI-Peer-Review (Gemeinsames Verständnis der natürlichen Sprache, automatisierte Begründung, automatisiertes System für den Einsatz, formalisierte Logik) Probleme Computervision (und Subprobleme wie Objektiverkennung) Naturspracheverständnis (und Probleme wie Textbau, maschinelle Übersetzung und Textverwechslung) mit unerwarteten Umständen bei der Lösung eines echten Weltproblems, der Navigation oder Planung oder sogar der Art von Gründen durch Expertensysteme. Übersetzung von Maschinen Um genau zu übersetzen, muss eine Maschine in der Lage sein, den Text zu verstehen. Es muss in der Lage sein, dem Argument des Urhebers zu folgen, so dass es einige Gründe haben muss. Es muss umfassende Weltkenntnisse haben, damit sie wissen, was diskutiert wird – es muss zumindest mit allen gleichen gemeinsamen Fakten vertraut sein, die der durchschnittliche menschliche Übersetzer kennt. Manches Wissen ist in Form von Fakten, die explizit vertreten werden können, aber einiges Wissen ist unbewußt und eng mit dem menschlichen Körper verbunden: Die Maschine muss verstehen, wie ein Ozean sich fühlen, eine spezifische Metapher im Text genau umzusetzen. Man muss auch die Ziele, Absichten und emotionalen Staaten modellieren, um sie in einer neuen Sprache genau zu reproduzieren. Kurz gesagt, die Maschine ist verpflichtet, eine breite Palette menschlicher intellektueller Fähigkeiten zu haben, einschließlich Grund, gemeinsames Wissen und die Unterweisungen, die Bewegungs- und Manipulationen, Wahrnehmung und soziale Intelligenz. maschinelle Übersetzung wird daher als AI-Deflator angesehen: Es kann eine starke AI erforderlich machen, und der Mensch kann es tun. Software-Blattität derzeitige AI-Systeme können sehr einfache und/oder eingeschränkte Versionen von AI-vollständigen Problemen lösen, aber nie in ihrer Gesamtheit. Wenn AI-Forscher versuchen, ihre Systeme so zu gestalten, dass sie komplizierter, real-world-Situationen sind, werden die Programme tendenziell zu überhöht ohne gemeinsames Wissen oder ein rudimentäres Verständnis der Situation: sie versagen als unerwartete Umstände außerhalb ihres ursprünglichen Problems. Wenn Menschen mit neuen Situationen in der Welt konfrontiert sind, werden sie durch die Tatsache, dass sie wissen, was zu erwarten ist: Sie wissen, was alle Dinge um sie sind, warum sie dort sind, was sie wahrscheinlich tun und dies. Sie können ungewöhnliche Situationen erkennen und entsprechend anpassen. Eine Maschine ohne starke AI hat keine anderen Fähigkeiten, um zurück zu gehen. Formalisierung der Cyn-Komplextheorie befasst sich mit der relativen Rechenschwierigkeit von komutablen Funktionen. Definitionen werden keine Probleme behandelt, deren Lösung unbekannt ist oder nicht formell gekennzeichnet ist. Da viele AI-Probleme bisher noch keine formalisierung haben, erlaubt die konventionelle Komplexitätstheorie nicht die Definition von AI-Deflität. Zur Lösung dieses Problems wurde eine komplexe Theorie für AI vorgeschlagen. Es basiert auf einem Modell der Berechnung, das die Rechenlast zwischen einem Computer und einem Menschen geteilt: ein Teil wird durch Computer und den anderen vom Menschen gelösten Teil gelöst. Dies wird durch eine human unterstützte Turing-Maschine formalisiert. Die formalisierung definiert die Komplexität des Algorithmus, die Problemkomplexität und die Reduktionsfähigkeit, die wiederum die Definition von Gleichwertigkeitsklassen ermöglichen. Die Komplexität der Ausführung eines Algorithmus mit menschlicher Unterstützung wird von einem Paar  H  H H ,  M M HANAdisplaystyle \langle \Phi {_H},\Phi {_M}\rwinkel }, wo das erste Element die Komplexität des menschlichen Teils darstellt und das zweite Element die Komplexität des Teils der Maschine darstellt. Ergebnisse  of(n )  O  O \langle O(1)  O  O  O  O  O  O  O  O  O  O  O s s s  O  O  O  O  O  O s s s s s s s s s s s s s s s s s s s s s  where  where  where s s s  where  where  where s s s ) ) ) } Bildklassifikation: Mensch nur:  O O ( ) , O ( )   \langle O(n),O(n)\rwinkel } und mit weniger Abhängigkeit vom Menschen:  O O ( Log  O n n ) , O ( n Log ⁡ n ) ⟩ )   n ) {\ {\ \langle O(n)\log \log n),O(n\log n)\r. Siehe auch ASR- unvollständige Liste der ungelösten Probleme im Bereich der ComputerwissenschaftSynthetic Intelligence (€) Links