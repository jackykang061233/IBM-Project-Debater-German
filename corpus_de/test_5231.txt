Ein System auf einem Chip (SoC; es-oh-SEE oder sock) ist eine integrierte Schaltung (auch als Chip bekannt), die alle oder die meisten Komponenten eines Computers oder eines anderen elektronischen Systems integriert. Diese Komponenten umfassen fast immer eine zentrale Verarbeitungseinheit (CPU,) Speicher, Ein-/Ausgabe-Ports und sekundäre Speicherung, oft neben anderen Komponenten wie Radiomodems und einer Grafikverarbeitungseinheit (GPU) – alles auf einem einzigen Substrat oder Mikrochip. Es kann digitale, analoge, gemischte Signale und oft Funkfrequenzsignalverarbeitungsfunktionen enthalten (anders wird es als nur ein Anwendungsprozessor betrachtet). Höhere Leistung SoCs werden oft mit dedizierten und physikalisch getrennten Speicher- und Sekundärspeichern (fast immer LPDDR bzw. eUFS bzw. eMMC) Chips gepaart, die auf der SoC in der sogenannten Paket-Konfiguration (PoP) aufgeschichtet oder in der Nähe der SoC platziert werden können. Darüber hinaus können SoCs separate drahtlose Modem verwenden. SoCs stehen im Gegensatz zu der herkömmlichen PC-Architektur auf Motherboard-Basis, die Komponenten basierend auf Funktion trennt und über eine zentrale Leiterplatte verbindet. Während ein Mainboard Häuser beherbergt und lösbare oder austauschbare Komponenten verbindet, integrieren SoCs all diese Komponenten in einen einzigen integrierten Schaltkreis. Ein SoC wird in der Regel eine CPU, Grafik und Speicherschnittstellen, Festplatten- und USB-Konnektivität, zufällige Zugriffs- und Lesespeicher sowie sekundäre Speicher und/oder deren Controller auf einem einzigen Stromkreis sterben, während ein Mainboard diese Module als diskrete Komponenten oder Erweiterungskarten verbinden würde. Ein SoC integriert einen Mikrocontroller, Mikroprozessor oder vielleicht mehrere Prozessorkerne mit Peripheriegeräten wie GPU, Wi-Fi und Mobilfunkmodems und/oder einem oder mehreren Coprozessoren. Wie ein Mikrocontroller einen Mikroprozessor mit Peripherieschaltungen und Speicher integriert, kann ein SoC als Integration eines Mikrocontrollers mit noch fortgeschritteneren Peripheriegeräten angesehen werden. Zur Übersicht der Integration von Systemkomponenten siehe Systemintegration. Mehr eng integrierte Computer-System-Designs verbessern die Leistung und reduzieren den Stromverbrauch sowie die Halbleiter-Druckfläche als Multi-Chip-Designs mit gleichwertiger Funktionalität. Dies kommt zu den Kosten der reduzierten Austauschbarkeit von Komponenten. SoC-Designs sind definitionsgemäß vollständig oder fast vollständig über verschiedene Komponentenmodule integriert. Aus diesen Gründen gab es einen allgemeinen Trend zur engeren Integration von Komponenten in die Computerhardwareindustrie, zum Teil aufgrund des Einflusses von SoCs und Lehren aus den mobilen und Embedded Computing-Märkten. SoCs können als Teil einer größeren Tendenz zur Embedded Computing und Hardwarebeschleunigung betrachtet werden. SoCs sind sehr häufig in der mobilen Computing (wie in Smartphones und Tablet-Computern) und Edge Computing-Märkten. Sie werden auch häufig in eingebetteten Systemen wie WLAN-Routern und dem Internet der Dinge eingesetzt. Arten Im Allgemeinen gibt es vier unterscheidbare Arten von SoCs: SoCs um einen Mikrocontroller gebaut, SoCs um einen Mikroprozessor gebaut, oft in Mobiltelefonen gefunden; Spezialisierte anwendungsspezifische integrierte Schaltung SoCs für spezifische Anwendungen, die nicht in die oben beiden Kategorien passen, und programmierbare SoCs (PSoC), wo die meisten Funktionalitäten festgelegt sind, aber einige Funktionalität ist in einer Weise analog zu einem feldprogrammierbaren Gate-Array umprogrammierbar. Anwendungen SoCs können auf jede Rechenaufgabe angewendet werden. Sie werden jedoch typischerweise in mobilen Computern wie Tablets, Smartphones, Smartwatches und Netbooks sowie Embedded Systemen und in Anwendungen eingesetzt, in denen bisher Mikrocontroller eingesetzt werden. Embedded Systeme Wo bisher nur Mikrocontroller eingesetzt werden konnten, steigen SoCs auf den Markt für Embedded-Systeme. Die Tighter-Systemintegration bietet eine bessere Zuverlässigkeit und mittlere Zeit zwischen Ausfall und SoCs bieten erweiterte Funktionalität und Rechenleistung als Mikrocontroller. Anwendungen umfassen KI-Beschleunigung, eingebettete Bildverarbeitung, Datenerfassung, Telemetrie, Vektorverarbeitung und Umgebungsinformationen. Oft setzen eingebettete SoCs auf das Internet der Dinge, industrielles Internet der Dinge und Edge Computing Märkte. Mobile Computing Mobile Computing basierte SoCs bündeln immer Prozessoren, Speicher, On-Chip-Caches, drahtlose Netzwerkfähigkeiten und oft digitale Kamera-Hardware und Firmware. Mit zunehmenden Speichergrößen werden High-End-SoCs oft keinen Speicher und Flash-Speicher haben und stattdessen wird der Speicher und Flash-Speicher direkt neben oder oben (Paket auf Paket,) der SoC platziert. Einige Beispiele für mobile Computing SoCs sind: Samsung Electronics: Liste, typischerweise basierend auf ARM Exynos, hauptsächlich von Samsung Galaxy-Serie von Smartphones verwendet Qualcomm: Snapdragon (list,) in vielen LG, Xiaomi, Google Pixel, HTC und Samsung Galaxy Smartphones verwendet. 2018 werden Snapdragon SoCs als Rückgrat von Laptop-Computern mit Windows 10 verwendet, die als "Always Connected PCs" vermarktet werden. Personal Computer 1992 produzierte Acorn Computer die A3010, A3020 und A4000 Palette von Personalcomputern mit der ARM250 SoC. Es kombinierte den ursprünglichen Acorn ARM2 Prozessor mit einem Speichercontroller (MEMC,) Video Controller (VIDC,) und I/O Controller (IOC). In früheren Acorn ARM-Computern waren dies vier diskrete Chips. Der ARM7500-Chip war ihre zweite Generation SoC, basierend auf den ARM700, VIDC20 und IOMD-Controllern, und wurde weit verbreitet in eingebetteten Geräten wie Set-Top-Boxen, sowie später Acorn Personal Computer. SoCs werden ab 2018 auf Mainstream-Personalcomputer angewendet. Sie werden insbesondere auf Laptops und Tablet-PCs angewendet. Tablet- und Laptop-Hersteller haben Erfahrungen von Embedded-Systemen und Smartphone-Märkten über reduzierten Stromverbrauch, bessere Leistung und Zuverlässigkeit von der engeren Integration von Hardware- und Firmware-Modulen sowie LTE- und anderen auf Chip integrierten drahtlosen Netzwerkkommunikationen (integrierte Netzwerkschnittstellencontroller) gelernt. ARM-basiert: Qualcomm Snapdragon ARM250 ARM7500(FE)Apple M1x86-basiert: Intel Core CULV Structure Ein SoC besteht aus Hardware-Funktionseinheiten, einschließlich Mikroprozessoren, die Softwarecode betreiben, sowie einem Kommunikations-Subsystem, um diese Funktionsmodule zu verbinden, zu steuern, zu steuern, zu steuern und zu schnittstellen. Funktionelle Komponenten Prozessorkerne Eine SoC muss mindestens einen Prozessorkern aufweisen, aber typischerweise hat eine SoC mehr als einen Kern. Prozessorkerne können ein Mikrocontroller, Mikroprozessor (μP,) Digitalsignalprozessor (DSP) oder anwendungsspezifischer Befehlssatzprozessor (ASIP) Kern sein. ASIPs verfügen über Befehlssätze, die für eine Anwendungsdomäne angepasst sind und für eine bestimmte Art von Arbeitsbelastung effizienter als allgemeine Gebrauchsanweisungen ausgelegt sind. Multiprozessor SoCs haben mehr als einen Prozessorkern nach Definition. Ob Single-Core, Multi-Core oder Manycore, SoC-Prozessor-Kerne verwenden typischerweise RISC-Instruktionsset-Architekturen. RISC-Architekturen sind gegenüber CISC-Prozessoren für SoCs vorteilhaft, weil sie weniger digitale Logik benötigen, und daher weniger Strom und Fläche an Bord, und in den Embedded- und Mobile-Computing-Märkten sind Flächen und Strom oft stark eingeschränkt. Insbesondere verwenden SoC-Prozessor-Kerne oft die ARM-Architektur, da es sich um einen weichen Prozessor handelt, der als IP-Kern bezeichnet wird und leistungsfähiger ist als x86. Speicher SoCs müssen Halbleiterspeicherblöcke haben, um ihre Berechnung durchzuführen, ebenso Mikrocontroller und andere eingebettete Systeme. Je nach Anwendung kann SoC-Speicher eine Speicherhierarchie und Cache-Hierarchie bilden. Im Mobilfunkmarkt ist dies häufig, aber in vielen leistungsarmen eingebetteten Mikrocontrollern ist dies nicht notwendig. Speichertechnologien für SoCs umfassen nur Lesespeicher (ROM,) Zufalls-Zugriff-Speicher (RAM,) Elektrische Erasable Programmable ROM (EEPROM) und Flash-Speicher. Wie bei anderen Computersystemen kann RAM in relativ schnellere, aber teurere statische RAM (SRAM) und das langsamere, aber billigere dynamische RAM (DRAM) unterteilt werden. Wenn eine SoC eine Cache-Hierarchie hat, wird SRAM in der Regel verwendet, um Prozessor-Register und Cores L1 Caches zu implementieren, während DRAM für niedrigere Ebenen der Cache-Hierarchie einschließlich Hauptspeicher verwendet wird. "Hauptspeicher" kann für einen einzigen Prozessor (der Multi-Core sein kann) spezifisch sein, wenn der SoC mehrere Prozessoren hat, wobei er Speicher verteilt ist und über den von einem anderen Prozessor zuzugreifenden § Intermodule-Kommunikations-on-Chip gesendet werden muss. Zur weiteren Diskussion von mehrverarbeitenden Gedächtnisproblemen siehe Cache-Kohärenz und Gedächtnis-Latenz. Schnittstellen SoCs umfassen externe Schnittstellen, typischerweise für Kommunikationsprotokolle. Diese basieren oft auf Industriestandards wie USB, FireWire, Ethernet, USART, SPI, HDMI, I2C, etc. Diese Schnittstellen unterscheiden sich je nach Anwendungszweck. Es können auch drahtlose Netzwerkprotokolle wie WLAN, Bluetooth, 6LoWPAN und Nahfeldkommunikation unterstützt werden. Bei Bedarf umfassen SoCs analoge Schnittstellen einschließlich Analog-Digital- und Digital-Analog-Wandler, oft zur Signalverarbeitung. Diese können in der Lage sein, mit verschiedenen Arten von Sensoren oder Aktuatoren, einschließlich intelligenter Wandler, zu verbinden. Sie können mit anwendungsspezifischen Modulen oder Schilden Schnittstelle. Oder sie können intern an die SoC sein, beispielsweise wenn ein analoger Sensor in die SoC eingebaut ist und dessen Messwerte in digitale Signale für die mathematische Verarbeitung umgewandelt werden müssen. Digitale Signalprozessoren Digitaler Signalprozessor (DSP) Kerne sind oft auf SoCs enthalten. Sie führen Signalverarbeitungsvorgänge in SoCs für Sensoren, Aktoren, Datenerfassung, Datenanalyse und Multimedia-Verarbeitung durch. DSP-Kerne weisen typischerweise sehr lange Befehlsworte (VLIW) und Einzelanweisungen, mehrere Daten (SIMD) Befehlssatzarchitekturen auf und sind daher durch parallele Verarbeitung und superscalare Ausführung sehr gut geeignet, Befehlsebenenparallelität auszunutzen. DSP-Kerne weisen meist anwendungsspezifische Anweisungen auf und sind typischerweise anwendungsspezifische Instruktionsset-Prozessoren (ASIP.) Solche anwendungsspezifischen Anweisungen entsprechen dedizierten Hardware-Funktionseinheiten, die diese Anweisungen berechnen. Typische DSP-Anweisungen umfassen multiply-accumulate, Fast Fourier-Transformation, fusionierte multiply-add und Faltungen. Andere Wie bei anderen Computersystemen benötigen SoCs Zeitquellen, um Taktsignale zu erzeugen, die Ausführung von SoC-Funktionen zu steuern und bei Bedarf Zeitkontexte für Signalverarbeitungsanwendungen der SoC bereitzustellen. Beliebte Zeitquellen sind Kristalloszillatoren und phasenverriegelte Schleifen. SoC-Peripheriegeräte einschließlich Zählerständer, Echtzeit-Timer und Power-on-Reset-Generatoren. SoCs umfassen auch Spannungsregler und Leistungsmanagementschaltungen. Intermodule Kommunikation SoCs umfassen viele Ausführungseinheiten. Diese Einheiten müssen oft Daten und Anweisungen hin und her senden. Aus diesem Grund benötigen alle, aber die meisten trivialen SoCs Kommunikationssubsysteme. Ursprünglich wurden, wie bei anderen Mikrocomputer-Technologien, Data-Bus-Architekturen verwendet, aber vor kurzem Designs basierend auf spärlichen Interkommunikationsnetzwerken, die als Netzwerk-on-Chip (NoC) bekannt sind, sind auf Vorherrschaft gestiegen und werden in naher Zukunft Bus-Architekturen für SoC-Design überholen. Busbasierte Kommunikation Historisch verbindet ein gemeinsamer globaler Computerbus typischerweise die verschiedenen Komponenten, auch Blöcke der SoC genannt. Ein sehr häufiger Bus für SoC-Kommunikation ist ARMs lizenzfreier Advanced Microcontroller Bus Architecture (AMBA). Direkte Speicherzugriffssteuerungen Routendaten direkt zwischen externen Schnittstellen und SoC-Speicher, um die CPU oder Steuereinheit zu umgehen, wodurch der Datendurchsatz der SoC erhöht wird. Dies ist ähnlich wie einige Gerätetreiber von Peripheriegeräten auf komponentenbasierten Multichip-Modul-PC-Architekturen. Computer-Busse sind in Skalierbarkeit begrenzt und unterstützen nur bis zu zehn Kerne (Multicore) auf einem einzigen Chip. Die Kabelverzögerung ist nicht skalierbar, da die Systemleistung nicht mit der Anzahl der angeschlossenen Kerne skalierbar ist, die Betriebsfrequenz der SoC muss mit jedem zusätzlichen Kern, der für eine nachhaltige Leistung angebracht ist, abnehmen, und lange Drähte verbrauchen große Mengen an elektrischer Leistung. Diese Herausforderungen sind untersagt, viele Core-Systeme auf Chip zu unterstützen. Netzwerk auf einem Chip In den späten 2010er Jahren hat sich ein Trend von SoCs zur Implementierung von Kommunikations-Subsystemen in Bezug auf eine netzartige Topologie anstelle von busbasierten Protokollen herausgestellt. Ein Trend zu mehr Prozessorkernen auf SoCs hat dazu geführt, dass On-Chip-Kommunikationseffizienz zu einem der Schlüsselfaktoren bei der Bestimmung der Gesamtsystemleistung und -kosten wird. Dies hat zur Entstehung von Verbindungsnetzwerken mit Router-basierten Paketvermittlungen, die als "Netzwerke auf Chip" (NoCs) bekannt sind, geführt, um die Engpässe von Bus-basierten Netzwerken zu überwinden. Networks-on-Chip haben Vorteile einschließlich der ziel- und anwendungsspezifischen Routing, höhere Leistungseffizienz und reduzierte Möglichkeit der Bus-Inhalte. Netzwerk-on-Chip-Architekturen inspirieren sich von Kommunikationsprotokollen wie TCP und der Internet-Protokoll-Suite für On-Chip-Kommunikation, obwohl sie typischerweise weniger Netzwerkschichten haben. Optimale Netzwerk-on-Chip-Netzwerk-Architekturen sind ein laufender Bereich von viel Forschungsinteresse. NoC-Architekturen reichen von traditionellen verteilten Rechennetzwerktopologien wie Torus, Hypercube, Meshs und Baumnetzwerken bis hin zu genetischen Algorithmen, wie zufällige Spaziergänge mit Verzweigung und randomisierter Zeit bis zum Leben (TTL). Viele SoC-Forscher halten NoC-Architekturen für die Zukunft des SoC-Designs, weil sie gezeigt wurden, um den Leistungs- und Durchsatzbedarf von SoC-Designs effizient zu erfüllen. Aktuelle NoC-Architekturen sind zweidimensional. 2D-IC-Design hat begrenzte Bodenplaning-Auswahlen, da die Anzahl der Kerne in SoCs zunehmen, so wie dreidimensionale integrierte Schaltungen (3DICs) entstehen, SoC-Designer blicken auf den Aufbau dreidimensionaler On-Chip-Netzwerke, die als 3DNoCs bekannt sind. Der Design-Flow für eine SoC zielt darauf ab, diese Hardware und Software gleichzeitig zu entwickeln, auch als architektonisches Co-Design bekannt. Der Designfluss muss auch Optimierungen (§ Optimierungsziele) und Einschränkungen berücksichtigen. Die meisten SoCs werden aus vorqualifizierten Hardware-Komponenten-IP-Kernspezifikationen für die Hardware-Elemente und Ausführungseinheiten entwickelt, gemeinsam Blöcke, oben beschrieben, zusammen mit Software-Gerätetreibern, die ihren Betrieb steuern können. Von besonderer Bedeutung sind die Protokollstapel, die branchenübliche Schnittstellen wie USB antreiben. Die Hardware-Blöcke werden mit computergestützten Design-Tools, speziell elektronischen Design-Automatisierungs-Tools, zusammengebaut; die Software-Module werden mit einer softwareintegrierten Entwicklungsumgebung integriert. SoCs-Komponenten sind auch oft in hochrangigen Programmiersprachen wie C,+ MATLAB oder SystemC konzipiert und durch hochgradige Synthese (HLS)-Tools wie C bis HDL oder HDL in RTL-Designs umgewandelt. HLS-Produkte, die als "algorithmische Synthese" bezeichnet werden, ermöglichen es den Designern, C+ zu verwenden, um System-, Schaltungs-, Software- und Verifikationsebenen in einer hohen Sprache zu modellieren und zu synthetisieren. Andere Komponenten können Software bleiben und als Module in HDL als IP-Kerne auf Soft-Core-Prozessoren zusammengestellt und eingebettet werden. Sobald die Architektur des SoC definiert ist, werden alle neuen Hardware-Elemente in einer abstrakten Hardware-Beschreibungssprache mit dem Namen Register-Transfer-Level (RTL) geschrieben, die das Schaltungsverhalten definiert oder aus einer hochrangigen Sprache durch hochrangige Synthese in RTL synthetisiert. Diese Elemente sind in einer Hardware-Beschreibungssprache miteinander verbunden, um das komplette SoC-Design zu erstellen. Die zur Verbindung dieser Komponenten angegebene Logik und Konvertierung zwischen eventuell verschiedenen Schnittstellen, die von verschiedenen Anbietern bereitgestellt werden, wird als Leimlogik bezeichnet. Design-Verifikation Chips werden für Validierungsfehler überprüft, bevor sie an eine Halbleiter-Gießerei gesendet werden. Dieser Prozess wird als funktionelle Überprüfung bezeichnet, und er macht einen signifikanten Teil der Zeit und Energie aus, die im Chip-Design-Lebenszyklus, oft als 70% angegeben, verbraucht wird. Mit der wachsenden Komplexität von Chips werden Hardware-Verilog-Sprachen wie SystemVerilog, SystemC, e und OpenVera verwendet. Fehler, die in der Prüfphase gefunden wurden, werden dem Designer gemeldet. Traditionell haben Ingenieure Simulationsbeschleunigung, Emulation oder Prototyping auf reprogrammierbaren Hardware eingesetzt, um Hardware und Software für SoC-Designs vor der Fertigstellung des Designs, bekannt als Tape-out, zu überprüfen und zu debuggen. Feldprogrammierbare Gate-Arrays (FPGAs) werden für die Prototyping von SoCs bevorzugt, da FPGA-Prototypen neu programmierbar sind, Debugging erlauben und flexibler sind als anwendungsspezifische integrierte Schaltungen (ASICs). Mit hoher Kapazität und schneller Compilationszeit sind Simulationsbeschleunigung und Emulation leistungsfähige Technologien, die eine breite Sichtbarkeit in Systeme bieten. Beide Technologien funktionieren jedoch langsam, auf der Größenordnung von MHz, was wesentlich langsamer sein kann – bis zu 100 mal langsamer – als die Betriebsfrequenz des SoC. Beschleunigungs- und Emulationsboxen sind auch sehr groß und teuer mit über 1 Million US$. FPGA-Prototypen hingegen nutzen FPGAs direkt, um Ingenieuren die volle Betriebsfrequenz eines Systems mit realen Reizes zu validieren und zu testen. Werkzeuge wie Certus werden verwendet, um Sonden im FPGA RTL einzufügen, die Signale zur Beobachtung zur Verfügung stellen. Dies wird verwendet, um Hardware-, Firmware- und Software-Interaktionen über mehrere FPGAs mit ähnlichen Funktionen wie ein Logikanalysator zu debuggen. Parallel werden die Hardwareelemente gruppiert und durch einen Prozess der Logiksynthese geleitet, bei dem Leistungszwänge, wie Betriebsfrequenz und erwartete Signalverzögerungen, angelegt werden. Dadurch wird ein als Netzliste bezeichneter Ausgang erzeugt, der das Design als physikalische Schaltung und dessen Verknüpfungen beschreibt. Diese Netzlisten werden mit der die Komponenten verbindenden Klebelogik kombiniert, um die schematische Beschreibung der SoC als Schaltung zu erzeugen, die auf einen Chip gedruckt werden kann. Dieses Verfahren ist als Ort und Weg bekannt und wickelt vor, wenn die SoCs als anwendungsspezifische integrierte Schaltungen (ASIC) hergestellt werden. Optimierungsziele SoCs müssen den Stromverbrauch, die Fläche auf der Düse, die Kommunikation, die Positionierung für die Lokalität zwischen modularen Einheiten und anderen Faktoren optimieren. Optimierung ist notwendigerweise ein Designziel von SoCs. Falls eine Optimierung nicht erforderlich wäre, würden die Ingenieure eine Multichip-Modul-Architektur verwenden, ohne die Flächenauslastung, den Stromverbrauch oder die Leistung des Systems in gleichem Maße zu berücksichtigen. Gemeinsame Optimierungsziele für SoC-Designs folgen, mit Erklärungen von jedem. Im allgemeinen kann die Optimierung einer dieser Größen ein hartes kombinatorisches Optimierungsproblem sein, und kann in der Tat NP-hart ziemlich einfach sein. Daher werden häufig anspruchsvolle Optimierungsalgorithmen benötigt und es kann in einigen Fällen sinnvoll sein, Approximationsalgorithmen oder Heuristiken zu verwenden. Zusätzlich enthalten die meisten SoC-Designs mehrere Variablen, um gleichzeitig zu optimieren, so werden Pareto effiziente Lösungen im SoC-Design gesucht. Oftmals stehen die Ziele der Optimierung einiger dieser Größen direkt im Widerspruch, die Komplexität der Designoptimierung von SoCs und die Einführung von Kompromissen im Systemdesign. Für eine breitere Erfassung von Abschlüssen und Anforderungen siehe Anforderungstechnik. Ziele Leistungsaufnahme SoCs sind optimiert, um die elektrische Leistung zu minimieren, die zur Ausführung der SoC-Funktionen verwendet wird. Die meisten SoCs müssen niedrige Leistung verwenden. SoC-Systeme benötigen oft eine lange Akkulaufzeit (wie Smartphones), können möglicherweise Monate oder Jahre ohne eine Stromquelle, die autonome Funktion aufrecht erhalten muss, ausgeben und sind oft durch eine hohe Anzahl von eingebetteten SoCs, die in einem Bereich miteinander vernetzt werden, eingeschränkt.Darüber hinaus können die Energiekosten hoch sein und die Energieeinsparung wird die Gesamtkosten des Eigentums an der SoC reduzieren. Schließlich kann die Abwärme aus dem hohen Energieverbrauch andere Schaltungskomponenten beschädigen, wenn zu viel Wärme abgeführt wird, was einen weiteren pragmatischen Grund zur Energieeinsparung gibt. Die Menge an Energie, die in einer Schaltung verwendet wird, ist das Integral von Energie, die in Bezug auf die Zeit verbraucht wird, und die durchschnittliche Stromaufnahme ist das Produkt von Strom durch Spannung. Äquivalent, nach Ohm's Gesetz, Strom quadratische Zeiten Widerstand oder Spannung quadratisch geteilt durch Widerstand: SoCs sind häufig in tragbare Geräte wie Smartphones, GPS-Navigationsgeräte, digitale Uhren (einschließlich Smartwatches) und Netbooks eingebettet. Kunden wollen lange Akkulaufzeiten für mobile Computergeräte, ein weiterer Grund, dass der Stromverbrauch in SoCs minimiert werden muss. Multimedia-Anwendungen werden oft auf diesen Geräten ausgeführt, darunter Videospiele, Videostreaming, Bildverarbeitung, die in den letzten Jahren mit Benutzeranforderungen und Erwartungen für hochwertige Multimedia-Anwendungen rechnerisch komplex geworden sind. Die Computation ist anspruchsvoller, da sich die Erwartungen in Richtung 3D-Video mit hoher Auflösung mit mehreren Standards bewegen, so dass SoCs, die Multimedia-Aufgaben ausführen, eine rechnerisch fähige Plattform sein muss, während sie eine geringe Leistung zur Ausschaltung eines Standard-Mobilbatteries ist. Leistung pro Watt SoCs sind optimiert, um die Leistungseffizienz in Leistung pro Watt zu maximieren: maximieren Sie die Leistung der SoC bei einem Budget der Leistungsnutzung. Viele Anwendungen wie Edge Computing, verteilte Verarbeitung und Umgebungsintelligenz erfordern ein bestimmtes Maß an Rechenleistung, aber die Leistung ist in den meisten SoC-Umgebungen begrenzt. Die ARM-Architektur hat eine höhere Leistung pro Watt als x86 in eingebetteten Systemen, so ist es über x86 für die meisten SoC-Anwendungen bevorzugt, die einen eingebetteten Prozessor benötigen. Abfallwärme SoC-Designs sind optimiert, um die Abwärmeleistung auf dem Chip zu minimieren. Wie bei anderen integrierten Schaltkreisen sind Wärme aufgrund hoher Leistungsdichte der Engpass zur weiteren Miniaturisierung von Bauteilen. Die Leistungsdichten von High-Speed-integrierten Schaltungen, insbesondere Mikroprozessoren und einschließlich SoCs, sind sehr ungleichmäßig geworden. Zu viel Abwärme kann Schaltkreise beschädigen und die Zuverlässigkeit der Schaltung über die Zeit erodieren. Hohe Temperaturen und thermische Belastung negativ beeinflussen Zuverlässigkeit, Stressmigration, verringerte mittlere Zeit zwischen Ausfällen, Elektromigration, Drahtbonden, Metastabilität und andere Leistungsabbau der SoC im Laufe der Zeit. Insbesondere sind die meisten SoCs in einem kleinen physikalischen Bereich oder Volumen und daher werden die Auswirkungen der Abwärme vereinigt, weil es wenig Raum gibt, um aus dem System zu diffundieren. Aufgrund des hohen Transistors zählt auf moderne Geräte aufgrund des Moore-Gesetzes oft ein Layout ausreichender Durchsatz und hoher Transistordichte aus Fertigungsprozessen physikalisch realisierbar, würde aber zu unannehmbar hohen Wärmemengen im Stromkreis führen. Diese thermischen Effekte zwingen SoC und andere Chip-Designer, konservative Design Margen anzuwenden, wodurch weniger performante Geräte, um das Risiko eines katastrophalen Ausfalls zu mindern. Durch erhöhte Transistordichten, da Längenmaßstäbe kleiner werden, erzeugt jede Prozessgeneration mehr Wärmeleistung als die letzte. SoC-Architekturen sind in der Regel heterogen und erzeugen räumlich inhomogene Wärmeflüsse, die durch eine gleichmäßige passive Kühlung nicht effektiv gemildert werden können. Durchsatz-SoCs werden optimiert, um den Rechen- und Kommunikationsdurchsatz zu maximieren. Latenz SoCs sind optimiert, um Latenz für einige oder alle ihre Funktionen zu minimieren. Dies kann erreicht werden, indem Elemente mit der richtigen Nähe und Lokalität zu jeder anderen, um die Verbindungsverzögerungen zu minimieren und die Geschwindigkeit zu maximieren, mit der Daten zwischen Modulen, Funktionseinheiten und Speichern kommuniziert werden. Im allgemeinen ist die Optimierung der Latenz ein NP-komplettes Problem, das dem booleanischen Befriedigungsproblem entspricht. Für Aufgaben, die auf Prozessorkernen laufen, können Latenz und Durchsatz mit Aufgabenplanung verbessert werden. Einige Aufgaben laufen in anwendungsspezifischen Hardware-Einheiten, und sogar Aufgabenplanung kann nicht ausreichen, um alle softwarebasierten Aufgaben zu optimieren, um Timing und Durchsatzzwänge zu erfüllen. Methoden Systeme auf Chip werden mit Standard-Hardware-Verifikations- und Validierungstechniken modelliert, aber zusätzliche Techniken werden verwendet, um SoC-Design-Alternativen zu modellieren und zu optimieren, um das System optimal in Bezug auf die Multiple-Crteria-Entscheidungsanalyse zu den oben genannten Optimierungszielen zu machen. Aufgabenplanung Task-Scheduling ist eine wichtige Aktivität in jedem Computersystem mit mehreren Prozessen oder Threads, die einen einzigen Prozessorkern teilen. Es ist wichtig, § Latency zu reduzieren und § Durchsatz für eingebettete Software zu erhöhen, die auf den § Processor Cores eines SoC läuft. Nicht jede wichtige Computing-Aktivität in einem SoC wird in Software ausgeführt, die auf On-Chip-Prozessoren läuft, aber Schieduling kann die Leistung von softwarebasierten Aufgaben und anderen Aufgaben mit gemeinsamen Ressourcen drastisch verbessern. SoCs terminieren oft Aufgaben nach Netzwerk-Scheduling und randomisierten Terminierungsalgorithmen. Pipelining Hardware und Software-Aufgaben werden oft in Prozessor-Design Pipeline. Pipelining ist ein wichtiges Prinzip zur Beschleunigung in der Computerarchitektur. Sie werden häufig in GPUs (Grafikenpipeline) und RISC-Prozessoren (Evolutionen der klassischen RISC-Pipeline) eingesetzt, werden aber auch auf anwendungsspezifische Aufgaben wie digitale Signalverarbeitung und Multimedia-Manipulationen im Kontext von SoCs angewendet. Probabilistische Modellierung SoCs werden oft analysiert, obwohl probabilistische Modelle, Queueing Theorie § Queueing-Netzwerke und Markov-Ketten. Zum Beispiel erlaubt Littles Gesetz, SoC-Staaten und NoC-Puffer als Ankunftsprozesse zu modellieren und durch Poisson Zufallsvariablen und Poisson-Prozesse zu analysieren. Markov-Ketten SoCs werden oft mit Markov-Ketten modelliert, sowohl diskrete Zeit als auch kontinuierliche Zeitvarianten. Markov-Kettenmodellierung ermöglicht eine asymmetrische Analyse der stetigen Zustandsverteilung von Strom, Wärme, Latenz und anderen Faktoren, um Designentscheidungen für den gemeinsamen Fall zu optimieren. SoC-Chips werden üblicherweise mit der Metall-Oxid-Halbleiter-Technologie (MOS) hergestellt. Die oben beschriebenen Netzlisten werden als Grundlage für den physikalischen Entwurf (Ort und Route) Fluss verwendet, um die Absicht der Designer in das Design der SoC umzuwandeln. Während dieses Umwandlungsprozesses wird das Design mit statischer Timing-Modellierung, Simulation und anderen Werkzeugen analysiert, um sicherzustellen, dass es die vorgegebenen Betriebsparameter wie Frequenz, Stromverbrauch und Dissipation, Funktionsintegrität (wie im Register-Transfer-Level-Code beschrieben) und elektrische Integrität erfüllt. Wenn alle bekannten Fehler behoben wurden und diese neu verifiziert wurden und alle physikalischen Design-Checks durchgeführt werden, werden die physikalischen Design-Dateien, die jede Schicht des Chips beschreiben, in den Maskenshop der Gießerei geschickt, wo eine komplette Reihe von glaslithographischen Masken geätzt werden. Diese werden an eine Waferfabrik geschickt, um die SoC Würfel vor der Verpackung und Prüfung zu erstellen. SoCs können durch mehrere Technologien hergestellt werden, darunter: Volle benutzerdefinierte ASIC Standardzelle ASIC Feldprogrammierbares Gate-Array (FPGA)ASICs verbrauchen weniger Strom und sind schneller als FPGAs, können aber nicht neu programmiert werden und sind teuer zu fertigen. FPGA-Designs sind besser geeignet für kleinere Volumen-Designs, aber nach genug Produktionseinheiten reduzieren ASICs die Gesamtbetriebskosten. SoC-Designs verbrauchen weniger Strom und haben eine geringere Kosten und höhere Zuverlässigkeit als die Multichip-Systeme, die sie ersetzen. Mit weniger Paketen im System werden auch Montagekosten reduziert. Wie die meisten großformatigen Integrations- (VLSI)-Designs sind die Gesamtkosten jedoch für einen großen Chip höher als für die gleiche Funktionalität, die über mehrere kleinere Chips verteilt wird, wegen niedrigerer Erträge und höherer nicht wiederkehrender Engineering-Kosten. Wenn es nicht möglich ist, eine SoC für eine bestimmte Anwendung zu konstruieren, ist eine Alternative ein System in Paket (SiP) mit einer Anzahl von Chips in einem einzigen Paket. Bei der Herstellung in großen Volumina ist SoC kostengünstiger als SiP, da seine Verpackung einfacher ist. Ein weiterer Grund, warum SiP bevorzugt sein kann, ist die Abwärme in einer SoC für einen bestimmten Zweck zu hoch, da Funktionskomponenten zu nahe beieinander liegen und in einer SiP-Wärme besser von verschiedenen Funktionsmodulen ableiten wird, da sie physikalisch weiter auseinander liegen. Benchmarks SoC Forschung und Entwicklung vergleicht oft viele Optionen. Benchmarks wie COSMIC werden entwickelt, um solche Bewertungen zu unterstützen. Siehe auch Liste der System-on-a-Chip-Lieferanten Post-Silizium Validierung ARM-Architektur Single-Board-Computer System in Paket Netzwerk auf einem Chip Programmable SoC Application-spezifische Instruktionsset-Prozessor (ASIP) Plattformbasiertes Design Lab auf einem Chip Organ auf einem Chip in der Biomedizinischen Technologie Multi-Chip-Modul Liste der Qualcomm Snapdragon-Prozessoren - Qualcomm Exynos - Samsung Notes - Samsung Notes Referenzen weiter lesen Badawy, Wael. System-on-Chip für Echtzeit-Anwendungen. Kluwer internationale Serie in Ingenieur- und Informatik, SECS 711. Boston: Kluwer Academic Publishers.ISBN 9781402072543.OCLC 50478525.465 Seiten. Furber, Stephen B. (2000). ARM-System-on-Chip-Architektur. Boston: Addison-Wesley.ISBN 0-201-67519-6.Kundu, Santanu; Chattopadhyay, Santanu (2014). Netzwerk-on-Chip: die nächste Generation der System-on-Chip-Integration (1. ed.). Boca Raton, FL: CRC Press.ISBN 9781466565272.OCLC 895661009. Externe Links SOCC Annual IEEE International SoC Conference Baya free SoC Plattform Assembly and IP Integration tool Systems on Chip for Embedded Applications, Auburn University Seminar in VLSI Instant SoC für FPGAs definiert von C+