Die Probenkomplexität eines maschinellen Lernalgorithmus stellt die Anzahl der Trainingsproben dar, die er benötigt, um eine Zielfunktion erfolgreich zu erlernen. Genauer gesagt ist die Probenkomplexität die Anzahl der Trainingsproben, die wir dem Algorithmus liefern müssen, so dass die vom Algorithmus zurückgegebene Funktion innerhalb eines willkürlich kleinen Fehlers der bestmöglichen Funktion liegt, mit Wahrscheinlichkeit willkürlich nahe 1. Es gibt zwei Varianten der Probenkomplexität: Die schwache Variante stellt eine bestimmte Input-Output-Verteilung fest; die starke Variante nimmt den schlimmsten Probenkomplex über alle Input-Output-Verteilungen. Das unten diskutierte No Free Lunch Theorem beweist, dass im Allgemeinen die starke Probenkomplexität unendlich ist, d.h. es gibt keinen Algorithmus, der die global optimierte Zielfunktion mit einer endlichen Anzahl von Trainingsproben erlernen kann. Wenn wir jedoch nur an einer bestimmten Klasse von Zielfunktionen (z.B. nur lineare Funktionen) interessiert sind, dann ist die Probenkomplexität endlich, und sie hängt linear von der VC-Dimension von der Klasse der Zielfunktionen ab. Definition Lassen X {\displaystyle X} ein Raum sein, den wir den Eingaberaum nennen, und Y {\displaystyle Y} ein Raum sein, den wir den Ausgaberaum nennen, und Z {\displaystyle Z} das Produkt X × Y {\displaystyle X\times Y} bezeichnen lassen. Fixieren Sie einen Hypothesenraum H {\displaystyle {\mathcal {H} der Funktionen h : X → Y {\displaystyle h\colon X\to Y} .Ein Lernalgorithmus über H {\displaystyle {\mathcal {H} ist eine rechnerische Karte von Z χ {\displaystyle Z^{}* zu H {\displaystyle {\\mathcal {H}} . Mit anderen Worten, es ist ein Algorithmus, der als Eingabe eine endliche Sequenz von Trainingsproben nimmt und eine Funktion von X {\displaystyle X} bis Y {\displaystyle Y} ausgibt. Typische Lernalgorithmen umfassen empirische Risikominimierung, ohne oder mit Tikhonov Regularisierung. (x) In unserer Einstellung haben wir h = A (S n ) {\displaystyle h={\mathcal A}(S_{n) , wobei A {\displaystyle {\mathcal {A} ein Lernalgorithmus ist und S n = ( x 1 , y 1 ) , ..., ( x n , y n ) ) S_{n}=((x_{1},y_{1}),\ldots (x_{n},y_{n}))\sim \rho {^n} ist eine Sequenz von Vektoren, die alle unabhängig von ρ {\displaystyle \rho } gezogen werden. Setzen Sie h n = A (S n ) {\displaystyle h_{n}={\mathcal A}(S_{n) , für jede n {\displaystyle n} .Bemerken Sie, dass h n {\displaystyle h_{n} eine zufällige Variable ist und von der Zufallsvariable S n\displaystyle S_{n} style abhängt, die aus der Verteilung ρ n {\displayn} gezogen wird. Der Algorithmus A {\displaystyle {\mathcal {A} wird als konsistent bezeichnet, wenn E (h n ) {\displaystyle {\mathcal E}(h_{n) probabilistisch zu E H Ψ\displaystyle {\mathcal E}_{\mathcal In anderen Worten gibt es für alle ε, δ > 0 {\displaystyle \epsilon ,\delta >0} eine positive ganze Zahl N {\displaystyle N}, so dass für alle n ≥ N {\displaystyle\geq N} die Probenkomplexität von A {\displaystyle {\mathcal {A} dann die minimale N\geq n} ist N} hängt von ρ , ε {\displaystyle \rho ,\epsilon } und δ {\displaystyle \delta } ab. Wenn A {\displaystyle {\mathcal {A} nicht konsistent ist, dann setzen wir N ( ρ , ε , δ ) = ∞ {\displaystyle N(\rho ,\epsilon ,\delta =\)infty }. Wenn es einen Algorithmus gibt, für den N ( ρ , ε , δ ) {\displaystyle N(\rho ,\epsilon ,\delta )} endlich ist, dann sagen wir, dass der Hypothesenraum H {\displaystyle {\mathcal {H} erlernbar ist. In anderen Worten, die Probenkomplexität N (ρ , ε , δ ) {\displaystyle N(\rho ,\epsilon } definiert die Konsistenz des Algorithmus: bei einer gewünschten Genauigkeit ε {\displaystyle \epsilon } und dem Vertrauen δ\displaystyle \delta } Beachten Sie, dass dies ein stärkerer Begriff ist als erlernbar. Unbeschränkter Hypothesenraum: unendliche Probenkomplexität Man kann fragen, ob es einen Lernalgorithmus gibt, so dass die Probenkomplexität im starken Sinne endlich ist, d.h. es gibt eine Begrenzung auf die Anzahl der benötigten Proben, so dass der Algorithmus jede Verteilung über den Ein-Ausgaberaum mit einem vorgegebenen Zielfehler erlernen kann. Mehr formal fragt man, ob es einen Lernalgorithmus gibt A {\displaystyle {\mathcal {A}, so dass für alle ε, δ > 0 {\displaystyle \epsilon,\delta >0} eine positive ganze Zahl N {\displaystyle N} vorhanden ist, so dass für alle n ≥ N\displaystyle n\geq N} haben wir, wo h n = A (S n) {\displaystyle (S_{n}={\mathcal A}}(S_{n) , mit S n = (x 1 , y 1 , ..., (x n , y n ) S_{n}=((x_{1},y_{1}),\ldots (x_{n},y_{n}))\sim \rho {^n} wie oben. Das kostenlose Mittagessen Theorem sagt, dass ohne Einschränkungen auf den Hypothesenraum H {\displaystyle {\mathcal {H}, dies nicht der Fall ist, d.h. es gibt immer schlechte Verteilungen, für die die Probenkomplexität willkürlich groß ist. Um Aussagen über die Konvergenzgeschwindigkeit der Menge zu machen, muss man also entweder den Raum der Wahrscheinlichkeitsverteilungen ρ {\displaystyle \rho }, z.B. über einen parametrischen Ansatz, einschränken oder den Raum der Hypothesen H {\displaystyle {\mathcal {H} wie bei verteilungsfreien Ansätzen einschränken. Eingeschränkter Hypothesenraum: endliche Probenkomplexität Letzterer Ansatz führt zu Konzepten wie VC-Dimension und Rademacher-Komplexität, die die Komplexität des Raumes H {\displaystyle {\mathcal {H} steuern.Ein kleinerer Hypothesenraum führt mehr Vorspannung in den Inferenzprozess ein, was bedeutet, dass E H ++ {\displaystyle {\\mathcal E}}_{\mathcal H^* kann größer sein als das bestmögliche Risiko in einem größeren Raum. Durch die Einschränkung der Komplexität des Hypothesenraums wird es jedoch möglich, dass ein Algorithmus einheitlichere Funktionen erzeugt. Diese Abhandlung führt zum Begriff der Regulierung. Es ist ein Theorem aus der VC-Theorie, dass die folgenden drei Aussagen für einen Hypothesenraum H {\displaystyle {\mathcal {H} gleichwertig sind: H {\displaystyle {\mathcal {H} ist PAC-learnierbar. Die VC-Dimension von H {\displaystyle {\mathcal {H} ist endlich. H {\displaystyle {\mathcal {H} ist eine einheitliche Glivenko-Cantelli Klasse. Dies gibt einen Weg zu beweisen, dass bestimmte Hypothesenräume PAC erlernbar sind, und durch Erweiterung, erlernbar. Ein Beispiel für einen PAC-lösbaren Hypothesenraum X = R d , Y = { - 1 , 1 } {\displaystyle X=\mathbb {R} ^d},Y=\{-1,1 , und lassen H {\displaystyle {\mathcal {H} der Raum der Affinfunktionen auf X {\displaystyle X} sein, d.h. Funktionen des Formulars x  w w , x ・ + b\displaystyle x\mapsto \langle w,x\rangle {R} .This ist die lineare Klassifikation mit Offset-Learning-Problem. Beachten Sie nun, dass vier Koplanarpunkte auf einem Quadrat nicht durch eine Affinfunktion zersplittert werden können, da keine Affinfunktion auf zwei diagonal gegenüberliegenden Vertiken und Negativ auf den übrigen beiden positiv sein kann. So ist die VC-Dimension von H {\displaystyle {\mathcal {H} d + 1 {\displaystyle d+1}, so ist es endlich. Es folgt die obige Charakterisierung von PAC-learnable Klassen, die H {\displaystyle {\mathcal {H} PAC-learnable ist, und durch Erweiterung, erlernbar. Probenkomplexität gebunden Suppose H {\displaystyle} {H} ist eine Klasse binärer Funktionen (Funktionen zu {0, 1} {\displaystyle {0,1} .) Dann ist H {\displaystyle {\mathcal {H} (ε , δ ) {\displaystyle \(epsilon ,\delta } PAC-lösbar mit einer Größe: wobei V C (H) {\displaystyle VC({\mathcal {H}) die VC-Dimension von H {\displaystyle {\mathcal {H} ist.Mehr, jeder (ε δ ) {\displaystyle \(epsilon ,\delta )} PAC-learning-Algorithmus für H\ Angenommen H {\displaystyle} {H} ist eine Klasse von real bewerteten Funktionen mit Reichweite in [0 , T ] {\displaystyle [0,T]} .Dann, H {\displaystyle {\mathcal {H} ist ( ε , δ ) {\displaystyle \(epsilon ,\delta )} PAC-lösbar mit einer Größe: wobei P D (H) {\displaystyle PD({\mathcal {H}) Pollards Pseudodimension von H {\displaystyle {\mathcal {H} ist. Weitere Einstellungen Neben der beaufsichtigten Lerneinstellung ist die Komplexität der Stichprobe für semi-supervised Lernprobleme, einschließlich des aktiven Lernens, relevant, wo der Algorithmus nach Labels zu speziell ausgewählten Eingaben verlangen kann, um die Kosten für die Gewinnung von vielen Labels zu reduzieren.Das Konzept der Probenkomplexität zeigt sich auch in der Verstärkung des Lernens, des Online-lernens und unübertroffenen Algorithmen, z.B. für das Wörterbuchlernen. Effizienz in der Robotik Eine hohe Probenkomplexität bedeutet, dass viele Berechnungen für den Betrieb einer Monte Carlo Baumsuche erforderlich sind. Es entspricht einer modellfreien brutalen Kraftsuche im Staatsraum. Ein hoher Wirkungsgradalgorithmus weist dagegen eine geringe Probenkomplexität auf. Mögliche Techniken zur Reduzierung der Probenkomplexität sind metrisches Lernen und modellbasiertes Verstärkungslernen. = Referenzen ==