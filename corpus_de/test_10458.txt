Gesetze der Robotik sind eine Reihe von Gesetzen, Regeln oder Grundsätzen, die als grundlegender Rahmen dienen, um das Verhalten von Robotern zu unterstützen, die eine gewisse Autonomie haben. Roboter dieser Komplexität sind noch nicht vorhanden, aber sie sind in der Science-Fiction, Filme weit verbreitet und sind ein Thema der aktiven Forschung und Entwicklung in den Bereichen Robotik und künstliche Intelligenz. Die besten bekannten Gesetze sind jene, die von Isaac Asimov in den 1940er Jahren geschrieben wurden oder auf deren Grundlage basieren, aber in den Jahrzehnten haben Forscher weitere Gesetze vorgeschlagen. Isaac Asimov's "Three Law of Robotics" Isaac Asimov's "Three Laws of Robotics". Diese wurden in seiner kurzen Geschichte von 1942 Runabout eingeführt, obwohl sie in einigen früheren Geschichten verborgen waren. Drei Gesetze sind: Ein Roboter kann ein menschliches Leben nicht verletzen oder durch Untätigkeit den Menschen den Schaden zufügen. Ein Roboter muss die ihm vom Menschen erteilten Bestellungen einhalten, es sei denn, solche Bestellungen würden mit dem ersten Gesetz in Konflikt geraten. Ein Roboter muss sein eigenes Bestehen schützen, solange ein solcher Schutz nicht mit den ersten oder Zweiten Gesetzen im Widerspruch steht. In dem Evitable-Konflikt werden die Maschinen das erste Gesetz zu dem Schluss bringen: „Keine Maschine kann die Menschheit schädigen oder durch Untätigkeit die Menschheit schädigen. " Am Ende der Stiftung und der Erde wurde ein Nullgesetz eingeführt, wobei der ursprüngliche drei als nachrangig zu lesende Artikel: 0.A Roboter kann die Menschheit nicht verletzen oder durch Untätigkeit die Menschheit schädigen. Anpassungen und Erweiterungen gibt es auf der Grundlage dieses Rahmens. Im Jahr 2011 bleiben sie ein „kritisches Gerät“. EPSRC / AHRC Grundsätze der Robotik 2011 haben der Forschungsrat für Ingenieurwissenschaften und Physik (EPSRC) und der Forschungsrat für Kunst und Geisteswissenschaften (AHRC) des Vereinigten Königreichs gemeinsam eine Reihe von fünf ethischen "Grundsätzen für Designer, Bauherren und Nutzer von Robotern" in der realen Welt sowie sieben "hochrangige Botschaften" veröffentlicht, die auf einem Forschungsseminar vom September 2010 basieren: Roboter sollten nicht allein oder in erster Linie bestimmt werden, um Menschen zu töten oder zu schädigen. Menschen, nicht Roboter, sind verantwortliche Agenten. Roboter sind Instrumente zur Erreichung menschlicher Ziele. Roboter sollten so konzipiert werden, dass ihre Sicherheit und Sicherheit gewährleistet sind. Roboter sind Art; sie sollten nicht so konzipiert werden, dass sie gefährdete Nutzer nutzen, indem sie eine emotionale Reaktion oder Abhängigkeit vorweisen. Es sollte immer möglich sein, einen Roboter von einem Menschen zu melden. Man sollte immer herausfinden, wer für einen Roboter rechtlich verantwortlich ist. Die zu vermittelnden Botschaften waren: Wir glauben, dass Roboter das Potenzial haben, der Gesellschaft enorme positive Auswirkungen zu verleihen. Wir wollen verantwortungsbewusste Roboterforschung fördern. Bad Praxis schadet uns allen. Klare öffentliche Anliegen werden uns dabei helfen, Fortschritte zu erzielen. Man muss nachweisen, dass wir als Roboter auf die besten Praxisstandards setzen. Um den Kontext und die Auswirkungen unserer Forschung zu verstehen, sollten wir mit Experten anderer Disziplinen zusammenarbeiten, darunter Sozialwissenschaften, Recht, Philosophie und Kunst. Wir sollten die Ethik der Transparenz in Betracht ziehen: Es gibt Grenzen, was offen sein sollte? Wenn wir falsche Konten in der Presse sehen, verpflichten wir uns, die Zeit zu nehmen, um mit den Berichterstattungsjournalisten Kontakt aufzunehmen. Die Grundsätze der EPSRC werden weitgehend als nützlicher Ausgangspunkt anerkannt. Im Jahr 2016 veranstaltete Tony Prescott einen Workshop, um diese Grundsätze zu überarbeiten, z.B. durch unterschiedliche ethische Grundsätze. Justizielle Entwicklung Eine weitere umfassende terminologische Kodifizierung für die rechtliche Bewertung der technologischen Entwicklungen in der Robotik-Industrie hat bereits hauptsächlich in asiatischen Ländern begonnen. Dieser Fortschritt stellt eine zeitgenössische Neuausrichtung des Gesetzes (und der Ethik) im Bereich der Robotik dar, eine Auslegung, die eine Neuausrichtung der traditionellen Rechtskonstellationen übernimmt. Diese umfassen vor allem rechtliche Haftungsfragen im Zivil- und Strafrecht. Satya Naturla-Gesetze im Juni 2016 hatte Satya Naturela, CEO der Microsoft Corporation, ein Interview mit dem Slate Magazine und rund sechs Regeln für künstliche Intelligenz, die von ihren Designern zu beobachten sind: „A.I muss so konzipiert sein, dass die Menschheit unterstützt werden kann“, d. h. die menschliche Autonomie muss respektiert werden. „A.I muss transparent sein“, d. h. der Mensch sollte wissen und in der Lage sein zu verstehen, wie er funktioniert. „A.I muss Effizienzgewinne maximieren, ohne die Würde der Menschen zu zerstören“, muss die A.I für intelligente Privatsphäre konzipiert werden, so dass sie Vertrauen durch Schutz ihrer Informationen verdient. "A.I muss die Rechenfähigkeit haben, damit der Mensch unbeabsichtigte Schaden zunichte machen kann"."A.I muss vor Verzerrungen schützen, damit sie Menschen nicht diskriminieren dürfen. Tilden's "Laws of Robotics" Mark W. Tilden ist ein Roboterphysiker, der ein Pionier bei der Entwicklung einfacher Robotik war. Seine drei Leitprinzipien für Roboter sind: Ein Roboter muss seine Existenz bei allen Kosten schützen. Ein Roboter muss Zugang zu seiner eigenen Stromquelle erhalten und erhalten. Ein Roboter muss kontinuierlich auf bessere Energiequellen suchen. Kennzeichnend in diesen drei Regeln ist, dass dies im Wesentlichen Regeln für das Wildleben sind, so dass die Tilden erklärt hat, dass sie "eine Silicium-Arten in die Geimpfung verlagern wollten, aber mit der vollen Kontrolle über die Spekulationen. Keine Anlage. Kein Tier. Nichts anderes. Sehen Sie auch eine freundschaftlich-ethische Ethik künstlicher militärischer Roboter, die so konzipiert werden können, dass sie gegen das erste Gesetz von Asimov verstoßen. Drei Gesetze von Transhumanism Clarke's drei Gesetze Niven's Laws Links