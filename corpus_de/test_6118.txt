In der Informatik ist Online-Maschinenlernen eine Methode des maschinellen Lernens, bei der Daten in einer sequentiellen Reihenfolge zur Verfügung stehen und verwendet wird, um den besten Predictor für zukünftige Daten an jedem Schritt zu aktualisieren, im Gegensatz zu Batch-Learning-Techniken, die den besten Predictor durch Lernen auf dem gesamten Trainingsdatensatz auf einmal erzeugen. Online-Lernen ist eine gemeinsame Technik, die in Bereichen des maschinellen Lernens verwendet wird, wo es rechnerisch unfehlbar ist, über den gesamten Datensatz zu trainieren, was die Notwendigkeit von Out-of-Core-Algorithmen erfordert. Es wird auch in Situationen verwendet, in denen es für den Algorithmus erforderlich ist, sich dynamisch an neue Muster in den Daten anzupassen, oder wenn die Daten selbst in Abhängigkeit von der Zeit erzeugt werden, z.B. Aktienkursvorhersage. Online-Lernalgorithmen können anfällig für katastrophale Störungen sein, ein Problem, das durch inkrementelle Lernansätze angesprochen werden kann. Einleitung In der Einstellung des überwachten Lernens, eine Funktion von f : X → Y {\displaystyle f:X\to Y} ist zu erlernen, wo X {\displaystyle X} als ein Raum von Eingaben und Y {\displaystyle Y} als ein Raum von Ausgängen gedacht wird, die gut auf Instanzen vorhersagen, die aus einer gemeinsamen Wahrscheinlichkeitsverteilung p (x, y ) {\displaystyle p(x,y}) auf X × Y {\displaystyle X\times Y} gezogen werden. Vielmehr hat der Lernende in der Regel Zugriff auf ein Trainingsset von Beispielen (x 1 , y 1 ) , ... , (x n , y n ) {\displaystyle (x_{1},y_{1}),\ldots (x_{n},y_{n) .In dieser Einstellung wird die Verlustfunktion als V : Y × Das ideale Ziel ist es, eine Funktion f ε H {\displaystyle f\in {\mathcal {H} zu wählen, in der H {\displaystyle {\mathcal {H} ein Raum der Funktionen ist, die als Hypothesenraum bezeichnet werden, so dass ein Teil der Vorstellung von Gesamtverlust minimiert wird. Je nach Art des Modells (statistisch oder adversarial) kann man verschiedene Begriffe des Verlusts entwickeln, die zu unterschiedlichen Lernalgorithmen führen. Statistische Sicht des Online-Lernens In statistischen Lernmodellen wird davon ausgegangen, dass die Trainingsprobe (x i, y i) {\displaystyle (x_{i},y_{i} aus der wahren Verteilung p (x, y ) {\displaystyle p(x,y}) gezogen worden ist und das erwartete Risiko I [f ] = E [ V (f ( x ) , y ) f] = δ {\displaystyle I[f]=\mathbb {E} [V(f(x),y)]=\int V(f(x),y)\,dp(x,y) Ein gemeinsames Paradigma in dieser Situation besteht darin, eine Funktion f ^ {\displaystyle {\hat {f} durch empirische Risikominimierung oder normierte empirische Risikominimierung (in der Regel Tikhonov Regularisierung) abzuschätzen. Die Wahl der Verlustfunktion führt hier zu mehreren bekannten Lernalgorithmen wie regelmäßige kleinste Quadrate und Unterstützungsvektormaschinen. Ein reines Online-Modell in dieser Kategorie würde anhand der neuen Eingabe (x t + 1 , y t + 1 ) {\displaystyle (x_{t+1},y_{t+1) , des aktuellen besten Prädiktors f t {\displaystyle f_{t} und einiger extra gespeicherter Informationen (die in der Regel von der Trainingsdatengröße unabhängig sind) lernen. Für viele Formulierungen, z.B. nichtlineare Kernel-Methoden, ist ein echtes Online-Lernen nicht möglich, obwohl eine Form des hybriden Online-Lernens mit rekursiven Algorithmen verwendet werden kann, wobei f t + 1 {\displaystyle f_{t+1} von f t {\displaystyle f\t} und alle vorherigen Datenpunkte ( x 1 , y 1 play) abhängen darf. Eine gemeinsame Strategie zur Überwindung der oben genannten Probleme ist es, mit Mini-Batches zu lernen, die eine kleine Charge von b ≥ 1 {\displaystyle b\geq 1} Datenpunkten zu einem Zeitpunkt verarbeiten, dies kann als pseudo-online-Lernen für b {\displaystyle b} viel kleiner als die Gesamtzahl der Trainingspunkte betrachtet werden. Mini-Batch-Techniken werden mit wiederholtem Überlaufen der Trainingsdaten verwendet, um optimierte Out-of-Core-Versionen von maschinellen Lernalgorithmen zu erhalten, beispielsweise stochastische Gradientenabstieg. In Kombination mit Backpropagation ist dies derzeit die de facto-Trainingsmethode für die Ausbildung künstlicher neuronaler Netze. Beispiel: lineare kleinste Quadrate Das einfache Beispiel von linearen kleinsten Quadraten wird verwendet, um eine Vielzahl von Ideen im Online-Lernen zu erklären. Die Ideen sind allgemein genug, um auf andere Einstellungen angewendet werden, zum Beispiel mit anderen konvexen Verlustfunktionen. Batch lernen Betrachten Sie die Einstellung des überwachten Lernens mit f {\displaystyle f} ist eine lineare zu lernende Funktion: f ( x j ) =  of w, x j ・ = w ∙ x j {\displaystyle f(x_{j})=\langle w,x_{j}\rangle=w\cdot x_{j} wobei x j ε R d {\displaystyle x_{j}\in \mathbb {R} {^d} ein Vektor von Eingängen (Datenpunkte) ist und w ε R d {\displaystyle w\in \mathbb {R} {^d} ein linearer Filtervektor ist. Ziel ist es, den Filtervektor w {\displaystyle w} zu berechnen. Zu diesem Zweck ist eine quadratische Verlustfunktion V ( f ( x j ) , y j ) = ( f ( x j ) - y j ) 2 = (⟩ w , x j ・ - y j ) 2 {\displaystyle V(f(x_{j}),y_{j})=(f(x_{j})-y_{j})^{2}=(\langle w,x_{j}\rangle -y_{j}^^{2 verwendet wird, um den Vektor w {\display} zu berechnen ,x_{j}\rangle ,y_{j}=\sum j=1}^^{n}(x_{j}{T}w-y_{j}{2 wo y j ε R\displaystyle y_{j} in \mathbb {R} } .Let X {\displaystyle X} ist die i × d {\displaystyle i\times d} Datenmatrix und y ε R i {\displaystyle y\in \mathbb {R}^i} ist der Spaltenvektor von Zielwerten nach dem Eintreffen der ersten i {\displaystyle i} Datenpunkte. Unter der Annahme, dass die Kovarianzmatrix Σ i = X T X {\displaystyle \Sigma _i}=X^{T}X invertierbar ist (anders ist es bevorzugt, in ähnlicher Weise mit Tikhonov Regularisierung fortzufahren), ist die beste Lösung f χ χ ) = ∗ w ≠, x ・\displaystyle f^{*}(x)=\langle w (X T X ) - 1 X T y = Σ i - 1 Σ j = 1 i x j y j j {\displaystyle w^{*}=(X{T}X{-1}X^{T}y=\Sigma _i}\sum j=1^{i}x_{j}y_{j .Now, Berechnung der Kovarianzmatrix Σ i = Σ j = 1 i x j x j T {\displaystyle *Sigma {_i} i=1^{i}x_{j}x_{j}^{T nimmt die Zeit O (i d 2 ) {\displaystyle O(id^{2}, invertiert die d × d {\displaystyle d\times d}-Matrix die Zeit O (d 3 ) i + 1 x i + 1 T x_{i+1}x_{i+1}^{T, die O (d 2 ) {\displaystyle O(d^{2}) Zeit nimmt, die Gesamtzeit auf O (n d 2 + n d 3 ) = O (n d 3 ) {\displaystyle O(nd{2}+nd^{3})=O(nd^{3 }, aber mit einem zusätzlichen Speicherplatz Online-Lernen: wiederkehrende kleinste Plätze Der rekursive Wenigsten Quadrate (RLS) Algorithmus betrachtet einen Online-Ansatz zum kleinsten Quadrat Problem. Es kann gezeigt werden, dass durch Initialisierung w 0 = 0 ε R d {\displaystyle \textstyle w_{0}=0\in \mathbb (R) R d × d {\displaystyle \textstyle \Gamma {_0}=I\in \mathbb {R} {^d\times d}, die Lösung des linearen kleinsten Quadrats Problem im vorherigen Abschnitt kann durch folgende Iteration berechnet werden: Γ i = Γ i - 1 - Γ i - 1 x i x i T Γ i - 1 1 + x i T Γ i - 1 x i Gamma {_i} - Ich... - Ja. Gamma ***** Gamma i-1 w i = w i - 1 − Γ i x i ( x i T w i - 1 − y i ) {\displaystyle ! Gamma i}x_{i}(x_{i}{T}w_{i-1}-y_{i} Der obige Iterationsalgorithmus kann mit Induktion auf i {\displaystyle i} nachgewiesen werden. Der Nachweis zeigt auch, dass Γ i = Σ i - 1 {\displaystyle \Gamma {_i}=\Sigma _i}^{-1 .Man kann RLS auch im Kontext adaptiver Filter betrachten (siehe RLS). Die Komplexität für n {\displaystyle n}-Schritte dieses Algorithmus ist O (n d 2 ) {\displaystyle O(nd^{2}), die eine Größenordnung schneller als die entsprechende Batch-Learning-Komplexität ist. Die Speicheranforderungen an jeden Schritt i {\displaystyle i} sollen die Matrix Γ i {\displaystyle \Gamma {_i} speichern, die bei O (d 2) konstant ist {\displaystyle O(d^{2} . Für den Fall, dass Σ i {\displaystyle \Sigma {_i} nicht invertierbar ist, betrachten Sie die normierte Version der Problemverlustfunktion Σ j = 1 n ( x j t w - y j ) 2 + λ | w  w dis 2 {\displaystyle \sum j=1{n}(x_{j}^{T}w-y_{j}^) w||_{2}^{2 .Dann ist es einfach zu zeigen, dass der gleiche Algorithmus mit Γ 0 = (I + λ I) - 1 {\displaystyle \Gamma {_0}=(I+\lambda I)^{-1} arbeitet und die Iterationen zu Γ i = (Σ i + λ I ) − 1 {\displaystyle ** ***************************************************************************** I) Stochastic Gradientenabstieg Wenn diese w i = w i - 1 - Γ i x i ( x i T w i - 1 - y i) {\displaystyle \textstyle ! Gamma i}x_{i}(x_{i}^{T}w_{i-1}-y_{i) wird durch w i = w i - 1 − γ i x i ( x i T w i - 1 - y i ) = w i - 1 - γ i ‡ V ( ⟨ w i − 1 , x i ・ , y i ) {\displaystyle \textstyle ) ) ! w_{i-1},x_{i}\rangle ,y_{i}) oder Γ i ε R d × d {\displaystyle \Gamma {_i}\in \mathbb {R}^d\times d} von γ i ε R {\displaystyle \gamma {_i}\in \mathbb {R} } wird dieser Gradientenalgorithmus der stoch In diesem Fall reduziert sich die Komplexität für n {\displaystyle n}-Schritte dieses Algorithmus auf O (n d ) {\displaystyle O(nd}) .Die Speicheranforderungen an jeden Schritt i {\displaystyle i} sind konstant bei O (d ) {\displaystyle O(d}) . Allerdings muss die Schrittgröße γ i {\displaystyle \gamma risk {_i} sorgfältig gewählt werden, um das Problem zu lösen. Durch die Wahl einer Zerfallschrittsgröße γ i ≈ 1 i, {\displaystyle \gamma {_i}\approx {\frac 1}{\sqrt {i,} kann man die Konvergenz des durchschnittlichen Iterats w ̄ n = 1 n Σ i = 1 n w i {\displaystyle {\overline ) 1 ) .Diese Einstellung ist ein besonderer Fall der stochastischen Optimierung, ein bekanntes Problem bei der Optimierung. Inkrementelle stochastische Gradientenabstieg In der Praxis kann man mehrere stochastische Gradienten-Pässe (auch Zyklen oder Epochen genannt) über die Daten ausführen. Der so erhaltene Algorithmus wird inkrementale Gradientenmethode genannt und entspricht einer Iteration w i = w i - 1 - γ i ‡ V ( ) w i - 1 , x t i ・ y t i ) {\displaystyle \textstyle ) ! ,,y_{t_{i} Der Hauptunterschied zur stochastischen Gradientenmethode besteht darin, dass hier eine Sequenz t i {\displaystyle t_{i} gewählt wird, um zu entscheiden, welcher Trainingspunkt im i {\displaystyle i} -ten Schritt besucht wird. Eine solche Sequenz kann stochastisch oder deterministisch sein. Die Anzahl der Iterationen wird dann auf die Anzahl der Punkte entkoppelt (jeder Punkt kann mehr als einmal betrachtet werden). Das inkrementale Gradientenverfahren kann gezeigt werden, um ein Minimierer für das empirische Risiko zu bieten. Inkrementale Techniken können vorteilhaft sein, wenn man objektive Funktionen betrachtet, die aus einer Summe von vielen Begriffen bestehen, z.B. einem empirischen Fehler, der einem sehr großen Datensatz entspricht. Kernelverfahren Kernel können verwendet werden, um die obigen Algorithmen auf nicht-parametrische Modelle zu erweitern (oder Modelle, bei denen die Parameter einen unendlichen Raum bilden). Das entsprechende Verfahren wird nicht mehr wirklich online sein und stattdessen alle Datenpunkte speichern, sondern ist noch schneller als die brutale Kraftmethode. Diese Diskussion ist auf den Fall des Quadratverlustes beschränkt, obwohl sie auf jeden konvexen Verlust ausgedehnt werden kann. Es kann durch eine einfache Induktion gezeigt werden, dass, wenn X i {\displaystyle X_{i} die Datenmatrix ist und w i {\displaystyle w_{i} der Ausgang nach i {\displaystyle i} Schritten des SGD-Algorithmus ist, dann, w i = X i T c i {\displaystyle i} ) T}c_{i, wobei c i = (c i ) 1 , (c i ) 2 ..., (c i ) i ε R i {\displaystyle \textstyle c_{i}=(c_{i})_{1},(c_{i})_{2},...,(c_{i})_{i})\in \mathbb {R} {i} und die Sequenz c i\displaystyle c_{i} satisfis die Wiederholung: c 0 = 0 {\displaystyle c_{0}=0 (c i ) j = ( c i - 1 ) j, j = 1 , 2 ... i - 1 {\displaystyle c_{i}_{j}=(c_{i-1})_{j},j=1,2,...,i-1 und (c i) i = γ i ( y i - Σ j = 1 i - 1 (c i - 1 ) j ⟨ x j , x i ・ Groß ) x_{j},x_{i}\rangle {\Big }}}}} ⟩ dann wird der gleiche Beweis auch zeigen, dass der Prädiktor, der den geringsten Quadratverlust minimiert, durch Änderung der obigen Rekursion zu (c i) i = γ i ( y i - Σ j = 1 i - 1 (c i - 1 ) j K ( x j , x i ) ) (y_{i}-\sum j=1}{i-1}(c_{i-1})_{j}K(x_{j},x_{i} Groß. Der vorstehende Ausdruck erfordert die Speicherung aller Daten zur Aktualisierung c i {\displaystyle c_{i} . Die Gesamtzeitkomplexität für die Rekursion bei der Auswertung für den n {\displaystyle n} -th datapoint is O ( n 2 d k) {\displaystyle O(n^{2}dk) , wobei k {\displaystyle k} die Kosten für die Auswertung des Kernels auf einem einzigen Paar von Punkten ist. So hat die Verwendung des Kernels die Bewegung aus einem endlichen dimensionalen Parameterraum w i ε R d {\displaystyle \textstyle w_{i}\in \mathbb {R} {^d} zu einer möglicherweise unendlichen dimensionalen Funktion, die durch einen Kernel K {\displaystyle K} dargestellt wird, erlaubt, indem statt dessen Rekursion auf dem Raum der Parameter c i ε R i {display} Im Allgemeinen ist dies eine Folge des Repräsentantentheorems. Online-Konvex-Optimierung Online-Konvex-Optimierung (OCO) ist ein allgemeiner Rahmen für die Entscheidungsfindung, die konvexe Optimierung nutzt, um effiziente Algorithmen zu ermöglichen. Das Framework ist das von wiederholtem Spiel wie folgt:For t = 1 , 2 ,..., T {\displaystyle t=1,2,...,T} Lernender erhält Eingang x t {\displaystyle x_{t} Lernerausgänge w t {\displaystyle w_{t} aus einem festen konvexen Satz S {\displaystyle S} Natur sendet eine konvexe Verlustfunktion v t: S → R {\displaystyle v_{t}:S\rightarrow \mathbb {R} .Learner leidet Verlust v t (w t) {\displaystyle v_{t}(w_{t) und aktualisiert sein Modell Das Ziel ist es, das Bedauern oder den Unterschied zwischen kumulativem Verlust und dem Verlust des besten Fixpunktes u ε S {\displaystyle u\in S} in Hindsight zu minimieren. Als Beispiel betrachten Sie den Fall der Online-Letzte Quadrate lineare Regression. Hier kommen die Gewichtsvektoren aus dem konvexen Satz S = R d {\displaystyle S=\mathbb {R} {^d} und die Natur sendet die konvexe Verlustfunktion v t (w) = ( ⟨ w, x t ・ - y t ) 2 {displaystyle v_{t}(w)=(\langle w,x_{t}\rangle -y_{t)Beachten Sie hier, dass y t {\displaystyle y_{t} implizit mit v t {\displaystyle v_{t} gesendet wird .Einige Online-Prädiktionsprobleme können jedoch nicht im Rahmen von OCO passen. Beispielsweise sind in der Online-Klassifikation die Prädiktionsdomäne und die Verlustfunktionen nicht konvex. In solchen Szenarien werden zwei einfache Techniken zur Konvexierung verwendet: Zufalls- und Surrogatverlustfunktionen. Einige einfache online konvexe Optimierungsalgorithmen sind: Folgen Sie dem Führer (FTL)Die einfachste Lernregel zu versuchen ist, die Hypothese (im aktuellen Schritt) auszuwählen, die den geringsten Verlust über alle vergangenen Runden hat. Dieser Algorithmus wird aufgerufen Folgen Sie dem Anführer und wird einfach rund t {\displaystyle t} von: w t = a r g m i n w ε S Σ i = 1 t - 1 v i (w ) {\displaystyle Der Name ist: (arg\,min) Summe (w) Dieses Verfahren kann somit als gieriger Algorithmus betrachtet werden. Für den Fall der Online quadratischen Optimierung (wo die Verlustfunktion v t ist (w ) = | | w − x t dis ), 2 {\displaystyle v_{t}(w)=||w-x_{t}^_{2}^{2}{2 ), kann man ein Bedauern zeigen, das als log ≠ wächst (T ) {\displaystyle \log(T}). Für andere wichtige Familien von Modellen wie die Online-Linearoptimierung können jedoch ähnliche Grenzen für den FTL-Algorithmus nicht erreicht werden. Dazu modifiziert man FTL durch die Hinzufügung von Regularisierung. Folgen Sie dem regulären Führer (FTRL) Dies ist eine natürliche Modifikation von FTL, die verwendet wird, um die FTL-Lösungen zu stabilisieren und bessere Bedauern Grenzen zu erhalten. Eine Regelfunktion R : S → R {\displaystyle R:S\rightarrow \mathbb {R} } wird ausgewählt und das Lernen in Runde t wie folgt durchgeführt: w t = a r g m i n w ε S ermittelt i = 1 t - 1 v i ( w ) + R ( w ) Der Name ist: (arg\,min) (w\in S}\sum i=1{t-1}v_{i}(w)+R(w) Als besonderes Beispiel betrachten Sie den Fall der Online-Linear-Optimierung, d.h. wo die Natur Rückverlustfunktionen des Formulars v t (w ) = ⟨ w , z t ・ {\displaystyle v_{t}(w)=\langle w,z_{t}\rangle } zurücksendet. R d {\displaystyle S=\mathbb {R} {^d} .Angenommen die Regularisierungsfunktion R (w ) = 1 2 η  w w  w | 2 {\displaystyle R(w)={\frac 1}{2\eta w||_{2}^{2 wird für eine positive Zahl η {\displaystyle \eta } gewählt.Dann kann man zeigen, dass die bedauerliche Minimierung der Iteration w t + 1 = - η Σ i = 1 t z i = w t - η z t ) Z_{t) Beachten Sie, dass dies mit w t + 1 = w t - η MENT v t (w t ) {\displaystyle w_{t+1}=w_{t}-\eta \nabla v_{t}(w_{t)  neu geschrieben werden kann, die genau wie Online-Gradientenabstieg aussieht. Wenn S stattdessen ein konvexer Subraum von R d {\displaystyle \mathbb {R} {^d} ist, müsste S projiziert werden, was zu der geänderten Aktualisierungsregel w t + 1 = Π S führt ( - η Σ i = 1 t z i) = Π S ( η θ t + 1 ) w_{t+1}=\Pi {_S}(-\eta \sum i=1}^{t}z_{i}=\Pi {_S}(\eta \theta {_t+1} Dieser Algorithmus ist als faule Projektion bekannt, da der Vektor θ t + 1 {\displaystyle \theta {_t+1} die Gradienten ansammelt. Es ist auch bekannt als Nesterovs Dual-Aging-Algorithmus. In diesem Szenario der linearen Verlustfunktionen und der quadratischen Regularisierung wird das Bedauern durch O (T ) {\displaystyle O({\sqrt {T}) begrenzt und damit das durchschnittliche Bedauern auf 0 wie gewünscht. Online-Subgradient-Abstieg (OSD) Das vorstehende bewies ein Bedauern für lineare Verlustfunktionen v t (w ) = ⟨ w , z t ・ {\displaystyle v_{t}(w)=\langle w,z_{t}\rangle } . Zur Verallgemeinerung des Algorithmus auf jede konvexe Verlustfunktion wird der Subgradient ∂ v t (w t) {\displaystyle v_{t} als lineare Approximation zu v t {\displaystyle v_{t} in der Nähe von w t {\displaystyle w_{t} verwendet, was zum Online-Subgradient des Initialisierungsparameter η , w 1 = 0 {\displaystyle \eta ,w_{1}=0 Für t = 1 , 2 , . . ., T {\displaystyle t=1,2,...,T} Voraussagen mit w t {\displaystyle w_{t}, erhalten f t {\displaystyle f_{t} aus der Natur. Wählen Sie z t ε ∂ v t (w t ) {\displaystyle z_{t}\in \partial v_{t}(w_{t) Wenn S = R d {\displaystyle S=\mathbb {R} {^d}, update w t + 1 = w t - η z t {\displaystyle ,...................................... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . z_{t} Wenn S ξ R d {\displaystyle S\subset \mathbb {R} {^d}, Projekt kumulative Gradienten auf S {\displaystyle S} d.h. w t + 1 = D S (η θ t + 1 ) , θ t + 1 = θ t + z t {\displaystyle ******* Pi {_S}(\eta \theta {_t+1},\theta {_t+1}=\theta )+z_{t Man kann den OSD-Algorithmus verwenden, um O (T ) {\displaystyle O({\sqrt {T}) Reue gebunden für die Online-Version von SVM's für die Klassifikation abzuleiten, die den Scharnierverlust v t (w ) = max { 0, 1 - y t (w ⋅ x t) } {\displaystyle v_{t}(w)=max\{\{\{\{\{\{\{\{\{\{\{\{\{\{\{\{\{\{\{\\\\\\\\\}}}}},1-y\c}) Andere Algorithmen Quadratisch normierte FTRL-Algorithmen führen wie oben beschrieben zu lazily projizierten Gradientenalgorithmen. Um die oben genannten für willkürliche konvexe Funktionen und Regularisatoren zu verwenden, verwendet man Online-Spiegelabstieg. Für lineare Verlustfunktionen kann die optimale Regelmäßigung im Hindsight abgeleitet werden, was zum AdaGrad-Algorithmus führt. Für die Euclidean-Regulierung kann man ein Bedauern an O (T ) {\displaystyle O({\sqrt {T}) zeigen, das für stark konvexe und exp-concave-Verlustfunktionen weiter zu einem O (log ≠ T ) {\displaystyle O(\log T}) verbessert werden kann. Kontinuierliches Lernen bedeutet ständig die Verbesserung des erlernten Modells durch die Verarbeitung kontinuierlicher Informationsströme. Ständige Lernfähigkeiten sind für Softwaresysteme und autonome Agenten, die in einer sich ständig verändernden realen Welt interagieren, unerlässlich. Das kontinuierliche Lernen ist jedoch eine Herausforderung für maschinelles Lernen und neuronale Netzwerkmodelle, da die kontinuierliche Erfassung von inkremental verfügbaren Informationen aus nichtstationären Datenverteilungen im Allgemeinen zu einem katastrophalen Vergessen führt. Interpretationen des Online-Lernens Das Paradigma des Online-Lernens hat je nach Wahl des Lernmodells unterschiedliche Interpretationen, die jeweils deutliche Auswirkungen auf die Prädiktivqualität der Funktionssequenz f 1 , f 2 , ..., f n {\displaystyle f_{1},f_{2},\ldots ,f_{n} haben. Der prototypische stochastische Gradientenabstiegsalgorithmus wird für diese Diskussion verwendet. Wie oben erwähnt, wird seine Rekursion durch w t = w t - 1 - γ t ) - Nein. ,x_{t}\rangle,y_{t} Die erste Interpretation betrachtet die stochastische Gradientenabstiegsmethode, die auf das oben definierte Problem der Minimierung des erwarteten Risikos I [w] {\displaystyle I[w]} angewendet wird. In der Tat, bei einem unendlichen Datenstrom, da die Beispiele (x 1 , y 1 ) , (x 2 , y 2 ) , ... I[w]} .Diese Interpretation ist auch bei einem endlichen Trainingssatz gültig; obwohl bei mehreren Durchgängen die Daten die Gradienten nicht mehr unabhängig sind, können in Sonderfällen noch Komplexitätsresultate erzielt werden. Die zweite Interpretation gilt für den Fall eines endlichen Trainingssatzes und betrachtet den SGD-Algorithmus als Inkrementalgradientenabstiegsmethode. In diesem Fall betrachtet man stattdessen das empirische Risiko: I n [w ] = 1 n Σ i = 1 n V ( ⟨ w, x i ・ , y i ) . {\displaystyle I_{n}[w]={\frac 1}{n}}\sum _i=1}^{n}V(\langle w,x_{i}\rangle,y_{i\} Da die Gradienten von V ( ⋅, ⋅ ) {\displaystyle V(\cdot ,\cdot )} in den Inkrementalgradientenabwärtsfahrten auch stochastische Schätzungen des Gradienten von I n [w ] {\displaystyle I_{n}[w] sind, ist diese Interpretation auch mit dem stochastischen Gradientenabstiegsverfahren verbunden, aber zur Minimierung des empirischen Risikos angewendet. Da diese Interpretation das empirische Risiko betrifft und nicht das erwartete Risiko, werden mehrere Übergänge durch die Daten leicht erlaubt und führen tatsächlich zu engeren Grenzen der Abweichungen I n [w t] - I n [ w n ♦ ] {\displaystyle I_{n}[w_{t}]-I_{n}[w_{n}^{\ast }]}, wobei w n χ{\displaystyle w_{n}^{\ast } der Minimierer von I n [w]\displaystyle I_{n}[w] ist. Open-Source-schnelles Out-of-Core-Online-Lernsystem, das für die Unterstützung einer Reihe von maschinellen Lernreduktionen, Gewichtung und eine Auswahl verschiedener Verlustfunktionen und Optimierungsalgorithmen bemerkenswert ist. Es verwendet den Hashing-Trick, um die Größe des Satzes von Funktionen unabhängig von der Menge der Trainingsdaten zu begrenzen. scikit-learn: Bietet Out-of-Core Implementierungen von Algorithmen für die Klassifizierung: Perceptron, SGD-Klassifikator, Naive Bayes Klassifikator. Regression: SGD Regressor, Passive Aggressive Regressor. Clustering: Minibatch k-Means. Merkmalsextraktion: Mini-batch Wörterbuch Lernen, Incremental PCA. Siehe auch Lernparadigmen Inkrementelles Lernen Lazy learning Offline learning, das entgegengesetzte Modell Verstärkung Lernen Supervised learningAllgemeine Algorithmen Online-AlgorithmusOnline-Optimierung Streaming-Algorithmus Stochastic Gradienten descentLearning-Modelle Adaptive Resonance Theory Hierarchical temporal Memory k-nearest nextalgorithm Lernvektorisierung Perceptron Referenzen Externe Links http://onlineprediction.net, Wiki for On-Line Prediction. 6.883: Online Methoden im maschinellen Lernen: Theorie und Anwendungen. Alexander Rakhlin.MITSuffering Risiken, genannt Kurzrisiken, sind zukünftige Ereignisse mit der Möglichkeit, eine astronomische Menge an Leiden zu erzeugen. Diese Ereignisse können mehr Leiden erzeugen, als jemals auf der Erde existiert hat, in der Gesamtheit ihrer Existenz. Quellen möglicher S-Risikosen umfassen verkörperte künstliche Intelligenz und Superintelligenz sowie Raumkolonisation, die möglicherweise zu "konstanten und katastrophalen Kriegen" führen könnte, und eine immense Zunahme der wilden Tiere, die durch die Einführung wilder Tiere leiden, die "in der Regel kurze, mißbräuchliche Leben voller manchmal brutalster Leiden" zu anderen Planeten führen, entweder absichtlich oder versehentlich. Referenzen Weiter lesen Metzinger, Thomas (2021-02-19)." Künstliches Leiden: Ein Argument für ein globales Moratorium für synthetische Phänomene". Journal of Artificial Intelligence and Consciousness.08: 43–66.doi:10.1142/S270507852150003X ISSN 2705-0785.Minardi, Di (2020-10-15)."Das grausame Schicksal, das 'raus als Aussterben' sein könnte." BBC Future. Retrieved 2021-02-11.Baumann, Tobias (2017). " S-Risiken: Eine Einführung". Zentrum zur Reduzierung des Leidens. Retrieved 2021-02-10. Althaus, David; Gloor, Lukas (2016-09-14)."Reducing Risks of Astronomical Suffering: A Neglected Priority". Center on Long-Term Risk. Retrieved 2021-02-10. Siehe auch KI-Kontrollproblem Ethik der künstlichen Intelligenz Ethik der terraforming Vorhandenes Risiko durch künstliche allgemeine Intelligenz Globales katastrophales Risiko Suffering-fokussierte Ethik Wildes Tier leiden