Affective Rechen ist die Studie und Entwicklung von Systemen und Geräten, die erkennen, interpretieren, verarbeiten und menschliche Auswirkungen simuliert. Es ist ein interdisziplinärer Bereich, der Computerwissenschaften, Psychologie und kognitive Wissenschaft umfasst. Obwohl einige Kernideen auf dem Gebiet weit zurückverfolgt werden können, um zu früh philosophischen Ermittlungen über die Emotionen zu gelangen, der modernere Bereich der Computerwissenschaft stammt aus dem Papier von Rosalind Picard aus dem Jahr 1995 über produktive Rechen- und Buchführungskompetenz, das von MIT Presse veröffentlicht wurde. Einer der Gründe für die Forschung ist die Fähigkeit, Maschinen emotionale Intelligenz zu geben, einschließlich der simulierten Emopathie. Die Maschine sollte den emotionalen Zustand des Menschen interpretieren und ihr Verhalten an sie anpassen, indem sie eine angemessene Antwort auf diese Emotionen geben. Bereiche, die emotionale Informationen erkennen und erkennen, beginnen in der Regel mit passiven Sensoren, die Daten über den physischen Zustand oder Verhalten des Nutzers erfassen, ohne den Input auszulegen. Die gesammelten Daten entsprechen der Verwendung von Emotionen in anderen Menschen. Beispielsweise kann eine Videokamera Gesichtsausdrücke, Körperposten und Gesten erfassen, während ein Mikrofon die Rede erfassen könnte. Andere Sensoren erkennen emotionale cues durch direkte Messung physiologischer Daten, wie Hauttemperatur und Galvanische Resistenz. Erkenntnis emotionaler Informationen erfordert die Gewinnung sinnvoller Muster aus den gesammelten Daten. Dies geschieht mit maschinellen Lernmethoden, die unterschiedliche Modalitäten wie Spracherkennung, natürliche Sprachverarbeitung oder Gesichtserkennung verarbeiten. Ziel der meisten dieser Techniken ist es, Etiketten zu produzieren, die den Etiketten entsprechen würden, würde ein Menscher, der in derselben Lage wäre: Kann eine Person zum Beispiel einen Gesichtsdruck, der ihr browing, dann könnte das Computer-Vision-System gelehrt werden, um ihr Gesicht als verwechselt oder als "schwer negative" zu kennzeichnen (im Gegensatz zu positiven, die es vielleicht sagen könnte, wenn sie glücklicherweise waren). Diese Etiketten können oder können nicht dem entsprechen, was die Person tatsächlich fühlt. Emotionen in Maschinen ein anderes Gebiet, in dem es sich um die Entwicklung von Rechengeräten handelt, die vorgeschlagen werden, entweder unzuverlässige emotionale Fähigkeiten zu zeigen oder überzeugende Emotionen zu simulierten. Ein praktischer Ansatz, der auf aktuellen technologischen Fähigkeiten basiert, ist die Simulation von Emotionen in Gesprächspartnern, um die Interaktivität zwischen Mensch und Maschine zu bereichern und zu erleichtern. Marvin Minsky, einer der Pionier-Computer-Wissenschaftler in der künstlichen Intelligenz, bezieht sich auf Emotionen zu den breiteren Themen der maschinellen Intelligenz, die in der emotionalen Entwicklung "nicht besonders anders aus den Prozessen, die wir uns Gedanken machen". Technologien In den Bereichen Psychologie, kognitive Wissenschaft und Neurowissenschaften gibt es zwei wesentliche Ansätze, um zu beschreiben, wie Menschen die Wahrnehmung und Kategorisierung von Emotionen verstehen: kontinuierliche oder Kategorisierung. Der kontinuierliche Ansatz dient der Nutzung von Dimensionen wie negativem vs. positivem, ruhigem oder geräuchertem Ausmaß. Der kategorische Ansatz ist tendenziell geeignet, eigene Klassen wie glücklich, traurig, befürchtet, Überraschung, Ungewissheit zu verwenden. unterschiedliche Arten von Maschinenlernregression und Klassifikationsmodelle können verwendet werden, wenn Maschinen ständig oder diskrete Etiketten produzieren. Manchmal werden auch Modelle gebaut, die Kombinationen in den Kategorien ermöglichen, z.B. ein glückliches Gesicht oder ein befürchtetes Gesicht. In den folgenden Abschnitten werden viele der Arten von Inputdaten für die Aufgabe der Anerkennung von Emotionen berücksichtigt. emotionale Reden Verschiedene Veränderungen im autonomen Nervensystem können die Rede einer Person mittelbar verändern, und die beeinflussenden Technologien können diese Informationen nutzen, um die Emotionen zu erkennen. Beispielsweise wird die Rede, die in einem Zustand der Angst, einer Fälschung oder Freude produziert wird, schnell, laut und genau enunciiert, mit einem höheren und breiteren Rand, während Emotionen wie Müdigkeit, Langem oder Trauer tendenziell langsam, niedrig geführt und stagniert werden. Manche Emotionen wurden gefunden, um leichter rechnerisch identifiziert zu werden, wie z.B. eine Fälschung oder Genehmigung. emotionale Sprachverarbeitungstechnologien erkennen den emotionalen Zustand des Nutzers an, indem sie die rechnerische Analyse der Redemerkmale verwenden. Mye Parameter und prosodikative Merkmale wie Spielvariablen und Redequote können durch Mustererkennungstechniken analysiert werden. Sprachanalyse ist eine wirksame Methode zur Ermittlung des beeinträchtigten Zustands mit einer durchschnittlichen gemeldeten Genauigkeit von 70 bis 80 % in der jüngsten Forschung. In diesen Systemen ist die durchschnittliche menschliche Genauigkeit (rund 60) %, aber weniger genau als Systeme, die andere Modalitäten für die Erkennung von Emotionen, wie z.B. physiologische Staaten oder Gesichtsausdrücke, beschäftigen. Da viele Spracheigenschaften von semantischen oder kulturellen Merkmalen unabhängig sind, gilt diese Technik als eine vielversprechende Route für die weitere Forschung. AlgorithmsDer Prozess der Rede/Text-Beeinflussung erfordert die Schaffung einer zuverlässigen Datenbank, einer Wissensbasis oder eines Vektor-Raummodells, das weit genug reicht, um jeden Bedarf an Anwendung zu decken, sowie die Auswahl eines erfolgreichen Klassenprüfers, der eine schnelle und genaue Erkennung der Emotionen ermöglicht. Derzeit sind die am häufigsten verwendeten Klassenaggregatoren linear diskriminierende Klassenstellen (LDC), k-norest benachbarte (k-NN), Gaussian-Gemischmodell (GMM), unterstützen Vektormaschinen (SVM), künstliche Neuralnetze (ANN), Entscheidungsbaumgorithmen und versteckte Markov-Modelle (HMMs). Verschiedene Studien zeigten, dass die Auswahl der geeigneten Klassenstelle die Gesamtleistung des Systems erheblich verbessern kann. Die nachstehende Liste enthält eine kurze Beschreibung jedes Algorithmus: LDC – Klassifikation basiert auf dem Wert, der aus der linearen Kombination der Merkmalswerte gewonnen wurde, die in der Regel in Form von Vektorfunktionen bereitgestellt werden. k-NN – Einstufung geschieht durch die Zusammenstellung des Gegenstands in der Positionsfläche und den Vergleich mit den k nächstgelegenen Nachbarn (Fortbildungsbeispiele). Die Mehrheit beschließt über die Einstufung. GMM – ist ein probabilistisches Modell, das zur Darstellung der Existenz von Untervölkern in der Gesamtbevölkerung verwendet wird. Jede Unterbevölkerung wird mit der Mischungsverteilung beschrieben, die die Einstufung von Beobachtungen in die Unterbevölkerung ermöglicht. SVM – ist ein Typ von (normalerweise binären) linearen Klassensteigern, die entscheiden, in welchen der beiden (oder mehr) möglichen Klassen jeder Input fallen kann. ANN – ist ein mathematisches Modell, das von biologischen Neuralnetzen inspiriert wird, das mögliche Nichtlinearitäten des Merkmalsraums besser nutzen kann. Entscheidung Baumgorithmen – auf der Grundlage eines Entscheidungsbaums, in dem die Klassifikationsergebnisse verbleibt, und Zweige stellen die Verbindung der nachfolgenden Merkmale dar, die zur Einstufung führen. HMMs – ein statistisches Markov-Modell, in dem die Staaten und die staatlichen Übergänge nicht direkt zur Beobachtung zur Verfügung stehen. Stattdessen sind die Outputs, die von den Staaten abhängig sind, sichtbar. Im Falle der Auswirkungen auf die Anerkennung stellen die Outputs die Sequenz der Redeeigenschaftenvektoren dar, die eine Abführung der Sequenzen der Staaten ermöglichen, durch die das Modell vorangebracht wurde. Die Staaten können aus verschiedenen Zwischenschritten im Sinne einer Emotionen bestehen, und jeder von ihnen hat eine Wahrscheinlichkeitsverteilung über die möglichen Outputvektoren. Die Sequenzen der Staaten erlauben uns, den beeinträchtigen Zustand vorherzusagen, den wir versuchen, einzustufen, und dies ist eines der am häufigsten verwendeten Techniken im Bereich der Spracherkennung. Es ist erwiesen, dass mit ausreichend akustischen Beweismitteln der emotionale Zustand einer Person durch eine Reihe von Mehrheits-Parteien klassifiziert werden kann. Die vorgeschlagenen Klassenzeichen basieren auf drei Hauptklassen: kNN, C4.5 und SVM-RBF-Chip. Dieser Satz erreicht eine bessere Leistung als jeder einzelne Grundklasseempfänger. Vergleicht es mit zwei anderen Klassenaggregaten: ein-against-all (OAA) multiclass SVM mit Hybridkernen und das Set von Klassenaggregaten, die aus den folgenden zwei Grundklassen bestehen: C5.0 und Neural Network. Die vorgeschlagene Variante erreicht eine bessere Leistung als die beiden anderen Klassenzeichen. Datenbanken Die große Mehrheit der vorhandenen Systeme ist datenunabhängig. Dies stellt eine der größten Herausforderungen bei der Erkennung von Emotionen auf der Basis von Reden dar, da sie die Wahl einer geeigneten Datenbank erschwert, die für die Schulung des Prüfers verwendet wird. Die meisten der derzeit vorhandenen Daten wurden von den Akteuren gesammelt und sind somit eine Darstellung der archetypischen Emotionen. Diese sogenannten, gehandelten Datenbanken basieren in der Regel auf der Grundtheorie (von Paul Ekman), die die Existenz von sechs Grundgedanken (Risiko, Angst, Ungemut, Überraschung, Freude, Trauer) übernimmt, die anderen einfach als eine Mischung aus den ehemaligen. Jedoch bieten diese immer noch eine hohe Audioqualität und ausgewogene Klassen (obwohl oft zu wenige), die zu hohen Erfolgen bei der Erkennung von Emotionen beitragen. Naturistische Daten werden jedoch für die tatsächliche Anwendung bevorzugt. Eine natürliche Datenbank kann durch Beobachtung und Analyse von Themen in ihrem natürlichen Kontext erstellt werden. Letztlich sollte eine solche Datenbank das System ermöglichen, Emotionen zu erkennen, die auf ihrem Kontext basieren, und die Ziele und Ergebnisse der Interaktion zu verfolgen. Diese Art von Daten ermöglicht eine echte lebensrettende Umsetzung, da sie Staaten beschreibt, die während der Interaktion zwischen Mensch und Computer (HCI) natürlich vorkommen. Trotz der zahlreichen Vorteile, die natürliche Daten über gehandelt haben, ist es schwierig, Daten zu erhalten und in der Regel eine geringe emotionale Intensität zu haben. Daten, die in einem natürlichen Kontext gesammelt wurden, haben aufgrund von Umgebungslärm und Entfernung der Fächer des Mikrofons niedrigere Signalqualität. Erster Versuch, eine solche Datenbank zu erstellen, war das FAU Aibo emotional Corpus für CEICES (Combining-Anstrengungen für die Verbesserung der automatischen Klassifikation der emotionalen Nutzerstaaten), das auf einem realistischen Kontext von Kindern (Alte 10–13) entwickelt wurde, der mit Sony's Aibo Roboter Haustier spielt. Ebenso würde die Erstellung einer Standarddatenbank für alle emotionalen Forschungsarbeiten eine Methode zur Bewertung und Vergleich verschiedener relevanter Anerkennungssysteme darstellen. Rede deskriptoren Die Komplexität des Folgenabschätzungsverfahrens erhöht sich mit der Anzahl der Klassen (Kämpfe) und Sprachdeskriptoren, die innerhalb des Klassenprüfers verwendet werden. Es ist daher von entscheidender Bedeutung, nur die wichtigsten Merkmale auszuwählen, um die Fähigkeit des Modells zu gewährleisten, die Emotionen erfolgreich zu erkennen und die Leistung zu steigern, die besonders wichtig für die Echtzeit-Erkennung ist. Es gibt ein breites Spektrum möglicher Entscheidungen, mit einigen Studien über die Nutzung von mehr als 200 verschiedenen Merkmalen. Es ist von entscheidender Bedeutung, diejenigen zu identifizieren, die überflüssig und unerwünscht sind, um das System zu optimieren und die Erfolgsquote der korrekten Erkennung von Emotionen zu erhöhen. Die häufigsten Sprachmerkmale werden in folgende Gruppen zusammengefasst. HäufigkeitsmerkmaleAccent Form – betroffen durch die Veränderung der Grundfrequenz. Durchschnittswert – Beschreibung, wie hoch/niedrig der Sprecher im Verhältnis zur normalen Rede steht. Konjunkturabschwächung – beschreibt die Tendenz des Frequenzwechsels im Laufe der Zeit, kann es steigen, sinken oder stufenweise. Endabschwächung – der Betrag, den die Häufigkeit am Ende der Beatmung fällt. Lochbereich – Maßnahmen, die zwischen der maximalen und minimalen Häufigkeit der Beatmung reichen. Zeitbezogene Merkmale: Redesatz – beschreibt den Satz von Wörtern oder sysllables, der über ein Maß an Zeitdruckfrequenzen hinausgeht – Maßnahmen zur Häufigkeit von Ereignissen mit verstärkten Sprachqualitätsparametern und Energiedeskriptoren: Atemweg – Maßnahmen des Geräuschpegels in der Rede von Briiance – beschreiben die beherrschende Stellung von hohen oder niedrigen Frequenzen In der Rede Loudness – die Amplitude der Redewellenform, übersetzt die Energie einer Leerruhe – beschreibt den Übergang zwischen Geräusch- und Schweigensstörungen – und beschreibt den Übergang der Grundfrequenz. Schadenserkennung Durch verschiedene Methoden wie optischer Strom, versteckte Markov-Modelle, Neuralnetzverarbeitung oder aktives Aussehen werden die Erkennung und Verarbeitung von Gesichtstexten erreicht. Mehr als eine Modalitäten können kombiniert oder genutzt werden (multimodale Anerkennung, z.B. Gesichtstexte und Redeprosody, Gesichtstexte und Hand Gesten oder Gesichtsausdrücke mit Rede und Text für multimodale Daten und Metadatenanalyse), um eine robustere Schätzung des emotionalen Zustands des Gegenstands zu ermöglichen. Affectiva ist ein Unternehmen (von Rosalind Picard und Rana El Kaliouby) direkt im Zusammenhang mit der beeinträchtigten Rechentechnik und zielt darauf ab, Lösungen und Software zur Erkennung von Gesichtsschäden zu untersuchen. Facial Expression Datenbanken Einrichtung einer emotionalen Datenbank ist eine schwierige und zeitaufwendige Aufgabe. Datenbankaufbau ist jedoch ein wichtiger Schritt bei der Schaffung eines Systems, das menschliche Emotionen anerkennt. Die meisten der öffentlich zugänglichen emotionalen Datenbanken umfassen ausschließliche Gesichtsausdrücke. Die Teilnehmer werden gebeten, verschiedene grundlegende emotionale Ausdrucksformen zu zeigen, während in der spontanen Ausdrucksdatenbank natürliche Ausdrucksformen sind. Spontane emotionale Erledigung erfordert erhebliche Anstrengungen bei der Auswahl von geeigneten Stimulen, die zu einer reichhaltigen Darstellung der gewünschten Emotionen führen können. Zweitens bedeutet der Prozess, dass die Emotionen von ausgebildeten Individuen manuell getragen werden, was die Datenbanken sehr zuverlässig macht. Da die Wahrnehmung von Ausdrucken und ihre Intensität subjektiv ist, ist die Anmeldung durch Experten für die Zwecke der Validierung unerlässlich. Forscher arbeiten mit drei Arten von Datenbanken, wie z.B. einer Datenbank von Spitzentextbildern, einer Datenbank von Bildsequenzen, die eine Emotionen von neutral bis zu ihrem Spitzenwert darstellen, und Videoclips mit emotionalen Annotationen. Viele Gesichtsbilddatenbanken wurden geschaffen und für die Zwecke der Ausdruckserkennung veröffentlicht. Zwei der häufig verwendeten Datenbanken sind CK+ und JAFFE. emotionale Einstufung Paul Ekman schlug vor, Ende der 60er Jahre eine multikulturelle Forschung in Papua-Neuguinea, an den Fore1-Pansmen, durchzuführen. So schlug er vor, dass sie biologische Herkunft sind und daher sicher und korrekt kategorisiert werden können. Er legte daher im Jahr 1972 sechs grundlegende Emotionen vor: Anger Disgust Glück Sadness Überraschung, wie immer, hat in den 90er Jahren Ekman seine Liste der Grundgedanke erweitert, darunter eine Reihe positiver und negativer Emotionen, die nicht alle in Gesichtsmuskeln verdächtigt sind. Die neu aufgenommenen Emotionen sind: Freizeitpark Contnot Contentment Embarrassment Excitement Guilt Pride zur Erzielung von Satisfaction Sensory Scheine Facial Action Coding System Ein System wurde von Psychologen entwickelt, um den physischen Ausdruck von Emotionen auf Gesicht formell zu kategorisieren. Das zentrale Konzept des Facial Action Coding Systems oder des FACS, das 1978 von Paul Ekman und Wallace V. Bohen auf der Grundlage früherer Arbeiten von Carl-Herman Hjsjö geschaffen wurde, sind Aktionseinheiten (AU). Im Wesentlichen handelt es sich um einen Vertrag oder eine Lockerung eines oder mehrerer Muskeln. Psychologen haben nach ihren Aktionseinheiten (+) die folgende Einstufung von sechs Grundnahrungsmitteln vorgeschlagen: Herausforderungen bei der Gesichtserkennung Wie bei jeder Rechenpraxis, die die Erkennung durch Gesichtsverarbeitung beeinträchtigt, müssen einige Hindernisse überschritten werden, um das versteckte Potenzial des Gesamtgorithmus oder der angewandten Methode voll auszuschöpfen. In den frühen Tagen fast jede Art von AI-basierten Nachweis (Ausbildung, Gesichtserkennung, Auswirkungen auf die Anerkennung), ist die Genauigkeit von Modellierung und Tracking ein Thema. Hardware entwickelt sich, da mehr Daten gesammelt werden und neue Entdeckungen erstellt werden und neue Praktiken eingeführt werden, dies Fehlen von Genauigkeitserträgen, die hinter Lärmproblemen liegen. Methoden zur Lärmbeseitigung gibt es jedoch auch die Umgebungsdurchdringung, lineare Gausssian glatting, mediane Filterung oder neuere Methoden wie das Bacterial Foraging Algorithm. Andere Herausforderungen Die Tatsache, dass die von den meisten Fächern der verschiedenen Studien verwendeten Ausdrucksformen nicht natürlichen Charakter haben und daher Algorithmen, die auf diese Weise ausgebildet werden, nicht für natürliche Ausdrucke gelten. Mangel an Rotationsfreiheit. Affect-Erkennung funktioniert sehr gut mit Frontalnutzung, aber nach dem Wechsel des Kopfes mehr als 20 Grad „Es gab Probleme“. Straftaten entsprechen nicht immer einer zugrunde liegenden Emotionen, die ihnen entspricht (z.B. können sie hergestellt oder gefälscht werden, oder eine Person kann Gefühl haben, aber ein "Blitz" erhalten). FACS umfasste keine Dynamik, während die Dynamik dazu beitragen kann, unambiguate zu helfen (z.B. das Gefühl eines echten Glücks ist tendenziell unterschiedlicher Dynamik zu haben als "Nachahmungen".) Die FACS-Kombinationen entsprechen nicht 1:1 den Emotionen, die die ursprünglich vorgeschlagenen Psychologen hatten (siehe auch, dass dieses Fehlen einer 1:1-Karte auch in der Spracherkennung mit Homophonen und Homonymen und vielen anderen Quellen von Ambiguity geschieht und durch die Bereitstellung anderer Informationskanäle abgeschwächt werden kann). Angemessenheit der Anerkennung wird dadurch verbessert, dass Kontext hinzugefügt wird und andere Modalitäten die Rechenkosten und die Komplexität erhöhen. Körper Gestenkleber könnten effizient als Mittel genutzt werden, um einen besonderen emotionalen Zustand des Benutzers zu erkennen, insbesondere wenn sie in Verbindung mit Rede und Gesichtserkennung verwendet werden. Je nach konkreten Maßnahmen könnten Gesten einfache Reflexreaktionen sein, wie die Aufhebung Ihrer Schultern, wenn Sie nicht die Antwort auf eine Frage kennen, oder sie könnten komplex und sinnvoll sein, wenn man mit der Anmeldesprache kommunizieren kann. Ohne die Verwendung eines Gegenstands oder Umgebungs können wir unsere Hände, das Schwervermögen oder das Entenon ausdrücken. Hingegen können wir bei der Verwendung von Gegenständen auf sie hinweisen, sie bewegen, berühren oder behandeln. Ein Computer sollte in der Lage sein, diese zu erkennen, den Kontext zu analysieren und in sinnvoller Weise zu reagieren, um effizient für die Interaktion zwischen Mensch und Computer eingesetzt werden zu können. Es gibt viele vorgeschlagene Methoden zur Erkennung der Geste. Manche Literatur unterscheidet zwei unterschiedliche Ansätze in der Anerkennung: ein 3D-Modell, das auf einem Erscheinungsbild basiert. In erster Linie werden 3D-Informationen von Schlüsselelementen der Körperteile verwendet, um mehrere wichtige Parameter wie die Palmposition oder gemeinsame Winkel zu erhalten. Erscheinungsbildbasierte Systeme verwenden Bilder oder Videos zur direkten Auslegung. Hand Gesten waren ein gemeinsamer Schwerpunkt der Körperspenden. Physiologische Überwachung Dies könnte genutzt werden, um einen beeinflussenden Zustand der Nutzer durch Überwachung und Analyse ihrer physiologischen Zeichen zu erkennen. Diese Zeichen reichen von Veränderungen der Herzrate und der Hautausübung bis zu Minuteverträgen der Gesichtsmuskeln und Veränderungen des Gesichtsblutflusses. Dieser Bereich gewinnt an Dynamik und wir sehen nun echte Produkte, die die Techniken umsetzen. Die vier wichtigsten physiologischen Zeichen, die in der Regel analysiert werden, sind blutiges Puls, galvanische Hautreaktion, Gesichtselektromyographie und Gesichtsfarben. Blutvolumen Puls Übersicht A Thema Blutmenge Puls (BVP) kann anhand eines Prozesses gemessen werden, der Photoplethysmographie enthält, das ein Bild mit Blutfluss durch die Extremitäten erstellt. Die Spitzenwerte der Wellen zeigen einen Herzzyklus, in dem das Herz Blut an die Extremitäten pumpt. Wenn das Thema Angst hat oder begonnen wird, wächst das Herz in der Regel schnell und holt schnell auf, was zu einer Zunahme des Herzkreislaufs führt. Man kann auf einem Photoplethysmograph deutlich gesehen werden, wenn die Entfernung zwischen dem Tal und dem Spitzenwert der Welle zurückgegangen ist. Da das Thema beruhigend ist, und da der innere Kern des Körpers erweitert, sodass mehr Blut in die Extremitäten fließen kann, wird der Zyklus wieder normalisiert. Methode Infra-red-Licht ist auf der Haut durch spezielle Sensor-Hardware geschrumpft, und die Lichtmenge wird gemessen. Die Menge der reflektierten und übermittelten Licht korreliert der BVP als Licht, wird von Hemoglobin aufgenommen, der im Blutstrom reich ist.Nachteile Man kann schwerfällig sein, um sicherzustellen, dass der Sensor ein undurchsichtiges Licht auszeichnet und das reflektierte Licht immer auf derselben Extremität verweist, vor allem als Themen, die häufig ihre Position unter Verwendung eines Computers strecken und lesen. Es gibt andere Faktoren, die die Blutmenge beeinflussen können. Da es sich um eine Maßnahme des Blutflusses durch die Extremitäten handelt, wenn das Thema heiße oder besonders kalt hält, kann ihr Körper mehr oder weniger Blut in die Extremitäten einbringen, unabhängig vom emotionalen Zustand des Gegenstands. Facial Electromyographie Facial Electromyographie ist eine Technik, die zur Messung der elektrischen Aktivität der Gesichtsmuskeln eingesetzt wird, indem sie die winzigen elektrischen Impulse, die durch Muskelfasern entstehen, verstärkt. Das Gesicht zeigt ein großes Gefühlsproblem, aber es gibt zwei große Gesichtsmuskelgruppen, die in der Regel zur Erkennung von Emotionen untersucht werden: Der Korrugator Supercilii Muskel, der auch als Frustrationsmuskel bekannt ist, zieht den Aufschwung in ein Froschenkel und ist daher der beste Test für negative, unangenehme emotionale Reaktionen.↵ Der zygomaticus große Muskel ist dafür verantwortlich, die Ecken des Mundes wieder zu ziehen, wenn Sie ein Lächeln haben, und ist daher der Muskel, der für eine positive emotionale Reaktion eingesetzt wird. Leichte HautreaktionGalvanic Hautreaktion (GSR) ist ein überholter Begriff für ein allgemeineres Phänomen, das als „Elektrodermal Aktivität“ oder EDA bekannt ist. EDA ist ein allgemeines Phänomen, bei dem sich die elektrischen Eigenschaften der Haut ändern. Die Haut ist durch das [sympathtische Nervensystem] umgeben, so dass die Messung ihrer Widerstands- oder Verhaltenskraft einen Weg zur Quantifizierung kleiner Veränderungen in der Sympathie des autonomen Nervensystems darstellt. Da die Schweißdrüsen aktiviert werden, auch vor dem Schwitzen der Haut, kann das Niveau der EDA (normalerweise mit der Durchführung) erfasst und verwendet werden, um kleine Veränderungen in autonomem Aal zu erkennen. Je größer die Haut ist. Hautausübung wird oft anhand zweier kleiner Silberchloridelektroden gemessen, die irgendwo auf der Haut platziert und eine kleine Spannung zwischen ihnen angewendet werden. Um den Komfort zu maximieren und die Reizung zu verringern, können die Elektroden auf dem Handgelenk, Beinen oder Füßen platziert werden, die die Hände für tägliche Aktivitäten vollständig frei lassen. Farbübersicht Die Oberfläche des menschlichen Gesichts ist mit einem großen Netz von Blutgefäßen überzogen. Blutflussschwankungen in diesen Schiffen führen sichtbare Farbänderungen auf dem Gesicht. Ob oder nicht Gesichtsschmerzen Gesichtsmuskeln aktivieren Gesichtsmuskeln, Variationen im Blutfluss, Blutdruck, Glukosepegel und andere Veränderungen. Des Weiteren ist das Gesichtsfarbesignal unabhängig von der von Gesichtsmuskelbewegungen bereitgestellten. Methodik Konzepte basieren auf Veränderungen der Gesichtsfarbe. Delaunay Triangulation wird zur Schaffung der dreieckigen lokalen Gebiete genutzt. Manche dieser Dreiecke, die das Innere des Mundes und der Augen (Sclera und iris) definieren, werden entfernt. Verwenden Sie die nachstehenden Triangularflächen, um Bildvektoren zu schaffen. Es zeigt, dass die Umwandlung der Pixelfarbe des Standard-Grampenraums in einen Farbraum, wie z.B. den Farbraum ORGB oder die LMS-Kanäle, bei der Behandlung von Gesichtern besser funktioniert. Auf diese Weise legen Sie den oben genannten Vektor auf den besseren Farbraum und entbinden Sie in rote und gelbe Kanäle. In diesem Fall verwenden Sie tiefe Lernmethoden, um gleichwertige Emotionen zu finden. visuelle Ästhetik, in der Welt der Kunst und Fotografie, bezieht sich auf die Grundsätze der Natur und der Wertschätzung der Schönheit. Schönheit und andere ästhetische Qualitäten sind eine sehr subjektive Aufgabe. Computer-Wissenschaftler in Penn State behandeln die Herausforderung, die ästhetische Qualität der Bilder, die ihre visuellen Inhalte als maschinelle Lernproblem verwenden, automatisch zu beeinträchtigen, mit einer Peer-ated on-line Photo Sharing Website als Datenquelle. Sie ziehen bestimmte visuelle Merkmale auf der Grundlage der Intuation, dass sie zwischen ästhetischen, erfreulichen und enttäuschenden Bildern diskriminieren können. Lernzustand der Lernenden beeinflusst mögliche Anwendungen Bildung. Computer können den Einfluss und den Lernzustand der Lernenden beurteilen, indem sie ihre Gesichtsausdrücke erkennen. In der Bildung kann der Lehrer die Analyseergebnisse nutzen, um das Lernen der Studierenden zu verstehen und die Fähigkeit zu akzeptieren, und dann geeignete Lehrpläne formulieren. Gleichzeitig können sie den inneren Gefühle der Studierenden, die für die psychische Gesundheit der Studierenden hilfreich sind, Aufmerksamkeit schenken. Insbesondere im Fernunterricht gibt es aufgrund der Trennung von Zeit und Raum keinen emotionalen Anreiz zwischen Lehrern und Studenten für eine zweiseitige Kommunikation. Ohne die Atmosphäre, die durch das traditionelle Klassenzimmerlernen ausgelöst wird, sind die Studierenden leicht zuweilen und beeinflussen den Lerneffekt. Durch die Anwendung des relevanten Rechensystems im Fernunterricht kann diese Situation effektiv verbessert werden. Gesundheits- und Sozialroboter sowie eine wachsende Zahl von Robotern, die in der Gesundheitsversorgung eingesetzt werden, profitieren von emotionalem Bewusstsein, da sie die emotionalen Verhältnisse von Patienten und Patienten besser beurteilen und ihre Maßnahmen/Programmierung entsprechend ändern können. Dies ist besonders wichtig in jenen Ländern mit wachsender alternden Bevölkerung und/oder einem Mangel an jüngeren Arbeitskräften, um ihren Bedürfnissen gerecht zu werden. Affective Rechentechnik wird auch auf die Entwicklung von übertragbaren Technologien zur Nutzung von Menschen mit Autismus angewendet. In zunehmendem Maße wird auch die Bedeutung eines Texts, insbesondere seine Rolle im sogenannten emotionalen oder emotivierenden Internet, stärker berücksichtigt. Video-Spiele Affektive Videospiele können durch Bio-Rückgangsgeräte den emotionalen Zustand ihrer Spieler nutzen. Eine besonders einfache Form von Bio-Rückmeldungen ist über Spielpads erhältlich, die den Druck messen, mit dem ein Knopf gedrückt wird: Dies wurde gezeigt, dass dies stark mit dem Niveau der Spieler korreliert; am anderen Ende der Skala sind Gehirn-Computer-Schnittstellen. Affektive Spiele wurden in der medizinischen Forschung verwendet, um die emotionale Entwicklung von autistischen Kindern zu unterstützen. Andere Anwendungen Andere mögliche Anwendungen sind im Bereich der sozialen Überwachung vorgesehen. Beispielsweise kann ein Fahrzeug die Emotionen aller Insassen überwachen und zusätzliche Sicherheitsmaßnahmen ergreifen, wie etwa die Warnung anderer Fahrzeuge, wenn er den Fahrer aufstößigt. Affective Rechentechnik hat potenzielle Anwendungen in der menschlichen – Computer-Interaktion, wie z.B. die beeinflussenden Spiegel, die es dem Nutzer ermöglichen, zu sehen, wie er oder sie führt; emotionale Überwachungsbeauftragte, die eine Warnung vor einer verdächtigten E-Mail senden, oder sogar Musikakteure, die auf einer Stimmung basieren. Eine Idee, die der rumänische Forscher Dr. Nicu Sebe in einem Interview vorgestellt hat, ist die Analyse des Gesichts einer Person, während sie ein bestimmtes Produkt verwenden (he genannte Eiscreme als Beispiel). Unternehmen könnten dann eine solche Analyse verwenden, um herauszufinden, ob ihr Produkt vom jeweiligen Markt empfangen wird oder nicht. Man könnte auch die Beeinträchtigung der staatlichen Anerkennung nutzen, um die Auswirkungen einer TV-Werbung durch eine Echtzeit-Videoaufzeichnung dieser Person und durch die anschließende Untersuchung ihres Gesichts Ausdrucks zu beurteilen. Einvernehmen der Ergebnisse, die auf einer großen Gruppe von Themen erzielt wurden, kann sagen, ob der kommerzielle (oder Film) die gewünschte Wirkung hat und welche Elemente, die den Zuschauer am meisten interessieren, sind. Cognitivist vs. Interaktionskonzepte im Bereich menschlicher – Computerinteraktionen, Rosalind Picard's cognitivist oder "Informationsmodell" wurde kritisiert und kontrastiert mit dem post-kognitivistischen oder interreligiösen pragmatistischen Ansatz von Kirsten Boehner und anderen, der die Emotionen als inhärent betrachtet. Picardie konzentriert sich auf Mensch-Computer-Interaktionen, und ihr Ziel ist es, "die Computer in der Lage zu erkennen, ausdrücklich und in einigen Fällen Emotionen zu haben". Im Gegensatz dazu soll der Interaktionsansatz dazu beitragen, "die Menschen zu verstehen und ihre eigenen Emotionen kennenzulernen" und die computervermittelte interpersonelle Kommunikation zu verbessern. Man bemüht sich nicht unbedingt, die Emotionen in ein objektives mathematisches Modell für die maschinelle Auslegung zu stellen, sondern den Menschen den Sinn ihrer emotionalen Ausdrucke in offenen, unklaren, subjektiven und heiklen Zusammenhängen zu vermitteln. Picardische Kritiker beschreiben ihr Konzept der Emotionen als "Ziel, intern, privat und mechanistisch". Sie sagen, sie mindern die Emotionen auf ein interaktives psychologisches Signal innerhalb des Körpers, das gemessen werden kann, und das ist ein Beitrag zur Kodierung, unter Berücksichtigung der Komplexität emotionaler Erfahrungen. Der Interaktionsansatz behauptet, dass die Emotionen zwar biophysikalische Aspekte hat, aber es ist "kulturell gefestigt, dynamisch und in gewissem Maße in Aktion und Interaktion aufgebaut". In einer anderen Weise betrachtet er "emotion als soziales und kulturelles Produkt, das durch unsere Interaktionen erfahren wird". Siehe auch Citations Allgemeine Quellen Hudlicka, Eva (2003). " zu fühlen oder nicht: Rolle der Auswirkungen auf Mensch-Computer-Interaktion." International Journal of Human-Computer Studies.59 (1–2): 1–32CiteSeerX 10.1.180.6429.doi:10.1016/s1071-5819(03)00047-8.Scherer Klaus R; Bänziger, Tanja; Roesch, Etienne B (2010). Ein Blueprint für Affective Computing: A Sourcebook und Handbuch. Oxford: Oxford University Press. Externe Links Affective Computing Research Group at the MIT Media Laboratory Computational Emotion Group at USC emotional Processing Unit – EPU Emotive Computing Group at the University of Boston 2011 International Conference on Affective Computing and Smart Brain Interaktion, Body and Alert: Psychophysiologische Nutzer-Wechselwirkungen 2010 Workshop (10–15, April 2010)IEEE Transaktionen auf Affective Computing (TAC) OpenSMILE: populärer hochmoderner Open-Source-Werkzeugkit für großmaßstäbliche Produktgewinnung zur Auswirkungen auf die Anerkennung und die rechneralen Paralinguistics