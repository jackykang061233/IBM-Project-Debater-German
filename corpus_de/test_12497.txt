Im maschinellen Lernen ist der Perceptron ein Algorithmus zum überwachten Lernen binärer Klassifikatoren. Ein binärer Klassifikator ist eine Funktion, die entscheiden kann, ob eine Eingabe, die durch einen Zahlenvektor repräsentiert wird, einer bestimmten Klasse gehört. Es ist eine Art linearer Klassifikator, d.h. ein Klassifikationsalgorithmus, der seine Vorhersagen basierend auf einer linearen Prädiktorfunktion ausführt, die eine Gewichtsmenge mit dem Merkmalsvektor kombiniert. Geschichte Der Perceptron-Algorithmus wurde 1958 im Cornell Aeronautical Laboratory von Frank Rosenblatt, gefördert durch das United States Office of Naval Research, erfunden. Der Perceptron sollte eine Maschine sein, anstatt ein Programm, und während seine erste Implementierung in der Software für den IBM 704 war, wurde er anschließend in benutzerdefinierte Hardware als "Mark 1 Perceptron" implementiert. Diese Maschine wurde für die Bilderkennung konzipiert: sie hatte eine Reihe von 400 Fotozellen, zufällig mit den Neuronen verbunden". Gewichte wurden in Potentiometern kodiert, und Gewichtsaktualisierungen während des Lernens wurden von Elektromotoren durchgeführt. In einer von der US-Marine organisierten Pressekonferenz von 1958 gab Rosenblatt Aussagen über den Perceptron, der eine erhitzte Kontroverse unter der fledgling AI-Gemeinschaft verursachte; basierend auf Rosenblatts Aussagen berichtete die New York Times den Perceptron als "der Embryo eines elektronischen Computers zu sein, der erwartet, dass [die Marine] in der Lage sein wird, zu gehen, zu sprechen, zu lesen, zu schreiben, sich selbst zu reproduzieren und sich bewusst sein. " Obwohl der Perceptron zunächst vielversprechend schien, wurde schnell bewiesen, dass Perceptrons nicht ausgebildet werden konnten, um viele Musterklassen zu erkennen. Dies führte dazu, dass das Gebiet der neuralen Netzwerkforschung viele Jahre lang stagniert, bevor erkannt wurde, dass ein zukunftsweisendes neuronales Netz mit zwei oder mehr Schichten (auch als Mehrschicht-Perceptron bezeichnet) eine höhere Verarbeitungsleistung als Perceptron mit einer Schicht (auch als Einschicht-Perceptron) hatte. Einzelschicht-Perceptrons sind nur in der Lage, linear trennbare Muster zu lernen. Für eine Klassifikationsaufgabe mit einer Schritt-Aktivierungsfunktion hat ein einziger Knoten eine einzige Zeile, die die Muster bildenden Datenpunkte teilt. Mehr Knoten können mehr Trennlinien erstellen, aber diese Zeilen müssen irgendwie zu komplexeren Klassifikationen kombiniert werden. Eine zweite Schicht von Perceptronen oder sogar linearen Knoten reicht aus, um viele sonst nicht trennbare Probleme zu lösen. 1969 zeigte ein berühmtes Buch mit dem Titel Perceptrons von Marvin Minsky und Seymour Papert, dass es für diese Netzwerkklassen unmöglich war, eine XOR-Funktion zu lernen. Es wird oft angenommen (unrichtig), dass sie auch verworfen, dass ein ähnliches Ergebnis für ein mehrschichtiges Perceptron-Netzwerk halten würde. Dies ist jedoch nicht wahr, da sowohl Minsky als auch Papert bereits wussten, dass mehrschichtige Perceptrons in der Lage waren, eine XOR-Funktion zu erzeugen. (Siehe die Seite auf Perceptrons (Buch) für weitere Informationen.) Dennoch verursachte der oft mitgeführte Minsky/Papert-Text einen signifikanten Rückgang des Interesses und der Finanzierung der neuralen Netzwerkforschung. Es dauerte zehn Jahre, bis die neurale Netzwerkforschung in den 1980er Jahren eine Rechirurgie erlebte. Dieser Text wurde 1987 als "Perceptrons - Expanded Edition" aufgedruckt, wo einige Fehler im Originaltext angezeigt und korrigiert werden. Der Kernel-Perceptron-Algorithmus wurde bereits 1964 von Aizerman et al. Margin gebundene Garantien wurden für den Perceptron-Algorithmus in der allgemeinen nicht-trennbaren Fall zuerst von Freund und Schapire (1998,) und vor kurzem von Mohri und Rostamizadeh (2013) gegeben, die frühere Ergebnisse erweitern und neue L1 Grenzen geben. Das Perceptron ist ein vereinfachtes Modell eines biologischen Neurons. Während die Komplexität biologischer Neuronmodelle oft benötigt wird, um das neuronale Verhalten vollständig zu verstehen, schlägt die Forschung vor, dass ein perceptronähnliches lineares Modell ein gewisses Verhalten in realen Neuronen erzeugen kann. Begriff Im modernen Sinne ist der Perceptron ein Algorithmus zum Erlernen eines binären Klassifikators namens einer Schwellwertfunktion: eine Funktion, die seinen Eingang x {\displaystyle \mathbf {x} (ein echtwertiger Vektor) auf einen Ausgangswert f ( x ) {\displaystyle f(\mathbf {x})} abbildet. (ein einzelner binärer Wert) f ( x ) = { 1 wenn w ⋅ x + b > 0 , 0andernfalls {\displaystyle f(\mathbf {x} =)begin{cases}1&{\text{if }\ \mathbf {w} \cdot \mathbf {x} +b>,\\\0&{\text{otherwise}\end{cases where w {\displaystyle \mathbf {w}} is avektor of real-valued weights, w ∙ x {\displaystyle \mathbf {w} \cdot \mathbf {x} } ist das Dot-Produkt style Die Vorspannung verschiebt die Entscheidungsgrenze vom Ursprung weg und hängt nicht von einem Eingangswert ab. Der Wert von f ( x ) {\displaystyle f(\mathbf {x} (0 oder 1) wird verwendet, um x {\displaystyle \mathbf {x} als eine positive oder negative Instanz bei einem binären Klassifikationsproblem zu klassifizieren. Wenn b negativ ist, muss die gewichtete Kombination von Eingängen einen positiven Wert erzeugen, der größer als   b | {\displaystyle b} ist, um das Klassifikator-Neuron über die 0-Schwelle zu drücken. Spatial ändert die Vorspannung die Position (wenn auch nicht die Orientierung) der Entscheidungsgrenze. Der Perceptron Lernalgorithmus schließt nicht ab, wenn der Lernsatz nicht linear trennbar ist. Wenn die Vektoren nicht linear trennbares Lernen sind, wird nie einen Punkt erreichen, wo alle Vektoren richtig klassifiziert werden. Das bekannteste Beispiel für die Unfähigkeit des Perceptron, Probleme mit linear nicht trennbaren Vektoren zu lösen, ist das Boolesche Exklusiv-oder Problem. Die Lösungsräume von Entscheidungsgrenzen für alle binären Funktionen und Lernverhalten werden in der Referenz untersucht. Im Rahmen von neuronalen Netzen ist ein Perceptron ein künstliches Neuron mit der Heaviside-Schrittfunktion als Aktivierungsfunktion. Der Perceptron-Algorithmus wird auch als einschichtiger Perceptron bezeichnet, um ihn von einem mehrschichtigen Perceptron zu unterscheiden, der ein Fehler für ein komplizierteres neuronales Netz ist. Als linearer Klassifikator ist der einschichtige Perceptron das einfachste zukunftsweisende neuronale Netz. Lernalgorithmus Im Folgenden ist ein Beispiel für einen Lernalgorithmus für einen einschichtigen Perceptron. Für mehrschichtige Perceptrons, wo eine versteckte Schicht besteht, müssen komplexere Algorithmen wie Backpropagation verwendet werden. Ist die Aktivierungsfunktion oder der zugrunde liegende Prozess, der vom Perceptron modelliert wird, nichtlinear, können alternative Lernalgorithmen wie die Delta-Regel verwendet werden, solange die Aktivierungsfunktion differenzierbar ist. Dennoch wird der in den folgenden Schritten beschriebene Lernalgorithmus häufig auch für mehrschichtige Perceptrons mit nichtlinearen Aktivierungsfunktionen funktionieren. Wenn mehrere Perceptrons in einem künstlichen neuronalen Netz kombiniert werden, arbeitet jede Ausgangsneuron unabhängig von allen anderen; so kann das Lernen jeder Ausgabe isoliert betrachtet werden. Begriffsbestimmungen Wir definieren zunächst einige Variablen: r ist die Lernrate des Perceptron. Die Lernrate liegt zwischen 0 und 1, größere Werte machen die Gewichtsänderungen flüchtiger. y = f (z ) {\displaystyle y=f(\mathbf {z} )} den Ausgang aus dem Perceptron für einen Eingangsvektor z {\displaystyle \mathbf {z} D = { ( x 1 , d 1 ) , ... , ( x s , d s } {\displaystyle D=\{(\mathbf {x} 1},d_{1}),\dots ,(\mathbf {x} s},d_{s)\ ist das Trainingsset von s {\displaystyle s}-Proben, wobei x j {\displaystyle \mathbf {x} {_j} die n {\displaystyle n} -dimensionale Eingabed j {\displaystyle d_{j} ist der gewünschte Ausgangswert des Perceptrons für diesen Eingang. Wir zeigen die Werte der Features wie folgt: x j, i {\displaystyle x_{j,i} ist der Wert des i {\displaystyle i} der Funktion des j {\displaystyle j} des Trainingseingangsvektors. x j , 0 = 1 {\displaystyle x_{j,0}=1 .Um die Gewichte zu repräsentieren: w i {\displaystyle w_{i} ist der i {\displaystyle i}-Wert im Gewichtsvektor, der mit dem Wert des i {\displaystyle i}-ten Eingangsmerkmals multipliziert wird. Da x j , 0 = 1 {\displaystyle x_{j,0}=1 ist, ist die w 0 {\displaystyle w_{0} effektiv eine Vorspannung, die wir anstelle der Vorspannkonstante b {\displaystyle b} verwenden. Um die Zeitabhängigkeit von w {\displaystyle \mathbf {w} anzuzeigen, verwenden wir: w i ( t ) {\displaystyle w_{i}(t) ist das Gewicht i {\displaystyle i} zum Zeitpunkt t {\displaystyle t} . Schritte Der Algorithmus aktualisiert die Gewichte nach den Schritten 2a und 2b. Diese Gewichte werden sofort auf ein Paar im Trainingsset aufgebracht und anschließend aktualisiert, anstatt zu warten, bis alle Paare im Trainingsset diese Schritte durchlaufen haben. Konvergenz Der Perceptron ist ein linearer Klassifikator, so wird er niemals mit allen korrekt klassifizierten Eingangsvektoren in den Zustand gelangen, wenn der Trainingssatz D nicht linear trennbar ist, d.h. wenn die positiven Beispiele nicht durch ein Hyperplan von den negativen Beispielen getrennt werden können. In diesem Fall wird unter dem Standard-Lernalgorithmus keine nähere Lösung nach und nach angegangen, sondern das Lernen wird vollständig scheitern. Wenn also eine lineare Trennbarkeit des Trainingssatzes nicht bekannt ist, sollte eine der folgenden Trainingsvarianten verwendet werden. Ist das Trainingsset linear trennbar, so wird der Perceptron garantiert konvergieren. Darüber hinaus gibt es eine obere Grenze an der Anzahl der Zeiten, die der Perceptron seine Gewichte während des Trainings anpassen wird. Es wird vorausgesetzt, daß die Eingabevektoren aus den beiden Klassen durch ein Hyperplane mit einem Rand γ {\displaystyle \gamma } getrennt werden können, d.h. es gibt einen Gewichtsvektor w , | w < | | = 1 {\displaystyle \math\bf\w}Lassen Sie R auch die maximale Norm eines Eingangsvektors bezeichnen. Novikoff (1962) bewies, dass in diesem Fall der Perceptron-Algorithmus nach O (R 2 / γ 2 ) konvergiert {\displaystyle O(R^{2}/\gamma {^2}) Updates. Der Nachweis besteht darin, dass der Gewichtsvektor in einer Richtung, mit der er ein negatives Punktprodukt aufweist, stets um eine gebundene Menge eingestellt wird und somit oben durch O(√t) begrenzt werden kann, wobei t die Anzahl der Änderungen des Gewichtsvektors ist. Es kann aber auch weiter unten durch O(t) begrenzt werden, da bei Vorhandensein eines (unbekannten) befriedigenden Gewichtsvektors jede Änderung in dieser (unbekannten) Richtung um einen positiven Betrag vorankommt, der nur vom Eingangsvektor abhängt. Während der Perceptronalgorithmus bei einem linear trennbaren Trainingsset auf eine Lösung abgestimmt wird, kann er dennoch jede Lösung auswählen und Probleme können viele Lösungen unterschiedlicher Qualität zugeben. Der Perceptron der optimalen Stabilität, heute besser bekannt als die lineare Stützvector-Maschine, wurde entwickelt, um dieses Problem zu lösen (Krauth und Mezard, 1987.) Varianten Der Taschenalgorithmus mit Ratsche (Gallant, 1990) löst das Stabilitätsproblem des Perceptron-Lernens, indem er die bisher "in seiner Tasche" beste Lösung erhält. Der Taschenalgorithmus gibt dann die Lösung in der Tasche zurück, anstatt die letzte Lösung. Es kann auch für nicht getrennte Datensätze verwendet werden, bei denen es darum geht, einen Perceptron mit einer geringen Anzahl von Fehlklassifikationen zu finden. Jedoch erscheinen diese Lösungen rein stochastisch und damit der Taschenalgorithmus nähert sich ihnen nicht allmählich im Laufe des Lernens, noch sind sie garantiert, innerhalb einer bestimmten Anzahl von Lernschritten aufzutauchen. Der Maxover-Algorithmus (Wendemuth, 1995) ist robust in dem Sinne, dass er unabhängig von (priorem) Kenntnis der linearen Trennbarkeit des Datensatzes konvergieren wird. Im linear trennbaren Fall löst es das Trainingsproblem – falls gewünscht – auch bei optimaler Stabilität (maximale Marge zwischen den Klassen). Für nicht getrennte Datensätze wird eine Lösung mit einer geringen Anzahl von Fehlklassifikationen zurückgegeben. In allen Fällen nähert sich der Algorithmus allmählich der Lösung im Laufe des Lernens, ohne vorhergehende Zustände und ohne stochastische Sprünge zu merken. Konvergence ist die globale Optimität für separable Datensätze und die lokale Optimität für nicht getrennte Datensätze. The Voted Perceptron (Freund und Schapire, 1999,) ist eine Variante mit mehreren gewichteten Perceptronen. Der Algorithmus startet ein neues Perceptron jedes Mal, wenn ein Beispiel falsch klassifiziert wird, Initialisierung des Gewichtsvektors mit den letzten Gewichten des letzten Perceptron. Jeder Perceptron wird auch ein weiteres Gewicht gegeben, das der Art entspricht, wie viele Beispiele sie korrekt klassifizieren, bevor sie falsch klassifizieren, und am Ende wird die Ausgabe eine gewichtete Stimme über alle Perceptronen sein. Bei trennbaren Problemen kann das Perceptron-Training auch darauf abzielen, den größten Trennrand zwischen den Klassen zu finden. Der sogenannte Perceptron optimaler Stabilität kann mittels iterativer Trainings- und Optimierungsschemata, wie dem Min-Over-Algorithmus (Krauth und Mezard, 1987) oder dem AdaTron (Anlauf und Biehl, 1989) bestimmt werden. AdaTron nutzt die Tatsache, dass das entsprechende quadratische Optimierungsproblem konvex ist. Der Perceptron der optimalen Stabilität, zusammen mit dem Kernel-Trick, sind die konzeptionellen Grundlagen der Support-Vector-Maschine. Der α {\displaystyle \alpha } -Perceptron verwendet weiter eine vorverarbeitende Schicht von festen Zufallsgewichten, mit Schwellen-Ausgangseinheiten. Dadurch konnte der Perceptron analoge Muster klassifizieren, indem er sie in einen binären Raum projizierte. Tatsächlich können für einen Projektionsraum ausreichend hoher Dimension Muster linear trennbar werden. Eine andere Möglichkeit, nichtlineare Probleme zu lösen, ohne mehrere Schichten zu verwenden, ist die Verwendung von höheren Ordnungsnetzwerken (sigma-pi-Einheit). Bei dieser Art von Netzwerk wird jedes Element im Eingangsvektor mit jeder paarweisen Kombination von multiplizierten Eingängen (zweite Ordnung) erweitert. Dies kann auf ein n-Ordner-Netzwerk erweitert werden. Es ist jedoch zu beachten, dass der beste Klassifikator nicht unbedingt derjenige ist, der alle Trainingsdaten perfekt klassifiziert. Wenn wir die vorhergehende Einschränkung hätten, dass die Daten aus äquivarianten Gaussian-Verteilungen stammen, ist die lineare Trennung im Eingangsraum optimal und die nichtlineare Lösung wird überrüstet.Weitere lineare Klassifizierungsalgorithmen umfassen Winnow, Support-Vector-Maschine und logistische Regression. Multiclass-Perceptron Wie die meisten anderen Techniken für die Ausbildung linearer Klassifikatoren, verallgemeinert der Perceptron natürlich zu multiclass Klassifikation. Hier werden der Eingang x {\displaystyle x} und der Ausgang y {\displaystyle y} aus beliebigen Sätzen gezogen. Eine Feature-Darstellungsfunktion f ( x , y ) {\displaystyle f(x,y}) stellt jedes mögliche Ein-/Ausgangspaar zu einem finite-dimensionalen real-valuierten Merkmalsvektor zusammen. Wie zuvor wird der Merkmalsvektor mit einem Gewichtsvektor w {\displaystyle w} multipliziert, aber jetzt wird die resultierende Punktzahl verwendet, um unter vielen möglichen Ausgängen zu wählen: y ^ = argmax y ≠ f ( x , y ) ∙ w . {\displaystyle {\hat {y}}=\operatorname {argmax} {_y}f(x,y)\cdot w}. Das Lernen iteriert über die Beispiele, prognostiziert für jeden eine Ausgabe, lässt die Gewichte unverändert, wenn die prognostizierte Ausgabe dem Ziel entspricht, und ändert sie, wenn es nicht. Das Update wird: w t + 1 = w t + f ( x , y ) - f ( x , y ^ ) . {\displaystyle w_{t+1}=w_{t}+f(x,y)-f(x,{\hat {y}.) Diese Multi-Class-Feedback-Formulierung reduziert sich auf den ursprünglichen Perceptron, wenn x {\displaystyle x} ein echter Vektor ist, y {\displaystyle y} aus {0, 1} {\displaystyle {0,1} und f (x, y ) = y x {\displaystyle f(x,y)=yx} gewählt wird. Für bestimmte Probleme können Eingabe-/Ausgabedarstellungen und Merkmale so gewählt werden, dass eine r g m a x y f ( x , y ) ∙ w {\displaystyle \mathrm {argmax} {_y}f(x,y)\cdot w} effizient gefunden werden kann, auch wenn y {\displaystyle y} aus einem sehr großen oder sogar unendlichen Satz gewählt wird. Seit 2002 ist das Perceptron-Training im Bereich der natürlichen Sprachverarbeitung für Aufgaben wie zum Teil-of-speech-Tagging und syntaktische Parsing (Collins, 2002) populär geworden. Es wurde auch auf großformatige maschinelle Lernprobleme in einer verteilten Rechenstellung angewendet. Referenzen Weiter lesen Aizerman, M. A. und Braverman, E. M. und Lev I. Rozonoer. Theoretische Grundlagen der Potentialfunktionsmethode im Mustererkennungslernen. Automation and Remote Control, 25:821–837, 1964.Rosenblatt, Frank (1958) The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain, Cornell Aeronautical Laboratory, Psychological Review, v65, No. 6, pp.386–408.doi:10.1037/h0042519.Rosenblatt, Frank (1962) Principles of Neurodynamics. Washington, DC:Spartan Books. Minsky M. L. und Papert S. A. 1969.Perceptrons. Cambridge, MA: MIT Drücken. Gallant, S. I. (1990). Perceptron-basierte Lernalgorithmen. IEEE Transactions on Neural Networks, Band 1, Nr. 2, S.179–191. Mohri, Mehryar und Rostamizadeh, Afshin (2013). Perceptron Mistake Bounds arXiv:1305.0208, 2013.Novikoff, A. B. (1962). Auf Konvergenznachweise auf Perceptronen. Symposium über die mathematische Theorie von Automata, 12, 615–622. Polytechnic Institute of Brooklyn. Widrow, B., Lehr, M.A, "30 Jahre Adaptive Neural Networks: Perceptron, Madaline und Backpropagation", Proc.IEEE, vol 78, no 9, pp.1415–1442, (1990). Collins, M. 2002. Diskriminative Trainingsmethoden für versteckte Markov-Modelle: Theorie und Experimente mit dem Perceptron-Algorithmus in Proceedings der Konferenz über empirische Methoden in der natürlichen Sprachverarbeitung (EMNLP '02.)Yin, Hongfeng (1996,) Perceptron-Based Algorithms and Analysis, Spectrum Library, Concordia University, Canada Externe Links A Perceptron in MATLAB implementiert, um binäre NAND-Funktion Kapitel 3Gewächse Netzwerke zu lernen - der Perceptron und Kapitel 4Perceptron Lernen von neuronalen Netzwerken - Eine systematische Einführung von Raúl Rojas (ISBN 978-3-540-605-05-8) Geschichte der Perceptrons Mathematik von Mehrschicht-Perceptrons Visualisieren Sie mehrere Perceptron-Varianten Lernen im Browser