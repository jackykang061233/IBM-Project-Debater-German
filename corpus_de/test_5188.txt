Im Deep Learning ist ein konvolutionales neuronales Netzwerk (CNN oder ConvNet) eine Klasse von künstlichen neuronalen Netzwerken, die am häufigsten zur Analyse von visuellen Bildern eingesetzt werden. Sie sind auch als Verschiebungsinvariante oder Rauminvariante künstliche neuronale Netzwerke (SIANN) bekannt, die auf der gemeinsamen Gewichtsarchitektur der Convolution-Kernels oder Filter basieren, die entlang der Eingabefunktionen gleiten und Übersetzungs-äquivariante Antworten liefern, die als Feature-Karten bekannt sind. Unzählig sind die meisten konvolutionalen neuronalen Netzwerke nur äquivariant, im Gegensatz zur invarianten Übersetzung. Sie haben Anwendungen in der Bild- und Videoerkennung, Empfehlungssysteme, Bildklassifizierung, Bildsegmentierung, medizinische Bildanalyse, natürliche Sprachverarbeitung, Hirncomputerschnittstellen und Finanzzeitreihen. CNNs sind regelmäßige Versionen von Multilayer-Perceptrons. Multilayer-Perceptrons bedeuten in der Regel vollständig vernetzte Netzwerke, d.h. jedes Neuron in einer Schicht ist mit allen Neuronen in der nächsten Schicht verbunden. Die "vollständige Konnektivität" dieser Netzwerke macht sie anfällig für die Überarbeitung von Daten. Typische Möglichkeiten der Regulierung oder der Vermeidung von Überbelegung umfassen: penalisierende Parameter während des Trainings (wie Gewichtsabnahme) oder Trimmverbindung (kippte Verbindungen, Dropout, etc.) CNNs nehmen einen anderen Ansatz zur Regulierung ein: Sie nutzen das hierarchische Muster in Daten und montieren Muster zunehmender Komplexität mit kleineren und einfacheren Mustern, die in ihren Filtern geprägt sind. Daher sind CNNs auf einer Skala von Konnektivität und Komplexität am unteren Extrem. Konvolutionale Netzwerke wurden von biologischen Prozessen inspiriert, indem das Konnektivitätsmuster zwischen Neuronen der Organisation der Tieroptik ähnelt. Einzelne kortikale Neuronen reagieren auf Reize nur in einem eingeschränkten Bereich des visuellen Feldes, das als empfängliches Feld bekannt ist. Die Aufnahmefelder verschiedener Neuronen überlappen sich teilweise so, dass sie das gesamte visuelle Feld abdecken. CNNs verwenden relativ wenig Vorverarbeitung im Vergleich zu anderen Bildklassifikationsalgorithmen. Das bedeutet, dass das Netzwerk lernt, die Filter (oder Kernel) durch automatisiertes Lernen zu optimieren, während in traditionellen Algorithmen diese Filter handgefertigt werden. Diese Unabhängigkeit von Vorkenntnissen und menschlichem Eingreifen in die Merkmalsextraktion ist ein wesentlicher Vorteil. Begriff Der Name "Convolutional neuronal network" gibt an, dass das Netzwerk eine mathematische Operation verwendet, die sogenannte Convolution. Konvolutionale Netzwerke sind eine spezialisierte Art von neuronalen Netzwerken, die anstelle der allgemeinen Matrixmultiplikation in mindestens einer ihrer Schichten Konvolution verwenden. Architektur Ein konvolutionales neuronales Netz besteht aus einer Eingangsschicht, versteckten Schichten und einer Ausgangsschicht. In jedem Feed-Forward-Neural-Netzwerk werden alle Mittelschichten als verdeckt bezeichnet, da ihre Ein- und Ausgänge durch die Aktivierungsfunktion und Endverstimmung maskiert werden. In einem konvolutionalen neuronalen Netz enthalten die versteckten Schichten Schichten, die Faltungen durchführen. Typischerweise umfasst dies eine Schicht, die mit der Eingabematrix der Schicht ein Punktprodukt des Faltenkerns ausführt. Dieses Produkt ist in der Regel das Frobenius Innenprodukt, und seine Aktivierungsfunktion ist häufig ReLU. Da der Faltungskern entlang der Eingabematrix für die Schicht gleitet, erzeugt der Faltungsvorgang eine Merkmalskarte, die wiederum zum Eingang der nächsten Schicht beiträgt. Es folgen weitere Schichten, wie z.B. Poolingschichten, voll verbundene Schichten und Normalisierungsschichten. Konvolutionsschichten In einem CNN ist der Eingang ein Tensor mit einer Form: (Anzahl der Eingänge) x (Eingangshöhe)x (Eingangsbreite) x (Eingangskanäle). Nach Durchlaufen einer konvolutionalen Schicht wird das Bild auf eine Merkmalskarte abstrahiert, auch als Aktivierungskarte bezeichnet, mit Form: (Anzahl der Eingänge) x (Feature Map Höhe) x (Feature Map Breite) x (Feature Map Channels). Konvolutionsschichten bündeln den Eingang und passieren sein Ergebnis auf die nächste Schicht. Dies ist ähnlich wie die Reaktion eines Neurons im visuellen Kortex auf einen bestimmten Reiz. Jedes konvolutionale Neuron verarbeitet Daten nur für sein empfängliches Feld. Obwohl vollständig vernetzte neuronale Netzwerke verwendet werden können, um Funktionen zu lernen und Daten zu klassifizieren, ist diese Architektur in der Regel für größere Eingänge wie hochauflösende Bilder unpraktisch. Es würde eine sehr hohe Anzahl von Neuronen erfordern, auch in einer flachen Architektur, aufgrund der großen Eingabegröße von Bildern, wo jedes Pixel ein relevantes Eingabemerkmal ist. Beispielsweise weist eine vollständig verbundene Schicht für ein (kleines) Bild der Größe 100 x 100 für jedes Neuron in der zweiten Schicht 10.000 Gewichte auf. Stattdessen reduziert die Faltung die Anzahl der freien Parameter, wodurch das Netzwerk tiefer sein kann. Zum Beispiel, unabhängig von der Bildgröße, mit einem 5 x 5 Tiling-Bereich, jeweils mit den gleichen gemeinsamen Gewichten, benötigen nur 25 erlernbare Parameter. Mit regelmäßigen Gewichten über weniger Parameter vermeiden die verschwindenden Gradienten und explodierenden Gradienten Probleme bei der Rückverbreitung in traditionellen neuronalen Netzwerken. Darüber hinaus sind konvolutionale neuronale Netzwerke ideal für Daten mit einer gitterartigen Topologie (wie Bilder) da räumliche Beziehungen zwischen einzelnen Merkmalen bei der Faltung und/oder Bündelung berücksichtigt werden. Konvolutionale Netzwerke können lokale und/oder globale Pooling Schichten zusammen mit traditionellen Faltungsschichten umfassen. Durch die Kombination der Ausgänge von Neuron-Clustern an einer Schicht in ein einziges Neuron in der nächsten Schicht reduzieren die Pooling-Schichten die Datenabmessungen. Lokale Pooling kombiniert kleine Cluster, Fliesen Größen wie 2 x 2 werden häufig verwendet. Globale Pooling wirkt auf alle Neuronen der Feature-Karte. Es gibt zwei gemeinsame Arten von Pooling in der beliebten Verwendung: max und Durchschnitt. Max-Pooling verwendet den Maximalwert jedes lokalen Clusters von Neuronen in der Feature-Karte, während durchschnittliche Pooling den Durchschnittswert nimmt. Vollständig verbundene Schichten Vollständig verbundene Schichten verbinden jedes Neuron in einer Schicht mit jedem Neuron in einer anderen Schicht. Es ist das gleiche wie ein traditionelles mehrschichtiges Perceptron-Neuralnetzwerk (MLP). Die abgeflachte Matrix geht durch eine vollständig verbundene Schicht, um die Bilder zu klassifizieren. Aufnahmefeld In neuronalen Netzen erhält jedes Neuron einen Eingang von einigen Stellen in der vorherigen Schicht. In einer konvolutionalen Schicht erhält jedes Neuron nur einen begrenzten Bereich der vorherigen Schicht, genannt das rezeptive Feld des Neurons. Typischerweise ist die Fläche ein Quadrat (z.B. 5 von 5 Neuronen). Während in einer vollständig verbundenen Schicht das Aufnahmefeld die gesamte vorherige Schicht ist. In jeder Faltungsschicht nimmt also jedes Neuron von einem größeren Bereich im Eingang als frühere Schichten ein. Dies liegt daran, die Faltung über und über anzuwenden, was den Wert eines Pixels sowie dessen umgebenden Pixel berücksichtigt. Bei Verwendung von dilatierten Schichten bleibt die Anzahl der Pixel im Aufnahmefeld konstant, aber das Feld wird bei der Kombination der Wirkung mehrerer Schichten sparsamer bevölkert, da seine Abmessungen wachsen. Jedes Neuron in einem neuronalen Netzwerk berechnet einen Ausgangswert, indem eine bestimmte Funktion auf die vom Aufnahmefeld in der vorherigen Schicht empfangenen Eingangswerte angewendet wird. Die auf die Eingangswerte aufgebrachte Funktion wird durch einen Gewichtsvektor und eine Vorspannung (typischerweise reale Zahlen) bestimmt. Das Lernen besteht darin, diese Vorurteile und Gewichte iterativ anzupassen. Der Gewichtsvektor und die Vorspannung werden als Filter bezeichnet und stellen bestimmte Merkmale des Eingangs (z.B. eine bestimmte Form) dar. Ein Unterscheidungsmerkmal von CNNs ist, dass viele Neuronen den gleichen Filter teilen können. Dies reduziert den Speicherfußabdruck, da eine einzige Vorspannung und ein einziger Gewichtsvektor über alle empfänglichen Felder verwendet werden, die diesen Filter teilen, im Gegensatz zu jedem empfänglichen Feld mit eigener Vorspannung und Vektorgewichtung. Die Geschichte CNN wird oft mit der Art verglichen, wie das Gehirn Vision-Verarbeitung in lebenden Organismen erreicht. In den 1950er und 1960er Jahren zeigten empfängliche Felder im visuellen Kortex Work von Hubel und Wiesel, dass Katzenoptiken Neuronen enthalten, die auf kleine Bereiche des visuellen Feldes individuell reagieren. Sofern sich die Augen nicht bewegen, ist der Bereich des visuellen Raumes bekannt, in dem visuelle Reize das Brennen eines einzelnen Neurons beeinflussen. Nachbarzellen haben ähnliche und überlappende Aufnahmefelder. Die empfängliche Feldgröße und -lage variiert systematisch über den Kortex hinweg, um eine komplette Bildkarte zu bilden. Der Kortex in jeder Halbkugel stellt das kontralaterale Sehfeld dar. Ihr 1968er Papier identifizierte zwei grundlegende visuelle Zelltypen im Gehirn: einfache Zellen, deren Ausgang durch gerade Kanten mit bestimmten Orientierungen innerhalb ihrer rezeptiven Feldkomplexzellen maximiert wird, die größere rezeptive Felder aufweisen, deren Ausgang unempfindlich gegenüber der exakten Position der Kanten im Feld ist. Hubel und Wiesel schlugen auch ein Kaskadierungsmodell dieser beiden Arten von Zellen für den Einsatz in Mustererkennungsaufgaben vor. Neocognitron, Ursprung der CNN-Architektur Das Neocognitron wurde 1980 von Kunihiko Fukushima eingeführt. Es wurde von der oben genannten Arbeit von Hubel und Wiesel inspiriert. Das Neocognitron führte die beiden Grundtypen von Schichten in CNNs ein: Faltungsschichten und Downsamplingschichten. Eine konvolutionale Schicht enthält Einheiten, deren rezeptive Felder einen Patch der vorherigen Schicht abdecken. Der Gewichtsvektor (der Satz von adaptiven Parametern) einer solchen Einheit wird oft als Filter bezeichnet. Einheiten können Filter teilen. Downsampling-Schichten enthalten Einheiten, deren Aufnahmefelder Patches früherer Faltungsschichten abdecken. Eine solche Einheit berechnet typischerweise den Mittelwert der Aktivierungen der Einheiten in ihrem Patch. Dieses Downsampling hilft, Objekte in visuellen Szenen richtig einzuordnen, auch wenn die Objekte verschoben werden. In einer Variante des Neocognitrons, genannt Cresceptron, anstelle der Verwendung von Fukushimas räumliche Mittelung, J. Weng et al. ein Verfahren mit dem Namen max-pooling eingeführt, bei dem eine Downsampling-Einheit das Maximum der Aktivierungen der Einheiten in ihrem Patch berechnet. Max-Pooling wird oft in modernen CNNs verwendet.In den Jahrzehnten wurden verschiedene beaufsichtigte und nicht überwachte Lernalgorithmen vorgeschlagen, um die Gewichte eines Neocognitrons zu trainieren. Die CNN-Architektur wird heute jedoch meist durch Rückverbreitung geschult. Das Neocognitron ist das erste CNN, das Einheiten an mehreren Netzwerkpositionen benötigt, um gemeinsame Gewichte zu haben. Beim Neural Information Processing Workshop wurden 1987 konvolutionelle neuronale Netzwerke vorgestellt, die zeitverändernde Signale automatisch analysieren, indem er die erlernte Multiplikation mit einer zeitlichen Konvolution ersetzte und zur Spracherkennung demonstrierte. Zeitverzögerung neuronaler Netze Das Zeitverzögerungs-Neuralnetzwerk (TDNN) wurde 1987 von Alex Waibel et al.and eingeführt und war eines der ersten Faltungsnetze, wie es eine Verschiebungsinvarianz erreichte. Es tat dies durch die Verwendung Gewicht-Sharing in Kombination mit Backpropagation Training. So führte sie, auch unter Verwendung einer pyramidenförmigen Struktur wie im Neocognitron, eine globale Optimierung der Gewichte statt einer lokalen. TDNNs sind Faltungsnetze, die Gewichte entlang der zeitlichen Dimension teilen. Sie ermöglichen es, Sprachsignale zeitinvariant zu verarbeiten. 1990 führte Hampshire und Waibel eine Variante ein, die eine zweidimensionale Faltung durchführt. Da diese TDNs auf Spektrogrammen betrieben werden, war das resultierende Phonemerkennungssystem invariant für beide Zeit- und Frequenzverschiebungen. Diese inspirierte Übersetzungsinvarianz bei der Bildverarbeitung mit CNNs. Das Abfliessen von Neuron-Ausgängen kann zeitliche Phasen abdecken. TDNNs erreichen nun die beste Leistung bei Fernredeerkennung. Max Pooling Im Jahr 1990 hat Yamaguchi et al. das Konzept der Max-Pooling vorgestellt, die eine feste Filterung ist, die den Maximalwert einer bestimmten Region berechnet und propagiert. Sie taten dies, indem sie TDNNs mit max-Pooling kombinierten, um ein Lautsprecher unabhängiges isoliertes Worterkennungssystem zu realisieren. In ihrem System benutzten sie mehrere TDNs pro Wort, eine für jedes Silbe. Die Ergebnisse jedes TDNN über das Eingangssignal wurden mit max-Pooling kombiniert und die Ausgänge der Pooling-Schichten wurden dann an Netzwerke weitergeleitet, die die eigentliche Wortklassifikation durchführen. Bilderkennung mit CNNs trainiert von Gradientenabstieg Ein System zur Erkennung von handschriftlichen ZIP-Code-Nummern beteiligten Faltungen, in denen die Kernelkoeffizienten mühsam Hand entworfen worden waren. Yann LeCun et al.(1989) verwendet Back-Propagation, um die Faltungskernelkoeffizienten direkt aus Bildern von handschriftlichen Zahlen zu lernen. Das Lernen war somit vollautomatisch, besser als das manuelle Koeffizientendesign, und eignete sich für eine breite Palette von Bilderkennungsproblemen und Bildtypen. Dieser Ansatz wurde zum Fundament moderner Computer-Vision. LeNet-5 LeNet-5, ein wegweisendes 7-Level-Convolutional-Netzwerk von LeCun et al.in 1998, das die Ziffern klassifiziert, wurde von mehreren Banken angewendet, um handschriftliche Zahlen bei Kontrollen (British English: cheques) zu erkennen, die in 32x32 Pixel-Bildern digitalisiert wurden. Die Fähigkeit, höhere Auflösungsbilder zu verarbeiten, erfordert größere und mehr Schichten von konvolutionalen neuronalen Netzwerken, so dass diese Technik durch die Verfügbarkeit von Rechenressourcen eingeschränkt wird. Shift-invariantes neuronales Netz Ebenso wurde 1988 von W. Zhang et al.for Bildzeichenerkennung ein Schichtinvariantes neuronales Netz vorgeschlagen. Der Architektur- und Trainingsalgorithmus wurde 1991 modifiziert und zur medizinischen Bildverarbeitung und automatischen Erkennung von Brustkrebs in Mammogrammen angewendet. 1988 wurde für die Anwendung auf die Zersetzung von eindimensionalen elektromyographisch konvolvierten Signalen durch De-Konvolution eine andere konvolutionsbasierte Konstruktion vorgeschlagen. Dieses Design wurde 1989 auf andere de-convolution-basierte Designs modifiziert. Neurale Abstraktionspyramide In der neuralen Abstraktionspyramide wurde die zukunftsweisende Architektur von konvolutionalen neuronalen Netzen durch seitliche und Rückkopplungsverbindungen erweitert. Das sich daraus ergebende wiederkehrende konvolutionale Netz ermöglicht die flexible Einbeziehung von kontextuellen Informationen, um lokale Mehrdeutigkeiten iterativ zu lösen. Im Gegensatz zu bisherigen Modellen wurden bildähnliche Ausgänge mit höchster Auflösung erzeugt, z.B. für semantische Segmentierung, Bildrekonstruktion und Objektlokalisierungsaufgaben. GPU-Implementierungen Obwohl CNNs in den 1980er Jahren erfunden wurden, erforderte ihr Durchbruch in den 2000er Jahren schnelle Implementierungen auf Grafikverarbeitungseinheiten (GPUs). Im Jahr 2004 wurde es von K. S.Oh und K gezeigt. Jung, dass Standard-Neuralnetze auf GPUs stark beschleunigt werden können. Ihre Implementierung war 20 mal schneller als eine äquivalente Implementierung auf CPU. 2005 betonte ein weiteres Papier auch den Wert von GPGPU für maschinelles Lernen. Die erste GPU-Ergänzung eines CNN wurde 2006 von K. Chellapilla et al. Ihre Implementierung war 4 mal schneller als eine äquivalente Implementierung auf CPU. Anschließende Arbeiten nutzten auch GPUs, zunächst für andere Arten von neuronalen Netzwerken (unterschiedlich von CNNs), besonders unübertroffene neuronale Netzwerke. Im Jahr 2010 zeigte Dan Ciresan et al.at IDSIA, dass auch tiefe Standard-Neuralnetzwerke mit vielen Schichten schnell auf GPU trainiert werden können, indem das Lernen durch die alte Methode, die als Backpropagation bekannt ist, überwacht wird. Ihr Netzwerk übertraf die bisherigen maschinellen Lernmethoden auf dem MNIST handschriftliche Ziffern-Benchmark. 2011 erweiterten sie diesen GPU-Ansatz auf CNNs und erzielten einen Beschleunigungsfaktor von 60 mit beeindruckenden Ergebnissen. Im Jahr 2011 nutzten sie solche CNNs auf GPU, um einen Bilderkennungswettbewerb zu gewinnen, wo sie erstmals übermenschliche Leistung erreichten. Zwischen 15. Mai 2011 und 30. September 2012 gewannen ihre CNNs nicht weniger als vier Bildwettbewerbe. Im Jahr 2012 verbesserten sie auch deutlich die beste Performance in der Literatur für mehrere Bilddatenbanken, einschließlich der MNIST-Datenbank, der NORB-Datenbank, des HWDB1.0-Datensatzes (chinesische Zeichen) und des CIFAR10-Datensatzes (Datensatz von 60000 32x32 markierten RGB-Bildern). Anschließend eine ähnliche GPU-basierte CNN von Alex Krizhevsky et al.won the ImageNet Large Scale Visual Recognition Challenge 2012. Ein sehr tiefes CNN mit über 100 Schichten von Microsoft gewann den ImageNet 2015 Wettbewerb. Intel Xeon Phi Implementierungen Im Vergleich zur Ausbildung von CNNs mit GPUs wurde dem Intel Xeon Phi Coprozessor nicht viel Aufmerksamkeit geschenkt. Eine bemerkenswerte Entwicklung ist eine Parallelisierungsmethode zum Training von konvolutionalen neuronalen Netzwerken auf dem Intel Xeon Phi, genannt Controlled Hogwild mit Arbitrary Order of Synchronisation (CHAOS). CHAOS nutzt sowohl die Parallelität von Thread- als auch SIMD-Ebene, die auf dem Intel Xeon Phi zur Verfügung steht. Besonderheiten In der Vergangenheit wurden zur Bilderkennung traditionelle mehrschichtige Perceptron-Modelle (MLP) verwendet. Die vollständige Verbindung zwischen Knoten verursachte jedoch den Fluch der Dimensionalität und war mit höheren Auflösungsbildern rechnerisch untragbar. Ein 1000 x 100 Pixel-Bild mit RGB-Farbkanälen hat 3 Millionen Gewichte, die zu hoch ist, um effektiv im Maßstab mit voller Konnektivität zu verarbeiten. Beispielsweise sind in CIFAR-10 Bilder nur von der Größe 32×32×3 (32 breit, 32 hoch, 3 Farbkanäle), so dass ein einziges vollständig vernetztes Neuron in der ersten versteckten Schicht eines regelmäßigen neuronalen Netzes 32*32*3 = 3,072 Gewichte hätte. Ein 200 x 200 Bild würde jedoch zu Neuronen führen, die 200 * 200 * 3 = 120.000 Gewichte haben. Auch berücksichtigt diese Netzwerkarchitektur nicht die räumliche Struktur von Daten, behandelt Eingabepixel, die in der gleichen Weise weit voneinander entfernt sind wie Pixel, die eng zusammen sind. Dies ignoriert die Lokalität der Referenz in Daten mit einer Netztopologie (wie Bilder), sowohl rechnerisch als auch semantisch. So ist die vollständige Konnektivität von Neuronen für Zwecke wie Bilderkennung, die von räumlich lokalen Eingabemustern dominiert werden, verschwendet. Konvolutionale neuronale Netzwerke sind Varianten von mehrschichtigen Perceptronen, die das Verhalten eines visuellen Kortex emulieren. Diese Modelle mildern die Herausforderungen der MLP-Architektur, indem sie die starke räumlich lokale Korrelation in natürlichen Bildern ausnutzen. Im Gegensatz zu MLPs haben CNNs folgende Unterscheidungsmerkmale: 3D-Volumen von Neuronen. Die Schichten eines CNN haben Neuronen in 3 Dimensionen angeordnet: Breite, Höhe und Tiefe. Wo jedes Neuron innerhalb einer konvolutionalen Schicht mit nur einem kleinen Bereich der Schicht davor verbunden ist, genannt ein Rezeptorfeld. Unterscheidende Schichten, sowohl lokal als auch vollständig miteinander verbunden, werden zu einer CNN-Architektur gestapelt. Lokale Konnektivität: Nach dem Konzept der empfänglichen Felder nutzen CNNs die räumliche Lokalität, indem sie ein lokales Konnektivitätsmuster zwischen Neuronen benachbarter Schichten aufzwingen. Die Architektur stellt somit sicher, dass die gelernten Filter die stärkste Reaktion auf ein räumlich lokales Eingabemuster erzeugen. Das Stapeln vieler solcher Schichten führt zu nichtlinearen Filtern, die zunehmend global werden (d.h. in Abhängigkeit von einem größeren Bereich des Pixelraums), so dass das Netzwerk zunächst Darstellungen von kleinen Teilen des Eingangs erstellt, von denen dann Darstellungen größerer Bereiche zusammenstellt. Geteilte Gewichte: In CNNs wird jeder Filter über das gesamte Sichtfeld repliziert. Diese replizierten Einheiten teilen die gleiche Parametrierung (Gewichtsvektor und Bias) und bilden eine Merkmalskarte. Dies bedeutet, dass alle Neuronen in einer bestimmten Faltungsschicht auf das gleiche Merkmal innerhalb ihres spezifischen Antwortfeldes reagieren. Auf diese Weise können Replikationseinheiten die resultierende Aktivierungskarte unter Verschiebungen der Orte der Eingabemerkmale im visuellen Bereich gleichvariant sein, d.h. sie gewähren eine translatorische Äquivarianz - vorausgesetzt, dass die Schicht einen Streifen hat. Pooling: In den Bündelungsschichten eines CNN werden die Merkmalskarten in rechteckige Teilbereiche unterteilt, und die Merkmale in jedem Rechteck werden unabhängig voneinander auf einen einzigen Wert herabgetastet, häufig durch die Einnahme ihres Durchschnitts- oder Maximalwertes. Neben der Verringerung der Größe der Merkmalskarten gewährt der Pooling-Betrieb eine gewisse lokale Übersetzungsinvarianz zu den darin enthaltenen Merkmalen, so dass der CNN robuster sein kann für Veränderungen in ihren Positionen. Gemeinsam ermöglichen diese Eigenschaften CNNs eine bessere Verallgemeinerung der Sehprobleme. Die Gewichtsverteilung reduziert die Anzahl der gewonnenen freien Parameter drastisch und senkt so die Speicheranforderungen für den Betrieb des Netzes und ermöglicht das Training größerer, leistungsfähiger Netzwerke.Bausteine Eine CNN-Architektur wird durch einen Stapel unterschiedlicher Schichten gebildet, die das Eingangsvolumen durch eine differenzierbare Funktion in ein Ausgabevolumen (z.B. mit den Klassenpunkten) transformieren. Ein paar verschiedene Arten von Schichten werden häufig verwendet. Diese werden weiter unten diskutiert. Konvolutionsschicht Die Faltungsschicht ist der Kernbaustein eines CNN. Die Parameter der Schicht bestehen aus einem Satz von erlernbaren Filtern (oder Kernen), die ein kleines Aufnahmefeld aufweisen, sich aber durch die volle Tiefe des Eingangsvolumens erstrecken. Während des Vorlaufs wird jedes Filter über die Breite und Höhe des Eingangsvolumens konvolviert, wobei das Punktprodukt zwischen den Filtereinträgen und dem Eingang berechnet wird, wodurch eine 2-dimensionale Aktivierungskarte dieses Filters erzeugt wird. Dadurch erlernt das Netzwerk Filter, die aktivieren, wenn es eine bestimmte Art von Feature an einer räumlichen Position im Eingang erkennt. Die Stapelung der Aktivierungskarten für alle Filter entlang der Tiefendimension bildet das volle Ausgangsvolumen der Faltungsschicht. Jeder Eintrag im Ausgangsvolumen kann somit auch als Ausgang eines Neurons interpretiert werden, der einen kleinen Bereich in der Eingabe betrachtet und Parameter mit Neuronen in der gleichen Aktivierungskarte teilt. Lokale Vernetzung Beim Umgang mit hochdimensionalen Eingaben wie Bildern ist es unpraktisch, Neuronen mit allen Neuronen im vorherigen Volumen zu verbinden, da eine solche Netzwerkarchitektur die räumliche Struktur der Daten nicht berücksichtigt. Konvolutionale Netzwerke nutzen räumlich lokale Korrelation, indem ein spärliches lokales Konnektivitätsmuster zwischen Neuronen benachbarter Schichten erzeugt wird: Jedes Neuron ist mit nur einem kleinen Bereich des Eingangsvolumens verbunden. Das Ausmaß dieser Konnektivität ist ein Hyperparameter, genannt das empfängliche Feld des Neurons. Die Verbindungen sind im Raum lokal (unter Breite und Höhe), erstrecken sich aber immer über die gesamte Tiefe des Eingangsvolumens. Eine solche Architektur sorgt dafür, dass die Lernfilter die stärkste Reaktion auf ein räumlich lokales Eingabemuster erzeugen. Raumordnung Drei Hyperparameter steuern die Größe des Ausgangsvolumens der konvolutionalen Schicht: die Tiefe, die Streifen- und Polstergröße. Die Tiefe des Ausgangsvolumens steuert die Anzahl der Neuronen in einer Schicht, die mit demselben Bereich des Eingangsvolumens verbunden ist. Diese Neuronen lernen für verschiedene Funktionen in der Eingabe zu aktivieren. Nimmt beispielsweise die erste Faltungsschicht das Rohbild als Eingabe, so können unterschiedliche Neuronen entlang der Tiefendimension in Gegenwart verschiedener orientierter Kanten oder Farbblobs aktivieren. Stride steuert, wie Tiefensäulen um Breite und Höhe zugeordnet werden. Wenn der Schritt 1 ist, dann bewegen wir die Filter ein Pixel zu einem Zeitpunkt. Dies führt zu stark überlappenden Aufnahmefeldern zwischen den Spalten und zu großen Ausgangsvolumina. Für jede ganze Zahl S > 0, {\textstyle S>0,} bedeutet ein Stride S, dass der Filter S-Einheiten zu einem Zeitpunkt pro Ausgang übersetzt wird. In der Praxis ist S ≥ 3 {\textstyle S\geq 3} selten. Ein größerer Streifen bedeutet kleinere Überlappung von Aufnahmefeldern und kleineren Raumabmessungen des Ausgabevolumens. Manchmal ist es zweckmäßig, den Eingang an der Grenze des Eingangsvolumens mit Nullen (oder anderen Werten, wie dem Mittelwert des Bereichs) zu sperren. Die Größe dieser Polsterung ist ein dritter Hyperparameter. Das Padding ermöglicht die Kontrolle der räumlichen Größe des Ausgangsvolumens. Insbesondere ist es manchmal wünschenswert, die räumliche Größe des Eingangsvolumens genau zu erhalten, dies wird allgemein als gleiche Polsterung bezeichnet. Die räumliche Größe des Ausgangsvolumens ist eine Funktion der Eingangsvolumengröße W {\displaystyle W}, der Kernelfeldgröße K {\displaystyle K} der Faltschichtneuronen, der Stride S {\displaystyle S} und der Menge der Nullpadding P {\displaystyle P} an der Grenze. Die Anzahl der Neuronen, die in ein bestimmtes Volumen passen, ist dann: Ist diese Zahl keine ganze Zahl, so sind die Stride falsch und die Neuronen können nicht symmetrisch über das Eingangsvolumen gefliest werden. Im allgemeinen sorgt die Einstellung der Null-Padierung auf P = (K - 1 ) / 2 {\textstyle P=(K-1)/2} bei S = 1 {\displaystyle S=1} dafür, dass das Eingangsvolumen und das Ausgangsvolumen die gleiche Größe haben. Es ist jedoch nicht immer vollständig notwendig, alle Neuronen der vorherigen Schicht zu verwenden. Beispielsweise kann ein neuronaler Netzwerk-Designer entscheiden, nur einen Teil der Polsterung zu verwenden. Parameterfreigabe Ein Parameter-Sharing-System wird in Faltungsschichten verwendet, um die Anzahl der freien Parameter zu steuern. Es beruht auf der Annahme, dass, wenn ein Patch-Feature nützlich ist, um an einer bestimmten räumlichen Position zu berechnen, dann sollte es auch nützlich sein, an anderen Positionen zu berechnen. Die Neuronen in jeder Tiefenscheibe sind dazu gezwungen, die gleichen Gewichte und Vorspannungen zu verwenden. Da alle Neuronen in einem einzigen Tiefenschnitt dieselben Parameter teilen, kann der Vorlauf in jedem Tiefenschnitt der Faltungsschicht als Faltung der Gewichte des Neurons mit dem Eingangsvolumen berechnet werden. Es ist daher üblich, auf die Gewichtssätze als Filter (oder Kernel) zu verweisen, der mit der Eingabe verknüpft ist. Das Ergebnis dieser Faltung ist eine Aktivierungskarte, und der Satz von Aktivierungskarten für jedes unterschiedliche Filter werden entlang der Tiefendimension zur Erzeugung des Ausgabevolumens zusammengestapelt. Die Parameterfreigabe trägt zur Übersetzungsinvarianz der CNN-Architektur bei. Manchmal kann die Parameterfreigabeannahme keinen Sinn ergeben. Dies ist insbesondere dann der Fall, wenn die Eingabebilder zu einem CNN eine bestimmte zentrierte Struktur haben; für die wir erwarten, dass an verschiedenen räumlichen Standorten völlig unterschiedliche Merkmale erlernt werden. Ein praktisches Beispiel ist, wenn die Eingaben Gesichter sind, die im Bild zentriert wurden: wir könnten erwarten, dass in verschiedenen Teilen des Bildes unterschiedliche Augen- oder haarspezifische Merkmale erlernt werden. In diesem Fall ist es üblich, das Parameter-Sharing-Programm zu entspannen und stattdessen einfach die Schicht eine "lokal verbundene Schicht" nennen. Schwimmschicht Ein weiteres wichtiges Konzept der CNNs ist die Bündelung, die eine Form der nichtlinearen Down-Sampling ist. Es gibt mehrere nicht-lineare Funktionen, um die Pooling zu implementieren, wobei die maximale Pooling am häufigsten ist. Es spaltet das Eingabebild in eine Reihe von Rechtecken und gibt für jeden solchen Teilbereich das Maximum aus. Intuitiv ist die genaue Lage eines Merkmals weniger wichtig als seine raue Lage gegenüber anderen Merkmalen. Dies ist die Idee hinter der Verwendung von Pooling in konvolutionalen neuronalen Netzwerken. Die Poolingschicht dient dazu, die räumliche Größe der Darstellung schrittweise zu reduzieren, die Anzahl der Parameter, Speicherfußabdruck und Berechnungsmenge im Netzwerk zu reduzieren und damit auch das Überrüsten zu steuern. Dies ist als Down-Sampling bekannt Es ist üblich, zwischen aufeinanderfolgenden Faltungsschichten (jeweils einer typischerweise gefolgten Aktivierungsfunktion, wie einer ReLU-Schicht) in einer CNN-Architektur periodisch eine Bündelungsschicht einzufügen. Während die Bündelung von Schichten zur lokalen Übersetzungsinvarianz beitragen, bieten sie keine globale Übersetzungsinvarianz in einem CNN, es sei denn, eine Form der globalen Bündelung wird verwendet. Die Poolingschicht arbeitet üblicherweise unabhängig von jeder Tiefe oder Schicht des Eingangs und resizet sie räumlich. Eine sehr häufige Form der Max-Poolierung ist eine Schicht mit Filtern der Größe 2×2, aufgetragen mit einem Streifen von 2, die jede Tiefenscheibe im Eingang um 2 entlang der Breite und Höhe subsamplest und 75% der Aktivierungen verworfen: In diesem Fall ist jede max Operation über 4 Zahlen. Die Tiefendimension bleibt unverändert (dies gilt auch für andere Formen der Bündelung). Neben dem max-Pooling können Pooling-Einheiten andere Funktionen nutzen, wie z.B. durchschnittliche Pooling oder l2-Norm-Pooling. Durchschnittliche Pooling wurde oft historisch verwendet, aber vor kurzem fiel aus Gunst im Vergleich zu max. Pooling, die in der Regel besser in der Praxis. Durch die Auswirkungen einer schnellen räumlichen Reduktion der Größe der Darstellung ergibt sich ein neuer Trend zur Verwendung kleinerer Filter oder der Verstopfungsschichten insgesamt. "Region of Interest"-Pooling (auch bekannt als RoI-Pooling) ist eine Variante der Max-Pooling, in der die Ausgangsgröße festgelegt ist und das Eingangs-Rechnereck ein Parameter ist. Die Pooling ist ein wichtiger Bestandteil von konvolutionalen neuronalen Netzwerken zur Objekterkennung auf Basis der Fast R-CNN Architektur. ReLU-Schicht ReLU ist die Abkürzung der gleichgerichteten Lineareinheit, die die nicht gesättigte Aktivierungsfunktion f (x) = max (0, x ) {\textstyle f(x)=\max(0,x} anwendet. Es entfernt effektiv negative Werte aus einer Aktivierungskarte, indem sie auf Null gesetzt werden. Sie führt Nichtlinearitäten der Entscheidungsfunktion und im gesamten Netzwerk ein, ohne die Aufnahmefelder der Faltungsschichten zu beeinflussen. Andere Funktionen können auch verwendet werden, um die Nichtlinearität zu erhöhen, z.B. die sättigende hyperbolische Tangente f ( x ) = tanh ▼ ( x ) {\displaystyle f(x)=\tanh(x} , f (x ) = | tanh LU Vollständig vernetzte Schicht Nach mehreren Faltungs- und Max-Poolierungsschichten erfolgt die abschließende Klassifikation über voll verbundene Schichten. Neuronen in einer vollständig verbundenen Schicht haben Verbindungen zu allen Aktivierungen in der vorherigen Schicht, wie in regelmäßigen (nicht-konvolutionalen) künstlichen neuronalen Netzwerken. Ihre Aktivierungen können somit als Affin-Transformation berechnet werden, mit Matrix-Multiplikation gefolgt von einem Bias-Offset (Vektor-Addition eines gelernten oder festen Biasterms). Verlustschicht Die "Verlustschicht" oder "Verlustfunktion" gibt an, wie das Training die Abweichung zwischen der vorhergesagten Ausgabe des Netzes und den wahren Datenetiketten (während des überwachten Lernens) penalisiert. Je nach Aufgabe können verschiedene Verlustfunktionen verwendet werden. Die Softmax-Verlustfunktion wird verwendet, um eine einzelne Klasse von K gegenseitig exklusive Klassen vorherzusagen. Sigmoid Cross-Entropy-Verlust wird verwendet, um K unabhängige Wahrscheinlichkeitswerte in [0, 1] {\displaystyle [0,1]} vorherzusagen.Euclidean-Verlust wird verwendet, um auf real bewertete Etiketten ( − ∞, ∞ )\displaystyle (\-infty,\infty )} zurückzugreifen. Hyperparameter Hyperparameter sind verschiedene Einstellungen, die zur Steuerung des Lernprozesses verwendet werden. CNNs verwenden mehr Hyperparameter als ein Standard-Multilayer-Perceptron (MLP.) Kernelgröße Der Kernel ist die Anzahl der zusammen verarbeiteten Pixel. Es wird typischerweise als die Abmessungen des Kernels, z.B. 2x2, oder 3x3 ausgedrückt. Padding Padding ist die Zugabe von (typischerweise) 0 bewerteten Pixeln an den Grenzen eines Bildes. Dies geschieht so, dass die Grenzpixel nicht unterschätzt werden (verloren), weil sie gewöhnlich nur an einer einzigen empfänglichen Feldinstanz teilnehmen würden. Das Padding wird typischerweise auf die Kernel-Dimension -1 eingestellt.So würde ein 3x3 Kernel auf allen Seiten des Bildes ein 2-Pixel-Pad erhalten. Str. Der Schritt ist die Anzahl der Pixel, die das Analysefenster bei jeder Iteration bewegt. Ein Schritt von 2 bedeutet, dass jeder Kernel von seinem Vorgänger um 2 Pixel versetzt wird. Anzahl der Filter Da die Kartengröße mit der Tiefe abnimmt, neigen Schichten in der Nähe der Eingangsschicht weniger Filter, während höhere Schichten mehr haben können. Um die Berechnung an jeder Schicht auszugleichen, wird das Produkt der Merkmalswerte va mit Pixelposition über Schichten annähernd konstant gehalten. Die Speicherung von mehr Informationen über die Eingabe würde erfordern, dass die Gesamtanzahl der Aktivierungen (Anzahl der Merkmalskarten mal Anzahl der Pixelpositionen) von einer Schicht zur nächsten nicht abnimmt. Die Anzahl der Feature-Karten steuert die Kapazität direkt und hängt von der Anzahl der verfügbaren Beispiele und Aufgabenkomplexität ab. Die in der Literatur gefundenen gemeinsamen Filtergrößen variieren stark und werden in der Regel anhand des Datensatzes gewählt. Die Herausforderung besteht darin, das richtige Maß an Granularität zu finden, um bei einem bestimmten Datensatz Abstraktionen auf der richtigen Skala zu erstellen und ohne zu übertreffen. Pooling Typ und Größe Max Pooling wird typischerweise verwendet, oft mit einer 2x2 Dimension. Dies bedeutet, dass der Eingang drastisch gesenkt wird, wodurch die Bearbeitungskosten reduziert werden. Große Eingangsvolumina können 4×4 in den unteren Schichten bündeln. Eine größere Bündelung reduziert die Dimension des Signals und kann zu unannehmbaren Informationsverlusten führen. Oft spielen nicht überschneidende Pooling-Fenster am besten. Dilation Dilation beinhaltet ignorierende Pixel innerhalb eines Kernels. Dies reduziert die Verarbeitung/Speicherung potenziell ohne signifikanten Signalverlust. Eine Dilation von 2 auf einem 3x3 Kernel erweitert den Kernel auf 7x7, während noch 9 (gerade) Pixel verarbeitet werden. Dementsprechend erweitert die Dilation von 4 den Kernel auf 15x15. Übersetzung Equivarie Es wird allgemein angenommen, dass CNNs invariant auf Verschiebungen der Eingabe sind. Jedoch sind Faltungs- oder Bündelungsschichten innerhalb eines CNN, die keinen Streifen größer als ein haben, im Gegensatz zu invarianten Übersetzungen der Eingabe gleich. Schichten mit einem Streifen größer als einer ignoriert das Nyquist-Shannon-Samplingtheorem und führt zu einer Aliase des Eingangssignals, das die Äquivarianz (auch als Kovarianz bezeichnet) Eigenschaft bricht. Auch wenn ein CNN vollverbundene Schichten nutzt, bedeutet die Translationsäquivarianz keine Translationsinvarianz, da die vollständig verbundenen Schichten nicht immer auf Verschiebungen des Eingangs stehen. Eine Lösung für die vollständige Übersetzungsinvarianz ist die Vermeidung von Down-Sampling im gesamten Netzwerk und die Anwendung der globalen durchschnittlichen Pooling auf der letzten Ebene. Darüber hinaus wurden mehrere andere Teillösungen vorgeschlagen, wie Anti-Aliasing-, Raumtransformator-Netzwerke, Daten-Augmentation, Subsampling kombiniert mit Pooling und Kapsel-Neural-Netzwerke. Reglementierungsverfahren Reglementierung ist ein Prozess der Einführung zusätzlicher Informationen zur Lösung eines schlechten Problems oder zur Vermeidung von Überbelegung. CNNs verwenden verschiedene Arten von Regularisierung. Empirische Dropout Da eine vollständig verbundene Schicht die meisten Parameter einnimmt, ist sie anfällig zu überrüsten. Ein Verfahren zur Reduzierung des Überfütterungsaufwandes ist ein Ausfall. In jeder Trainingsphase werden einzelne Knoten entweder "ausgetropft" aus dem Netz (ignoriert) mit der Wahrscheinlichkeit 1 - p {\displaystyle 1-p} oder mit der Wahrscheinlichkeit p {\displaystyle p} gehalten, so dass ein reduziertes Netzwerk übrig bleibt; eingehende und ausgehende Kanten an einen ausgefallenen Knoten werden ebenfalls entfernt. In dieser Phase wird nur das reduzierte Netzwerk auf die Daten geschult. Die entfernten Knoten werden dann mit ihren ursprünglichen Gewichten wieder in das Netzwerk eingespeist. In den Trainingsstufen beträgt p {\displaystyle p} in der Regel 0,5; bei Eingabeknoten ist es in der Regel viel höher, weil bei ignorierten Eingabeknoten Informationen direkt verloren gehen. Zum Testzeitpunkt nach Abschluss der Ausbildung möchten wir idealerweise einen Probendurchschnitt aller möglichen 2 n {\displaystyle 2^{n} ausgefallenen Netzwerke finden; leider ist dies für große Werte von n {\displaystyle n} nicht machbar. Allerdings können wir eine Approximation finden, indem man das gesamte Netzwerk mit der Ausgabe jedes Knotens verwendet, die um den Faktor p {\displaystyle p} gewichtet ist, so dass der erwartete Wert der Ausgabe jedes Knotens gleich ist wie in den Trainingsstufen. Dies ist der größte Beitrag der Dropout-Methode: Obwohl es effektiv erzeugt 2 n {\displaystyle 2^{n} neuronal Netze, und als solche ermöglicht Modellkombination, zum Testzeitpunkt muss nur ein einziges Netzwerk getestet werden. Durch das Vermeiden der Ausbildung aller Knoten auf allen Trainingsdaten verringert sich die Ausfallüberholung. Das Verfahren verbessert auch die Trainingsgeschwindigkeit deutlich. Dies macht die Modellkombination auch für tiefe neuronale Netzwerke praktisch. Die Technik scheint Knoteninteraktionen zu reduzieren, was sie dazu führt, robustere Features zu lernen, die sich besser auf neue Daten verallgemeinern. DropConnect DropConnect ist die Verallgemeinerung von Dropout, bei der jede Verbindung anstatt jede Ausgabeeinheit mit der Wahrscheinlichkeit 1 - p {\displaystyle 1-p} abfallen kann. Jede Einheit erhält somit von einer zufälligen Teilmenge von Einheiten in der vorherigen Schicht Eingang. DropConnect ist ähnlich wie Dropout, da es dynamische Sparsität innerhalb des Modells einführt, unterscheidet sich jedoch darin, dass die Sparsität auf den Gewichten liegt, anstatt die Ausgangsvektoren einer Schicht. Mit anderen Worten wird die vollständig verbundene Schicht mit DropConnect zu einer sparsam verbundenen Schicht, in der die Verbindungen während der Trainingsstufe beliebig gewählt werden. Stochastic Pooling Ein großer Nachteil bei Dropout ist, dass es nicht die gleichen Vorteile für Faltungsschichten hat, wo die Neuronen nicht vollständig verbunden sind. Bei der stochastischen Bündelung werden die herkömmlichen deterministischen Pooling-Operationen durch eine stochastische Prozedur ersetzt, bei der die Aktivierung innerhalb jedes Pooling-Gebiets nach einer multinomialen Verteilung, gegeben durch die Aktivitäten innerhalb des Pooling-Gebiets, zufällig abgegriffen wird. Dieser Ansatz ist frei von Hyperparametern und kann mit anderen Regularisierungsansätzen kombiniert werden, wie z.B. Dropout und Datenvergrößerung. Eine alternative Ansicht der stochastischen Pooling ist, dass es dem Standard-Max-Pooling entspricht, aber mit vielen Kopien eines Eingabebildes, jede mit kleinen lokalen Verformungen. Dies ist ähnlich wie explizite elastische Verformungen der Eingabebilder, die eine hervorragende Leistung auf dem MNIST-Datensatz liefert. Durch die Verwendung der stochastischen Verklebung in einem Mehrschichtmodell ergibt sich eine exponentielle Anzahl von Verformungen, da die Auswahlen in höheren Schichten unabhängig von den nachstehenden sind. Künstliche Daten Da der Grad der Modellüberarbeitung sowohl durch seine Leistung als auch durch die Höhe der von ihm erhaltenen Ausbildung bestimmt wird, kann die Bereitstellung eines Faltungsnetzes mit mehr Ausbildungsbeispielen die Überarbeitung reduzieren. Da diese Netzwerke in der Regel mit allen verfügbaren Daten trainiert werden, ist ein Ansatz, entweder neue Daten von Grund auf (sofern möglich) zu generieren oder bestehende Daten zu erfassen, um neue zu erstellen. Beispielsweise können Eingabebilder geerntet, gedreht oder neu skaliert werden, um neue Beispiele mit den gleichen Labels wie das Original-Trainingsset zu erstellen. Explice Early Stopp Eines der einfachsten Methoden, um eine Überrüstung eines Netzes zu verhindern, ist es, das Training einfach zu stoppen, bevor eine Überarbeitung eine Chance hatte. Nachteilig ist, dass der Lernprozess gestoppt wird. Anzahl der Parameter Eine weitere einfache Möglichkeit, eine Überrüstung zu verhindern, besteht darin, die Anzahl der Parameter zu begrenzen, typischerweise durch Begrenzung der Anzahl der versteckten Einheiten in jeder Schicht oder Begrenzung der Netztiefe. Für Faltungsnetze wirkt sich die Filtergröße auch auf die Anzahl der Parameter aus. Die Begrenzung der Anzahl der Parameter begrenzt die Prädiktionsleistung des Netzes direkt, wodurch die Komplexität der Funktion, die sie auf den Daten ausführen kann, reduziert und damit die Überarbeitungsmenge begrenzt wird.Dies entspricht einer "Nullnorm". Eine einfache Form des hinzugefügten Regularizers ist Gewichtsabnahme, die einfach einen zusätzlichen Fehler, proportional zur Summe der Gewichte (L1-Norm) oder quadratische Größe (L2-Norm) des Gewichtsvektors, zum Fehler an jedem Knoten addiert. Die Höhe der akzeptablen Modellkomplexität kann durch die Erhöhung der Proportionalitätskonstante ('alpha Hyperparameter') reduziert werden, wodurch die Strafe für große Gewichtsvektoren erhöht wird. L2 Regularisierung ist die häufigste Form der Regularisierung. Sie kann durch die Straffung der quadratischen Größe aller Parameter direkt im Objektiv realisiert werden. Die L2 Regularisierung hat die intuitive Interpretation von stark penalisierenden Spitzengewichtsvektoren und bevorzugt diffuse Gewichtsvektoren. Durch multiplikative Interaktionen zwischen Gewichten und Eingängen hat dies die nützliche Eigenschaft, das Netzwerk zu ermutigen, alle seine Eingänge ein wenig anstatt einige seiner Eingänge viel zu verwenden. Die L1-Regulierung ist ebenfalls üblich. Es macht die Gewichtsvektoren sparsam bei der Optimierung. Mit anderen Worten, Neuronen mit L1 Regularisierung enden mit nur einer spärlichen Teilmenge ihrer wichtigsten Inputs und werden fast invariant zu den lauten Inputs. L1 mit L2 Regularisierung kann kombiniert werden; dies wird Elastic net Regularization genannt. Max norm Zwänge Eine andere Form der Regularisierung besteht darin, für jedes Neuron eine absolute obere Grenze für die Größe des Gewichtsvektors durchzusetzen und projizierte Gradientenabstieg zur Durchsetzung der Strenge zu verwenden. In der Praxis entspricht dies der Ausführung des Parameter-Updates als normal, und dann die Begrenzung durch Klemmen des Gewichtsvektors w → {\displaystyle {\vec {w} jedes Neurons zu erfüllen w → gefunden 2 < c {\displaystyle {\vec w}\|\|_{2}{2}c .Typische Werte von c{\displaystyle c} sind in der Reihenfolge von 3–4. Einige Papiere berichten Verbesserungen bei der Verwendung dieser Form der Regularisierung. Hierarchische Koordinatenrahmen Pooling verliert die präzisen räumlichen Zusammenhänge zwischen hochrangigen Teilen (wie Nase und Mund in einem Gesichtsbild). Diese Beziehungen werden zur Identitätserkennung benötigt. Überlappung der Pools, so dass jede Funktion in mehreren Pools auftritt, hilft, die Informationen zu behalten. Die Übersetzung allein kann das Verständnis geometrischer Zusammenhänge nicht auf einen radikal neuen Blickpunkt, wie eine andere Orientierung oder Skala, extrapolieren. Auf der anderen Seite sind die Menschen sehr gut zu extrapolieren; nach einer neuen Form zu sehen, sobald sie sie aus einem anderen Blickwinkel erkennen können. Ein früher häufiger Umgang mit diesem Problem ist, das Netzwerk auf transformierten Daten in verschiedenen Orientierungen, Skalen, Beleuchtung usw. so zu trainieren, dass das Netzwerk mit diesen Variationen umgehen kann. Dies ist für große Datenmengen rechnerisch intensiv. Die Alternative besteht darin, eine Hierarchie von Koordinatenrahmen zu verwenden und eine Gruppe von Neuronen zu verwenden, um eine Konjunktion der Form des Merkmals und seiner Pose relativ zur Netzhaut darzustellen. Die Pose relativ zur Netzhaut ist die Beziehung zwischen dem Koordinatenrahmen der Netzhaut und dem intrinsischen Merkmale' Koordinatenrahmen. So ist eine Möglichkeit, etwas darzustellen, darin den Koordinatenrahmen einzubetten. Dadurch können große Merkmale erkannt werden, indem die Konsistenz der Posen ihrer Teile verwendet wird (z.B. Nase und Mund Posen machen eine konsistente Vorhersage der Pose des ganzen Gesichts). Dieser Ansatz stellt sicher, dass die übergeordnete Einheit (z.B. Gesicht) vorhanden ist, wenn die untere Ebene (z.B. Nase und Mund) auf ihre Vorhersage der Pose zustimmen. Die Vektoren der neuronalen Aktivität, die Pose repräsentieren ("Pee-Vektoren") erlauben räumliche Transformationen, die als lineare Operationen modelliert werden, die es dem Netzwerk erleichtern, die Hierarchie von visuellen Wesen zu erlernen und über Sichtpunkte zu verallgemeinern. Dies ist ähnlich wie das menschliche visuelle System Koordinatenrahmen aufzwingt, um Formen darzustellen. Anwendungen Bilderkennung CNNs werden häufig in Bilderkennungssystemen verwendet. 2012 wurde eine Fehlerquote von 0,23 % auf der MNIST-Datenbank gemeldet. Ein weiteres Papier über die Verwendung von CNN für die Bildklassifikation berichtete, dass der Lernprozess "überraschend schnell" war; in demselben Papier wurden die am besten veröffentlichten Ergebnisse ab 2011 in der MNIST-Datenbank und der NORB-Datenbank erreicht. Anschließend gewann ein ähnliches CNN namens AlexNet die ImageNet Large Scale Visual Recognition Challenge 2012. Bei Anwendung auf die Gesichtserkennung erzielte CNN eine große Abnahme der Fehlerrate. Ein weiteres Papier berichtete über eine Erkennungsrate von 97,6% auf "5,600 noch Bilder von mehr als 10 Themen". CNNs wurden verwendet, um die Videoqualität nach der manuellen Ausbildung objektiv zu bewerten; das resultierende System hatte einen sehr niedrigen wurzelförmigen mittleren quadratischen Fehler. Die ImageNet Large Scale Visual Recognition Challenge ist ein Benchmark in der Objektklassifizierung und -erkennung, mit Millionen von Bildern und Hunderten von Objektklassen. Im ILSVRC 2014 hat fast jedes hochrangige Team CNN als Grundgerüst eingesetzt. Der Sieger GoogLeNet (die Basis von DeepDream) erhöhte die mittlere durchschnittliche Genauigkeit der Objekterkennung auf 0,439329 und reduzierte Klassifizierungsfehler auf 0,06656, das beste Ergebnis bis heute. Sein Netzwerk hat mehr als 30 Schichten aufgebracht. Diese Leistung von konvolutionalen neuronalen Netzwerken auf den ImageNet-Tests lag nahe bei der des Menschen. Die besten Algorithmen kämpfen noch mit Objekten, die klein oder dünn sind, wie eine kleine Ameise auf einem Stamm einer Blume oder einer Person, die eine Quill in ihrer Hand hält. Sie haben auch Probleme mit Bildern, die mit Filtern verzerrt wurden, ein immer häufigeres Phänomen mit modernen Digitalkameras. Im Gegensatz dazu beunruhigen diese Bilder selten Menschen. Menschen neigen jedoch dazu, Probleme mit anderen Problemen zu haben. Zum Beispiel sind sie nicht gut, Objekte in feinkörnige Kategorien wie die jeweilige Rasse von Hund oder Vogelarten einzuordnen, während Falten-Neural-Netzwerke diese behandeln. Im Jahr 2015 zeigte ein vielschichtiger CNN die Fähigkeit, Gesichter aus einer breiten Palette von Winkeln zu erkennen, einschließlich auf dem Boden, auch wenn teilweise eingeschlossen, mit wettbewerbsfähiger Leistung. Das Netzwerk wurde auf einer Datenbank von 200.000 Bildern ausgebildet, die Gesichter unter verschiedenen Winkeln und Orientierungen und weitere 20 Millionen Bilder ohne Gesichter enthalten. Sie verwendet Chargen von 128 Bildern über 50.000 Iterationen. Videoanalyse Im Vergleich zu Bilddatendomänen gibt es relativ wenig Arbeit, CNNs auf Videoklassifikation anzuwenden. Video ist komplexer als Bilder, da es eine andere (temporale) Dimension hat. Allerdings wurden einige Erweiterungen von CNNs in die Video-Domäne erforscht. Ein Ansatz ist, Raum und Zeit als gleichwertige Dimensionen der Eingabe zu behandeln und Faltungen in Zeit und Raum durchzuführen. Eine andere Möglichkeit besteht darin, die Merkmale zweier konvolutionaler neuronaler Netze, eines für den Raum und eines für den zeitlichen Strom, zu verschmelzen. Lange Kurzzeitspeicher (LSTM)-Rezidiveinheiten werden typischerweise nach dem CNN eingebaut, um Interframe- oder Inter-Clip-Abhängigkeiten zu berücksichtigen. Unsupervised Lernprogramme für die Ausbildung von Spatio-Temporal-Funktionen wurden eingeführt, basierend auf Convolutional Gated Restricted Boltzmann Machines und Independent Subspace Analysis. Natürliche Sprachverarbeitung CNNs wurden auch für die natürliche Sprachverarbeitung untersucht. CNN-Modelle sind für verschiedene NLP-Probleme wirksam und haben hervorragende Ergebnisse bei semantischen Parsing-, Suchabfrage-Retrieval-, Satzmodellierung, Klassifizierung, Vorhersage und anderen traditionellen NLP-Aufgaben erzielt. Anomaly Detection A CNN mit 1-D-Konvolutionen wurde auf Zeitreihen im Frequenzbereich (spektraler Rest) von einem nicht überwachten Modell zur Detektion von Anomalien im Zeitbereich verwendet. Drogenentdeckung CNNs wurden in der Drogenentdeckung verwendet. Die Vorhersage der Wechselwirkung zwischen Molekülen und biologischen Proteinen kann potenzielle Behandlungen identifizieren. Im Jahr 2015, Atomwise eingeführt AtomNet, das erste Deep Learning-Neural-Netzwerk für strukturbasierte rationale Drogendesign. Das System trainiert direkt auf 3-dimensionale Darstellungen chemischer Wechselwirkungen. Wie Bilderkennungsnetzwerke lernen, kleinere, räumlich proximierte Eigenschaften in größere, komplexe Strukturen zu komponieren, entdeckt AtomNet chemische Eigenschaften wie Aromatizität, sp3 Kohlenstoffe und Wasserstoffbindung. Anschließend wurde AtomNet verwendet, um neue Kandidaten-Biomoleküle für multiple Krankheitsziele, insbesondere Behandlungen für das Ebola-Virus und Multiple Sklerose vorherzusagen. Gesundheitsrisikobewertung und Biomarker von alternden Entdeckungen CNNs können selbstverständlich auf eine ausreichend große Sammlung von Zeitreihendaten zugeschnitten werden, die einwöchige menschliche körperliche Aktivitätsströme darstellen, die von den reichen klinischen Daten (einschließlich des Todesregisters, wie z.B. der NHANES-Studie, erweitert werden). Ein einfaches CNN wurde mit dem Cox-Gompertz-Proportional-Risikomodell kombiniert und verwendet, um ein Nachweisbeispiel für digitale Biomarker von Alterung in Form von All-Causes-Morgen-Vorhersage zu erstellen. Checkers Spiel CNNs wurden im Spiel der Checkers verwendet. Von 1999 bis 2001 veröffentlichten Fogel und Chellapilla Papiere, in denen gezeigt wurde, wie ein konvolutionales neuronales Netz mit Co-Evolution den Checker spielen kann. Der Lernprozess nutzte keine vorherigen menschlichen professionellen Spiele, sondern konzentrierte sich auf eine minimale Menge von Informationen im Checkerboard enthalten: die Lage und Art der Stücke, und die Differenz in der Anzahl der Stücke zwischen den beiden Seiten. Letztlich wurde das Programm (Blondie24) auf 165 Spiele gegen Spieler getestet und in den höchsten 0,4% rangiert. Es hat auch einen Sieg gegen das Programm Chinook auf seiner fachlichen Ebene des Spiels verdient. Go CNNs wurden im Computer verwendet Go.Im Dezember 2014, Clark und Storkey veröffentlichte ein Papier, das zeigt, dass ein CNN trainiert durch beaufsichtigtes Lernen aus einer Datenbank der menschlichen professionellen Spiele könnte übertreffen GNU Go und gewinnen einige Spiele gegen Monte Carlo Baum Suche Fuego 1.1 in einem Bruchteil der Zeit, die Fuego zu spielen. Später wurde bekannt gegeben, dass ein großes 12-lagiges konvolutionales neuronales Netz die berufliche Bewegung in 55% der Positionen korrekt vorhergesagt hatte, was der Genauigkeit eines 6-Dan-Menschenspielers entspricht. Als das geschulte Faltungsnetzwerk direkt verwendet wurde, um Spiele von Go zu spielen, ohne jede Suche, es schlug das traditionelle Suchprogramm GNU Go in 97 % der Spiele, und entsprach die Leistung des Monte Carlo Baum-SuchprogrammFuego simuliert zehntausend Playouts (ca. eine Million Positionen) pro Bewegung. Ein paar CNNs für die Auswahl von Schritten zu versuchen ("policy network") und die Bewertung von Positionen ("value network"), die MCTS fahren, wurden von AlphaGo verwendet, der erste, der den besten menschlichen Spieler zu dieser Zeit schlägt. Zeitreihenprognose Recurrent neural networks werden in der Regel als die besten neuralen Netzwerkarchitekturen für Zeitreihenprognose (und Sequenzmodellierung im Allgemeinen) betrachtet, aber die letzten Studien zeigen, dass konvolutionale Netzwerke vergleichbar oder sogar besser funktionieren können. Dilierte Konvolutionen können eindimensionale konvolutionale neuronale Netzwerke ermöglichen, die Abhängigkeiten der Zeitreihen effektiv zu erlernen. Konvolutionen können effizienter umgesetzt werden als RNN-basierte Lösungen, und sie leiden nicht unter verschwindenden (oder explodierenden) Gradienten. Konvolutionale Netzwerke können eine verbesserte Prognoseleistung bieten, wenn es mehrere ähnliche Zeitreihen zum Lernen gibt. CNNs können auch auf weitere Aufgaben in der Zeitreihenanalyse angewendet werden (z.B. Zeitreihenklassifikation oder Quantenprognose). Kulturerbe und 3D-Datensätze Da archäologische Funde wie Clay-Tabletten mit Cuneiform-Schreiben zunehmend durch 3D-Scanner erfasst werden, werden erste Benchmark-Datensätze wie HeiCuBeDa zur Verfügung gestellt, die fast 2.000 normalisierte 2D- und 3D-Datensätze mit dem GigaMesh Software Framework bereitstellt. So werden krümmungsbasierte Maßnahmen in Verbindung mit geometrischen Neural Networks (GNNs) verwendet, z.B. für die Periodenklassifizierung dieser Tontabletten, die zu den ältesten Dokumenten der Menschheitsgeschichte gehören. Feinabstimmung Für viele Anwendungen sind die Trainingsdaten weniger verfügbar. Konvolutionelle neuronale Netzwerke erfordern in der Regel eine große Anzahl von Trainingsdaten, um Überbelegung zu vermeiden. Eine gemeinsame Technik ist es, das Netzwerk auf einem größeren Datensatz aus einer verwandten Domain zu trainieren. Sobald die Netzwerkparameter einen zusätzlichen Trainingsschritt mit den in-Domain-Daten zur Feinabstimmung der Netzwerkgewichte durchgeführt haben, wird dies als Transfer-Learning bezeichnet. Darüber hinaus ermöglicht diese Technik die erfolgreiche Anwendung von konvolutionalen Netzwerkarchitekturen auf Probleme mit kleinen Trainingseinheiten. Menschen interpretierbare Erklärungen End-to-End-Training und Vorhersage sind häufig in der Computer-Vision. Für kritische Systeme, wie z.B. selbstfahrende Autos, sind jedoch menschliche interpretierbare Erklärungen erforderlich. Mit den jüngsten Fortschritten in der visuellen Salience, der räumlichen und zeitlichen Aufmerksamkeit konnten die kritischsten räumlichen Regionen/Zeitpunkte visualisiert werden, um die CNN-Vorhersage zu rechtfertigen. Ähnliche Architekturen Deep Q-Netzwerke Ein tiefes Q-Netzwerk (DQN) ist eine Art tiefes Lernmodell, das ein tiefes neuronales Netzwerk mit Q-Lernen kombiniert, eine Form von Verstärkungslernen. Anders als bei früheren Verstärkungslernern können DQNs, die CNN verwenden, direkt von hochdimensionalen sensorischen Eingaben über Verstärkungslernen lernen. Vorläufige Ergebnisse wurden 2014 mit einem Begleitpapier im Februar 2015 vorgestellt. Die Forschung beschreibt eine Anwendung auf Atari 2600 Gaming. Andere Tiefenverstärkung Lernmodelle vor ihm. Deep-Glaube-Netzwerke Convolutional Deep-Glaube-Netzwerke (CDBN) haben Struktur sehr ähnlich zu konvolutionalen neuronalen Netzwerken und werden ähnlich wie tiefe Glaubensnetzwerke ausgebildet. Daher nutzen sie die 2D-Struktur von Bildern, wie CNNs tun, und nutzen Pre-Training wie Deep-Glaube-Netzwerke. Sie bieten eine generische Struktur, die in vielen Bildverarbeitungs- und Signalverarbeitungsaufgaben verwendet werden kann. Benchmark-Ergebnisse auf Standard-Bilddatensätzen wie CIFAR wurden mit CDBNs gewonnen. Notwendige Bibliotheken Koffein: Eine Bibliothek für konvolutionale neuronale Netze. Erstellt vom Berkeley Vision and Learning Center (BVLC). Es unterstützt sowohl CPU als auch GPU. Entwickelt in C,+ und hat Python- und MATLAB-Wrappers. Deeplearning4j:Deep Learning in Java und Scala auf multi-GPU-fähigen Spark. Eine universelle Deep-Learning-Bibliothek für den JVM-Produktionsstapel, der auf einem C+-Wissenschaftsrechner läuft. Ermöglicht die Erstellung von benutzerdefinierten Schichten. Integriert mit Hadoop und Kafka. Dlib:Ein Toolkit für die Herstellung von realen Anwendungen für maschinelles Lernen und Datenanalyse in C++. Microsoft Cognitive Toolkit: Ein Deep Learning Toolkit von Microsoft mit mehreren einzigartigen Funktionen, die die Skalierbarkeit über mehrere Knoten verbessern. Es unterstützt vollwertige Schnittstellen für das Training in C+ und Python und mit zusätzlicher Unterstützung für Modellinterferenz in C# und Java. TensorFlow: Apache 2.0-lizenziert Theano-ähnliche Bibliothek mit Unterstützung für CPU, GPU, Googles proprietäre Tensor-Verarbeitungseinheit (TPU) und mobile Geräte. Theano:Die Referenz-TiefLearning-Bibliothek für Python mit einer API weitgehend kompatibel mit der beliebten NumPy-Bibliothek. Erlaubt dem Benutzer, symbolische mathematische Ausdrücke zu schreiben, erzeugt dann automatisch ihre Derivate und speichert den Benutzer davor, Gradienten oder Backpropagation zu kodieren. Diese symbolischen Ausdrücke werden automatisch auf CUDA-Code für eine schnelle, on-the-GPU-Implementierung kompiliert. Torch: Ein wissenschaftlicher Rechenrahmen mit breiter Unterstützung für maschinelle Lernalgorithmen, geschrieben in C und Lua. Der Hauptautor ist Ronan Collobert und wird nun bei Facebook AI Research und Twitter verwendet. Notable APIs Keras: Eine hochrangige API geschrieben in Python für TensorFlow und Theano konvolutionale neuronalen Netzwerke. Siehe auch Achtung (Maschinenlernen)ConvolutionDeep Learning Natürliche Sprachverarbeitung Neocognitron Scale-invariant Feature-Transformation Zeitverzögerung neuronales Netz Vision-Verarbeitungseinheit Hinweise Externe Links CS231n: Convolutional Neural Networks for Visual Recognition — Andrej Karpathy's Stanford Informatikkurs auf CNNs in der Computervision Eine intuitive Erklärung von konvolutionalen neuronalen Netzwerken — Ein Einstieg in das, was Convolutional Neural Networks sind und wie sie Convolutional Neural Networks for Image Classification — Literaturerhebung