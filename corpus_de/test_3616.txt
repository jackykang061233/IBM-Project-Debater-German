Logische Programmierung ist ein Programmierparadigma, das weitgehend auf formaler Logik basiert. Jedes in einer logischen Programmiersprache geschriebene Programm ist eine Reihe von Sätzen in logischer Form, die Fakten und Regeln über einige Problemdomäne ausdrücken. Zu den wichtigsten Sprachfamilien der logischen Programmierung gehören Prolog, Antwortset-Programmierung (ASP) und Datalog. In allen diesen Sprachen sind Regeln in Form von Klauseln geschrieben: H : B1, ... Bn.and werden als logische Implikationen deklarativ gelesen: H wenn B1 und... und Bn.H als Leiter der Regel und B1, ..., Bn wird den Körper genannt. Fakten sind Regeln, die keinen Körper haben und in vereinfachter Form geschrieben werden: H. Im einfachsten Fall, in dem H, B1,...Bn alle atomaren Formeln sind, werden diese Klauseln als bestimmte Klauseln oder Horn-Klausel bezeichnet. Es gibt jedoch viele Erweiterungen dieses einfachen Falles, wobei die wichtigste der Fall ist, bei dem Bedingungen im Körper einer Klausel auch Negationen von atomaren Formeln sein können. Logische Programmiersprachen, die diese Erweiterung enthalten, haben die Fähigkeiten der Wissensdarstellung einer nicht-monotonischen Logik. In ASP und Datalog haben Logikprogramme nur eine deklarative Lektüre und ihre Ausführung erfolgt mittels eines Proof-Verfahrens oder Modellgenerators, dessen Verhalten nicht vom Programmierer gesteuert werden soll. In der Prolog-Sprachenfamilie haben Logikprogramme jedoch auch eine Verfahrensinterpretation als Zielreduktionsverfahren: H zu lösen, B1 zu lösen und Bn.Consider die folgende Klausel als Beispiel: fallible(X) :- human(X) basierend auf einem von Terry Winograd verwendeten Beispiel zur Veranschaulichung der Programmiersprache Planner. Als Klausel in einem Logikprogramm kann sowohl als Prozedur geprüft werden, ob X durch Testen, ob X Mensch ist, als auch als Prozedur ein X gefunden werden kann, das durch Auffinden eines Xs, das Mensch ist, unterbleibbar ist. Selbst Fakten haben eine verfahrenstechnische Interpretation. Zum Beispiel die Klausel: human(socrates). kann sowohl als Verfahren verwendet werden, um zu zeigen, dass Sokrates Mensch ist, als auch als Verfahren, um ein X zu finden, das durch die Zuordnung von Sokrates zu X menschlich ist. Das deklarative Lesen von Logikprogrammen kann von einem Programmierer verwendet werden, um ihre Richtigkeit zu überprüfen. Darüber hinaus können Logik-basierte Programmtransformationstechniken auch verwendet werden, um Logikprogramme in logisch äquivalente Programme zu transformieren, die effizienter sind. In der Prolog-Familie von logischen Programmiersprachen kann der Programmierer auch das bekannte Problemlöseverhalten des Ausführungsmechanismus zur Verbesserung der Effizienz von Programmen verwenden. Geschichte Die Verwendung mathematischer Logik zur Darstellung und Durchführung von Computerprogrammen ist auch ein Merkmal des Lambda-Kalkus, entwickelt von Alonzo Kirche in den 1930er Jahren. Der erste Vorschlag, die klausale Form der Logik für die Darstellung von Computerprogrammen zu verwenden, wurde von Cordell Green gemacht. Dies nutzte eine Axiomatisierung einer Teilmenge von LISP zusammen mit einer Darstellung einer Input-Output-Beziehung, um die Relation durch Simulation der Ausführung des Programms in LISP zu berechnen. Foster und Elcock's Absys hingegen setzten eine Kombination aus Gleichungen und Lambda-Calculus in einer durchsetzungsorientierten Programmiersprache ein, die keine Einschränkungen auf die Reihenfolge, in der Operationen durchgeführt werden, legt. Logische Programmierung in seiner jetzigen Form kann auf Debatten in den späten 1960er und frühen 1970er Jahren über deklarative versus verfahrensbezogene Darstellungen von Wissen in der künstlichen Intelligenz zurückverfolgt werden. Advokate deklarativer Repräsentationen arbeiteten insbesondere an Stanford, verbunden mit John McCarthy, Bertram Raphael und Cordell Green, und in Edinburgh, mit John Alan Robinson (ein akademischer Besucher der Syrakus-Universität), Pat Hayes und Robert Kowalski. Die Befürworter der Verfahrensvertretung konzentrierten sich hauptsächlich auf das MIT unter der Leitung von Marvin Minsky und Seymour Papert. Obwohl es auf den Beweismethoden der Logik basierte, war Planner, entwickelt am MIT, die erste Sprache, die in diesem prozeduralistischen Paradigma auftauchte. Der Planer verfügte über eine mustergerichtete Invokation von Verfahrensplänen aus Zielen (d.h. Torreduktion oder Rückketten) und aus Behauptungen (d.h. Vorwärtsketten). Die einflussreichste Umsetzung von Planner war die Untergruppe von Planner, genannt Micro-Planner, umgesetzt von Gerry Sussman, Eugene Charniak und Terry Winograd. Es wurde verwendet, um Winograds natürlichsprachiges Verständnis Programm SHRDLU zu implementieren, das damals ein Wahrzeichen war. Um die damals sehr begrenzten Speichersysteme zu bewältigen, benutzte Planner eine Rückverfolgungs-Steuerstruktur, so dass nur ein möglicher Rechenpfad zu einem Zeitpunkt gespeichert werden musste. Planner gab die Programmiersprachen QA-4, Popler, Conniver, QLISP und die gleichzeitige Sprache Ether an. Hayes und Kowalski in Edinburgh versuchten, den logischen deklarativen Ansatz der Wissensvertretung mit Planners Verfahrensansatz zu vereinbaren. Hayes (1973) entwickelte eine Gleichungssprache, Golux, in der verschiedene Verfahren durch Veränderung des Verhaltens des Theorem-Provers erhalten werden konnten. Kowalski hingegen entwickelte die SLD-Auflösung, eine Variante der SL-Resolution und zeigte, wie sie Auswirkungen als zielreduzierende Verfahren behandelt. Kowalski arbeitete mit Colmerauer in Marseille zusammen, die diese Ideen in der Gestaltung und Umsetzung der Programmiersprache Prolog entwickelt. Die Association for Logic Programming wurde 1986 gegründet, um Logic Programming zu fördern. Prolog gab die Programmiersprachen ALF, Fril, Gödel, Mercury, Oz, Ciao, Visual Prolog, XSB und λProlog an, sowie eine Vielzahl von gleichzeitigen logischen Programmiersprachen, konstraktiven Programmiersprachen und Datalog. Concepts Logic und Control Logic-Programmierung kann als gesteuerter Abzug betrachtet werden. Ein wichtiges Konzept in der logischen Programmierung ist die Trennung von Programmen in ihre Logikkomponente und ihre Steuerkomponente. Mit reinen logischen Programmiersprachen bestimmt die Logikkomponente allein die erzeugten Lösungen. Die Steuerkomponente kann variiert werden, um alternative Wege zur Ausführung eines Logikprogramms bereitzustellen. Dieser Begriff wird durch den Slogan Algorithm = Logic + Controlwhere Logic ein Logikprogramm darstellt und Control verschiedene theorem-proving-Strategien repräsentiert. Problemlösung Im vereinfachten, propositionalen Fall, bei dem ein Logikprogramm und ein hochrangiges Atomziel keine Variablen enthalten, bestimmt rückwärtsgerichtetes Denken einen und-oder Baum, der den Suchraum zur Lösung des Ziels darstellt. Das oberste Ziel ist die Wurzel des Baumes. Bei jedem Knoten im Baum und jeder Klausel, deren Kopf mit dem Knoten übereinstimmt, gibt es eine Reihe von Kinderknoten, die den Untergängen im Körper der Klausel entsprechen. Diese Child-Knoten werden durch ein und" zusammengefasst. Die alternativen Sätze von Kindern, die alternativen Möglichkeiten zur Lösung des Knotens entsprechen, werden durch ein oder" zusammengefaßt. Jede Suchstrategie kann verwendet werden, um diesen Raum zu suchen. Prolog verwendet eine sequentielle, letzte-in-first-out-, Backtracking-Strategie, in der nur eine Alternative und ein Sub-Goal zu einem Zeitpunkt betrachtet wird. Auch andere Suchstrategien, wie Parallelsuche, intelligente Rückverfolgung oder Best-First-Suche, um eine optimale Lösung zu finden, sind möglich. Im allgemeinen Fall, in dem Sub-Galerie-Aktien-Variablen teilen, können andere Strategien verwendet werden, wie die Wahl des Subgoals, das am meisten instantiiert ist oder das ausreichend instantiiert ist, so dass nur ein Verfahren gilt. Solche Strategien werden beispielsweise in der gleichzeitigen Logik-Programmierung verwendet. Verhandlungen als Versagen Für die meisten praktischen Anwendungen, sowie für Anwendungen, die nicht-monotone Argumentation in der künstlichen Intelligenz erfordern, müssen Horn-Klausel-Logikprogramme auf normale Logikprogramme erweitert werden, mit negativen Bedingungen. Eine Klausel in einem normalen Logikprogramm hat die Form: H : A1, ..., An, not B1, ..., nicht Bn und wird als logische Implikation deklarativ gelesen: H wenn A1 und ... und An und nicht B1 und ... und nicht Bn.where H und alle Ai und Bi Atomformeln sind. Die Negation in den Negativbuchstaben nicht Bi wird häufig als "Negation als Ausfall" bezeichnet, weil in den meisten Implementierungen eine negative Bedingung nicht Bi gezeigt wird, durch zu zeigen, dass die positive Bedingung Bi nicht zu halten. Zum Beispiel: Angesichts des Ziels, etwas zu finden, das fliegen kann: Es gibt zwei Kandidatenlösungen, die den ersten Subgoalvogel (X) lösen, nämlich X = john und X = mary. Das zweite Subgoal nicht abnormal(john) der ersten Kandidatenlösung scheitert, weil verwundet(john) erfolgreich ist und daher abnormal(john) erfolgreich ist. Das zweite Subgoal, das nicht anormal (Mary) der zweiten Kandidatenlösung ist, gelingt jedoch, weil verwundet(mary) ausfällt und daher abnormal(mary) ausfällt. Daher ist X = mary die einzige Lösung des Ziels. Micro-Planner hatte ein Konstrukt namens thnot, das bei Anwendung auf einen Ausdruck den Wert true zurückgibt, wenn (und nur, wenn) die Auswertung des Ausdrucks ausfällt. Ein gleichwertiger Bediener existiert in der modernen Prolog-Implementierung. Es wird in der Regel als nicht(Goal) oder \+ Goal geschrieben, wo Goal ist ein Ziel (Bestellung) durch das Programm nachgewiesen werden. Dieser Operator unterscheidet sich von der Negation in der First-Ordner-Logik: eine Negation wie \+ X == 1 fehlschlägt, wenn die Größe X an das Atom 1 gebunden ist, aber es gelingt in allen anderen Fällen, auch wenn X nicht gebunden ist. Das macht Prologs Argumentation non-monotonic: X = 1, \+ X==1 scheitert immer, während \+ X == 1, X = 1 erfolgreich sein kann, X bis 1 bindend, je nachdem, ob X ursprünglich gebunden war (Anmerkung, dass Standard Prolog Ziele in links-rechts Reihenfolge ausführt). Der logische Status der Negation als Misserfolg wurde ungelöst, bis Keith Clark [1978] zeigte, dass es unter bestimmten natürlichen Bedingungen eine korrekte (und manchmal vollständige) Implementierung der klassischen Negation in Bezug auf die Vollendung des Programms ist. Der Abschluss entspricht etwa dem Satz aller Programmklauseln mit dem gleichen Prädikat auf der linken Seite, sagen H:- Body1. ... H : Bodyk.as eine Definition des Prädikats H iff (Body1 oder ... oder Bodyk), wo iff "wenn und nur wenn" bedeutet. Das Schreiben der Fertigstellung erfordert auch eine ausdrückliche Verwendung des Prädikats der Gleichheit und die Aufnahme eines Satzes geeigneter Äxt für Gleichheit. Allerdings braucht die Umsetzung von Negation als Misserfolg nur die if-halves der Definitionen ohne die Axiome der Gleichheit. Zum Beispiel ist der Abschluss des obigen Programms: canfly(X)iff bird(X), nicht abnormal(X).abnormal(X iff Wunded(X.) bird(X)iff X = john oder X = mary. X=X. nicht john = mary. not mary = john. Der Begriff der Fertigstellung ist eng mit McCarthys Umschreibungssemantik aus der Standardvernunft und der geschlossenen Weltannahme verbunden. Alternativ zur Fertigstellungssemantik kann auch die Negation als Ausfall epistemisch interpretiert werden, wie in der stabilen Modellsemantik der Antwortset-Programmierung. In dieser Interpretation bedeutet nicht(Bi) buchstäblich, dass Bi nicht bekannt oder nicht geglaubt ist. Die epistemische Interpretation hat den Vorteil, dass sie sehr einfach mit klassischer Negation kombiniert werden kann, wie in "erweiterte Logik-Programmierung", solche Phrasen wie "das Gegenteil kann nicht gezeigt werden", wo im Gegensatz ist klassische Negation und "kann nicht gezeigt werden" ist die epistemische Interpretation von Negation als Versagen. Wissensdarstellung Die Tatsache, dass Horn-Klausel eine verfahrensmäßige Interpretation gegeben werden können und umgekehrt, dass zielreduzierende Verfahren als Horn-Klausel + rückständige Argumentation verstanden werden können, bedeutet, dass Logikprogramme declarative und verfahrensbezogene Darstellungen von Wissen kombinieren. Die Einbindung von Negation als Ausfall bedeutet, dass die logische Programmierung eine Art nicht-monotonische Logik ist. Trotz seiner Einfachheit gegenüber der klassischen Logik hat sich diese Kombination von Horn-Klausel und Negation als Versagen als überraschend expressiv erwiesen. Zum Beispiel gibt es eine natürliche Darstellung für die gängigen Ursachen- und Wirkungsgesetze, die sowohl von der Situationsrechnung als auch von der Ereignisrechnung formalisiert wird. Es wurde auch gezeigt, dass es ganz natürlich der halbformalen Rechtssprache entspricht. Insbesondere würdigen Prakken und Sartor die Darstellung des britischen Nationalitätsgesetzes als logisches Programm, das "einflussreich für die Entwicklung von rechnerischen Darstellungen von Rechtsvorschriften ist, zeigt, wie die Logik-Programmierung intuitiv ansprechende Darstellungen ermöglicht, die direkt zur Erzeugung automatischer Inferenzen eingesetzt werden können." Varianten und Erweiterungen Prolog Die Programmiersprache Prolog wurde 1972 von Alain Colmerauer entwickelt. Es entstand aus einer Zusammenarbeit zwischen Colmerauer in Marseille und Robert Kowalski in Edinburgh. Colmerauer arbeitete an der natürlichen Sprachverständigung, nutzte Logik, um die Semantik zu repräsentieren und die Lösung für Fragen zu verwenden. Im Sommer 1971 entdeckten Colmerauer und Kowalski, dass die klausale Form der Logik verwendet werden könnte, um formale Grammatiken zu repräsentieren, und dass Resolutionstheorem-Proversen zur Parsing verwendet werden könnten. Sie beobachteten, dass einige Theorem-Proversen, wie Hyper-Resolution, sich wie Bottom-up-Parser und andere, wie SL-Resolution (1971), wie Top-down-Parser verhalten. Im darauffolgenden Sommer 1972 entwickelte Kowalski, wieder mit Colmerauer, die verfahrensmäßige Interpretation der Implikationen. Diese zweideklarative/verfahrensmäßige Interpretation wurde später in der Prologanschrift H:- B1, ..., Bn., die sowohl deklarativ als auch verfahrenstechnisch gelesen und verwendet werden können. Es wurde auch deutlich, dass solche Klauseln auf bestimmte Klauseln oder Horn-Klausel beschränkt werden könnten, wobei H, B1,...,Bn alle atomaren Prädikatlogikformeln sind, und dass die SL-Resolution auf LUSH oder SLD-Resolution beschränkt werden könnte. Kowalskis verfahrensmäßige Interpretation und LUSH wurden in einer 1973 veröffentlichten Memo beschrieben. Colmerauer, mit Philippe Roussel, nutzte diese doppelte Interpretation von Klauseln als Grundlage von Prolog, die im Sommer und Herbst 1972 umgesetzt wurde. Das erste Prolog-Programm, das auch 1972 geschrieben und in Marseille umgesetzt wurde, war ein französisches Frage-Antwort-System. Die Verwendung von Prolog als praktische Programmiersprache wurde durch die Entwicklung eines Compilers von David Warren in Edinburgh im Jahr 1977 in großer Dynamik erreicht. Experimente zeigten, dass Edinburgh Prolog mit der Verarbeitungsgeschwindigkeit anderer symbolischer Programmiersprachen wie Lisp konkurrieren konnte. Edinburgh Prolog wurde der de facto-Standard und stark beeinflusst die Definition von ISO-Standard Prolog. Abduktive Logik-Programmierung Die ableitende Logik-Programmierung ist eine Erweiterung der normalen Logik-Programmierung, die es erlaubt, einige Prädikate, die als abduzierbare Prädikate erklärt werden, offen oder undefiniert zu sein. Eine Klausel in einem ableitenden Logikprogramm hat die Form: H :- B1,..., Bn, A1,..., An.where H ist eine Atomformel, die nicht abduzierbar ist, alle Bi sind Literale, deren Prädikate nicht abduzierbar sind, und die Ai sind atomare Formeln, deren Prädikate abduzierbar sind. Die abduzierbaren Prädikate können durch Integritätsbeschränkungen eingeschränkt werden, die die Form haben können: false :- L1, ..., Ln.where the Li are willkürliche Literale (definiert oder abduzierbar, atomar oder negiert). Zum Beispiel: wo das Prädikat normal abduzierbar ist. Die Problemlösung wird dadurch erreicht, dass Hypothesen, die in Bezug auf die abziehbaren Prädikate ausgedrückt werden, als Lösung der zu lösenden Probleme abgeleitet werden. Diese Probleme können entweder Beobachtungen sein, die erklärt werden müssen (wie bei der klassischen ableitenden Argumentation) oder Ziele zu lösen (wie bei der normalen Logik-Programmierung). Beispielsweise erklärt die Hypothese normal(mary) die Beobachtung canfly(mary). Die gleiche Hypothese beinhaltet außerdem die einzige Lösung X = mary des Ziels, etwas zu finden, das fliegen kann: Ableitende Logik-Programmierung wurde für Fehlerdiagnose, Planung, natürliche Sprachverarbeitung und maschinelles Lernen verwendet. Es wurde auch verwendet, um Verhandlungen als Nichtigkeit als eine Form der ableitenden Argumentation zu interpretieren. Metalogic-Programmierung Da mathematische Logik eine lange Tradition hat, zwischen Objektsprache und Metalanguage zu unterscheiden, erlaubt die Logik-Programmierung auch die Metalevel-Programmierung. Das einfachste metallogische Programm ist der sogenannte Vanille-meta-Interpreter: Wo wahr eine leere Konjunktion darstellt, und Klausel (A,B) bedeutet, dass es eine Objekt-Level-Klausel der Form A gibt:- B. Metalogic-Programmierung ermöglicht die Kombination von Objekt- und Metalevel-Repräsentationen, wie in der natürlichen Sprache. Es kann auch verwendet werden, um jede Logik zu implementieren, die als Inferenzregeln bezeichnet wird. Metalogic wird in der logischen Programmierung verwendet, um Metaprogramme zu implementieren, die andere Programme, Datenbanken, Wissensbasen oder axiomatische Theorien als Daten manipulieren. Constraint Logik-Programmierung Kontraint Logik-Programmierung kombiniert Horn-Klausel-Logik-Programmierung mit Zwangslösung. Es erweitert die Horn-Klausel, indem es einigen Prädikaten, die als konstruierende Prädikate erklärt werden, als Literale im Körper von Klauseln auftreten. Ein konsequentes Logikprogramm ist ein Satz von Klauseln der Form: H : C1, ..., Cn ≈ B1, ..., Bn.wo H und das ganze Bi atomare Formeln sind, und die Ci sind Zwänge. Deklarativ werden solche Klauseln als gewöhnliche logische Implikationen gelesen: H wenn C1 und... und Cn und B1 und... und Bn.Allerdings, während die Prädikate in den Klauselköpfen durch das constraint-Logic-Programm definiert sind, werden die Prädikate in den Zwängen durch eine Domänen-spezifische modelltheoretische Struktur oder Theorie vorgegeben. Prozedur werden Subgoals, deren Prädikate durch das Programm definiert werden, wie in der gewöhnlichen Logik-Programmierung durch eine Domänen-spezifische Konstrat-Lösunger, die die Semantik der constraint Prädikate implementiert, auf eine Befriedigung überprüft. Ein erstes Problem wird dadurch gelöst, daß es zu einer befriedigenden Konjunktion von Zwängen reduziert wird. Das folgende konstraktive Logikprogramm stellt eine zeitliche Datenbank der johnischen Geschichte als Lehrer dar: Hier ≤ und < sind Zwangsprädikate, mit ihrer üblichen beabsichtigten Semantik. Die folgende Zielklausel fragt die Datenbank ab, um herauszufinden, wann john beide Logik gelehrt und Professor war: :- lehrtes(john, logic, T), Rang(john, Professor, T). Die Lösung ist 2010 ≤ T, T ≤ 2012. Die Logik-Programmierung wurde verwendet, um Probleme in Bereichen wie Bauingenieurwesen, Maschinenbau, digitale Schaltung Verifikation, automatisierte Zeiterfassung, Luftverkehrskontrolle und Finanzen zu lösen. Es ist eng mit der ableitenden Logik-Programmierung verbunden. Gleichzeitige Logik-Programmierung Mit gleichzeitiger Programmierung integriert die Concurrent-Logik-Programmierung Konzepte der Logik-Programmierung. Seine Entwicklung wurde in den 1980er Jahren durch ihre Wahl für die Programmiersprache der Systeme des japanischen Fünften Generationsprojekts (FGCS) einen großen Impuls verliehen. Ein gleichzeitiges Logikprogramm ist eine Reihe von bewachten Horn-Klausel der Form: H :- G1, ..., Gn | B1, ..., Bn.Die Konjunktion G1, ... Gn wird als Wächter der Klausel bezeichnet, und . ist der Verpflichtungsbetreiber. Deklarativ, bewacht Horn-Klausel werden als gewöhnliche logische Implikationen gelesen: H wenn G1 und... und Gn und B1 und... und Bn.Allerdings, verfahrenstechnisch, wenn es mehrere Klauseln gibt, deren Köpfe H einem bestimmten Ziel entsprechen, dann werden alle Klauseln parallel ausgeführt, um zu überprüfen, ob ihre Wächter G1, ..., Gn halten. Wenn die Wächter von mehr als einer Klausel halten, dann wird eine entschiedene Wahl zu einer der Klauseln getroffen, und die Ausführung geht mit den Subgoals B1, ..., Bn der gewählten Klausel. Diese Subgoals können auch parallel ausgeführt sein. Die gleichzeitige Logik-Programmierung implementiert also eine Form von "Nichtdeterminismus interessieren", anstatt "Nichtdeterminismus kennen". Das folgende gleichzeitige Logikprogramm definiert z.B. einen Prädikats-Shuffle(Left, Right, Merge) , mit dem zwei Listen geschüttelt werden können. Links und rechts, kombinieren sie in eine einzige Liste Verschmelzung, die die Reihenfolge der beiden Listen links und rechts bewahrt: Hier, [] repräsentiert die leere Liste, und [Head | Tail] stellt eine Liste mit dem ersten Element Kopf gefolgt von der Liste Tail, wie in Prolog. (Anmerkung, dass das erste Auftreten von | in der zweiten und dritten Klausel der Listenkonstruktor ist, während das zweite Auftreten von | der Verpflichtungsbetreiber ist.) Das Programm kann zum Beispiel verwendet werden, um die Listen [ace, queen, king] und [1, 4, 2] durch Aufruf der Zielklausel zu rühmen: Das Programm wird nicht-deterministisch eine einzige Lösung erzeugen, z.B. Merge = [ace, queen, 1, king, 4, 2].Wahrscheinlich basiert die gleichzeitige logische Programmierung auf der Nachrichtenübermittlung, so dass sie der gleichen Unbestimmtheit unterliegt wie andere gleichzeitige Nachrichtenübermittlungssysteme, wie z.B. Actors (siehe Unbestimmtheit bei gleichzeitiger Berechnung). Carl Hewitt hat argumentiert, dass die gleichzeitige Logik-Programmierung nicht auf Logik in seinem Sinne basiert, dass Rechenschritte nicht logisch abgeleitet werden können. Bei der gleichzeitigen Logikprogrammierung ist jedoch jedes Ergebnis einer abschließenden Berechnung eine logische Folge des Programms, und jedes Teilergebnis einer Teilrechnung ist eine logische Folge des Programms und des Restziels (Prozessnetzwerk). So bedeutet die Unbestimmtheit der Berechnungen, dass nicht alle logischen Konsequenzen des Programms abgeleitet werden können. Concurrent constraint Logik-Programmierung Concurrent constraint Logik-Programmierung kombiniert gleichzeitige Logik-Programmierung und constraint Logik-Programmierung, mit Einschränkungen, um Koncurrency zu steuern. Eine Klausel kann eine Wache enthalten, die eine Reihe von Zwängen ist, die die Anwendbarkeit der Klausel blockieren können. Wenn die Wächter mehrerer Klauseln zufrieden sind, macht die gleichzeitige konstrate Logik-Programmierung eine entschlossene Wahl, nur einen zu verwenden. Induktive Logikprogrammierung Induktive Logikprogrammierung beschäftigt sich mit der Verallgemeinerung positiver und negativer Beispiele im Kontext von Hintergrundwissen: maschinelles Lernen von Logikprogrammen. Die jüngsten Arbeiten in diesem Bereich, die Verknüpfung von Logikprogrammierung, Lernen und Wahrscheinlichkeit, haben das neue Feld des statistischen relationalen Lernens und der probabilistischen induktiven Logikprogrammierung hervorgerufen. Mehrere Forscher haben eine erweiterte Logik-Programmierung mit höherwertigen Programmierfunktionen, die aus der Logik höherer Ordnung abgeleitet sind, wie z.B. Prädikatvariablen. Zu diesen Sprachen gehören die Prolog-Erweiterungen HiLog und λProlog. Lineare Logik-Programmierung Basing-Logik-Programmierung innerhalb der linearen Logik hat zur Gestaltung von logischen Programmiersprachen geführt, die wesentlich ausdrucksvoller sind als die auf der klassischen Logik basierenden. Horn-Klausel-Programme können nur durch die Änderung der Argumente zu Prädikaten Zustandsänderung darstellen. Bei der linearen Logik-Programmierung kann die Umgebungslinearlogik zur Unterstützung des Zustandswechsels verwendet werden. Einige frühe Entwürfe von logischen Programmiersprachen auf der Grundlage linearer Logik umfassen LO [Andreoli & Pareschi, 1991], Lolli, ACL und Forum [Miller, 1996]. Forum bietet eine zielgerichtete Interpretation aller linearen Logik. Objektorientierte Logik-Programmierung F-logic erweitert die Logik-Programmierung mit Objekten und der Rahmen-Syntax. Logtalk erweitert die Programmiersprache Prolog mit Unterstützung von Objekten, Protokollen und anderen OOP-Konzepten. Es unterstützt die meisten standardkonformen Prolog-Systeme als Backend-Compiler. Transaction Logik-Programmierung Transaction Logik ist eine Erweiterung der Logik-Programmierung mit einer logischen Theorie der staatlich-modifizierenden Updates. Es hat sowohl eine modelltheoretische Semantik als auch eine verfahrenstechnische. Eine Implementierung einer Teilmenge von Transaction-Logik ist im Flora-2 System verfügbar. Weitere Prototypen sind ebenfalls verfügbar. Siehe auch Automated theorem proving Constraint Logik Programmierung Steuertheorie Datalog Fril Funktionelle Programmierung Fuzzy Logik Induktive Logik Programmierung Logic in Informatik (inklusive formale Methoden) Logik Programmiersprachen Programmierbarer Logik-Controller R+ Begründungssystem Regelbasiertes maschinelles Lernen Zufriedenheit Boolean Zufriedenheit Problem Lineare Logik Citations Quellen Allgemeine Einführungen Baral, C.; Gelfond, M. (1994). "Logische Programmierung und Wissensdarstellung" (PDF). Das Journal of Logic Programming.19–20:73–148.doi:10.1016/0743-1066(94)90025-6.Kowalski, R. A. (1988). "Die frühen Jahre der logischen Programmierung" (PDF). Mitteilungen der ACM.31: 38–43.doi:10.1145/35043.35046.S2CID 12259230.[1] Lloyd, J. W. (1987). Grundlagen der Logikprogrammierung.(2. Auflage). Springer-Verlag Andere Quellen John McCarthy. "Programme mit gemeinsamem Sinn". Symposium zur Mechanisierung von Gedankenprozessen. Nationales Physikalisches Labor. Teddington, England. 1958.Miller, Dale; Nadathur, Gopalan; Pfenning, Frank; Scedrov, Andre (1991). " Einheitliche Beweise als Grundlage für die logische Programmierung". Annals of Pure and Applied Logic.51 (1–2:) 125–157.doi:10.1016/0168-0072(91)90068-W Ehud Shapiro (Editor). Concurrent Prolog. MIT Press.1987.James Slagle."Erfahrungen mit einem deduktiven Frage-Antwort-Programm". CACM.Dezember 1965.Gabbay, Dov M.; Hogger, Christopher John; Robinson, J.A., eds.(1993-1998). Handbuch der Logik in künstlicher Intelligenz und Logikprogrammierung. Vols.1–5, Oxford University Press. Weiter lesen Carl Hewitt. "Procedural Embedding of Knowledge in Planner". IJCAI 1971.Carl Hewitt. "The Repeated Demise of Logic Programming and Why It will Reincarnated". AAAI Spring Symposium: Went Wrong und warum: Lehren aus AI-Forschung und Anwendungen 2006: 2–9. Evgeny Dantsin, Thomas Eiter, Georg Gottlob, Andrei Voronkov: Komplexität und Ausdruckskraft der Logikprogrammierung. ACM Comput.Surv.33(3:) 374–425 (2001)Ulf Nilsson und Jan Maluszynski, Logic, Programmierung und Prolog Externe Links Logic Programming Virtual Library entry Bibliographies on Logic Programming Association for Logic Programming (ALP) Theorie und Praxis der Logic Programming (journal) Logic Programmierung in C+ mit Castor Logic Development Center in Oz