Die wissenschaftliche Methode ist eine empirische Methode des Wissenserwerbs, die die Entwicklung der Wissenschaft seit mindestens dem 17. Jahrhundert (mit bemerkenswerten Praktizierenden in den vergangenen Jahrhunderten) charakterisiert hat. Es beinhaltet sorgfältige Beobachtung, Anwendung strenger Skepsis über das, was beobachtet wird, da kognitive Annahmen verzerren können, wie man die Beobachtung interpretiert. Es geht um die Formulierung von Hypothesen über Induktion auf der Grundlage solcher Beobachtungen; experimentelle und meßbasierte Prüfung von aus den Hypothesen gezogenen Abzügen; und Verfeinerung (oder Eliminierung) der Hypothesen auf der Grundlage der Versuchsergebnisse. Dies sind Prinzipien der wissenschaftlichen Methode, die sich aus einer endgültigen Reihe von Maßnahmen für alle wissenschaftlichen Unternehmen unterscheiden. Obwohl Verfahren von einem Untersuchungsfeld zum anderen variieren, ist der zugrunde liegende Prozess häufig gleich von einem Feld zum anderen. Der Prozess in der wissenschaftlichen Methode beinhaltet die Herstellung von Konjektionen (Hypothesen), die Vorhersagen von ihnen als logische Folgen ableiten und anschließend Experimente oder empirische Beobachtungen auf Basis dieser Vorhersagen durchführen. Eine Hypothese ist eine Konjektur, die auf dem Wissen basiert, während sie Antworten auf die Frage sucht. Die Hypothese könnte sehr spezifisch sein, oder sie könnte breit sein. Wissenschaftler testen dann Hypothesen durch Experimente oder Studien. Eine wissenschaftliche Hypothese muss verfälscht werden, was bedeutet, dass es möglich ist, ein mögliches Ergebnis eines Experiments oder einer Beobachtung zu identifizieren, dass mit Vorhersagen, die aus der Hypothese abgeleitet werden, Konflikte auftreten; andernfalls kann die Hypothese nicht sinnvoll getestet werden. Ziel eines Experiments ist es, festzustellen, ob Beobachtungen mit den aus einer Hypothese abgeleiteten Erwartungen übereinstimmen oder widersprechen. Experimente können überall von einer Garage bis zum CERN's Large Hadron Collider stattfinden. Es gibt jedoch Schwierigkeiten in einer formelmäßigen Verfahrensweise. Obwohl die wissenschaftliche Methode oft als feste Schrittfolge dargestellt wird, stellt sie eher eine Reihe von allgemeinen Prinzipien dar. Nicht alle Schritte finden in jeder wissenschaftlichen Untersuchung statt (nicht in gleichem Maße), und sie sind nicht immer in derselben Reihenfolge. Geschichte Wichtige Debatten in der Geschichte der Wissenschaft betreffen Rationalität (insbesondere wie von René Descartes befürwortet), Induktivismus, Imperiumismus (wie von Francis Bacon argumentiert, und auf besondere Prominenz mit Isaac Newton und seinen Anhängern zu steigen), und Hypothetik-Deduktivismus, die Anfang des 19. Jahrhunderts in den Vordergrund kamen. Der Begriff "wissenschaftliche Methode" entstand im 19. Jahrhundert, als eine bedeutende institutionelle Entwicklung der Wissenschaft stattgefunden hat und Terminologien, die klare Grenzen zwischen Wissenschaft und Nicht-Wissenschaft, wie Wissenschaftler und Pseudo-Wissenschaft, festlegten. In den 1830er und 1850er Jahren, in denen Zeit Baconianismus populär war, engagierten sich Naturwissenschaftler wie William Whewell, John Herschel, John Stuart Mill in Debatten über Induktion und Fakten und konzentrierten sich darauf, wie man Wissen erzeugt. Im späten 19. und frühen 20. Jahrhundert wurde eine Debatte über den Realismus gegen den Antirealismus als mächtige wissenschaftliche Theorien geführt, die über das Reich des Beobachtbaren hinausreichten. Der Begriff "wissenschaftliche Methode" kam im zwanzigsten Jahrhundert in populäre Verwendung; Dewey 1910, Wie Wir denken inspiriert beliebte Richtlinien, Popup in Wörterbücher und Wissenschaft Lehrbücher, obwohl es wenig wissenschaftliche Konsens über seine Bedeutung. Obwohl es in der Mitte des zwanzigsten Jahrhunderts Wachstum gab, hatten in den 1960er und 1970er Jahren zahlreiche einflussreiche Philosophen der Wissenschaft wie Thomas Kuhn und Paul Feyerabend die Universalität der "wissenschaftlichen Methode" in Frage gestellt und dadurch den Begriff der Wissenschaft als homogene und universelle Methode weitgehend ersetzt, mit der einer heterogenen und lokalen Praxis. Insbesondere Paul Feyerabend, in der 1975 ersten Ausgabe seines Buches Gegen Methode, argumentierte, dass es irgendwelche universellen Regeln der Wissenschaft; Popper 1963, Gauch 2003, und Tow 2010 sind nicht mit Feyerabends Behauptung; Forscher und Problemlöser sind mit ihren Ressourcen während ihrer Untersuchung vorsichtig zu sein. Spätere Haltungen umfassen Physiker Lee Smolins 2013 Essay "Es gibt keine wissenschaftliche Methode", in dem er zwei ethische Prinzipien, und Historiker der Wissenschaft Daniel Thurs Kapitel in dem 2015 Buch Newtons Apple und andere Mythen über Wissenschaft, die folge, dass die wissenschaftliche Methode ein Mythos oder, bestenfalls, eine Idealisierung. Da Mythen Glauben sind, unterliegen sie dem narrativen Verfall, wie Taleb betont. Die Philosophen Robert Nola und Howard Sankey, in ihrem Buch von 2007 Theorien der wissenschaftlichen Methode, sagten, dass die Debatten über die wissenschaftliche Methode weitergehen und argumentierten, dass Feyerabend trotz des Titels Gegen Methode bestimmte Regeln der Methode akzeptierte und versuchte, diese Regeln mit einer Meta-Methodik zu rechtfertigen.Staddon (2017) argumentiert, dass es ein Fehler ist, nach Regeln zu versuchen, in Abwesenheit einer algorithmischen wissenschaftlichen Methode; in diesem Fall "Wissenschaft wird am besten durch Beispiele verstanden". Aber algorithmische Methoden, wie z.B. die Disproof der vorhandenen Theorie durch Experimente, wurden seit Alhacen (1027)Book of Optics und Galileo (1638)Two New Sciences immer noch als wissenschaftliche Methode verwendet, die Feyers Haltung widerspricht. Das allgegenwärtige Element in der wissenschaftlichen Methode ist Imperiumismus. Dies steht im Widerspruch zu strengen Formen des Rationalitätsprinzips: Die wissenschaftliche Methode verkörpert die Position, die allein ein bestimmtes wissenschaftliches Problem nicht lösen kann. Eine starke Formulierung der wissenschaftlichen Methode ist nicht immer auf eine Form des Empirismus ausgerichtet, in der die empirischen Daten in Form von Erfahrungen oder anderen abstrakten Wissensformen vorgetragen werden; in der aktuellen wissenschaftlichen Praxis wird jedoch die Verwendung von wissenschaftlicher Modellierung und Abhängigkeit von abstrakten Typologien und Theorien in der Regel akzeptiert. Die wissenschaftliche Methode behauptet, dass Offenbarung, politisches oder religiöses Dogma, Berufung auf die Tradition, allgemein gehaltene Überzeugungen, gesunden Menschenverstand oder aktuell gehaltene Theorien die einzigen möglichen Mittel darstellen, die Wahrheit zu demonstrieren. Verschiedene frühe Ausdrücke des Imperiumismus und der wissenschaftlichen Methode finden Sie in der gesamten Geschichte, zum Beispiel mit den alten Stoics, Epicurus, Alhazen, Roger Bacon und William von Ockham. Ab dem 16. Jahrhundert wurden Experimente von Francis Bacon befürwortet und von Giambatista della Porta, Johannes Kepler und Galileo Galilei durchgeführt. Es gab eine besondere Entwicklung, die von theoretischen Arbeiten von Francisco Sanches, John Locke, George Berkeley und David Hume unterstützt wurde. Eine Seereise von Amerika nach Europa bot C. S. Peirce die Distanz, um seine Ideen zu klären, und nach und nach das hypothetisch-deduktive Modell. Im 20. Jahrhundert wurde das Modell seit dem ersten Vorschlag (für eine formalere Diskussion siehe § Elemente der wissenschaftlichen Methode) erheblich überarbeitet. Überblick Die wissenschaftliche Methode ist der Prozess, nach dem die Wissenschaft durchgeführt wird. Wie in anderen Untersuchungsbereichen kann die Wissenschaft (durch die wissenschaftliche Methode) auf früheres Wissen aufbauen und ein anspruchsvolleres Verständnis ihrer Studienthemen über die Zeit entwickeln. Dieses Modell lässt sich der wissenschaftlichen Revolution unterziehen. Verfahren Der Gesamtprozess beinhaltet die Herstellung von Konjektionen (Hypothesen), die Vorhersagen von ihnen als logische Folgen ableiten und anschließend Experimente auf Basis dieser Vorhersagen durchführen, um festzustellen, ob die ursprüngliche Konjektur korrekt war. Es gibt jedoch Schwierigkeiten in einer formelmäßigen Verfahrensweise. Obwohl die wissenschaftliche Methode oft als feste Abfolge von Schritten dargestellt wird, werden diese Aktionen besser als allgemeine Prinzipien betrachtet. Nicht alle Schritte finden in jeder wissenschaftlichen Untersuchung statt (nicht in gleichem Maße), und sie werden nicht immer in derselben Reihenfolge durchgeführt. Wie von Wissenschaftler und Philosoph William Whewell (1794–1866) bemerkt wird, sind bei jedem Schritt "Erfindung, Sagacity, [und] Genie" erforderlich. Formulierung einer Frage Die Frage kann sich auf die Erklärung einer bestimmten Beobachtung beziehen, wie in "Warum ist der Himmel blau?" aber kann auch offen enden, wie in "Wie kann ich ein Medikament zur Heilung dieser bestimmten Krankheit entwerfen? " Diese Phase beinhaltet häufig die Feststellung und Auswertung von Beweisen aus früheren Experimenten, persönlichen wissenschaftlichen Beobachtungen oder Behauptungen sowie die Arbeit anderer Wissenschaftler. Wenn die Antwort bereits bekannt ist, kann eine andere Frage gestellt werden, die auf den Beweisen beruht. Bei der Anwendung der wissenschaftlichen Methode auf die Forschung kann die Ermittlung einer guten Frage sehr schwierig sein und wird das Ergebnis der Untersuchung beeinflussen. Hypothese Eine Hypothese ist eine Konjektur, basierend auf Kenntnissen, die bei der Formulierung der Frage erhalten werden, die jedes gegebene Verhalten erklären kann. Die Hypothese könnte sehr spezifisch sein; zum Beispiel Einsteins Gleichwertigkeitsprinzip oder Francis Cricks "DNA macht RNA Protein", oder es könnte breit sein; zum Beispiel "unbekannte Lebensarten wohnen in den unerforschten Tiefen der Ozeane". Siehe § Hypothesenentwicklung Eine statistische Hypothese ist eine Vermutung über eine bestimmte statistische Bevölkerung. Beispielsweise könnte die Bevölkerung Menschen mit einer bestimmten Krankheit sein. Eine Vermutung könnte sein, dass ein neues Medikament die Krankheit in einigen der Menschen in dieser Bevölkerung heilen wird, wie in einer klinischen Studie des Medikaments. Eine Nullhypothese würde bedeuten, dass die statistische Hypothese falsch ist; zum Beispiel, dass das neue Medikament nichts tut, und dass jede Heilung in der Bevölkerung durch Zufall (eine zufällige Variable) verursacht würde.Eine Alternative zur Nullhypothese, die verfälscht werden soll, muss sagen, dass ein Behandlungsprogramm mit dem Medikament besser ist als die Chance. Um die Aussage zu testen, dass ein Behandlungsprogramm mit dem Medikament besser ist als Zufall, wird ein Experiment entwickelt, in dem ein Teil der Bevölkerung (die Kontrollgruppe,) unbehandelt gelassen werden soll, während ein anderer, separater Teil der Bevölkerung behandelt werden soll. t-Tests könnten dann festlegen, wie groß die behandelten Gruppen sind und wie groß die Kontrollgruppen sein sollen, um zu unterziehen, ob ein gewisser Behandlungsverlauf der Bevölkerung zu einer Heilung von einigen von ihnen in jeder der Gruppen geführt hat. Die Gruppen werden wiederum von den Forschern in einem Protokoll untersucht. Starke Inferenz könnte alternativ mehrere alternative Hypothesen vorschlagen, die in randomisierten kontrollierten Versuchen, Behandlungen A, B, C, ..., (Test in einem blinden Experiment mit variierenden Dosierungen, oder mit Lebensstil-Änderungen, und so weiter) verkörpert werden, um keine Bestätigung Bias zugunsten eines bestimmten Behandlungsverlaufs einzuführen. Ethische Erwägungen könnten verwendet werden, um die Zahlen in den unbehandelten Gruppen zu minimieren, z.B. fast jede Behandlung in jeder Gruppe verwenden, jedoch außer A, B, C, ... als Kontrollen. Prädiktion Der Prädiktionsschritt löst die logischen Folgen der Hypothese ab, bevor das Ergebnis bekannt ist. Diese Vorhersagen sind Erwartungen für die Ergebnisse der Tests. Wenn das Ergebnis bereits bekannt ist, ist es ein Beweis, der bereit ist, bei der Annahme oder Ablehnung der Hypothese berücksichtigt zu werden. Der Nachweis ist auch stärker, wenn das tatsächliche Ergebnis des Prädiktionstests nicht bereits bekannt ist, da eine Manipulation mit dem Test ausgeschlossen werden kann, wie z.B. eine Andeutung (siehe Postdiktion). Idealerweise muss die Vorhersage auch die Hypothese von wahrscheinlichen Alternativen unterscheiden; wenn zwei Hypothesen die gleiche Vorhersage machen, ist die Beobachtung der Vorhersage korrekt zu sein, kein Beweis für entweder über dem anderen.( Diese Aussagen über die relative Beweisstärke können mit Bayes' Theorem mathematisch abgeleitet werden. Die Folge ist also gleichzeitig oder kurz nach der Aussage der Hypothese anzugeben, bevor das Versuchsergebnis bekannt ist. Ebenso ist das Testprotokoll vor der Durchführung des Tests anzugeben. Diese Anforderungen werden Vorsorge gegen Manipulationen und unterstützen die Reproduzierbarkeit des Experiments. Durch geeignete Tests einer Hypothese werden die erwarteten Werte aus den Tests dieser Hypothese mit den tatsächlichen Ergebnissen dieser Tests verglichen. Wissenschaftler (und andere Menschen) können dann durch geeignete Experimente ihre Hypothesen sichern oder verwerfen. Analyse Eine Analyse bestimmt aus den Ergebnissen des Experiments die nächsten Schritte. Die erwarteten Werte aus der Prüfung der alternativen Hypothese werden mit den erwarteten Werten verglichen, die sich aus der Null-Hypothese ergeben (d.h. eine Vorhersage ohne Unterschied im Status quo). Der Unterschied zwischen erwartetem und tatsächlichem Zeigt an, welche Hypothese die resultierenden Daten aus dem Experiment besser erläutert. In Fällen, in denen ein Experiment mehrfach wiederholt wird, kann eine statistische Analyse wie ein Chi-Quadrat-Test, ob die Null-Hypothese wahr ist, erforderlich sein. Beweise von anderen Wissenschaftlern und aus Erfahrung sind für die Einarbeitung in jedem Stadium des Prozesses verfügbar. Je nach Komplexität des Experiments kann eine Iteration des Prozesses erforderlich sein, um hinreichende Beweise zu sammeln, um die Frage mit Vertrauen zu beantworten oder andere Antworten auf sehr spezifische Fragen zu erstellen, um eine einzige umfassendere Frage zu beantworten. Wenn die Beweise die alternative Hypothese verfälscht haben, ist eine neue Hypothese erforderlich; wenn die Beweise die alternative Hypothese nicht abschließend rechtfertigen, könnten andere Vorhersagen aus der alternativen Hypothese berücksichtigt werden. Pragmatische Überlegungen, wie die verfügbaren Mittel, um die Untersuchung fortzusetzen, könnten den weiteren Verlauf der Untersuchung leiten. Wenn der Nachweis für eine Hypothese stark unterstützt, dass Hypothese, weitere Fragen können folgen, um Einblick in die breitere Untersuchung unter Untersuchung. DNA-Beispiel Die grundlegenden Elemente der wissenschaftlichen Methode werden durch das folgende Beispiel (das von 1944 bis 1953 aufgetreten ist) aus der Entdeckung der Struktur der DNA veranschaulicht: Frage: Vorherige Untersuchung der DNA hatte ihre chemische Zusammensetzung (die vier Nukleotide) die Struktur jedes einzelnen Nukleotids und andere Eigenschaften bestimmt. DNA wurde 1944 als Träger genetischer Informationen durch das Avery-MacLeod-McCarty-Experiment identifiziert, aber der Mechanismus, wie genetische Informationen in DNA gespeichert wurden, war unklar.Hypothese: Linus Pauling, Francis Crick und James D. Watson Hypothese, dass DNA eine helixförmige Struktur hatte. Vorhersage: Hätte DNA eine schraubenförmige Struktur, wäre sein Röntgenbeugungsmuster röntgenförmig. Diese Vorhersage wurde mit der Mathematik der Helix-Transformation bestimmt, die von Cochran, Crick und Vand (und unabhängig von Stokes) abgeleitet worden war. Diese Vorhersage war ein mathematisches Konstrukt, völlig unabhängig vom biologischen Problem zur Hand. Experiment: Rosalind Franklin verwendet reine DNA, um Röntgenbeugung durchzuführen, um Foto 51 herzustellen. Die Ergebnisse zeigten eine X-Form. Analyse: Als Watson das detaillierte Beugungsmuster sah, erkannte er es sofort als Helix. Er und Crick produzierten dann ihr Modell mit diesen Informationen zusammen mit den bisher bekannten Informationen über die Zusammensetzung von DNA, insbesondere Chargaffs Regeln der Basispaarung. Die Entdeckung wurde Ausgangspunkt für viele weitere Studien, die das genetische Material, wie das Feld der molekularen Genetik, betreffen, und wurde 1962 mit dem Nobelpreis ausgezeichnet. Jeder Schritt des Beispiels wird später im Artikel näher untersucht. Andere Bauteile Die wissenschaftliche Methode umfasst auch andere Komponenten, die erforderlich sind, auch wenn alle Iterationen der obigen Schritte abgeschlossen sind: Wiederholung Wenn ein Experiment nicht wiederholt werden kann, um die gleichen Ergebnisse zu erzielen, bedeutet dies, dass die ursprünglichen Ergebnisse in Fehlern gewesen sein könnten. Dadurch ist es üblich, dass ein einziger Versuch mehrfach durchgeführt wird, insbesondere wenn unkontrollierte Variablen oder andere Indikationen des experimentellen Fehlers vorliegen. Für signifikante oder überraschende Ergebnisse können auch andere Wissenschaftler versuchen, die Ergebnisse für sich selbst zu replizieren, insbesondere wenn diese Ergebnisse für ihre eigene Arbeit wichtig wären. Die Replikation ist in der Sozial- und Biomedizinischen Wissenschaft zu einem heiklen Thema geworden, in dem die Behandlungen an Gruppen von Individuen verabreicht werden. Typischerweise bekommt eine experimentelle Gruppe die Behandlung, wie ein Medikament, und die Kontrollgruppe bekommt einen Placebo. John Ioannidis im Jahr 2005 wies darauf hin, dass die verwendete Methode zu vielen Ergebnissen geführt hat, die nicht repliziert werden können. Außenüberprüfung Der Prozess der Peer Review beinhaltet die Bewertung des Experiments von Experten, die in der Regel ihre Meinungen anonym geben. Einige Zeitschriften verlangen, dass der Experimentator Listen von möglichen Peer-Reviewern, vor allem, wenn das Feld sehr spezialisiert ist. Die Peer-Review bescheinigt nicht die Korrektheit der Ergebnisse, nur dass die Experimente selbst nach Meinung des Prüfers klingen (basierend auf der Beschreibung des Experimentators). Wenn die Arbeit eine Peer-Review übergeht, die gelegentlich neue Experimente erfordern kann, die von den Prüfern angefordert werden, wird sie in einer peer-reviewed wissenschaftlichen Zeitschrift veröffentlicht. Das spezielle Journal, das die Ergebnisse veröffentlicht, zeigt die wahrgenommene Qualität der Arbeit an. Datenerfassung und -austausch Wissenschaftler sind in der Regel vorsichtig bei der Erfassung ihrer Daten, eine Anforderung von Ludwik Fleck (1896–1961) und anderen. Diese Daten können zwar nicht in der Regel benötigt werden, um anderen Wissenschaftlern diese Daten zu liefern, die ihre ursprünglichen Ergebnisse (oder Teile ihrer ursprünglichen Ergebnisse) replizieren möchten, die sich auf den Austausch von experimentellen Proben erstrecken, die schwer zu erhalten sind. Siehe §Kommunikation und Gemeinde. Besetzung Siehe wissenschaftliche Gemeinschaft, große Wissenschaft. Institutionelle Forscher könnten ein Instrument zur Institutionalisierung ihrer Tests erwerben. Diese Instrumente würden Beobachtungen der realen Welt nutzen, die mit ihren Vorhersagen, die aus ihrer Hypothese abgeleitet werden, übereinstimmen oder vielleicht widersprechen könnten. Diese Institutionen reduzieren damit die Forschungsfunktion auf Kosten/Nutzen, die als Geld ausgedrückt wird, und die Zeit und Aufmerksamkeit der zu erweiternden Forscher im Austausch für einen Bericht an ihre Bestandteile. Aktuelle Großinstrumente, wie CERN's Large Hadron Collider (LHC,) oder LIGO, oder die National Ignition Facility (NIF,) oder die International Space Station (ISS,) oder das James Webb Space Telescope (JWST), führen zu erwarteten Kosten von Milliarden von Dollar und Zeitrahmen, die sich über Jahrzehnte erstrecken. Diese Arten von Institutionen beeinflussen die öffentliche Politik auf nationaler oder sogar internationaler Ebene, und die Forscher würden einen gemeinsamen Zugang zu diesen Maschinen und ihrer Nebeninfrastruktur benötigen. Siehe Perceptual control Theorie, §Open-loop und Closed-loop Feedback Elemente der wissenschaftlichen Methode Es gibt verschiedene Möglichkeiten, die für wissenschaftliche Untersuchungen verwendete Grundmethode zu überdenken. Die wissenschaftliche Gemeinschaft und die Philosophen der Wissenschaft stimmen in der Regel über die folgende Klassifizierung von Methodenkomponenten.Diese methodischen Elemente und die Organisation von Verfahren sind eher charakteristisch für experimentelle Wissenschaften als Sozialwissenschaften. Dennoch wird der Zyklus der Formulierung von Hypothesen, Prüfung und Analyse der Ergebnisse und Formulierung neuer Hypothesen dem unten beschriebenen Zyklus ähneln. Die wissenschaftliche Methode ist ein iterativer, zyklischer Prozess, durch den die Informationen kontinuierlich überarbeitet werden. Es wird allgemein anerkannt, Wissensfortschritte durch folgende Elemente in unterschiedlichen Kombinationen oder Beiträgen zu entwickeln: Charakterisierungen (Beobachtungen, Definitionen und Messungen des Untersuchungsgegenstandes) Hypothesen (theoretische, hypothetische Erklärungen von Beobachtungen und Messungen des Subjekts)Prädiktionen (induktive und deduktive Argumentation aus der Hypothese oder Theorie) Experimente (Tests aller oben genannten) Jedes Element der wissenschaftlichen Methode unterliegt der Peer-Review für mögliche Fehler. Diese Aktivitäten beschreiben nicht alles, was Wissenschaftler tun, sondern beziehen sich meist auf experimentelle Wissenschaften (z.B. Physik, Chemie, Biologie und Psychologie). Die oben genannten Elemente werden im Bildungssystem oft als "wissenschaftliche Methode" gelehrt. Die wissenschaftliche Methode ist kein einziges Rezept: Es erfordert Intelligenz, Phantasie und Kreativität. In diesem Sinne ist es keine achtlose Reihe von Standards und Verfahren zu folgen, sondern ist ein kontinuierlicher Zyklus, der immer nützlicher, genauer und umfassender Modelle und Methoden entwickelt. Zum Beispiel, als Einstein die speziellen und allgemeinen Theorien der Relativität entwickelt, er nicht in irgendeiner Weise widerlegt oder Rabatt Newtons Principia. Im Gegenteil, wenn die astronomischen Massen, das Federlicht und die extrem schnellen aus Einsteins Theorien entfernt werden – alle Phänomene Newton konnten nicht beobachtet haben – Newtons Gleichungen bleiben. Einsteins Theorien sind Erweiterungen und Verfeinerung von Newtons Theorien und erhöhen damit das Vertrauen in Newtons Arbeit. Ein iteratives, pragmatisches Schema der vier oben genannten Punkte wird manchmal als Leitlinie für das Verfahren angeboten: Eine Frage stellen Informationen und Ressourcen sammeln (observieren) Eine erläuternde Hypothese bilden Testen Sie die Hypothese, indem Sie ein Experiment durchführen und Daten auf reproduzierbare Weise sammeln Analyse der Daten Interpretieren Sie die Daten und ziehen Sie Schlussfolgerungen, die als Ausgangspunkt für eine neue Hypothese dienen. Der bei diesem Schritt-für-Schritt-Verfahren inhärente Iterativzyklus geht von Punkt 3 auf 6 wieder auf 3 zurück. Während dieses Schema eine typische Hypothese/Testmethode skizziert, behaupten viele Philosophen, Historiker und Soziologen der Wissenschaft, einschließlich Paul Feyerabend, dass solche Beschreibungen der wissenschaftlichen Methode wenig Bezug auf die Art haben, wie die Wissenschaft tatsächlich praktiziert wird. Charakterisierungen Die wissenschaftliche Methode hängt von zunehmend anspruchsvolleren Charakterisierungen der Untersuchungsthemen ab.( Die Themen können auch als ungelöste Probleme oder die Unbekannten bezeichnet werden.) Zum Beispiel, Benjamin Franklin verworfen, richtig, dass St. Elmo Feuer war elektrisch in der Natur, aber es hat eine lange Reihe von Experimenten und theoretischen Veränderungen, um dies zu etablieren. Bei der Suche nach den jeweiligen Eigenschaften der Themen kann ein sorgfältiger Gedanke auch einige Definitionen und Beobachtungen mit sich bringen; die Beobachtungen verlangen oft sorgfältige Messungen und/oder Zählung. Die systematische, sorgfältige Erfassung von Messungen oder Zählungen relevanter Mengen ist oft der entscheidende Unterschied zwischen Pseudo-Wissenschaften wie Alchemie und Wissenschaft, wie Chemie oder Biologie. Wissenschaftliche Messungen werden in der Regel tabellarisch, grafisch oder kartiert und auf ihnen durchgeführte statistische Manipulationen, wie Korrelation und Regression. Die Messungen können in einer kontrollierten Umgebung, wie einem Labor, durchgeführt werden oder an mehr oder weniger unzugänglichen oder nicht manipulierbaren Objekten wie Sternen oder Menschen gemacht werden. Die Messungen erfordern oft spezialisierte wissenschaftliche Instrumente wie Thermometer, Spektroskope, Teilchenbeschleuniger oder Voltmeter, und der Fortschritt eines wissenschaftlichen Feldes ist in der Regel innig an ihre Erfindung und Verbesserung gebunden. Ich bin nicht daran gewöhnt, etwas mit Sicherheit nach nur einer oder zwei Beobachtungen zu sagen. Ungewissheitsmessungen in der wissenschaftlichen Arbeit werden in der Regel von Schätzungen ihrer Unsicherheit begleitet. Die Unsicherheit wird oft durch wiederholte Messungen der gewünschten Menge geschätzt. Die Unsicherheiten können auch unter Berücksichtigung der Unsicherheiten der einzelnen zugrunde liegenden Mengen berechnet werden.Zählungen von Dingen, wie die Anzahl der Menschen in einer Nation zu einem bestimmten Zeitpunkt, können auch eine Unsicherheit aufgrund der Datenerhebung Einschränkungen haben. Oder Zählungen können eine Probe von gewünschten Mengen darstellen, mit einer Unsicherheit, die von der verwendeten Probenahmemethode und der Anzahl der entnommenen Proben abhängt. Definitionsmessungen verlangen die Verwendung betrieblicher Definitionen relevanter Mengen. Das heißt, eine wissenschaftliche Menge wird beschrieben oder definiert, wie sie gemessen wird, im Gegensatz zu einer vageren, ungenauen oder idealisierten Definition. Beispielsweise kann in Ampere gemessener elektrischer Strom hinsichtlich der in einer bestimmten Zeit auf einer Elektrode in einer elektrochemischen Vorrichtung abgeschiedenen Silbermasse betriebsmäßig definiert werden, die näher beschrieben wird. Die betriebliche Definition einer Sache beruht oft auf Vergleichen mit Standards: Die operative Definition der Masse beruht letztlich auf der Verwendung eines Artefaktes, wie einem bestimmten Kilogramm Platin-Iridium, das in einem Labor in Frankreich gehalten wird. Die wissenschaftliche Definition eines Begriffs unterscheidet sich manchmal wesentlich von seinem natürlichen Sprachgebrauch. So überlappen sich Masse und Gewicht im allgemeinen Diskurs, haben aber in der Mechanik verschiedene Bedeutungen. Wissenschaftliche Größen zeichnen sich oft durch ihre Maßeinheiten aus, die später in Bezug auf konventionelle physikalische Einheiten bei der Vermittlung der Arbeit beschrieben werden können. Neue Theorien werden manchmal entwickelt, nachdem bestimmte Begriffe bisher nicht hinreichend klar definiert wurden. Zum Beispiel beginnt Albert Einsteins erstes Relativitätspapier, indem Simultanität und Mittel zur Bestimmung der Länge definiert werden. Diese Ideen wurden von Isaac Newton übersprungen, mit: "Ich definieren nicht Zeit, Raum, Ort und Bewegung, wie es allen bekannt ist." Einsteins Papier zeigt dann, dass sie (viz., absolute Zeit und Länge unabhängig von Bewegung) Annäherungen waren. Francis Crick weist uns darauf hin, dass es bei der Charakterisierung eines Subjekts jedoch verfrüht sein kann, etwas zu definieren, wenn es unverständlich bleibt. In Cricks Bewusstseinsstudie fand er es tatsächlich leichter, das Bewusstsein im visuellen System zu studieren, anstatt beispielsweise freien Willen zu studieren. Sein vorsichtiges Beispiel war das Gen; das Gen war viel schlechter verstanden, bevor Watson und Cricks wegweisende Entdeckung der Struktur der DNA; es wäre kontraproduktiv gewesen, viel Zeit auf die Definition des Gens zu verbringen, vor ihnen. DNA-Kennlinien Die Geschichte der Entdeckung der Struktur der DNA ist ein klassisches Beispiel für die Elemente der wissenschaftlichen Methode: 1950 war bekannt, dass genetische Erbschaft eine mathematische Beschreibung hatte, beginnend mit den Studien von Gregor Mendel, und dass DNA genetische Informationen enthielt (Oswald Avery's transformierende Prinzip). Aber der Mechanismus der Speicherung von genetischen Informationen (d.h. Gene) in der DNA war unklar. Forscher im Labor von Bragg an der Universität Cambridge machten Röntgenbeugungsbilder verschiedener Moleküle, beginnend mit Salzkristallen, und gehen zu komplizierteren Substanzen. Unter Verwendung von Hinweisen, die über Jahrzehnte schmerzhaft zusammengebaut wurden, ausgehend von seiner chemischen Zusammensetzung, wurde festgestellt, dass es möglich sein sollte, die physikalische Struktur von DNA zu charakterisieren, und die Röntgenbilder wären das Fahrzeug...2.DNA-Hypothesen Ein weiteres Beispiel: Präzession der Merkur Das Charakterisierungselement kann eine ausgedehnte und umfangreiche Studie erfordern, sogar Jahrhunderte. Es dauerte Tausende von Jahren Messungen, von den Chaldäern, indischen, persischen, griechischen, arabischen und europäischen Astronomen, um die Bewegung des Planeten Erde vollständig aufzunehmen. Newton war in der Lage, diese Messungen in die Konsequenzen seiner Bewegungsgesetze einzubeziehen. Aber die Perihelion des Planeten Mercury's Orbit zeigt eine Präzession, die durch Newtons Bewegungsgesetze nicht vollständig erklärt werden kann (siehe Diagramm rechts), wie Leverrier 1859 betonte. Der beobachtete Unterschied für Mercurys Präzession zwischen Newtonischer Theorie und Beobachtung war eines der Dinge, die Albert Einstein als möglicher Frühtest seiner Theorie der allgemeinen Relativität auftrat. Seine relativistischen Berechnungen entsprachen der Beobachtung viel enger als die Newtonische Theorie. Der Unterschied beträgt etwa 43 Bogensekunden pro Jahrhundert. Hypothesenentwicklung Eine Hypothese ist eine vorgeschlagene Erklärung eines Phänomens, oder abwechselnd ein mit Gründen versehener Vorschlag, der eine mögliche Korrelation zwischen oder unter einem Satz von Phänomenen nahelegt. Normalerweise haben Hypothesen die Form eines mathematischen Modells. Manchmal, aber nicht immer, können sie auch als existentielle Aussagen formuliert werden, indem man feststellt, dass eine bestimmte Instanz des untersuchten Phänomens einige charakteristische und ursächliche Erläuterungen hat, die die allgemeine Form von universalen Aussagen haben, indem man feststellt, dass jede Instanz des Phänomens eine bestimmte Eigenschaft hat.Wissenschaftler sind frei, alle Ressourcen zu nutzen, die sie haben – ihre eigene Kreativität, Ideen aus anderen Bereichen, induktive Argumentation, Bayesische Inferenz und so weiter –, um mögliche Erklärungen für ein Phänomen im Studium vorzustellen. Albert Einstein beobachtete einmal: "Es gibt keine logische Brücke zwischen Phänomenen und ihren theoretischen Prinzipien." Charles Sanders Peirce, eine Seite von Aristoteles (Prior Analytics, 2.25) leihte, beschrieb die anfänglichen Untersuchungsstadien, die von der "Reritation des Zweifels" angestiftet wurden, um eine plausible Vermutung als verführerische Vernunft zu wagen. Die Geschichte der Wissenschaft ist gefüllt mit Geschichten von Wissenschaftlern, die einen "Flash of inspiration" oder einen Hunch, die dann motiviert sie nach Beweisen zu suchen, um ihre Idee zu unterstützen oder zu widerlegen. Michael Polanyi machte solche Kreativität zum Mittelpunkt seiner Diskussion über Methodik. William Glen stellt fest, dass der Erfolg einer Hypothese oder seines Dienstes für die Wissenschaft nicht einfach in seiner wahrgenommenen Wahrheit oder Macht liegt, eine Vorgängeridee zu verdrängen, zu subsumieren oder zu reduzieren, sondern vielleicht mehr in seiner Fähigkeit, die Forschung zu stimulieren, die beleuchten wird... kahlen Suppositionen und Bereiche der Vase. Im Allgemeinen suchen Wissenschaftler eher nach Theorien, die elegant oder schön sind". Wissenschaftler verwenden diese Begriffe oft auf eine Theorie, die den bekannten Tatsachen folgt, aber dennoch relativ einfach und leicht zu handhaben ist. Occam's Razor dient in der Regel als Daumen für die Wahl der wünschenswertesten unter einer Gruppe von gleich erläuternden Hypothesen. Um die Bestätigungsvoreingenommenheit zu minimieren, die sich aus einer einzigen Hypothese ergibt, betont starke Inferenz die Notwendigkeit, mehrere alternative Hypothesen zu unterhalten. DNA-Hypothesen Linus Pauling schlug vor, dass DNA eine dreifache Helix sein könnte. Diese Hypothese wurde auch von Francis Crick und James D. Watson betrachtet, aber verworfen. Als Watson und Crick von Paulings Hypothese erfuhren, verstanden sie aus vorhandenen Daten, dass Pauling falsch war. und dass Pauling bald seine Schwierigkeiten mit dieser Struktur zugeben würde. So war das Rennen auf, um herauszufinden, die richtige Struktur (außer, dass Pauling nicht erkannte zu der Zeit, dass er in einem Rennen war) 3.DNA-Prädiktionen Vorhersagen aus der Hypothese Jede nützliche Hypothese wird Vorhersagen ermöglichen, indem sie einschließlich deduktiver Argumentation. Es könnte das Ergebnis eines Experiments in einem Labor oder die Beobachtung eines Phänomens in der Natur vorhersagen. Die Vorhersage kann auch statistisch sein und nur mit Wahrscheinlichkeiten umzugehen. Es ist wichtig, dass das Ergebnis einer solchen Vorhersage derzeit unbekannt ist. Nur in diesem Fall erhöht ein erfolgreiches Ergebnis die Wahrscheinlichkeit, dass die Hypothese wahr ist. Wenn das Ergebnis bereits bekannt ist, wird es als Folge bezeichnet und sollte bereits bei der Formulierung der Hypothese berücksichtigt worden sein. Wenn die Vorhersagen nicht durch Beobachtung oder Erfahrung zugänglich sind, ist die Hypothese noch nicht bezeugbar und so bleibt in einem strengen Sinne in diesem Ausmaß unwissenschaftlich. Eine neue Technologie oder Theorie könnte die notwendigen Experimente möglich machen. Während beispielsweise eine Hypothese über das Vorhandensein anderer intelligenter Spezies mit wissenschaftlich fundierten Spekulationen überzeugen kann, kann kein bekannter Versuch diese Hypothese testen. Daher kann die Wissenschaft selbst wenig über die Möglichkeit zu sagen haben. In Zukunft kann eine neue Technik einen experimentellen Test erlauben und die Spekulation würde dann Teil der akzeptierten Wissenschaft werden. DNA-Prädiktionen James D. Watson, Francis Crick und andere unterschätzten, dass DNA eine helixförmige Struktur hatte. Dies deutete darauf hin, dass das Röntgenbeugungsmuster der DNA "x-formiert" wäre. Diese Vorhersage folgte aus der Arbeit von Cochran, Crick und Vand (und unabhängig von Stokes). Die Cochran-Crick-Vand-Stokes-Theorem lieferte eine mathematische Erklärung für die empirische Beobachtung, dass Beugung von wendelförmigen Strukturen x-förmige Muster erzeugt. In ihrem ersten Papier merkten Watson und Crick auch an, dass die von ihnen vorgeschlagene Doppelhelixstruktur einen einfachen Mechanismus für die DNA-Replikation, Schreiben, "Es hat nicht entgangen unsere Mitteilung, dass die spezifische Paarung, die wir postuliert haben sofort einen möglichen Kopiermechanismus für das genetische Material schlägt." 4.DNA-Erfahrungen Ein weiteres Beispiel: Die allgemeine Relativitätstheorie Einsteins der allgemeinen Relativität macht mehrere spezifische Vorhersagen über die beobachtbare Struktur der Raumzeit, wie das Licht in einem Gravitationsfeld biegt, und dass die Biegung präzise von der Stärke dieses Gravitationsfeldes abhängt. Arthur Eddingtons Beobachtungen während einer Sonnenfinsternis von 1919 unterstützten die Allgemeine Relativität und nicht die neutonische Gravitation.Versuche Sobald Vorhersagen gemacht werden, können sie durch Experimente gesucht werden. Widersprechen die Testergebnisse den Vorhersagen, so werden die mit ihnen verbundenen Hypothesen in Frage gestellt und weniger vertretbar. Manchmal werden die Experimente falsch durchgeführt oder sind im Vergleich zu einem entscheidenden Experiment nicht sehr gut gestaltet. Wenn die experimentellen Ergebnisse die Vorhersagen bestätigen, dann werden die Hypothesen eher als korrekt betrachtet, aber möglicherweise noch falsch sein und weiterhin weiteren Tests unterzogen. Die experimentelle Kontrolle ist eine Technik zur Behandlung von Beobachtungsfehlern. Diese Technik verwendet den Kontrast zwischen mehreren Proben oder Beobachtungen oder Populationen unter unterschiedlichen Bedingungen, um zu sehen, was variiert oder was bleibt gleich. Wir variieren die Bedingungen für die Messhandlungen, um zu isolieren, was sich geändert hat. Mills Kanonen können uns dann helfen herauszufinden, was der wichtige Faktor ist. Faktoranalyse ist eine Technik, um den wichtigen Faktor in einem Effekt zu entdecken. Je nach Vorhersagen können die Experimente unterschiedliche Formen aufweisen. Es könnte ein klassisches Experiment in einem Labor, einer Doppelblind-Studie oder einer archäologischen Ausgrabung sein. Auch ein Flugzeug von New York nach Paris zu nehmen ist ein Experiment, das die aerodynamischen Hypothesen testet, die für die Konstruktion des Flugzeugs verwendet werden. Wissenschaftler nehmen eine Haltung von Offenheit und Rechenschaftspflicht auf dem Teil der Experimente an. Eine detaillierte Aufzeichnung ist unerlässlich, um bei der Erfassung und Berichterstattung über die experimentellen Ergebnisse zu helfen und die Wirksamkeit und Integrität des Verfahrens zu unterstützen. Sie werden auch bei der Wiedergabe der experimentellen Ergebnisse helfen, wahrscheinlich von anderen. Spuren dieses Ansatzes können in der Arbeit von Hipparchus (190–120 v. Chr.) bei der Bestimmung eines Wertes für die Präzession der Erde gesehen werden, während kontrollierte Experimente in den Arbeiten von Al-Battani (853–929 c.) und Alhazen (965–1039 c.) DNA-Erfahrungen Watson und Crick zeigten einen ersten (und falschen) Vorschlag für die Struktur von DNA zu einem Team von Kings. Franklin entdeckte sofort die Fehler, die den Wassergehalt betrafen. Später sah Watson Franklins detaillierte Röntgenbeugungsbilder, die eine X-Form zeigten und die Struktur bestätigen konnte, war schraubenförmig. Dieses neu entfachte Watson und Crick Modellbau und führte zu der richtigen Struktur...1.DNA-Charakterisierungen Evaluation und Verbesserung Die wissenschaftliche Methode ist iterativ. In jedem Stadium ist es möglich, seine Genauigkeit und Präzision zu verfeinern, so dass einige Überlegungen dazu führen, dass der Wissenschaftler einen früheren Teil des Prozesses wiederholt. Die Nichterarbeitung einer interessanten Hypothese kann einen Wissenschaftler dazu führen, das betrachtete Thema neu zu definieren. Die Nichteinhaltung einer Hypothese zur Herstellung interessanter und prüfbarer Vorhersagen kann zu einer Überlegung der Hypothese oder der Definition des Subjekts führen. Das Fehlen eines Experiments, um interessante Ergebnisse zu erzielen, kann einen Wissenschaftler dazu führen, die experimentelle Methode, die Hypothese oder die Definition des Themas zu überdenken. Andere Wissenschaftler können ihre eigene Forschung beginnen und den Prozess auf jeder Stufe einleiten. Sie könnten die Charakterisierung annehmen und ihre eigene Hypothese formulieren, oder sie könnten die Hypothese annehmen und ihre eigenen Vorhersagen ableiten. Oft wird das Experiment nicht von der Person durchgeführt, die die Vorhersage gemacht hat, und die Charakterisierung basiert auf Experimenten, die von einer anderen gemacht werden. Die veröffentlichten Ergebnisse von Experimenten können auch als Hypothese dienen, die ihre eigene Reproduzierbarkeit vorhersagt. DNA-Bewegungen Nach erheblichen fruchtlosen Experimenten, die von ihrem Vorgesetzten und zahlreichen Fehlstarts entmutigt wurden, konnten Watson und Crick die wesentliche Struktur der DNA durch konkrete Modellierung der physikalischen Formen der Nukleotide, die sie enthalten, erniedrigen. Sie wurden von den Bandlängen geführt, die von Linus Pauling und von Rosalind Franklins Röntgenbeugungsbildern abgeleitet worden waren... DNA Beispiel Confirmation Science ist ein soziales Unternehmen, und wissenschaftliche Arbeit neigt dazu, von der wissenschaftlichen Gemeinschaft akzeptiert werden, wenn es bestätigt wurde. In der wissenschaftlichen Gemeinschaft müssen streng experimentelle und theoretische Ergebnisse von anderen wiedergegeben werden. Die Forscher haben ihr Leben für diese Vision gegeben; Georg Wilhelm Richmann wurde von Ballblitz (1753) getötet, als er versuchte, das 1752 kitefliegende Experiment von Benjamin Franklin zu replizieren. Um vor schlechten wissenschaftlichen und betrügerischen Daten zu schützen, haben staatliche Forschungsagenturen wie die National Science Foundation und Wissenschaftsmagazine, einschließlich Natur und Wissenschaft, eine Politik, die Forscher ihre Daten und Methoden archivieren müssen, damit andere Forscher die Daten und Methoden testen und auf der Forschung aufbauen können, die vorher gegangen ist.Die wissenschaftliche Datenarchivierung kann in mehreren nationalen Archiven in den USA oder im World Data Center erfolgen. Wissenschaftliche Untersuchung Wissenschaftliche Untersuchung zielt generell darauf ab, Kenntnisse in Form von prüfbaren Erklärungen zu erhalten, mit denen Wissenschaftler die Ergebnisse zukünftiger Experimente vorhersagen können. Dies ermöglicht es Wissenschaftlern, ein besseres Verständnis des Themas zu gewinnen, und später, dieses Verständnis zu verwenden, um in seine ursächlichen Mechanismen einzugreifen (z.B. Krankheit zu heilen). Je besser eine Erklärung ist, Vorhersagen zu machen, desto nützlicher kann es häufig sein, und je wahrscheinlicher es wird weiterhin einen Körper von Beweisen besser erklären als seine Alternativen. Die erfolgreichsten Erklärungen – diejenigen, die genaue Vorhersagen in einer Vielzahl von Umständen erklären und machen – werden oft als wissenschaftliche Theorien bezeichnet. Die meisten experimentellen Ergebnisse produzieren keine großen Veränderungen des menschlichen Verständnisses; Verbesserungen des theoretischen wissenschaftlichen Verständnisses resultieren in der Regel aus einem allmählichen Entwicklungsprozess im Laufe der Zeit, manchmal über verschiedene Bereiche der Wissenschaft. Wissenschaftliche Modelle variieren in dem Maße, in dem sie experimentell getestet wurden und wie lange und in ihrer Akzeptanz in der wissenschaftlichen Gemeinschaft. Im Allgemeinen werden Erklärungen im Laufe der Zeit akzeptiert, da sich die Beweise auf einem bestimmten Thema ansammeln, und die fragliche Erklärung erweist sich als mächtiger als ihre Alternativen zur Erklärung der Beweise. Oft bilden sich anschließende Forscher die Erklärungen im Laufe der Zeit neu, oder kombinierte Erklärungen, um neue Erklärungen zu erstellen. Tow sieht die wissenschaftliche Methode in Bezug auf einen evolutionären Algorithmus angewandt auf Wissenschaft und Technologie. Siehe Ceteris paribus, und Mutatis mutandis Eigenschaften der wissenschaftlichen Untersuchung Wissenschaftliches Wissen ist eng mit empirischen Befunden verknüpft und kann der Fälschung unterliegen, wenn neue experimentelle Beobachtungen mit dem, was gefunden wird, unvereinbar sind. Das heißt, keine Theorie kann jemals als endgültig betrachtet werden, da neue problematische Beweise entdeckt werden könnten. Wenn solche Beweise gefunden werden, kann eine neue Theorie vorgeschlagen werden, oder (mehr allgemein) wird festgestellt, dass Änderungen der vorherigen Theorie ausreichen, um die neuen Beweise zu erklären. Die Stärke einer Theorie bezieht sich darauf, wie lange sie ohne wesentliche Änderungen an ihren Kernprinzipien fortbesteht (siehe invariante Erklärungen). Theorien können auch von anderen Theorien subsumiert werden. Zum Beispiel, Newtons Gesetze erklärt Tausende von Jahren wissenschaftlichen Beobachtungen der Planeten fast perfekt. Diese Gesetze wurden dann jedoch als Sonderfälle einer allgemeineren Theorie (Relativität) bestimmt, die sowohl die (bisher unerklärten) Ausnahmen zu Newtons Gesetzen erklärten und andere Beobachtungen wie die Ablenkung von Licht durch die Schwerkraft vorhergesagt und erläuterte. So können in bestimmten Fällen unabhängige, nicht miteinander verbundene wissenschaftliche Beobachtungen verbunden werden, die durch Prinzipien der zunehmenden Erwartungskraft vereinheitlicht werden. Da neue Theorien möglicherweise umfassender sein könnten als dem, was ihnen vorausging, und damit mehr als früher erklären können, können Nachfolgetheorien einen höheren Standard erfüllen, indem sie einen größeren Beobachtungskörper als ihre Vorgänger erklären. So erklärt beispielsweise die Evolutionstheorie die Vielfalt des Lebens auf der Erde, wie sich Spezies an ihre Umgebungen anpassen und viele andere in der natürlichen Welt beobachtete Muster; ihre jüngste große Veränderung war die Vereinigung mit Genetik, um die moderne evolutionäre Synthese zu bilden. In nachfolgenden Modifikationen hat sie auch Aspekte vieler anderer Bereiche wie Biochemie und Molekularbiologie subsumiert. Beliefs und Bias Wissenschaftliche Methodik leitet oft, dass Hypothesen unter kontrollierten Bedingungen getestet werden, wo immer möglich. Dies ist häufig in bestimmten Bereichen, wie in den biologischen Wissenschaften, und in anderen Bereichen, wie in der Astronomie, schwieriger möglich. Die Praxis der experimentellen Kontrolle und Reproduzierbarkeit kann die Wirkung haben, die potenziell schädlichen Auswirkungen von Umstand und zu einem Grad persönliche Vorspannung zu verringern. Zum Beispiel können vorbestehende Überzeugungen die Interpretation der Ergebnisse verändern, wie in Bestätigungsvoreingenommenheit; dies ist eine heuristische, die eine Person mit einem bestimmten Glauben führt, Dinge zu sehen, die ihren Glauben verstärken, auch wenn ein anderer Beobachter widersprechen könnte (d.h. die Menschen neigen dazu, zu beobachten, was sie erwarten). ( T] die Handlung des Denkens wird durch die Irritation des Zweifels aufgeregt und hört auf, wenn der Glaube erreicht wird – C.S Peirce (1877) Wie wir unsere Ideen machenClear Ein historisches Beispiel ist der Glaube, dass die Beine eines galoppierenden Pferdes an dem Punkt, an dem keiner der Beine des Pferdes den Boden berührt, an den Punkt dieses Bildes in Gemälden von seinen Anhängern eingeschlossen wird.Die ersten Stop-Action-Bilder eines Pferdegalopps von Eadweard Muybridge zeigten jedoch, dass dies falsch ist und die Beine stattdessen zusammengefügt werden. Eine weitere wichtige menschliche Voreingenommenheit, die eine Rolle spielt, ist eine Vorliebe für neue, überraschende Aussagen (siehe Berufung auf Neuheit), die zu einer Suche nach Beweisen führen können, dass das Neue wahr ist. Schlecht bezeugte Überzeugungen können über eine weniger strenge heuristische geglaubt und gehandelt werden. Goldhaber und Nieto veröffentlichten im Jahr 2010 die Beobachtung, dass, wenn theoretische Strukturen mit "viele eng benachbarte Themen durch die Verbindung von theoretischen Konzepten beschrieben werden, die theoretische Struktur eine Robustheit erwirbt, die es immer schwieriger macht – wenn auch sicher nie unmöglich – zu stürzen". Wenn eine Erzählung aufgebaut ist, werden ihre Elemente leichter zu glauben. Fleck 1979, S. 27 bemerkt "Words und Ideen sind ursprünglich phonetische und geistige Äquivalenz der Erfahrungen, die mit ihnen übereinstimmen. .Such proto-ideas sind zunächst immer zu breit und unzureichend spezialisiert.... Sobald ein strukturell vollständiges und geschlossenes Meinungssystem aus vielen Details und Beziehungen gebildet wurde, bietet es dauerhaften Widerstand gegen alles, was ihm widerspricht". Manchmal haben diese Beziehungen ihre Elemente a priori angenommen, oder enthalten einige andere logische oder methodologische Fehler in dem Prozess, die sie schließlich produziert. Donald M. MacKay hat diese Elemente in Bezug auf die Messgenauigkeit in Grenzen analysiert und mit Instrumentalelementen in einer Messkategorie verknüpft. Modelle der wissenschaftlichen Untersuchung Klassisches Modell Das klassische Modell der wissenschaftlichen Untersuchung leitet sich von Aristoteles ab, der die Formen der ungefähren und genauen Begründung unterscheidet, das dreifache Schema der ableitenden, deduktiven und induktiven Inferenz festlegte und auch die Verbindungsformen wie Argumentation durch Analogie behandelte. Hypothetisch-deduktives Modell Das hypothetisch-deduktive Modell oder Verfahren ist eine vorgeschlagene Beschreibung des wissenschaftlichen Verfahrens. Hier sind Vorhersagen aus der Hypothese zentral: Wenn Sie die Hypothese wahrnehmen, welche Konsequenzen folgen? Wenn eine anschließende empirische Untersuchung nicht zeigt, dass diese Konsequenzen oder Vorhersagen der beobachtbaren Welt entsprechen, kann die Hypothese als falsch abgeschlossen werden. Pragmatisches ModellIm Jahre 1877 charakterisierte Charles Sanders Peirce (1839–1914) die Untersuchung im Allgemeinen nicht als die Verfolgung der Wahrheit an sich, sondern als Kampf um den Umzug von irritierenden, hemmenden Zweifeln, die von Überraschungen, Meinungsverschiedenheiten und dergleichen geboren wurden, und um einen sicheren Glauben zu erreichen, der glaubt, dass man bereit ist zu handeln. Er hat wissenschaftliche Untersuchung im Rahmen eines breiteren Spektrums gerahmt und, wie die Untersuchung allgemein, durch tatsächliche Zweifel, nicht bloße verbale oder hyperbolische Zweifel, die er als fruchtlos gehalten. Er skizzierte vier Methoden der Meinungssetzung, die von mindestens bis zum erfolgreichsten bestellt wurden: Die Methode der Hartnäckigkeit (Politik, sich an den ursprünglichen Glauben zu halten) – die Komfort und Entschlossenheit bringt, aber dazu führt, zu versuchen, gegensätzliche Informationen und andere Ansichten zu ignorieren, als wäre die Wahrheit intrinsisch privat, nicht öffentlich. Es geht gegen den sozialen Impuls und lässt sich leicht ändern, denn man kann gut bemerken, wenn die Meinung eines anderen genauso gut ist wie die eigene erste Meinung. Seine Erfolge können glänzen, aber neigen dazu, vorübergehend zu sein. Die Methode der Autorität – die Unstimmigkeiten überwindet, aber manchmal brutal. Seine Erfolge können majestätisch und langlebig sein, aber es kann nicht gut genug funktionieren, um Zweifel unbestimmt zu unterdrücken, vor allem wenn die Menschen von der Gegenwart und Vergangenheit anderer Gesellschaften lernen. Die Methode der a priori – die die Konformität weniger brutal fördert, fördert aber Meinungen als etwas wie Geschmack, entsteht im Gespräch und Vergleichen von Perspektiven in Bezug auf "was zu vernunften ist." Dabei hängt es von der Mode in Paradigmen ab und geht im Laufe der Zeit in Kreisen. Es ist intellektueller und respektvoller, aber, wie die ersten beiden Methoden, hält versehentliche und katastrophale Überzeugungen, die einige Geister dazu bestimmt, es zu zweifeln. Die wissenschaftliche Methode – die Methode, bei der sich die Untersuchung als fallbar betrachtet und gezielt selbst testet und kritisiert, korrigiert und sich verbessert. Peirce stellte fest, dass eine langsame, stolpernde Rationanzierung in praktischer Hinsicht gefährlich schlechter als instinkte und traditionelle Stimmung sein kann, und dass die wissenschaftliche Methode am besten für die theoretische Forschung geeignet ist, die wiederum nicht durch die anderen Methoden und praktischen Enden zertrümmert werden sollte; die "erste Regel" der Vernunft ist, dass man lernen muss und als Corollar den Weg der Untersuchung nicht blockieren muss.Die wissenschaftliche Methode zeichnet die anderen dadurch aus, dass sie bewusst ankommen – schließlich – zu den sichersten Überzeugungen, auf denen die erfolgreichsten Praktiken basieren können. Ausgehend von der Idee, dass die Menschen nicht die Wahrheit an sich suchen, sondern irritierende, hemmende Zweifel zu unterwerfen, zeigte Peirce, wie durch den Kampf einige kommen können, um der Wahrheit um der Integrität des Glaubens zu unterwerfen, als Wahrheit die Führung der möglichen Praxis richtig zu ihrem gegebenen Ziel zu suchen, und sich der wissenschaftlichen Methode zu weiden. Für Peirce, rationale Untersuchung impliziert Präsuppositionen über die Wahrheit und das Reale; zu Vernunft ist, (und zumindest zu hoffen) als Prinzip der Selbstregulierung des Vernunfters zu presuppieren, dass das Reale von unseren Meinungsvätern erfindbar und unabhängig ist. In dieser Vene definierte er die Wahrheit als die Korrespondenz eines Zeichens (insbesondere eine Veranlagung) zu seinem Objekt und pragmatisch nicht als der tatsächliche Konsens einer bestimmten, endlichen Gemeinschaft (so, dass die Experten befragt werden sollten), sondern als die endgültige Meinung, die alle Ermittler früher oder später erreichen würden, aber immer noch unvermeidlich, wenn sie die Untersuchung weit genug verschieben würden, auch wenn sie von verschiedenen Punkten ausgehen. In Tandem definierte er das reale als ein wahres Zeichenobjekt (sein, dass eine Möglichkeit oder Qualität, oder eine Aktualität oder brutale Tatsache, oder eine Notwendigkeit oder Norm oder Gesetz,) das ist, was es unabhängig von einer endlichen Meinung der Gemeinschaft ist und pragmatisch nur von der endgültigen Stellungnahme abhängt, die in einer ausreichenden Untersuchung vorgesehen ist. Das ist ein Ziel, soweit oder nahe, wie die Wahrheit selbst dir oder mir oder der gegebenen endlichen Gemeinschaft. So kocht seine Untersuchungstheorie auf "Do the science. " Diese Wahrheitsbegriffe und das Reale beinhalten die Idee einer Gemeinschaft, die sowohl ohne bestimmte Grenzen (und damit potentiell selbstkorrigierend, soweit erforderlich) als auch in der Lage ist, den Wissensanstieg zu bestimmen. Als Inferenz "die Logik ist im sozialen Prinzip verwurzelt", da sie von einem Standpunkt abhängt, der in einem Sinne unbegrenzt ist. Als besonderes Augenmerk auf die Erstellung von Erklärungen legte Peirce die wissenschaftliche Methode als Koordinierung von drei Arten von Gegensätzen in einem gezielten Zyklus dar, der darauf abzielte, wie folgt zu zweifeln (in §III-IV in "A Neglected Argument" mit Ausnahme der anderen Ausführungen:) Entführung (oder Nachführung). Ratet, in Bezug auf die erläuternden Hypothesen für die Auswahl der besten versuchen. Von der Entführung unterscheidet Peirce Induktion als Induktion, basierend auf Tests, den Anteil der Wahrheit in der Hypothese. Jede Untersuchung, ob zu Ideen, brutalen Fakten oder Normen und Gesetzen, ergibt sich aus überraschenden Beobachtungen in einem oder mehreren dieser Bereiche (und zum Beispiel in jedem Stadium einer bereits laufenden Untersuchung). Alle erläuternden Inhalte der Theorien stammen aus der Entführung, die eine neue oder äußere Idee ermutigt, um auf einfache, wirtschaftliche Weise für ein überraschendes oder komplizierendes Phänomen zu berücksichtigen. Oft vermutet sogar ein gut vorbereiteter Geist falsch. Aber der Erfolgsmodicum unserer Vermutungen weit übertrifft die von viel Glück und scheint von der Verstimmung der Natur durch Instinkte entwickelt oder inhärent geboren, vor allem, wenn die besten Vermutungen sind optimal plausibel und einfach im Sinne, sagte Peirce, der "Facile und natürlich", wie durch Galileos natürliches Licht der Vernunft und so deutlich von "logischer Einfachheit". Entführung ist die fruchtbarste, aber am wenigsten sichere Art der Inferenz. Seine allgemeine Rationalität ist induktiv: es gelingt oft genug und ohne sie gibt es keine Hoffnung auf hinreichend expeditierende Untersuchung (oft multigenerational) zu neuen Wahrheiten. Die koordinative Methode führt dazu, dass eine plausible Hypothese abgestoßen wird, um sie für ihre Testbarkeit zu beurteilen und wie ihre Studie die Untersuchung selbst stimulieren würde. Peirce nennt seinen Pragmatismus "die Logik der Entführung". Seine pragmatische Maxime ist: "Berücksichtigen Sie, welche Auswirkungen, die wahrscheinlich praktische Lager haben könnten, die Sie die Objekte Ihrer Konzeption zu haben. Dann ist Ihre Konzeption dieser Effekte die ganze Vorstellung von dem Objekt". Sein Pragmatismus ist eine Methode, um konzeptionelle Verwirrung fruchtbar zu reduzieren, indem er die Bedeutung jeder Konzeption mit den denkbaren praktischen Auswirkungen seiner empfundenen Wirkungen gleichsetzt – eine Methode der experimentellen mentalen Reflexion, die zur Bildung von Hypothesen und zur Untersuchung dieser geeignet ist. Es begünstigt Effizienz. Die Hypothese, die unsicher ist, muss praktische Auswirkungen haben, die zumindest zu psychischen Tests führen und sich in der Wissenschaft an wissenschaftliche Tests vergeben. Eine einfache, aber unwahrscheinliche Vermutung, wenn unzu teuer, um auf Fälschungen zu testen, kann zuerst in der Linie für die Prüfung gehören.Eine Vermutung ist intrinsisch zu testen, ob sie instinktive Plausibilität oder begründete objektive Wahrscheinlichkeit hat, während subjektive Wahrscheinlichkeit, obwohl befunden, irreführend verführerisch sein kann. Guesses kann für den Prozess strategisch gewählt werden, für ihre Vorsicht (für die Peirce gab als Beispiel das Spiel von Zwanzig Fragen,) Breite und Unkomplexität. Man kann hoffen, nur jene Zeit zu entdecken, die durch die ausreichende Erfahrung eines Lernenden sowieso enthüllen würde, so dass es darum geht, es zu beschleunigen; die Wirtschaft der Forschung ist das, was den Sprung, sozusagen, von Entführung verlangt und seine Kunst regiert. Abzug. Zwei Stufen: Explikation. Unklar prämisierte, aber deduktive Analyse der Hypothese, um ihre Teile so klar wie möglich zu machen. Demonstration: Deduktive Argumentation, Euclidean im Verfahren. Explizite Ableitung der Folgen der Hypothese als Vorhersagen, für Induktion zu testen, über Beweise gefunden werden. Corollarial oder, falls erforderlich, theorematisch. Induktion. Die langfristige Gültigkeit der Induktionsregel ist aus dem Prinzip (vorübergehender, allgemeiner Begründung) abziehbar, dass die Realität nur das Ziel der endgültigen Stellungnahme ist, zu der eine angemessene Untersuchung führen würde; alles, was kein solcher Prozess jemals führen würde, wäre nicht real. Induktion mit laufenden Tests oder Beobachtungen folgt ein Verfahren, das seinen Fehler unter einem vorbeschriebenen Grad verringert. Drei Stufen: Klassifizierung. Unklar prämiert, aber induktiv, Klassifizierung von Objekten der Erfahrung unter allgemeinen Ideen. Aussprache: direkte induktive Argumentation. Crude (die Aufzählung von Instanzen) oder allmählich (neue Schätzung des Anteils der Wahrheit in der Hypothese nach jedem Test). Graduale Induktion ist qualitativ oder quantitativ; wenn qualitativ, dann abhängig von Gewichtungen von Qualitäten oder Zeichen; wenn quantitativ, dann abhängig von Messungen, oder von Statistiken, oder von Zählungen. Sentential Induction. "... die durch induktive Argumentationen die unterschiedlichen Probationen einzeln begutachtet, dann ihre Kombinationen, dann macht sich selbstbegutachtend von diesen Einschätzungen selbst und vergeht das endgültige Urteil über das gesamte Ergebnis." Invariante Erklärung In einem TED-Gespräch 2009 veröffentlichte Deutsch ein Kriterium für die wissenschaftliche Erklärung, das heißt, Unzulänglichkeiten zu formulieren: "Eine Erklärung [öffentlich, so dass sie später von anderen datiert und verifiziert werden kann], die invariant bleibt [in Angesicht der scheinbaren Veränderung, neuen Informationen oder unerwarteten Bedingungen]". "Eine schlechte Erklärung ist einfach zu variieren. " "Die Suche nach schwergängigen Erklärungen ist der Ursprung aller Fortschritte" "Dass die Wahrheit aus hart-vären Behauptungen über die Realität besteht, ist die wichtigste Tatsache über die physische Welt. " Invarianz als fundamentaler Aspekt einer wissenschaftlichen Realität war schon lange Teil der Wissenschaftsphilosophie: So bemerkte Friedel Weinerts Buch The Scientist as Philosoph (2004) das Thema in vielen Schriften von etwa 1900 an, wie Werke von Henri Poincaré (1902,) Ernst Cassirer (1920,) Max Born (1949 und 1953,) Paul Dirac (1958,) Olivier Costa de Beauwell Kommunikation und Gemeinschaft Häufig wird die wissenschaftliche Methode nicht nur von einer einzigen Person, sondern auch von mehreren Personen verwendet, die direkt oder indirekt zusammenarbeiten. Eine solche Zusammenarbeit kann als wichtiges Element einer wissenschaftlichen Gemeinschaft angesehen werden. Verschiedene Standards der wissenschaftlichen Methodik werden in einem solchen Umfeld verwendet. Peer Review Evaluation Wissenschaftliche Zeitschriften verwenden einen Prozess der Peer Review, in dem die Manuskripte von Wissenschaftlern von Redakteuren wissenschaftlicher Zeitschriften an (in der Regel ein bis drei, meist anonyme) Wissenschaftler, die mit dem Bereich der Evaluation vertraut sind, eingereicht werden. In bestimmten Zeitschriften wählt die Zeitschrift selbst die Schiedsrichter; während in anderen (insbesondere Zeitschriften, die extrem spezialisiert sind) der Manuskript-Autor kann Referenten empfehlen. Die Schiedsrichter können oder dürfen keine Veröffentlichung empfehlen, oder sie können die Veröffentlichung mit vorgeschlagenen Änderungen empfehlen, oder manchmal, Veröffentlichung in einem anderen Journal. Dieser Standard wird durch verschiedene Zeitschriften auf verschiedene Grade geübt und kann die Wirkung haben, die Literatur frei von offensichtlichen Fehlern zu halten und generell die Qualität des Materials zu verbessern, insbesondere in den Zeitschriften, die den Standard am strengsten verwenden.Der Peer-Review-Prozess kann Einschränkungen haben, wenn man die Forschung außerhalb des herkömmlichen wissenschaftlichen Paradigmas betrachtet: Probleme von Groupthink können die offene und faire Beratung einiger neuer Forschungen beeinträchtigen. Dokumentation und ReplikationSometimes-Experimente können während ihrer Experimente systematische Fehler machen, aus verschiedenen Gründen Veer aus Standardmethoden und Praktiken (Pathologische Wissenschaft) oder in seltenen Fällen bewusst falsche Ergebnisse melden. Gelegentlich deshalb könnten andere Wissenschaftler versuchen, die Experimente zu wiederholen, um die Ergebnisse zu duplizieren. Die Archivierung von Forschern praktiziert manchmal die wissenschaftliche Datenarchivierung, wie etwa in Übereinstimmung mit den Politiken von staatlichen Förderorganisationen und wissenschaftlichen Zeitschriften. In diesen Fällen können detaillierte Aufzeichnungen über ihre experimentellen Verfahren, Rohdaten, statistische Analysen und Quellcode aufbewahrt werden, um die Methodik und Praxis des Verfahrens zu belegen und potenzielle zukünftige Versuche zur Reproduktion des Ergebnisses zu unterstützen. Diese Verfahrensprotokolle können auch bei der Konzeption neuer Experimente helfen, die Hypothese zu testen, und können Ingenieuren nützlich sein, die die möglichen praktischen Anwendungen einer Entdeckung untersuchen könnten. Datenaustausch Wenn zusätzliche Informationen benötigt werden, bevor eine Studie reproduziert werden kann, könnte der Autor der Studie gebeten werden, sie bereitzustellen. Sie können sie bereitstellen, oder wenn der Autor sich weigert, Daten zu teilen, können Berufungen an die Journal-Editoren, die die Studie oder an die Institution, die die Forschung finanziert. Einschränkungen Da ein Wissenschaftler nicht alles aufzeichnen kann, was in einem Experiment stattgefunden hat, werden Fakten gemeldet, die für ihre offensichtliche Relevanz ausgewählt wurden. Dies kann unvermeidlich zu Problemen führen, wenn einige angeblich irrelevante Funktion in Frage gestellt wird. Zum Beispiel hat Heinrich Hertz nicht die Größe des Raumes berichtet, der verwendet wurde, um Maxwells Gleichungen zu testen, was sich später als eine kleine Abweichung in den Ergebnissen herausstellte. Das Problem ist, dass Teile der Theorie selbst angenommen werden müssen, um die experimentellen Bedingungen auszuwählen und zu melden. Die Beobachtungen werden daher manchmal als theoriebeladen bezeichnet. Wissenschaft komplexer Systeme Wissenschaft auf komplexe Systeme angewendet kann Elemente wie Transdisziplinarität, Systemtheorie, Steuerungstheorie und wissenschaftliche Modellierung beinhalten. Das Santa Fe-Institut untersucht solche Systeme; Murray Gell-Mann verbindet diese Themen mit der Nachrichtenübermittlung. Im Allgemeinen kann die wissenschaftliche Methode schwierig sein, auf vielfältige, miteinander verbundene Systeme und große Datensätze streng anzuwenden. Insbesondere können Praktiken, die innerhalb von Big-Daten verwendet werden, wie z.B. Prädiktionsanalysen, als mit der wissenschaftlichen Methode unwahrscheinlich angesehen werden, da einige der Daten von den Parametern, die in alternativen Hypothesen für eine Erklärung substanziell sein könnten, abgestreift worden sind; so würden die abgestreiften Daten nur dazu dienen, die Nullhypothese in der Prädiktivanalytik-Anwendung zu unterstützen. Fleck 1979, S.38–50 bemerkt "eine wissenschaftliche Entdeckung bleibt unvollständig, ohne die sozialen Praktiken zu berücksichtigen, die sie beeinflussen." Philosophie und Soziologie der Wissenschaft Analytische Philosophie Wissenschaftsphilosophie betrachtet die zugrunde liegende Logik der wissenschaftlichen Methode, was die Wissenschaft von der Nicht-Wissenschaft trennt, und die Ethik, die in der Wissenschaft implizit ist. Es gibt grundlegende Annahmen, die von der Philosophie von mindestens einem prominenten Wissenschaftler abgeleitet werden, die die Grundlage der wissenschaftlichen Methode bilden – nämlich dass die Realität objektiv und konsequent ist, dass die Menschen die Fähigkeit haben, die Realität genau wahrzunehmen, und dass rationale Erklärungen für Elemente der realen Welt existieren. Diese Annahmen aus dem methodischen Naturalismus bilden eine Grundlage, auf der die Wissenschaft geerdet werden kann. Logical Positivist, empiricist, Falsificationist und andere Theorien haben diese Annahmen und angesichts alternativer Konten der Logik der Wissenschaft kritisiert, aber jeder ist auch selbst kritisiert worden. Thomas Kuhn untersuchte die Geschichte der Wissenschaft in seiner Struktur der wissenschaftlichen Revolutionen und fand heraus, dass die tatsächliche Methode, die von Wissenschaftlern verwendet wurde, dramatisch von der damals verschwendeten Methode abweichte. Seine Beobachtungen der Wissenschaftspraxis sind im Wesentlichen sozilogisch und sprechen nicht darüber, wie die Wissenschaft in anderen Zeiten und anderen Kulturen praktiziert werden kann. Norwood Russell Hanson, Imre Lakatos und Thomas Kuhn haben umfangreiche Arbeiten an dem theoretischen Charakter der Beobachtung gemacht. Hanson (1958) prägte zunächst den Begriff für die Idee, dass alle Beobachtungen vom konzeptionellen Rahmen des Betrachters abhängig sind, indem er das Konzept der Gestalt nutzt, um zu zeigen, wie die Vorurteile sowohl die Beobachtung als auch die Beschreibung beeinflussen können.Er öffnet Kapitel 1 mit einer Diskussion über die Golgi-Körper und ihre anfängliche Ablehnung als Artefakt der Färbetechnik, und eine Diskussion von Brahe und Kepler beobachten die Morgendämmerung und sehen einen anderen Sonnenaufgang trotz des gleichen physiologischen Phänomens. Kuhn und Feyerabend erkennen die wegweisende Bedeutung von Hansons Arbeit an. Kuhn sagte, der Wissenschaftler hat in der Regel eine Theorie im Auge, bevor er Experimente entwerfen und unternehmen, um empirische Beobachtungen zu machen, und dass der "Weg von Theorie zu Messung fast nie rückwärts gefahren werden kann". Für Kuhn bedeutet dies, dass, wie Theorie getestet wird, durch die Art der Theorie selbst diktiert wird, was Kuhn dazu führte, zu argumentieren, dass "da es von einem Beruf angenommen wurde .keine Theorie wird durch irgendwelche quantitative Tests, die es nicht bereits bestanden erkannt werden" (wie Kuhn rationalistische Denken Stil.) Der Postmoderne- und Wissenschaftskrieg Paul Feyerabend hat die Geschichte der Wissenschaft ähnlich untersucht und verleugnet, dass die Wissenschaft wirklich ein methodologischer Prozess ist. In seinem Buch Gegen Methode argumentiert er, dass der wissenschaftliche Fortschritt nicht das Ergebnis der Anwendung einer bestimmten Methode ist. Im Wesentlichen sagt er, dass man für jede bestimmte Methode oder Norm der Wissenschaft eine historische Episode finden kann, in der sie gegen den Fortschritt der Wissenschaft beigetragen hat. Wenn also Gläubige an die wissenschaftliche Methode eine einzige allgemein gültige Regel ausdrücken wollen, schlägt Feyerabend vor, dass es "alles geht". Dies ist jedoch unwirtschaftlich. Kritiken wie Feyerabend führten zum starken Programm, einem radikalen Ansatz der Soziologie der Wissenschaft. Die postmodernen Kritiken der Wissenschaft waren selbst Gegenstand intensiver Kontroversen. Diese laufende Debatte, die als Wissenschaftskriege bekannt ist, ist das Ergebnis von widersprüchlichen Werten und Annahmen zwischen postmodernen und realistischen Lagern. Während Postmodernisten behaupten, dass das wissenschaftliche Wissen einfach ein weiterer Diskurs ist (Anmerkung, dass dieser Begriff in diesem Zusammenhang besondere Bedeutung hat) und nicht repräsentativ für jede Form der fundamentalen Wahrheit ist, behaupten Realisten in der wissenschaftlichen Gemeinschaft, dass wissenschaftliche Erkenntnisse reale und grundlegende Wahrheiten über die Realität offenbaren. Viele Bücher wurden von Wissenschaftlern geschrieben, die dieses Problem angehen und die Behauptungen der Postmodernisten herausfordern und die Wissenschaft als legitime Methode der Wahrheitsableitung verteidigen. Anthropologie und Soziologie In der Anthropologie und Soziologie, nach der Feldforschung in einem wissenschaftlichen Labor von Latour und Woolgar, hat Karin Knorr Cetina eine vergleichende Studie von zwei wissenschaftlichen Feldern (nämlich Hochenergiephysik und Molekularbiologie) durchgeführt, um zu schließen, dass die epistemischen Praktiken und Argumente in beiden wissenschaftlichen Gemeinschaften unterschiedlich sind, um das Konzept der "epistemischen Kulturen" im Widerspruch zu der Idee, dass eine so genannte "wissenschaftliche Methode" ist. Vergleiche "epistemische Kulturen" mit Fleck 1935, Gedankenkollektiven, (denkkollektiven:) Entstehung und Entwicklung einer wissenschaftlichen Tatsache:Einfǖhrung in der Lehre vom Denkstil und DenkkollektivFleck 1979, p. xxvii erkennt, dass Tatsachen Leben haben, die erst nach Inkubationszeiten blühen. Seine gewählte Frage nach der Untersuchung (1934) war "HOW, THEN, DID DIESES EMPIRISCHE FRAGEN ORIGINATE UND IN WAS IT CONSIST?". Aber von Fleck 1979, S.27, müssen sich die Gedankenkollektive in den jeweiligen Bereichen auf gemeinsame Fachterminologie begeben, ihre Ergebnisse veröffentlichen und mit ihren Kollegen über die gemeinsame Terminologie weiter kommunizieren, um voranzukommen. Siehe: Psychologie und Neurowissenschaften Beziehung mit Mathematik Wissenschaft ist der Prozess der Sammlung, Vergleichen und Bewertung der vorgeschlagenen Modelle gegen Beobachtungsmaterialien. Ein Modell kann eine Simulation, mathematische oder chemische Formel oder Satz von vorgeschlagenen Schritten sein. Wissenschaft ist wie Mathematik in, dass Forscher in beiden Disziplinen versuchen, zu unterscheiden, was aus dem, was unbekannt ist, in jeder Phase der Entdeckung. Modelle, sowohl in der Wissenschaft als auch in der Mathematik, müssen intern konsistent sein und sollten auch verfälscht sein (unsicherbar). In der Mathematik muss eine Aussage noch nicht nachgewiesen werden; in einer solchen Phase würde diese Aussage als Konjektur bezeichnet werden. Aber wenn eine Aussage mathematischen Beweis erreicht hat, gewinnt diese Aussage eine Art Unsterblichkeit, die von Mathematikern hochgeschätzt wird und für die einige Mathematiker ihr Leben widmen. Mathematische Arbeit und wissenschaftliche Arbeit können sich inspirieren. So entstand das technische Konzept der Zeit in der Wissenschaft, und die Zeitlosigkeit war ein Kennzeichen eines mathematischen Themas.Aber heute hat sich die Poincaré-Konjektur mit der Zeit als mathematisches Konzept bewährt, in dem Objekte fließen können (siehe Ricci-Flow). Dennoch bleibt die Verbindung zwischen Mathematik und Realität (und so die Wissenschaft in dem Maße, wie sie die Realität beschreibt) obskur. Eugene Wigners Papier, The Unreasonable Effectiveness of Mathematics in the Natural Sciences, ist ein sehr bekanntes Konto der Ausgabe eines Nobelpreisgekrönten Physikers. In der Tat haben einige Beobachter (einschließlich einige bekannte Mathematiker wie Gregory Chaitin, und andere wie Lakoff und Núñez) vorgeschlagen, dass Mathematik das Ergebnis der Praktizierenden Bias und menschliche Einschränkung (einschließlich kultureller,) etwas wie die postmoderne Sicht der Wissenschaft ist. Die Arbeit von George Pólya an der Problemlösung, die Konstruktion von mathematischen Beweisen und heuristischen zeigen, dass die mathematische Methode und die wissenschaftliche Methode im Detail unterscheiden, während dennoch ähneln einander in der Verwendung iterativer oder rekursiver Schritte. In Pólyas Ansicht besteht das Verständnis darin, nicht vertraute Definitionen in Ihren eigenen Worten zu ruhen, auf geometrische Zahlen zurückgreifen und zu hinterfragen, was wir wissen und nicht schon wissen; Analyse, die Pólya von Pappus nimmt, beinhaltet freie und heuristische Konstruktion von plausiblen Argumenten, rückständig vom Ziel zu arbeiten und einen Plan zur Konstruktion des Beweises zu entwickeln; Synthese ist die strenge euklidische Aussetzung von Schritt Aufbauend auf Pólyas Arbeit argumentierte Imre Lakatos, dass Mathematiker tatsächlich Widerspruch, Kritik und Revision als Prinzipien zur Verbesserung ihrer Arbeit verwenden. Wie die Wissenschaft, wo die Wahrheit gesucht wird, aber die Gewissheit wird nicht gefunden, in Proofs und Refutations, was Lakatos versucht zu etablieren war, dass kein Theorem der informellen Mathematik ist endgültig oder perfekt. Das bedeutet, dass wir nicht denken sollten, dass ein Theorem letztendlich wahr ist, nur dass noch kein Gegenbeispiel gefunden wurde. Sobald ein Gegenbeispiel gefunden wird, d.h. eine Entität, die vom Theorem widerspricht/nicht erklärt wird, passen wir das Theorem an und verlängern möglicherweise den Bereich seiner Gültigkeit. Dies ist eine kontinuierliche Art und Weise, wie sich unser Wissen ansammelt, durch die Logik und den Prozess der Beweise und Widerlegungen. (Aber wenn Axiome für einen Zweig der Mathematik gegeben werden, schafft dies ein logisches System -Wittgenstein 1921 Tractatus Logico-Philosophicus 5.13; Lakatos behauptete, dass Beweise aus einem solchen System waren tautologische, d.h. intern logisch wahr, durch Rewriting Formen, wie von Poincaré gezeigt, die die Technik der Transformation tautologischer wahrer Formen zeigten. Lakatos schlug ein Konto von mathematischem Wissen basierend auf Polyas Idee von Heuristik. In Proofs und Refutations gab Lakatos mehrere Grundregeln, um Beweise und Gegenbeispiele zu Konjektionen zu finden. Er dachte, dass mathematische "Gedanken-Experimente" ein gültiger Weg sind, um mathematische Konjekte und Beweise zu entdecken. Gauss, als er fragte, wie er über seine Theoreme kam, antwortete einmal "durch planmäßiges Tattonieren" (durch systematische palpable Experimentation.) Verhältnis zur Statistik Wenn die wissenschaftliche Methode Statistiken als Teil ihres Arsenals verwendet, gibt es mathematische und praktische Fragen, die sich nachteilig auf die Zuverlässigkeit der Produktion von wissenschaftlichen Methoden auswirken können. Dies wird in einem beliebten wissenschaftlichen Papier "Warum die meisten veröffentlichten Forschungsergebnisse sind falsch" von John Ioannidis beschrieben, die als Grundlage für den Bereich der Metawissenschaften betrachtet wird. Viele Forschungen in der Metawissenschaft versuchen, den schlechten Gebrauch von Statistiken zu identifizieren und seine Verwendung zu verbessern. Die einzelnen Punkte sind statistisch (" Je kleiner die in einem wissenschaftlichen Bereich durchgeführten Studien sind, desto weniger wahrscheinlich sind die Forschungsergebnisse wahr" und "je größer die Flexibilität in Designs, Definitionen, Ergebnissen und analytischen Moden in einem wissenschaftlichen Bereich, desto weniger wahrscheinlich sind die Forschungsergebnisse wahr zu sein.)" und wirtschaftlich (" Je größer die finanziellen und anderen Interessen und Vorurteile in einem wissenschaftlichen Bereich, desto weniger wahrscheinlich sind die Forschungsergebnisse zu sein " Daher: "Die meisten Forschungsergebnisse sind für die meisten Forschungsdesigns und für die meisten Bereiche falsch" und "Wie gezeigt, ist die Mehrheit der modernen biomedizinischen Forschung in Gebieten mit sehr geringer Vor- und Nachbildungswahrscheinlichkeit für wahre Befunde."Allerdings: "Die meisten neuen Entdeckungen werden weiterhin von der hypothesiserzeugenden Forschung mit niedrigen oder sehr niedrigen Vorstudienquoten stammen", was bedeutet, dass neue Entdeckungen aus der Forschung kommen, dass, wenn diese Forschung begann, niedrige oder sehr niedrige Chancen (eine niedrige oder sehr geringe Chance) erfolgreich waren. Wenn also die wissenschaftliche Methode zur Erweiterung der Wissensgrenzen verwendet wird, wird die Erforschung von Gebieten außerhalb des Mainstreams die neuesten Erkenntnisse liefern. Siehe: Voraussichtlicher Wert von Stichprobeninformationen,Test-statistische Rolle des Zufalls bei der Entdeckung Irgendwo werden zwischen 33% und 50% aller wissenschaftlichen Entdeckungen geschätzt, auf stolpert zu sein, anstatt heraus gesucht. Dies kann erklären, warum Wissenschaftler so oft ausdrücken, dass sie Glück hatten. Louis Pasteur wird mit dem berühmten Spruch ausgezeichnet, dass "Luck den vorbereiteten Verstand begünstigt", aber einige Psychologen haben begonnen, zu studieren, was es bedeutet, "für Glück vorbereitet" im wissenschaftlichen Kontext. Forschung zeigt, dass Wissenschaftler verschiedene Heuristiken gelehrt werden, die die Chance und das Unerwartete nutzen. Dies ist, was Nassim Nicholas Taleb Antifragilität nennt; während einige Systeme der Untersuchung zerbrechlich sind angesichts menschlicher Fehler, menschlicher Voreingenommenheit und Zufall, die wissenschaftliche Methode ist mehr als widerstandsfähig oder hart – es profitiert tatsächlich von solcher Zufallskraft in vielerlei Hinsicht (es ist antifragil). Taleb glaubt, dass je anti-fragiler das System, desto mehr wird es in der realen Welt blühen. Der Psychologe Kevin Dunbar sagt, der Entdeckungsprozess beginnt oft mit Forschern, die Fehler in ihren Experimenten finden. Diese unerwarteten Ergebnisse führen Forscher zu versuchen, zu beheben, was sie für einen Fehler in ihrer Methode halten. Schließlich entscheidet der Forscher, dass der Fehler zu persistent und systematisch ist, um ein Zufall zu sein. Die stark kontrollierten, vorsichtigen und neugierigen Aspekte der wissenschaftlichen Methode sind daher gut geeignet, solche persistenten systematischen Fehler zu identifizieren. An dieser Stelle wird der Forscher an theoretische Erklärungen für den Fehler denken, oft die Hilfe von Kollegen in verschiedenen Fachbereichen suchen. Siehe auch Probleme und Probleme Geschichte, Philosophie, Soziologie Hinweise Quellen Weiter lesen Externe Links Andersen, Anne; Hepburn, Brian. "Wissenschaftliche Methode." In Zalta, Edward N. (Hrsg.). Stanford Enzyklopädie der Philosophie."Bestätigung und Induktion". Internet Enzyklopädie der Philosophie. Wissenschaftliche Methode bei PhilPapers Wissenschaftliche Methode beim Indiana Philosophy Ontology Project Eine Einführung in Wissenschaft: Wissenschaftliches Denken und eine wissenschaftliche Methode von Steven D. Schafersman. Einführung in die wissenschaftliche Methode an der Universität von Rochester Theorie-Beladen von Paul Newall an der Galileischen Bibliothek Vortrag über wissenschaftliche Methode von Greg Anderson Mit der wissenschaftlichen Methode zur Gestaltung von wissenschaftlichen Messprojekten wissenschaftliche Methoden ein Online-Buch von Richard D. Jarrard Richard Feynman über den Schlüssel zur Wissenschaft (eine Minute, drei Sekunden) aus den Cornell Lectures. Vorträge über die wissenschaftliche Methode von Nick Josh Karean, Kevin Padian, Michael Shermer und Richard Dawkins "Wie wissen wir, was wahr ist?"(belebtes Video; 2:52)