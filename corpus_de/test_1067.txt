Künstliche neuronale Netzwerke (ANNs), meist einfach neurale Netzwerke (NNs) genannt, sind Rechensysteme, die von den biologischen neuronalen Netzwerken inspiriert sind, die tierische Gehirne bilden. Eine ANN basiert auf einer Sammlung von vernetzten Einheiten oder Knoten namens künstliche Neuronen, die lose die Neuronen in einem biologischen Gehirn modellieren. Jede Verbindung, wie die Synapsen in einem biologischen Gehirn, kann ein Signal an andere Neuronen übertragen. Ein künstliches Neuron erhält dann ein Signal und kann damit verbundene Neuronen signalisieren. Das Signal an einer Verbindung ist eine echte Zahl, und der Ausgang jedes Neurons wird durch eine nichtlineare Funktion der Summe seiner Eingänge berechnet. Die Verbindungen werden Kanten genannt. Neuronen und Kanten haben typischerweise ein Gewicht, das sich als Lernfortschritte anpasst. Das Gewicht erhöht oder verringert die Stärke des Signals an einer Verbindung. Neuronen können eine solche Schwelle aufweisen, dass ein Signal nur gesendet wird, wenn das Aggregatsignal diese Schwelle überschreitet. Typischerweise werden Neuronen in Schichten aggregiert. Verschiedene Schichten können unterschiedliche Transformationen an ihren Eingängen durchführen. Signale gelangen von der ersten Schicht (der Eingangsschicht) zur letzten Schicht (der Ausgangsschicht), gegebenenfalls nach mehrfachem Durchlaufen der Schichten. Ausbildende Neural-Netzwerke lernen (oder trainieren) durch Verarbeitungsbeispiele, die jeweils einen bekannten Eingang und Ergebnis enthalten, wobei zwischen den beiden Wahrscheinlichkeitsverbände gebildet werden, die innerhalb der Datenstruktur des Netzes selbst gespeichert sind. Die Ausbildung eines neuronalen Netzes aus einem bestimmten Beispiel wird üblicherweise durch die Bestimmung der Differenz zwischen der verarbeiteten Leistung des Netzes (oft eine Vorhersage) und einer Zielausgabe durchgeführt. Dieser Unterschied ist der Fehler. Das Netzwerk passt dann seine gewichteten Assoziationen nach einer Lernregel und mit diesem Fehlerwert an. Nachhaltige Anpassungen führen dazu, dass das neuronale Netz die Leistung erzeugt, die dem Zielausgang zunehmend ähnlich ist. Nach ausreichender Anzahl dieser Anpassungen kann das Training nach bestimmten Kriterien beendet werden. Dies ist als beaufsichtigtes Lernen bekannt. Solche Systeme lernen, Aufgaben durch die Betrachtung von Beispielen zu erfüllen, in der Regel ohne mit aufgabenspezifischen Regeln programmiert zu werden. Beispielsweise können sie bei der Bilderkennung lernen, Bilder zu identifizieren, die Katzen enthalten, indem sie Beispielbilder analysieren, die manuell als Katze oder "keine Katze" markiert wurden und die Ergebnisse verwenden, um Katzen in anderen Bildern zu identifizieren. Sie tun dies ohne vorherige Kenntnis von Katzen, zum Beispiel, dass sie Fell, Schwänze, Whisker und Katzen-ähnliche Gesichter haben. Stattdessen erzeugen sie automatisch Identifikationsmerkmale aus den Beispielen, die sie bearbeiten. Geschichte Warren McCulloch und Walter Pitts (1943) eröffneten das Thema durch die Schaffung eines rechnerischen Modells für neuronale Netze. In den späten 1940er Jahren schuf D. O. Hebb eine Lernhypothese basierend auf dem Mechanismus der neuralen Plastizität, die als hebbianisches Lernen bekannt wurde. Farley und Wesley A. Clark (1954) nutzten zunächst Rechenmaschinen, die dann Rechner genannt werden, um ein Hebbian-Netzwerk zu simulieren. Rosenblatt (1958) schuf den Perceptron. Die ersten funktionellen Netzwerke mit vielen Schichten wurden 1965 von Ivakhnenko und Lapa als Group Method of Data Handling veröffentlicht. Die Grundlagen der kontinuierlichen Backpropagation wurden im Rahmen der Steuerungstheorie von Kelley 1960 und von Bryson 1961 unter Verwendung von Prinzipien der dynamischen Programmierung abgeleitet. Danach stagnierte die Forschung nach Minsky und Papert (1969), die entdeckte, dass grundlegende Perceptronen nicht in der Lage waren, die Exklusiv-oder Schaltung zu verarbeiten und dass Computer nicht genügend Macht hatten, nützliche neuronale Netzwerke zu verarbeiten. Im Jahr 1970 veröffentlichte Seppo Linnainmaa die allgemeine Methode zur automatischen Differenzierung (AD) von diskreten vernetzten Netzwerken von geschachtelten differenzierbaren Funktionen. Im Jahre 1973 nutzte Dreyfus die Rückverbreitung, um Parameter von Reglern im Verhältnis zu Fehlergradienten anzupassen. Werbos (1975) Backpropagationsalgorithmus ermöglichte die praktische Ausbildung von mehrschichtigen Netzwerken. 1982 wendete er die AD-Methode von Linnainmaa an neuronale Netzwerke an, die weit verbreitet wurden. Die Entwicklung von Metall-Oxid-Halbleiter (MOS) sehr großflächiger Integration (VLSI) in Form einer komplementären MOS (CMOS)-Technologie ermöglichte eine Erhöhung der MOS-Transistorzahlen in der digitalen Elektronik. Dies lieferte in den 1980er Jahren mehr Verarbeitungsleistung für die Entwicklung praktischer künstlicher neuronaler Netze. Im Jahr 1986 zeigten Rumelhart, Hinton und Williams, dass Backpropagation interessante interne Darstellungen von Wörtern als Merkmalsvektoren erlernte, wenn sie ausgebildet sind, das nächste Wort in einer Sequenz vorherzusagen. Im Jahr 1992 wurde die Max-Rolle eingeführt, um mit der geringsten Verschiebung Invarianz und Toleranz gegenüber der Verformung zu Hilfe 3D-Objekterkennung zu helfen. Schmidhuber nahm eine mehrstufige Hierarchie von Netzwerken (1992) an, die eine Ebene zu einer Zeit durch ununterbrochenes Lernen und Feinabstimmung durch Backpropagation vorgebildet hatte. Geoffrey Hinton et al.(2006) schlug vor, eine hochrangige Darstellung unter Verwendung aufeinanderfolgender Schichten binärer oder echter latenter Variablen mit einer eingeschränkten Boltzmann-Maschine zu modellieren. Im Jahr 2012 haben Ng und Dean ein Netzwerk geschaffen, das gelernt hat, übergeordnete Konzepte wie Katzen zu erkennen, nur von unmarkierten Bildern. Unsupervised Pretraining und erhöhte Rechenleistung von GPUs und verteiltes Computing ermöglichten die Nutzung größerer Netzwerke, insbesondere bei Bild- und Seherkennungsproblemen, die als "Deep Learning" bekannt wurden. Ciresan und Kollegen (2010) zeigten, dass trotz des verschwindenden Gradientenproblems GPUs Rückverbreitung für viele Schichten nach vorn gerichtete neuronale Netzwerke möglich machen. Zwischen 2009 und 2012 begann ANNs mit dem Gewinnen von Preisen in ANN-Wettbewerben und näherte sich der Leistungsfähigkeit der menschlichen Ebene auf verschiedenen Aufgaben, zunächst in Mustererkennung und maschinelles Lernen. Beispielsweise der bidirektionale und mehrdimensionale Langzeit-Kurzzeitspeicher (LSTM) von Graves et al. gewann im Jahr 2009 drei Wettbewerbe in vernetzter Handschrifterkennung ohne Vorkenntnisse über die drei zu lernenden Sprachen. Ciresan und Kollegen bauten die ersten Muster-Erkenner auf Benchmarks wie der Erkennung von Verkehrszeichen (IJCNN 2012). Modelle ANNs begannen als Versuch, die Architektur des menschlichen Gehirns zu nutzen, um Aufgaben zu erfüllen, mit denen konventionelle Algorithmen wenig Erfolg hatten. Sie orientieren sich bald an der Verbesserung der empirischen Ergebnisse, meist aufzugeben Versuche, ihren biologischen Vorläufern treu zu bleiben. Neuronen sind in verschiedenen Mustern miteinander verbunden, um die Ausgabe einiger Neuronen zum Eingang anderer zu ermöglichen. Das Netzwerk bildet eine gerichtete, gewichtete Grafik. Ein künstliches neuronales Netz besteht aus einer Sammlung simulierter Neuronen. Jedes Neuron ist ein Knoten, der über Verbindungen mit anderen Knoten verbunden ist, die biologischen axon-synapse-dendriten Verbindungen entsprechen. Jeder Link hat ein Gewicht, das die Stärke des Einflusses eines Knotens auf einen anderen bestimmt. Komponenten der ANNs Neurons ANNs bestehen aus künstlichen Neuronen, die konzeptuell von biologischen Neuronen abgeleitet sind. Jedes künstliche Neuron hat Eingänge und produziert eine einzige Ausgabe, die an mehrere andere Neuronen gesendet werden kann. Die Eingänge können die Merkmalswerte einer Probe externer Daten sein, wie Bilder oder Dokumente, oder sie können die Ausgänge anderer Neuronen sein. Die Ausgänge der End-Ausgangsneuronen des neuronalen Netzes erfüllen die Aufgabe, wie das Erkennen eines Objekts in einem Bild. Um die Leistung des Neurons zu finden, nehmen wir zunächst die gewichtete Summe aller Eingänge, gewichtet durch die Gewichte der Verbindungen von den Eingängen zum Neuron. Wir fügen dieser Summe einen Vorurteil hinzu. Diese gewichtete Summe wird manchmal als Aktivierung bezeichnet. Diese gewichtete Summe wird dann durch eine (in der Regel nichtlineare) Aktivierungsfunktion zur Erzeugung der Leistung geleitet. Die Initialeingänge sind externe Daten, wie Bilder und Dokumente. Die ultimativen Ausgänge erfüllen die Aufgabe, wie das Erkennen eines Objekts in einem Bild. Verbindungen und Gewichte Das Netzwerk besteht aus Verbindungen, wobei jede Verbindung den Ausgang eines Neurons als Eingang zu einem anderen Neuron liefert. Jede Verbindung ist ein Gewicht zugeordnet, das ihre relative Bedeutung darstellt. Ein vorgegebenes Neuron kann mehrere Eingangs- und Ausgangsverbindungen aufweisen. Vermehrungsfunktion Die Ausbreitungsfunktion berechnet den Eingang zu einem Neuron aus den Ausgängen seiner Vorgängerneuronen und deren Verbindungen als gewichtete Summe. Dem Ergebnis der Ausbreitung kann ein Biasterm hinzugefügt werden. Organisation Die Neuronen werden typischerweise in mehrere Schichten, insbesondere im Deep Learning, organisiert. Neuronen einer Schicht verbinden sich nur mit Neuronen der unmittelbar vorangehenden und unmittelbar folgenden Schichten. Die Schicht, die externe Daten empfängt, ist die Eingangsschicht. Die Schicht, die das ultimative Ergebnis erzeugt, ist die Ausgangsschicht. Dazwischen sind null oder mehr versteckte Schichten. Es werden auch einschichtige und unbeschichtete Netzwerke eingesetzt. Zwischen zwei Schichten sind mehrere Verbindungsmuster möglich. Sie können vollständig verbunden werden, mit jedem Neuron in einer Schicht, die mit jedem Neuron in der nächsten Schicht verbunden ist. Sie können bündeln, wobei eine Gruppe von Neuronen in einer Schicht mit einem einzigen Neuron in der nächsten Schicht verbinden, wodurch die Anzahl der Neuronen in dieser Schicht reduziert wird. Neuronen mit nur solchen Verbindungen bilden eine gerichtete acyclische Graphik und sind als Feedforward-Netzwerke bekannt. Alternativ sind Netzwerke bekannt, die Verbindungen zwischen Neuronen in den gleichen oder früheren Schichten ermöglichen. Hyperparameter Ein Hyperparameter ist ein konstanter Parameter, dessen Wert vor Beginn des Lernprozesses eingestellt wird. Die Werte von Parametern werden über Lernen abgeleitet. Beispiele für Hyperparameter sind die Lernrate, die Anzahl der versteckten Schichten und die Chargengröße. Die Werte einiger Hyperparameter können von denen anderer Hyperparameter abhängig sein. Beispielsweise kann die Größe einiger Schichten von der Gesamtzahl der Schichten abhängen. Learning Learning ist die Anpassung des Netzwerks, um eine Aufgabe besser zu bewältigen, indem man Probenbeobachtungen betrachtet. Lernen beinhaltet die Anpassung der Gewichte (und optionale Schwellenwerte) des Netzes, um die Genauigkeit des Ergebnisses zu verbessern. Dies geschieht durch Minimierung der beobachteten Fehler. Das Lernen ist abgeschlossen, wenn zusätzliche Beobachtungen untersucht werden, reduziert die Fehlerrate nicht sinnvoll. Auch nach dem Lernen erreicht die Fehlerrate in der Regel nicht 0. Wenn nach dem Lernen die Fehlerrate zu hoch ist, muss das Netzwerk typischerweise neu gestaltet werden. Praktisch geschieht dies durch die Festlegung einer Kostenfunktion, die während des Lernens periodisch ausgewertet wird. Solange der Output weiter zurückgeht, geht das Lernen weiter. Die Kosten werden häufig als Statistik definiert, deren Wert nur angenähert werden kann. Die Ausgänge sind tatsächlich Zahlen, also wenn der Fehler niedrig ist, ist der Unterschied zwischen dem Ausgang (fast sicher eine Katze) und der richtigen Antwort (Kat) klein. Lernversuche, die Summe der Unterschiede in den Beobachtungen zu reduzieren. Die meisten Lernmodelle können als einfache Anwendung der Optimierungstheorie und der statistischen Schätzung betrachtet werden. Lernrate Die Lernrate definiert die Größe der Korrekturschritte, die das Modell benötigt, um Fehler in jeder Beobachtung anzupassen. Eine hohe Lernrate verkürzt die Trainingszeit, aber mit geringerer ultimativer Genauigkeit, während eine geringere Lernrate länger dauert, aber mit dem Potenzial für größere Genauigkeit. Optimierungen wie Quickprop sind in erster Linie darauf ausgerichtet, die Fehlerminimierung zu beschleunigen, während andere Verbesserungen vor allem versuchen, die Zuverlässigkeit zu erhöhen. Um eine Schwingung innerhalb des Netzes zu vermeiden, wie z.B. alternierende Verbindungsgewichte, und um die Konvergenzgeschwindigkeit zu verbessern, verwenden Veredelungen eine adaptive Lernrate, die entsprechend zunimmt oder abnimmt. Das Konzept des Momentums erlaubt es, die Balance zwischen dem Gradienten und der vorherigen Änderung so zu gewichten, dass die Gewichtseinstellung in gewissem Maße von der vorherigen Änderung abhängt. Ein Impuls nahe 0 betont den Gradienten, während ein Wert nahe 1 die letzte Änderung betont. Kostenfunktion Während es möglich ist, eine Kostenfunktion ad hoc zu definieren, wird häufig die Wahl durch die wünschenswerten Eigenschaften der Funktion (wie Konvexität) bestimmt oder weil es aus dem Modell (z.B. in einem probabilistischen Modell kann die Posteriorwahrscheinlichkeit des Modells als inverse Kosten verwendet werden). Backpropagation Backpropagation ist ein Verfahren, mit dem die Verbindungsgewichte eingestellt werden, um jeden beim Lernen gefundenen Fehler zu kompensieren. Die Fehlermenge wird effektiv auf die Verbindungen aufgeteilt. Technisch berechnet backprop den Gradienten (die Ableitung) der Kostenfunktion, die einem gegebenen Zustand bezüglich der Gewichte zugeordnet ist. Die Gewichtsaktualisierungen können über stochastische Gradientenabstieg oder andere Methoden erfolgen, wie Extreme Learning Machines, No-prop-Netzwerke, Schulungen ohne Rückverfolgung, gewichtslose Netzwerke und nicht-konnektorische neuronale Netzwerke. Paradigmen lernen Die drei großen Lernparadigmen sind beaufsichtigtes Lernen, unübertroffenes Lernen und Bewehrung Lernen. Sie entsprechen jeweils einer bestimmten Lernaufgabe Supervised learning verwendet eine Reihe von gepaarten Inputs und gewünschten Outputs. Die Lernaufgabe besteht darin, für jede Eingabe die gewünschte Ausgabe zu erzeugen. In diesem Fall ist die Kostenfunktion mit der Beseitigung falscher Abzüge verbunden. Ein häufig verwendeter Aufwand ist der mittelständische Fehler, der versucht, den durchschnittlichen quadratischen Fehler zwischen dem Ausgang des Netzes und dem gewünschten Ausgang zu minimieren. Für beaufsichtigtes Lernen geeignete Aufgaben sind Mustererkennung (auch als Klassifikation bezeichnet) und Regression (auch als Funktion Approximation bezeichnet). Beaufsichtigtes Lernen gilt auch für sequentielle Daten (z.B. für Handschrift, Sprache und Gestenerkennung). Dies kann als Lernen mit einem Lehrer gedacht werden, in Form einer Funktion, die ein kontinuierliches Feedback zur Qualität der bisher erhaltenen Lösungen liefert. Unsupervisiertes Lernen Bei unsupervised Learning werden Eingabedaten zusammen mit der Kostenfunktion, eine Funktion der Daten x {\displaystyle \textstyle x} und der Ausgabe des Netzwerks angegeben. Die Kostenfunktion ist abhängig von der Aufgabe (der Modelldomäne) und allen a priori Annahmen (die impliziten Eigenschaften des Modells, dessen Parameter und die beobachteten Variablen). Als triviales Beispiel, betrachten Sie das Modell f ( x ) = a {\displaystyle \textstyle f(x)=a}, bei dem ein {\displaystyle \textstyle a} eine Konstante ist und die Kosten C = E [ ( x - f ( x) ) 2 ]\displaystyle \textstyle C=E[(x-f(x)style)^{2]} Die Kostenfunktion kann viel komplizierter sein. Seine Form hängt von der Anwendung ab: z.B. in der Komprimierung könnte es mit den gegenseitigen Informationen zwischen x {\displaystyle \textstyle x} und f ( x ) {\displaystyle \textstyle f(x)} zusammenhängen, während es bei der statistischen Modellierung auf die posterior Wahrscheinlichkeit des Modells bei den Daten bezogen werden könnte (Anmerkung, dass in beiden diesen Beispielen diese Mengen eher maximiert werden als minimiert). Aufgaben, die in das Paradigma des ununterbrochenen Lernens fallen, sind generelle Schätzungsprobleme; die Anwendungen umfassen Clustering, die Schätzung der statistischen Verteilungen, Kompression und Filterung. Verstärktes Lernen Bei Anwendungen wie dem Spielen von Videospielen nimmt ein Schauspieler eine Reihe von Aktionen auf, die nach jedem einzelnen eine allgemein unvorhersehbare Antwort aus der Umgebung erhalten. Das Ziel ist es, das Spiel zu gewinnen, d.h. die positivsten (niedrigsten Kosten) Antworten zu generieren. Bei der Stärkung des Lernens ist es das Ziel, das Netzwerk (eine Politik) zu gewichten, um Aktionen durchzuführen, die langfristig (erwartete kumulative) Kosten minimieren. Zu jedem Zeitpunkt führt der Agent eine Aktion durch und die Umwelt erzeugt eine Beobachtung und eine momentane Kosten, nach einigen (meist unbekannten) Regeln. Die Regeln und die langfristigen Kosten können in der Regel nur geschätzt werden. Jedenfalls entscheidet der Agent, ob er neue Handlungen erforscht, um seine Kosten aufzudecken oder vor dem Lernen zu nutzen, um schneller voranzukommen. Formal wird die Umgebung als Markov-Entscheidungsprozess (MDP) mit den Zuständen s 1 , . ., s n ε S {\displaystyle \textstyle s_{1},...,s_{n}\in modelliert. S} und Aktionen a 1 , . . . . A {\displaystyle \textstyle a_{1}...,a_{m}\in A} .Weil die Zustandsübergänge nicht bekannt sind, werden stattdessen Wahrscheinlichkeitsverteilungen verwendet: die momentane Kostenverteilung P (c t s s t ) {\displaystyle \textstyle P(c_{t}|s_{t) , die Beobachtungsverteilung P (x t s s t )) {\displaystyle p(x_{t}}} Die beiden definieren eine Markov-Kette (MC). Ziel ist es, das kostengünstigste MC zu entdecken. ANNs dienen als Lernkomponente in solchen Anwendungen. Dynamische Programmierung in Verbindung mit ANNs (vermittelnde neurodynamische Programmierung) wurde auf Probleme wie die an Fahrzeug-Routing, Videospielen, natürlichem Ressourcenmanagement und Medizin wegen der Fähigkeit der ANNs, Genauigkeitsverluste auch bei der Verringerung der Diskretisierungsgitterdichte zur numerischen Annäherung der Lösung von Kontrollproblemen zu mindern, angewendet. Aufgaben, die in das Paradigma des Verstärkungslernens fallen, sind Kontrollprobleme, Spiele und andere sequentielle Entscheidungsaufgaben. Selbstlernendes Selbstlernen in neuronalen Netzwerken wurde 1982 zusammen mit einem neuronalen Netzwerk eingeführt, das selbstlernend Crossbar Adaptive Array (CAA) genannt werden kann. Es ist ein System mit nur einem Eingang, Situation s und nur einem Ausgang, Aktion (oder Verhalten) a. Es hat weder externe Beratung Eingang noch externe Verstärkung Eingang aus der Umgebung. Die CAA berechnet in einer Crossbar-Mode sowohl Entscheidungen über Handlungen und Emotionen (Feelings) über aufgetretene Situationen. Das System wird von der Interaktion zwischen Wahrnehmung und Emotion angetrieben. Bei der Speichermatrix W =w(a,s) führt der Crossbar-Selbstlernalgorithmus in jeder Iteration die folgende Berechnung aus: In der Situation führen sie die Aktion a; Erhalten der Folgesituation s;' Berechnen Sie die Emotion des Seins in der Folge Situation v(s;') Aktualisieren Sie den Crossbar-Speicher w'(a,s) =w(a,s) + v(s)'. Der rückverschobene Wert (sekundäre Verstärkung) ist die Emotion zur Folgesituation. Die CAA existiert in zwei Umgebungen, eine ist Verhaltensumgebung, in der sie sich verhält, und die andere ist genetische Umgebung, wo von ihr zunächst und nur einmal erste Emotionen empfangen, um Situationen in der Verhaltensumgebung zu begegnen. Nachdem der Genomvektor (Speziesvektor) aus der genetischen Umgebung erhalten wurde, wird die CAA ein zielsuchendes Verhalten in der Verhaltensumgebung erlernen, die sowohl wünschenswerte als auch unerwünschte Situationen enthält. Sonstige In einem Bayesischen Rahmen wird eine Verteilung über den Satz der erlaubten Modelle gewählt, um die Kosten zu minimieren. Evolutionäre Methoden, Gen-Expressions-Programmierung, simulierte Glühung, Erwartungsmaximierung, nichtparametrische Methoden und Partikelschwarm-Optimierung sind andere Lernalgorithmen. Konvergente Rekursion ist ein Lernalgorithmus für cerebellar model artikulation Controller (CMAC) neuronalen Netzwerken. Moden Zwei Lernmodi sind verfügbar: stochastisch und Batch. Im stochastischen Lernen erstellt jede Eingabe eine Gewichtsanpassung. In Batch-Lerngewichten werden basierend auf einer Reihe von Eingaben eingestellt, die Fehler über den Ansatz ansammeln. Stochastic Learning führt Geräusche in den Prozess ein, indem der lokale Gradient aus einem Datenpunkt berechnet wird; dies reduziert die Chance, dass das Netzwerk in lokalen Minima stecken bleibt. Allerdings ergibt das Batch-Erlernen typischerweise eine schnellere, stabilere Abstieg auf ein lokales Minimum, da jedes Update in Richtung des durchschnittlichen Fehlers des Batch durchgeführt wird. Ein gemeinsamer Kompromiss ist die Verwendung von Mini-Batches, kleinen Chargen mit Proben in jeder Charge, die stochastisch aus dem gesamten Datensatz ausgewählt wird. Arten ANNs haben sich zu einer breiten Reihe von Techniken entwickelt, die den Stand der Technik über mehrere Domänen erweitert haben. Die einfachsten Typen haben eine oder mehrere statische Komponenten, einschließlich Anzahl der Einheiten, Anzahl der Schichten, Einheitsgewichte und Topologie. Dynamische Typen ermöglichen es einem oder mehreren dieser über das Lernen zu entwickeln. Letztere sind viel komplizierter, können aber Lernzeiten verkürzen und bessere Ergebnisse erzielen. Einige Arten erlauben/erfordern das Lernen, vom Bediener überwacht werden, während andere unabhängig arbeiten. Einige Arten arbeiten rein in der Hardware, andere sind rein Software und laufen auf allgemeinen Computern. Einige der Hauptdurchbrüche umfassen: konvolutionale neuronale Netzwerke, die sich besonders erfolgreich bei der Verarbeitung von visuellen und anderen zweidimensionalen Daten bewährt haben; langes Kurzzeitgedächtnis vermeidet das verschwindende Gradientenproblem und kann Signale behandeln, die eine Mischung von niedrigen und hochfrequenten Komponenten zur Unterstützung von groß-vocabularischen Spracherkennung, Text-zu-Peak-Synthese und fotorealen Sprechköpfen haben; Wettbewerbsnetzwerken wie generative Adversen, die Netzwerke, in denen sich ändernde Netzwerke struktur. Netzwerk-Design Neural Architektur-Suche (NAS) verwendet maschinelles Lernen, um ANN-Design zu automatisieren. Verschiedene Ansätze für NAS haben Netzwerke entwickelt, die gut mit handgestalteten Systemen vergleichen. Der grundlegende Suchalgorithmus besteht darin, ein Kandidatenmodell vorzuschlagen, es gegen einen Datensatz auszuwerten und die Ergebnisse als Feedback zu nutzen, um das NAS-Netzwerk zu lehren. Zu den verfügbaren Systemen gehören AutoML und AutoKeras. Entscheidend für die Anzahl, den Typ und die Verbindung von Netzwerkschichten sowie die Größe jedes und des Verbindungstyps (Voll, Pooling, ). Hyperparameter müssen auch als Teil des Designs definiert werden (sie sind nicht erlernt), was Angelegenheiten wie viele Neuronen in jeder Schicht, Lernrate, Schritt, Schritt, Tiefe, Aufnahmefeld und Polsterung (für CNNs) etc. Die Verwendung künstlicher neuronaler Netzwerke erfordert ein Verständnis ihrer Eigenschaften. Wahl des Modells: Dies hängt von der Datendarstellung und der Applikation ab. Über komplexe Modelle langsames Lernen. Lernalgorithmus: Es gibt zahlreiche Abschlüsse zwischen Lernalgorithmen. Fast jeder Algorithmus wird gut mit den richtigen Hyperparametern für das Training auf einem bestimmten Datensatz arbeiten. Die Auswahl und Abstimmung eines Algorithmus für die Ausbildung auf ungesehenen Daten erfordert jedoch ein signifikantes Experimentieren. Robustheit: Werden das Modell, die Kostenfunktion und der Lernalgorithmus entsprechend ausgewählt, kann die resultierende ANN robust werden. ANN-Fähigkeiten fallen in folgende breite Kategorien: Funktions- oder Regressionsanalyse, einschließlich Zeitreihen-Prädiktion, Fitness-Approximation und Modellierung. Einstufung, einschließlich Muster- und Sequenzerkennung, Neuheitserkennung und sequentielle Entscheidungsfindung. Datenverarbeitung, einschließlich Filterung, Clustering, blinde Quellentrennung und Komprimierung. Robotik, einschließlich Regie Manipulatoren und Prothesen. Anwendungen Aufgrund ihrer Fähigkeit, nichtlineare Prozesse zu reproduzieren und zu modellieren, haben künstliche neuronale Netzwerke Anwendungen in vielen Disziplinen gefunden. Anwendungsbereiche umfassen Systemidentifikation und -steuerung (Fahrzeugsteuerung, Trajektorienvorhersage, Prozesssteuerung, natürliche Ressourcenverwaltung), Quantenchemie, allgemeines Spiel, Mustererkennung (Radsysteme, Gesichtserkennung, Signalklassifizierung, 3D-Rekonstruktion, Objekterkennung und mehr), Sequenzerkennung (Geste, Sprache, handschriftliche und gedruckte Texterkennung), medizinische Diagnose, Finanzen (z.B. automatisierte Handelssysteme), Data Mining, Visualisierung, Maschinenübersetzung, Maschinenübersetzung, Social Network Filtering ANNs wurden verwendet, um verschiedene Krebsarten zu diagnostizieren und hochinvasive Krebszellenlinien von weniger invasiven Linien mit nur Zellforminformationen zu unterscheiden. ANNs wurden verwendet, um die Zuverlässigkeitsanalyse von Infrastrukturen, die Naturkatastrophen ausgesetzt sind, zu beschleunigen und Stiftungssiedlungen vorherzusagen. ANNs wurden auch für den Bau von Black-Box-Modellen in Geowissenschaften verwendet: Hydrologie, Ozeanmodellierung und Küstentechnik und Geomorphologie. ANNs wurden in Cybersicherheit eingesetzt, mit dem Ziel, zwischen legitimen Aktivitäten und bösartigen zu diskriminieren. Zum Beispiel wurde maschinelles Lernen zur Klassifizierung von Android-Malware verwendet, um Domains, die zu Bedrohungsakteure gehören, zu identifizieren und URLs zu erkennen, die ein Sicherheitsrisiko darstellen. Die Forschung läuft auf ANN-Systemen, die für Penetrationstests, für die Erkennung von Botnets, Kreditkartenbetrugs und Netzintrusionen konzipiert sind. ANNs wurden als Werkzeug vorgeschlagen, um partielle Differentialgleichungen in der Physik zu lösen und die Eigenschaften von körperoffen Quantensystemen zu simulieren. In der Hirnforschung haben ANNs das kurzfristige Verhalten einzelner Neuronen untersucht, die Dynamik der Neuralschaltung entsteht durch Wechselwirkungen zwischen einzelnen Neuronen und wie Verhalten aus abstrakten neuronalen Modulen entstehen kann, die komplette Teilsysteme darstellen. Studien betrachteten eine langfristige Plastizität von neuronalen Systemen und ihre Beziehung zu Lernen und Gedächtnis von der einzelnen Neuron auf die Systemebene. Theoretische Eigenschaften Rechenleistung Der mehrschichtige Perceptron ist ein universeller Funktions-Atmator, wie durch das universelle Approximationstheorem bewiesen. Der Nachweis ist jedoch nicht konstruktiv bezüglich der Anzahl der benötigten Neuronen, der Netzwerktopologie, der Gewichte und der Lernparameter. Eine spezifische rezidive Architektur mit rational bewerteten Gewichten (im Gegensatz zu vollpräzisen realen Zahlenwertgewichten) hat die Leistung einer universellen Turing-Maschine, mit einer endlichen Anzahl von Neuronen und Standard-Linearverbindungen. Ferner führt die Verwendung von Reizwerten für Gewichte zu einer Maschine mit Super-Turing-Leistung. Kapazität Die Kapazitätseigenschaft eines Modells entspricht der Fähigkeit, eine bestimmte Funktion zu modellieren. Es ist mit der Menge an Informationen verbunden, die im Netzwerk gespeichert werden können und mit dem Begriff der Komplexität. Zwei Vorstellungen von Kapazität sind von der Gemeinde bekannt. Die Informationskapazität und die VC Dimension. Die Informationskapazität eines Perceptrons wird in Sir David MacKays Buch intensiv diskutiert, das die Arbeit von Thomas Cover zusammenfasst. Die Kapazität eines Netzwerks von Standardneuronen (nicht konvolutional) kann durch vier Regeln abgeleitet werden, die aus dem Verständnis eines Neurons als elektrisches Element abgeleitet werden. Die Informationskapazität erfasst die von dem Netzwerk modellierbaren Funktionen, wenn Daten als Eingabe verwendet werden. Der zweite Begriff ist die VC-Dimension. VC Dimension verwendet die Prinzipien der Messtheorie und findet die maximale Kapazität unter den bestmöglichen Umständen. Dies ist bei Eingabedaten in einer bestimmten Form. Wie bereits erwähnt, ist die VC-Dimension für beliebige Eingänge die halbe Informationskapazität eines Perceptrons. Die VC Dimension für beliebige Punkte wird manchmal als Speicherkapazität bezeichnet. Convergence Models können nicht konsequent auf eine einzige Lösung konvergieren, zum einen weil lokale Minima existieren kann, je nach Kostenfunktion und Modell. Zweitens kann die verwendete Optimierungsmethode nicht garantieren, zu konvergieren, wenn sie weit von einem lokalen Minimum beginnt. Drittens werden für ausreichend große Daten oder Parameter einige Methoden unpraktisch. Das Konvergenzverhalten bestimmter Arten von ANN-Architekturen wird mehr verstanden als andere. Wenn sich die Breite des Netzwerks auf Unendlichkeit nähert, wird die ANN durch ihre erste Ordnung Taylor-Erweiterung während des Trainings gut beschrieben, und so erbt das Konvergenzverhalten der Affine-Modelle. Ein weiteres Beispiel ist, wenn Parameter klein sind, wird beobachtet, dass ANNs häufig Zielfunktionen von niedrigen bis hohen Frequenzen passt. Dieses Phänomen ist das Gegenteil zum Verhalten einiger gut untersuchten iterativen numerischen Systeme wie Jacobi-Methode. Verallgemeinerung und Statistik Anwendungen, deren Ziel es ist, ein System zu schaffen, das gut auf ungesehene Beispiele verallgemeinert, die Möglichkeit der Überschulung. Dies ergibt sich bei konvolutierten oder über spezifizierten Systemen, wenn die Netzkapazität die benötigten freien Parameter deutlich übersteigt. Zwei Ansätze befassen sich mit Übertraining. Die erste ist, Cross-validierung und ähnliche Techniken zu verwenden, um das Vorhandensein von Over-Training zu überprüfen und Hyperparameter auszuwählen, um den Verallgemeinerungsfehler zu minimieren. Die zweite ist, irgendeine Form der Regularisierung zu verwenden. Dieses Konzept tritt in einem probabilistischen (Bayesischen) Rahmen auf, in dem die Regularisierung durch die Wahl einer größeren Vorwahrscheinlichkeit gegenüber einfacheren Modellen durchgeführt werden kann; aber auch in der statistischen Lerntheorie, in der das Ziel besteht, über zwei Größen zu minimieren: das 'empirische Risiko' und das 'Strukturrisiko', das etwa dem Fehler über das Trainingsset und den vorhergesagten Fehler ingesehenen Daten durch Überbelegung entspricht. Beaufsichtigte neuronale Netze, die eine mittlere quadratische Fehler (MSE) Kostenfunktion verwenden, können formale statistische Methoden verwenden, um das Vertrauen des geschulten Modells zu bestimmen. Die MSE auf einem Validierungssatz kann als Schätzung für Varianz verwendet werden. Dieser Wert kann dann verwendet werden, um das Konfidenzintervall der Netzausgabe unter Annahme einer normalen Verteilung zu berechnen. Eine so vorgenommene Vertrauensanalyse ist statistisch gültig, solange die Ausgangswahrscheinlichkeitsverteilung gleich bleibt und das Netzwerk nicht verändert wird. Durch die Zuordnung einer Softmax-Aktivierungsfunktion, einer Verallgemeinerung der logistischen Funktion auf der Ausgangsschicht des neuronalen Netzes (oder einer Softmax-Komponente in einem komponentenbasierten Netzwerk) für kategorische Zielvariablen können die Ausgänge als posterior-Probabilities interpretiert werden. Dies ist nützlich in der Klassifizierung, da es eine gewisse Maßnahme zur Klassifizierung gibt. Die Softmax Aktivierungsfunktion ist: y i = e x i Σ j = 1 c e x j {\displaystyle * ) ) Kritische Ausbildung Eine gemeinsame Kritik an neuronalen Netzen, vor allem in der Robotik, ist, dass sie zu viel Schulung für den realen Betrieb benötigen. Potentielle Lösungen umfassen zufällig schüttelnde Trainingsbeispiele, indem ein numerischer Optimierungsalgorithmus verwendet wird, der beim Wechseln der Netzwerkverbindungen nach einem Beispiel nicht zu große Schritte einnimmt, Beispiele in sogenannten Minibatches gruppiert und/oder einen rekursiven kleinsten Quadrat-Algorithmus für CMAC einführt. Theorie Ein grundlegender Einwand ist, dass ANNs nicht ausreichend neuronale Funktion reflektieren. Backpropagation ist ein kritischer Schritt, obwohl in biologischen neuronalen Netzen kein solcher Mechanismus vorhanden ist. Wie Informationen von realen Neuronen kodiert werden, ist nicht bekannt. Sensorneurons Feuerwirkungspotentiale häufiger mit Sensoraktivierung und Muskelzellen ziehen stärker, wenn ihre zugehörigen Motorneuronen häufiger Aktionspotentiale erhalten. Anders als bei der Übertragung von Informationen von einem Sensor-Neuron zu einem Motor-Neuron, ist fast nichts von den Prinzipien, wie Informationen von biologischen neuronalen Netzwerken behandelt wird bekannt. Ein zentraler Anspruch von ANNs ist, dass sie neue und leistungsfähige allgemeine Grundsätze für die Verarbeitung von Informationen bilden. Diese Prinzipien sind undefiniert. Es wird oft behauptet, sie seien aus dem Netz selbst hervorgegangen. Dies ermöglicht eine einfache statistische Zuordnung (die Grundfunktion künstlicher neuronaler Netze) als Lernen oder Erkennung zu beschreiben. Alexander Dewdney kommentierte, dass künstliche neuronale Netzwerke eine "etwas-für-nichts-Qualität, eine, die eine eigentümliche Aura der Faulheit und ein deutliches Mangel an Neugier über genau wie gut diese Computersysteme sind. Keine menschliche Hand (oder Geist) greift ein; Lösungen werden gefunden, als ob durch Magie; und niemand, es scheint, hat etwas gelernt". Eine Antwort auf Dewdney ist, dass neuronale Netzwerke viele komplexe und vielfältige Aufgaben bewältigen, von autonom fliegenden Flugzeugen bis zur Erkennung von Kreditkartenbetrug bis zum Master des Spiels von Go.Technology Autor Roger Bridgman kommentiert: Neural-Netzwerke, zum Beispiel, sind in der Dodierung nicht nur, weil sie in den hohen Himmel hypediert wurden, (was hat nicht?) sondern auch, weil Sie ein erfolgreiches Netz schaffen konnten, ohne zu verstehen, wie es funktionierte: die Zahlen, die sein Verhalten erfasst, würde in aller Wahrscheinlichkeit "ein opaker, unlesbarer Tisch... wertlos als wissenschaftliche Ressource". Trotz seiner emphatischen Erklärung, dass die Wissenschaft nicht Technologie ist, Dewdney scheint hier, um plündernde neuronale Netze als schlechte Wissenschaft, wenn die meisten von denen, die sie entwickeln, nur versuchen, gute Ingenieure zu sein. Eine unlesbare Tabelle, die eine nützliche Maschine lesen könnte, wäre immer noch gut zu haben. Biologische Gehirne verwenden sowohl flache als auch tiefe Schaltkreise, die von der Gehirnanatomie gemeldet werden und eine Vielzahl von Invarianzen darstellen. Weng argumentierte, dass das Gehirn selbst Drähte weitgehend nach Signalstatistiken und daher eine serielle Kaskade nicht alle wichtigen statistischen Abhängigkeiten erfassen kann. Hardware Große und effektive neuronale Netzwerke erfordern erhebliche Rechenressourcen. Während das Gehirn Hardware hat, die auf die Aufgabe der Verarbeitung von Signalen durch einen Graph von Neuronen zugeschnitten ist, kann die Simulation sogar eines vereinfachten Neurons auf der von Neumann-Architektur enorme Mengen an Speicher und Speicher verbrauchen. Darüber hinaus muss der Designer oft Signale über viele dieser Verbindungen und ihre damit verbundenen Neuronen übertragen – die enorme CPU-Leistung und Zeit erfordern. Schmidhuber stellte fest, dass die Resistenz von neuronalen Netzen im 21. Jahrhundert weitgehend auf Hardwarefortschritte zurückzuführen ist: von 1991 bis 2015 hat sich die Rechenleistung, insbesondere wie sie von GPGPUs (auf GPUs) geliefert wird, um ein Millionenfach erhöht, wodurch der Standard-Backpropagationsalgorithmus für Trainingsnetzwerke möglich ist, die mehrere Schichten tiefer sind als zuvor. Der Einsatz von Beschleunigern wie FPGAs und GPUs kann die Trainingszeiten von Monaten bis Tagen reduzieren. Neuromorphes Engineering befasst sich direkt mit der Hardwareschwierigkeit, indem nicht-von-Neumann-Chips konstruiert werden, um neuronale Netzwerke in der Kreislaufwirtschaft direkt zu implementieren. Eine andere für die neuronale Netzwerkverarbeitung optimierte Chipart wird als Tensor Processing Unit oder TPU bezeichnet. Praktische Gegenbeispiele Die Analyse, was von einer ANN gelernt wurde, ist viel einfacher als die Analyse, was von einem biologischen neuronalen Netzwerk gelernt wurde. Darüber hinaus werden Forscher, die an der Erkundung von Lernalgorithmen für neuronale Netzwerke beteiligt sind, nach und nach allgemeine Prinzipien aufdecken, die es einer Lernmaschine ermöglichen, erfolgreich zu sein. Zum Beispiel lokale vs. nicht-lokales Lernen und flache vs. tiefe Architektur. Hybride Ansätze Advocate von Hybrid-Modellen (die Kombination von neuronalen Netzwerken und symbolischen Ansätzen), behaupten, dass eine solche Mischung die Mechanismen des menschlichen Geistes besser erfassen kann. Galerie Siehe auch Referenzen Bibliographie Externe Links Der Neural Network Zoo – eine Zusammenstellung neuronaler Netzwerktypen Die Stilwell Brain – eine Mind Field Episode mit einem Experiment, in dem Menschen als einzelne Neuronen in einem neuronalen Netzwerk wirken, das handschriftliche Ziffern klassifiziert