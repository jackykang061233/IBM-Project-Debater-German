Informationsabruf (IR) ist der Prozess der Gewinnung von Informationssystem-Ressourcen, die für einen Informationsbedarf aus einer Sammlung dieser Ressourcen relevant sind. Suchen können auf Volltext- oder anderen Content-basierten Indexing basieren. Informationsabruf ist die Wissenschaft der Suche nach Informationen in einem Dokument, der Suche nach Dokumenten selbst, sowie der Suche nach Metadaten, die Daten beschreiben, und nach Datenbanken von Texten, Bildern oder Tönen. Automatisierte Informationsabrufsysteme werden verwendet, um das sogenannte Informationsüberlastung zu reduzieren. Ein IR-System ist ein Software-System, das Zugriff auf Bücher, Zeitschriften und andere Dokumente bietet; speichert und verwaltet diese Dokumente. Web-Suchmaschinen sind die sichtbarsten IR-Anwendungen. Überblick Ein Informationsabrufvorgang beginnt, wenn ein Benutzer eine Abfrage in das System eingibt. Abfragen sind formale Aussagen von Informationsbedürfnissen, z.B. Suchfolgen in Web-Suchmaschinen. Bei der Datenabrufung identifiziert eine Abfrage nicht eindeutig ein einzelnes Objekt in der Sammlung. Stattdessen können mehrere Objekte mit der Abfrage übereinstimmen, vielleicht mit unterschiedlichen Höhen. Ein Objekt ist eine Einheit, die durch Informationen in einer Content-Sammlung oder Datenbank dargestellt wird. Benutzeranfragen werden an die Datenbankinformationen angepasst. Im Gegensatz zu klassischen SQL-Abfragen einer Datenbank können die zurückgegebenen Ergebnisse jedoch nicht mit der Abfrage übereinstimmen, so dass die Ergebnisse typischerweise geordnet werden. Dieses Ranking der Ergebnisse ist ein wesentlicher Unterschied der Informationssuche im Vergleich zur Datenbanksuche. Je nach Anwendung können die Datenobjekte beispielsweise Textdokumente, Bilder, Audio-, Mindmaps oder Videos sein. Oft werden die Dokumente selbst nicht direkt im IR-System gehalten oder gespeichert, sondern im System durch Dokumentüberschriften oder Metadaten dargestellt. Die meisten IR-Systeme berechnen eine numerische Punktzahl, wie gut jedes Objekt in der Datenbank der Abfrage entspricht, und ordnen die Objekte nach diesem Wert. Die Top-Ranking-Objekte werden dann dem Benutzer angezeigt. Der Vorgang kann dann iteriert werden, wenn der Benutzer die Abfrage verfeinern möchte. Geschichte gibt es ... eine Maschine namens Univac... wobei Buchstaben und Figuren als Muster von magnetischen Flecken auf einem langen Stahlband kodiert werden. Auf diese Weise kann der Text eines Dokuments, dem sein Subjekt-Code-Symbol vorausgeht, aufgezeichnet werden. die Maschine ... wählt automatisch die Referenzen aus, die in beliebiger Weise mit einer Rate von 120 Wörtern pro Minute codiert wurden Die Idee der Verwendung von Computern zur Suche nach relevanten Informationen wurde in dem Artikel populär, wie wir Mai denken von Vannevar Bush in 1945. Es scheint, dass Bush von Patenten für eine "statistische Maschine" inspiriert wurde - eingereicht von Emanuel Goldberg in den 1920er und 30er Jahren -, die nach Dokumenten im Film gesucht. Die erste Beschreibung eines Computers, der nach Informationen sucht, wurde 1948 von Holmstrom beschrieben, der eine frühe Erwähnung des Univac-Computers beschreibt. In den 1950er-Jahren wurden Automatisierte Informationsabrufsysteme eingeführt:Eine wurde sogar in der romantischen Komödie von 1957 vorgestellt. In den 1960er Jahren wurde die erste große Informationsretrieval-Forschungsgruppe von Gerard Salton in Cornell gebildet. In den 1970er Jahren wurden mehrere verschiedene Retrieval-Techniken gezeigt, um gut auf kleinen Texten wie der Cranfield-Sammlung (mehrtausend Dokumente) durchzuführen. In den siebziger Jahren wurden bereits umfangreiche Retrievalsysteme wie das Lockheed Dialog System eingesetzt. 1992 koordinierte das US-Verteidigungsministerium zusammen mit dem National Institute of Standards and Technology (NIST) die Text-Retrieval-Konferenz (TREC) im Rahmen des TIPSTER-Textprogramms. Ziel war es, die Informationsabruf-Gemeinschaft durch die Bereitstellung der Infrastruktur, die für die Bewertung von Textabruf-Methoden für eine sehr große Textsammlung benötigt wurde, zu untersuchen. Diese katalysierte Forschung über Methoden, die zu riesigen Körper. Die Einführung von Web-Suchmaschinen hat die Notwendigkeit von sehr großen Retrieval-Systemen noch weiter erhöht. Anwendungen Bereiche, in denen Informationsabruftechniken verwendet werden, umfassen (die Einträge sind in alphabetischer Reihenfolge in jeder Kategorie:) Allgemeine Anwendungen Digitale Bibliotheken Information Filtern Weiterempfehlersysteme Mediensuche Blog Suche Bilder abrufen 3D abrufen Musik abrufen Nachrichtensuche Speech abrufen Video abrufen Search Engines Site search Enterprise search Federated search Mobile search Social search Web search Domain-spezifische Anwendungen Fachsuche Suche Genomische Information retrieval Geographic information retrieval Informationen retrieval für chemische Strukturen Informationen retrieval in der Softwaretechnik Rechtliche Informationen retrieval Vertikale Suche Andere Abrufmethoden Methoden/Techniken, bei denen Informationsabruftechniken eingesetzt werden, umfassen: Adversariale Informationsabrufeval Automatische Zusammenfassung Multi-Dokument-Zusammenfassung Compound Begriff Verarbeitung Cross-linguale Abruf-Dokument-Klassifikation Spam-Filterung Fragebeantwortung Modelltypen Zum effektiven Abrufen relevanter Dokumente durch IR-Strategien werden die Dokumente typischerweise in eine geeignete Darstellung umgewandelt. Jede Retrieval-Strategie enthält ein spezifisches Modell für ihre Dokumentdarstellungszwecke. Das Bild rechts zeigt die Beziehung einiger gemeinsamer Modelle. Im Bild werden die Modelle nach zwei Dimensionen kategorisiert: die mathematische Basis und die Eigenschaften des Modells. Erste Dimension: mathematische Basis Set-theoretische Modelle stellen Dokumente als Sätze von Wörtern oder Phrasen dar. Ähnlichkeiten werden in der Regel von Set-theoretischen Operationen auf diesen Sets abgeleitet. Häufige Modelle sind: Standard Boolean Modell Erweiterte Boolean Modell Fuzzy retrieval Algebraic Modelle repräsentieren Dokumente und Abfragen in der Regel als Vektoren, Matrizen oder Tupel. Die Ähnlichkeit des Abfragevektors und Dokumentvektors ist als Skalarwert dargestellt. Vector Raummodell Verallgemeinertes Vektor-Raummodell (Enhanced)Topic-basierte Vector Space Model Extended Boolean Modell Latent semantic indexing a.k.a.latent semantic analysis Probabilistic models behandeln den Prozess der Dokumentenretrieval als probabilistische Inferenz. Ähnlichkeiten werden als Wahrscheinlichkeiten berechnet, die ein Dokument für eine bestimmte Abfrage relevant ist. Probabilistische Theoreme wie die Bayes' Theorem werden häufig in diesen Modellen verwendet. Binäre Unabhängigkeit Modell Probabilistische Relevanz Modell, auf dem die okapi (BM25) Relevanz Funktion Unsichere Inferenz SprachmodelleDivergence-from-randomness Modell Latent Dirichlet Zuordnung Feature-basierte Retrieval Modelle betrachten Dokumente als Vektoren von Werten von Feature-Funktionen (oder nur Features) und suchen Sie den besten Weg, diese Funktionen in eine einzige Relevanz Score zu kombinieren, typischerweise durch Lernen auf Rang Methoden. Feature-Funktionen sind willkürliche Funktionen von Dokument und Abfrage, und als solche können einfach fast jedes andere Retrieval-Modell als nur ein weiteres Feature integrieren. Zweite Dimension: Eigenschaften des Modells Modelle ohne Term-Interdependenzen behandeln verschiedene Begriffe/Worte als unabhängig. Diese Tatsache wird üblicherweise in Vektorraummodellen durch die Orthogonalitätsannahme von Termvektoren oder in probabilistischen Modellen durch eine Independenzannahme für Termvariablen dargestellt. Modelle mit immanent term interdependencies ermöglichen eine Darstellung von Interdependenzen zwischen Begriffen. Der Grad der Interdependenz zwischen zwei Begriffen wird jedoch durch das Modell selbst definiert. Sie wird in der Regel direkt oder indirekt (z.B. durch Maßverkleinerung) aus der Ko-Okkurrenz dieser Begriffe in der Gesamtheit der Dokumente abgeleitet. Modelle mit transzendenten Begriff-Interdependenzen erlauben eine Darstellung von Interdependenzen zwischen Begriffen, aber sie lehnen nicht ab, wie die Interdependenz zwischen zwei Begriffen definiert ist. Sie verlassen eine externe Quelle für den Grad der Interdependenz zwischen zwei Begriffen (z.B. ein menschlicher oder anspruchsvoller Algorithmus). Durchführungs- und Korrekturmaßnahmen Die Bewertung eines Informationsabrufsystems ist der Prozess der Bewertung, wie gut ein System den Informationsbedürfnissen seiner Nutzer gerecht wird. Im Allgemeinen betrachtet die Messung eine Sammlung von zu durchsuchenden Dokumenten und eine Suchanfrage. Traditionelle Bewertungsmetriken, konstruiert für Boolean Retrieval oder Top-k Retrieval, umfassen Präzision und Rückruf. Alle Maßnahmen nehmen eine Grundwahrheitsrelevanz an: Jedes Dokument ist bekanntlich relevant oder für eine bestimmte Abfrage nicht relevant. In der Praxis können Abfragen schlecht gestellt werden und es können verschiedene Farbtöne von Relevanz sein. Timeline Vor den 1900er Jahren 1801: Joseph Marie Jacquard erfindet die Jacquardwebmaschine, die erste Maschine, die gestanzte Karten verwendet, um eine Abfolge von Operationen zu kontrollieren. 1880s:Herman Hollerith erfindet einen elektromechanischen Daten-Tabulator mit Stempelkarten als maschinenlesbares Medium. 1890 Hollerith Karten, Keypunches und Tabulatoren verwendet, um die 1890 US Census Daten zu verarbeiten.1920s-1930s Emanuel Goldberg erteilt Patente für seine "Statistical Machine" eine Dokumentsuchmaschine, die photoelektrische Zellen und Mustererkennung verwendet, um die Metadaten auf Rollen von mikroverfilmten Dokumenten zu suchen. 1940s–1950s Ende 1940s: Das US-Militär konfrontierte Probleme der Indexierung und Retrieval von Kriegszeit-wissenschaftlichen Forschungsdokumenten von Deutschen gefangen genommen.1945:Vannevar Bush's As We May Think erschien im Atlantic Monthly. 1947:Hans Peter Luhn (Forschungsingenieur bei IBM seit 1941) begann mit der Arbeit an einem mechanisierten Stanzkarten-basierten System zur Suche von chemischen Verbindungen.1950s:Gründe Sorge in den USA für eine "Wissenschaftslücke" mit der UdSSR motiviert, gefördert und einen Hintergrund für mechanisierte Literatursuchsysteme (Allen Kent et al. und die Erfindung der Zitationsindexierung (Eugene Garfield).1950:Der Begriff "Informationsabruf" wurde von Calvin Mooers geprägt. 1951:Philip Bagley führte das früheste Experiment im computergestützten Dokumentenabruf in einer Masterarbeit am MIT.1955: Allen Kent trat der Case Western Reserve University bei und wurde schließlich assoziierter Direktor des Center for Documentation and Communications Research. Im selben Jahr veröffentlichten Kent und Kollegen ein Dokument in der amerikanischen Dokumentation, in dem die Präzisions- und Rückrufmaßnahmen beschrieben wurden, sowie einen vorgeschlagenen Rahmen für die Bewertung eines IR-Systems, das statistische Stichprobenverfahren zur Bestimmung der Anzahl der nicht abgerufenen relevanten Dokumente enthielt. 1958: Internationale Konferenz über wissenschaftliche Informationen Washington DC beinhaltete die Berücksichtigung von IR-Systemen als Lösung für identifizierte Probleme. Vgl.: Proceedings of the International Conference on Scientific Information, 1958 (National Academy of Sciences, Washington, DC, 1959) 1959:Hans Peter Luhn veröffentlichte "Auto-Kodierung von Dokumenten für Informationsabrufe". 1960er Jahre: Anfang der 1960er Jahre:Gerard Salton begann mit der Arbeit an IR in Harvard, später zog nach Cornell. 1960:Melvin Earl Maron und John Lary Kuhns veröffentlicht "Über Relevanz, probabilistische Indexierung und Informationsabruf" im Journal of the ACM 7(3):216–244, Juli 1960.1962: Cyril W. Cleverdon veröffentlichte erste Ergebnisse der Cranfield-Studien und entwickelte ein Modell zur IR-Systembewertung. Siehe: Cyril W. Cleverdon, "Report on the Testing and Analysis of an Investigation in the Comparative Efficiency of Indexing Systems". Cranfield Collection of Aeronautics, Cranfield, England, 1962. Kent veröffentlichte Informationsanalyse und Retrieval. 1963:Weinberg-Bericht "Wissenschaft, Regierung und Information" gab eine vollständige Artikulation der Idee einer "Krise der wissenschaftlichen Informationen". Der Bericht wurde nach Dr. Alvin Weinberg benannt. Joseph Becker und Robert M. Hayes veröffentlichten Text zum Informationsabruf. Becker, Joseph; Hayes, Robert Mayo.Informationsspeicherung und Abruf: Werkzeuge, Elemente, Theorien. New York, Wiley (1963).1964:Karen Spärck Jones beendete ihre Dissertation in Cambridge, Synonymy und Semantic Classification und setzte die Arbeit an Computerlinguistiken fort, wie es für IR gilt. Das National Bureau of Standards sponserte ein Symposium mit dem Titel "Statistical Association Methods for Mechanized Documentation. " Mehrere hochwertig bedeutende Papiere, darunter G. Saltons erste publizierte Referenz (wir glauben) an das SMART system.mid-1960s: National Library of Medicine entwickelte MEDLARS Medical Literature Analysis and Retrieval System, die erste große maschinell lesbare Datenbank und Batch-Retrieval System. Projekt Intrex am MIT.1965:J C. R. Licklider veröffentlichte Bibliotheken der Zukunft. 1966:Don Swanson war an Studien an der University of Chicago über Anforderungen für zukünftige Kataloge beteiligt. Ende der 1960er Jahre:F. Wilfrid Lancaster absolvierte Bewertungsstudien des MEDLARS-Systems und veröffentlichte die erste Ausgabe seines Textes zum Informationsabruf.1968:Gerard Salton veröffentlichte automatische Informationsorganisation und Retrieval. John W. Sammon, Jr.'s RADC Tech-Bericht "Einige Mathematik der Informationsspeicher und Retrieval". skizzierte das Vektormodell.1969:Sammons "A nonlinear mapping for data structure analysis" (IEEE Transactions on Computers) war der erste Vorschlag für Visualisierungsschnittstelle an ein IR-System.1970s Anfang der 1970er Jahre: Erste Online-Systeme – die AIM-TWX, MEDLINE; Lockheed's Dialog; SDCs ORBIT. Theodor Nelson fördert Konzept von Hypertext, veröffentlicht Computer Lib/Dream Machines. 1971:Nicholas Jardine und Cornelis J. van Rijsbergen veröffentlichten "Die Verwendung hierarchischer Clustering in information retrieval", die die "Cluster Hypothese" artikulierten. 1975:Drei hoch einflussreiche Publikationen von Salton artikulierten sein vektorverarbeitendes Rahmen- und Begriffsdiskriminierungsmodell vollständig:Eine Theorie der Indexierung (Gesellschaft für industrielle und angewandte Mathematik)Eine Theorie der Term-Importanz in der automatischen Textanalyse (JASIS v. 26)Ein Vektor-Raummodell für automatische Indexierung (CACM 18:11) 1978:The First ACM SIGIR Konferenz. 1979: C. J. van Rijsbergen veröffentlichte Information Retrieval (Butterworths). Schwere Betonung auf probabilistische Modelle.1979:Tamas Doszkocs implementierte die CITE-Natur-Benutzeroberfläche für MEDLINE in der National Library of Medicine. Das CITE-System unterstützte die kostenlose Formularabfrage-Input, rangierte Ausgabe und Relevanz-Feedback. 1980: Erste internationale ACM SIGIR-Konferenz, gemeinsam mit der britischen Computer Society IR-Gruppe in Cambridge. 1982:Nicholas J. Belkin, Robert N. Oddy und Helen M. Brooks schlugen den Standpunkt der ASK (Anomalous State of Knowledge) zur Informationsabrufung vor. Dies war ein wichtiges Konzept, obwohl ihr automatisiertes Analyse-Tool letztendlich enttäuschend erwies. 1983:Salton (und Michael J. McGill) publizierte Einführung in das Modern Information Retrieval (McGraw-Hill) mit starkem Schwerpunkt auf Vektormodellen.1985:David Blair und Bill Maron veröffentlichen: Eine Bewertung von Retrieval Effectiveness für ein Full-Text Document-Retrieval System Mitte der 1980er Jahre: Bemühungen, Endbenutzerversionen kommerzieller IR-Systeme zu entwickeln.1985-1993: Schlüsselpapiere und experimentelle Systeme zur Visualisierung von Schnittstellen. Arbeit von Donald B. Crouch, Robert R. Korfhage, Matthew Chalmers, Anselm Spoerri und anderen.1989: Erste World Wide Web-Vorschläge von Tim Berners-Lee am CERN. 1990s 1992: Erste TREC-Konferenz. 1997:Veröffentlichung von Korfhage's Information Storage and Retrieval mit Schwerpunkt auf Visualisierung und Multi-Referenz-Systeme.1999:Veröffentlichung von Ricardo Baeza-Yates und Berthier Ribeiro-Netos Modern Information Retrieval von Addison Wesley, dem ersten Buch, das versucht, alle IR.late 1990s zu decken: Web-Suchmaschinen Umsetzung von vielen Features, die bisher nur in experimentellen IR-Systemen gefunden wurden. Suchmaschinen werden die häufigste und vielleicht beste Instantiation von IR-Modellen. Große Konferenzen SIGIR: Konferenz über Forschung und Entwicklung in der Informationsgewinnung ECIR: Europäische Konferenz zum Informationsabruf CIKM: Konferenz zum Informations- und Wissensmanagement WWW: Internationale World Wide Web Conference WSDM: Konferenz über Websuche und Data Mining ICTIR: International Conference on Theory of Information Retrieval Awards auf dem Gebiet Tony Kent Strix Award Gerard Salton Award Karen Spärck Jones Award Siehe auch Referenzen Weiter lesen Ricardo Baeza-Yates, Berthier Ribeiro-Neto. Modern Information Retrieval: The Concepts and Technology hinter Search (zweite Ausgabe). Addison-Wesley, Großbritannien, 2011. Stefan Büttcher, Charles L. A. Clarke und Gordon V. Cormack. Information Retrieval: Implementierung und Auswertung von Suchmaschinen.MIT Presse, Cambridge, Massachusetts, 2010."Information Retrieval System".Bibliothek & Information Science Network.24 April 2015. Christopher D. Manning, Prabhakar Raghavan und Hinrich Schütze. Einführung in Information Retrieval. Cambridge University Press, 2008. ACM SIGIR: Information Retrieval Special Interest Group BCS IRSG: British Computer Society - Information Retrieval Specialist Group Text Retrieval Conference (TREC)Forum for Information Retrieval Evaluation (FIRE) Information Retrieval (online book) von C. J. van Rijsbergen Information Retrieval Wiki Information Retrieval Facility Information Retrieval Techniken @DUTH TREC report Wie eBay Such Relevanz misst Information retrieval performance Evaluation tool @Athena Research Centre