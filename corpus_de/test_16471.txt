Abhängige und unabhängige Variablen sind Variablen in der mathematischen Modellierung, statistischen Modellierung und experimentellen Wissenschaften. Abhängige Variablen erhalten diesen Namen, weil in einem Experiment ihre Werte unter der Supposition oder Forderung untersucht werden, dass sie durch irgendein Gesetz oder Regel (z.B. durch eine mathematische Funktion) von den Werten anderer Variablen abhängen. Unabhängige Variablen werden wiederum nicht als abhängig von einer anderen Variable im Rahmen des betreffenden Experiments betrachtet. In diesem Sinne sind einige gemeinsame unabhängige Variablen Zeit, Raum, Dichte, Masse, Fluidflussrate und frühere Werte von einigen beobachteten Werten von Interesse (z.B. menschliche Bevölkerungsgröße), um zukünftige Werte (die abhängige Variable) vorherzusagen. Von den beiden ist es immer die abhängige Größe, deren Variation untersucht wird, durch Veränderung von Eingängen, auch als Regressoren in einem statistischen Kontext bekannt. In einem Experiment kann jede Variable, die der Experimentator manipuliert, als eigenständige Variable bezeichnet werden. Modelle und Experimente testen die Auswirkungen, die die unabhängigen Variablen von den abhängigen Variablen haben. Manchmal können auch, wenn ihr Einfluss nicht von direktem Interesse ist, aus anderen Gründen unabhängige Variablen berücksichtigt werden, wie beispielsweise deren potenzielle Einfallswirkung. Mathematik In der Mathematik ist eine Funktion eine Regel für die Eingabe (im einfachsten Fall, eine Anzahl oder eine Anzahl von Zahlen) und die Bereitstellung einer Ausgabe (die auch eine Zahl sein kann). Ein Symbol, das für einen beliebigen Eingang steht, wird als eigenständige Größe bezeichnet, während ein Symbol, das für einen beliebigen Ausgang steht, als abhängige Größe bezeichnet wird. Das häufigste Symbol für die Eingabe ist x, und das häufigste Symbol für die Ausgabe ist y; die Funktion selbst ist allgemein geschrieben y = f(x). Es können mehrere unabhängige Variablen oder mehrere abhängige Variablen sein. So trifft man beispielsweise in multivariablem Kalkül häufig auf Funktionen der Form z = f(x,y), wobei z eine abhängige Größe ist und x und y unabhängige Variablen sind. Funktionen mit mehreren Ausgängen werden oft als vektorbewertete Funktionen bezeichnet. Modellierung Bei der mathematischen Modellierung wird die abhängige Variable untersucht, um zu sehen, ob und wie viel sie variiert, da die unabhängigen Variablen variieren. Im einfachen stochastischen Linearmodell yi = a + bxi + ei ist der Begriff yi der Ith-Wert der abhängigen Größe und xi der Ith-Wert der unabhängigen Größe. Der Begriff ei ist als Fehler bekannt und enthält die Variabilität der nicht durch die unabhängige Größe erläuterten abhängigen Größe. Bei mehreren unabhängigen Variablen ist das Modell yi = a + bxi,1 + bxi,2 + ... + bxi,n + ei, wobei n die Zahl der unabhängigen Variablen ist. Das lineare Regressionsmodell wird nun diskutiert. Zur Verwendung einer linearen Regression wird mit X als unabhängiger Variable und Y als abhängige Variable ein Streudiagramm von Daten erzeugt. Dieser wird auch als bivariate Datensatz (x1, y1)(x2, y2) (xi, yi) bezeichnet. Das einfache lineare Regressionsmodell ist die Form von Yi = a + Bxi + Ui, für i = 1, 2, ..., n. In diesem Fall sind Ui, ...,Un unabhängige Zufallsvariablen. Dies geschieht, wenn die Messungen sich nicht beeinflussen. Durch die Unabhängigkeitsverbreitung impliziert die Unabhängigkeit von Ui die Unabhängigkeit von Yi, obwohl jede Yi hat einen anderen Erwartungswert. Jeder Ui hat einen Erwartungswert von 0 und eine Varianz von σ2. Erwartung von Yi Proof: E [ Y i ] = E [ α + β x i + U i ] = α + β x i + E [ U i ] = α + β x i . ^displaystyle E[Y_{i}=E[\alpha +\beta] x_{i}+U_{i}=\alpha +\beta x_{i}+E[U_{i}]=\alpha +\beta x_{i}. Die für den bivariaten Datensatz am besten geeignete Linie ist die Form y = α + βx und wird als Regressionslinie bezeichnet.α und β entsprechen dem Abfang bzw. der Steigung. Simulation Bei der Simulation wird die abhängige Größe in Abhängigkeit von Änderungen der unabhängigen Variablen geändert. Statistik In einem Experiment ist die Variable, die von einem Experimenter manipuliert wird, etwas, das sich als eigenständige Variable erweist. Die abhängige Variable ist das Ereignis, das bei der Manipulation der unabhängigen Variablen erwartet wird. In Data Mining Tools (für multivariate Statistiken und maschinelles Lernen) wird der abhängigen Variablen eine Rolle als Zielvariable (oder in einigen Werkzeugen als Label Attribut) zugewiesen, während eine unabhängige Variable eine Rolle als reguläre Variable zugewiesen werden kann. Für den Trainingsdatensatz und Testdatensatz sind bekannte Werte für die Zielgröße vorgesehen, sollten aber für andere Daten vorhergesagt werden. Die Zielvariable wird in beaufsichtigten Lernalgorithmen, aber nicht in unübertroffenem Lernen verwendet. Statistik-Synonyme Je nach Kontext wird eine unabhängige Variable manchmal als "Predictor-Variable", Regressor, covariate, "manipulated variable", "Explanatory variable", Belichtungsvariable (siehe Zuverlässigkeitstheorie), "Risikofaktor" (siehe medizinische Statistik,) Feature (in maschinellem Lernen und Mustererkennung) oder "Eingabevariable" bezeichnet. Bei Ökonometrien wird der Begriff "Steuergröße" üblicherweise anstelle von Kovariat" verwendet."Erklärungsvariable" wird von einigen Autoren über "unabhängige Variable" bevorzugt, wenn die als unabhängige Variablen behandelten Mengen vom Forscher nicht statistisch unabhängig oder unabhängig manipulierbar sind. Wird die unabhängige Variable als "Erklärungsvariable" bezeichnet, so wird der Begriff "Responsevariable" von einigen Autoren für die abhängige Variable bevorzugt. Aus der Wirtschaftsgemeinschaft werden die unabhängigen Variablen auch exogen genannt. Je nach Kontext wird eine abhängige Variable manchmal als "Response-Variable", Regressand, Kriterium, "vorhergesagte Variable", "gemessene Variable", "erklärte Variable", "erfahrene Variable", "entsprechende Variable", "outcome-Variable", "output variabel", "Ziel oder Label" bezeichnet. In der Ökonomie beziehen sich endogene Variablen in der Regel auf das Ziel. "Erklärte Variable" wird von einigen Autoren über "abhängige Variable" bevorzugt, wenn die als "abhängige Variablen" behandelten Mengen nicht statistisch abhängig sind. Wird die abhängige Variable als "erklärte Variable" bezeichnet, so wird der Begriff "Predictor variable" von einigen Autoren für die unabhängige Variable bevorzugt. Variablen können auch durch ihre Form bezeichnet werden: kontinuierlich oder kategorisch, die wiederum binär/dichotom, nominell kategorisch, und ordinal kategorisch sein kann, unter anderem. Ein Beispiel ist die Analyse der Entwicklung des Meeresspiegels von Woodworth (1987). Hier war die abhängige Variable (und Variable von den meisten Interessen) der jährliche mittlere Meeresspiegel an einem bestimmten Ort, für den eine Reihe von jährlichen Werten zur Verfügung stand. Die primäre unabhängige Variable war Zeit. Es wurde ein Kovariat verwendet, das aus jährlichen Durchschnittswerten des atmosphärischen Jahresdrucks auf Seeniveau besteht. Die Ergebnisse zeigten, dass die Einbeziehung der Kovariate verbesserte Schätzungen des zu erzielenden Trends gegen die Zeit gegenüber Analysen erlaubte, die das Kovariat weggelassen hatten. Sonstige Variablen Eine Variable kann gedacht werden, um die abhängigen oder unabhängigen Variablen zu verändern, kann aber nicht tatsächlich der Fokus des Experiments sein. Damit die Variable konstant gehalten oder überwacht wird, um ihre Wirkung auf das Experiment zu minimieren. Solche Variablen können entweder als "kontrollierte Variable", "Steuergröße", oder "fixierte Variable" bezeichnet werden. Außergewöhnliche Variablen, wenn sie in einer Regressionsanalyse als unabhängige Variablen enthalten sind, können einen Forscher mit einer genauen Antwortparameterschätzung, Vorhersage und Güte der Passform unterstützen, sind aber nicht von wesentlichem Interesse für die untersuchte Hypothese. In einer Studie, in der die Auswirkungen der postsekundären Bildung auf das Lebenseinkommen untersucht werden, könnten einige außergewöhnliche Variablen Geschlecht, Ethnizität, soziale Klasse, Genetik, Intelligenz, Alter und so weiter sein. Eine Variable ist nur dann außerordentlich, wenn davon ausgegangen werden kann (oder dargestellt), die abhängige Variable zu beeinflussen. Wenn in einer Regression enthalten, kann es die Passform des Modells verbessern. Wird sie von der Regression ausgeschlossen und hat sie eine nicht-Null-Kovarianz mit einer oder mehreren der unabhängigen Variablen von Interesse, so wird ihre Unterlassung das Ergebnis der Regression für die Wirkung dieser unabhängigen Variablen von Interesse vorbeugen. Dieser Effekt wird als konfounding oder weggelassene Variable Bias bezeichnet; in diesen Situationen sind Designänderungen und/oder Steuerungen für eine variable statistische Steuerung erforderlich. Extrane Variablen werden oft in drei Typen klassifiziert: Betreffvariablen, die die Merkmale der untersuchten Personen sind, die ihre Handlungen beeinflussen könnten. Diese Variablen umfassen Alter, Geschlecht, Gesundheitsstatus, Stimmung, Hintergrund, etc. Blockiervariablen oder experimentelle Variablen sind Merkmale der Experimentierpersonen, die beeinflussen können, wie sich eine Person verhält. Geschlecht, das Vorhandensein von Rassendiskriminierung, Sprache oder anderen Faktoren können als solche Variablen gelten. Situationsvariablen sind Merkmale der Umwelt, in der die Studie oder Forschung durchgeführt wurde, die sich negativ auf das Ergebnis des Experiments auswirken. Inklusive der Lufttemperatur, der Aktivität, der Beleuchtung und der Tageszeit. Bei der Modellierung wird die Variabilität, die nicht von der unabhängigen Variablen abgedeckt wird, mit e I \{displaystyle e_{I} bezeichnet und als Rest, "Seiteneffekt", Fehler, "unerklärter Anteil", "Restgröße", Störung oder Toleranz bezeichnet. Beispiele Wirkung von Dünger auf Pflanzenwachstum: In einer Studie, die den Einfluss unterschiedlicher Mengen an Düngemittel auf das Pflanzenwachstum messen würde, wäre die unabhängige Variable die Menge an Düngemittel. Die abhängige Größe wäre das Wachstum in Höhe oder Masse der Pflanze. Die kontrollierten Variablen wären die Art der Pflanze, die Art des Düngers, die Menge des Sonnenlichts, das die Pflanze bekommt, die Größe der Töpfe, etc. Wirkung der Medikamentendosierung auf Symptomenschwere: In einer Studie, wie unterschiedliche Dosen eines Medikaments die Schwere der Symptome beeinflussen, könnte ein Forscher die Häufigkeit und Intensität der Symptome vergleichen, wenn verschiedene Dosen verabreicht werden. Dabei ist die unabhängige Größe die Dosis und die abhängige Größe die Häufigkeit/Intensität der Symptome. Wirkung der Temperatur auf die Pigmentierung: Bei der Messung der Farbmenge, die bei unterschiedlichen Temperaturen aus Rübenstichproben entfernt wird, ist die Temperatur die unabhängige Größe und die abgetragene Pigmentmenge die abhängige Größe. Wirkung des Zuckers in einem Kaffee: Der Geschmack variiert mit der Zuckermenge im Kaffee. Hier ist der Zucker die unabhängige Variable, während der Geschmack die abhängige Variable ist. Siehe auch Abszisse und Ordinate Blocking (Statistik)Latentvariable versus beobachtbare Variable Noten == Referenzen ==