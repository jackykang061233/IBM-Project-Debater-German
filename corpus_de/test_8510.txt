Operative Konditionierung (auch instrumentale Konditionierung genannt) ist eine Art assoziativer Lernprozess, durch den die Stärke eines Verhaltens durch Verstärkung oder Strafe verändert wird. Es ist auch ein Verfahren, das verwendet wird, um ein solches Lernen zu bewirken. Obwohl operierende und klassische Konditionierung beide von Umweltreizen kontrollierte Verhaltensweisen beinhalten, unterscheiden sie sich in der Natur. In der operierenden Konditionierung wird das Verhalten durch externe Reize gesteuert. Zum Beispiel kann ein Kind lernen, eine Box zu öffnen, um die Süßigkeiten innen zu bekommen, oder lernen, um zu vermeiden, einen heißen Herd zu berühren; in operierenden Begriffen sind die Box und der Herd "diskriminative Reize". Operatives Verhalten soll freiwillig sein". Die Reaktionen stehen unter der Kontrolle des Organismus und sind Opern. Zum Beispiel kann das Kind eine Wahl zwischen Öffnen der Box und Streichen eines Welpen. Im Gegensatz dazu beinhaltet die klassische Konditionierung unfreiwilliges Verhalten basierend auf der Paarung von Reize mit biologisch bedeutsamen Ereignissen. Die Antworten stehen unter der Kontrolle einiger Reize, weil sie Reflexe sind, die von den entsprechenden Reize automatisch elicitiert werden. Zum Beispiel kann der Anblick von Süßigkeiten dazu führen, dass ein Kind saliviert wird, oder der Klang eines Türslams kann einen wütenden Elternteil signalisieren, wodurch ein Kind zittert. Salivierung und Zittern sind keine Opern; sie werden nicht durch ihre Folgen verstärkt, und sie werden nicht freiwillig gewählt". Allerdings können beide Arten von Lernen das Verhalten beeinflussen. Klassisch bedingte Reize – zum Beispiel ein Bild von Süßigkeiten auf einer Kiste – verstärken die operierende Konditionierung, indem sie ein Kind ermutigt, sich anzunähern und die Kiste zu öffnen. Die Forschung hat gezeigt, dass dies ein günstiges Phänomen ist, wenn das operierende Verhalten fehleranfällig ist. Die Studie des Tierlernens im 20. Jahrhundert wurde von der Analyse dieser beiden Arten von Lernen dominiert, und sie befinden sich noch im Kern der Verhaltensanalyse. Sie wurden auch auf die Studie der Sozialpsychologie angewendet, um bestimmte Phänomene wie den falschen Konsenseffekt zu klären. Historische Notiz Thorndikes Gesetz der Wirkung Operante Konditionierung, manchmal instrumental Lernen genannt, wurde zunächst umfassend von Edward L. Thorndike (1874–1949) untersucht, die das Verhalten von Katzen beobachtete, die versuchen, aus hausgemachten Puzzle-Boxen zu entkommen. Eine Katze konnte durch eine einfache Reaktion aus der Box entweichen, wie z.B. das Ziehen eines Seils oder das Drücken eines Pols, aber wenn sie erst eingeschränkt wurde, dauerten die Katzen lange, um herauszukommen. Bei wiederholten Versuchen traten weniger häufige und erfolgreiche Reaktionen auf, so dass die Katzen immer schneller entkamen. Thorndike verallgemeinerte diese Erkenntnis in seinem Wirkungsgesetz, das besagt, dass Verhaltensweisen, die von befriedigenden Folgen gefolgt sind, sich wiederholen und jene, die unangenehme Folgen hervorbringen, weniger wahrscheinlich wiederholt werden. Kurz gesagt, einige Konsequenzen stärken das Verhalten und einige Konsequenzen schwächen das Verhalten. Durch die Aufzeichnung der Fluchtzeit gegen die Testnummer erzeugte Thorndike durch dieses Verfahren die ersten bekannten tierischen Lernkurven. Menschen scheinen viele einfache Verhaltensweisen durch die Art des von Thorndike untersuchten Prozesses zu lernen, jetzt als operierende Konditionierung bezeichnet. Das heißt, Antworten bleiben erhalten, wenn sie zu einem erfolgreichen Ergebnis führen und verworfen, wenn sie nicht, oder wenn sie aversive Effekte erzeugen. Dies geschieht in der Regel, ohne von einem Lehrer geplant zu werden, aber die operierende Konditionierung wurde von Eltern verwendet, um ihre Kinder für Tausende von Jahren zu lehren. B. F. Skinner B.F Skinner (1904–1990) wird als Vater der operierenden Konditionierung bezeichnet und seine Arbeit wird häufig im Zusammenhang mit diesem Thema zitiert. Sein 1938 Buch "The Behavior of Organisms: An Experimental Analysis", initiierte sein lebenslanges Studium der operierenden Konditionierung und der Anwendung auf menschliches und tierisches Verhalten. Nach den Vorstellungen von Ernst Mach lehnte Skinner Thorndikes Hinweis auf unbeobachtbare mentale Zustände wie Zufriedenheit ab, baute seine Analyse auf beobachtbarem Verhalten und seine ebenso beobachtbaren Konsequenzen. Skinner glaubte, dass die klassische Konditionierung zu simpelistisch sei, um etwas so komplexes wie menschliches Verhalten zu beschreiben. Operante Konditionierung, seiner Meinung nach besser beschrieben menschliches Verhalten, wie es untersucht Ursachen und Auswirkungen von absichtlichen Verhalten. Zur Umsetzung seines empirischen Ansatzes erfand Skinner die operierende Konditionierkammer oder "Skinner Box", in der Themen wie Tauben und Ratten isoliert wurden und sorgfältig kontrollierten Reize ausgesetzt werden konnten. Im Gegensatz zu Thorndikes Puzzlebox erlaubte diese Anordnung dem Subjekt eine oder zwei einfache, wiederholbare Reaktionen zu machen, und die Rate solcher Reaktionen wurde Skinners primäre Verhaltensmaßnahme. Eine weitere Erfindung, der kumulative Recorder, ergab einen grafischen Datensatz, aus dem diese Antwortraten geschätzt werden konnten. Diese Aufzeichnungen waren die primären Daten, die Skinner und seine Kollegen nutzten, um die Auswirkungen auf die Ansprechrate verschiedener Bewehrungspläne zu untersuchen. Ein Bewehrungsplan kann definiert werden als "jedes Verfahren, das Bewehrung an einen Organismus nach einer bestimmten Regel liefert". Die Auswirkungen der Fahrpläne wurden wiederum die grundlegenden Erkenntnisse, aus denen Skinner sein Konto der operierenden Konditionierung entwickelt. Er zog auch auf viele weniger formale Beobachtungen des menschlichen und tierischen Verhaltens. Viele der Schriften von Skinner widmen sich der Anwendung der operierenden Konditionierung auf das menschliche Verhalten. 1948 veröffentlichte er Walden Two, ein fiktives Konto einer friedlichen, glücklichen, produktiven Gemeinschaft, die um seine Konditionierungsprinzipien organisiert ist. Im Jahr 1957 veröffentlichte Skinner Verbal Behavior, der die Prinzipien der operierenden Konditionierung auf Sprache erweiterte, eine Form des menschlichen Verhaltens, die zuvor ganz anders von Linguisten und anderen analysiert worden war. Skinner definierte neue funktionale Beziehungen wie Mands und Takte, um einige wesentliche Sprachkenntnisse zu erfassen, aber er führte keine neuen Prinzipien ein, behandelte verbales Verhalten wie jedes andere Verhalten, das von seinen Folgen kontrolliert wurde, was die Reaktionen des Sprechers beinhaltete. Begriffe und Prozeduren Ursprung des operierenden Verhaltens: Operative Variabilität Operatives Verhalten soll emittiert werden, d.h. es wird zunächst nicht von einem bestimmten Reiz elicited. So kann man fragen, warum es an erster Stelle geschieht. Die Antwort auf diese Frage ist wie Darwins Antwort auf die Frage der Herkunft einer neuen Körperstruktur, nämlich Variation und Auswahl. In ähnlicher Weise variiert das Verhalten eines Individuums von Moment zu Moment, in solchen Aspekten wie den jeweiligen Bewegungen, der aufgebrachten Kraftmenge oder dem Zeitpunkt der Reaktion. Variationen, die zu Verstärkung führen, werden verstärkt, und wenn Verstärkung konsistent ist, das Verhalten tendenziell stabil bleiben. Durch die Manipulation bestimmter Variablen kann jedoch selbst die Verhaltensvariabilität verändert werden. Operatives Verhalten: Verstärkung und Bestrafung Verstärkung und Bestrafung sind die Kernwerkzeuge, durch die das operierende Verhalten verändert wird. Diese Begriffe werden durch ihre Wirkung auf Verhalten definiert. Entweder kann positiv oder negativ sein. Positive Verstärkung und negative Verstärkung erhöhen die Wahrscheinlichkeit eines Verhaltens, das sie folgen, während positive Bestrafung und negative Bestrafung die Wahrscheinlichkeit des Verhaltens verringern, das sie folgen. Ein weiteres Verfahren wird Extinktion genannt. Extinktion tritt auf, wenn ein zuvor verstärktes Verhalten nicht mehr mit einer positiven oder negativen Verstärkung verstärkt wird. Beim Aussterben wird das Verhalten weniger wahrscheinlich. Die kirchliche Verstärkung kann zu einer noch längeren Verzögerung vor dem Aussterben des Verhaltens führen, da der Lernfaktor wiederholter Instanzen notwendig wird, um Verstärkung zu erhalten, wenn bei jeder Gelegenheit vor dem Aussterben Verstärkung gegeben wird. Es gibt insgesamt fünf Konsequenzen. Positive Verstärkung tritt auf, wenn ein Verhalten (Response) belohnt wird oder dem Verhalten ein weiterer Reiz folgt, der belohnt und die Frequenz dieses Verhaltens erhöht. Wenn z.B. eine Ratte in einer Skinner-Box Nahrung bekommt, wenn sie einen Hebel drückt, wird ihre Pressgeschwindigkeit steigen. Dieser Vorgang wird üblicherweise einfach als Verstärkung bezeichnet. Negative Verstärkung (a.k.a.) tritt auf, wenn ein Verhalten (Response) durch die Entfernung eines aversiven Reizs gefolgt wird, wodurch die Frequenz des ursprünglichen Verhaltens erhöht wird. Im Skinner Box-Experiment könnte der aversive Reiz ein lautes Geräusch sein, das kontinuierlich in der Box herrscht; negative Verstärkung würde passieren, wenn die Ratte einen Hebel drückt, um das Geräusch abzuschalten. Positive Bestrafung (auch als "Verletzung durch contingent Stimulation" bezeichnet) tritt auf, wenn ein Verhalten (Response) von einem aversiven Reiz gefolgt wird. Beispiel: Schmerzen aus einem Überspannen, was oft zu einer Abnahme dieses Verhaltens führen würde. Positive Strafe ist ein verwirrender Begriff, so wird das Verfahren in der Regel als Strafe bezeichnet". Negative Bestrafung (Penalty) (auch als "Putishment by contingent Abzug" bezeichnet) tritt auf, wenn ein Verhalten (Response) von der Entfernung eines Reizes gefolgt wird. Beispiel: Abnehmen eines Kinderspielzeugs nach einem unerwünschten Verhalten durch ihn/ihr, was zu einer Abnahme des unerwünschten Verhaltens führen würde. Extinktion tritt auf, wenn ein zuvor verstärktes Verhalten (Response) nicht mehr wirksam ist. Beispiel: Eine Ratte wird zum Drücken eines Hebels zunächst viel Nahrung gegeben, bis der Experimentator nicht mehr als Belohnung Nahrung ausgibt. Die Ratte würde typischerweise den Hebel weniger oft drücken und dann anhalten. Die Hebelpressung soll dann ausgelöscht werden. " Es ist wichtig zu beachten, dass die Akteure (z.B. eine Ratte) nicht als verstärkt, bestraft oder gelöscht gesprochen werden; es sind die Aktionen, die verstärkt, bestraft oder gelöscht werden. Verstärkung, Bestrafung und Auslöschung sind keine Begriffe, deren Verwendung auf das Labor beschränkt ist. Natürlich auftretende Folgen können auch das Verhalten verstärken, bestrafen oder löschen und sind nicht immer geplant oder vor Ort geliefert. Zeitpläne der Bewehrung Zeitpläne der Bewehrung sind Regeln, die die Lieferung der Bewehrung steuern. Die Regeln geben entweder die Zeit an, in der die Verstärkung zur Verfügung gestellt werden soll, oder die Anzahl der zu treffenden Antworten oder beides. Viele Regeln sind möglich, aber die folgenden sind die grundlegendsten und häufig verwendeten Fixed Intervall Zeitplan: Die Verstärkung erfolgt nach dem ersten Ansprechen nach Ablauf einer festen Zeit nach der vorherigen Verstärkung. Dieser Zeitplan ergibt ein bruchartiges Reaktionsmuster, d.h. nach dem Training auf diesem Zeitplan hält der Organismus typischerweise nach der Verstärkung ein und beginnt dann, schnell zu reagieren, wie die Zeit für die nächsten Verstärkungsansätze. Variabler Intervallplan: Die Verstärkung erfolgt nach dem ersten Ansprechen nach Ablauf einer variablen Zeit von der vorherigen Verstärkung. Dieser Zeitplan ergibt typischerweise eine relativ konstante Reaktionsgeschwindigkeit, die mit der durchschnittlichen Zeit zwischen Verstärkungen variiert. Behobenes Verhältnis: Die Verstärkung erfolgt, nachdem seit der vorherigen Verstärkung eine feste Anzahl von Antworten abgegeben worden ist. Ein auf diesem Zeitplan trainierter Organismus hält typischerweise eine Weile nach einer Verstärkung und reagiert dann mit einer hohen Rate. Ist die Ansprechanforderung gering, kann es keine Pause geben; wenn die Ansprechanforderung hoch ist, kann der Organismus aufhören, insgesamt zu antworten. Variables Verhältnis: Die Verstärkung erfolgt, nachdem seit der vorherigen Verstärkung eine variable Anzahl von Antworten abgegeben wurden. Dieser Zeitplan liefert typischerweise eine sehr hohe, anhaltende Reaktionsgeschwindigkeit. Kontinuierliche Verstärkung: Die Verstärkung erfolgt nach jeder Reaktion. Organisatoren reagieren typischerweise so schnell wie möglich, angesichts der Zeit, die benötigt wird, um Verstärkung zu erhalten und zu konsumieren, bis sie satiiert sind. Faktoren, die die Wirksamkeit der Verstärkung und Strafe verändern Die Wirksamkeit von Verstärkung und Strafe kann geändert werden. Befriedigung/Befreiung: Die Wirksamkeit eines positiven oder appetitiven Reizs wird reduziert, wenn der Individuum genug von diesem Reiz erhalten hat, um seinen Appetit zu befriedigen. Der entgegengesetzte Effekt wird auftreten, wenn das Individuum von diesem Reiz beraubt wird: die Wirksamkeit einer Folge wird dann zunehmen. Ein Thema mit vollem Magen würde sich nicht als hungrig motiviert fühlen. Unmittelbar: Eine sofortige Folge ist wirksamer als eine verzögerte. Wenn man einem Hund einen Leckerbissen für das Sitzen innerhalb von fünf Sekunden gibt, wird der Hund schneller lernen, als wenn der Leckerbissen nach dreißig Sekunden gegeben wird. Konsistenz: Um am effektivsten zu sein, sollte die Verstärkung nach Reaktionen konsequent und nicht zu anderen Zeiten auftreten. Das Lernen kann langsamer sein, wenn die Verstärkung intermittierend ist, d.h. nach nur einigen Fällen derselben Reaktion. Reaktionen, die intermittierend verstärkt werden, sind in der Regel langsamer zu löschen als Reaktionen, die immer verstärkt wurden. Größe: Die Größe oder Menge eines Stimulus beeinflusst oft seine Potenz als Verstärker. Menschen und Tiere beschäftigen sich mit der Kosten-Nutzen-Analyse. Wenn eine Hebelpresse zehn Lebensmittelpellets bringt, kann der Hebeldruck schneller erlernt werden, als wenn eine Presse nur ein Pellet bringt. Ein Viertelstapel von einer Spielautomat kann einen Spieler halten, der den Hebel länger als ein Viertel zieht. Die meisten dieser Faktoren dienen biologischen Funktionen. Beispielsweise hilft der Prozess der Satiation dem Organismus eine stabile innere Umgebung (Hoostasis). Wenn beispielsweise ein Organismus von Zucker beraubt wurde, ist der Geschmack von Zucker ein wirksamer Versteifer. Wenn der Blutzucker des Organismus ein optimales Niveau erreicht oder überschreitet, wird der Geschmack des Zuckers weniger wirksam oder sogar aversiv. Shaping Shaping ist eine Konditionierungsmethode, die in der Tierschulung und in der Lehre von nicht-verbalen Menschen viel verwendet wird. Es hängt von der operierenden Variabilität und Verstärkung ab, wie oben beschrieben. Der Trainer beginnt, indem er das gewünschte endgültige (oder Ziel) Verhalten ermittelt. Als nächstes wählt der Trainer ein Verhalten, das das Tier oder die Person bereits mit einer gewissen Wahrscheinlichkeit emittiert. Die Form dieses Verhaltens wird dann über aufeinanderfolgende Versuche allmählich verändert, indem Verhaltensweisen verstärkt werden, die das Zielverhalten immer enger annähern. Wenn das Zielverhalten endlich ausgesandt wird, kann es durch den Einsatz eines Bewehrungsplans verstärkt und gepflegt werden. Nichtkontinuierliche Verstärkung Nichtkontinuierliche Verstärkung ist die Abgabe von Verstärkungsreizen unabhängig vom Verhalten des Organismus. Eine nichtkontinente Verstärkung kann zum Versuch genutzt werden, ein unerwünschtes Zielverhalten zu reduzieren, indem mehrere alternative Reaktionen unter Auslöschen der Zielantwort verstärkt werden. Da kein gemessenes Verhalten als verstärkt erkannt wird, gibt es Kontroversen, die die Verwendung des Begriffs nichtkontinent Verstärkung umgeben. Stimulus-Kontrolle des operierenden Verhaltens Obwohl zunächst operierendes Verhalten ohne identifizierten Bezug auf einen bestimmten Reiz emittiert wird, kommen während der operierenden Konditionierungsopern unter der Kontrolle von Reize, die bei verstärktem Verhalten vorhanden sind. Solche Reize werden "diskriminative Reize" genannt. Eine sogenannte "drei-term contingency" ist das Ergebnis. Das heißt, diskriminative Reize setzen den Anlass für Reaktionen, die Belohnung oder Strafe erzeugen. Beispiel: Eine Ratte kann trainiert werden, um einen Hebel nur zu drücken, wenn ein Licht kommt; ein Hund eilt in die Küche, wenn es die Rassel seiner/ihr Lebensmitteltasche hört; ein Kind erreicht Süßigkeiten, wenn er es auf einem Tisch sieht. Diskriminierung, Verallgemeinerung und Kontext Das meiste Verhalten ist unter Reizkontrolle. Mehrere Aspekte können unterschieden werden: Die Diskriminierung tritt typischerweise dann auf, wenn eine Reaktion nur in Gegenwart eines bestimmten Reizs verstärkt wird. Zum Beispiel könnte ein Taube zum Pecken an einem roten Licht und nicht an einem grünen Licht gefüttert werden; folglich stößt er an Rot und stoppt das Pecken an Grün. Es wurden viele komplexe Kombinationen von Stimuli und anderen Bedingungen untersucht; beispielsweise könnte ein Organismus in einem Intervallplan in Gegenwart eines Stimulus und in einem Verhältnisplan in Gegenwart eines anderen verstärkt werden. Die Verallgemeinerung ist die Tendenz, auf Reize zu reagieren, die einem zuvor geschulten diskriminativen Reiz ähnlich sind. Zum Beispiel, in Rot geschult, könnte ein Taube auch bei Pink pecken, wenn auch in der Regel weniger stark. Kontext bezieht sich auf Reize, die in einer Situation kontinuierlich vorhanden sind, wie die Wände, Tische, Stühle, etc. in einem Raum, oder das Innere einer operierenden Konditionierkammer. Kontextreize können dazu kommen, das Verhalten als diskriminierende Reize zu steuern, wenn auch in der Regel schwacher. Die in einem Kontext gelernten Verhaltensweisen können in einem anderen Kontext abwesend oder verändert sein. Dies kann zu Schwierigkeiten bei der Verhaltenstherapie führen, da in der therapeutischen Umgebung gelernte Verhaltensweisen in anderen Situationen nicht auftreten können. Verhaltenssequenzen: bedingte Verstärkung und Ketten Die meisten Verhaltensweisen lassen sich nicht leicht in Bezug auf einzelne Reaktionen beschreiben, die von einem verstärkt werden. Der Umfang der Opernanalyse wird durch die Idee von Verhaltensketten erweitert, die Sequenzen von Reaktionen sind, die durch die oben definierten dreifachen Kontingenzen miteinander verknüpft sind. Die Kettenbildung basiert auf der Tatsache, experimentell demonstriert, dass ein diskriminativer Reiz nicht nur den Anlass für ein späteres Verhalten setzt, sondern auch ein ihm vorausgehendes Verhalten verstärken kann. Das heißt, ein diskriminativer Reiz ist auch ein "konditionierter Versteifer". Beispielsweise kann das Licht, das den Anlass zum Hebelpressen setzt, dazu verwendet werden, das "Umdrehen" in Gegenwart eines Geräuschs zu verstärken. Dies führt in der Folge "Geräusch – Rundum – Licht – Druckhebel – Lebensmittel". Viel längere Ketten können gebaut werden, indem mehr Reize und Antworten hinzugefügt werden. Flucht und Vermeidung Beim Entfliehen endet ein Verhalten einen (aversiven) Reiz. Zum Beispiel beendet die Abschirmung der Augen vor Sonnenlicht die (aversive) Stimulation des hellen Lichts in den Augen. (Dies ist ein Beispiel für negative Verstärkung, oben definiert.) Behavior, das durch die Verhinderung eines Stimulus gehalten wird, wird als Vermeidung bezeichnet, wie zum Beispiel, auf Sonnenbrille setzen, bevor Sie im Freien gehen. Vermeidungsverhalten erhöht das sogenannte "Vermeidungsparadox", denn es kann gefragt werden, wie kann die Nicht-Okkurrenz eines Stimulus als Verstärkung dienen? Diese Frage wird von mehreren Theorien der Vermeidung behandelt (siehe unten). Zwei Arten von experimentellen Einstellungen werden häufig verwendet: diskriminiertes und frei funktionierendes Vermeidungslernen. Diskrierte Vermeidung von Lernen Ein diskriminiertes Vermeidungsexperiment beinhaltet eine Reihe von Versuchen, bei denen ein neutraler Reiz, wie ein Licht, von einem aversiven Reiz wie einem Schock gefolgt wird. Nachdem der neutrale Reiz erscheint, verhindert oder beendet eine operierende Reaktion wie eine Hebelpresse den aversiven Reiz. In frühen Versuchen macht das Thema nicht die Antwort, bis der aversive Reiz aufgetreten ist, so dass diese frühen Versuche als Fluchtversuche bezeichnet werden. Beim Fortschreiten des Lernens beginnt das Thema während des neutralen Reizs zu reagieren und verhindert so, dass der aversive Reiz auftritt. Solche Versuche werden als "Vermeidungsversuche" bezeichnet. Dieses Experiment soll eine klassische Konditionierung beinhalten, da ein neutraler CS (konditionierter Reiz) mit den aversiven US (unkonditionierter Reiz) gepaart wird; diese Idee basiert auf der zwei-Faktor Theorie des Vermeidungserlernens, die unten beschrieben wird. Freilauf-Vermeidung Lernen Bei freier Vermeidung erhält ein Subjekt periodisch einen aversiven Stimulus (oft einen elektrischen Schock), es sei denn, eine operierende Antwort erfolgt; die Reaktion verzögert den Beginn des Schocks. In dieser Situation, anders als diskriminierte Vermeidung, signalisiert kein vorheriger Reiz den Schock. Zwei entscheidende Zeitintervalle bestimmen die Geschwindigkeit des Vermeidens Lernens. Das erste ist das S-S (shock-shock) Intervall. Dies ist Zeit zwischen aufeinanderfolgenden Schocks in Abwesenheit einer Reaktion. Das zweite Intervall ist das R-S (Response-shock) Intervall. Dies gibt die Zeit an, in der eine operierende Reaktion den Beginn des nächsten Schocks verzögert. Beachten Sie, dass jedes Mal, wenn das Subjekt die operierende Reaktion durchführt, das R-S-Intervall ohne Schock neu beginnt. Zweistufige Theorie der Vermeidung Diese Theorie wurde ursprünglich vorgeschlagen, um diskriminiertes Vermeidenslernen zu erklären, in dem ein Organismus lernt, einen aversiven Reiz zu vermeiden, indem er aus einem Signal für diesen Reiz entweicht. Zwei Prozesse sind dabei: klassische Konditionierung des Signals, gefolgt von einer funktionsfähigen Konditionierung der Fluchtreaktion: a) Klassische Konditionierung der Angst.Zunächst erfährt der Organismus die Paarung einer CS mit einer US. Die Theorie geht davon aus, dass diese Paarung durch klassische Konditionierung einen Zusammenhang zwischen der CS und den USA schafft und die CS aufgrund der aversiven Natur der USA eine bedingte emotionale Reaktion (CER) – Angst "b) Verstärkung der operierenden Reaktion durch Angst-Reduktion. Durch den ersten Prozess signalisiert die CS nun Angst; diese unangenehme emotionale Reaktion dient der Motivation von operierenden Reaktionen, und Reaktionen, die die CS beenden, werden durch Angstabbruch verstärkt. Beachten Sie, dass die Theorie nicht sagt, dass der Organismus die USA im Sinne der Antizipation vermeidet, sondern dass der Organismus einem aversiven inneren Zustand entweicht, der durch die CS verursacht wird. Mehrere experimentelle Erkenntnisse scheinen der Zwei-Faktor-Theorie entgegenzulaufen. Zum Beispiel löscht das Vermeidungsverhalten oft sehr langsam, auch wenn die anfängliche CS-US-Paarung nie wieder auftritt, so dass die Angstantwort voraussichtlich löschen (siehe Klassische Konditionierung). Darüber hinaus haben Tiere, die gelernt haben, oft wenig Beweise für Angst zu zeigen, was darauf hindeutet, dass Flucht aus Angst nicht notwendig ist, um das Vermeidungsverhalten zu erhalten. Operative oder einstufige Theorie Einige Theoretiker vermuten, dass Vermeidungsverhalten einfach ein besonderer Fall des operierenden Verhaltens sein kann, das durch seine Folgen aufrechterhalten wird. In dieser Hinsicht wird die Idee der Konsequenzen erweitert, um die Sensibilität für ein Muster von Ereignissen einzubeziehen. Die Folge einer Reaktion ist somit in Vermeidung eine Verringerung der Aversivstimulation. In der Tat weisen experimentelle Beweise darauf hin, dass ein "missierter Schock" als Reiz erkannt wird und als Versteifer wirken kann. Kognitive Theorien der Vermeidung nehmen diese Idee einen Schritt weiter. Zum Beispiel erwartet eine Ratte einen Schock, wenn sie einen Hebel nicht drückt und "kein Schock erwartet", wenn sie es drückt, und das Vermeiden Verhalten wird verstärkt, wenn diese Erwartungen bestätigt werden. Operative Hoarding Operant Hoarding bezieht sich auf die Beobachtung, dass Ratten in einer bestimmten Weise verstärkt können, dass Lebensmittelpellets in einem Lebensmittel Tablett ansammeln können, anstatt diese Pellets zu entfernen. Bei dieser Verfahrensweise war die Retrievalierung der Pellets immer eine einminütige Extinktionszeit eingeführt worden, während der keine zusätzlichen Lebensmittelpellets zur Verfügung standen, sondern jene, die früher angesammelt worden waren, verzehrt werden konnten. Diese Erkenntnis scheint der üblichen Erkenntnis zu widersprechen, dass sich Ratten impulsiv in Situationen verhalten, in denen eine Wahl zwischen einem kleineren Lebensmittelobjekt sofort und einem größeren Lebensmittelobjekt nach einiger Verzögerung besteht. Sehen Sie die Zeitpläne der Verstärkung. Neurobiologische Korrelationen Die ersten wissenschaftlichen Studien zur Identifizierung von Neuronen, die auf eine Art und Weise reagierten, dass sie für bedingte Reize kodieren, stammten aus der Arbeit von Mahlon deLong und von R.T Richardson. Sie zeigten, dass Nucleus basalis Neuronen, die Acetylcholin breit über den zerebralen Kortex freisetzen, kurz nach einem bedingten Reiz oder nach einer primären Belohnung aktiviert werden, wenn kein bedingter Reiz vorhanden ist. Diese Neuronen sind gleichermaßen für positive und negative Verstärkungsmittel aktiv und haben sich in vielen kortikalen Regionen als mit Neuroplastizität verwandt erwiesen. Es gibt auch Beweise, dass Dopamin zu ähnlichen Zeiten aktiviert wird. Es gibt beträchtliche Beweise, dass Dopamin sowohl an der Verstärkung als auch an dem aversiven Lernen beteiligt ist. Dopamin-Pfadbahnen Projekt viel dichter auf frontale Kortex-Regionen. Cholinergische Projektionen hingegen sind auch in den posterior kortikalen Bereichen wie der primären visuellen Kortex dicht. Eine Studie von Patienten mit Parkinson-Krankheit, eine Bedingung, die auf die unzureichende Wirkung von Dopamin zurückzuführen ist, verdeutlicht die Rolle von Dopamin bei der positiven Verstärkung. Es zeigte sich, dass die Patienten während ihres Medikaments mit aversiven Konsequenzen leichter lernten als mit einer positiven Verstärkung. Patienten, die auf ihrem Medikament waren, zeigten das Gegenteil, um der Fall zu sein, positive Verstärkung bewiesen, die effektivere Form des Lernens zu sein, wenn Dopamin-Aktivität ist hoch. Ein neurochemischer Prozess mit Dopamin wurde vorgeschlagen, die Verstärkung zu untergraben. Wenn ein Organismus einen verstärkenden Reiz erfährt, werden Dopaminpfade im Gehirn aktiviert. Dieses Netz von Pfaden "löst einen kurzen Puls von Dopamin auf viele Dendriten und sendet so ein globales Verstärkungssignal an postynaptische Neuronen." Dies ermöglicht vor kurzem aktivierte Synapsen, um ihre Empfindlichkeit gegenüber fehlerhaften (leitenden) Signalen zu erhöhen, wodurch die Wahrscheinlichkeit des Auftretens für die jüngsten Antworten erhöht wird, die der Verstärkung vorausgegangen sind. Diese Antworten sind statistisch am wahrscheinlichsten das für die erfolgreiche Verstärkung verantwortliche Verhalten gewesen. Aber wenn die Anwendung der Verstärkung entweder weniger unmittelbar oder weniger konsistent ist (weniger konsistent), wird die Fähigkeit von Dopamin, auf die entsprechenden Synapsen zu wirken reduziert. Fragen zum Wirkungsgesetz Eine Reihe von Beobachtungen scheinen zu zeigen, dass operierendes Verhalten ohne Verstärkung im oben definierten Sinne etabliert werden kann. Am meisten zitiert ist das Phänomen der Autoshaping (manchmal als "Zeichenverfolgung" bezeichnet), in dem ein Reiz wiederholt durch Verstärkung gefolgt wird, und folglich beginnt das Tier auf den Reiz zu reagieren. Zum Beispiel wird ein Antwortschlüssel beleuchtet und dann Lebensmittel präsentiert. Wenn dies ein paar Mal wiederholt wird, beginnt ein Taubenthema, den Schlüssel zu pecken, auch wenn Nahrung kommt, ob der Vogel pinkelt oder nicht. Ebenso beginnen die Ratten mit kleinen Objekten wie einem Hebel zu umgehen, wenn Lebensmittel in der Nähe präsentiert werden. Bemerkenswert ist, dass Tauben und Ratten in diesem Verhalten auch dann bestehen, wenn der Schlüssel oder das Drücken des Hebels zu weniger Nahrung führt (Omissionstraining). Ein weiteres sichtbares funktionsloses Verhalten, das ohne Verstärkung erscheint, ist eine kontrastreiche Belastung. Diese Beobachtungen und andere scheinen dem Wirkungsgesetz zu widersprechen, und sie haben einige Forscher aufgefordert, neue Konzeptualisierungen der operierenden Verstärkung vorzuschlagen (z. Eine allgemeinere Ansicht ist, dass Autoshaping eine Instanz der klassischen Konditionierung ist; das Autoshaping-Verfahren hat in der Tat eine der häufigsten Möglichkeiten, die klassische Konditionierung zu messen. In dieser Hinsicht können viele Verhaltensweisen sowohl von klassischen Kontingenzen (Stimulus-Response) als auch von operierenden Kontingenzen (Response-Reforcement) beeinflusst werden, und die Aufgabe des Experimenters besteht darin, herauszufinden, wie diese interagieren. Anwendungen Verstärkung und Bestrafung sind in menschlichen sozialen Interaktionen allgegenwärtig, und eine Vielzahl von Anwendungen von operierenden Prinzipien wurden vorgeschlagen und umgesetzt. Nachfolgend einige Beispiele. Addiction und Abhängigkeit Positive und negative Verstärkung spielen zentrale Rolle bei der Entwicklung und Aufrechterhaltung der Abhängigkeit von Sucht und Drogen. Eine süchtig machende Droge ist intrinsisch belohnt, d.h. sie fungiert als primäre positive Verstärkung des Drogenkonsums. Das Belohnungssystem des Gehirns ordnet ihm Anreiz Salience (d.h. es wird gewünscht oder gewünscht), so dass sich eine Sucht entwickelt, Entbehrung des Medikaments führt zum Verlangen. Darüber hinaus werden Reize im Zusammenhang mit dem Drogenkonsum – z.B. dem Anblick einer Spritze und dem Einsatzort – mit der durch das Medikament induzierten intensiven Verstärkung verbunden. Diese zuvor neutralen Reize erwerben mehrere Eigenschaften: ihr Aussehen kann das Verlangen hervorrufen, und sie können konditionierte positive Verstärkungen der Weiterverwendung werden. Wenn also ein süchtiger Individuum einem dieser Drogenschüren begegnet, kann ein Verlangen nach dem damit verbundenen Medikament wieder auftreten. Zum Beispiel benutzten Anti-Drug-Agenturen zuvor Plakate mit Bildern von Drogenparaphernalien als Versuch, die Gefahren des Drogenkonsums zu zeigen. Solche Poster werden jedoch nicht mehr wegen der Auswirkungen von Anreizgelassenheit verwendet, wenn sie einen Rückfall auf die in den Postern dargestellten Reize verursachen. Bei drogenabhängigen Individuen tritt eine negative Verstärkung auf, wenn ein Medikament selbstverwaltet wird, um die Symptome der körperlichen Abhängigkeit (z.B. Tremors und Schwitzen) und/oder psychologischer Abhängigkeit (z.B. Anhedonia, Unruhe, Reizbarkeit und Angst) zu lindern oder zu entkommen, die während des Drogenentzugs auftreten. Tierschulungen Tierzüchter und Tierbesitzer wendeten die Prinzipien und Praktiken der operierenden Konditionierung schon lange an, bevor diese Ideen benannt und untersucht wurden, und Tierschulungen bieten immer noch eines der klarsten und überzeugendsten Beispiele für die operierende Kontrolle. Von den in diesem Artikel beschriebenen Konzepten und Verfahren sind einige der am meisten entfremdend: (a) Verfügbarkeit von Primärverstärkung (z.B. eine Tasche von Hund-Yummies); (b) die Verwendung von Sekundärverstärkung, (z.B. das Abklingen eines Klickers unmittelbar nach einer gewünschten Reaktion, dann geben Sie yummy); (c) Kontingenz, indem Sie sicherstellen, dass die Verstärkung (z.B. der Klick-Hund) dem gewünschten Verhalten folgt und nicht mehr Beispiel für Tierschulungen von Seaworld im Zusammenhang mit der betrieblichen Konditionierung Tierschulung hat Auswirkungen auf positive Verstärkung und negative Verstärkung. Die Versteifungspläne können eine große Rolle bei der Tierschulung spielen. Angewandte Verhaltensanalyse Angewandte Verhaltensanalyse ist die von B. F. Skinner initiierte Disziplin, die die Prinzipien der Konditionierung auf die Modifizierung von sozial signifikantem menschlichem Verhalten anwendet. Es verwendet die Grundkonzepte der Konditionierungstheorie, einschließlich bedingter Reiz (SC,) diskriminativer Reiz (Sd,) Reaktion (R,) und verstärkender Reiz (Srein oder Sr für Versteifer, manchmal Sparen für aversive Reize). Ein bedingter Reiz steuert Verhaltensweisen, die durch eine (klassische) Konditionierung, wie emotionale Reaktionen, entwickelt wurden. Die anderen drei Begriffe verbinden sich zu Skinners "drei-term contingency": ein diskriminativer Reiz setzt den Anlass für Reaktionen, die zu Verstärkung führen. Forscher haben das folgende Protokoll gefunden, um effektiv zu sein, wenn sie die Werkzeuge der opernierenden Konditionierung verwenden, um das menschliche Verhalten zu verändern: Staatsziel Klären Sie genau, welche Veränderungen zu bewirken sind. Zum Beispiel "reduzieren Gewicht um 30 Pfund. " Monitorverhalten Behalten Sie das Verhalten, so dass man sehen kann, ob die gewünschten Effekte auftreten. Zum Beispiel, halten Sie ein Diagramm der täglichen Gewichte. Verstärkung gewünschtes Verhalten Zum Beispiel gratulieren Sie dem Einzelnen zu Gewichtsverlust. Bei Menschen kann ein Verhaltensrekord als Verstärkung dienen. Wenn beispielsweise ein Teilnehmer ein Muster von Gewichtsverlust sieht, kann dies die Kontinuität in einem verhaltenen Gewichtsverlust Programm verstärken. Individuen können jedoch Verstärkung wahrnehmen, die als negativ und umgekehrt positiv gedacht ist. Zum Beispiel kann eine Aufzeichnung des Gewichtsverlusts als negative Verstärkung wirken, wenn es den einzelnen erinnert, wie schwer sie tatsächlich sind. Die Tokenwirtschaft ist ein Austauschsystem, in dem Token als Belohnungen für gewünschte Verhaltensweisen gegeben werden. Token können später für einen gewünschten Preis oder Belohnungen wie Macht, Prestige, Waren oder Dienstleistungen ausgetauscht werden. Reduzieren Sie Anreize, unerwünschtes Verhalten durchzuführen Zum Beispiel, entfernen Sie Süßigkeiten und fette Snacks aus Küchenregalen. Die Praktizierenden der angewandten Verhaltensanalyse (ABA) bringen diese Verfahren und viele Variationen und Entwicklungen auf eine Vielzahl von sozial bedeutsamen Verhaltensweisen und Problemen. In vielen Fällen nutzen Praktizierende operierende Techniken, um konstruktive, sozial akzeptable Verhaltensweisen zu entwickeln, um abscheuliche Verhaltensweisen zu ersetzen. Die Techniken der ABA wurden effektiv auf solche Dinge angewendet, wie frühe intensive Verhaltenseingriffe für Kinder mit einer Autismusspektrumstörung (ASD) Forschung über die Prinzipien beeinflussen kriminelles Verhalten, HIV-Prävention, Erhaltung von natürlichen Ressourcen, Bildung, Gerontologie, Gesundheit und Bewegung, industrielle Sicherheit, Spracherwerb, Littering, medizinische Verfahren, Erziehung, Psychotherapie, Sitzgelegenheit, schwere psychische Störungen, Sport, Substanzmissbrauch, Phobias, Kinderpflege, Kinderkrankungen, Kinderkrankungen, Kinderkrankungen, Kinderkrankheiten, Kinderkrankheiten, Kinderkrankheiten, Kinderkrankheit, Kinderkrankheit, Kinderkrankheit, Kinderkrankheit, Kinderkrankheit, Kinderkrankheit Einige dieser Anwendungen gehören zu den nachstehend beschriebenen. Child-Verhalten – Eltern-Management-Training Die Bereitstellung einer positiven Verstärkung für entsprechende Kinder-Verhalten ist ein Schwerpunkt der Eltern-Management-Training. Typischerweise lernen Eltern, durch soziale Belohnungen (wie Lob, Lächeln und Umarmungen) ein angemessenes Verhalten zu belohnen sowie konkrete Belohnungen (wie Aufkleber oder Punkte auf eine größere Belohnung als Teil eines Anreizsystems, das gemeinsam mit dem Kind geschaffen wurde). Darüber hinaus lernen Eltern, einfache Verhaltensweisen als Anfangsfokus auszuwählen und jede der kleinen Schritte zu belohnen, die ihr Kind zu einem größeren Ziel erreicht (dieses Konzept wird als "erfolgreiche Annäherungen" bezeichnet). Wirtschaft Sowohl Psychologen als auch Ökonomen haben sich daran interessiert, operierende Konzepte und Erkenntnisse auf das Verhalten der Menschen auf dem Markt anzuwenden. Ein Beispiel ist die Analyse der Verbrauchernachfrage, wie durch die Menge einer Ware, die gekauft wird, indexiert. In der Wirtschaft wird der Grad, in dem der Preis den Verbrauch beeinflusst, als "die Preiselastizität der Nachfrage bezeichnet. "Eigene Waren sind elastischer als andere; zum Beispiel kann eine Preisänderung bestimmter Lebensmittel eine große Auswirkung auf die gekaufte Menge haben, während Benzin und andere alltägliche Verbrauchsmaterialien von Preisänderungen weniger betroffen sein können. Im Hinblick auf die betriebseigene Analyse können diese Auswirkungen auf die Motivation der Verbraucher und den relativen Wert der Waren als Verstärkungsmittel interpretiert werden. Gambling – variables Verhältnis Schieduling Wie bereits in diesem Artikel angegeben, ergibt ein variabler Verhältnisplan eine Verstärkung nach der Emission einer unvorhersehbaren Anzahl von Antworten. Dieser Zeitplan erzeugt typischerweise eine schnelle, anhaltende Reaktion. Spielautomaten zahlen auf einem variablen Verhältnis Zeitplan ab, und sie produzieren nur diese Art von persistenten Hebel-Pulling-Verhalten in Spielern. Das variable Verhältnis Auszahlung von Spielautomaten und anderen Glücksspielformen wurde oft als Faktor zugrunde Glücksspielsucht genannt. Militärpsychologie Menschen haben einen angeborenen Widerstand gegen das Töten und sind zögerlich, in einer direkten, aggressiven Weise gegen Mitglieder ihrer eigenen Spezies zu handeln, sogar um das Leben zu retten. Dieser Widerstand gegen das Töten hat dazu geführt, dass die Infanterie während der gesamten Geschichte der militärischen Kriegsführung bemerkenswert ineffizient ist. Dieses Phänomen wurde nicht verstanden, bis S.L.A Marshall (Brigadier General und Militärhistoriker) Interview Studien der WWII Infanterie unmittelbar nach dem Kampfverlobung. Marshalls bekanntes und kontroverses Buch, Men Against Fire, zeigte, dass nur 15% der Soldaten ihre Gewehre mit dem Zweck des Mordes im Kampf gefeuert haben. Nach der Annahme von Marshalls Forschung durch die US-Armee im Jahr 1946 begann das Human Resources Research Office der US-Armee, neue Trainingsprotokolle zu implementieren, die opernerhaltenden Methoden ähneln. Anschließende Anwendungen solcher Methoden erhöhten den Anteil der Soldaten, die in Korea auf rund 50 % und in Vietnam über 90 % töten konnten. Revolutionen in der Ausbildung waren die Ersetzung traditioneller Pop-up-Feuerstrecken durch dreidimensionale, man-förmige, Pop-up-Ziele, die beim Treffer zusammenbrachen. Dies lieferte sofortiges Feedback und wirkte als positive Verstärkung für das Verhalten eines Soldaten. Weitere Verbesserungen der militärischen Trainingsmethoden haben den zeitlichen Brennkurs; realistischere Ausbildung; hohe Wiederholungen; Lob von Vorgesetzten; Prämien für die Markenführung; und Gruppenerkennung. Negative Bewehrung beinhaltet die Verantwortung für Peer oder die Forderung, Kurse wieder aufzunehmen. Moderne militärische Trainingsbedingungen Mid-brain Reaktion auf den Kampfdruck durch die genaue Simulation des tatsächlichen Kampfes, hauptsächlich Pavlovian klassische Konditionierung und Skinnerian Opernkonditionierung (beide Verhaltensformen). Das moderne Markmanship-Training ist ein so ausgezeichnetes Beispiel für den Verhaltenismus, dass es seit Jahren im einleitenden Psychologie-Kurs verwendet wurde, der allen Kadetten an der US Militärakademie in West Point als klassisches Beispiel der Opernkonditionierung gelehrt wurde. In den 1980er Jahren, während eines Besuchs in West Point, B.F Skinner identifizierte moderne Militärmarkenmanship-Training als eine fast perfekte Anwendung der Opern-Konditionierung. Lt Col. Dave Grossman sagt über die opernierende Konditionierung und US-Militärausbildung, dass: Es ist durchaus möglich, dass niemand absichtlich darauf saß, Opern- oder Verhaltensmodifikationstechniken zu verwenden, um Soldaten in diesem Bereich zu trainieren... Aber vom Standpunkt eines Psychologen, der auch Historiker und Karrieresoldat ist, ist mir immer offensichtlicher geworden, dass genau das erreicht wurde. Nudge-Theorie Nudge-Theorie (oder Nudge) ist ein Konzept in der Verhaltenswissenschaft, politischen Theorie und Ökonomie, die argumentiert, dass indirekte Vorschläge, um zu versuchen, nicht-forced Compliance zu erreichen, die Motive, Anreize und Entscheidungsfindung von Gruppen und Einzelpersonen beeinflussen kann, zumindest so effektiv - wenn nicht effektiver - als direkte Anweisung, Gesetzgebung oder Durchsetzung. Lob Das Lobkonzept als Mittel zur verhaltensverstärkung ist in B.F Skinners Modell der operierenden Konditionierung verwurzelt. Durch diese Linse wurde Lob als Mittel einer positiven Verstärkung angesehen, wobei ein beobachtetes Verhalten wahrscheinlicher gemacht wird, indem man dieses Verhalten konsequent praktiziert. Hunderte von Studien haben die Effektivität des Lobes bei der Förderung positiver Verhaltensweisen bewiesen, vor allem in der Studie des Lehrers und der Elternnutzung des Lobes auf das Kind bei der Förderung eines verbesserten Verhaltens und der akademischen Leistung, aber auch in der Studie der Arbeitsleistung. Präsentiert wurde auch, um positive Verhaltensweisen bei nicht praktizierten Nachbarpersonen (z.B. einem Klassenkameraden des Lobpreisträgers) durch kraftvolle Verstärkung zu verstärken. Präsen kann mehr oder weniger effektiv in wechselndem Verhalten je nach Form, Inhalt und Lieferung sein. Um eine positive Verhaltensänderung zu loben, muss sie auf das positive Verhalten (d.h. erst nach dem Wirken des gezielten Verhaltens appliziert), die Besonderheiten des zu verstärkenden Verhaltens angeben und aufrichtig und glaubhaft geliefert werden. Die Anerkennung der Wirkung von Lob als positive Verstärkungsstrategie, zahlreiche verhaltens- und kognitive Verhaltenseingriffe haben die Verwendung von Lob in ihre Protokolle integriert. Die strategische Verwendung von Lob wird als evidenzbasierte Praxis sowohl in der Klassenzimmerverwaltung als auch in der Erziehung von Ausbildungsinterventionen anerkannt, obwohl Lob oft in der Interventionsforschung in eine größere Kategorie positiver Bewehrung aufgenommen wird, die Strategien wie strategische Aufmerksamkeit und Verhaltensbelohnungen umfasst. Es wurden mehrere Studien über die Wirkung der kognitiven Verhaltenstherapie und der opern-behavioralen Therapie auf verschiedene medizinische Bedingungen durchgeführt. Als die Patienten kognitive und verhaltensbezogene Techniken entwickelt haben, die ihre Verhaltensweisen, Einstellungen und Emotionen veränderten; ihre Schmerzschwere verringerte sich. Die Ergebnisse dieser Studien zeigten einen Einfluss von Kognitionen auf die Schmerzwahrnehmung und -auswirkungen, erläuterten die allgemeine Wirksamkeit der Kognitiv-Behavioral-Therapie (CBT) und Operant-Behavioral-Therapie (OBT). Psychologische Manipulation Braiker identifizierte die folgenden Möglichkeiten, wie Manipulatoren ihre Opfer kontrollieren: Positive Verstärkung: beinhaltet Lob, oberflächlicher Charme, oberflächliche Sympathie (krokodile Tränen,) übermäßige Verarmung, Geld, Genehmigung, Geschenke, Aufmerksamkeit, Gesichtsausdrücke wie ein Zwangslachen oder Lächeln, und öffentliche Anerkennung. Negative Verstärkung: kann eine von einer negativen Situation entfernen Intermittierende oder teilweise Verstärkung: Teil- oder intermittierende negative Verstärkung kann ein effektives Klima von Angst und Zweifel schaffen. Teilweise oder intermittierende positive Verstärkung kann das Opfer dazu ermutigen, zu bestehen – zum Beispiel in den meisten Formen des Glücksspiels, der Spieler wird wahrscheinlich gewinnen jetzt und wieder, aber immer noch verlieren Geld insgesamt. Bestrafung: beinhaltet Nagging, Schreien, die stille Behandlung, Einschüchterung, Bedrohungen, schwören, emotionale Erpressung, die Schuldreise, schwulen, weinen und spielen das Opfer.Traumhaftes Ein-Trial-Erlernen: Mit verbalem Missbrauch, explosiver Wut oder einem anderen einschüchternden Verhalten, um Dominanz oder Überlegenheit zu etablieren; sogar ein Vorfall eines solchen Verhaltens kann die Opfer konditionieren oder trainieren, um Stürme zu vermeiden, gegen den Manipulator zu konfrontieren oder zu widersprechen. Die traumatische Verklebung tritt durch laufende Missbrauchszyklen auf, in denen die intermittierende Belohnung und Bestrafung kraftvolle emotionale Bindungen schafft, die wechselsicher sind. Die andere Quelle deutete darauf hin, dass "die notwendigen Bedingungen für die traumatische Verklebung sind, dass eine Person die andere dominieren muss und dass das Ausmaß des Missbrauchs chronisch spikes und dann nachlässt. Die Beziehung ist gekennzeichnet durch Perioden von permissiven, mitfühlenden und sogar liebevollen Verhalten von der dominanten Person, durch intermittierende Episoden von intensivem Missbrauch punktiert. Um die Oberhand zu erhalten, manipuliert der Opfer das Verhalten des Opfers und begrenzt die Optionen des Opfers, um das Machtungleichgewicht zu verewigen. Jede Bedrohung des Gleichgewichts von Dominanz und Unterwerfung kann mit einem eskalierenden Zyklus der Strafe getroffen werden, von sehender Einschüchterung bis zu intensiv gewalttätigen Ausbrüchen. Der Opfer isoliert auch das Opfer aus anderen Quellen der Unterstützung, die die Wahrscheinlichkeit von Erkennung und Intervention reduziert, beeinträchtigt die Fähigkeit des Opfers, gegensätzliche selbst-referente Feedback zu erhalten, und stärkt das Gefühl einer einseitigen Abhängigkeit... Die traumatischen Auswirkungen dieser missbräuchlichen Beziehungen können die Beeinträchtigung der Fähigkeit des Opfers für eine genaue Selbstbeurteilung beinhalten, was zu einem Gefühl der persönlichen Unzulänglichkeit und einem untergeordneten Gefühl der Abhängigkeit von der dominierenden Person führt. Opfer können auch eine Vielzahl von unangenehmen sozialen und rechtlichen Folgen ihrer emotionalen und verhaltensbezogenen Zugehörigkeit mit jemandem begegnen, der aggressive Handlungen durchdrungen hat, auch wenn sie selbst die Empfänger der Aggression waren. '. Videospiele Die meisten Videospiele sind rund um eine Compulsion-Schleife entworfen, um eine Art positiver Verstärkung durch einen variablen Tarifplan hinzuzufügen, um den Spieler spielen zu lassen. Dies kann zur Pathologie der Videospielsucht führen. Im Rahmen eines Trends bei der Monetarisierung von Videospielen in den 2010er Jahren boten einige Spiele Loot-Boxen als Belohnungen oder als Gegenstände, die durch echte Weltfonds purchasierbar sind. Boxes enthält eine zufällige Auswahl an In-Game-Elementen. Die Praxis wurde an die gleichen Methoden gebunden, dass Spielautomaten und andere Glücksspiel-Geräte lohnen, wie es einem variablen Tarif Zeitplan folgt. Während die allgemeine Wahrnehmung, dass Loot-Boxen eine Form des Glücksspiels sind, wird die Praxis nur in einigen Ländern als solche eingestuft. Methoden, um diese Elemente als virtuelle Währung für Online-Glücksspiel oder den Handel für echte Weltgeld zu verwenden, hat jedoch einen Skin-Glücksspiel-Markt geschaffen, der unter rechtlicher Bewertung ist. Workplace Kultur der Angst Ashforth diskutierte potenziell destruktive Seiten der Führung und identifizierte, was er als kleine Tyrannen bezeichnete: Führer, die einen tyrannischen Stil des Managements ausüben, was zu einem Klima der Angst am Arbeitsplatz führt. Eine teilweise oder intermittierende negative Verstärkung kann ein effektives Klima der Angst und des Zweifels schaffen. Wenn die Angestellten das Gefühl bekommen, dass Stiere toleriert werden, kann ein Klima der Angst das Ergebnis sein. Individuelle Unterschiede in der Sensitivität von Belohnung, Bestrafung und Motivation wurden unter den Räumen der Sensitivitätstheorie der Bewehrung untersucht und wurden auch auf die Leistung des Arbeitsplatzes angewendet. Einer der vielen Gründe, die für die dramatischen Kosten im Zusammenhang mit der Gesundheitsversorgung vorgeschlagen werden, ist die Praxis der defensiven Medizin. Prabhu überprüft den Artikel von Cole und diskutiert, wie die Reaktionen von zwei Gruppen von Neurochirurgen klassisches Opernverhalten sind. Eine Gruppe praktiziert in einem Staat mit Einschränkungen der medizinischen Klagen und die andere Gruppe ohne Einschränkungen. Die Gruppe der Neurochirurgen wurde anonym auf ihre Praxismuster abgefragt. Die Ärzte änderten ihre Praxis in Reaktion auf ein negatives Feedback (Gebühren aus Klagen) in der Gruppe, die in einem Staat ohne Einschränkungen für medizinische Klagen praktiziert. Siehe auch Referenzen {78} Alexander B.K (2010) Addiction: The View From Rat Park, from Addiction: The View from Rat Park (2010) Externe Links Operant Conditioning Artikel in Scholarpedia Journal of Applied Behavior Analysis Journal of the Experimental Analysis of Behavior Negative Verstärkung Scienceofbehavior.com