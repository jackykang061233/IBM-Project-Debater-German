Ein intelligenter Wirkstoff (IA) ist alles, was seine Umwelt wahrnimmt, autonom Maßnahmen trifft, um Ziele zu erreichen und seine Leistung mit dem Lernen zu verbessern oder Wissen zu nutzen. Sie können einfach oder komplex sein – ein Thermostat gilt als Beispiel für einen intelligenten Agenten, wie ein Mensch, wie ein System, das der Definition entspricht, wie ein Unternehmen, ein Staat oder ein Biome. Intelligente Agenten werden häufig als abstraktes funktionelles System beschrieben, das einem Computerprogramm ähnelt. Forscher wie Russell & Norvig (2003) halten ein zielgerichtetes Verhalten für das Wesen der Intelligenz; ein normativer Agenten kann mit einem Begriff gekennzeichnet werden, der von Wirtschaft, „rationaler Wirkstoff“ aufgenommen wird. In diesem rationalistischen Paradigma verfügt eine IA über ein internes Modell ihrer Umwelt. Dieses Modell setzt alle Überzeugungen des Agenten über die Welt ein. Der Agenten verfügt auch über eine "objektive Funktion", die alle Ziele der IA enthält. Ein solcher Agenten soll nach Fertigstellung jeden Plan erstellen und ausführen, um den erwarteten Wert der objektiven Funktion zu maximieren. Ein verstärkter Lernmittel kann eine „reward-Funktion“ haben, die es den Programmern ermöglicht, das gewünschte Verhalten der IA zu gestalten, und ein evolutionäres Algorithmus wird durch eine „Fitness-Funktion“ geprägt. Klare Beschreibungen intelligenter Wirkstoffe werden manchmal als abstrakte intelligente Agenten (AIA) bezeichnet, um sie von ihren tatsächlichen weltweiten Umsetzungen als Computersysteme, biologische Systeme oder Organisationen zu unterscheiden. Manche autonome intelligente Agenten sollen in Abwesenheit menschlicher Eingriffe funktionieren. intelligente Agenten werden immer beliebter, es gibt immer mehr rechtliche Risiken. Intelligente Agenten in der künstlichen Intelligenz sind eng mit Agenten in den Wirtschaften verbunden, und die Versionen des intelligenten Agenten Paradigmas werden in kognitiven Wissenschaften, Ethik, der Philosophie von praktischen Gründen sowie in vielen interdisziplinären sozio-kognitiven Modell- und Computersimulationen untersucht. Intelligente Agenten sind auch eng mit Softwareagenten verbunden (ein autonomes Computerprogramm, das im Auftrag der Nutzer Aufgaben wahrnimmt). In der Computerwissenschaft ist ein intelligenter Agenten ein Software-Beauftragter, der z.B. über autonome Programme verfügt, die für die Unterstützung des Betreibers oder den Data-Mining verwendet werden (etwa als Bots bezeichnete Zeiten). Definitionen und Merkmale, die der Nikola Kasabov (1998) entsprechen, sollten IA-Systeme folgende Merkmale aufweisen: neue Problemlösungsregeln incrementally Adapt Online und in Echtzeit können Sie sich in Bezug auf Verhalten, Fehler und Erfolg analysieren. Lernen und Verbesserung durch die Interaktion mit der Umwelt (Gemeinsamung) Lernen schnell von großen Datenmengen Können Speicher- und Rückgewinnungskapazitäten auf Gedächtnisbasis genutzt werden Parameter, um kurz- und langfristiges Gedächtnis, Alter, Vergessenheit usw. zu vertreten. Padgham & Winikoff (2005) ist sich darin einig, dass ein intelligenter Wirkstoff in einem Umfeld liegt und (in einer fristgerechten, aber nicht notwendigerweise Echtzeit) auf Umweltänderungen reagiert. intelligente Agenten müssen jedoch auch proaktiv auf flexible und robuste Weise verfolgen. Fakultativ desiderata beinhaltet, dass der Wirkstoff rational ist und dass der Wirkstoff in der Lage ist, eine Empfindungsanalyse durchzuführen. Manche Definitionen des 20. Jahrhunderts sind ein Erreger als Programm, das einen Benutzer unterstützt oder im Namen eines Nutzers handelt. Der einflussreiche AIMA (2009) definiert einen Agenten als "jedes, was durch Sensoren als Umwelt empfunden werden kann und auf diese Umwelt durch Beatmungen reagieren" und definiert Intelligenz als die Fähigkeit, nach bestimmten Idealnormen für Rationalität erfolgreich zu handeln."Intelligent Agent" wird häufig als vage Marketing verwendet, manchmal auch als "virtuelles persönliches Assistent" bezeichnet. Manche Agenten können eine explizite "goale Funktion" zugewiesen werden;" ein Agenten wird als intelligenter betrachtet, wenn er konsequent Maßnahmen trifft, die seine programmierte Zielfunktion erfolgreich optimieren. Die "goale Funktion" setzt alle Ziele ein, die der Agenten verfolgt, um zu handeln; im Falle rationaler Einwirkungen wird die Funktion auch die akzeptablen Ausstiege zwischen der Erreichung von Konfliktzielen umfassen.(Terminologie variiert; zum Beispiel versuchen einige Erreger, eine "utilitätsfunktion" oder "Verlustfunktion" zu maximieren oder zu minimieren. theoretisches und unkomputierbares AIXI-Design ist ein höchst intelligentes Erreger in diesem Paradigmen; in der realen Welt wird die IA durch finite Zeit und Hardware-Ressourcen eingeschränkt, und die Wissenschaftler konkurrieren um Algorithmen zu produzieren, die bei Benchmark-Tests mit Echtzeit-Hardware schrittweise höhere Ergebnisse erzielen können. Systeme, die nicht traditionell als Agenten gelten, wie z.B. wissensrepräsentierende Systeme, werden manchmal in das Paradigma aufgenommen, indem sie als Agenten definiert werden, die ein Ziel (z.B.) haben, Fragen so genau wie möglich zu beantworten; das Konzept einer Maßnahme wird hier auf den Akt der Beantwortung einer Frage ausgedehnt. Mit einer zusätzlichen Erweiterung können mimicry-gesteuerte Systeme als Agenten konzipiert werden, die eine "goale Funktion" optimieren, die darauf beruht, wie eng die IA gelingt, das gewünschte Verhalten zu diktieren. In den physikalisch-präversarialen Netzen der 2010er Jahre versucht ein Klärstoff"/„Erzeugungselement Versuche, die Zusammensetzung des menschlichen Texts zu verwechseln und zu.. Der Generator versucht, eine Funktion zu maximieren, die zeigt, wie gut es einen antagonistischen Berechenter katastrophalisieren kann"/„Diskriminator-Komponente. GOFAI-Systeme akzeptieren zwar oft eine explizite Zielfunktion, doch kann das Paradigma auch auf neurale Netze und auf das evolutionäre Rechen angewendet werden. Verstärktes Lernen kann intelligente Agenten erzeugen, die sich auf die Maximierung einer „reward“-Funktion beziehen. Manchmal wird nicht die Vergütungsfunktion direkt an die gewünschte Benchmark-Bewertungsfunktion angepasst, sondern die Entwickler von Wettbewerbsvorteilen nutzen, um zunächst die maschinellen Belohnungen für inkrementelle Fortschritte im Lernen zu verleihen. Yann LeCun erklärte im Jahr 2018, dass "dass die Lernalgorithmen, die Menschen im Wesentlichen aus einer Minimierung bestimmter objektiver Funktionen kommen." AlphaZero Schach hatte eine einfache objektive Funktion; jeder gewinnt als +1 Punkt an und jeder Verlust als -1 Punkt. Eine objektive Funktion für ein selbstfahrendes Auto wäre komplizierter. Entwicklung intelligenter Wirkstoffe, die sich auf die Maximierung einer „Eigenschaftsfunktion“ beziehen, die die Art und Weise beeinflusst, wie viele Nachkommen jeder Agenten verlassen darf. Struktur der Agenten Ein einfaches Erregerprogramm kann mathematisch als Funktion f(wie die "Produktfunktion") definiert werden, die jede mögliche Folge einer möglichen Maßnahme, die der Wirkstoff ausüben kann oder zu einem Koeffizienten, Feedback-Element, Funktion oder ständigem Einfluss auf mögliche Maßnahmen: f: P ∗ → A KINGstyle f:P:ast \}rightmark A} Agentenfunktion ist ein abstraktes Konzept, da es verschiedene Grundsätze der Entscheidungsfindung wie die Berechnung des Gebrauchs einzelner Optionen, Abzug über Logikregeln, fuzzy Logik usw. enthalten könnte. Der Programmregisseur stellt stattdessen jede mögliche Kritik an einer Aktion dar. Wir verwenden den Begriff, auf jeden Fall unmittelbar auf die Wahrnehmungsleistungen des Agenten zu verweisen. In den folgenden Zahlen ist ein Agenten alles, was durch Sensoren und durch Auslöser als Beförderer für die Umwelt angesehen werden kann. Architekturen Weiss (2013) legt vier Kategorien von Agenten fest: plastische Agenten – in denen die Entscheidung darüber, welche Maßnahmen durchzuführen sind, über logischen Abzug erfolgt; Reaktive Agenten – in der Entscheidungsfindung in einer Form der direkten Kartierung von der Situation bis zum Handeln umgesetzt wird; Belief-desire-intention –, in der die Entscheidungsfindung von der Manipulation von Datenstrukturen abhängt, die die Überzeugungen, Wünsche und Absichten des Wirkstoffs repräsentieren; und schließlich, schichtierte Architekturen – in denen die Entscheidungsfindung über verschiedene Softwareschichten erfolgt, die mehr oder weniger explizit auf verschiedenen Ebenen liegt. In der Regel kann ein Erreger durch die Trennung des Körpers in die Sensoren und Beatmungsgeräte gebaut werden, so dass er mit einem komplexen Wahrnehmungssystem arbeitet, das die Beschreibung der Welt als Input für einen für die Verarbeitung Verantwortlichen und Outputs zuständigen Befehlsträger annimmt. Jedoch ist eine Hierarchie der für die Verarbeitung Verantwortlichen oft notwendig, um die unmittelbare Reaktion, die für Aufgaben auf niedrigem Niveau und den langsamen Grund für komplexe, hochrangig ausgerichtete Ziele erforderlich ist, auszugleichen. Klasses Russell & Norvig (2003) Gruppenagenten in fünf Klassen, die auf ihrem Niveau wahrgenommener Erkenntnisse und Fähigkeiten basieren: einfache Reflexagenten modellbasierte Reflexagenten brauchsbasierte Erreger einfache Reflexe Einfache Reflexe wirken nur auf der Grundlage der aktuellen Percept, die den Rest der Percept-Geschichte ignoriert. Die Funktion des Agenten beruht auf der Bedingungsregel: "wenn Bedingung, dann handeln". Diese Funktion ist nur dann erfolgreich, wenn die Umwelt in vollem Umfang geschützt ist. Manche Reflexe können auch Informationen über ihren derzeitigen Staat enthalten, die es ihnen ermöglichen, Bedingungen zu missachten, deren Auslöser bereits ausgelöst werden. Nanoanschlüsse sind häufig unumgänglich für einfache Reflex-Betreiber, die in teilweise konservierbaren Umgebungen tätig sind. Hinweis: Wenn der Agenten seine Maßnahmen randomisieren kann, kann es möglich sein, aus unbegrenzten Schleifen zu entkommen. modellbasierte Reflexe Ein modellbasierter Wirkstoff kann teilweise übertragbare Umgebungen bewältigen. Ihr derzeitiger Staat wird im Agenten gelagert, der eine Art von Struktur bewahrt, die den Teil der Welt beschreibt, der nicht zu sehen ist. Dieses Wissen über "wie die Welt funktioniert" ist ein Modell der Welt und damit der Name "modellbasierter Agenten". Ein modellbasierter Reflex sollte eine Art internes Modell beibehalten, das von der Percept-Geschichte abhängt und dadurch mindestens einige der unobservierten Aspekte des aktuellen Staates widerspiegelt. Percept Geschichte und Auswirkungen von Maßnahmen auf die Umwelt können mithilfe des internen Modells bestimmt werden. Sie wählt dann eine Maßnahme in gleicher Weise wie Reflexe aus. Ein Agenten kann auch Modelle verwenden, um das Verhalten anderer Agenten in der Umwelt zu beschreiben und vorherzusagen. Zielbasierte Agenten Zielbasierte Agenten erweitern die Fähigkeiten der modellbasierten Agenten, indem sie objektive Informationen verwenden. Zielinformationen beschreiben Situationen, die wünschenswert sind. Dies bietet den Agenten eine Möglichkeit, sich unter mehreren Möglichkeiten zu entscheiden, wobei die Auswahl der zu einem Zielstaat gelangt. Suche und Planung sind die Unterfelder künstlicher Intelligenz, die darauf abzielen, Aktionssequenzen zu finden, die die Ziele des Agenten erreichen. Gebrauchsbasierte Erreger werden nur zwischen Zielstaaten und nicht-goalen Staaten unterschieden. Man kann auch eine Maßnahme festlegen, wie wünschenswert ein bestimmter Staat ist. Diese Maßnahme kann durch die Nutzung einer Versorgungsfunktion erreicht werden, die einen Staat auf eine Maßnahme des staatlichen Nutzens stellt. Eine allgemeinere Leistungsmaßnahme sollte einen Vergleich zwischen verschiedenen Weltstaaten ermöglichen, so dass sie die Ziele des Agenten erfüllen. Der Begriff kann verwendet werden, um zu beschreiben, wie glücklich der Agenten ist. Ein rationeller, auf Versorgungsbasis beruhender Wirkstoff wählt die Maßnahme aus, die den erwarteten Nutzen der Aktionsergebnisse maximiert – das ist, was der Agenten erwartet, im Durchschnitt aufgrund der Probabilities und Versorgungsleistungen jedes Ergebnisses abzulösen. Ein brauchbarer Wirkstoff muss seine Umwelt modellieren und verfolgen, Aufgaben, die einen großen Teil der Forschung über Wahrnehmung, Vertretung, Grundbildung und Lernen betreffen. Lernende haben den Vorteil, dass es den Agenten ermöglicht, zunächst in unbekannten Umgebungen zu arbeiten und besser als ihre ursprünglichen Kenntnisse allein zu werden. Die wichtigste Unterscheidung ist zwischen dem „Lernelement“, das für Verbesserungen verantwortlich ist, und dem „Leistungselement“, das für die Auswahl externer Maßnahmen zuständig ist. Das Lernelement verwendet Feedback von den Kritikern, wie der Wirkstoff funktioniert und bestimmt, wie das Leistungselement oder der Schauspieler künftig besser angepasst werden sollten. Das Leistungselement ist das, was wir bisher als Gesamtmittel betrachtet haben: es nimmt in Perzepten und entscheidet über Maßnahmen. Die letzte Komponente des Lernmittels ist der "Problemerzeuger". Es ist verantwortlich für Maßnahmen, die zu neuen und informativen Erfahrungen führen. Al Byrd beschreibt in seinem Buch die konzeptuelle Architektur für einen künstlichen Agenten, der als wissenschaftliche Entitäten (ACE) bezeichnet wird. Eine ACE ist ein zielorientiertes AI-System, das über ein autobiographisches Gedächtnis seiner Vergangenheit und Gegenwart verfügt, und ihre Pläne für die Zukunft, die es ermöglichen, sein Verhalten in einer sozial akzeptablen Weise sowohl in realen als auch in vorstellbaren Situationen zu unterbinden und zu rechtfertigen. Der Autor argumentiert, dass ein Unternehmen mit dieser Architektur immer für sein Verhalten verantwortlich sein wird und in gewisser Weise handeln wird. Hemmnisse von Agenten Künftig werden Smart Agents heute in einer hierarchischen Struktur zusammengefasst, die viele „Subagen“ enthält. Intelligente Subagenzien verarbeiten und schneiden niedrigere Funktionen ab. Mit vereinten Kräften und Subagenzien schaffen ein komplettes System, das schwierige Aufgaben oder Ziele mit Verhaltens- und Reaktionspraktiken erfüllen kann, die eine Form von Intelligenz aufweisen. Anwendungen Intelligente Agenten werden als automatisierte Online-Assistenten eingesetzt, wo sie die Bedürfnisse der Kunden wahrnehmen, um individuelle Kundendienstleistungen zu erbringen. Ein solcher Agenten kann im Wesentlichen aus einem Dialogsystem, einem Avatar und einem Sachverständigensystem bestehen, um dem Benutzer spezifisches Fachwissen zu vermitteln. Sie können auch genutzt werden, um die Koordinierung der menschlichen Gruppen online zu optimieren. Hallerbach et al. erörterten die Anwendung von agentenbasierten Konzepten für die Entwicklung und Validierung von automatischen Fahrsystemen über ein digitales Paar der Fahrzeugunter-Test- und mikroskopischen Verkehrssimulation auf der Grundlage unabhängiger Agenten. Waymo hat ein Multi-Produktsimulationsumgebung Carcraft geschaffen, um Algorithmen für Selbstdrehwagen zu testen. Es simuliert Verkehrsinteraktionen zwischen menschlichen Fahrern, Fußgängern und automatischen Fahrzeugen. Das Verhalten der Menschen wird durch künstliche Erreger auf der Grundlage von Daten des tatsächlichen menschlichen Verhaltens beeinträchtigt. Anfang 2003 wurde die Grundidee der Verwendung von rezeptpflichtigen Modellen erörtert, um selbstfahrende Autos zu verstehen. Siehe auch Software-Werkzeuge Kognitive Architektur – ein praktischer Bereich für die Umsetzung von Cybernetics, Computer Science Data Mining Em eingebettete Suche – die Fähigkeit von Agenten zur Suche heterogener Datenquellen mithilfe eines einheitlichen bulanten Flämischen Radios – IA umgesetzt mit adaptiver fuzzy Logik GOAL Agent Programmierung Sprache Intelligentes System JACK Smart Agents Multi-agen-System und Multi-agenzien-System – Multiple interaktive PEAS-Klassifikation eines Umweltreinforcement-Web – Bereitstellung von Daten für die automatisierte Verarbeitung durch Sima-Indikatoren von Social-Indikatoren Andere Bezugnahmen Russell, Stuart J. Norvig, Peter (2003). Künstliche Nachrichten: Ein modernes Konzept (2. ed). Oberstes Fluss, New Jersey: Prentice Hall.Chapter 2.ISBN 0-13-790395-2.Franklin, Stan; Graesser, Art (1996). " Ist es ein Agenten oder nur ein Programm?: Eine Taxonomy für autonome Agenten" (PDF). Demonstrationen des Dritten Internationalen Workshops über Arbeitsstoffe, Architekturen und Sprachen. Springer-Verlag. Archiviert vom Original (PDF) am 29. Mai 2015. Kasabov, N. (1998)." Einführung: Hybride intelligente Anpassungssysteme". International Journal of Intelligent Systems.13 (6): 453–454.doi:10.1002/(SICI)1098-111X(199806)13:6<3: AID-INT1>3.0.CO;2-K Weiss, G. (2013) Multiagenziensysteme (2. Cambridge, MA: MIT Presse. ISBN: [0-262-01889-0. Außenbeziehungen