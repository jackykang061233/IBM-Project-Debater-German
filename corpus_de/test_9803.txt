Künstliches Bewusstsein (AC,) auch als Maschinenbewusstsein (MC) oder synthetisches Bewusstsein (Gamez 2008; Reggia 2013) bekannt, ist ein Feld, das mit künstlicher Intelligenz und kognitiver Robotik zusammenhängt. Ziel der Theorie des künstlichen Bewusstseins ist es, "diejenigen zu definieren, die synthetisiert werden müssten, war das Bewusstsein in einem konstruierten Artefakt zu finden" (Aleksander 1995). Neurowissenschaften heuchelt, dass das Bewusstsein durch die Interaktion verschiedener Gehirnteile erzeugt wird, die neurale Korrelate des Bewusstseins oder NCC genannt werden, obwohl es Herausforderungen für diese Perspektive gibt. Komponenten von AC glauben, dass es möglich ist, Systeme (z.B. Computersysteme) zu konstruieren, die diese NCC-Interoperation nachempfunden können. Künstliche Bewusstseinskonzepte werden auch in der Philosophie der künstlichen Intelligenz durch Fragen über Geist, Bewusstsein und geistige Zustände nachgedacht. philosophische Ansichten Da es viele hypothetische Arten des Bewusstseins gibt, gibt es viele mögliche Implementierungen des künstlichen Bewusstseins. In der philosophischen Literatur ist vielleicht die häufigste Taxonomie des Bewusstseins in Zugang und phänomenale Varianten. Das Zugangsbewußtsein betrifft die Aspekte der Erfahrung, die begriffen werden können, während das phänomenale Bewusstsein jene Aspekte der Erfahrung betrifft, die scheinbar nicht begriffen werden können, sondern qualitativ in Bezug auf „Rohgefühle“, „was es ist wie“ oder Qualia (Block 1997). Plausibilitätsdebatte Typ-Identitätstheoretiker und andere Skeptiker halten die Ansicht, dass Bewusstsein nur in bestimmten physischen Systemen realisiert werden kann, weil Bewusstsein Eigenschaften hat, die notwendigerweise von der physischen Verfassung abhängig sind (Block 1978; Bickle 2003). In seinem Artikel "Künstliche Bewusstheit: Utopie oder Real Possibility" sagt Giorgio Buttazzo, dass ein gemeinsamer Einwand gegen künstliches Bewusstsein darin besteht, dass "Arbeiten in einem vollautomatisierten Modus, sie [die Computer] keine Kreativität, Unreprogrammierung (was bedeutet, nicht mehr neu programmiert werden kann, aus Umdenken,) Emotionen oder freien Willen. Ein Computer ist wie eine Waschmaschine ein Slave, der von seinen Komponenten betrieben wird. " Für andere Theoretiker (z.B. Funktionalitäten), die mentale Zustände in Bezug auf Kausalrollen definieren, wird jedes System, das das gleiche Muster von Kausalrollen, unabhängig von der physischen Konstitution, sofort die gleichen mentalen Zustände, einschließlich Bewusstsein (Putnam 1967.) Argument der Computational Foundation Eines der explizitsten Argumente für die Plausibilität von AC kommt von David Chalmers. Sein Vorschlag, der in seinem Artikel Chalmers 2011 gefunden wurde, ist etwa, dass die richtigen Berechnungen für den Besitz eines bewussten Geistes ausreichen. Im Umriss verteidigt er seine Behauptung also: Computer führen Berechnungen durch. Computations können die abstrakte Kausalorganisation anderer Systeme erfassen. Der umstrittenste Teil von Chalmers' Vorschlag ist, dass geistige Eigenschaften "organisatorisch invariant" sind. Mentale Eigenschaften sind von zwei Arten, psychologische und phenomenologische. Psychologische Eigenschaften, wie Glaube und Wahrnehmung, sind solche, die durch ihre ursächliche Rolle "charakterisiert sind". Er begibt sich auf die Arbeit von Armstrong 1968 und Lewis 1972, indem er behauptet, dass ["s]ystems mit der gleichen Kausaltopologie... ihre psychologischen Eigenschaften teilen wird". Die phänomenologischen Eigenschaften sind in Bezug auf ihre ursächlichen Rollen nicht primär facie definierbar. Die Feststellung, dass phänomenologische Eigenschaften geeignet sind, durch kausale Rolle zu unterscheiden, erfordert daher Argument. Chalmers bietet dazu sein Dancing Qualia Argument. Chalmers beginnt mit der Annahme, dass Agenten mit identischen Kausalorganisationen verschiedene Erfahrungen haben könnten. Er bittet uns dann, einen Agenten durch den Austausch von Teilen (neurale Teile, die durch Silizium ersetzt werden, zu konzipieren, indem er seine ursächliche Organisation bewahrt. Ex hypothesi, die Erfahrung des Agenten unter Transformation würde sich ändern (wie die Teile ersetzt wurden), aber es gäbe keine Änderung der Kausaltopologie und daher keine Mittel, wodurch der Agent die Verschiebung der Erfahrung bemerken konnte. Kritik an AC-Objekt, dass Chalmers die Frage in der Annahme, dass alle geistigen Eigenschaften und externe Verbindungen ausreichend von abstrakter Kausalorganisation erfasst werden. Ethik Wenn man vermutet, dass eine bestimmte Maschine bewusst war, wären ihre Rechte ein ethisches Problem, das beurteilt werden müsste (z.B. welche Rechte sie nach dem Gesetz haben würde). Beispielsweise ist ein bewusster Computer, der als Werkzeug oder Zentralrechner eines Gebäudes größerer Maschine gehört und verwendet wurde, eine besondere Mehrdeutigkeit. Sollten Gesetze für einen solchen Fall gemacht werden? Das Bewußtsein würde auch in diesem konkreten Fall eine rechtliche Definition erfordern. Da künstliches Bewusstsein noch weitgehend ein theoretisches Subjekt ist, wurden solche Ethik nicht in großem Maße diskutiert oder entwickelt, obwohl es oft ein Thema in Fiktion war (siehe unten). Der deutsche Philosoph Thomas Metzinger hat 2021 aus ethischen Gründen ein globales Moratorium für synthetische Phänomenologie bis 2050 gefordert. Die Regeln für den Loebner-Preiswettbewerb 2003 richteten sich ausdrücklich auf die Frage der Roboterrechte: 61.Wenn in jedem gegebenen Jahr ein öffentlich zugänglicher Open Source Entry der University of Surrey oder des Cambridge Centers die Silbermedaille oder die Goldmedaille gewinnt, wird die Medaille und der Cash Award an den für die Entwicklung dieser Entry verantwortlichen Körper vergeben. Wenn kein solcher Körper identifiziert werden kann, oder wenn es eine Meinungsverschiedenheit zwischen zwei oder mehreren Antragstellern gibt, werden die Medaille und der Cash Award vertrauenswürdig gehalten, bis der Entry legal besitzen kann, entweder in den Vereinigten Staaten von Amerika oder am Veranstaltungsort des Wettbewerbs, der Cash Award und Gold Medal in seinem eigenen Recht. Forschungs- und Umsetzungsvorschläge Aspekte des Bewusstseins Es gibt verschiedene Aspekte des Bewusstseins, die allgemein als notwendig erachtet werden, um eine Maschine künstlich bewusst zu sein. Eine Vielzahl von Funktionen, in denen das Bewusstsein eine Rolle spielt, wurden von Bernard Baars (Baars 1988) und anderen vorgeschlagen. Die von Bernard Baars vorgeschlagenen Funktionen des Bewusstseins sind Definition und Kontexteinstellung, Anpassung und Lernen, Editing, Flagging und Debugging, Recruiting und Control, Priorisierung und Access-Control, Entscheidungsfindung oder Executive Function, Analogy-forming Function, Metakognitive und Self-Monitoring Function, Autoprogramming und Self-Maintenance Function. Igor Aleksander schlug 12 Prinzipien für künstliches Bewusstsein vor (Aleksander 1995) und dies sind: The Brain ist eine State Machine, Inner Neuron Partitioning, Conscious und Unbewusste Staaten, Wahrnehmung Lernen und Gedächtnis, Prediction, Das Bewusstsein für Selbst, Darstellung von Bedeutung, Lernen Utterancen, Lernsprache, Will, Instinct und Emotion. Ziel von AC ist es, zu definieren, ob und wie diese und andere Aspekte des Bewusstseins in einem entwickelten Artefakt wie einem digitalen Computer synthetisiert werden können. Diese Liste ist nicht vollständig; es gibt viele andere nicht abgedeckt. Awareness Awareness könnte ein notwendiger Aspekt sein, aber es gibt viele Probleme mit der exakten Definition des Bewusstseins. Die Ergebnisse der Experimente des Neuroscannings auf Affen legen nahe, dass ein Prozess, nicht nur ein Zustand oder Objekt, Neuronen aktiviert. Awareness umfasst die Erstellung und Prüfung alternativer Modelle jedes Prozesses auf der Grundlage der durch die Sinne empfangenen oder vorgestellten Informationen und ist auch für die Vorhersagen nützlich. Eine solche Modellierung braucht viel Flexibilität. Ein solches Modell zu schaffen beinhaltet die Modellierung der physischen Welt, die Modellierung der eigenen inneren Zustände und Prozesse und die Modellierung anderer bewusster Wesen. Es gibt mindestens drei Arten von Bewusstsein: Agenturbewusstsein, Zielbewusstsein und sensorimotorische Wahrnehmung, die auch bewusst oder nicht sein kann. Zum Beispiel, in der Agentur-Bewusstsein, können Sie sich bewusst sein, dass Sie eine bestimmte Aktion gestern, aber nicht jetzt bewusst davon. In der Zielwahrnehmung kann man sich bewusst sein, dass man nach einem verlorenen Objekt suchen muss, aber nicht jetzt bewusst davon. In sensorimotorischem Bewusstsein können Sie sich bewusst sein, dass Ihre Hand auf einem Objekt ruht, aber nicht jetzt bewusst davon. Al Byrd, der Autor von übermenschlichen Schöpfern, definiert das Bewusstsein, für Tiere, Menschen und künstliche Agenten, als die Wirkung der Integration und Filterung vieler verschiedener Arten von Bereitstellungsbewusstsein, d.h. das Bewusstsein für die Handlungsmöglichkeiten in einer Umgebung. Nach dieser Definition sind alle Agenten, die die Gelder wahrnehmen und auf sie wirken können, teilweise bewusst. Da die Wahrnehmungsobjekte oft bewusst sind, wird die Unterscheidung zwischen Bewusstsein und Bewusstsein häufig verwundet oder als Synonyme verwendet. Memory Conscious Ereignisse interagieren mit Speichersystemen beim Lernen, proben und retrieval. Das IDA-Modell verdeutlicht die Rolle des Bewusstseins bei der Aktualisierung des Wahrnehmungsgedächtnisses, des transienten episodischen Gedächtnisses und des Verfahrensgedächtnisses. Transiente episodische und declarative Erinnerungen haben verteilte Darstellungen in IDA, es gibt Beweise, dass dies auch im Nervensystem der Fall ist. In der IDA werden diese beiden Speicher rechnerisch mit einer modifizierten Version von KanervasSparse verteilter Speicherarchitektur realisiert. Learning Learning wird auch für AC als notwendig angesehen. Von Bernard Baars wird bewusste Erfahrung benötigt, um neue und bedeutende Ereignisse zu repräsentieren und anzupassen (Baars 1988). Von Axel Cleeremans und Luis Jiménez wird das Lernen als "eine Reihe von philogenetisch [sischen] fortschrittlichen Anpassungsprozessen definiert, die kritisch von einer zunehmenden Sensibilität für subjektive Erfahrungen abhängen, um Agenten eine flexible Kontrolle über ihre Aktionen in komplexen, unvorhersehbaren Umgebungen zu ermöglichen" (Cleeremans 2001.) Vorfreude Für AC von Igor Aleksander gilt die Fähigkeit, vorhersehbare Ereignisse vorherzusagen (oder vorherzusagen). Das von Daniel Dennett in Consciousness Explained vorgeschlagene Grundsatz der Mehrfachentwürfe kann für die Vorhersage nützlich sein: es beinhaltet die Bewertung und Auswahl des am besten geeigneten Entwurfs für die aktuelle Umwelt. Die Vorfreude beinhaltet die Vorhersage der Folgen der eigenen vorgeschlagenen Handlungen und die Vorhersage der Folgen wahrscheinlicher Handlungen anderer Organisationen. Beziehungen zwischen realen Weltstaaten werden in der Zustandsstruktur eines bewussten Organismus gespiegelt, der es dem Organismus ermöglicht, Ereignisse vorherzusagen. Eine künstlich bewusste Maschine sollte in der Lage sein, die Ereignisse richtig zu antizipieren, um bereit zu sein, auf sie zu reagieren, wenn sie auftreten oder preemptive Maßnahmen ergreifen, um erwartete Ereignisse abzuwenden. Die Implikation hier ist, dass die Maschine flexible, Echtzeit-Komponenten benötigt, die räumliche, dynamische, statistische, funktionale und Ursache-Effekt-Modelle der realen Welt aufbauen und vorhergesagte Welten prognostizieren, so dass es in der Gegenwart und Zukunft künstliches Bewusstsein besitzt und nicht nur in der Vergangenheit. Um dies zu tun, sollte eine bewusste Maschine kohärente Vorhersagen und Kontingenzpläne machen, nicht nur in Welten mit festen Regeln wie einem Schachbrett, sondern auch für neue Umgebungen, die sich ändern können, nur dann ausgeführt werden, wenn es angemessen ist, die reale Welt zu simulieren und zu kontrollieren. Subjektive Erfahrungen Subjektive Erfahrungen oder Qualia werden weithin als das harte Problem des Bewusstseins angesehen. In der Tat wird es gehalten, eine Herausforderung für den Physikalismus zu stellen, geschweige denn Rechenschaft. Auf der anderen Seite gibt es Probleme in anderen Bereichen der Wissenschaft, die begrenzen, was wir beobachten können, wie das Unsicherheitsprinzip in der Physik, die die Forschung in diesen Bereichen der Wissenschaft nicht unmöglich gemacht haben. Rolle der kognitiven Architekturen Der Begriff "kognitive Architektur" kann sich auf eine Theorie über die Struktur des menschlichen Geistes oder einen beliebigen Teil oder eine Funktion desselben beziehen, einschließlich Bewusstsein. In einem anderen Kontext implementiert eine kognitive Architektur die Theorie auf Computern. Ein Beispiel ist QuBIC: Quantum und Bio-inspirierte kognitive Architektur für Maschinenbewusstsein. Eines der Hauptziele einer kognitiven Architektur ist die Zusammenfassung der verschiedenen Ergebnisse der kognitiven Psychologie in einem umfassenden Computermodell. Die Ergebnisse müssen jedoch formalisiert sein, so dass sie die Grundlage eines Computerprogramms sein können. Auch ist die Rolle der kognitiven Architektur für die A.I klar zu strukturieren, zu bauen und umzusetzen. Symbolische oder hybride Vorschläge Franklins Intelligent Distribution Agent Stan Franklin (1995, 2003) definiert einen autonomen Agenten als funktionelles Bewusstsein, wenn es in der Lage ist, mehrere der Funktionen des Bewusstseins, die von Bernard Baars' Global Workspace Theory identifiziert wurden (Baars 1988, 1997). Sein Gehirnkind IDA (Intelligent Distribution Agent) ist eine Software-Implementierung von GWT, die es funktional durch Definition bewusst macht. IDA ist die Aufgabe, neue Aufgaben für Segler in der US-Marine zu verhandeln, nachdem sie eine Pflichtreise beendet haben, indem sie die Fähigkeiten und Vorlieben jedes Einzelnen mit den Bedürfnissen der Marine übereinstimmen. IDA interagiert mit Navy-Datenbanken und kommuniziert mit den Matrosen über natürliche Sprache E-Mail-Dialog und gehorcht eine große Menge von Navy-Richtlinien. Das IDA-Rechnungsmodell wurde 1996–2001 an der Stan Franklin's Conscious Software Research Group an der Universität Memphis entwickelt. Es "konsistiert von etwa einer Viertelmillion Zeilen Java-Code und verbraucht fast vollständig die Ressourcen einer 2001 High-End-Workstation." Sie stützt sich stark auf Codelets, die "besonderer Zweck, relativ unabhängig, mini-agent[s] sind, typischerweise als kleines Stück Code ausgeführt, das als separates Gewinde läuft. " In der Top-down-Architektur der IDA werden hochrangige kognitive Funktionen explizit modelliert (siehe Franklin 1995 und Franklin 2003 für Details). Während IDA durch Definition funktionell bewusst ist, schreibt Franklin "keine phänomenale Bewusstheit zu seinem eigenen bewussten Software-Agenten, IDA, trotz ihrer vielen menschlichen Verhaltensweisen. Dies, obwohl mehrere US-Marine-Details immer wieder ihre Köpfe sagen: "Ja, das ist, wie ich es mache", während sie IDAs interne und externe Aktionen beobachtet, wie sie ihre Aufgabe erfüllt." IDA wurde auf LIDA (Learning Intelligent Distribution Agent) erweitert. Ron Suns kognitive Architektur CLARION CLARION präsentiert eine zweistufige Darstellung, die die Unterscheidung zwischen bewussten und unbewussten geistigen Prozessen erklärt. CLARION ist erfolgreich in der Abrechnung einer Vielzahl von psychologischen Daten. Mit CLARION, die das Spektrum von einfachen reaktiven Fähigkeiten bis hin zu komplexen kognitiven Fähigkeiten überspannt, wurden eine Reihe bekannter Lernaufgaben simuliert. Zu den Aufgaben gehören serielle Reaktionszeit (SRT) Aufgaben, künstliches Grammatiklernen (AGL) Aufgaben, Prozesssteuerung (PC) Aufgaben, die kategorische Inferenz (CI) Aufgabe, die alphabetische arithmetische (AA) Aufgabe und der Tower of Hanoi (TOH) Task (Sun 2002). Unter ihnen sind SRT, AGL und PC typische implizite Lernaufgaben, die für die Frage des Bewusstseins sehr relevant sind, da sie den Begriff des Bewusstseins im Kontext psychologischer Experimente in Betrieb genommen haben. Ben Goertzels OpenCog Ben Goertzel verfolgt eine verkörperte AGI durch das Open-Source OpenCog-Projekt. Aktueller Code umfasst verkörperte virtuelle Haustiere, die in der Lage sind, einfache englischsprachige Befehle zu lernen, sowie die Integration mit realen Weltrobotik, die an der Hong Kong Polytechnic University durchgeführt wird. Die kognitive Architektur von Haikonen Pentti Haikonen (2003) hält klassisches regelbasiertes Computing für unzulänglich für AC: "Das Gehirn ist definitiv kein Computer. Denken ist keine Ausführung von programmierten Befehlsketten. Das Gehirn ist auch kein numerischer Rechner. Wir denken nicht nach Zahlen. " Anstatt zu versuchen, Geist und Bewusstsein durch die Identifizierung und Umsetzung ihrer zugrunde liegenden Rechenregeln zu erreichen, schlägt Haikonen "eine spezielle kognitive Architektur vor, um die Prozesse der Wahrnehmung, der inneren Bildsprache, der inneren Sprache, Schmerz, Vergnügen, Emotionen und der kognitiven Funktionen hinter diesen zu reproduzieren. Diese Bottom-up-Architektur würde höhere Funktionen durch die Leistung der elementaren Verarbeitungseinheiten, die künstlichen Neuronen, ohne Algorithmen oder Programme erzeugen". Haikonen glaubt, dass diese Architektur, wenn sie mit ausreichender Komplexität umgesetzt wird, das Bewusstsein entwickeln wird, das er als "ein Stil und eine Arbeitsweise betrachtet, die sich durch verteilte Signaldarstellung, Wahrnehmungsprozess, Cross-Modalitätsberichterstattung und Verfügbarkeit für die Retrospektion auszeichnet." Haikonen ist nicht allein in dieser Prozessansicht des Bewusstseins, oder der Ansicht, dass AC spontan in autonomen Agenten entstehen wird, die eine geeignete neuroinspirierte Architektur der Komplexität besitzen; diese werden von vielen geteilt, z.B. Freeman (1999) und Cotterill (2003). Eine Low-Complexity-Implementierung der von Haikonen (2003) vorgeschlagenen Architektur war bekanntlich nicht in der Lage, AC, sondern zeigte Emotionen wie erwartet. Siehe Doan (2009) für eine umfassende Einführung in die kognitive Architektur von Haikonen. In Haikonen (2012,) Haikonen (2019) ist ein aktualisierter Bericht der Architektur von Haikonen sowie eine Zusammenfassung seiner philosophischen Ansichten. Shanahans kognitive Architektur Murray Shanahan beschreibt eine kognitive Architektur, die Baars Idee eines globalen Arbeitsraums mit einem Mechanismus für interne Simulations-Imagination verbindet" (Shanahan 2006). Für Diskussionen über Shanahans Architektur siehe (Gamez 2008) und (Reggia 2013) und Kapitel 20 von (Haikonen 2012.) Takenos Selbstbewusstseinsforschung Selbstbewusstsein in Robotern wird von Junichi Takeno an der Meiji University in Japan untersucht. Takeno behauptet, dass er einen Roboter entwickelt hat, der in der Lage ist, zwischen einem Selbstbild in einem Spiegel und einem anderen mit einem identischen Bild zu unterscheiden, und dieser Anspruch wurde bereits überprüft (Takeno, Inaba & Suzuki 2005). Takeno behauptet, dass er zunächst das Rechenmodul namens MoNAD kontrizierte, das eine selbstbewusste Funktion hat, und er konstruierte dann das künstliche Bewusstseinssystem, indem er die Beziehungen zwischen Emotionen, Gefühlen und Vernunft formulierte, indem er die Module in einer Hierarchie verbindet (Igarashi, Takeno 2007). Takeno beendete ein Spiegelbilderkennungsexperiment mit einem Roboter, der mit dem MoNAD-System ausgestattet ist. Takeno hat die Selbstorganisation vorgeschlagen Theorie besagt, dass "die Menschen fühlen, dass ihr eigenes Spiegelbild näher an sich ist als ein tatsächlicher Teil von sich selbst. " Der wichtigste Punkt bei der Entwicklung des künstlichen Bewusstseins oder der Aufklärung des menschlichen Bewusstseins ist die Entwicklung einer Funktion des Selbstbewusstseins, und er behauptet, dass er in seiner These physische und mathematische Beweise dafür gezeigt hat. Er zeigte auch, dass Roboter Episoden in Erinnerung studieren können, wo die Emotionen stimuliert wurden und diese Erfahrung verwenden, um Vorhersageaktionen zu ergreifen, um die Wiederauftreten unangenehmer Emotionen zu verhindern (Torigoe, Takeno 2009.) Aleksanders unmöglicher Geist Igor Aleksander, emeritierter Professor für Neural Systems Engineering am Imperial College, hat in seinem Buch impossible Minds umfassend künstliche neuronale Netzwerke und Ansprüche erforscht: Meine Neuronen, Mein Bewusstsein, dass die Prinzipien für die Schaffung einer bewussten Maschine bereits existieren, aber dass es vierzig Jahre dauern würde, eine solche Maschine zu trainieren, um Sprache zu verstehen. Ob dies wahr ist, bleibt zu demonstrieren, und das Grundprinzip, das in Impossible Minds genannt wird – das Gehirn ist eine neuronale Zustandsmaschine – ist offen für Zweifel. Thalers Kreativitätsmaschine Paradigm Stephen Thaler schlug eine mögliche Verbindung zwischen Bewusstsein und Kreativität in seinem 1994 Patent, genannt "Gerät für die autonome Generation der nützlichen Informationen" (DAGUI), oder die sogenannte "Kreativitätsmaschine", in der Rechenkritiker die Injektion von synaptischen Rauschen und Degradation in neuronale Netze regieren, um falsche Erinnerungen oder Konfiabulationen zu verursachen, die als mögliche Ideen oder Strategien qualifizieren können. Er rekrutiert diese neurale Architektur und Methodologie, um dem subjektiven Bewusstseinsgefühl Rechnung zu tragen, indem er behauptet, dass ähnliche geräuschgetriebene neurale Baugruppen innerhalb des Gehirns zweifelhafte Bedeutung für die gesamte kortikale Aktivität erfinden. Thalers Theorie und die daraus resultierenden Patente im Maschinenbewußtsein wurden von Experimenten inspiriert, in denen er intern geschulte neuronale Netze durchbrachte, um eine Folge von neuronalen Aktivierungsmustern zu treiben, die er dem Bewusstseinsstrom mochte.Michael Grazianos Aufmerksamkeitsschema Im Jahr 2011 veröffentlichten Michael Graziano und Sabine Kastler ein Papier mit dem Namen "Menschenbewusstsein und seine Beziehung zur sozialen Neurowissenschaft: Eine neuartige Hypothese", die eine Bewusstseinstheorie als Aufmerksamkeitsschema vorschlägt. Graziano veröffentlichte in seinem Buch "Consciousness and the Social Brain" eine erweiterte Diskussion über diese Theorie. Diese Attention Schema Theory of Consciousness, wie er es nannte, schlägt vor, dass das Gehirn die Aufmerksamkeit auf verschiedene sensorische Inputs über ein Aufmerksamkeitsschema, analog zu dem gut untersuchten Körperschema, das den räumlichen Ort eines Körpers verfolgt. Dies bezieht sich auf künstliches Bewusstsein, indem es einen bestimmten Mechanismus des Informationshandling vorschlägt, der das erzeugt, was wir angeblich als Bewusstsein erfahren und beschreiben, und der durch eine Maschine mit der aktuellen Technologie dupliziert werden sollte. Wenn das Gehirn feststellt, dass die Person X sich der Sache Y bewusst ist, wird in der Tat der Zustand modelliert, in dem die Person X eine Aufmerksamkeitsverbesserung auf Y anwendet.In der Aufmerksamkeitsschema-Theorie kann der gleiche Prozess auf sich selbst angewendet werden. Das Gehirn verfolgt die Aufmerksamkeit auf verschiedene sensorische Inputs, und das eigene Bewusstsein ist ein schematisiertes Modell der eigenen Aufmerksamkeit. Graziano schlägt bestimmte Stellen im Gehirn für diesen Prozess vor und schlägt vor, dass ein solches Bewusstsein eine berechnete Funktion ist, die von einem Expertensystem im Gehirn aufgebaut wird. Selbstmodellierung Hod Lipson definiert Selbstmodellierung als notwendige Komponente von Selbstbewusstsein oder Bewusstsein in Robotern. "Selbstmodellierung besteht aus einem Roboter, der ein internes Modell oder eine Simulation von sich selbst betreibt. Prüfung Das bekannteste Verfahren zum Testen von Maschineninformationen ist der Turing-Test. Aber wenn es nur als Beobachtung interpretiert wird, widerspricht dieser Test der Philosophie der Wissenschaftsprinzipien der theoretischen Abhängigkeit der Beobachtungen. Es wurde auch vorgeschlagen, dass Alan Turings Empfehlung, nicht ein menschliches erwachsenes Bewusstsein nachzuahmen, sondern ein menschliches Kindbewußtsein ernst genommen werden sollte. Andere Tests, wie ConsScale, testen das Vorhandensein von Merkmalen, die von biologischen Systemen inspiriert sind, oder messen die kognitive Entwicklung künstlicher Systeme. Qualia, oder phänomenologisches Bewusstsein, ist ein inhärent erstes Phänomen. Obwohl verschiedene Systeme verschiedene Verhaltensweisen anzeigen können, die mit dem funktionalen Bewusstsein korrelieren, ist es nicht denkbar, dass Drittpersonentests Zugriff auf phänomenologische Merkmale haben können. Dadurch, und weil es keine empirische Definition des Bewusstseins gibt, kann ein Test der Anwesenheit des Bewusstseins in AC unmöglich sein. Im Jahr 2014 schlug Victor Argonov einen nicht-Turing-Test für Maschinenbewusstsein auf der Grundlage der Fähigkeit der Maschine, philosophische Urteile zu produzieren. Er argumentiert, dass eine deterministische Maschine als bewusst betrachtet werden muss, wenn sie in der Lage ist, Urteile über alle problematischen Eigenschaften des Bewusstseins (wie Qualia oder Bindung) ohne angeborene (vorgeladene) philosophische Kenntnisse in diesen Fragen, keine philosophischen Diskussionen während des Lernens, und keine Informationsmodelle anderer Geschöpfe in ihrem Gedächtnis (diese Modelle können implizit oder explizit Kenntnisse über das Bewusstsein dieser Geschöpfe enthalten). Dieser Test kann jedoch nur verwendet werden, um die Existenz des Bewusstseins zu erkennen, aber nicht widerlegen. Ein positives Ergebnis beweist, dass Maschine bewusst ist, aber ein negatives Ergebnis beweist nichts. Beispielsweise kann das Fehlen philosophischer Urteile durch das Fehlen des Verstandes der Maschine verursacht werden, nicht durch das Fehlen des Bewusstseins. In Fiktion Charaktere mit künstlichem Bewusstsein (oder zumindest mit Persönlichkeiten, die implizieren, dass sie Bewusstsein haben), aus Fiktionswerken: AC – geschaffen durch Verschmelzung von zwei AIs in der Sprawl-Trilogie von William Gibson Agenten – in der simulierten Mouss-Realität als "The Matrix" in The Matrix franchise Agent Smith – begann als Agent in The Matrix, dann wurde ein renegade-Programm von überwachsender Macht, die Kopien von sich selbst machen könnte wie ein. Ein allmächtiger, hoch intelligenter Supercomputer, sein Hass für die Menschheit fuhr ihn dazu, Massengenozid gegen die menschliche Rasse zu verursachen und fünf Menschen zu sparen, sadistische Spiele mit ihnen für alle Ewigkeit zu spielen. Ein Beispiel für den Vergnügungspark, der in der Westworld und in der Futureworld Annalee Call – ein Auton (Android von anderen Androiden) aus dem Film Alien Resurrection Arnold Rimmer – Computer-generierte sapient Hologramme an Bord des Red DwarfAva – ein humanoider Roboter in Ex Machina Ash – android Crew-Mitglied des Nostromo-Starship Bender hat auch einen eigenen Verstand. Gideon – ein interaktives künstliches Bewusstsein von Barry Allen in DC-Comics gezeigt und zeigt wie The Flash and Legends of Tomorrow GLaDOS (und Persönlichkeitskerne) – aus der Portal-Serie der Spiele HAL 9000 – Raumschiff USS Discovery One's onboard Computer, die aufgrund von einander exklusiven Richtlinien, aus dem 1968er Roman 2001:A Space Odyssey und im Film Holly-Iferville-Computer Jane – Orson Scott Card's Speaker for the Dead, Xenocide, Children of the Mind, and "Investment Counselor" Johnny Five – Short Circuit Joshua – WarGames Keymaker – a exile sapient program in The franc Matrixhise Lieutenant Commander Data – Star Trek: The Next Generation Machine – androidual from the Machine, dessen Besitzer versuchen, sie zu töten, wenn sie ihre bewussten Gedanken erleben, aus Angst, dass Kulturromanen Omnius – sende Computernetzwerk, das das Universum bis zum Sturz durch den Butlerian Jihad in der Dune franchise Betriebssysteme im Film Her The Oracle – sapient Programm in The Matrix franchise Professor James Moriarty – sendient Holodeck Charakter in der "Ship in a Bottagtle" Episode von Star Trek: Die nächste Generation In Greg Egans neuartige Permutation Stadt und der Film Blade Runner, der zeigt, was passieren könnte, wenn künstlich bewusste Roboter sehr eng auf den Menschen Roboduck modelliert werden – Kampfroboter Superheld in der NEU-GEN Comic-Serie von Marvel Comics Robots in Isaac Asimov Roboter-Serie Robots in The Matrix Franchise, vor allem in The Animatrix The Ship – das Ergebnis eines groß angelegten AC-Experiments, in Frank Herbert's Destination: Void und sequels, trotz frühere Edicts Warnung vor "Making a Machine in the Image of a Man's Mind" Skynet – aus den Terminator franchise Synths sind eine Art Android im Videospiel Fallout 4. Es gibt eine Fraktion im Spiel namens "The Railroad", die glaubt, dass Synths als bewusste Wesen ihre eigenen Rechte haben. Das Institut, das Labor, das die Synths produziert, glaubt meist nicht, dass sie wirklich bewusst sind und zeigt scheinbare Freiheitswünsche als Fehlfunktion an. TARDIS – Zeitmaschine und Raumschiff von Doctor Who, manchmal mit einem Geist von seinen eigenen Terminator Cyborgs – aus dem Terminator-Franchise, mit visuellem Bewusstsein dargestellt über First-Person-Perspektive Transformers – sandige Roboter aus den verschiedenen Serien in der Transformers Roboter Superhelden-Franchise des gleichen Namens Vanamonde – ein künstliches Wesen, das immens mächtig, aber ganz kinder war in Arthur C. Die Nier-Franchise verwendet wiederholt simuliertes Bewusstsein und Philosophie als zentrales Thema. Siehe auch Referenzen Zitate Bibliographie weiterlesen Baars, Bernard; Franklin, Stan (2003). "Wie bewusste Erfahrung und Arbeitsspeicher interagieren" (PDF). Trends in kognitiven Wissenschaften.7 (4): 166–172. doi:10.1016/s1364-6613(03)00056-1.PMID 12691765.S2CID 14185056. Casti, John L. "The Cambridge Quintet: A Work of Scientific Speculation", Perseus Books Group, 1998 Franklin, S, B J Baars, U Ramamurthy und Matthew Ventura. 2005. Die Rolle des Bewusstseins im Gedächtnis. Brains, Minds and Media 1: 1–38, pdf.Haikonen, Pentti (2004,) Conscious Machines and Machine Emotions, präsentiert auf Workshop on Models for Machine Consciousness, Antwerp, BE, Juni 2004. McCarthy, John (1971–1987), Generalität in Künstlicher Intelligenz. Stanford University, 1971-1987.Penrose, Roger, The Emperor's New Mind, 1989. Sternberg, Eliezer J. (2007) Sind Sie eine Maschine?: Das Gehirn, der Geist, und was es bedeutet, Mensch zu sein. Amherst, NY: Prometheus Books. Suzuki T,. Inaba K,. Takeno, Junichi (2005,) Conscious Robot that Distinguishes Between Self and Others and Implements Imitation Behavior, (Best Paper of IEA/AIE2005,) Innovationen in Applied Artificial Intelligence, 18. Internationale Konferenz über industrielle und technische Anwendungen von künstlichen Intelligenz und Expertensystemen, pp.101–110, IEA/AIE. Takeno, Junichi (2006,) The Self-Aware Robot -A Response to Reactions to Discovery News,- HRI Press, August 2006. Zagal, J.C, Lipson, H. (2009) "Self-Reflection in Evolutionary Robotics", Proceedings of the Genetic and Evolutionary Computation Conference, S. 2179–2188, GECCO 2009. Externe Links Artefaktuelle Bewusstseinsdarstellung von Professor Igor Aleksander FOCS 2009: Manuel Blum - Can (Theoretical Computer) Die Wissenschaft kommt mit dem Bewußtsein zurecht? www.Conscious-Robots.com, Machine Consciousness und Conscious Robots Portal.