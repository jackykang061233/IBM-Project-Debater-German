In der Statistik ist die Überarbeitung "die Erstellung einer Analyse, die zu eng oder genau einem bestimmten Datensatz entspricht, und kann daher nicht zu zusätzlichen Daten passen oder zukünftige Beobachtungen zuverlässig vorhersagen". Ein überrüstetes Modell ist ein statistisches Modell, das mehr Parameter enthält als durch die Daten gerechtfertigt werden kann. Die Essenz der Überfütterung ist, einen Teil der Restvariation (d.h. das Rauschen) unbemerkt extrahiert zu haben, als ob diese Variation die zugrunde liegende Modellstruktur darstellt. Die Ermittlung erfolgt, wenn ein statistisches Modell die zugrunde liegende Struktur der Daten nicht ausreichend erfassen kann. Ein unterfitiertes Modell ist ein Modell, bei dem einige Parameter oder Begriffe fehlen, die in einem korrekt spezifizierten Modell erscheinen würden. Eine Unterrüstung würde beispielsweise beim Anbringen eines linearen Modells an nichtlineare Daten auftreten. Ein solches Modell wird tendenziell schlechte Vorhersageleistung haben. Die Möglichkeit der Überarbeitung besteht darin, dass das zur Auswahl des Modells verwendete Kriterium nicht das gleiche ist wie das Kriterium, das zur Beurteilung der Eignung eines Modells herangezogen wird. So kann beispielsweise ein Modell gewählt werden, indem es seine Leistung auf einige Ausbildungsdaten maximiert, und dennoch kann seine Eignung durch seine Fähigkeit, gut auf ungesehenen Daten durchzuführen bestimmt werden; dann erfolgt eine Überarbeitung, wenn ein Modell beginnt, Trainingsdaten zu merken, anstatt von einem Trend zu verallgemeinern. Ist die Anzahl der Parameter gleich oder größer als die Anzahl der Beobachtungen, so kann ein Modell die Trainingsdaten einfach durch die vollständige Datenerfassung perfekt vorhersagen. (Für eine Abbildung siehe Abbildung 2). Ein solches Modell wird jedoch typischerweise bei Vorhersagen schwer ausfallen. Das Potential zur Überarbeitung hängt nicht nur von der Anzahl der Parameter und Daten, sondern auch von der Konformität der Modellstruktur mit der Datenform und der Größe des Modellfehlers im Vergleich zum erwarteten Rauschen oder Fehler in den Daten ab. Auch wenn das eingebaute Modell keine überhöhte Anzahl von Parametern aufweist, ist zu erwarten, dass die angepasste Beziehung auf einem neuen Datensatz weniger gut auskommt als auf dem Datensatz, der für die Montage verwendet wird (ein Phänomen, das manchmal als Schrumpfung bezeichnet wird). Insbesondere wird der Wert des Bestimmungskoeffizienten relativ zu den ursprünglichen Daten schrumpfen. Um die Wahrscheinlichkeit oder die Höhe der Überbelegung zu verringern, stehen mehrere Techniken zur Verfügung (z.B. Modellvergleich, Cross-validierung, Regularisierung, Frühstopp, Pflaumen, Bayesian Priors oder Dropout). Die Grundlage einiger Techniken ist entweder (1), um über komplexe Modelle explizit zu bestrafen oder (2), um die Fähigkeit des Modells zu testen, durch die Bewertung seiner Leistung auf einer Reihe von Daten, die nicht für die Ausbildung verwendet werden, zu verallgemeinern, die angenommen wird, um die typischen ungesehenen Daten, die ein Modell zu begegnen. Statistische Angaben In der Statistik wird von einem statistischen Modell gesprochen, das über ein bestimmtes Verfahren ausgewählt wurde. Burnham & Anderson, in ihrem viel zitierten Text zur Modellauswahl, argumentieren, dass, um zu vermeiden, zu übertreffen, wir sollten an der "Principle of Parsimony" halten. Die Autoren geben auch Folgendes an. Überrüstete Modelle ... sind oft frei von Vorurteilen in den Parameterschätzern, haben jedoch geschätzte (und tatsächliche) Abtastabweichungen, die unnötig groß sind (die Genauigkeit der Schätzer ist schlecht, bezogen auf das, was mit einem parsimoneren Modell erreicht werden konnte). Falsche Behandlungseffekte neigen dazu, identifiziert zu werden, und falsche Variablen sind mit überrüsteten Modellen enthalten. ... Ein am besten anpassungsfähiges Modell wird erreicht, indem die Fehler von Unterfütterung und Überfütterung richtig ausgeglichen werden. Die Überarbeitung ist eher ein ernstes Anliegen, wenn es wenig Theorie zur Verfügung steht, um die Analyse zu führen, zum Teil weil dann eine große Anzahl von Modellen zu wählen. Das Buch Model Selection and Model Averaging (2008) stellt es so. Bei einem Datensatz können Sie Tausende von Modellen auf Knopfdruck anpassen, aber wie wählen Sie das Beste? Mit so vielen Kandidatenmodellen ist Überfütterung eine echte Gefahr. Ist der Affe, der Hamlet tatsächlich ein guter Schriftsteller eingegeben hat? Regression Bei der Regressionsanalyse erfolgt häufig eine Überbelegung. Als extremes Beispiel, wenn es p-Variablen in einer linearen Regression mit p-Datenpunkten gibt, kann die angepasste Linie genau durch jeden Punkt gehen. Bei logistischen Regressions- oder Cox-Proportional-Risikomodellen gibt es eine Vielzahl von Regeln des Daumens (z.B. 5–9, 10 und 10–15 — die Leitlinie von 10 Beobachtungen pro unabhängiger Variable ist als "ein in zehn Regel" bezeichnet). Bei der Regressionsmodellauswahl kann der mittlere quadratische Fehler der zufälligen Regressionsfunktion in zufälliges Rauschen, Näherungsvorspannung und Varianz in der Schätzung der Regressionsfunktion aufgeteilt werden. Der Bias-Variance-Tradeoff wird häufig verwendet, um Overfit-Modelle zu überwinden. Bei einem großen Satz von erläuternden Variablen, die tatsächlich keinen Bezug zur vorhergesagten abhängigen Variablen haben, werden im allgemeinen einige Variablen falsch als statistisch signifikant empfunden und der Forscher kann sie somit im Modell behalten, wodurch das Modell überholt wird. Das ist bekannt als Freedmans Paradox. Lernen von Maschinen Üblicherweise wird ein Lernalgorithmus unter Verwendung eines Satzes von "Trainingsdaten" trainiert, bei dem die gewünschte Ausgabe bekannt ist. Ziel ist es, dass der Algorithmus auch bei der Vorhersage der Ausgabe gut funktioniert, wenn er "validierungsdaten" gespeist wurde, die während des Trainings nicht aufgetreten waren. Overfitting ist die Verwendung von Modellen oder Verfahren, die gegen den Rasierapparat von Occam verstoßen, z.B. durch die Einbeziehung von einstellbareren Parametern als letztlich optimal, oder durch die Verwendung eines komplizierteren Ansatzes als letztendlich optimal. Beispielsweise bei zu vielen einstellbaren Parametern ist ein Datensatz zu beachten, bei dem Trainingsdaten für y durch eine lineare Funktion zweier unabhängiger Variablen ausreichend vorhergesagt werden können. Eine solche Funktion benötigt nur drei Parameter (Abfang und zwei Steigungen). Diese einfache Funktion mit einer neuen, komplexeren quadratischen Funktion oder mit einer neuen, komplexeren linearen Funktion auf mehr als zwei unabhängigen Variablen zu wiederholen, birgt ein Risiko: Der Rasierapparat von Occam bedeutet, dass jede gegebene komplexe Funktion a priori weniger wahrscheinlich ist als jede gegebene einfache Funktion. Wird die neue, kompliziertere Funktion anstelle der einfachen Funktion gewählt, und wenn es nicht eine große genug Verstärkung in Trainingsdaten zur Verrechnung der Komplexitätssteigerung passte, dann übertrifft die neue komplexe Funktion die Daten, und die komplexe überrüstete Funktion wird wahrscheinlich schlechter als die einfachere Funktion bei Validierungsdaten außerhalb des Trainingsdatensatzes, auch wenn die komplexe Funktion auch oder vielleicht noch besser am Trainingsdatensatz ausgeführt wird. Beim Vergleich verschiedener Typen von Modellen kann die Komplexität nicht allein durch Zählen, wie viele Parameter in jedem Modell vorhanden sind, sondern auch die Ausdrücklichkeit jedes Parameters berücksichtigt werden. Beispielsweise ist es nicht trivial, die Komplexität eines neuronalen Netzes (welche curvilineare Beziehungen verfolgen kann) mit m-Parametern direkt mit einem Regressionsmodell mit n-Parametern zu vergleichen. Eine Überarbeitung ist besonders wahrscheinlich in Fällen, in denen das Lernen zu lange durchgeführt wurde oder in denen Ausbildungsbeispiele selten sind, so dass der Lernende sich auf sehr bestimmte zufällige Merkmale der Trainingsdaten, die keinen ursächlichen Bezug zur Zielfunktion haben, einzustellen. In diesem Prozess der Überarbeitung erhöht sich die Performance auf den Trainingsbeispielen noch, während die Performance auf ungesehenen Daten schlechter wird. Als einfaches Beispiel betrachten Sie eine Datenbank der Einzelhandelskäufe, die den gekauften Artikel, den Käufer und das Datum und die Uhrzeit des Kaufs umfasst. Es ist einfach, ein Modell zu konstruieren, das das Trainingsset perfekt passt, indem es das Datum und die Uhrzeit des Kaufs verwendet, um die anderen Attribute vorherzusagen, aber dieses Modell wird überhaupt nicht zu neuen Daten verallgemeinern, weil diese letzten Zeiten nie wieder auftreten. In der Regel soll ein Lernalgorithmus relativ zu einem einfacheren überrüsten, wenn es bei der Anbringung bekannter Daten (Hinblick) genauer ist, aber bei der Vorhersage neuer Daten (Vorsicht) weniger genau ist. Man kann intuitiv verstehen, dass Informationen aus der Vergangenheit in zwei Gruppen aufgeteilt werden können: Informationen, die für die Zukunft relevant sind, und irrelevante Informationen (Rausch). Alles andere ist gleich, umso schwieriger ist es, vorherzusagen (d.h. je höher seine Ungewissheit), desto mehr Lärm existiert in früheren Informationen, die ignoriert werden müssen. Das Problem ist, welchen Teil ignoriert werden soll. Ein Lernalgorithmus, der die Wahrscheinlichkeit des Anpassens reduzieren kann, wird als robust bezeichnet. Folgen Die offensichtlichste Folge der Überarbeitung ist eine schlechte Leistung auf dem Validierungsdatensatz. Weitere negative Folgen sind: Eine überrüstete Funktion wird wahrscheinlich mehr Informationen über jeden Gegenstand im Validierungsdatensatz verlangen als die optimale Funktion; die Erfassung dieser zusätzlichen nicht benötigten Daten kann teuer oder fehleranfällig sein, insbesondere wenn jede einzelne Information durch menschliche Beobachtung und manuelle Dateneingabe erfasst werden muss. Eine komplexere, überrüstete Funktion ist wahrscheinlich weniger tragbar als eine einfache. Bei einem Extrem ist eine einvariable lineare Regression so tragbar, dass sie, falls erforderlich, sogar von Hand durchgeführt werden könnte. Am anderen Extrem sind Modelle, die nur durch die exakte Vervielfältigung der kompletten Einrichtung des Originalmodellierers reproduziert werden können, was eine Wiederverwendung oder wissenschaftliche Reproduktion erschwert. Remedaille Die optimale Funktion benötigt meist eine Überprüfung auf größeren oder komplett neuen Datensätzen. Es gibt jedoch Verfahren wie minimaler Spannbaum oder Laufzeit der Korrelation, die die Abhängigkeit zwischen Korrelationskoeffizienten und Zeitreihen (Fensterbreite) anwendet. Wenn die Fensterbreite groß genug ist, sind die Korrelationskoeffizienten stabil und hängen nicht mehr von der Fensterbreitengröße ab. Daher kann durch Berechnung eines Korrelationskoeffizienten zwischen untersuchten Variablen eine Korrelationsmatrix erzeugt werden. Diese Matrix kann topologisch als komplexes Netzwerk dargestellt werden, in dem direkte und indirekte Einflüsse zwischen Variablen visualisiert werden. Das Underfitting erfolgt, wenn ein statistischer Modell- oder maschineller Lernalgorithmus die zugrunde liegende Struktur der Daten nicht ausreichend erfassen kann. Es tritt auf, wenn das Modell oder Algorithmus nicht die Daten genug passt. Die Unterteilung erfolgt, wenn das Modell oder Algorithmus eine geringe Varianz, aber eine hohe Vorspannung zeigt (um das Gegenteil zu kontrastieren, von hoher Varianz und geringer Vorspannung übergeht). Es ist oft ein zu einfaches Modell, das die Komplexität des Problems nicht verarbeiten kann (siehe auch Näherungsfehler). Dies führt zu einem Modell, das nicht geeignet ist, das ganze Signal zu handhaben und daher gezwungen ist, ein Signal als Rauschen zu nehmen. Wenn stattdessen ein Modell in der Lage ist, das Signal zu handhaben, aber trotzdem einen Teil davon auch als Rauschen nimmt, wird es auch als unterfitiert betrachtet. Letzteres kann geschehen, wenn die Verlustfunktion eines Modells eine zu hohe Strafe in diesem konkreten Fall beinhaltet. Burnham & Anderson geben folgendes an. ... ein unterfitiertes Modell würde einige wichtige replizierbare (d.h. konzeptuell replizierbare in den meisten anderen Proben) Struktur in den Daten ignorieren und somit keine Effekte identifizieren, die tatsächlich von den Daten unterstützt wurden. In diesem Fall ist die Vorspannung in den Parameterschätzern oft beträchtlich, und die Stichprobenvarianz wird unterschätzt, beide Faktoren führen zu einer schlechten Konfidenzintervallabdeckung. Verwandte Modelle neigen dazu, wichtige Behandlungseffekte in experimentellen Einstellungen zu vermissen. Siehe auch Hinweise Referenzen Leinweber, D. J. (2007). "Stupid data miner tricks". Das Journal of Investing. 16: 15–22. doi:10.3905/joi.2007.681820 S2CID 108627390. Tetko, I. V;. Livingstone, D. J;. Luik, A. I. (1995). "Neurale Netzwerkstudien. 1. Vergleich von Overfitting und Overtraining" (PDF). Journal of Chemical Information and Modeling. 35 (5:) 826–833. doi:10.1021/ci00027a006.Tip 7: Minimieren Sie das Overfitting. Chicco, D. (Dezember 2017). "Ten schnelle Tipps für maschinelles Lernen in der Rechenbiologie". BioData Mining. 10 (35:) 35. doi:10.1186/s13040-017-0155-3 PMC 5721660. PMID 29234465. Christian, Brian; Griffiths, Tom (April 2017), "Kapitel 7: Overfitting", Algorithms To Live By: The computer science of human Decisions, William Collins, S. 149–168, ISBN 978-0-00-754799-9 Externe Links Overfitting: wenn die Genauigkeit misst falsch (ein einleitendes Video-Tutorial) Das Problem der Überarbeitung von Daten —Stony Brook University Was ist das Überfüllen? —Andrew Gelman blog CSE546: Linear Regression Bias / Variance Tradeoff —University of Washington