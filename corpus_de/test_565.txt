Eine Datenbank ist eine organisierte Sammlung von Daten, die elektronisch von einem Computersystem gespeichert und aufgerufen werden. Wo Datenbanken komplexer sind, werden sie oft mit formalen Design- und Modellierungstechniken entwickelt. Das Datenbankverwaltungssystem (DBMS) ist die Software, die mit Endbenutzern, Anwendungen und der Datenbank selbst interagiert, um die Daten zu erfassen und zu analysieren. Die DBMS-Software umfasst zusätzlich die zur Verwaltung der Datenbank bereitgestellten Kernanlagen. Die Summe der Datenbank, der DBMS und der zugehörigen Anwendungen kann als "Datenbanksystem" bezeichnet werden. Oft wird der Begriff Datenbank auch lose verwendet, um sich auf eine der DBMS, das Datenbanksystem oder eine der Datenbank zugeordnete Anwendung zu beziehen. Computerwissenschaftler können Datenbank-Management-Systeme nach den Datenbank-Modellen, die sie unterstützen, klassifizieren. Die Beziehungsdatenbanken wurden in den 1980er Jahren dominant. Diese Modelldaten als Zeilen und Spalten in einer Reihe von Tabellen und die überwiegende Mehrheit verwenden SQL zum Schreiben und Abfragen von Daten. In den 2000er Jahren wurden nicht-relationale Datenbanken populär, genannt NoSQL, weil sie verschiedene Abfragesprachen verwenden. Terminologie und Übersicht Formal bezieht sich eine Datenbank auf eine Reihe von verwandten Daten und die Art, wie sie organisiert wird. Der Zugriff auf diese Daten wird in der Regel durch ein "Datenbankverwaltungssystem" (DBMS) bereitgestellt, das aus einem integrierten Satz von Computersoftware besteht, mit dem Benutzer mit einer oder mehreren Datenbanken interagieren können und Zugriff auf alle in der Datenbank enthaltenen Daten bietet (obwohl Einschränkungen bestehen können, die den Zugriff auf bestimmte Daten begrenzen). Das DBMS bietet verschiedene Funktionen, die den Eintrag, die Speicherung und das Abrufen großer Informationsmengen ermöglichen und die Verwaltung dieser Informationen ermöglichen. Aufgrund der engen Beziehung zwischen ihnen wird der Begriff Datenbank oft lässig verwendet, um sich sowohl auf eine Datenbank als auch auf das verwendete DBMS zu beziehen. Außerhalb der Welt der professionellen Informationstechnologie wird der Begriff Datenbank oft verwendet, um auf jede Sammlung von verwandten Daten (z.B. ein Tabellenblatt oder einen Kartenindex) Bezug zu nehmen, da Größen- und Nutzungsanforderungen typischerweise die Verwendung eines Datenbankmanagementsystems erfordern. Vorhandene DBMSs bieten verschiedene Funktionen, die die Verwaltung einer Datenbank und ihrer Daten ermöglichen, die in vier Hauptfunktionsgruppen klassifiziert werden können: Datendefinition – Erstellung, Änderung und Entfernung von Definitionen, die die Organisation der Daten definieren. Update – Einfügen, Änderung und Löschung der tatsächlichen Daten. Retrieval – Bereitstellung von Informationen in einer Form direkt nutzbar oder zur Weiterverarbeitung durch andere Anwendungen. Die abgerufenen Daten können grundsätzlich in einer Form zur Verfügung gestellt werden, wie sie in der Datenbank oder in einer neuen Form gespeichert wird, die durch Veränderung oder Kombination bestehender Daten aus der Datenbank erhalten wird. Administration – Registrierung und Überwachung von Benutzern, Durchsetzung der Datensicherheit, Überwachung der Leistung, Aufrechterhaltung der Datenintegrität, Umgang mit Konkurrenzkontrolle und Wiederherstellung von Informationen, die von einigen Ereignissen wie einem unerwarteten Systemausfall beschädigt wurden. Sowohl eine Datenbank als auch ihr DBMS entsprechen den Prinzipien eines bestimmten Datenbankmodells."Datenbanksystem" bezieht sich auf das Datenbankmodell, das Datenbankmanagementsystem und die Datenbank. Die Datenbankserver sind dedizierte Computer, die die eigentlichen Datenbanken halten und nur die DBMS und damit verbundene Software ausführen. Datenbankserver sind in der Regel Multiprozessor-Computer, mit großzügigem Speicher und RAID-Disk-Arrays für stabile Speicherung verwendet. Hardware-Datenbankbeschleuniger, die über einen Hochgeschwindigkeitskanal mit einem oder mehreren Servern verbunden sind, werden auch in großen Volumentransaktions-Verarbeitungsumgebungen eingesetzt. DBMSs finden sich im Herzen der meisten Datenbankanwendungen. DBMSs können um einen benutzerdefinierten Multitasking-Kernel mit integriertem Netzwerk-Support gebaut werden, aber moderne DBMSs verlassen sich typischerweise auf ein Standard-Betriebssystem, um diese Funktionen bereitzustellen. Da DBMSs einen bedeutenden Markt umfassen, berücksichtigen Computer- und Speicheranbieter häufig die DBMS-Anforderungen in ihren eigenen Entwicklungsplänen. Datenbanken und DBMSs können nach dem Datenbankmodell(en) kategorisiert werden, das sie (wie z.B. relationale oder XML), den Typ(en) des Computers, auf dem sie (von einem Server-Cluster zu einem Mobiltelefon) laufen, die Abfragesprache(n), die zum Zugriff auf die Datenbank (z.B. SQL oder XQuery) verwendet wird, und deren internes Engineering, das die Leistung, Skalierbarkeit, Widerstandsfähigkeit und Sicherheit betrifft. Geschichte Die Größen, Fähigkeiten und die Leistungsfähigkeit der Datenbanken und deren jeweilige DBMS sind in Größenordnungen gewachsen. Diese Leistungssteigerungen wurden durch den Technologiefortschritt in den Bereichen Prozessoren, Computerspeicher, Computerspeicher und Computernetzwerke ermöglicht. Das Konzept einer Datenbank wurde durch die Entstehung von direkten Zugriffsspeichermedien wie Magnetplatten ermöglicht, die Mitte der 1960er Jahre weit verbreitet wurden; frühere Systeme stützten sich auf die sequentielle Speicherung von Daten auf Magnetband. Die nachfolgende Entwicklung der Datenbanktechnologie kann in drei Ära auf Basis von Datenmodell oder Struktur unterteilt werden: Navigation, SQL/Relational und Post-Relational. Die beiden wichtigsten frühen Navigationsdatenmodelle waren das hierarchische Modell und das CODASYL-Modell (Netzwerkmodell). Diese wurden durch die Verwendung von Zeigern (oft physikalische Datenträgeradressen) gekennzeichnet, um Beziehungen von einem Datensatz zu einem anderen zu verfolgen. Das von Edgar F. Codd im Jahre 1970 vorgeschlagene relationale Modell ging von dieser Tradition aus, indem es darauf bestand, dass Anwendungen nach Daten durch Inhalte suchen sollten, anstatt nach Links. Das relationale Modell verwendet Sets von LED-Tischen, die jeweils für eine andere Art von Unternehmen verwendet werden. Erst Mitte der 1980er Jahre wurde die EDV-Hardware leistungsfähig genug, um den breiten Einsatz von relationalen Systemen (DBMSs plus Applikationen) zu ermöglichen. In den frühen 1990er-Jahren dominierten relationale Systeme jedoch in allen groß angelegten Datenverarbeitungsanwendungen, und ab 2018 sind sie dominant: IBM DB2, Oracle, MySQL und Microsoft SQL Server sind die am meisten gesuchten DBMS. Die dominante Datenbanksprache, standardisiertes SQL für das relationale Modell, hat Datenbanksprachen für andere Datenmodelle beeinflusst. Objektdatenbanken wurden in den 1980er Jahren entwickelt, um die Unannehmlichkeit von Objekt-Relationsimpedanz-Mixatch zu überwinden, was zur Prägung des Begriffs post-relational und auch zur Entwicklung von hybriden Objekt-relationalen Datenbanken führte. Die nächste Generation von Post-Relations-Datenbanken in den späten 2000er Jahren wurde als NoSQL-Datenbanken bekannt, wobei schnelle Schlüssel-Wert-Stores und dokumentorientierte Datenbanken eingeführt wurden. Eine konkurrierende "nächste Generation", die als NewSQL-Datenbanken bekannt ist, versuchte neue Implementierungen, die das relationale/SQL-Modell beibehalten und die hohe Leistung von NoSQL im Vergleich zu kommerziell verfügbaren relationalen DBMSs erfüllen. 1960er Jahre, Navigations-DBMSDie Einführung des Begriffs Datenbank stimmte mit der Verfügbarkeit von Direktzugriffsspeicher (Disks und Trommeln) ab Mitte der 1960er Jahre zusammen. Der Begriff stellte einen Kontrast zu den bandbasierten Systemen der Vergangenheit dar, der eine gemeinsame interaktive Nutzung anstelle der täglichen Chargenverarbeitung ermöglichte. Das Oxford English Dictionary zitiert einen Bericht von der System Development Corporation of California aus dem Jahr 1962, der als erster den Begriff Datenbank in einem bestimmten technischen Sinn verwendet. Da die Computer in Geschwindigkeit und Leistungsfähigkeit wuchsen, kam es zu einer Reihe allgemeiner Datenbanksysteme; Mitte der 1960er-Jahre war eine Reihe solcher Systeme kommerziell genutzt worden. Das Interesse an einem Standard begann zu wachsen, und Charles Bachman, Autor eines solchen Produkts, der Integrated Data Store (IDS), gründete die Datenbank Task Group innerhalb von CODASYL, der Gruppe verantwortlich für die Erstellung und Standardisierung von COBOL. 1971 lieferte die Datenbank Task Group ihren Standard, der im Allgemeinen als CODASYL-Ansatz bekannt wurde, und bald trat eine Reihe von kommerziellen Produkten auf Basis dieses Ansatzes in den Markt. Der CODASYL-Ansatz bot Anwendungen die Möglichkeit, um einen verknüpften Datensatz zu navigieren, der zu einem großen Netzwerk gebildet wurde. Anwendungen konnten Aufzeichnungen nach einer von drei Methoden finden: Verwendung eines primären Schlüssels (bekannt als CALC-Schlüssel, typischerweise durch Hashing implementiert)Navigation Beziehungen (genannte Sätze) von einem Datensatz zu einem anderen Scannen alle Datensätze in einer sequentiellen ReihenfolgeLater-Systeme hinzugefügt B-trees, um alternative Zugriffspfade zu bieten. Viele CODASYL-Datenbanken haben auch eine deklarative Abfragesprache für Endbenutzer hinzugefügt (wie von der Navigations-API deutlich). Allerdings waren CODASYL-Datenbanken komplex und erforderten erhebliche Schulungen und Anstrengungen, um nützliche Anwendungen zu produzieren. IBM hatte auch ein eigenes DBMS 1966, bekannt als Information Management System (IMS). IMS war eine Entwicklung von Software für das Apollo-Programm auf dem System/360 geschrieben. IMS war in der Regel ähnlich im Konzept zu CODASYL, aber verwendet eine strenge Hierarchie für sein Modell der Datennavigation anstelle von CODASYL Netzwerkmodell. Beide Konzepte wurden später als Navigationsdatenbanken aufgrund des Zugriffs auf Daten bekannt: Der Begriff wurde von Bachmans 1973 Turing Award-Präsentation The Programmer als Navigator populär gemacht. IMS wird von IBM als hierarchische Datenbank eingestuft. Die INSGESAMT-Datenbank von IDMS und Cincom Systems wird als Netzwerk-Datenbanken eingestuft. Das IMS bleibt ab 2014 im Einsatz. 1970er Jahre, relationale DBMS Edgar F. Codd arbeitete bei IBM in San Jose, Kalifornien, in einem ihrer Offshoot-Büros, die in erster Linie an der Entwicklung von Festplattensystemen beteiligt war. Er war unglücklich mit dem Navigationsmodell des CODASYL-Ansatzes, insbesondere dem Fehlen einer Sucheinrichtung. 1970 schrieb er eine Reihe von Papieren, die einen neuen Ansatz für den Datenbankaufbau skizzierten, der schließlich in das bahnbrechende A Relational Model of Data for Large Shared Data Banks gipfelte. In diesem Papier beschreibt er ein neues System zum Speichern und Arbeiten mit großen Datenbanken. Anstelle von Datensätzen, die wie in CODASYL in einer verlinkten Liste von Free-Form-Daten gespeichert werden, war Codds Idee, die Daten als eine Reihe von Tabellen zu organisieren, wobei jede Tabelle für eine andere Art von Einheit verwendet wird. Jede Tabelle enthält eine feste Anzahl von Spalten, die die Attribute des Unternehmens enthalten. Eine oder mehrere Spalten jeder Tabelle wurden als Primärschlüssel bezeichnet, mit dem die Zeilen der Tabelle eindeutig identifiziert werden konnten; Querverweise zwischen den Tabellen verwendet immer diese Primärschlüssel, anstatt Disk-Adressen, und Abfragen würden Tabellen auf Basis dieser Schlüsselbeziehungen unter Verwendung einer Reihe von Operationen basierend auf dem mathematischen System der relationalen Berechnung (von denen das Modell seinen Namen nimmt). Aufteilen der Daten in eine Reihe von normierten Tabellen (oder Beziehungen), die darauf abzielen, dass jede Tatsache nur einmal gespeichert wurde, wodurch die Aktualisierungsoperationen vereinfacht werden. Virtuelle Tabellen, die Ansichten genannt werden, könnten die Daten auf verschiedene Weise für verschiedene Benutzer darstellen, aber Ansichten konnten nicht direkt aktualisiert werden. Codd verwendet mathematische Begriffe, um das Modell zu definieren: Beziehungen, Tupel und Domains anstatt Tabellen, Zeilen und Spalten. Die jetzt vertraute Terminologie stammt aus frühen Implementierungen. Codd würde später die Tendenz für praktische Umsetzungen kritisieren, von den mathematischen Grundlagen, auf denen das Modell basiert. Die Verwendung von Primärschlüsseln (userorientierte Identifikatoren) zur Darstellung von kreuzstabilen Beziehungen statt von Festplattenadressen hatte zwei primäre Motivationen. Aus technischer Sicht ermöglichte es den Tabellen, ohne teure Datenbank-Umordnung umzusiedeln und zu verkleinern. Codd war jedoch eher an der Semantikdifferenz interessiert: Die Verwendung von expliziten Identifikatoren erleichterte die Definition von Update-Operationen mit sauberen mathematischen Definitionen und ermöglichte auch die Definition von Abfrage-Operationen in Bezug auf die etablierte Disziplin des Prädikats erster Ordnung; da diese Operationen saubere mathematische Eigenschaften haben, wird es möglich, Abfragen auf nachweislich korrekte Weise neu zu schreiben, was die Grundlage der Abfrageoptimierung ist. Im Vergleich zu den hierarchischen oder Netzwerkmodellen gibt es keinen Ausdrucksverlust, obwohl die Verbindungen zwischen den Tabellen nicht mehr so explizit sind. In den hierarchischen und Netzwerkmodellen durften Datensätze eine komplexe interne Struktur haben. Zum Beispiel könnte die Gehaltsgeschichte eines Mitarbeiters innerhalb der Mitarbeiterliste als "repeating group" dargestellt werden. Im relationalen Modell führte der Prozess der Normalisierung dazu, dass solche internen Strukturen durch in mehreren Tabellen gehaltene Daten ersetzt wurden, die nur durch logische Tasten verbunden sind. Eine häufige Verwendung eines Datenbanksystems ist zum Beispiel, um Informationen über Benutzer, ihren Namen, Anmeldeinformationen, verschiedene Adressen und Telefonnummern zu verfolgen. Im Navigationsansatz würden alle diese Daten in einem einzigen Variablen-Länge-Datensatz platziert werden. Im relationalen Ansatz würden die Daten in eine Benutzertabelle, eine Adresstabelle und eine Telefonnummerntabelle (z.B.) normiert. In diesen optionalen Tabellen würden nur dann Aufzeichnungen erstellt, wenn die Adressen oder Telefonnummern tatsächlich bereitgestellt wurden. Neben der Identifizierung von Zeilen/Aufzeichnungen mit logischen Kennungen anstelle von Festplattenadressen änderte Codd die Art, wie Anwendungen Daten aus mehreren Datensätzen zusammenbauen. Anstatt Anwendungen zu benötigen, um Daten zu einem Zeitpunkt zu sammeln, indem sie die Links navigieren, würden sie eine deklarative Abfragesprache verwenden, die ausdrückte, welche Daten benötigt wurden, anstatt den Zugriffspfad, mit dem sie gefunden werden sollte. Die Suche nach einem effizienten Zugriffspfad zu den Daten wurde die Verantwortung des Datenbank-Management-Systems und nicht des Anwendungs-Programmierers. Dieser Prozess, genannt Abfrageoptimierung, hängt davon ab, dass Abfragen in Bezug auf mathematische Logik ausgedrückt wurden. Codds Papier wurde von zwei Leuten in Berkeley, Eugene Wong und Michael Stonebraker abgeholt. Sie starteten ein Projekt, das als INGRES bezeichnet wurde, mit Mitteln, die bereits für ein geografisches Datenbankprojekt und Schülerprogrammierer zur Erstellung von Code zugewiesen wurden. Ab 1973 lieferte INGRES seine ersten Testprodukte, die 1979 allgemein für den weit verbreiteten Einsatz bereit waren. INGRES war ähnlich wie System R in einer Reihe von Möglichkeiten, einschließlich der Verwendung einer Sprache für den Datenzugriff, bekannt als QUEL. Im Laufe der Zeit wechselte INGRES in den aufstrebenden SQL-Standard. IBM selbst machte eine Test-Implementierung des relationalen Modells, PRTV, und eine Produktion, Business System 12, beide jetzt eingestellt. Honeywell schrieb MRDS für Multics, und jetzt gibt es zwei neue Implementierungen: Alphora Dataphor und Rel. Die meisten anderen DBMS-Implementierungen, die normalerweise relational genannt werden, sind SQL DBMSs. 1970 begann die University of Michigan mit der Entwicklung des MICRO Information Management Systems basierend auf D.L Childs' Set-Theoretic Data Modell. MICRO wurde verwendet, um sehr große Datensätze von der US Department of Labor, der US-Umweltschutzagentur, und Forscher von der University of Alberta, der University of Michigan und Wayne State University zu verwalten. Es lief auf IBM Mainframe-Computer mit dem Michigan Terminal System. Das System blieb bis 1998 in Produktion. Integrierter Ansatz In den 1970er und 1980er Jahren wurde versucht, Datenbanksysteme mit integrierter Hardware und Software aufzubauen. Die zugrunde liegende Philosophie war, dass eine solche Integration eine höhere Leistung zu niedrigeren Kosten bieten würde. Beispiele waren IBM System/38, das frühe Angebot von Teradata und die Datenbank-Maschine Britton Lee, Inc. Ein weiterer Ansatz zur Hardware-Unterstützung für die Datenbankverwaltung war der CAFS-Beschleuniger von ICL, ein Hardware-Disk-Controller mit programmierbaren Suchfunktionen. Langfristig waren diese Bemühungen in der Regel erfolglos, weil spezialisierte Datenbankmaschinen mit der schnellen Entwicklung und dem Fortschritt von Universalrechnern nicht Schritt halten konnten. So sind die meisten Datenbanksysteme heutzutage Softwaresysteme, die auf allgemeiner Hardware laufen, unter Verwendung von Computerdatenspeichern. Jedoch wird diese Idee noch für bestimmte Anwendungen von einigen Unternehmen wie Netezza und Oracle (Exadata.) Ende der 1970er Jahre begann SQL DBMS IBM, in den frühen 1970er-Jahren an einem Prototyp-System lose auf Basis von Codds Konzepten als System R zu arbeiten. Die erste Version war 1974/5 fertig, und die Arbeit begann dann auf Multitable-Systemen, in denen die Daten aufgeteilt werden konnten, so dass alle Daten für einen Datensatz (einige davon optional) nicht in einem einzigen großen Stück gespeichert werden mussten". Nachfolgende Multi-User-Versionen wurden von Kunden 1978 und 1979 getestet, um welche Zeit eine standardisierte Abfragesprache – SQL – hinzugefügt wurde. Die Ideen von Coddd stellten sich sowohl als arbeitsfähig als auch überlegen gegenüber CODASYL und drängten IBM auf, eine echte Produktionsversion von System R, bekannt als SQL/DS, und später Datenbank 2 (DB2) zu entwickeln. Larry Ellison's Oracle Database (oder einfach, Oracle) startete aus einer anderen Kette, basierend auf IBMs Papieren auf System R.Though Oracle V1 Implementierungen wurden im Jahr 1978 abgeschlossen, es war nicht bis Oracle Version 2, als Ellison IBM zum Markt im Jahr 1979 schlug. Stonebraker ging weiter, um die Lehren von INGRES um eine neue Datenbank zu entwickeln, Postgres, die jetzt als PostgreSQL bekannt ist.PostgreSQL wird oft für globale missionskritische Anwendungen verwendet (die .org und .info Domain Name Registries verwenden es als ihren primären Datenspeicher, wie viele große Unternehmen und Finanzinstitute). In Schweden wurde auch Codds Papier gelesen und Mimer SQL wurde Mitte der 1970er Jahre an der Universität Uppsala entwickelt. 1984 wurde dieses Projekt zu einem unabhängigen Unternehmen konsolidiert. Ein weiteres Datenmodell, das Entity-Relationship-Modell, erschien 1976 und gewann Popularität für Datenbank-Design, wie es eine vertrautere Beschreibung als das frühere relationale Modell betonte. Später wurden Entity-Relationship-Konstrukte als Datenmodellierungskonstrukt für das relationale Modell nachgerüstet und die Differenz zwischen den beiden ist irrelevant geworden. 1980er Jahre, auf dem Desktop Die 1980er Jahre im Alter von Desktop-Computing. Die neuen Computer befähigen ihre Benutzer mit Tabellenkalkulationen wie Lotus 1-2-3 und Datenbanksoftware wie dBASE. Das dBASE Produkt war leicht und leicht für jeden Computernutzer, um aus der Box zu verstehen. C Wayne Ratliff, der Schöpfer von dBASE, sagte: "dBASE war anders als Programme wie BASIC, C, FORTRAN und COBOL, da viele der schmutzigen Arbeiten bereits erledigt waren. Die Datenmanipulation erfolgt durch dBASE statt durch den Benutzer, so dass der Benutzer sich auf das konzentrieren kann, was er tut, anstatt mit den schmutzigen Details des Öffnens, Lesens und Schließens von Dateien und der Verwaltung von Raumzuordnung. "d BASE war in den 1980er und Anfang der 1990er Jahre einer der meistverkauften Softwaretitel. 1990er Jahre, objektorientiert Die 1990er-Jahre verzeichneten zusammen mit einem Anstieg der objektorientierten Programmierung ein Wachstum, wie Daten in verschiedenen Datenbanken behandelt wurden. Programmierer und Designer begannen, die Daten in ihren Datenbanken als Objekte zu behandeln. Das heißt, wenn die Daten einer Person in einer Datenbank waren, wurden die Attribute dieser Person, wie ihre Adresse, Telefonnummer und Alter, nun als zu dieser Person gehören, anstatt fremde Daten zu sein. Dies erlaubt es, die Beziehungen zwischen den Daten zu Objekten und ihren Attributen und nicht zu einzelnen Feldern zu sein. Der Begriff "Objekt-Relationsimpedanz-Fehler" beschreibt die Unannehmlichkeit der Übersetzung zwischen programmierten Objekten und Datenbanktabellen. Objektdatenbanken und Objekt-Relationsdatenbanken versuchen, dieses Problem zu lösen, indem eine objektorientierte Sprache (manchmal als Erweiterung auf SQL) bereitgestellt wird, die Programmierer als Alternative zu rein relationalen SQL verwenden können. Auf der Programmierseite versuchen Bibliotheken, die als Objekt-Relations-Mappings (ORMs) bekannt sind, das gleiche Problem zu lösen. 2000s, NoSQL und NewSQL XML Datenbanken sind eine Art strukturierter dokumentorientierter Datenbank, die eine Abfrage basierend auf XML-Dokumentattributen ermöglicht. XML-Datenbanken werden meist in Anwendungen verwendet, in denen die Daten bequem als Sammlung von Dokumenten angesehen werden, mit einer Struktur, die sich von der sehr flexiblen bis zu den höchst starren variieren kann: beispielsweise wissenschaftliche Artikel, Patente, Steueranmeldungen und Personalaufzeichnungen. NoSQL-Datenbanken sind oft sehr schnell, erfordern keine festen Tabellenschemas, vermeiden Sie die Join-Operationen durch die Speicherung von denormalisierten Daten und sind horizontal skaliert. In den letzten Jahren gab es eine starke Nachfrage nach massiv verteilten Datenbanken mit hoher Partitionstoleranz, aber nach dem CAP-Theorem ist es für ein verteiltes System unmöglich, gleichzeitig Konsistenz, Verfügbarkeit und Partitionstoleranzgarantien bereitzustellen.Ein verteiltes System kann alle zwei dieser Garantien gleichzeitig erfüllen, aber nicht alle drei. Aus diesem Grund verwenden viele NoSQL-Datenbanken die sogenannte evtl. Konsistenz, um sowohl Verfügbarkeits- als auch Partitionstoleranzgarantien mit einem reduzierten Maß an Datenkonsistenz bereitzustellen. NewSQL ist eine Klasse moderner relationaler Datenbanken, die die gleiche skalierbare Leistung von NoSQL-Systemen für die Online-Transaktionsbearbeitung (read-write) Workloads bieten soll, während weiterhin SQL verwendet wird und die ACID-Garantie eines traditionellen Datenbanksystems beibehalten wird. Datenbanken werden verwendet, um interne Operationen von Organisationen zu unterstützen und Online-Interaktionen mit Kunden und Lieferanten zu unterstützen (siehe Enterprise Software). Datenbanken werden verwendet, um administrative Informationen und mehr spezialisierte Daten, wie Engineering-Daten oder Wirtschaftsmodelle zu halten. Beispiele sind computergestützte Bibliothekssysteme, Flugreservierungssysteme, computergestützte Teileinventarsysteme und viele Content-Management-Systeme, die Webseiten als Sammlungen von Webseiten in einer Datenbank speichern. Einstufung Eine Möglichkeit, Datenbanken zu klassifizieren, ist die Art ihrer Inhalte, zum Beispiel: bibliographische, dokument-text-, statistische oder multimediale Objekte. Ein anderer Weg ist beispielsweise in ihrem Anwendungsgebiet: Buchhaltung, Musikkompositionen, Filme, Bankwesen, Fertigung oder Versicherung. Ein dritter Weg ist ein technischer Aspekt, wie beispielsweise die Datenbankstruktur oder Schnittstellenart. Dieser Abschnitt listet einige der Adjektive auf, die verwendet werden, um verschiedene Arten von Datenbanken zu charakterisieren. Eine in-memory-Datenbank ist eine Datenbank, die in erster Linie im Hauptspeicher liegt, aber typischerweise durch nichtflüchtige Computerdatenspeicher gesichert wird. Hauptspeicher-Datenbanken sind schneller als Festplatten-Datenbanken, und so werden oft verwendet, wo Reaktionszeit kritisch ist, wie zum Beispiel in Telekommunikationsnetzgeräten. Eine aktive Datenbank enthält eine ereignisgesteuerte Architektur, die sowohl innerhalb als auch außerhalb der Datenbank auf Bedingungen reagieren kann. Mögliche Anwendungen sind Sicherheitsüberwachung, Alarmierung, Statistiken sammeln und Autorisierung. Viele Datenbanken bieten aktive Datenbankfunktionen in Form von Datenbank-Triggern. Eine Cloud-Datenbank basiert auf Cloud-Technologie. Sowohl die Datenbank als auch der größte Teil ihrer DBMS liegen fern, "in der Cloud", während ihre Anwendungen sowohl von Programmierern entwickelt als auch später von Endbenutzern über einen Webbrowser und Open APIs genutzt werden. Datenlager archivieren Daten aus operativen Datenbanken und oft aus externen Quellen wie Marktforschungsunternehmen. Das Lager wird zur zentralen Datenquelle für die Nutzung durch Manager und andere Endnutzer, die keinen Zugang zu Betriebsdaten haben können. So können beispielsweise Verkaufsdaten in wöchentliche Gesamtsummen zusammengefasst und von internen Produktcodes zur Verwendung von UPCs umgerechnet werden, so dass sie mit ACNielsen-Daten verglichen werden können. Einige grundlegende und wesentliche Bestandteile der Datenspeicherung umfassen die Gewinnung, Analyse und Abbau von Daten, die Transformation, das Laden und die Verwaltung von Daten, um sie für die weitere Verwendung zur Verfügung zu stellen. Eine deduktive Datenbank kombiniert die logische Programmierung mit einer relationalen Datenbank. Eine verteilte Datenbank ist eine Datenbank, in der sowohl die Daten als auch das DBMS mehrere Computer umfassen. Eine dokumentorientierte Datenbank ist zum Speichern, Abrufen und Verwalten dokumentorientierter oder halb strukturierter Informationen konzipiert. Dokumentorientierte Datenbanken sind eine der Hauptkategorien von NoSQL-Datenbanken. Ein eingebettetes Datenbanksystem ist ein DBMS, das eng mit einer Applikationssoftware integriert ist, die den Zugriff auf gespeicherte Daten so erfordert, dass das DBMS vor den Endbenutzern der Anwendung verborgen ist und wenig oder keine laufende Wartung erfordert. Endbenutzer-Datenbanken bestehen aus Daten, die von einzelnen Endbenutzern entwickelt wurden. Beispiele hierfür sind Sammlungen von Dokumenten, Tabellen, Präsentationen, Multimedia und anderen Dateien. Es gibt mehrere Produkte, die solche Datenbanken unterstützen. Einige von ihnen sind viel einfacher als vollwertige DBMSs, mit mehr elementaren DBMS-Funktionalität. Ein federgeführtes Datenbanksystem umfasst mehrere verschiedene Datenbanken, jeweils mit eigenen DBMS. Es wird von einem föderierten Datenbankverwaltungssystem (FDBMS) als eine einzige Datenbank bearbeitet, das transparent mehrere autonome DBMSs, gegebenenfalls unterschiedlicher Typen, integriert (wobei es auch ein heterogenes Datenbanksystem wäre), und sie mit einer integrierten konzeptionellen Ansicht versorgt. Manchmal wird der Begriff Multi-Datenbank als Synonym für föderierte Datenbank verwendet, obwohl er sich auf eine weniger integrierte (z.B. ohne FDBMS und eine verwaltete integrierte Schema) Gruppe von Datenbanken beziehen kann, die in einer einzigen Anwendung zusammenarbeiten. In diesem Fall wird typischerweise Middleware zur Distribution verwendet, die typischerweise ein Atom Commit-Protokoll (ACP), z.B. das Zweiphasen Commit-Protokoll, umfasst, um verteilte (globale) Transaktionen über die teilnehmenden Datenbanken zu ermöglichen. Eine Graphendatenbank ist eine Art NoSQL-Datenbank, die Graphenstrukturen mit Knoten, Kanten und Eigenschaften verwendet, um Informationen darzustellen und zu speichern. Allgemeine Graphen-Datenbanken, die jede Grafik speichern können, unterscheiden sich von spezialisierten Graphen-Datenbanken wie Triplestores und Netzwerk-Datenbanken. Ein Array DBMS ist eine Art von NoSQL DBMS, die Modellierung, Speicherung und Abruf von (meist großen) mehrdimensionalen Arrays wie Satellitenbilder und Klimasimulationsausgabe erlaubt. In einer Hypertext- oder Hypermedia-Datenbank kann auf dieses Objekt jedes Wort oder ein Textstück, das ein Objekt darstellt, z.B. ein anderes Textstück, ein Artikel, ein Bild oder ein Film, verlinkt werden. Hypertext-Datenbanken sind besonders nützlich, um große Mengen von disparate Informationen zu organisieren. Zum Beispiel sind sie nützlich für die Organisation von Online-Enzyklopädien, wo Benutzer bequem um den Text springen können. Die Welt Web ist somit eine große verteilte Hypertext-Datenbank. Eine Wissensbasis (abgekürzt KB, kb oder Δ) ist eine spezielle Datenbank für das Wissensmanagement, die die Mittel für die computergestützte Sammlung, Organisation und Abruf von Wissen bietet. Auch eine Sammlung von Daten, die Probleme mit ihren Lösungen und verwandten Erfahrungen darstellen. Eine mobile Datenbank kann von einem mobilen Rechengerät getragen oder synchronisiert werden. Operationelle Datenbanken speichern detaillierte Daten über den Betrieb einer Organisation. Sie verarbeiten typischerweise relativ hohe Mengen von Updates mit Transaktionen. Beispiele sind Kundendatenbanken, die Kontakt-, Kredit- und demographische Informationen über Kunden eines Unternehmens, Personaldatenbanken, die Informationen wie Gehalt, Nutzen, Qualifikationsdaten über Mitarbeiter, Unternehmensressourcenplanungssysteme, die Details über Produktkomponenten, Teileinventar und Finanzdatenbanken erfassen, die das Geld, die Buchhaltung und den finanziellen Umgang der Organisation verfolgen. Eine parallele Datenbank zielt darauf ab, die Leistung durch Parallelisierung für Aufgaben wie Ladedaten, Bauindizes und Auswertung von Abfragen zu verbessern. Die großen parallelen DBMS-Architekturen, die durch die zugrunde liegende Hardware-Architektur induziert werden, sind: Geteilte Speicherarchitektur, wo mehrere Prozessoren den Hauptspeicherraum sowie andere Datenspeicher teilen. Geteilte Festplattenarchitektur, bei der jede Verarbeitungseinheit (typischerweise aus mehreren Prozessoren) einen eigenen Hauptspeicher hat, aber alle Einheiten teilen den anderen Speicher. Geteilte Architektur, bei der jede Verarbeitungseinheit einen eigenen Hauptspeicher und einen anderen Speicher hat. Probabilistische Datenbanken verwenden Fuzzy-Logik, um Rückschlüsse auf ungenaue Daten zu ziehen. Echtzeit-Datenbanken verarbeiten Transaktionen schnell genug, damit das Ergebnis zurückkommt und sofort gehandelt wird. Eine räumliche Datenbank kann die Daten mit mehrdimensionalen Merkmalen speichern. Die Abfragen zu solchen Daten beinhalten ortsbasierte Abfragen, wie "Wo ist das nächstgelegene Hotel in meiner Region?". Eine zeitliche Datenbank hat zeitliche Aspekte aufgebaut, beispielsweise ein zeitliches Datenmodell und eine zeitliche Version von SQL. Insbesondere die zeitlichen Aspekte umfassen in der Regel Gültigkeitsdauer und Transaktionsdauer. Eine terminologieorientierte Datenbank baut auf einer objektorientierten Datenbank auf, die oft auf ein bestimmtes Feld angepasst ist. Eine unstrukturierte Datendatenbank soll auf eine überschaubare und geschützte Art und Weise verschiedene Objekte speichern, die nicht natürlich und bequem in gemeinsamen Datenbanken passen. Es kann E-Mail-Nachrichten, Dokumente, Zeitschriften, Multimedia-Objekte usw. enthalten. Der Name kann irreführend sein, da einige Objekte hoch strukturiert werden können. Die gesamte mögliche Objektsammlung passt jedoch nicht in einen vordefinierten strukturierten Rahmen. Die meisten etablierten DBMSs unterstützen nun unstrukturierte Daten auf verschiedene Weise, und neue dedizierte DBMSs entstehen. Das Datenbankverwaltungssystem Connolly und Begg definieren das Datenbankverwaltungssystem (DBMS) als "Software-System, mit dem Benutzer den Zugriff auf die Datenbank definieren, erstellen, pflegen und kontrollieren können". Beispiele für DBMS sind MySQL, PostgreSQL, Microsoft SQL Server, Oracle Database und Microsoft Access. Das DBMS Akronym wird manchmal erweitert, um das zugrunde liegende Datenbankmodell anzuzeigen, mit RDBMS für das relationale, OODBMS für das Objekt (orientiert) und ORDBMS für das Objekt-Relationsmodell. Andere Erweiterungen können einige andere Merkmale wie DDBMS für verteilte Datenbankverwaltungssysteme angeben. Die Funktionalität eines DBMS kann enorm variieren. Die Kernfunktionalität ist die Speicherung, Abruf und Aktualisierung von Daten. Codd schlug folgende Funktionen und Dienste vor: Datenspeicherung, Abruf und Aktualisierung Benutzer zugänglicher Katalog oder Datenwörterbuch zur Beschreibung der Metadaten Unterstützung für Transaktionen und Koncurrenzeinrichtungen zur Wiederherstellung der Datenbank sollte es beschädigt werden Unterstützung für die Berechtigung des Zugriffs und der Aktualisierung von Daten Zugriffsunterstützung von entfernten Standorten Zwänge zu zwingen, Daten in der Datenbank nach bestimmten Regeln zu sichern Es ist auch allgemein zu erwarten, dass das DBMS eine Reihe von Diensten für solche Zwecke zur Verfügung stellt, wie es notwendig sein kann, die Datenbank effektiv zu verwalten, einschließlich Import, Export, Monitoring, Defragmentation und Analyseprogramme. Der Kernteil des DBMS, der zwischen der Datenbank und der Applikationsschnittstelle interagiert, wird manchmal als Datenbank-Engine bezeichnet. Oft haben DBMSs Konfigurationsparameter, die statisch und dynamisch abgestimmt werden können, beispielsweise die maximale Menge an Hauptspeicher auf einem Server, den die Datenbank verwenden kann. Der Trend besteht darin, die Menge der manuellen Konfiguration zu minimieren, und für Fälle wie eingebettete Datenbanken ist die Notwendigkeit, Null-Asministration anvisieren. Die großen großen Unternehmen DBMSs haben tendenziell die Größe und Funktionalität erhöht und können tausende von Menschenjahren Entwicklungsanstrengungen über ihr Leben involviert haben. Frühe Multi-User-DBMS erlaubte typischerweise nur, dass die Anwendung auf demselben Computer mit Zugriff über Terminals oder Terminal-Emulations-Software. Die Client-Server-Architektur war eine Entwicklung, in der die Anwendung auf einem Client-Desktop und der Datenbank auf einem Server basierte, um die Verarbeitung zu verbreiten. Dies entwickelte sich zu einer mehrstufigen Architektur mit Applikationsservern und Webservern mit der Endbenutzerschnittstelle über einen Webbrowser mit der Datenbank, die nur direkt mit der benachbarten Ebene verbunden ist. Ein Universal-DBMS wird öffentliche Anwendungs-Programmierschnittstellen (API) und optional einen Prozessor für Datenbanksprachen wie SQL bereitstellen, um Anwendungen zur Interaktion mit der Datenbank zu erstellen. Ein besonderer Zweck DBMS kann eine private API verwenden und speziell an eine einzelne Anwendung angepasst und verknüpft werden. Zum Beispiel ein E-Mail-System, das viele der Funktionen eines allgemeinen DBMS wie Nachrichteneinfügung, Nachrichtenlöschung, Anhängehandhabung, Blocklist-Lookup, Assoziierung von Nachrichten eine E-Mail-Adresse und so weiter, aber diese Funktionen sind auf das beschränkt, was zum Umgang mit E-Mail erforderlich ist. Anwendung Externe Interaktion mit der Datenbank wird über ein Anwendungsprogramm, das mit dem DBMS Schnittstelle. Dies kann von einem Datenbank-Tool reichen, das Benutzern erlaubt, SQL-Abfragen textuell oder grafisch auszuführen, zu einer Website, die zufällig eine Datenbank verwendet, um Informationen zu speichern und zu suchen. Anwendungsprogrammschnittstelle Ein Programmierer wird über eine Applikationsprogrammschnittstelle (API) oder über eine Datenbanksprache Interaktionen zur Datenbank (manchmal als Datenquelle bezeichnet) kodieren. Die ausgewählte API oder Sprache muss von DBMS unterstützt werden, die indirekt über einen Preprozessor oder eine Überbrückungs-API möglich ist. Einige APIs Ziel, Datenbank unabhängig zu sein, ODBC ist ein allgemein bekanntes Beispiel. Andere gemeinsame APIs umfassen JDBC und ADO. NET Datenbanksprachen Datenbanksprachen sind Spezialsprachen, die eine oder mehrere der folgenden Aufgaben zulassen, die sich manchmal als Untersprachen auszeichnen: Datensteuerungssprache (DCL) – steuert Zugriff auf Daten; Datendefinitionssprache (DDL) – definiert Datentypen wie das Erstellen, Ändern oder Ablegen von Tabellen und deren Zusammenhänge; Datenmanipulationssprache (DML) – führt Aufgaben wie das Einfügen, Aktualisieren oder Löschen von Datenereignissen durch; Datenabfragesprache (DQL) – ermöglicht die Suche nach Informationen und die Berechnung abgeleiteter Informationen. Datenbanksprachen sind für ein bestimmtes Datenmodell spezifisch. Wichtige Beispiele sind: SQL kombiniert die Rollen der Datendefinition, Datenmanipulation und Abfrage in einer einzigen Sprache. Es war eine der ersten Handelssprachen für das relationale Modell, obwohl es in gewisser Hinsicht von dem von Codd beschriebenen relationalen Modell abweicht (z.B. Zeilen und Spalten einer Tabelle können bestellt werden). SQL wurde 1986 zum Standard des American National Standards Institute (ANSI) und der International Organization for Standardization (ISO) im Jahr 1987. Die Standards wurden seitdem regelmäßig verbessert und werden von allen gängigen handelsbezogenen DBMSs unterstützt (mit unterschiedlichem Maß an Übereinstimmung). OQL ist ein Objektmodell-Sprachstandard (aus der Object Data Management Group). Es hat das Design einiger der neueren Abfragesprachen wie JDOQL und EJB QL beeinflusst. XQuery ist eine Standard-XML-Abfragesprache, die von XML-Datenbanksystemen wie MarkLogic und eXist, von relationalen Datenbanken mit XML-Fähigkeit wie Oracle und DB2 sowie von in-memory XML-Prozessoren wie Saxon implementiert wird. SQL/XML kombiniert XQuery mit SQL. Eine Datenbanksprache kann auch Funktionen wie: DBMS-spezifische Konfiguration und Speicher-Engine-Management Computations, um Abfrageergebnisse zu ändern, wie Zählen, Summieren, Mittelieren, Sortieren, Gruppieren, und Cross-Referencing Constraint Durchsetzung (z.B. in einer Automotive-Datenbank, nur einen Motortyp pro Auto zuzulassen)Anwendungs-Programmierschnittstellenversion der Abfragesprache, für Programmierer Bequemlichkeit Storage Datenbankspeicher ist der Container der physischen der Materialisierung einer Datenbank. Es umfasst die interne (physikalische) Ebene in der Datenbankarchitektur. Es enthält auch alle benötigten Informationen (z.B. Metadaten, "Daten über die Daten" und interne Datenstrukturen), um die konzeptionelle Ebene und externe Ebene bei Bedarf von der internen Ebene zu rekonstruieren. Daten in permanente Speicherung zu bringen, ist in der Regel die Verantwortung der Datenbank-Engine a.k.a."storage Engine". Obwohl typischerweise von einem DBMS über das zugrunde liegende Betriebssystem (und oft mit den Dateisystemen der Betriebssysteme als Zwischenprodukte für das Speicherlayout) Zugriff genommen wird, sind Speichereigenschaften und Konfigurationseinstellungen für den effizienten Betrieb des DBMS von großer Bedeutung und werden somit von Datenbankadministratoren genau eingehalten. Ein DBMS hat im Betrieb immer seine Datenbank mit mehreren Speicherarten (z.B. Speicher und externe Speicher). Die Datenbankdaten und die zusätzlichen benötigten Informationen, gegebenenfalls in sehr großen Mengen, werden in Bits kodiert. Die Daten liegen in der Regel in der Speicherung in Strukturen, die völlig anders aussehen als die Art und Weise, wie die Daten in der konzeptionellen und externen Ebene aussehen, aber in der Weise, die versuchen, die Rekonstruktion dieser Ebenen zu optimieren (die bestmögliche) bei Bedarf von Benutzern und Programmen, sowie für die Berechnung zusätzlicher Arten von benötigten Informationen aus den Daten (z.B. bei der Abfrage der Datenbank). Einige Unterstützung von DBMSs, welche Zeichencodierung verwendet wurde, um Daten zu speichern, so können mehrere Kodierungen in derselben Datenbank verwendet werden. Verschiedene Low-Level-Datenbank-Speicherstrukturen werden vom Speichermotor verwendet, um das Datenmodell zu serialisieren, so dass es auf das Medium der Wahl geschrieben werden kann. Techniken wie die Indexierung können verwendet werden, um die Leistung zu verbessern. Herkömmliche Speicherung ist zeilenorientiert, es gibt aber auch spaltenorientierte und Korrelationsdatenbanken. Materialisierte Ansichten Oft wird Speicher Redundanz verwendet, um die Leistung zu erhöhen. Ein gemeinsames Beispiel ist die Speicherung von materialisierten Ansichten, die aus häufig benötigten externen Ansichten oder Abfrageergebnissen bestehen. Das Speichern solcher Ansichten spart die teure Berechnung von ihnen jedes Mal, wenn sie benötigt werden. Die Nachteile der materialisierten Ansichten sind der Overhead, der bei der Aktualisierung entstanden ist, um sie mit ihren ursprünglichen aktualisierten Datenbankdaten synchron zu halten, und die Kosten für die Speicherredundanz. Wiederholung Gelegentlich verwendet eine Datenbank Speicherredundanz durch Datenbankobjekte Replikation (mit einer oder mehreren Kopien), um die Datenverfügbarkeit zu erhöhen (beide um die Leistung von gleichzeitigen mehreren Endbenutzern Zugriffen auf ein gleiches Datenbankobjekt zu verbessern und Widerstandsfähigkeit bei teilweisem Ausfall einer verteilten Datenbank zu bieten). Updates eines replizierten Objekts müssen über die Objektkopien synchronisiert werden. In vielen Fällen wird die gesamte Datenbank repliziert. Security Database Security befasst sich mit allen verschiedenen Aspekten des Schutzes der Datenbankinhalte, ihrer Eigentümer und ihrer Nutzer. Es reicht vom Schutz vor beabsichtigten unbefugten Datenbanken bis hin zu unbeabsichtigten Datenbankzugriffen durch unbefugte Einrichtungen (z.B. eine Person oder ein Computerprogramm). Datenbankzugriffskontrolle befasst sich mit der Kontrolle, wer (eine Person oder ein bestimmtes Computerprogramm) auf welche Informationen in der Datenbank zugreifen darf. Die Informationen können bestimmte Datenbankobjekte umfassen (z.B. Datentypen, bestimmte Datensätze, Datenstrukturen), bestimmte Berechnungen über bestimmte Objekte (z.B. Abfragetypen oder bestimmte Abfragen) oder bestimmte Zugriffspfade zu dem ersten (z.B. mit bestimmten Indexen oder anderen Datenstrukturen zur Zugriffsinformation). Datenbankzugriffskontrollen werden durch spezielle autorisierte (vom Datenbankbesitzer) Mitarbeiter eingestellt, die spezielle geschützte Sicherheits-DBMS-Schnittstellen verwenden. Dies kann direkt auf individueller Basis oder durch die Zuordnung von Individuen und Privilegien zu Gruppen oder (in den aufwändigsten Modellen) durch die Zuordnung von Individuen und Gruppen zu Rollen, die dann Berechtigungen erhalten. Datensicherheit verhindert, dass unbefugte Benutzer die Datenbank ansehen oder aktualisieren. Mit Passwörtern, Benutzer sind erlaubt Zugriff auf die gesamte Datenbank oder Untergruppen davon genannt Unterschemas". Beispielsweise kann eine Mitarbeiterdatenbank alle Daten über einen einzelnen Mitarbeiter enthalten, aber eine Gruppe von Nutzern kann berechtigt sein, nur Payroll-Daten anzuzeigen, während andere Zugriff auf nur Arbeitsgeschichte und medizinische Daten haben. Wenn das DBMS eine Möglichkeit bietet, die Datenbank interaktiv einzutragen und zu aktualisieren, sowie sie zu verhören, ermöglicht diese Möglichkeit, persönliche Datenbanken zu verwalten. Die Datensicherheit befasst sich im Allgemeinen mit dem Schutz spezifischer Datenklumpen, sowohl physisch (d.h. vor Korruption, Zerstörung oder Entfernung; z.B. siehe physische Sicherheit), oder deren Interpretation, oder Teilen von ihnen zu aussagekräftigen Informationen (z.B. durch die Betrachtung der Bitfolgen, die sie enthalten, zum Abschluss bestimmter gültiger Kreditkartennummern; z.B. siehe Datenverschlüsselung). Ändern und Zugriffsprotokolle, die auf die Attribute zugreifen, was geändert wurde, und wenn es geändert wurde. Logging-Dienste ermöglichen eine forensische Datenbank-Audit später, indem eine Aufzeichnung von Zugriffserscheinungen und Änderungen. Manchmal wird Anwendungs-Level-Code verwendet, um Änderungen aufzuzeichnen, anstatt diese in die Datenbank zu lassen. Die Überwachung kann eingerichtet werden, um Sicherheitsverletzungen zu erkennen. Transaktionen und Koncurrency-Datenbanktransaktionen können verwendet werden, um einige Maß an Fehlertoleranz und Datenintegrität nach der Wiederherstellung von einem Crash einzuführen. Eine Datenbanktransaktion ist eine Arbeitseinheit, die typischerweise eine Anzahl von Operationen über eine Datenbank (z.B. Lesen eines Datenbankobjekts, Schreiben, Erfassen von Schloss usw.) verkapselt, eine in Datenbank und auch andere Systeme unterstützte Abstraktion.Jede Transaktion hat genau definierte Grenzen, in denen Programm-/Codeausführungen in diese Transaktion einbezogen werden (bestimmt durch den Programmierer der Transaktion über spezielle Transaktionsbefehle). Das Akronym ACID beschreibt einige ideale Eigenschaften einer Datenbanktransaktion: Atomizität, Konsistenz, Isolation und Haltbarkeit. Migration Eine Datenbank, die mit einem DBMS aufgebaut ist, ist nicht für ein anderes DBMS (d.h. das andere DBMS kann es nicht ausführen). In manchen Fällen ist es jedoch wünschenswert, eine Datenbank von einem DBMS zum anderen zu migrieren. Die Gründe sind vor allem wirtschaftlich (verschiedene DBMSs können unterschiedliche Gesamtkosten des Eigentums oder TCOs haben), funktionell und betriebsfähig (verschiedene DBMS können unterschiedliche Fähigkeiten haben). Die Migration beinhaltet die Transformation der Datenbank von einem DBMS-Typ zum anderen. Die Transformation sollte (wenn möglich) die Datenbank-bezogene Anwendung (d.h. alle verwandten Applikationsprogramme) intakt halten. So sollte die konzeptionelle und externe Architektur der Datenbank in der Transformation beibehalten werden. Es kann erwünscht sein, dass auch einige Aspekte der Architektur interne Ebene beibehalten werden. Eine komplexe oder große Datenbankmigration kann ein kompliziertes und kostspieliges (einmaliges) Projekt selbst sein, das in die Entscheidung zur Migration einbezogen werden sollte. Dies trotz der Tatsache, dass Werkzeuge existieren können, um Migration zwischen bestimmten DBMSs zu helfen. Typischerweise bietet ein DBMS-Anbieter Tools, um Datenbanken von anderen beliebten DBMSs zu importieren. Aufbau, Wartung und Tuning Nach der Erstellung einer Datenbank für eine Anwendung baut die nächste Stufe die Datenbank. Typischerweise kann dazu eine entsprechende universelle DBMS gewählt werden. Ein DBMS bietet die benötigten Benutzeroberflächen, die von Datenbankadministratoren verwendet werden, um die Datenstrukturen der benötigten Applikation innerhalb des jeweiligen Datenmodells der DBMS zu definieren. Andere Benutzeroberflächen werden verwendet, um benötigte DBMS-Parameter auszuwählen (wie z.B. sicherheitsrelevante, Speicherzuordnungsparameter usw.). Wenn die Datenbank bereit ist (alle Datenstrukturen und andere benötigte Komponenten definiert sind), wird sie typischerweise mit den Daten der Erstanwendung (Datenbankan initialisation, die typischerweise ein ausgeprägtes Projekt ist; in vielen Fällen mit spezialisierten DBMS-Schnittstellen, die die Masseneinfügung unterstützen) bevölkert, bevor sie betriebsbereit ist. In einigen Fällen wird die Datenbank funktionsfähig, während die Anwendungsdaten leer sind, und die Daten werden während ihres Betriebs akkumuliert. Nachdem die Datenbank erstellt, initialisiert und besiedelt wird, muss sie gepflegt werden. Verschiedene Datenbank-Parameter müssen sich ändern und die Datenbank kann für eine bessere Leistung gestimmt werden müssen; die Datenstrukturen der Anwendung können geändert oder hinzugefügt werden, neue verwandte Anwendungsprogramme können geschrieben werden, um die Funktionalität der Anwendung hinzuzufügen, etc. Backup und WiederherstellungManchmal ist es erwünscht, eine Datenbank wieder in einen vorherigen Zustand zu bringen (aus vielen Gründen, z.B. Fälle, in denen die Datenbank aufgrund eines Softwarefehlers beschädigt gefunden wird, oder wenn sie mit fehlerhaften Daten aktualisiert wurde). Um dies zu erreichen, wird gelegentlich oder kontinuierlich ein Backup-Betrieb durchgeführt, bei dem jeder gewünschte Datenbankzustand (d.h. die Werte seiner Daten und deren Einbettung in Datenstrukturen der Datenbank) in dedizierten Backup-Dateien gehalten wird (viele Techniken existieren, um dies effektiv zu tun). Wenn es von einem Datenbankadministrator beschlossen wird, die Datenbank wieder in diesen Zustand zu bringen (z.B. durch Angabe dieses Zustands um einen gewünschten Zeitpunkt, wenn die Datenbank in diesem Zustand war), werden diese Dateien verwendet, um diesen Zustand wiederherzustellen. Statische Analyse Statische Analysetechniken zur Softwareverifikation können auch im Szenario von Abfragesprachen angewendet werden. Insbesondere wurde der *Abstract-Interpretationsrahmen auf den Bereich der Abfragesprachen für relationale Datenbanken erweitert, um Sound Approximationstechniken zu unterstützen. Die Semantik von Abfragesprachen kann nach geeigneten Abstraktionen der konkreten Datendomäne abgestimmt werden. Die Abstraktion des relationalen Datenbanksystems hat viele interessante Anwendungen, insbesondere für Sicherheitszwecke, wie z.B. Feinkornzugangskontrolle, Wasserzeichen usw. Verschiedene Merkmale Andere DBMS-Funktionen können: Datenbankprotokolle – Dies hilft, eine Geschichte der ausgeführten Funktionen zu halten. Grafische Komponente zur Erstellung von Diagrammen und Diagrammen, insbesondere in einem Datenlagersystem. Query Optimierer – Führen Sie die Abfrageoptimierung auf jeder Abfrage durch, um einen effizienten Abfrageplan (eine Teilreihenfolge) zu wählen, der zur Berechnung des Abfrageergebnisses ausgeführt werden soll. Kann speziell für einen bestimmten Speichermotor sein. Werkzeuge oder Haken für Datenbankdesign, Anwendungsprogrammierung, Anwendungsprogrammwartung, Datenbank-Leistungsanalyse und -überwachung, Datenbankkonfigurationsüberwachung, DBMS-Hardwarekonfiguration (eine DBMS und verwandte Datenbank kann Computer, Netzwerke und Speichereinheiten überspannen) und zugehörige Datenbank-Mapping (insbesondere für eine verteilte DBMS), Speicherzuordnung und Datenbank-Layout-Überwachung, Speichermigration usw. Zunehmend gibt es Aufrufe für ein einziges System, das all diese Kernfunktionalitäten in den gleichen Build-, Test- und Bereitstellungsrahmen für die Datenbankverwaltung und Quellkontrolle einbezieht. Aus anderen Entwicklungen in der Softwarebranche gründen sich einige Marktangebote wie "DevOps for Database". Design und Modellierung Die erste Aufgabe eines Datenbank-Designers besteht darin, ein konzeptionelles Datenmodell zu erstellen, das die Struktur der in der Datenbank abzuhaltenden Informationen widerspiegelt. Ein gemeinsamer Ansatz hierfür ist die Entwicklung eines Entity-Relationship-Modells, oft mit Hilfe von Ziehwerkzeugen. Ein weiterer beliebter Ansatz ist die Unified Modeling Language. Ein erfolgreiches Datenmodell wird den möglichen Zustand der modellierten Außenwelt genau widerspiegeln: beispielsweise, wenn Menschen mehr als eine Telefonnummer haben können, wird es die Erfassung dieser Informationen ermöglichen. Die Gestaltung eines guten konzeptionellen Datenmodells erfordert ein gutes Verständnis der Anwendungsdomäne; es beinhaltet in der Regel, tiefe Fragen über die Dinge von Interesse an einer Organisation zu stellen, wie "kann ein Kunde auch ein Lieferant sein?", oder "wenn ein Produkt mit zwei verschiedenen Verpackungsformen verkauft wird, sind das gleiche Produkt oder verschiedene Produkte?", oder "wenn ein Flugzeug von New York nach Dubai über Frankfurt fliegt, ist das ein oder zwei (oder vielleicht sogar drei)?" Die Antworten auf diese Fragen legen Definitionen der Terminologie fest, die für Unternehmen (Kunden, Produkte, Flüge, Flugsegmente) und deren Beziehungen und Attribute verwendet wird. Die Erstellung des konzeptionellen Datenmodells beinhaltet manchmal die Eingabe von Geschäftsprozessen oder die Analyse des Workflows in der Organisation. Dies kann dazu beitragen, zu ermitteln, welche Informationen in der Datenbank benötigt werden und was ausgelassen werden kann. Beispielsweise kann es bei der Entscheidung helfen, ob die Datenbank historische Daten sowie aktuelle Daten speichern muss. Nach der Erstellung eines konzeptionellen Datenmodells, mit dem Nutzer zufrieden sind, soll dies in ein Schema übersetzt werden, das die relevanten Datenstrukturen innerhalb der Datenbank implementiert. Dieser Vorgang wird oft als logisches Datenbankdesign bezeichnet, und die Ausgabe ist ein logisches Datenmodell, das in Form eines Schemas ausgedrückt wird. Während das konzeptionelle Datenmodell (in der Theorie zumindest) unabhängig von der Wahl der Datenbanktechnologie ist, wird das logische Datenmodell in Bezug auf ein bestimmtes Datenbankmodell ausgedrückt, das vom gewählten DBMS unterstützt wird.( Die Begriffe Datenmodell und Datenbankmodell werden oft austauschbar verwendet, aber in diesem Artikel verwenden wir Datenmodell für die Gestaltung einer bestimmten Datenbank und Datenbankmodell für die Modellierungsnotation, die verwendet wird, um dieses Design auszudrücken). Das beliebteste Datenbankmodell für allgemeine Datenbanken ist das relationale Modell oder genauer das relationale Modell, wie es durch die SQL-Sprache dargestellt wird. Der Prozess der Erstellung einer logischen Datenbank-Design mit diesem Modell verwendet einen methodischen Ansatz als Normalisierung bekannt. Ziel der Normalisierung ist es, sicherzustellen, dass jede elementare Tatsache nur an einer Stelle aufgezeichnet wird, so dass Einfügungen, Aktualisierungen und Löschungen die Konsistenz automatisch beibehalten. Die letzte Phase der Datenbank-Design ist, die Entscheidungen zu treffen, die die Leistung, Skalierbarkeit, Erholung, Sicherheit und dergleichen beeinflussen, die von dem jeweiligen DBMS abhängen. Dies wird oft als physikalisches Datenbankdesign bezeichnet, und die Ausgabe ist das physikalische Datenmodell. Ein zentrales Ziel in dieser Phase ist die Datenunabhängigkeit, was bedeutet, dass die für die Optimierung der Leistungen getroffenen Entscheidungen für Endnutzer und Anwendungen unsichtbar sein sollten. Es gibt zwei Arten von Datenunabhängigkeit: Physikalische Datenunabhängigkeit und logische Datenunabhängigkeit. Physikalisches Design wird hauptsächlich durch Leistungsanforderungen angetrieben und erfordert eine gute Kenntnis der erwarteten Workload- und Access-Muster und ein tiefes Verständnis der Funktionen des gewählten DBMS. Ein weiterer Aspekt der physischen Datenbankgestaltung ist die Sicherheit. Es umfasst sowohl die Definition der Zugriffskontrolle auf Datenbankobjekte als auch die Definition von Sicherheitsstufen und Methoden für die Daten selbst. Modelle Ein Datenbankmodell ist eine Art Datenmodell, das die logische Struktur einer Datenbank bestimmt und grundsätzlich bestimmt, in welcher Weise Daten gespeichert, organisiert und manipuliert werden können. Das beliebteste Beispiel für ein Datenbankmodell ist das relationale Modell (oder die SQL Approximation von relational), das ein tabellenbasiertes Format verwendet. Gemeinsame logische Datenmodelle für Datenbanken umfassen: Navigationsdatenbanken Hierarchisches Datenbankmodell Netzwerkmodell Graph Datenbank Relational model Entity–Relationship model Enhanced Entity–relationship model Objektmodell Dokumentmodell Entity–attribute–value model Star schema Eine Objekt-Relationsdatenbank kombiniert die beiden zugehörigen Strukturen. Physikalische Datenmodelle umfassen: Invertierter Index Flache Datei Weitere Modelle umfassen: Assoziatives Modell Multidimensionales Modell Array Modell Multivalue modelSpecialized Modelle sind für bestimmte Arten von Daten optimiert: XML Datenbank Semantic model Content store Event Store Time series model Externe, konzeptionelle und interne Ansichten Ein Datenbankmanagementsystem bietet drei Ansichten der Datenbankdaten: Die externe Ebene definiert, wie jede Gruppe von Endnutzern die Organisation von Daten in der Datenbank sieht. Eine einzige Datenbank kann eine beliebige Anzahl von Ansichten auf der externen Ebene haben. Die konzeptionelle Ebene vereint die verschiedenen externen Ansichten in eine kompatible globale Sicht. Es bietet die Synthese aller externen Ansichten. Es ist aus dem Umfang der verschiedenen Datenbank-Endbenutzer und ist eher von Interesse für Datenbank-Anwendungsentwickler und Datenbankadministratoren. Die interne Ebene (oder physische Ebene) ist die interne Organisation von Daten innerhalb eines DBMS. Es geht um Kosten, Leistung, Skalierbarkeit und andere betriebliche Fragen. Es befasst sich mit dem Speicherlayout der Daten, mit Speicherstrukturen wie Indexen, um die Leistung zu verbessern. Gelegentlich speichert es Daten von einzelnen Ansichten (materialisierte Ansichten), berechnet aus generischen Daten, wenn für solche Redundanz eine Leistungsberechtigung vorliegt. Es ausgeglichen alle Leistungsanforderungen der externen Ansichten, die möglicherweise widersprüchlich sind, um die Gesamtleistung über alle Aktivitäten zu optimieren. Während in der Regel nur eine konzeptuelle (oder logische) und physische (oder interne) Ansicht der Daten vorhanden ist, kann es eine beliebige Anzahl von verschiedenen externen Ansichten geben. Dies ermöglicht es Benutzern, Datenbankinformationen geschäftsbezogener zu sehen, anstatt von einem technischen, prozessierenden Standpunkt. Zum Beispiel benötigt eine Finanzabteilung eines Unternehmens die Zahlungsdetails aller Mitarbeiter im Rahmen der Aufwendungen des Unternehmens, benötigt aber keine Details über Mitarbeiter, die das Interesse der Personalabteilung sind. So benötigen verschiedene Abteilungen unterschiedliche Ansichten der Unternehmensdatenbank. Die dreistufige Datenbankarchitektur bezieht sich auf das Konzept der Datenunabhängigkeit, das eine der wichtigsten anfänglichen Antriebskräfte des relationalen Modells war. Die Idee ist, dass Änderungen auf einer bestimmten Ebene die Ansicht auf einer höheren Ebene nicht beeinflussen. Beispielsweise beeinflussen Änderungen in der internen Ebene keine Anwendungsprogramme, die mit konzeptionellen Level-Schnittstellen geschrieben werden, was die Auswirkungen der physischen Veränderungen zur Leistungsverbesserung reduziert. Die konzeptionelle Sicht bietet eine Richtungsebene zwischen innen und außen. Auf der einen Seite bietet sie eine gemeinsame Sicht auf die Datenbank, unabhängig von unterschiedlichen externen Sichtstrukturen, und auf der anderen Seite zieht sie Details davon ab, wie die Daten gespeichert oder verwaltet werden (interne Ebene). Grundsätzlich kann jede Ebene und sogar jede externe Ansicht durch ein anderes Datenmodell dargestellt werden. In der Praxis verwendet ein vorgegebenes DBMS in der Regel das gleiche Datenmodell sowohl für die externen als auch für die konzeptionellen Ebenen (z.B. relationales Modell). Die interne Ebene, die innerhalb der DBMS versteckt ist und von ihrer Implementierung abhängt, erfordert ein anderes Detail und verwendet eigene Arten von Datenstrukturtypen. Die Trennung der externen, konzeptionellen und internen Ebenen war ein wichtiges Merkmal der relationalen Datenbankmodell-Implementierungen, die die Datenbanken des 21. Jahrhunderts dominieren. Forschung Datenbanktechnologie ist seit den 1960er Jahren ein aktives Forschungsthema, sowohl in der Wissenschaft als auch in den Forschungs- und Entwicklungsgruppen von Unternehmen (z.B. IBM Research). Die Forschungstätigkeit umfasst Theorie und Entwicklung von Prototypen. Bemerkenswerte Forschungsthemen sind Modelle, das Atomtransaktionskonzept und verwandte Konkurrenzkontrolltechniken, Abfragesprachen und Abfrageoptimierungsmethoden, RAID und vieles mehr. Das Datenbankforschungsgebiet verfügt über mehrere akademische Fachzeitschriften (z.B. ACM Transactions on Database Systems-TODS, Data and Knowledge Engineering-DKE) und jährliche Konferenzen (z.B. ACM SIGMOD, ACM PODS, VLDB, IEEE ICDE). Siehe auch Anmerkungen Quellen Quellen Weiter lesen Ling Liu und Tamer M. Özsu (Hrsg.) (2009.) "Encyclopedia of Database Systems, 4100 p. 60 illus. ISBN 978-0-387-49616-0.Gray, J. and Reuter, A. Transaction Processing: Concepts and Techniques, 1. Auflage, Morgan Kaufmann Publishers, 1992. Kroenke, David M. und David J. Auer. Datenbank Concepts.3rd ed.New York: Prentice, 2007. Raghu Ramakrishnan und Johannes Gehrke, Datenbank Management Systems Abraham Silberschatz, Henry F. Korth, S. Sudarshan, Datenbank System Concepts Lightstone, S.; Teorey, T.; Nadeau, T. (2007). Physical Database Design: der Leitfaden für Datenbank-Profis, um Indexe, Ansichten, Speicher und mehr auszunutzen. Morgan Kaufmann Press.ISBN 978-0-12-369389-1. Teorey, T.; Lightstone, S. und Nadeau, T. Datenbank Modellierung & Design: Logical Design, 4. Auflage, Morgan Kaufmann Press, 2005.ISBN 0-12-685352-5 Externe Links DB Dateiendung – Informationen über die Dateien mit der DB-Erweiterung