Das Lernen zum Rangieren oder maschinelles Lernen (MLR) ist die Anwendung von maschinellem Lernen, typischerweise überwachtes, semi-supervisiertes oder Verstärkungslernen, im Aufbau von Ranking-Modellen für Informationsabrufsysteme. Die Trainingsdaten bestehen aus Listen von Artikeln mit einer Teilauftragsnummer, die in jeder Liste angegeben ist. Diese Reihenfolge wird typischerweise durch Angabe einer numerischen oder ordinalen Partitur oder eines binären Urteils (z.B. relevant oder "nicht relevant") für jeden Gegenstand induziert. Das Ranking-Modell dient zum Ranking, d.h. zum Erzeugen einer Permutation von Gegenständen in neuen, nicht-enen Listen in ähnlicher Weise wie Rankings in den Trainingsdaten. Anwendungen In der Informationsabruf-Ranking ist ein zentraler Teil vieler Informationsabrufprobleme, wie Dokumentenabruf, kollaborative Filterung, Stimmungsanalyse und Online-Werbung. Eine mögliche Architektur einer maschinengeführten Suchmaschine ist in der beigefügten Abbildung dargestellt. Trainingsdaten bestehen aus Abfragen und Dokumenten, die sie zusammen mit Relevanz Grad jedes Matches anpassen. Es kann manuell von menschlichen Bewertern (oder Ratgebern, wie Google sie anruft) erstellt werden, die Ergebnisse für einige Abfragen überprüfen und die Relevanz jedes Ergebnisses bestimmen. Es ist nicht möglich, die Relevanz aller Dokumente zu überprüfen, und so wird typischerweise eine Technik namens Pooling verwendet — nur die wenigen Top-Dokumente, die von einigen vorhandenen Ranking-Modellen abgerufen werden überprüft. Alternativ können Trainingsdaten automatisch durch die Analyse von Clickthrough-Logs (d.h. Suchergebnissen, die Klicks von Benutzern erhalten haben), Abfrageketten oder Funktionen von Suchmaschinen als Google's SearchWiki abgeleitet werden. Trainingsdaten werden von einem Lernalgorithmus zur Erstellung eines Rankingmodells verwendet, das die Relevanz von Dokumenten für aktuelle Abfragen berechnet. Typischerweise erwarten die Nutzer eine Suchanfrage, um in kurzer Zeit (z.B. ein paar hundert Millisekunden für die Websuche) abzuschließen, die es unmöglich macht, ein komplexes Ranking-Modell auf jedem Dokument im Korpus auszuwerten, so dass ein zweiphasiges Schema verwendet wird. Zunächst werden eine geringe Anzahl potenziell relevanter Dokumente anhand einfacherer Retrievalmodelle identifiziert, die eine schnelle Abfrageauswertung erlauben, wie z.B. das Vektorraummodell, das boolesche Modell, gewichtet UND oder BM25. Diese Phase wird als top- k \{displaystyle k} Dokument-Retrieval und viele heuristics wurden in der Literatur vorgeschlagen, um es zu beschleunigen, wie die Verwendung eines Dokuments statische Qualität Score und binred Indizes. In der zweiten Phase wird ein genaueres, aber rechnerisch teures maschinengeführtes Modell verwendet, um diese Dokumente neu zu ordnen. In anderen Bereichen wurden Algorithmen in anderen Bereichen als Informationsabruf genutzt: In der maschinellen Übersetzung zum Ranking einer Reihe von hypothetischen Übersetzungen; In der Rechenbiologie für Ranking Kandidaten 3-D Strukturen in Proteinstruktur Prädiktion Problem. In Empfehlungssystemen zur Identifizierung einer Liste von verwandten Nachrichtenartikeln, um einem Benutzer zu empfehlen, nachdem er oder sie einen aktuellen Nachrichtenartikel gelesen hat. In der Softwaretechnik wurden Lern-zu-Rank-Methoden zur Fehlerlokalisierung eingesetzt. Merkmalsvektoren Zur Bequemlichkeit von MLR-Algorithmen werden in der Regel Abfrage-Dokumentationspaare durch numerische Vektoren dargestellt, die als Merkmalsvektoren bezeichnet werden. Ein solcher Ansatz wird manchmal als Beutel von Merkmalen bezeichnet und ist analog zu der Tasche von Wörtern Modell und Vektor-Raum-Modell in der Informationsabruf für die Darstellung von Dokumenten verwendet. Komponenten solcher Vektoren werden Merkmale, Faktoren oder Rankingsignale genannt. Sie können in drei Gruppen eingeteilt werden (Beispiele sind:) Quer-unabhängige oder statische Merkmale — solche Merkmale, die nur vom Dokument abhängen, nicht aber von der Abfrage. Zum Beispiel PageRank oder Dokumentlänge. Solche Merkmale können während der Indexierung im Offline-Modus vorgerechnet werden. Sie können verwendet werden, um die statische Qualität des Dokuments (oder statischer Rang) zu berechnen, die oft verwendet wird, um die Suchanfragenauswertung zu beschleunigen. Query-abhängige oder dynamische Merkmale - solche Merkmale, die sowohl vom Inhalt des Dokuments als auch von der Abfrage, wie TF-IDF-Score oder anderen nicht-maschinenlesbaren Ranking-Funktionen, abhängen. Query-Level-Features oder Abfrage-Features, die nur von der Abfrage abhängen. Beispielsweise die Anzahl der Wörter in einer Abfrage. Einige Beispiele von Features, die im bekannten LETOR-Datensatz verwendet wurden: TF, TF-IDF, BM25 und Sprachmodellierungspunkte der Dokumentzonen (Titel, Körper, Ankertext, URL) für eine bestimmte Abfrage; Längen und IDF-Summen der Dokumentzonen; Document's PageRank, HITS Ranks und ihre Varianten. Die Auswahl und Gestaltung guter Features ist ein wichtiger Bereich im maschinellen Lernen, der als Feature Engineering bezeichnet wird. Evaluierungsmaßnahmen Es gibt mehrere Maßnahmen (Metriken), die häufig verwendet werden, um zu beurteilen, wie gut ein Algorithmus auf Trainingsdaten macht und die Leistung verschiedener MLR-Algorithmen zu vergleichen. Oft wird ein Lern-zu-Rank-Problem als Optimierungsproblem bezüglich einer dieser Metriken reformiert. Beispiele für Ranking-Qualitätsmaßnahmen: Mittlere mittlere Präzision (MAP); DCG und NDCG; Precision@n, NDCG@n, wobei @n bedeutet, dass die Metriken nur auf den oben n Dokumenten ausgewertet werden; Mean reciprocal Rang; Kendalls tau; Spearman's rho. DCG und seine normalisierte Variante NDCG werden in der akademischen Forschung in der Regel bevorzugt, wenn mehrere Relevanzstufen verwendet werden. Andere Metriken wie MAP, MRR und Präzision sind nur für binäre Urteile definiert. In jüngster Zeit wurden mehrere neue Bewertungsmetriken vorgeschlagen, die die Zufriedenheit der Nutzer mit Suchergebnissen besser modellieren als die DCG-Maße: Erwartete gegenseitige Rang (ERR); Yandexs Pfund. Beide dieser Metriken beruhen auf der Annahme, dass der Nutzer nach der Prüfung eines relevanteren Dokuments wahrscheinlicher aufhören wird, die Suchergebnisse zu betrachten, als nach einem weniger relevanten Dokument. Tie-Yan Liu von Microsoft Research Asia hat bereits bestehende Algorithmen analysiert, um Probleme in seinem Buch Lernen zum Rank für Information Retrieval zu ordnen. Er kategorisiert sie in drei Gruppen durch ihre Eingaberäume, Ausgaberäume, Hypothesenräume (die Kernfunktion des Modells) und Verlustfunktionen: der punktweise, paarweise und listenweise Ansatz. In der Praxis übertreffen listenweise Ansätze oft paarweise Ansätze und punktuelle Ansätze. Diese Aussage wurde durch ein umfangreiches Experiment zur Durchführung verschiedener Lern-zu-Rank-Methoden auf einer großen Sammlung von Benchmark-Datensätzen weiter unterstützt. In diesem Abschnitt bedeutet x \{displaystyle x} ein zu evaluierendes Objekt, z.B. ein Dokument oder ein Bild, f ( x ) \{displaystyle f(x}) eine einwertige Hypothese, h ( ) \{displaystyle h(\cdot )} eine bi-variate oder multivariate Funktionen Funktion und L (Leben) \{display funktion. Point-of-Ansatz Dabei wird davon ausgegangen, dass jedes Abfrage-Dokument-Paar in den Trainingsdaten eine numerische oder ordinale Score aufweist. Dann kann das Lern-zu-Rank-Problem durch ein Regressions-Problem angenähert werden — bei einem einzigen Abfrage-Dokument-Paar, prognostizieren Sie seine Punktzahl. Der punktweise Ansatz zielt darauf ab, eine Funktion f ( x ) \{displaystyle f(x}) zu erlernen, die den realen Wert oder die ordinale Score eines Dokuments x \{displaystyle x} anhand der Verlustfunktion L (f, x j, y ) \{displaystyle L(f,x_{j},y_{j) vorhersagt. Für diesen Zweck können eine Reihe bestehender überwachter maschineller Lernalgorithmen problemlos eingesetzt werden. Ordinalregressions- und Klassifikationsalgorithmen können auch in Pointwise-Ansatz verwendet werden, wenn sie verwendet werden, um die Punktzahl eines einzelnen Abfrage-Dokument-Paares vorherzusagen, und es nimmt eine kleine, endliche Anzahl von Werten. Paarweise In diesem Fall wird das Lern-zu-Rank-Problem durch ein Klassifikationsproblem angenähert - ein binäres Klassifikator h ( x u, x v ) \{displaystyle h(x_{u},x_{v) zu erlernen, welches Dokument in einem bestimmten Paar von Dokumenten besser ist. Der Klassifikator hat zwei Bilder als Eingabe und das Ziel ist, eine Verlustfunktion L (h ; x u , x v , y u , v ) \{displaystyle L(h;x_{u},x_{v},y_{u,v) zu minimieren. Die Verlustfunktion kann die durchschnittliche Anzahl der Inversionen im Ranking widerspiegeln. In vielen Fällen wird der binäre Klassifikator h ( x u, x v ) \{displaystyle h(x_{u},x_{v) mit einer Scoring-Funktion f ( x ) \{displaystyle f(x}) implementiert. Als Beispiel passt RankNet ein Wahrscheinlichkeitsmodell an und definiert h (x u, x v ) \{displaystyle h(x_{u},x_{v) als geschätzte Wahrscheinlichkeit des Dokuments x v \{displaystyle x_{v} eine höhere Qualität als x v \{displaystyle x_{v} \{displaystyle text{CDF}}(x)={\frac 1}{1+\exp left[-x\right.}] Auflistung des Ansatzes Diese Algorithmen versuchen, den Wert einer der oben genannten Bewertungsmaßnahmen direkt zu optimieren, gemittelt über alle Abfragen in den Trainingsdaten. Dies ist schwierig, weil die meisten Bewertungsmaßnahmen keine ständigen Funktionen im Hinblick auf die Parameter des Ranking-Modells sind, so dass kontinuierliche Annäherungen oder Begrenzungen bei Bewertungsmaßnahmen verwendet werden müssen. Liste der Methoden Eine Teilliste der veröffentlichten Lern-zu-Rank-Algorithmen wird unten mit Jahren der ersten Veröffentlichung jeder Methode angezeigt: Hinweis: Da die meisten beaufsichtigten Lernalgorithmen auf den punktuellen Fall angewendet werden können, werden oben nur die Methoden dargestellt, die speziell mit der Rangliste im Auge behalten werden. Die Geschichte Norbert Fuhr führte 1992 die allgemeine Idee von MLR ein und beschreibt Lernansätze beim Informationsabruf als Verallgemeinerung der Parameterschätzung; eine spezifische Variante dieses Ansatzes (unter Verwendung von polynomischer Regression) wurde von ihm drei Jahre früher veröffentlicht. Bill Cooper hat 1992 eine logistische Regression vorgeschlagen und mit seiner Berkeley-Forschungsgruppe eine erfolgreiche Ranking-Funktion für TREC trainiert. Manning et al. deuten darauf hin, dass diese frühen Arbeiten aufgrund geringer verfügbarer Trainingsdaten und schlechter maschineller Lerntechniken in ihrer Zeit begrenzte Ergebnisse erzielten. Mehrere Konferenzen wie NIPS, SIGIR und ICML hatten seit Mitte der 2000er Jahre Workshops zum Lern-zu-Rank-Problem (Decade). Praktische Nutzung durch Suchmaschinen Kommerzielle Web-Suchmaschinen begannen mit maschinell erlernten Ranking-Systemen seit den 2000er Jahren (Decade). Eines der ersten Suchmaschinen, die es nutzen, war AltaVista (später seine Technologie wurde von Overture erworben, und dann Yahoo), die im April 2003 eine Gradienten-Boosting-trained-Ranking-Funktion gestartet. Bings Suche soll von RankNet-Algorithmus betrieben werden, der 2005 bei Microsoft Research erfunden wurde. Im November 2009 kündigte eine russische Suchmaschine Yandex an, dass sie durch den Einsatz eines neuen proprietären MatrixNet-Algorithmus, einer Variante der Gradienten-Boosting-Methode, die oblivious Entscheidung Bäume verwendet, ihre Suchqualität deutlich erhöht hatte. Vor kurzem haben sie auch einen maschinengeführten Ranking-Wettbewerb "Internet Mathematics 2009" gesponsert, der auf den Produktionsdaten ihrer eigenen Suchmaschine basiert. Yahoo hat 2010 einen ähnlichen Wettbewerb angekündigt. Ab 2008 leugnete Googles Peter Norvig, dass ihre Suchmaschine ausschließlich auf maschinengeführten Ranglisten beruht. Cuils CEO, Tom Costello, schlägt vor, dass sie handgefertigte Modelle bevorzugen, weil sie maschinengeführte Modelle übertreffen können, wenn sie gegen Metriken wie Click-Through-Rate oder Zeit auf der Landing-Seite gemessen werden, weil maschinengeführte Modelle "lernen, was Leute sagen, sie mögen, nicht, was Menschen eigentlich mögen". Im Januar 2017 wurde die Technologie in der Open-Source-Suchmaschine Apache SolrTM enthalten, so dass Maschine gelernt Suche Rang weit zugänglich auch für Unternehmenssuche. Ähnlich wie bei Erkennungsapplikationen in der Computer-Vision finden sich auch die neuesten neuralen Netzwerk-basierten Ranking-Algorithmen, die sowohl auf den Kandidaten als auch auf den Abfragen anfällig sind. Mit kleinen, für den Menschen nicht wahrnehmbaren Störungen könnte die Rangfolge willkürlich verändert werden. Darüber hinaus finden sich modell-agnostische übertragbare Adversarialbeispiele als möglich, die Black-Box-Adversarial-Angriffe auf Deep Ranking-Systeme ermöglichen, ohne dass der Zugriff auf ihre zugrunde liegenden Implementierungen erforderlich ist. Umgekehrt kann die Robustheit solcher Ranking-Systeme durch adversariale Verteidigungen wie die Madry-Abwehr verbessert werden. Siehe auch Content-based image retrieval Multimedia information retrieval Image retrieval Triplet loss Referenzen Externe Links Wettbewerbe und öffentliche Datensätze LETOR: Eine Benchmark-Sammlung für die Forschung zum Lernen zum Ranken für Informationen Retrieval Yandex's Internet Mathematics 2009 Yahoo! Lernen Sie herausfordern Microsoft lernen, Datasets zu schätzen Open Source codeParallel C++/MPI Implementierung von Gradient Boosted Regression Trees für Ranking, veröffentlicht September 2011 C+ Implementierung von Gradient Boosted Regression Trees und Random Forests für Ranking C+ und Python Tools für die Verwendung des SVM-Rank-Algorithmus Java-Implementierung in der Apache Solr SuchmaschineAnimal: An International Journal of Animal Bioscience ist eine akademische Zeitschrift gegründet Februar 2007 und veröffentlicht monatlich von Cambridge University Press. Es gehört der British Society of Animal Science (BSAS,) Institut national de la recherche agronomique (INRA) und European Association for Animal Production (EAAP). Es ist die Zusammenführung von drei Zeitschriften: Tierwissenschaften - ISSN 1357-7298 (BSAS)Tierforschung - ISSN 0003-424X/ISSN 1627-3583 (INRA) Reproduktion, Ernährung, Entwicklung - ISSN 0926-5287/ISSN 0926-5309 (INRA) Externe Links Offizielle Website Tier, Cambridge University Press Animal, BSAS ISSN 1751-7311