Dieses Glossar der künstlichen Intelligenz ist eine Liste von Begriffen und Konzepten, die für die Erforschung künstlicher Erkenntnisse, deren Subdisziplines und verwandte Bereiche relevant sind. Linke Glossare Glossar der Computerwissenschaft, der Robotik und des Glossars der Maschinenvision. Eine abduktive Logik-Programmplanung (ALP) Ein hochrangiger Wissens-Repräsentierungsrahmen, der genutzt werden kann, um Probleme zu lösen, die deklarativ auf der Grundlage ableitender Gründe. Es erweitert die normale Logikplanung, indem einige Prädikatoren unvollständig definiert werden, die als unerträglich erklärt werden. Ableitende Gründe auch Abzüge. Eine Form der logischen Gleichgültigkeit, die mit einer Beobachtung oder einer Reihe von Beobachtungen beginnt, soll dann die einfachste und wahrscheinlichste Erklärung finden. Im Gegensatz zu deduktiven Gründen führt dieser Prozess zu einem plausiblen Abschluss, aber er überprüft ihn nicht positiv. Fehlentwicklung oder Rückführung abstrakter Datentyp Ein mathematisches Modell für Datentypen, bei dem ein Datentyp von seinem Verhalten (semantics) aus Sicht eines Nutzers der Daten definiert wird, insbesondere im Hinblick auf mögliche Werte, mögliche Transaktionen auf Daten dieser Art und das Verhalten dieser Vorgänge. abstrakt Der Prozess der Entfernung von materiellen, räumlichen oder zeitlichen Details oder Eigenschaften in der Untersuchung von Gegenständen oder Systemen, um enger an andere Einzelheiten der Zinserschleunigung teilnehmen zu können, wird in der gesamten Geschichte ein wahrgenommener Anstieg der Geschwindigkeit des technologischen Wandels, der eine raschere und tiefere Veränderung in der Zukunft vorschlagen könnte und möglicherweise oder nicht mit einem ebenso tiefgreifenden sozialen und kulturellen Wandel einhergehen kann. Sprache Eine Sprache für die Festlegung staatlicher Übergangssysteme und wird häufig verwendet, um formelle Modelle der Auswirkungen von Maßnahmen auf die Welt zu erstellen. Aktionssprachen werden häufig in den Bereichen künstliche Intelligenz und Robotik verwendet, in denen sie beschreiben, wie Maßnahmen die Staaten von Systemen im Laufe der Zeit betreffen und für eine automatisierte Planung verwendet werden können. Maßnahmenmodell Lernen ein Bereich des maschinellen Lernens, das mit der Schaffung und Änderung des Know-hows von Software-Beauftragten über die Auswirkungen und die Voraussetzungen der Aktionen, die in ihrer Umgebung ausgeführt werden können, befasst ist. Dieses Wissen ist in der Regel in der logikbasierten Sprache der Aktionsbeschreibung vertreten und wird als Input für automatisierte Planer verwendet. Auswahl Eine Artisierung des grundlegendsten Problems intelligenter Systeme: was nächstes tun soll. In der künstlichen Intelligenz und der rechnerischen kognitiven Wissenschaft ist das "Aktionsauswahlproblem" in der Regel mit intelligenten Agenten und Aimats – umfangreichen Systemen, die komplexes Verhalten in einem Agentenumfeld zeigen. Aktivierungsfunktion In künstlichen Neuralnetzen definiert die Aktivierungsfunktion eines node die Produktion dieser Node aufgrund eines Inputs oder einer Reihe von Inputs. adaptiver Algorithmus Ein Algorithmus, der sein Verhalten zu dem Zeitpunkt ändert, an dem es läuft, basierend auf einem zuvor festgelegten Belohnungsmechanismus oder Kriterium. Anpassung an das System der neurofuzzy-Diszipation (ANFIS) Eine Art künstliches Neuralnetz, das auf dem Spielsystem von Takagi-Sugeno fuzzy basiert. Anfang der 90er Jahre wurde die Technik entwickelt. Da es sowohl Neuralnetze als auch fuzzy Logikprinzipien integriert, hat es das Potenzial, die Vorteile sowohl in einem einzigen Rahmen zu erfassen. Das System der Gleichgültigkeit entspricht einer Reihe von Fuzzy IF-THEN-Vorschriften, die Lernfähigkeiten zur Angleichung nichtlinearer Funktionen haben. ANFIS gilt daher als universeller Ester. Für eine effizientere und optimale Nutzung des ANFIS kann man die besten Parameter nutzen, die durch genetischen Algorithmus gewonnen werden. zulässiger Tourismus In der Computerwissenschaft, insbesondere in Algorithmen im Zusammenhang mit der Erkundung, wird eine touristische Funktion als zulässig erklärt, wenn sie die Kosten für das Erreichen des Ziels nie überschätzt, d. h. die Kosten, die sie für die Erreichung des Ziels erwarten, sind nicht höher als die geringsten Kosten des aktuellen Pfades. Einflussnahme auf Computer künstliche emotionale Intelligenz oder Emotionen AI. Studie und Entwicklung von Systemen und Geräten, die erkennen, interpretieren, verarbeiten und menschliche Auswirkungen simulieren können. Affective Computing ist ein interdisziplinärer Bereich, der Computerwissenschaft, Psychologie und kognitive Wissenschaft umfasst. Systemarchitektur Konzept für Softwareagenten und intelligente Kontrollsysteme, in denen die Regelung von Bauteilen dargestellt wird. Die von intelligenten Agenten umgesetzten Architekturen werden als kognitive Architekturen bezeichnet. AI-Beschleuniger A Klasse von Mikroprozessor oder Computersystem, das als Hardware-Beschleunigung für künstliche Intelligenzanwendungen, insbesondere künstliche Neuralnetze, maschinelle Vision und maschinelles Lernen konzipiert wurde. AI-Deflator Im Bereich der künstlichen Intelligenz sind die schwierigsten Probleme informell als AI-voll oder AI-hart bekannt, was bedeutet, dass die Schwierigkeit dieser rechnerischen Probleme mit denen der Lösung des zentralen künstlichen Intelligenzproblems vergleichbar ist – Computer wie Menschen oder starke AI. Um ein Problem zu lösen, spiegelt sich die Haltung wider, die es nicht durch einen einfachen bestimmten Algorithmus lösen würde. Algorithmus Klare Spezifikation, wie eine Klasse von Problemen gelöst werden kann. Algorithms kann die Berechnung, die Datenverarbeitung und die automatisierte Begründung durchführen. Algorithmuseffizienz Eigentum eines Algorithmus, der sich auf die Zahl der vom Algorithmus verwendeten Rechenmittel bezieht. Ein Algorithmus muss analysiert werden, um seine Ressourcennutzung zu bestimmen, und die Effizienz eines Algorithmus kann anhand der Nutzung unterschiedlicher Ressourcen gemessen werden. Algorithmieeffizienz kann als Vergleich zur Ingenieurproduktivität für einen wiederholten oder kontinuierlichen Prozess angesehen werden. Wahrscheinlichkeit In der Algorithmen-Informationstheorie ist die algorische Wahrscheinlichkeit, auch bekannt als Salomonoff Wahrscheinlichkeit, eine mathematische Methode, um eine vorherige Wahrscheinlichkeit einer bestimmten Beobachtung zuzuweisen. Ray Salomonoff wurde in den 1960er Jahren entwickelt. AlphaGo Es wurde ein Computerprogramm entwickelt, das das Spiel Go. Es wurde von Alphabet Inc.'s Google DeepMind in London entwickelt. AlphaGo hat mehrere Versionen, darunter AlphaGo Zero, AlphaGo Master, AlphaGo Lee usw. Alpha im Oktober 2015 Go wurde der erste Computer Go-Programm zur Einstellung eines menschlichen Berufs Go Player ohne Benachteiligungen an einem vollgroßen 19 x19 Board. Umweltinformationen (AmI) Elektronische Umgebungen, die empfindlich und auf das Vorhandensein von Menschen reagieren. Analyse von Algorithmen Bestimmung der rechnerischen Komplexität von Algorithmen, d. h. die Menge der Zeit, Lagerung und/oder sonstigen Ressourcen, die zur Ausführung dieser Algorithmen erforderlich sind. In der Regel bedeutet dies, eine Funktion zu bestimmen, die die Länge des Inputs eines Algorithmus auf die Anzahl der von ihm ergriffenen Schritte (Zeitkomplex) oder die Anzahl der von ihm verwendeten Speicherstandorte (Raumkomplexität) betrifft. Analyse Entdeckung, Auslegung und Kommunikation sinnvoller Muster in Daten. Antwort Set-Programmplanung (ASP) Eine Form der deklarativen Programmierung, die auf schwierige (hauptsächlich NP-hard) Suchprobleme ausgerichtet ist. Es basiert auf dem stabilen Modell (Anlegeset) semantisches der Logikplanung. In ASP werden die Suchprobleme auf stabile Modelle reduziert, und die Lösungsgruppen – Programme zur Schaffung stabiler Modelle – werden zur Durchführung der Suche genutzt. jederzeit Algorithmus Ein Algorithmus, der eine gültige Lösung für ein Problem zurückgeben kann, auch wenn er unterbrochen wird, bevor er endet. Anwendungsschnittstelle (API)A Reihe von Subroutinedefinitionen, Kommunikationsprotokollen und Werkzeugen für die Bausoftware. Insgesamt ist es eine Reihe klar definierter Kommunikationsmethoden zwischen verschiedenen Komponenten. Eine gute API macht es einfacher, ein Computerprogramm zu entwickeln, indem alle Bausteine bereitgestellt werden, die dann vom Programmierer zusammengelegt werden. Eine API kann für ein internetbasiertes System, Betriebssystem, Datenbanksystem, Computer-Hardware oder Software-Bibliothek verwendet werden. Annäherungsspanne Suche nach Fuzzy. Technik der Suche nach Aufklebern, die einem Muster ungefähr entsprechen (und nicht genau). In der Regel wird das Problem der ungefähre Abstimmung in zwei Sub-Problemen unterteilt: Suche nach ungefähren Teilkapiteln innerhalb einer bestimmten Spanne und Suche nach den Mustern. Annäherungsfehler Diskrepanzen zwischen einem genauen Wert und einer gewissen Annäherung. Argumentationsrahmen System der Argumentation. Wege, um Inhalte und Schlussfolgerungen daraus zu erfassen. In einem abstrakten Argumentationsrahmen sind die Eingabeinformationen eine Reihe von abstrakten Argumenten, die beispielsweise Daten oder eine Vorgabe darstellen. Konflikte zwischen Argumenten werden durch einen binären Zusammenhang auf dem Satz von Argumenten vertreten. Konkret stellen Sie einen Argumentationsrahmen mit einem zielgerichteten Diagramm dar, so dass die Nodes die Argumente sind und die Pfeile den Angriffsbezug darstellen. Es gibt einige Erweiterungen des Dung-Rahmens, wie z.B. die logikbasierten Argumentationsrahmen oder die wertbasierten Rahmenregelungen. künstliche allgemeine Intelligenz (AGI) künstliches Immunsystem (AIS)A Klasse von rechnerisch intelligenten, regelgestützten Maschinenlernsystemen, die sich an den Grundsätzen und Prozessen des vertebraten Immunsystems orientieren. Die Algorithmen werden in der Regel nach den Merkmalen des Immunsystems für das Erlernen und das Gedächtnis für die Verwendung in der Problemlösung entwickelt. künstliche Intelligenz (AI) auch maschinelle Intelligenz. Jede von Maschinen gezeigte Intelligenz im Gegensatz zu den natürlichen Erkenntnissen von Menschen und anderen Tieren. In der Computerwissenschaft wird die AI-Forschung definiert als die Studie von "intelligenten Agenten:" jedes Gerät, das seine Umwelt wahrnimmt und Maßnahmen ergreift, die die Chance, seine Ziele erfolgreich zu erreichen. Colloquily, der Begriff "artificial Intelligence" wird angewendet, wenn eine Maschine kognitive Funktionen anwendet, die Menschen mit anderen menschlichen Köpfen, wie Lernen und "Problemlösung" verbinden. Künstliche Intelligenz Markup Language XML Dialekt für die Schaffung von natürlichen Sprachsoftware-Betreibern. künstliches Neuralnetz (ANN)ANN. Jedes Rechensystem vage inspiriert von den biologischen Neuralnetzen, die Tier Gehirn bilden. Association for the Advancement of Künstliche Intelligence (AAAI)An international, gemeinnützige, wissenschaftliche Gesellschaft zur Förderung der Forschung und der verantwortungsvollen Nutzung künstlicher Erkenntnisse. AAAI zielt auch darauf ab, das öffentliche Verständnis der künstlichen Intelligenz (AI) zu verbessern, den Unterricht und die Ausbildung von AI-Akteuren zu verbessern und Leitlinien für Forschungsplaner und Fonds für die Bedeutung und das Potenzial der aktuellen Entwicklungen und Zukunftsweisen der AI bereitzustellen. asymptotische Rechen Komplexität In der rechnerischen Komplexitätstheorie ist die asymptotische rechnerische Komplexität die Verwendung der asymptotischen Analyse zur Schätzung der rechnerischen Komplexität von Algorithmen und Rechenproblemen, die häufig mit der Nutzung der großen O-Zulassung verbunden sind. bei Zuweisung von kalorien System der Logik und Vertretung von Ryszard S. Michalski. Es kombiniert Elemente der prädikativen Logik, der Propositional-Calculus und der multi-Wertierten Logik. Aggregationionales Calcins ist eine formale Sprache für den natürlichen Induktions, ein induktives Lernprozess, dessen Ergebnisse den Menschen natürlichen Charakter haben. augmentierte Realität (AR)Eine interaktive Erfahrung eines echten Umfelds, in dem die Gegenstände, die in der realen Welt wohnen, durch computergenetische perkzeptable Informationen erweitert werden, manchmal über mehrere sensorische Modalitäten, einschließlich visueller, Auditory, haptic, somatosensory und Ol zufriedenstellend. Automatisierung Studie von abstrakten Maschinen und Automaten sowie die rechnerischen Probleme, die mit ihnen gelöst werden können. theoretische Informatik und Mathematik (ein Studienthema in Mathematik und Informatik) ist eine Theorie. automatisierte Planung und Planung Lediglich AI-Plan. Künstliche Intelligenz, die die Umsetzung von Strategien oder Aktionssequenzen betrifft, in der Regel für die Ausführung von intelligenten Agenten, autonomen Robotern und unbemannten Fahrzeugen. Anders als klassische Kontroll- und Klassifikationsprobleme sind die Lösungen komplex und müssen in multidimensionalem Raum entdeckt und optimiert werden. Planung ist auch mit der Entscheidungstheorie verbunden. automatisierte Begründung ein Bereich der Computerwissenschaft und mathematischen Logik, um verschiedene Aspekte der Begründung zu verstehen. Mit der Untersuchung von automatisierten Grundstoffen können Computerprogramme erstellt werden, die es Computern erlauben, vollständig oder nahezu vollständig, automatisch. Obwohl automatisierte Gründe als Teilbereich künstlicher Intelligenz betrachtet werden, verfügt sie auch über Verbindungen zur theoretischen Computerwissenschaft und sogar zur Philosophie. autonome Rechentechnik (AC) Die Selbstverwaltungsmerkmale der verteilten Rechenressourcen, die sich an unvorhersehbare Veränderungen anpassen und gleichzeitig die Komplexität für Betreiber und Nutzer verschleiern. Im Jahr 2001 von IBM initiierte Initiative zielte letztlich darauf ab, Computersysteme zu entwickeln, die in der Lage sind, sich selbst zu verwalten, die rasant wachsende Komplexität der Rechensysteme zu überwinden und die Hindernisse zu verringern, die die Komplexität für ein weiteres Wachstum darstellt. autonomes Auto Auto selbstfahren, Roboterwagen und fahrerlose Autos. Ein Fahrzeug, das in der Lage ist, seine Umwelt zu erkennen und mit wenig oder gar keinen menschlichen Input zu bewegen. autonomer Roboter Ein Roboter, der Verhaltensweisen oder Aufgaben mit hoher Autonomie erfüllt. autonome Robotik gelten in der Regel als Teilfeld künstlicher Intelligenz, Robotik und Informationstechnik. B Rückpropagation A Methode, die in künstlichen Neuralnetzen verwendet wird, um eine bei der Berechnung der im Netzwerk zu verwendenden Gewichte zu berechnen. Rückpropagation ist kurz für "die Rückführung von Fehlern", da ein Fehler bei der Produktion berechnet und über die Schichten des Netzes verteilt wird. Es wird häufig genutzt, um tiefe Neuralnetze auszubilden, die auf neurale Netze mit mehr als einer versteckten Schicht Bezug nehmen. Unterstützung durch die Zeit (BPTT)A stufenbasierte Technik zur Schulung bestimmter Arten von wiederkehrenden Neuralnetzen. Es kann genutzt werden, um Elman-Netze auszubilden. Der Algorithmus wurde von zahlreichen Forschern unabhängig voneinander abgeleitet, auch zurückgezogen. Eine kollidierende Methode, die als Gegenleistung bezeichnet wird. Es wird in automatisierten Amphorem-Proversen, Leistungsmotoren, Nachweisassistenten und anderen künstlichen Intelligenzanwendungen verwendet. Modell des Taschen Vereinfachung der Darstellung in der natürlichen Sprache Verarbeitung und Information (IR). In diesem Modell ist ein Text (z.B. ein Satz oder ein Dokument) als den Beutel (multiset) seiner Worte, der die pädagogische und sogar redaktionelle Ordnung missachtet, aber die Vielfalt bewahrt. In der Computervision wurde auch das Modell des Beutels verwendet. In den Methoden der Dokumentationsklassifikation, in denen die (Höchsthäufigkeit) jedes Wort als Merkmal für die Schulung eines Klassensteigers verwendet wird, wird das Warnmuster häufig verwendet. Modell für Computer-Vision In der Computervision kann das Rohrformmodell (BoW-Modell) auf Bildklassifikation angewendet werden, indem Bildmerkmale als Worte behandelt werden. In Dokumenteinstufung ist ein Satz von Worten ein geringer Herkunftsvektor; das ist ein wenig histogramm über das Vokular. In der Computervision ist eine Reihe visueller Wörter ein Vektor des Auftretens eines Vokulars lokaler Bildmerkmale. Normalisierung der Charge Technik zur Verbesserung der Leistung und Stabilität künstlicher Neuralnetze. Es ist eine Technik, um jede Schicht in einem Neuralnetz mit Inputs zu versorgen, die Null bedeuten. Batch Normalisierung wurde in einem Papier von 2015 eingeführt. Es wird zur Normalisierung der Inputschicht verwendet, indem die Aktivierungen angepasst und verstärkt werden. Bayesische Programmierung formalismus und eine Methode, um probabilistische Modelle festzulegen und Probleme zu lösen, wenn weniger als die notwendigen Informationen zur Verfügung stehen. Bienengorithmus Ein bevölkerungsbasierter Suchgorithmus, der von Pham, Ghanbarzadeh und et al.in 2005 entwickelt wurde. Es geht um die Lebensmittel für das Verhalten von Honigpest. In seiner grundlegenden Version führt der Algorithmus eine Art von Nachbarschaftssuche zusammen mit globaler Suche durch und kann sowohl für die Kombination von Methodenoptimierung als auch für die kontinuierliche Optimierung genutzt werden. Die einzige Voraussetzung für die Anwendung des Bienengorithmus ist, dass eine gewisse Entfernung zwischen den Lösungen definiert wird. Wirksamkeit und spezifische Fähigkeiten des Bienengorithmus wurden in einer Reihe von Studien nachgewiesen. Verhaltensinformationen (BI)Die Informationen über Verhaltensänderungen, um Verhaltensinformationen und Verhaltensanalysen zu erhalten. Verhaltensbaum (BT) Ein mathematisches Modell für die planmäßige Ausführung in Computerwissenschaften, Robotik, Kontrollsystemen und Videospielen. Sie beschreiben Wechseln zwischen einem finitären Aufgabenkatalog in modularer Weise. Ihre Stärke ist aus ihrer Fähigkeit, sehr komplexe Aufgaben zu schaffen, die sich aus einfachen Aufgaben zusammensetzen, ohne besorgniserregende Umsetzung der einfachen Aufgaben. BTs weisen einige Ähnlichkeiten mit den hierarchischen Staatsmaschinen auf, wobei der wesentliche Unterschied darin besteht, dass der Hauptblock eines Verhaltens eher eine Aufgabe als ein Staat ist. Ihre Erleichterung des menschlichen Verständnisses macht BTs weniger Fehler und sehr beliebt in der Spielentwicklergemeinschaft. BTs haben gezeigt, dass mehrere andere Kontrollarchitekturen allgemeinisiert werden. Entwicklung eines Softwaremodells (BDI)A für die Programmierung intelligenter Wirkstoffe. Superficially, das durch die Umsetzung der Überzeugungen, Wünsche und Absichten eines Agenten gekennzeichnet ist, nutzt sie diese Konzepte zur Lösung eines besonderen Problems in der Programmplanung. Wesentlich bietet sie einen Mechanismus, um die Aktivität der Auswahl eines Plans (von einer Planbibliothek oder einem externen Planer-Anwendung) von der Durchführung der derzeit aktiven Pläne zu trennen. BDI-Beamte können daher die Zeit, die für die Beratung über die geplanten Pläne (die das zu tun haben) und die Durchführung dieser Pläne (d. h. Eine dritte Tätigkeit, die die Pläne zum ersten Mal (Planung) schafft, ist nicht in den Anwendungsbereich des Modells fallen und bleibt dem Systementwickler und dem Programmierer überlassen. einseitige Differenzierung In Statistiken und Maschinenlernen ist der unvorhergesehene – Varianz-Ausstieg das Eigentum einer Reihe von prädikativen Modellen, bei denen Modelle mit niedrigeren Verzerrungen bei der Parameterschätzung eine höhere Varianz der Parameterschätzungen über Proben aufweisen, und umgekehrt. Große Daten Ein Begriff, der verwendet wird, um auf Datensets zu verweisen, die für traditionelle Datenverarbeitungssoftware zu groß oder komplex sind, um sich angemessen mit ihnen zu befassen. Daten mit vielen Fällen (Rücken) bieten eine höhere statistische Leistung, während Daten mit höherer Komplexität (mehre Eigenschaften oder Spalten) zu einer höheren Falscherkennungsrate führen können. Mehr Keine mathematische Notation, die das Begrenzungsverhalten einer Funktion beschreibt, wenn das Argument eher zu einem bestimmten Wert oder Unsicherheit führt. Sie ist Mitglied einer Familie von Notationen, die von Paul Bachmann, Edmund Landau, und anderen, gemeinsam als Bachmann-Landau-Zulassung oder alsymptotic-Befehlung bezeichnet werden. Karen Baum A Baumdatenstruktur, in der jeder Node über die meisten zwei Kinder verfügt, die als linken Kind und das richtige Kind bezeichnet werden. Eine recursive Definition, die nur theoretischen Begriffen verwendet, ist, dass ein (nichtbefreiter) binärer Baum ein mühsamer (L, S, R), wo L und R binäre Bäume oder das leere Set sind und S ein einziges Set ist. Manche Autoren erlauben es dem binären Baum auch die leere Set. Steuersystem Ein künstlicher Intelligenz-Ansatz, der auf dem Schwarzboard-Architekturmodell basiert, wo eine gemeinsame Wissensbasis, das Blackboard, durch eine Vielzahl von Fachkenntnissen, angefangen mit einer Problembeschreibung und einer Lösung, aktualisiert wird. Jede Wissensquelle aktualisiert das Blackboard mit einer partiellen Lösung, wenn seine internen Zwänge dem Blackboard State entsprechen. In diesem Sinne arbeiten die Spezialisten zusammen, um das Problem zu lösen. Ziegenzmann Werkzeugmaschinen auch krchastic Hopfield Network mit versteckten Einheiten. Eine Art krchastic recurrent Neural Network und Markov Randomfeld. Kronzmann-Maschinen können als katastrophaler, physikalischer Partner von Hopfield-Netzen angesehen werden. Probleme der Wirtschaftlichkeit Propositionelles Problem ist auch das Problem der Verschuldung; verkürzte SATISFIABILITY oder SAT.{Inhalte} Gehirntechnologie Selbstlern-Know-how-System. Eine Technologie, die die neuesten Erkenntnisse in der Neurowissenschaften einbringt. Im Rahmen des ROBOY-Projekts wurde der Begriff zunächst vom künstlichen Intelligenzlabor in Zürich, der Schweiz eingeführt. Gehirntechnik kann in Robotern, Know-how Managementsystemen und anderen Anwendungen mit Selbst-Lernkapazitäten eingesetzt werden. Insbesondere die Brain Technology-Anwendungen ermöglichen die Darstellung der zugrunde liegenden Lernarchitektur oft als „Wissenskarten“. Branchenfaktor Informatik, Baumdatenstrukturen und Spieltheorie, die Zahl der Kinder auf jedem Knoten, das Ex-Grad. Wenn dieser Wert nicht einheitlich ist, kann ein durchschnittlicher Abzweigungsfaktor berechnet werden. Färkte Suche auch erschöpfende Suche und Test. Eine sehr allgemeine Problemlösungstechnik und ein algorisches Paradigma, das alle möglichen Kandidaten für die Lösung systematisch ausdehnt und überprüft, ob jeder Bewerber die Erklärung des Problems erfüllt. C Kapsel-Neuralnetz (CapsNet)A Maschinenlernsystem, das eine Art künstliches Neuralnetz (ANN) ist, das genutzt werden kann, um hierarchische Beziehungen besser zu gestalten. Der Ansatz ist ein Versuch, die biologische Neuralorganisation zu verstärken. Verfahren zur Lösung neuer Probleme, die sich auf die Lösung ähnlicher früherer Probleme stützen. Chatbot Smartbot, Talkbot, Chatterbot, Bot, IM Bot, interaktiver Agenten, Gesprächsplattform oder künstlicher Gesprächskörper. Computerprogramm oder künstliche Intelligenz, die ein Gespräch über Prüf- oder Textmethoden führen. Robotik Robotik, die versuchen, Cloud-Technologien wie Cloud Computing, Cloud-Speicherung und andere Internet-Technologien zu nutzen, konzentrieren sich auf die Vorteile der konvergierten Infrastruktur und gemeinsamer Dienste für Robotik. Roboter können im Zusammenhang mit der Cloud von den leistungsfähigen Rechen-, Speicher- und Kommunikationsressourcen des modernen Datenzentrums in der Cloud profitieren, die Informationen verschiedener Roboter oder Agenten (andere Maschinen, intelligente Objekte, Menschen usw.) verarbeiten und weitergeben können. Menschen können auch Aufgaben an Roboter übertragen, die über Netze fern sind. Cloud Computing-Technologien ermöglichen es Robotersystemen, mit leistungsfähigen Fähigkeiten ausgestattet zu sein und die Kosten durch Cloud-Technologien zu senken. Intelligentere Roboter verfügen somit über intelligentes Gehirn in der Cloud. Das Gehirn besteht aus Datenzentrum, Wissensgrundlage, Taskplaner, tiefes Lernen, Informationsverarbeitung, Umweltmodelle, Kommunikationsunterstützung usw. Clusteranalyse Clustering. Die Aufgabe, eine Reihe von Gegenständen in einer Weise zusammenzufassen, die Gegenstände in der gleichen Gruppe (ein Cluster) einander gegenüber denen anderer Gruppen (Cluster) ähnlich sind. Es ist eine Hauptaufgabe des explorativen Data-Mining und einer gemeinsamen Analyse der statistischen Daten, die in vielen Bereichen verwendet wird, einschließlich maschinelles Lernen, Mustererkennung, Bildanalyse, Bioinformatik, Datenkompression und Computerdarstellung. Cobweb Ein incrementales System für hierarchisches Konzeptcluster. COBWEB wurde von Professor Douglas H. Fisher entwickelt, derzeit an der Vanderbilt University. COBWEB incrementiv organisiert Beobachtungen in einen Klassifikationsbaum. Jeder Node in einem Klassifikationsbaum stellt eine Klasse (Konzept) dar und wird durch ein probabilistisches Konzept gekennzeichnet, das die Attribut-Wertverteilung von Gegenständen, die unter der Node eingestuft werden, zusammenfasst. Dieser Klassifikationsbaum kann verwendet werden, um fehlende Eigenschaften oder die Klasse eines neuen Gegenstands vorherzusagen. kognitive Architektur Das Institut für Kreative Technologien definiert kognitive Architektur als: "Hypothesis über die festen Strukturen, die einen Blick darstellen, sei es in natürlichen oder künstlichen Systemen und wie sie zusammen arbeiten – in Verbindung mit den in der Architektur verankerten Kenntnissen und Fähigkeiten, um intelligentes Verhalten in einer Vielfalt komplexer Umgebungen zu erzielen". kognitives Lernen Insgesamt wurde der Begriff kognitive Rechen verwendet, um auf neue Hardware und/oder Software zu verweisen, die das Funktionieren des menschlichen Gehirns anpasst und zur Verbesserung der menschlichen Entscheidungsfindung beiträgt. In diesem Sinne ist CC eine neue Art von Computern mit dem Ziel genauerer Modelle, wie das menschliche Gehirn/Märkte, Gründe und Reaktionen auf Stimulierungen. kognitive Wissenschaft Interdisziplinäre wissenschaftliche Studie des Geistes und seiner Prozesse. Kombination In Operations Research, angewandte Mathematik- und theoretische Computerwissenschaft ist die kombinierte Optimierung ein Thema, das darin besteht, ein optimales Objekt aus einem finnischen Satz von Gegenständen zu finden. Maschinen Eine Art künstliches Neuralnetz mit einer Trenn- und Eroberungsstrategie, in der die Antworten mehrerer Neuralnetze (Experten) in eine einzige Antwort zusammengefasst sind. Die kombinierte Antwort des Ausschusses soll den Mitgliedern des Ausschusses überlegen sein. Vergleichselemente von Klassenprüfern. gemeinsames Wissen In der künstlichen Intelligenzforschung besteht ein gemeinsames Wissen aus Fakten über die Alltagswelt, wie "Lionen sind sour", dass alle Menschen wissen werden. Das erste AI-Programm, mit dem das gemeinsame Wissen bekämpft werden soll, war das Beratungsangebot von John McCarthy 1959. gemeinsame Gründe Ein Bereich künstlicher Intelligenz, der die menschliche Fähigkeit simuliert, Vermutungen über Art und Wesen gewöhnlicher Situationen, mit denen sie täglich konfrontiert sind, zu machen. Rechenchemie Chemie, die Computersimulation nutzt, um chemische Probleme zu lösen. Rechentechnik Konzentrationen auf die Einstufung von Rechenproblemen nach ihrer inhärenten Schwierigkeit und die Verknüpfung dieser Klassen untereinander. Ein Rechenproblem ist eine von einem Computer gelöste Aufgabe. Ein Rechenproblem ist durch mechanische Anwendung mathematischer Schritte, wie z.B. ein Algorithmus, so verstopft. Rechenliche Kreativität künstliche Kreativität, mechanische Kreativität, kreative Rechentechnik oder kreative Berechnung. Ein multidisziplinärer Versuch, der die Bereiche künstliche Intelligenz, kognitive Psychologie, Philosophie und Kunst umfasst. Rechentechnik Integration von Cybernetics und Rechentechniken. rechnerisches Zeichen Ein Zweig der Informatik und künstlichen Intelligenz, der Computer in der Literaturforschung verwendet. rechnerische Intelligenz (CI) bezieht sich in der Regel auf die Fähigkeit eines Computers, eine bestimmte Aufgabe von Daten oder experimenteller Beobachtung zu erfahren. Informatiktheorie In der Computerwissenschaft ist die rechnerische Lerntheorie (oder nur Lerntheorie) ein Teilbereich künstlicher Intelligenz, die die Konzeption und Analyse von maschinenlesbaren Lernalgorithmen untersucht. mathematische Sprachen Ein interdisziplinärer Bereich, der mit dem statistischen oder regelbasierten Modell der natürlichen Sprache aus einer rechnerischen Perspektive sowie der Studie geeigneter rechnerischer Ansätze für sprachliche Fragen befasst ist. Mathematik mathematische Forschung in Bereichen der Wissenschaft, in denen das Rechenwesen eine wesentliche Rolle spielt. rechnerische Neurowissenschaften theoretische Neurowissenschaften oder mathematische Neurowissenschaften. Ein Teil der Neurowissenschaften, der mathematische Modelle, theoretische Analysen und abstrakten des Gehirns beschäftigt, um die Grundsätze für Entwicklung, Struktur, Physiologie und kognitive Fähigkeiten des Nervensystems zu verstehen. Rechennummerntheorie auch die Algorithmen-Nummertheorie. Studie über Algorithmen für die Ausführung der Anzahl der oretic Berechnungen. Rechenproblem theoretische Computerwissenschaft ist ein mathematisches Problem, das eine Sammlung von Fragen darstellt, die Computer lösen können. Rechenstatistiken Statistik. Schnittstelle zwischen Statistik und Informatik. Computerautomatisiertes Design (CAutoD) Design Automation bezieht sich in der Regel auf elektronische Designautomatisierung oder Design Automation, die ein Produktkonfigurator ist. Ausweitung von Computer-Aided Design (CAD), automatisiertes Design und computerautomatisiertes Design sind Gegenstand einer breiteren Palette von Anwendungen wie Automobiltechnik, Bauingenieurwesen, Verbundmaterialdesign, Steuerungstechnik, dynamische Systemidentifikation und Optimierung, Finanzsysteme, Industrieausrüstung, Mechatronic-Systeme, Stahlbau, Strukturoptimierung und Erfindung neuer Systeme. Kürzlich wird die traditionelle CAD-simulation durch biologisch inspiriertes Maschinenlernen in CAutoD umgestaltet, u. a. durch he Tourist-Suchestechniken wie evolutionäre Berechnung und sachgerechte Intelligenz. Computeraudit (CA) Siehe maschinelles Gehör. Informatik Theorie, Erprobung und Ingenieurwesen, die die Grundlage für die Gestaltung und Verwendung von Computern bilden. Es umfasst die Untersuchung von Algorithmen, die Prozess, Speicherung und Kommunikation digitaler Informationen. Ein Computerwissenschaftler ist auf die Berechnungstheorie und die Gestaltung von Rechensystemen spezialisiert. Computervision Ein interdisziplinärer wissenschaftlicher Bereich, der sich mit der Frage befasst, wie Computer aus digitalen Bildern oder Videos auf hohem Niveau entwickelt werden können. Aus Sicht der Technik soll das menschliche visuelle System die Aufgaben optimieren. Konzept In prädikativen Analysen und Maschinenlernen bedeutet das Konzept, dass die statistischen Eigenschaften der Zielvariable, die das Modell zu vorhersagen versucht, sich über die Zeit in unvorhersehbarer Weise ändern. Dies führt zu Problemen, weil die Vorhersagen weniger genau sind als die Zeit. Linkismus Ein Ansatz in den Bereichen kognitive Wissenschaft, der hofft, psychische Phänomene mit künstlichen Neuralnetzen zu erklären. konsequenter Tourismus In der Studie über Erkundungsprobleme in der künstlichen Intelligenz wird eine he touristische Funktion konsistent oder Monoton sein, wenn ihre Schätzung immer weniger oder gleich der geschätzten Entfernung von benachbarten Wirbelstürmen zum Ziel entspricht und die Kosten für die Erreichung dieses Ziels. Gebremstes Modell (CCM)A maschinelles Lernen und Gleichgültigkeitsrahmen, das das Lernen von bedingten (probabilistischen oder diskriminativen) Modellen mit deklarativen Zwängen verstärkt. Steuerung der Logik eine Form der Druckprogrammierung, bei der die Programmierung der Logik auf Konzepte aus der Druckzufriedenheit ausgedehnt wird. Ein Drucklogikprogramm ist ein Logikprogramm, das Beschränkungen im Bereich der Klauseln enthält. Beispiel für eine Klausel, einschließlich eines Drucks, ist A(X,Y) :- X+Y>0, B(X), C(Y). In dieser Klausel ist X+Y>0 ein Hindernis; A(X,Y) B(X) und C(Y) sind Liter als reguläre Planung der Logik. Diese Klausel stellt eine Bedingung dar, unter der die Erklärung A(X,Y) X+Y ist mehr als Null, und beide B(X) und C(Y) sind wahr. Programmplanung Ein Programmierungsparat, bei dem die Beziehungen zwischen Variablen in Form von Zwängen angegeben werden. Constraints unterscheiden sich von den gemeinsamen Merkmalen der zwingend vorgeschriebenen Programmiersprachen, da sie keinen Schritt oder eine Reihe von Schritten zur Ausführung angeben, sondern die Eigenschaften einer zu findenden Lösung. Sprache auch konlang. Eine Sprache, deren Tonologie, Mathematik und Vokabular sich bewusst entwickelt haben, anstatt natürlich zu entwickeln. pädagogische Sprachen können auch als künstliche, geplante oder erfundene Sprachen bezeichnet werden. Kontrolle der Theorie Systemtechnik ist ein Teilbereich der Mathematik, der sich mit der Kontrolle ständiger dynamischer Systeme in technischen Prozessen und Maschinen befasst. Ziel ist es, ein Kontrollmodell für die Kontrolle solcher Systeme zu entwickeln, das eine Kontrollmaßnahme auf optimale Weise ohne Verzögerung oder Überschreitung und Gewährleistung der Kontrollstabilität nutzt. Konvolutionelles Neuralnetz Im tiefen Lernen ist ein konvolutionales Neuralnetz (CNN oder ConvNet) eine Klasse von tiefen Neuralnetzen, die am häufigsten auf die Analyse visueller Bilder angewendet werden. CNNs verwenden eine Änderung von Mehrschicht-Perceptronen, die eine minimale Vorverarbeitung erfordern. Sie sind auch bekannt als unvariable oder unvariable künstliche Neuralnetze (SIANN), die auf ihrer gemeinsamen Architektur und den Merkmalen der Übersetzung basieren. grenzüberschreitend Auch Recombination. In genetischen Algorithmen und Evolutionsberechnung verwendet ein genetischer Anbieter, der die genetischen Informationen von zwei Eltern kombiniert, um neue Nachkommen zu generieren. Es ist eine Möglichkeit, neue Lösungen aus einer bestehenden Bevölkerung zu finden und die Überlagerung, die während der sexuellen Reproduktion in biologischen Organismen geschieht, ähnlich zu gestalten. Lösungen können auch durch das Klonen einer bestehenden Lösung erzeugt werden, die ähnlich einer geschlechtsspezifischen Reproduktion ist. Neu generierte Lösungen werden in der Regel mutiert, bevor sie der Bevölkerung hinzugefügt werden. Dunkelwald Ein von Facebook entwickeltes Computerprogramm, das sich auf Tiefbildungstechniken mit einem konvolutionalen Neuralnetz stützt. Die aktualisierte Version Dunkelfores2 kombiniert die Techniken seines Vorgängers mit Monte Carlo Baumsuche. Mit dem MCTS werden die Methoden zur Suche von Baumarten, die in Computer-Bodenprogrammen üblich sind, effektiv genutzt. Mit der Aktualisierung ist das System als Darkfmcts3 bekannt. Campus-Workshop Das Forschungsprojekt „Cyle Sommer“ über künstliche Intelligenz war der Name eines Sommer-Workshops von 1956, der nun von vielen (aber nicht alle) als halbstaatliche Veranstaltung für künstliche Intelligenz als Feld betrachtet wurde. Datenverstärkung bei der Datenanalyse werden zur Erhöhung der Datenmenge eingesetzt. Sie hilft bei der Schulung eines maschinenlesbaren Lernens. Daten Fusion Integration mehrerer Datenquellen, um kohärentere, genaue und nützliche Informationen zu produzieren, als dies von jeder einzelnen Datenquelle vorgesehen ist. Integration von Daten Verfahren zur Kombination von Daten, die in verschiedenen Quellen wohnen und den Nutzern einen einheitlichen Standpunkt vermitteln. In einer Vielzahl von Situationen, die sowohl kommerzielle (wie z.B. wenn zwei ähnliche Unternehmen ihre Datenbanken zusammenlegen müssen) als auch wissenschaftliche (kombinierende Forschungsergebnisse aus verschiedenen Bioinformatik-Repositories, z.B.) Domänen umfassen. Datenintegration scheint mit zunehmender Häufigkeit wie das Volumen (d. h. große Daten) und die Notwendigkeit, bestehende Daten zu teilen. Es ist der Schwerpunkt einer umfassenden theoretischen Arbeit geworden, und zahlreiche offene Probleme sind ungelöst. Data Mining Prozess der Entdeckung von Mustern in großen Datensets, die Methoden an der Schnittstelle von Maschinenlern, Statistiken und Datenbankensystemen umfassen. Datenwissenschaft Ein interdisziplinärer Bereich, der wissenschaftliche Methoden, Prozesse, Algorithmen und Systeme nutzt, um Kenntnisse und Erkenntnisse aus Daten in verschiedenen Formen zu sammeln, sowohl strukturiert als auch unstrukturiert, ähnlich dem Datenabbau. Datenwissenschaft ist ein Konzept zur Vereinheitlichung von Statistiken, Datenanalyse, maschinellem Lernen und ihren verwandten Methoden, um "die tatsächlichen Phänomene" mit Daten zu vergleichen und zu analysieren. Sie beschäftigt Techniken und Theorien aus vielen Bereichen im Zusammenhang mit Mathematik, Statistiken, Informationstechnologie und Computerwissenschaften. Daten Datenset. Sammlung von Daten. Häufig entspricht ein Datensatz dem Inhalt einer einzigen Datenbanktabelle oder einer einheitlichen statistischen Datenmatrix, in der jede Spalte der Tabelle eine bestimmte Variablen darstellt, und jede Folge entspricht einem bestimmten Mitglied der betreffenden Daten. In den Daten sind Werte für die einzelnen Variablen, wie Höhe und Gewicht eines Gegenstands, für jedes Mitglied der Daten festgelegt. Jeder Wert ist als Datum bekannt. Je nach Anzahl der Folgen können die Daten für einen oder mehrere Mitglieder enthalten. Datenlager (DW oder DWH) Weiter Unternehmensdatenlager (EDW). Ein System zur Berichterstattung und Datenanalyse. DWs sind zentrale Datenspeicher aus einem oder mehreren unterschiedlichen Quellen. Sie speichern aktuelle und historische Daten in einem einzigen Ort Eine faktische Programmierungssprache ist ein Teil von Prolog. Es wird oft als Abfragesprache für deduktive Datenbanken verwendet. Datenlog hat in den letzten Jahren neue Anwendung in den Bereichen Datenintegration, Informationsgewinnung, Vernetzung, Programmanalyse, Sicherheit und Cloud Computing gefunden. Entscheidungsgrenze Im Falle von Backpropagation-basierten künstlichen Neuralnetzen oder Perceptrons ist die Art der Entscheidungsgrenze, die das Netzwerk erfahren kann, durch die Anzahl der versteckten Schichten bestimmt. Wenn es keine versteckten Schichten hat, kann es nur lineare Probleme erlernen. Wenn es eine versteckte Schicht hat, kann sie jede kontinuierliche Funktion in den von der Universalannäherung desorem aufgezeigten Compact-Untersets von Rn erfahren, so dass sie eine willkürliche Entscheidungsgrenze haben kann. Beschlussunterstützungssystem (DSS) Informationssystem für Unternehmen oder organisatorische Entscheidungen. DSSs dienen der Verwaltung, der Tätigkeit und der Planung einer Organisation (normalerweise Mitte und höheres Management) und helfen den Menschen, Entscheidungen über Probleme zu treffen, die sich schnell ändern und nicht im Voraus leicht spezifiziert werden können – d. h. unstrukturierte und halbstrukturierte Entscheidungsprobleme. Systeme zur Unterstützung der Entscheidung können entweder vollständig computergesteuert oder human angetrieben oder kombiniert werden. Entscheidungstheorie Theorie der Wahl. Studie über die Entscheidung eines Agenten. Entscheidungstheorie kann in zwei Bereiche unterteilt werden: normative Entscheidungstheorie, die Ratschläge dazu gibt, wie die besten Entscheidungen in Form von unsicheren Überzeugungen und einer Reihe von Werten getroffen werden können, und beschreibende Entscheidungstheorie, die untersucht, wie bestehende, möglicherweise irrationale Substanzen tatsächlich Entscheidungen treffen. Entscheidung Baum Lernen nutzt einen Beschlussbaum (als prädikatives Modell), um sich von Beobachtungen über einen Punkt (vorgeschrieben in den Zweigen) bis zu Schlussfolgerungen über den Zielwert des Gegenstands (vorgeschrieben in den Blätter) zu äußern. Es ist eines der prädiktiven Modellierungskonzepte, die in Statistiken, Datengewinnung und Maschinenbau verwendet werden. deklarative Programmierung Programmieren – eine Art des Aufbaus der Struktur und Elemente von Computerprogrammen, die die Logik einer Berechnung ohne Angabe des Kontrollflusses zum Ausdruck bringen. Deduktive Klasse eine Art künstlicher Intelligenz-Antriebsmotor. In einer Rahmensprache über einen Bereich, wie medizinische Forschung oder Molekularbiologie, wird dies als Input herangezogen. z.B. die Namen von Klassen, Unterklassen, Eigenschaften und Beschränkungen für zulässige Werte. Deep Blue war ein von IBM entwickeltes Hochleistungsrechner. Es ist bekannt, dass es das erste Computerspielsystem ist, um sowohl ein Schachspiel als auch ein Schachspiel gegen einen Weltführer unter regelmäßigen Kontrollen zu gewinnen. tiefes Lernen Tief strukturiertes Lernen oder hierarchisches Lernen. Teil einer breiteren Familie von maschinenlesbaren Lernmethoden auf der Grundlage von Lerndatenvertretungen im Gegensatz zu aufgabenspezifischen Algorithmen. Lernen kann beaufsichtigt, halbüberwacht oder unüberwacht werden. DeepMind Technologies A britisches Unternehmen für künstliche Intelligenz, das im September 2010 gegründet wurde. Das Unternehmen befindet sich in London mit Forschungszentren in Kanada, Frankreich und den Vereinigten Staaten. Google im Jahr 2014 hat das Unternehmen ein Neuralnetz geschaffen, das erfahren hat, wie Videospiele in einer Mode wie der des Menschen, sowie eine Neural Turing-Maschine oder ein Neuralnetz, das in der Lage sein kann, ein externes Gedächtnis wie eine herkömmliche Turing-Maschine zu nutzen, was zu einem Computer führt, der das kurzfristige Gedächtnis des menschlichen Gehirns anwendet. Das Unternehmen stellte im Jahr 2016 Schlagzeilen nach dem AlphaGo-Programm vor Go Player Lee Sedol, der Weltsieger, in einem fünfstufigen Spiel, das Gegenstand eines Dokumentarfilmfilms war. Mehr allgemeines Programm AlphaZero, das die leistungsstärksten Programme mit sich bringt Go, Schach und Shogi (Japanischer Schach) nach einigen Tagen Spiel gegen sich selbst durch verstärktes Lernen. Standardlogik Eine nicht-Montonische Logik, die von Raymond Reus vorgeschlagen wurde, um mit Standardannahmen die Begründung zu formalisieren. Beschreibungslogik (DL)Eine Familie formaler Sprachen zur Wissensvertretung. Viele DLs sind stärker als propositionale Logik, aber weniger als die erste Logik. Im Gegensatz zu Letzteren sind die Kerngrundprobleme für DLs (normalerweise) und effiziente Entscheidungsverfahren für diese Probleme konzipiert und umgesetzt worden.Es gibt allgemeine, räumliche, zeitliche, spatiotemporale und fuzzy Beschreibungen Logiken, und jede Beschreibungslogik ist ein anderes Gleichgewicht zwischen DL-Etilität und mit Gründen versehener Komplexität, indem verschiedene mathematische Bauherren unterstützt werden. Entwicklungstechniken (DevRob) auch epigentische Robotik. Ein wissenschaftlicher Bereich, der die Entwicklungsmechanismen, Architekturen und Zwänge untersucht, die ein lebenslanges und offenes Lernen neuer Fähigkeiten und neue Kenntnisse in eingebetteten Maschinen ermöglichen. Diagnose Was die Entwicklung von Algorithmen und Techniken angeht, die feststellen können, ob das Verhalten eines Systems korrekt ist. Wenn das System nicht ordnungsgemäß funktioniert, sollte der Algorithmus so genau wie möglich bestimmen können, welchen Teil des Systems versäumt ist und welche Art von Fehlern es sich stellt. Die Berechnung beruht auf Beobachtungen, die Informationen zum aktuellen Verhalten liefern. Dialogsystem Gesprächspartner (CA). Ein Computersystem, das mit einem Menschen mit einer kohärenten Struktur verwechselt werden soll. Dialogsysteme haben Text, Rede, Grafik, Häptik, Gesten und andere Kommunikationsarten sowohl im Input- als auch im Output-Kanal eingesetzt. Verringerung der Dimension Ebenfalls eine Verringerung der Dimension. Verfahren zur Verringerung der Anzahl der in Betracht gezogenen Zufallsvariablen durch Erlangung einer Reihe von Hauptvariablen. Es kann in die Auswahl und die Materialgewinnung unterteilt werden. System Jedes System mit einer zahlbaren Anzahl von Staaten. Diskrete Systeme können mit kontinuierlichen Systemen, die auch analoge Systeme genannt werden, im Gegensatz stehen. Ein endgültiges diskretes System wird oft mit einem zielgerichteten Diagramm konzipiert und wird nach Rechentheorie für Richtigkeit und Komplexität analysiert. Da diskrete Systeme eine zahlbare Anzahl von Staaten haben, können sie in genauen mathematischen Modellen beschrieben werden. Ein Computer ist eine finite staatliche Maschine, die als eigenes System angesehen werden kann. Da Computer häufig verwendet werden, um nicht nur andere diskrete Systeme zu modellieren, sondern auch kontinuierliche Systeme zu entwickeln, wurden Methoden entwickelt, um Echtzeit-Systeme als getrennte Systeme zu repräsentieren. Eine solche Methode beinhaltet die Probenahme eines kontinuierlichen Signals in bestimmten Zeitintervallen. dezentrale künstliche Intelligenz (DAI) Ein Teilbereich der künstlichen Intelligenzforschung zur Entwicklung verteilter Lösungen für Probleme. DAI ist eng mit einem Vorgänger des Bereichs der Multi-agen-Systeme verbunden. dynamische eipemic Logik (DEL)Ein logischer Rahmen für den Wissens- und Informationsaustausch. In der Regel konzentriert sich die DEL auf Situationen mit mehreren Agenten und Studien, wie ihre Wissensänderungen auftreten. Lernen Sie eine Lernmethode, bei der das System während der Ausbildung des Systems eine allgemeine, bedingungsunabhängige Zielfunktion im Vergleich zum Lernen von Lazy entwickeln soll, wo die allgemeine Ausrichtung über die Ausbildungsdaten hinaus verzögert wird, bis eine Abfrage an das System gestellt wird. Ebert test Ein Test, der zeigt, ob eine computerbasierte, synthetisierte Stimme ein Finger mit ausreichender Kompetenz, um die Menschen zu Lachen zu bringen. Roger Ebert wurde auf der TED-Konferenz 2011 als Herausforderung für Entwickler von Software vorgeschlagen, einen computerisierten Sprachführer zu haben, der die Verlagerungen, die Lieferung, die Zeitplanung und die Intonationen eines Menschen beherrscht. Der Test ähnelt dem von Alan Turing im Jahr 1950 vorgeschlagenen Turing-Test, um die Fähigkeit eines Computers zu ermitteln, intelligentes Verhalten zu zeigen, indem er von einem Menschen unzerstörbare Leistung schafft. Echo State Network (ESN) Ein wiederkehrendes Neuralnetz mit einer leicht vernetzten versteckten Schicht (mit typischerweise 1 % Konnektivität). Die Konnektivität und die Gewichte versteckter Neuronen sind fest und zufällig zugewiesen. Die Gewichte der Output-Neunen können gelernt werden, damit das Netz spezifische zeitliche Muster (re) erstellen kann. Hauptinteresse dieses Netzes ist, dass das Verhalten zwar nichtlinear ist, aber die einzigen Gewichte, die während der Ausbildung geändert werden, sind für die Synaps, die die versteckten Neuronen an die Produktion von Neuronen verbinden. So ist die Fehlerfunktion quadratisch gegenüber dem Parametervektor und kann leicht zu einem linearen System differenziert werden. Kondome auch Schnittstellenagent. Ein intelligenter Wirkstoff, der mit der Umwelt durch ein physikalisches Organ in dieser Umgebung interagieren kann. Agenten, die grafisch mit einem Körper vertreten sind, z.B. ein Mensch oder ein Karikaturer, werden ebenfalls als verkörperte Agenten bezeichnet, obwohl sie nur virtuelle, nicht physische, verkörperte. kognitive Wissenschaft Ein interdisziplinärer Forschungsbereich, dessen Ziel darin besteht, die Mechanismen zu erklären, die dem intelligenten Verhalten zugrunde liegen. Es umfasst drei Hauptmethoden: 1) das Modell psychologischer und biologischer Systeme in ganzheitlicher Weise, die den Geist und Körper als Einheit betrachten, 2) die Bildung eines gemeinsamen Regelwerks für intelligentes Verhalten und 3) die experimentelle Verwendung von Robotern in kontrollierten Umgebungen. fehlerorientiertes Lernen Ein Teilbereich des maschinenlesbaren Lernens besorgt darüber, wie ein Agenten Maßnahmen in einem Umfeld ergreifen sollte, um Fehler zu minimieren. Es ist eine Art des verstärkten Lernens. durchschnittlich maschinelles Lernen, insbesondere bei der Schaffung künstlicher Neuralnetze, ist der Prozess, mehrere Modelle zu erstellen und zu kombinieren, um einen gewünschten Output zu produzieren, anstatt nur ein Modell zu schaffen. Ethik der künstlichen Intelligenz Teil der Ethik der Technik, die auf künstliche Intelligenz zugeschnitten ist. Entwicklungsgorithmus (EA) Ein Teil der Entwicklungssoftware, ein generischer, bevölkerungsbasierter Metahetourismusoptimierungsgorithmus. Ein EA nutzt Mechanismen, die von der biologischen Entwicklung inspiriert sind, wie Reproduktion, Mutation, Recombination und Auswahl. Lösungen für das Optimierungsproblem spielen die Rolle der Menschen in einer Bevölkerung und die Eignungsfunktion bestimmt die Qualität der Lösungen (siehe auch Verlustfunktion). Evolution der Bevölkerung erfolgt dann nach wiederholter Anwendung der oben genannten Betreiber. Entwicklung Eine Familie von Algorithmen für die globale Optimierung, die von der biologischen Entwicklung inspiriert ist, und das Unterfeld künstlicher Intelligenz und Soft Computing studieren diese Algorithmen. Technischer Art sind sie eine Familie von bevölkerungsbasierten Versuchs- und Fehlerproblemen, die mit einem metahe touristischen oder katastrophalen Optimierungscharakter verbunden sind. Entwicklung der Klassifikationsfunktion (ECF) Evolvierende Klassenprüferfunktionen oder entwicklungsfördernde Klassengeräte werden für die Einstufung und Bündelung im Bereich des maschinellen Lernens und der künstlichen Intelligenz verwendet, die in der Regel für die Aufgaben im Bereich des Datastreaming in dynamischen und sich verändernden Umgebungen eingesetzt werden. bestehen Die Hypothese, dass bedeutende Fortschritte bei der künstlichen allgemeinen Intelligenz (AGI) zu einem gewissen Zeitpunkt zu menschlichem Aussterben oder einer anderen unerträglichen globalen Katastrophe führen könnten. Expertensystem Ein Computersystem, das die Entscheidungsfähigkeit eines menschlichen Experten verkörpert. Expertensysteme sollen komplexe Probleme lösen, indem sie durch Wissensgremien begründet werden, die vor allem als ob-thek-Regelung und nicht durch den herkömmlichen Verfahrenscode vertreten sind. Schnell-und-frugale Bäume Art des Klassifikationsbaums. Fast-and-frugale Bäume können als Entscheidungsinstrumente genutzt werden, die als lexicographische Klassenifier dienen und gegebenenfalls eine Maßnahme (Entscheidung) für jede Klasse oder Kategorie umfassen. Materialgewinnung In den Bereichen Maschinenbau, Mustererkennung und Bildverarbeitung beginnt die Materialgewinnung aus einem ersten Satz von Messdaten und baut abgeleitete Werte (Funktionen) auf, um informativ und unredlich zu sein, die nachfolgenden Lern- und allgemeinenisierungsschritte zu erleichtern und in einigen Fällen zu besseren menschlichen Interpretationen zu führen. Lernen maschinenlesbares Lernen ist eine Reihe von Techniken, die ein System ermöglichen, automatisch die für die Erkennung oder Klassifizierung von Rohdaten erforderlichen Vertretungen zu entdecken. Dies ersetzt manuelles Merkmal Engineering und ermöglicht es einer Maschine, die Merkmale zu lernen und sie zu nutzen, um eine bestimmte Aufgabe auszuführen. Auswahl In den Bereichen Maschinenbau und Statistik, Merkmalsauswahl, auch bekannt als variable Auswahl, Auswahl oder variable Auswahl, ist das Verfahren zur Auswahl eines Teils relevanter Merkmale ( Variablen, Vorhersehbare) für den Einsatz im Modellbau. federführendes Lernen Eine Art von Maschinenlernen, die eine Schulung auf mehreren Geräten mit dezentralen Daten ermöglichen, um so die Privatsphäre einzelner Nutzer und deren Daten zu erhalten. erste Logik Auch bekannt als First-order prädikate kalorien und prädikative Logik. Sammlung formaler Systeme in Mathematik, Philosophie, Sprachen und Computerwissenschaften. First-order Logik verwendet quantifizierte Variablen über nicht-logische Gegenstände und ermöglicht die Verwendung von Sätzen, die Variablen enthalten, so dass anstelle von Verhängungen wie Sokrates ein Mensch Ausdruck in der Form "Es gibt X so, dass es sich um Socrates und X handelt, und es gibt einen Quantifizierenden, während X variabler ist. Es unterscheidet sich von der propositionalen Logik, die nicht quantifizierte oder Beziehungen verwendet. fließend eine Bedingung, die sich über die Zeit ändern kann. In logischen Ansätzen, die sich auf Maßnahmen beziehen, können fließende in der ersten Logik vertreten werden, indem sie ein Argument vorweisen, das von der Zeit abhängt. formale Sprache Eine Reihe von Wörtern, deren Briefe aus einem Alphabet stammen und nach einem bestimmten Satz von Regeln gut informiert sind. Künftige Kette Weitere Gründe. Eines der beiden wichtigsten Methoden, die bei der Nutzung eines Gleichgültigkeits-Motors zugrunde liegen, kann logischerweise als wiederholte Anwendung von Modus-Mens bezeichnet werden. Forward Chaining ist eine beliebte Umsetzungsstrategie für Sachverständigensysteme, Unternehmens- und Produktionsregeln. Das Gegenteil von der zukunftsgerichteten Kette ist rückwärts. Künftige Kette beginnt mit den verfügbaren Daten und nutzt Regeln zur Erfassung von mehr Daten (z.B. von Endbenutzern), bis ein Ziel erreicht ist. Ein klasse-Motor mit einer vorausschauenden Kette sucht die Regeln für die Gleichgültigkeit, bis er feststellt, wo die Einspeise (If-Klausel) wahr ist. Wenn eine solche Regel gefunden wird, kann der Motor die Folge (Die Klausel) abschließen, was zur Ergänzung neuer Informationen zu seinen Daten führt. Rahmen Eine künstliche Datenstruktur, die genutzt wird, um Kenntnisse in Substrukturierungen zu zerteilen, indem sie "stereotypisierte Situationen" repräsentiert. Armaturen sind die primäre Datenstruktur, die in der künstlichen Intelligenz-Rahmensprache verwendet wird. Sprache Eine Technologie, die zur Wissensvertretung in der künstlichen Intelligenz verwendet wird. Laufbilder werden als Ontologien von Sets und Untersets der Rahmenkonzepte aufbewahrt. Sie sind ähnlich wie Klassenhierarchien in objektorientierten Sprachen, obwohl ihre grundlegenden Gestaltungsziele unterschiedlich sind. Leiterplatten konzentrieren sich auf die explizite und intuitive Darstellung von Wissen, während Objekte auf die Erfassung und das Verstecken von Informationen konzentrieren. Links stammen aus der AI-Forschung und Objekte hauptsächlich im Software-Engineering. In der Praxis überschneiden sich jedoch die Techniken und Fähigkeiten der Rahmen- und objektorientierten Sprachen erheblich. Kontext Problem der Suche nach ausreichenden Sammlungen von Axioms für eine tragfähige Beschreibung eines Roboterumfeldes. benutzerfreundliche künstliche Intelligenz auch freundschaftlich oder FAI. Eine hypothetische künstliche allgemeine Intelligenz (AGI), die sich positiv auf die Menschheit auswirken würde. Es ist Teil der Ethik der künstlichen Intelligenz und ist eng mit der Maschinenethik verknüpft. Maschinenethik ist zwar besorgt darüber, wie ein künstlich intelligentes Erreger verhalten sollte, aber eine benutzerfreundliche künstliche Intelligenzforschung konzentriert sich darauf, wie dieses Verhalten praktisch umgesetzt und sichergestellt wird, dass es angemessen eingeschränkt ist. Zukunftsstudien Studie über mögliche, wahrscheinliche und vorzugsweise zukunftsfähige Weltviews und Mythen, die sie untermauern. fuzzisches Kontrollsystem Ein Kontrollsystem auf der Grundlage der fuzzy Logik – ein mathematisches System, das die analogen Ausgangswerte in Bezug auf logische Variablen analysiert, die kontinuierliche Werte zwischen 0 und 1 im Gegensatz zu klassischer oder digitaler Logik einnehmen, die auf spezifischen Werten von 1 oder 0 (trugend oder falsch) betrieben werden. Fuzzenlogik Eine einfache Form für die viele wertgeschätzte Logik, in der die Wahrheitswerte von Variablen möglicherweise über einen Grad an Wahrheitsmäßigkeit verfügen, der durch jede echte Zahl in der Bandbreite zwischen 0 (wie in völliger Irreführung) und 1 (wie in völliger Eigenheit) inklusive vertreten werden kann. Somit Es wird eingesetzt, um das Konzept der partiellen Wahrheit zu handhaben, wo der Wahrheitswert zwischen völlig wahrheitsgemäß und völlig falsch reicht. Im Gegensatz zu der Logik von Boolean, wo die Wahrheitswerte von Variablen die Zahl 0 oder 1 nur haben können. fuzzische Regel Eine Regel, die innerhalb von Fuzzy Logiksystemen verwendet wird, um eine Produktion auf Basis von Inputvariablen zu stören. Fuzzen In der klassischen Set-theorie wird die Mitgliedschaft von Elementen in einem Set nach einem bivalenten Zustand bewertet – ein Element, das entweder gehört oder nicht dem Set gehört. Kontrastlich erlaubt fuzzy die schrittweise Bewertung der Mitgliedschaft von Elementen in einem Satz; dies wird mit Hilfe einer Mitgliedschaft beschrieben, die im realen Einheitsintervall [0, 1] bewertet wird. Fuzzy legt die klassischen Sätze in der Regel fest, da die Indikatorfunktionen (aka charakteristische Funktionen) der klassischen Sätze besondere Fälle der Mitgliedschaftsfunktionen von Fuzzy-Sets sind, wenn die letztere nur Werte 0 oder 1. In fuzzy Set Theorie werden klassische bivalente Sätze in der Regel als Kuponsets bezeichnet. In einer Vielzahl von Bereichen, in denen Informationen unvollständig oder unpräzise Informationen, wie Bioinformatik, verwendet werden können. G-Spieltheorie Studie über mathematische Modelle der strategischen Interaktion zwischen rationalen Entscheidungsträgern. Allgemeinspiel (GGP) Das allgemeine Spiel ist das Design künstlicher Intelligenzprogramme, um mehr als ein Spiel erfolgreich zu führen und zu spielen. generatives Netz (GAN)A Klasse von Maschinenlernsystemen. Zwei Neuralnetze Wettbewerb miteinander in einem Null-Risiko-Spielrahmen. Genetikalgorithmus (GA)A metahetourismus, inspiriert durch den Prozess der natürlichen Auswahl, der zur größeren Klasse von evolutionären Algorithmen (EA) gehört. Genetische Algorithmen werden häufig verwendet, um qualitativ hochwertige Lösungen für Optimierungs- und Suchprobleme zu schaffen, indem sie auf Bio-Inspiratoren wie Mutation, Crossover und Auswahl zurückgreifen. Genetiker Ein Betreiber, der in genetischen Algorithmen verwendet wird, um den Algorithmus auf eine Lösung eines bestimmten Problems auszurichten. Es gibt drei Hauptkategorien von Betreibern (Mutation, Crossover und Auswahl), die in Verbindung mit einem anderen arbeiten müssen, um erfolgreich zu sein. Leichte Würmer Schneller Intelligenzoptimierungsgorithmus basierend auf dem Verhalten von Rasierwürmern (auch bekannt als Feuerflies oder Blitzfehler). Grafik (Abstract-Datentyp) In der Computerwissenschaft ist ein Diagramm ein abstrakter Datentyp, der die undirektionalen Graphiken und zielgerichteten Graphiken von Mathematik umsetzen soll; speziell das Feld der Graphik. Grafik (unterschiedliche Mathematik) Mathematik, insbesondere in der Graphik, ist ein Diagramm eine Struktur, die eine Reihe von Gegenständen enthält, in denen einige Paare der Gegenstände in gewissem Maße miteinander verbunden sind. Die Gegenstände entsprechen mathematischen abstrakten, sogenannten Wirbels (auch als Knoten oder Punkte genannt) und jeder der damit zusammenhängenden Wirbelpaare ist ein Rand (auch als Bogen oder Linie bezeichnet). Graph-Datenbank (GDB)A, die Graphik-Strukturen für semantische Anfragen mit Knoten, Kanten und Eigenschaften zur Darstellung und Speicherung von Daten verwendet. Schlüsselbegriff des Systems ist das Diagramm (oder Rand oder Verhältnis), das direkt Datengegenstände in der Speicherung einer Sammlung von Daten und Kanten, die die Beziehungen zwischen den Knoten repräsentieren, betrifft. Die Beziehungen ermöglichen eine direkte Verknüpfung der Daten im Lager und in vielen Fällen mit einem Betrieb. Graph-Datenbanken halten die Beziehungen zwischen Daten als Priorität. Kontakt innerhalb einer Graph-Datenbank ist schnell, weil sie in der Datenbank selbst ständig gespeichert werden. Linke können mit Graphen-Datenbanken akkumuliert werden, was sie für stark miteinander verknüpfte Daten nützlich macht. Graphik Studie der Graphen, die mathematische Strukturen sind, die zur Modellierung von Paarenbeziehungen zwischen Gegenständen verwendet werden. Graphik Bildsuche. Besucher (Kontrolle und/oder Aktualisierung) jedes Vertex in einem Diagramm. Solche Traversals werden von der Reihenfolge klassifiziert, in der die Wirbeltiere besucht werden. Baumtraversal ist ein besonderer Fall von Graph-Traversal. He TouristA-Technik, die für eine schnellere Lösung eines Problems entwickelt wurde, wenn klassische Methoden zu langsam sind oder eine ungefähre Lösung finden, wenn klassische Methoden keine genaue Lösung finden. Dies wird erreicht durch den Handel optimal, Vollständigkeit, Genauigkeit oder Präzision für Geschwindigkeit. In einer Weise kann es als Kurzform betrachtet werden. Eine he Tourist-Funktion, die auch einfach ein Hetourismus genannt wird, ist eine Funktion, die Alternativen bei der Suche nach Algorithmen auf jeder Zweigniederlassung auf der Grundlage der verfügbaren Informationen, um zu entscheiden, welche Zweigniederlassung zu befolgen ist. Man kann beispielsweise die genaue Lösung angleichen. versteckte Schicht Eine interne Schicht von Neuronen in einem künstlichen Neuralnetz, das nicht für Input oder Output bestimmt ist. versteckte Einheit A Neuron in einer versteckten Schicht in einem künstlichen Neuralnetz. Hyperhetourismus Eine he Tourist-Suchesmethode, die versucht, den Prozess der Auswahl, Kombination, Erzeugung oder Anpassung mehrerer einfacherer Hetourismus (oder Komponenten solcher Hetourismus) zu automatisieren, um rechnerische Suchprobleme effizient zu lösen, oft durch die Einführung von maschinenlesbaren Lernmethoden. Einer der Motivationen für das Studium von Hyperhetourismus besteht darin, Systeme aufzubauen, die Klassen von Problemen bewältigen können, anstatt nur ein Problem zu lösen. IAD Computational Intelligence Society Eine professionelle Gesellschaft des Instituts für Elektro- und Elektronikingenieure (IEEE) konzentriert sich auf "die Theorie, Konzeption, Anwendung und Entwicklung biologisch und sprachlicher und motivierter rechnerischer Paradigmen, die die Neuralnetze, die Anschlusssysteme, die genetischen Algorithmen, die Entwicklung von Fuzzy-Systemen und hybride Systeme, in denen diese Paradigmen enthalten sind". Bildung Methode des maschinenlesbaren Lernens, bei dem die Inputdaten kontinuierlich verwendet werden, um das vorhandene Modell-Know-how auszuweiten, d. h. um das Modell weiter auszubilden. Es stellt eine dynamische Technik des kontrollierten Lernens und des unüberwindbaren Lernens dar, die angewendet werden können, wenn die Ausbildungsdaten im Laufe der Zeit schrittweise verfügbar werden oder ihre Größe aus Systemspeichergrenzwerten liegen. Algorithms, die das inkrementelle Lernen erleichtern können, sind als inklassische maschinelle Lernalgorithmen bekannt. Leistungsklasse Komponenten des Systems, die logischen Regeln für die Wissensbasis gelten, um neue Informationen zu erwirtschaften. Informationsintegration (II) Die Bündelung von Informationen aus heterogenen Quellen mit unterschiedlichen konzeptuellen, kontextalen und grafischen Vertretungen. Es wird verwendet, um Daten aus unstrukturierten oder halbstrukturierten Ressourcen zu sammeln. In der Regel bezieht sich die Informationsintegration auf Textangaben von Wissen, aber manchmal auf reiche Inhalte. Information Fusion, die eine verwandte Bezeichnung ist, beinhaltet die Kombination von Informationen in ein neues Informationspaket zur Verringerung von Entlassungen und Unsicherheit. Informationsverarbeitung Sprache (IPL) Programmierungssprache, die Merkmale enthält, die dazu beitragen sollen, Programme zu unterstützen, die einfache Problemlösungsaktionen wie Listen, dynamische Speicherzuweisung, Datentypen, Wiedereingliederung, Funktionen als Argumente, Generatoren und kooperative Multitasking durchführen. IPL hat das Konzept der Listeverarbeitung entwickelt, wenn auch in einem Sammelstil. Intelligence-Vereinfachung (IA) auch kognitive Augation, maschinell erweiterte Intelligenz und verstärkte Intelligenz. effektive Nutzung der Informationstechnologie in der Verstärkung der menschlichen Intelligenz. Intelligenz Explosion Ein mögliches Ergebnis der Menschheit baut künstliche allgemeine Intelligenz (AGI). AGI wäre in der Lage, die Selbstverbesserung wiederzuverfolgen, was zum raschen Auftreten von ASI (artificial Superintelligence), deren Grenzen zum Zeitpunkt der technologischen Einzigartigkeit unbekannt sind.intelligenter Agenten (IA)Ein autonomes Unternehmen, das seine Tätigkeit auf die Erreichung von Zielen (d. h. es ist ein Agenten) auf einem Umfeld mit Beobachtung durch Sensoren und damit einhergehende Antriebe (d. h. es ist intelligent). Intelligente Agenten können auch Kenntnisse lernen oder nutzen, um ihre Ziele zu erreichen. Sie können sehr einfach oder sehr komplex sein. intelligente Kontrolle Klasse der Kontrolltechniken, die verschiedene künstliche Intelligenz-.skonzepte wie Neuralnetze, Bayesische Wahrscheinlichkeit, Fuzzy Logik, Maschinenbau, verstärktes Lernen, evolutionäre Rechen- und Genetik verwenden. intelligente persönliche Assistentin virtuelle Assistentin oder persönliche digitale Assistentin. Software-Beauftragte, die Aufgaben oder Dienstleistungen für eine Person ausüben können, die auf verbalen Befehlen basiert. Manchmal wird der Begriff Chatbot verwendet, um virtuelle Assistenten allgemein oder speziell auf Online-Chat zu verweisen (oder in einigen Fällen Online-Chatprogramme, die ausschließlich für Unterhaltungszwecke sind). Manche virtuelle Assistenten sind in der Lage, die menschliche Rede zu interpretieren und über synthetische Stimmen zu antworten. Nutzer können Fragen der Assistenten, die Kontrolle der Heimautomatisierungsgeräte und die Wiedergabe der Medien über die Stimme stellen und andere grundlegende Aufgaben wie E-Mail, To-do-Listen und Kalender mit verbalen Befehlen verwalten. Auslegung Zuordnung von Bedeutung zu den Symbolen einer formalen Sprache. Viele formale Sprachen, die in Mathematik, Logik und theoretischer Computerwissenschaft verwendet werden, sind ausschließlich kontklusionsorientiert definiert, und so haben sie keine Bedeutung, bis sie eine gewisse Auslegung erhalten. Die allgemeine Studie über die Auslegung von formalen Sprachen wird als formale semantische Stoffe bezeichnet. natürliche Motivation Ein intelligenter Wirkstoff ist in der Tat motiviert, zu handeln, wenn allein die durch die Aktion gewonnenen Erfahrungen den Motivationsfaktor bilden. Informationsinhalte in diesem Zusammenhang werden in der Informationstheorie als Quantifizierung der Unsicherheit gemessen. Eine typische Motivation ist die Suche nach ungewöhnlichen (auffälligen) Situationen im Gegensatz zu einer typischen extrinsischen Motivation wie der Suche nach Lebensmitteln. Intrinsisch motivierte künstliche Erreger zeigen Verhaltenen, die auf Exploration und Neugier zurückzuführen sind. Baum Logikbaum. Eine grafische Aufschlüsselung einer Frage, die sie vertikal in ihre verschiedenen Komponenten eindringt und die Fortschritte in Details, wie sie das Recht gelesen. Problembäume sind nützlich bei der Problemlösung, um die Ursachen eines Problems zu ermitteln und mögliche Lösungen zu finden. Sie stellen auch einen Bezugspunkt dar, um zu sehen, wie jedes Stück in das Gesamtbild eines Problems passt. J-Zuckergorithmus Clique Baum. Eine Methode, die im Maschinenlernen verwendet wird, um die Marginalisierung in allgemeinen Graphen zu erhalten. Wesentlich bedeutet dies, dass die Anwendbarkeit auf ein verändertes Diagramm, das als Bindebaum bezeichnet wird, ausgeübt wird. Die Graphik wird als Baum bezeichnet, weil sie in verschiedene Datenabschnitte unterteilt ist; Knoten der Variablen sind die Zweige. KK-Methode Kern Kernmethoden sind eine Klasse von Algorithmen für Musteranalyse, deren bekanntestes Mitglied die Unterstützungsvektor (SVM) ist. Die allgemeine Aufgabe der Musteranalyse besteht darin, allgemeine Arten von Beziehungen zu finden und zu studieren (z.B. Cluster, Rankings, Hauptkomponenten, Korrelationen, Klassifizierungen). KL-ONEA bekanntes Wissensvertretungssystem in der Tradition semantischer Netze und Rahmen; das ist eine Rahmensprache. Das System ist ein Versuch, semantische Unterschiede in den semantischen Netzvertretungen zu überwinden und konzeptuelle Informationen als strukturiertes Erbschaftsnetz explizit darzustellen. Wissenserwerb Verfahren zur Festlegung der für ein wissensbasiertes System erforderlichen Regeln und Methoden. In Verbindung mit Sachverständigensystemen wurde der Satz erstmals verwendet, um die ersten Aufgaben im Zusammenhang mit der Entwicklung eines Expertensystems zu beschreiben, nämlich die Suche und das Interview von Domain-Experten und die Erfassung ihrer Kenntnisse über Regeln, Gegenstände und rahmenbasierte Ontologien. Know-how-basiertes System (KBS)A Computerprogramm, das aus Gründen und Verwendung einer Wissensbasis zur Lösung komplexer Probleme besteht. Der Begriff ist breit und bezieht sich auf viele unterschiedliche Systeme. Ein gemeinsames Thema, das alle wissensbasierten Systeme vereint, ist ein Versuch, Wissen explizit und ein Grundsystem zu vertreten, das es ermöglicht, neue Erkenntnisse zu gewinnen. So hat ein wissensbasiertes System zwei Unterscheidungsmerkmale: eine Wissensbasis und ein Gleichgültigkeitsmotor. Know-how-Engineering (KE) Alle technischen, wissenschaftlichen und sozialen Aspekte des Aufbaus, der Erhaltung und der Nutzung wissensbasierter Systeme. Wissensförderung Aufbau von Wissen aus strukturierten (relationalen Datenbanken, XML) und unstrukturierten (Text, Dokumente, Bilder) Quellen. Das daraus resultierende Wissen muss in einem maschinenlesbaren und maschinenlesbaren Format liegen und muss Wissen in einer Weise repräsentieren, die die Einziehung erleichtert. Obwohl es methodisch ähnlich ist wie die Informationsgewinnung (NLP) und ETL (Datenlager), sind die Hauptkriterien, dass das Extraktionsergebnis über die Schaffung strukturierter Informationen oder die Umwandlung in ein Vergleichsschema hinausgeht. Es erfordert entweder die Wiederverwendung bestehender formaler Kenntnisse (Verwendung von Identifikations- oder Ontologien) oder die Erstellung eines Schemas auf der Grundlage der Quellendaten. Know-how Interchange Format (KIF)A Computersprache, die Systeme zum Austausch und Weiterverwendung von Informationen aus wissensbasierten Systemen ermöglichen soll. KIF ist ähnlich wie die Gestaltung von Sprachen wie KL-ONE und LOOM, aber im Gegensatz zu dieser Sprache ist seine primäre Rolle nicht als Rahmen für den Ausdruck oder die Nutzung von Wissen, sondern für den Austausch von Wissen zwischen Systemen gedacht. Die Designer von KIF wiesen darauf hin, dass sie nach Postchi. Postchi wurde nicht in erster Linie als Sprache konzipiert, um Dokumente zu speichern und zu manipulieren, sondern als Interbankenformat für Systeme und Geräte, um Dokumente auszutauschen. KIF soll den Austausch von Wissen über verschiedene Systeme erleichtern, die unterschiedliche Sprachen, Formalismus, Plattformen usw. verwenden. .dt-Klasse="Gemeinde "id="Wissensvertretung und Begründung (kr2 oder kr &r)" Stil="margin-top: 0,4em;"[Wissensvertretung und Begründung (KR2 oder KR &R)The Bereich der künstlichen Intelligenz, die darauf abzielt, Informationen über die Welt in einer Form darzustellen, dass ein Computersystem komplexe Aufgaben wie die Diagnose eines medizinischen Zustands oder einen Dialog in einer natürlichen Sprache lösen kann. Wissensvertretung führt Erkenntnisse aus der Psychologie ein, wie Menschen Probleme lösen und Wissen darstellen, um formalismus zu entwerfen, die komplexe Systeme leichter gestalten und bauen. Wissensvertretung und Grundstoff enthalten auch Erkenntnisse aus Logik, um verschiedene Arten von Gründen zu automatisieren, wie die Anwendung von Regeln oder die Beziehungen von Set- und Untersets. Beispiele für die Darstellung von Wissen sind semantische Netze, Systemarchitektur, Rahmen, Regeln und Ontologien. Beispiele für automatisierte Anlaufmotoren sind Motoren für die Anteilnahme, die Proversorem-Provers und die Klassenaggregate. Lernen Lazy Learning ist eine Lernmethode, bei der die allgemeine Erfassung der Ausbildungsdaten grundsätzlich verzögert wird, bis eine Abfrage in das System gestellt wird, im Gegensatz zu ins Erwerbsleben, wo das System versucht, die Ausbildungsdaten vor dem Erhalt von Anfragen zu verbreiten. Lisp (Programmierungssprache) (LISP)A-Familie von Programmiersprachen mit langer Geschichte und einer eindeutigen, vollziehenden Prävalenz. Programmierung Konsortial Paradigma, das weitgehend auf formaler Logik basiert. Jedes in einer Logik-Programmsprache geschriebene Programm ist eine Reihe von Sätzen in logischer Form, die Fakten und Regeln zu einigen Problembereichen zum Ausdruck bringen. Familien mit wichtigen Logik-Programmplanungssprachen umfassen Prolog, die Programmierung (ASP) und Datenlog. langfristiges Gedächtnis (LSTM)Ein künstliches Netzarchitektur, das im Bereich des tiefen Lernens verwendet wird. Anders als Standard-Feedforward-Neural-Netze verfügt LSTM über Feedback-Verbindungen, die es zu einem „allgemeinen Zweck-Computer“ machen (d. h. es kann etwas berechnen, dass eine Turing-Maschine kann). Sie kann nicht nur einzelne Datenpunkte (wie Bilder) verarbeiten, sondern auch alle Datensequenzen (wie Reden oder Video). M Maschinenvision (MV) Die Technologien und Methoden, die zur Bereitstellung von bildgestützten automatischen Inspektionen und Analysen für Anwendungen wie automatische Inspektion, Prozesskontrolle und Roboterleitlinien verwendet werden, in der Regel in der Industrie. Maschinenvision ist ein Begriff, der eine große Anzahl von Technologien, Software und Hardware, integrierte Systeme, Maßnahmen, Methoden und Fachwissen umfasst. Maschinenvision als Systemtechnikdisziplin kann von Computervision, einer Form der Computerwissenschaft, unterschieden werden. Es versucht, bestehende Technologien in neue Weise zu integrieren und sie anzuwenden, um echte weltweite Probleme zu lösen. Der Begriff ist der bevorzugte Faktor für diese Funktionen in industriellen Automatisierungsumgebungen, wird aber auch für diese Funktionen in anderen Umgebungen wie Sicherheit und Fahrzeugberatung verwendet. Markov Kette Ein katastrophales Modell, das eine Reihe möglicher Ereignisse beschreibt, in denen die Wahrscheinlichkeit jeder Veranstaltung nur vom Staat abhängt, der im vorherigen Ereignis erreicht wurde. Markov-Entscheidungsprozess (MDP)A Einzelzeit krchastic controlprozess. Es bietet einen mathematischen Rahmen für die Modellierung der Entscheidungsfindung in Situationen, in denen die Ergebnisse teilweise zufällig und teilweise unter Kontrolle eines Entscheidungsträgers liegen. MDPs sind nützlich für die Prüfung von Optimierungsproblemen, die durch dynamische Programmierung und verstärktes Lernen gelöst werden. mathematische Optimierung mathematische Programmierung. Mathematik, Informatik und Betriebsforschung, die Auswahl eines besten Faktors (in Bezug auf einige Kriterien) aus einigen verfügbaren Alternativen. Maschinenbau (ML) Die wissenschaftliche Studie von Algorithmen und statistischen Modellen, die Computersysteme verwenden, um eine bestimmte Aufgabe effizient zu erfüllen, ohne explizite Anweisungen zu verwenden und sich stattdessen auf Muster und Gleichgültigkeit zu stützen. Maschinenaufhörung Computerprüfung (CA). ein allgemeines Feld der Studie über Algorithmen und Systeme für das Audioverständnis durch Maschinen. Maschinenwahrnehmung Fähigkeit eines Computersystems, Daten in einer Weise zu interpretieren, die der Art und Weise ähnelt, wie der Mensch seine Sinne nutzt, um sich auf die Welt um sie zu beziehen. Systemdesign Feld der Wirtschafts- und Spieltheorie, die einen ingenieurtechnischen Ansatz zur Gestaltung wirtschaftlicher Mechanismen oder Anreize, zu gewünschten Zielen in strategischen Situationen, in denen die Spieler rational handeln. Da es am Ende des Spiels beginnt, dann geht zurück, wird es auch umgekehrt. Es hat breite Anwendungsbereiche von Wirtschaft und Politik (Markt, Auktionen, Abstimmungsverfahren) bis zu vernetzten Systemen (Internet-Interbereichslinien, geförderte Suchversteigerungen). mechatronics Mechatronic Engineering. Ein multidisziplinärer Maschinenbausektor, der sich sowohl auf die Elektrotechnik als auch auf mechanische Systeme konzentriert, umfasst auch eine Kombination aus Robotik, Elektronik, Computer, Telekommunikation, Systemen, Kontrolle und Produkttechnik. Stoffwechselnetzaufbau und Simulation ermöglichen einen eingehenden Einblick in die molekularen Mechanismen eines bestimmten Organismus. Insbesondere korreliert diese Modelle mit Molekularphysiologie. Metahetourismus In der Computerwissenschaft und mathematischen Optimierung ist ein Metahetourismus ein höheres Verfahren oder erzielt, einen Hetourismus (partialer Suchgorithmus) zu finden, zu generieren oder auszuwählen, die eine hinreichend gute Lösung für ein Optimierungsproblem bieten können, insbesondere mit unvollständigen oder unvollkommenen Informationen oder begrenzten Rechenkapazitäten. Metahe Tourists Probenahme einer Reihe von Lösungen, die zu groß sind, um vollständig zu proben. Modellprüfung In der Computerwissenschaft ist ein Modell, das die Kontrolle oder die Kontrolle von Eigentum prüft, für ein bestimmtes System, erschöpfend und automatisch zu prüfen, ob dieses Modell einer bestimmten Spezifikation entspricht. In der Regel gibt es Hardware- oder Softwaresysteme, während die Spezifikation Sicherheitsanforderungen enthält, wie das Fehlen von Hemmnissen und ähnlichen kritischen Staaten, die das System zum Absturz bringen können. Modellprüfung ist eine Technik, die die Richtigkeit der finnischen Systeme automatisch überprüft. Modus ponens In der Präpositionslogik ist modus ponens eine Ausnahmeregel. Es kann als "P bedeutet, dass Q und P wahrheitsgemäß sind, so dass Q richtig sein muss". Modi In der Vorführungslogik ist Modus® ein gültiges Argument und eine Ausgewogenheitsregel. Es ist eine Anwendung der allgemeinen Wahrheit, dass, wenn eine Erklärung wahr ist, dann ist dies kontraproduktiv. In der Regel behauptet der Modus Modus Mods, dass die Gleichgültigkeit von P bedeutet, dass Q bis die Vorwürfe von Q bedeutet, dass die Vorwürfe von P gültig sind. Montenegro Suche nach Carlo Baum Monte Carlo Baumsuche (MCTS) ist eine he touristische Suche nach einigen Arten von Entscheidungsprozessen. Multi-agen-System (MAS) Selbstorganisation. Ein computergestütztes System, das aus mehreren Wechselwirkungen zwischen intelligenten Agenten besteht. Multi-agen-Systeme können Probleme lösen, die für einen einzelnen Agenten oder ein monolithisches System schwierig oder unmöglich sind. Nachrichten können methodische, funktionelle, verfahrenstechnische Ansätze, algorische Suche oder verstärktes Lernen umfassen. Multisiente Optimierung Eine Variante der Partikeloptimierung (PSO) auf der Grundlage der Verwendung von Multiplen Unterschläuchen anstelle eines (Standard-)Schillings. Die allgemeine Ausrichtung in der Multi-Sättigungsoptimierung ist, dass jede Unterernährung sich auf eine bestimmte Region konzentriert, während eine spezifische Diversifizierungsmethode beschließt, wo und wann die Unterernährung eingeleitet werden soll. Insbesondere ist der Multi-Schilling-Rahmen für die Optimierung von multimodalen Problemen, bei denen mehrere (lokale) Optima existieren, vorgesehen. Mutation Ein genetischer Anbieter, der zur Erhaltung der genetischen Vielfalt von einer Generation von genetischen Algorithmen verwendet wird. Es entspricht der biologischen Mutation. Gegenseitigkeit verändert eine oder mehrere Genwerte in einem Chromosom von seinem ursprünglichen Staat. In Mutation kann sich die Lösung vollständig von der vorherigen Lösung ändern. GA kann daher mit Mutation zu einer besseren Lösung kommen. Mutation tritt während der Entwicklung nach einer benutzerfreundlichen Mutationswahrscheinlichkeit ein. Diese Wahrscheinlichkeit sollte gering sein. Wenn es zu hoch ist, wird die Suche zu einer einfachen Zufallssuche. Mycin Ein frühes Rücklaufsystem, das künstliche Intelligenz verwendet hat, um Bakterien zu identifizieren, die schwere Infektionen verursachen, wie bacteremia und Meningitis, und Antibiotika zu empfehlen, mit der für das Körpergewicht des Patienten angepassten Dosis – dem aus den Antibiotika selbst abgeleiteten Namen, da viele Antibiotika die suffix -mycin haben. Das MYCIN-System wurde auch für die Diagnose von Blutgeruchen verwendet. N naive Bayes-Klasse Naive Bayes-Klassenifiers sind eine Familie einfacher Probstabilistischer Klassentoren, die auf der Anwendung des Bayes' theorem mit starken (naiven) Unabhängigkeitsvorgaben zwischen den Merkmalen basieren. naive semantische Ein Ansatz, der in der Computerwissenschaft für die Darstellung grundlegender Kenntnisse über eine bestimmte Domäne verwendet wird, wurde in Anwendungen wie der Darstellung der Bedeutung der natürlichen Sprache in künstlichen Intelligenzanwendungen verwendet. In einer allgemeinen Bestimmung wurde der Begriff verwendet, um auf die Nutzung eines begrenzten Speichers von allgemein anerkannten Kenntnissen über einen bestimmten Bereich in der Welt zu verweisen, und auf Bereiche wie das auf Wissen basierende Datenkonzept angewandt. Name verbindlich Programmiersprachen: Name bindend ist die Vereinigung von Unternehmen (Daten und/oder Code) mit Kennzeichen. Ein an ein Objekt gebundener Identifikator wird darauf hingewiesen. Maschinensprachen haben keine eingebauten Kennzeichen, aber Namen-Zielbindungen als Dienst und Notierung für den Programmanbieter werden von Programmiersprachen umgesetzt. Verbindlich ist eng mit Skoping verbunden, da der Geltungsbereich bestimmt, welche Bezeichnungen bindend sind, an denen Gegenstände, an denen Orte im Programmcode (lexly) und in denen eine der möglichen Hinrichtungen (vorübergehend) liegen. Verwendung eines Identifikators in einem Zusammenhang, der eine verbindliche Kennzeichnung für das Did festschreibt, wird als verbindliches (oder Definition) Auftreten bezeichnet. In allen anderen Ereignissen (z.B. in Ausdrucken, Zuteilungen und Unterprogrammen) steht ein Kennzeichen für das, was er gebunden ist; solche Ereignisse werden bezeichnet. Kennzeichnung von Unternehmen (NER)Erkennung, Einheitsbunking und Unternehmensförderung. Eine Unteraufgabe für die Informationsgewinnung, die die Bezeichnung „Unternehmen“ in unstrukturierter Text in vordefinierte Kategorien wie Personennamen, Organisationen, Orte, medizinische Codes, zeitliche Ausdrucksformen, Mengen, Geldwerte, Prozentsatze usw. nennen soll, ein Schlüsselkonzept der semantischen Web-Architektur, in dem eine Reihe von Ressourcenbeschreibungen (ein Graph) verwendet werden, um Beschreibungen zu ermöglichen, aus denen solche Aussagen wie Kontext, Nachweisinformationen oder andere solche Metadaten gemacht werden. Named Graphen sind eine einfache Erweiterung des RDF-Datenmodells, durch das Graphe erstellt werden können, aber das Modell fehlt ein wirksames Mittel, um zwischen ihnen zu unterscheiden, sobald es auf dem Web veröffentlicht wurde. Entwicklung der natürlichen Sprache (NLG)A Software-Prozess, der strukturierte Daten in einfache englische Inhalte verwandelt. Es kann verwendet werden, um langforme Inhalte für Organisationen zu produzieren, um maßgeschneiderte Berichte zu automatisieren und für eine Web- oder mobile Anwendung maßgeschneiderte Inhalte zu produzieren. Es kann auch genutzt werden, um Kurzverwischungen von Texten in interaktiven Gesprächen (ein Chatbot) zu erzeugen, die sogar durch ein Text-to-speech-System verwundert werden können. natürliche Sprachverarbeitung (NLP)A Unterfeld von Computerwissenschaften, Informationstechnik und künstlicher Intelligenz, die mit den Wechselwirkungen zwischen Computern und menschlichen (natürlichen) Sprachen betraut sind, insbesondere wie Computer zu verarbeiten und große Mengen natürlicher Sprachedaten zu analysieren sind. Programmierung der natürlichen Sprache Eine auffällige Programmierung in Bezug auf natürliche Sprachstrafen, z.B. Englisch. Netzwerk Alle Netze, einschließlich biologischer Netze, sozialer Netzwerke, technologische Netze (z.B. Computernetze und elektrische Schaltkreise) und mehr, können als Graphen, die eine breite Palette von Unterdaten umfassen, vertreten werden. Ein wichtiges lokales Eigentum der Netze sind so genannte Netzwerkmotiven, die als wiederkehrende und statistisch signifikante Untertage oder Muster definiert werden. Neuralmaschine Übersetzung (NMT)An Ansatz zur maschinellen Übersetzung, die ein großes künstliches Neuralnetz nutzt, um die Wahrscheinlichkeit einer Sequenzierung der Wörter vorherzusagen, in der Regel alle Sätze in einem einzigen integrierten Modell. Neural Turing Maschinen (NTM) Neurales Netzmodell. NTMs kombinieren das fuzzy-Muster, das die Fähigkeiten von Neuralnetzen mit der Algorithmuskraft von programmierbaren Computern verbindet. Ein NTM verfügt über ein neurales Netz, das in Verbindung mit externen Speicherressourcen steht, die es mit Hilfe spezifischer Mechanismen in Verbindung bringt. Die Speicherinteraktionen sind unterschiedliche End-to-end, so dass es möglich ist, sie mit einem Gefälle zu optimieren. Ein NTM mit einem langen kurzfristigen Speicher (LSTM) kann einfache Algorithmen wie Kopieren, Sortierung und alssoziative Rückrufe von Beispielen allein in Anspruch nehmen. neuro-fuzzy Kombinationen künstlicher Neuralnetze und fuzzy Logik. Neuroklonen Gehirn-Computer-Schnittstelle (BCI), Neural-Kontroll-Schnittstelle (NCI), Benutzeroberfläche (MMI), direkte Neuralschnittstelle (DNI) oder Gehirn-Maschine-Schnittstelle (BMI). Ein direkter Kommunikationsweg zwischen einem verstärkten oder verdrahteten Gehirn und einem externen Gerät. BCI unterscheidet sich von der Neuromodulation, da sie den bidirektionalen Informationsfluss ermöglicht. BCIs sind häufig auf Forschung, Kartierung, Unterstützung, Ausweitung oder Reparatur menschlicher kognitiver oder sensorischer Funktionen ausgerichtet. Neuromorphe Technik auch Neuromorphologie. Konzept zur Beschreibung der Nutzung der Systeme der sehr großen Integration (VLSI) mit elektronischen analogen Schaltkreisen, um neurologische Architekturen, die im Nervensystem vorhanden sind, zu wandern. In jüngster Zeit wurde der Begriff Neuromorphic verwendet, um analoge, digitale, gemischte Analog-/digitale VLSI und Softwaresysteme zu beschreiben, die Modelle von Neuralsystemen (für Wahrnehmung, Motorkontrolle oder mehrsensorische Integration) umsetzen.Durch oxid-basierte Memrister, Spintronics-Speicher, Schaltschwelle und Transistors kann die Einführung des Neuromorphischen Rechensystems auf der Hardwareebene erreicht werden. Keine Basiseinheit einer Datenstruktur, wie z.B. eine vernetzte Liste oder Baumdatenstruktur. Nodes enthält Daten und kann auch an andere Knoten verweisen. Links zwischen den Knoten werden häufig von den Stellen umgesetzt. nichtdeterminierter Algorithmus Ein Algorithmus, der selbst für denselben Input unterschiedliche Verhaltensweisen auf verschiedenen Ebenen gegenüber einem deterministischen Algorithmus zeigen kann. nouvelle AI Nouvelle AI unterscheidet sich von der klassischen AI, indem sie Roboter mit Intelligenz, ähnlich Insekten, produziert. Forscher sind der Ansicht, dass Erkenntnisse ökologisch aus einfachen Verhaltensmustern entstehen können, da diese Erkenntnisse mit der „realen Welt“ interagieren, anstatt die gebauten Welten zu nutzen, die symbolischen AIs in der Regel benötigt werden, um sie zu planen. NPIn rechnerische Komplexitätstheorie, NP (Nichtdeterministische Polynomialzeit) ist eine komplexe Klasse, die zur Einstufung von Entscheidungsproblemen verwendet wird. NP ist die Reihe von Entscheidungsproblemen, für die die Probleme auftreten, bei denen die Antwort ja ist, Beweismittel in Polynomialzeit haben. NP-Deflator In der rechnerischen Komplexitätstheorie ist ein Problem  NP-Viert, wenn es durch eine eingeschränkte Klasse von Spenderfiltern gelöst werden kann und es genutzt werden kann, um ein anderes Problem mit einem ähnlichen Algorithmus zu lösen. Genauer gesagt, jeder Beitrag zum Problem sollte mit einer Reihe von Lösungen von Polynomiallänge verbunden sein, deren Gültigkeit schnell getestet werden kann (in polynomialer Zeit), so dass die Produktion für jeden Input ja ist, wenn die Lösung nicht möglich ist und nicht, wenn sie leer ist. NP-Küste auch nicht-deterministische Polynomial-time-Flagge. In der rechnerischen Komplexitätstheorie ist die Definition des Eigentums einer Klasse von Problemen, die informell "mindestens so schwer wie die schwersten Probleme in NP sind". Ein einfaches Beispiel für ein  NP-hartes Problem ist das Problem der Teilphase. OOccam's razor auch Ockhams razor oder Ochams razor. Das Problemlösungsprinzip, das besagt, dass, wenn es mit konkurrierenden Hypothesen vorgelegt wird, die dieselben Vorhersagen machen, eine Lösung mit den wenigen Annahmen auswählen sollte; das Prinzip ist nicht dazu gedacht, Hypothesen zu filtern, die unterschiedliche Vorhersagen machen. Die Idee wird dem englischen Patriar William von Ockham (c. 1287-1347), einem scholischen Philosophen und Theologen zugeschrieben. Lernen online Eine Methode des maschinenlesbaren Lernens, bei der Daten in einer sequenziellen Reihenfolge zur Verfügung stehen, wird verwendet, um den besten Vorhersehbaren für künftige Daten in jedem Schritt zu aktualisieren, gegenüber den Methoden des Chargenlernens, die das beste vorhersagende Lernen durch das Erlernen sämtlicher Ausbildungsdaten auf einmal ermöglichen. Online-Learning ist eine gemeinsame Technik, die in Bereichen des maschinenlesbaren Lernens eingesetzt wird, in denen es rechnerisch unwiderruflich ist, über den gesamten Datensatz zu strecken, was die Notwendigkeit von nicht-coreen Algorithmen erfordert. In Situationen, in denen es für den Algorithmus notwendig ist, sich dynamisch an neue Muster in den Daten anzupassen, oder wenn die Daten selbst zu einem Zeitpunkt generiert werden. Lehrveranstaltungen Ontology Gewinnung, Ontologie-Generation oder Ontology- Erwerb. automatische oder halbautomatische Einführung von Ontologien, einschließlich der Ausschöpfung der jeweiligen Domain-Bedingungen und der Beziehungen zwischen den Konzepten, die diese Begriffe aus einem Korpus natürlicher Sprache darstellen, und deren Kodierung mit einer ontology-Sprache für einfache Rückgewinnung. OpenAIThe for-Profit OpenAI LP, deren Mutterorganisation die Non-Profit OpenAI Inc ist, die Forschung im Bereich der künstlichen Intelligenz (AI) mit dem erklärten Ziel fördert und entwickelt, um eine freundschaftliche biologische Vielfalt in einer Weise zu fördern, die der Menschheit insgesamt zugute kommt. OpenCog Ein Projekt, das auf den Aufbau eines offenen künstlichen Intelligenzrahmens abzielt. OpenCog Premierminister ist eine Architektur für Roboter- und virtuelles Miteinander, die eine Reihe von Interaktionskomponenten definiert, die eine humane, künstliche allgemeine Intelligenz (AGI) als ein Phänomen des gesamten Systems darstellen. Open Mind Common Sense Ein künstliches Intelligenz-Projekt auf der Grundlage des Massachusetts Institute of Technology (MIT)Media Lab, dessen Ziel es ist, eine breite gemeinsame Wissensgrundlage aus den Beiträgen vieler Tausender Menschen im Web. Open-Source-Software (OSS)A-Typ von Computersoftware zu bauen und zu nutzen, in der der die Quellecode unter einer Lizenz veröffentlicht wird, in der der der Urheberrechtsinhaber die Rechte auf Studium, Veränderung und Verbreitung der Software für jeden und Zweck gewährt. Open-Source-Software kann in öffentlicher Zusammenarbeit entwickelt werden. Open-Source-Software ist ein wichtiges Beispiel für eine offene Zusammenarbeit. P Teilauftragsverringerung A Technik zur Verringerung der Größe des Staatsraums, die von einem Modell, der die Planung oder den automatischen Planungs- und Planungsgorithmus untersucht. Er nutzt die Kontaminierung von gleichzeitig ausgeführten Übergangsprozessen, die in verschiedenen Aufträgen zum gleichen Staat führen. teilweise observable Markov-Entscheidungsprozess (POMDP)A Generalisierung eines Markov-Entscheidungsverfahrens (MDP). A POMDP-Modelle, bei denen davon ausgegangen wird, dass die Systemdynamik von einem MDP bestimmt wird, aber der Wirkstoff kann den zugrunde liegenden Zustand nicht unmittelbar beobachten. Stattdessen muss sie auf der Grundlage einer Reihe von Beobachtungen und Beobachtungsmöglichkeiten und der zugrunde liegenden MDP eine wahrscheinliche Verteilung über die möglichen Staaten beibehalten. Partikeloptimierung (PSO)A Berechnungsmethode, die ein Problem optimiert, indem er versucht, eine Kandidatenlösung im Hinblick auf eine bestimmte Qualität zu verbessern. Es löst ein Problem, indem man eine Population von Kandidatenlösungen, hier gestrichene Partikel, und bewegt diese Partikel im Suchraum nach einfachen mathematischen Formeln über die Position und Geschwindigkeit des Partikels. Die Bewegung jedes Partikels wird durch seine am besten bekannte Position beeinflusst, orientiert sich aber auch an den am besten bekannten Positionen im Suchraum, die als bessere Positionen von anderen Partikeln aktualisiert werden. Es wird erwartet, dass man die besten Lösungen bremst. Erkundung auch auf dem Weg. Mit einer Computeranwendung der kürzesten Strecke zwischen zwei Punkten. Es ist eine praktische Variante zur Lösung von Säugetieren. Dieser Forschungsbereich basiert stark auf dem Dijkstra-Algorithmus, um einen möglichst kurzen Weg auf einem gewichteten Diagramm zu finden. Mustererkennung Bedenken hinsichtlich der automatischen Erfassung von Ordnungsmäßigkeiten in Daten durch die Verwendung von Computeralgorithmen und mit der Verwendung dieser Ordnungsmäßigkeiten, um Maßnahmen wie die Einstufung der Daten in verschiedene Kategorien zu ergreifen. Prädikative Logik Ebenfalls erste Logik, vordringliche Logik und erste vorbeugende Kalkulation. Sammlung formaler Systeme in Mathematik, Philosophie, Sprachen und Computerwissenschaften. First-order Logik verwendet quantifizierte Variablen über nicht-logische Gegenstände und ermöglicht die Verwendung von Sätzen, die Variablen enthalten, so dass anstelle von Verhängungen wie Sokrates ein Mensch Ausdruck in der Form "Es gibt x so, dass es Sokrates und x gibt einen Mann" und es gibt einen Quantifizierenden, während x variabler ist. Es unterscheidet sich von der propositionalen Logik, die keine Quantifizierungs- oder Beziehungen verwendet; in diesem Sinne ist die Propositionallogik die Grundlage der ersten Logik. Vorhersage Vielfalt statistischer Techniken aus dem Data Mining, prädikative Modellierung und maschinellem Lernen, die aktuelle und historische Fakten analysieren, um Vorhersagen über künftige oder sonst unbekannte Ereignisse zu machen. Hauptkomponentenanalyse (PCA)Ein statistisches Verfahren, das eine orthogonale Transformation nutzt, um eine Reihe von Beobachtungen möglich korrelierter Variablen (die jeweils auf verschiedenen numerischen Werten beruhen) in eine Reihe von Werten linearer, nicht korrelativer Variablen namens Hauptkomponenten zu verwandeln. Diese Umwandlung ist so definiert, dass die erste Hauptkomponente die größte mögliche Varianz aufweist (d. h., so viele der Variabilität in den Daten so weit wie möglich), und jede erfolgreiche Komponente wiederum hat die höchste Varianz, die unter dem Druck möglich ist, dass es sich bei den vorherigen Komponenten handelt. Die daraus resultierenden Vektoren (je nach lineare Kombination der Variablen und der n Beobachtungen) sind eine unkorrekte orthogonale Basis. PCA ist empfindlich auf die relative Verkleinerung der ursprünglichen Variablen. Grundsatz der Rationalität Rationalitätsprinzip. Karl R. Popper in seinem Harvard-Professor von 1963 und veröffentlicht in seinem Buch Myth of Framework. In einem Wirtschaftsa-Artikel von 1944/1945, der später in seinem Buch "The Poverty of Historicism" veröffentlicht wurde, geht es darum, was er als "Bedeutung der Situation" bezeichnete. Laut dem Grundsatz der Rationalität handeln die Agenten nach der objektiven Situation am besten in angemessener Weise. Es ist eine idealisierte Konzeption des menschlichen Verhaltens, die er verwendet hat, um sein Modell der Situationsanalyse voranzutreiben. probabilistische Programmierung (PP)A-Programm Paradigma, in dem probabilistische Modelle spezifiziert werden, und Gleichgültigkeit für diese Modelle wird automatisch durchgeführt. Es stellt einen Versuch dar, probabilistische Modellierungen und traditionelle allgemeine Nutzungsprogramme zu vereinheitlichen, um die frühere einfachere und breitere Anwendung zu ermöglichen. Es kann genutzt werden, um Systeme zu schaffen, die helfen, Entscheidungen vor Unsicherheit zu treffen. Programmierungssprachen, die für die probabilistische Programmierung verwendet werden, werden als "Probabilistische Programmiersprachen" (PPLs) bezeichnet. Produktionssystem Programmierung Sprache Eine formale Sprache, die eine Reihe von Anweisungen enthält, die verschiedene Arten von Output produzieren. Programmiersprachen werden zur Umsetzung von Algorithmen verwendet. Prolog Logik Programmierungssprache im Zusammenhang mit künstlichen Intelligenz und Informatik. Prolog hat seine Wurzeln in der ersten Logik, einer formalen Logik und im Gegensatz zu vielen anderen Programmiersprachen ist Prolog in erster Linie als deklarative Programmiersprache gedacht: Die Programmlogik wird in Bezug auf die Beziehungen ausgedrückt, die als Fakten und Regeln vertreten sind. Eine Berechnung wird durch eine Abfrage über diese Beziehungen eingeleitet. Propositionäres Kalkül Ebenfalls propositionale Logik, Erklärungslogik, geschicktes kalkulierbares kalkulierbares, übertragbare Logik und die Nullkontraktion. eine Logik, die sich mit Vorwürfen (die wahrheitsgemäß oder falsch sein können) und Argumentfluss befasst. Verbindungspropositionen werden durch die Verknüpfung von Propositions durch logische Bindemittel gebildet. Die Vorwürfe ohne logische Verbindung werden als Atomproposition bezeichnet. Im Gegensatz zur ersten Logik behandelt die Propositionallogik nicht die nicht-logischen Gegenstände, die sie vorschreiben, oder die Quantifizierenden. Jedoch sind alle Mechanismen der Propositionallogik in der ersten Logik und in der höheren Logik enthalten. In diesem Sinne ist die Propositionslogik die Grundlage der ersten Logik und der höheren Logik. Bild Eine von Guido van Rossum erstellte und 1991 erstmals veröffentlichte, hochaufwendige Programmierungssprache. Skypes Design Philosophie unterstreicht die Rückverfolgbarkeit mit seiner bemerkenswerten Nutzung des bedeutenden weißen Raums. Ihre Sprache baut und objektorientierten Ansatz auf, um den Programmern zu helfen, klare, logische Code für kleine und große Projekte zu schreiben. Qualifikationsproblem Philosophie und künstliche Intelligenz (insbesondere wissensbasierte Systeme) sind besorgt über die Unmöglichkeit der Aufnahme aller Voraussetzungen, die für eine echte Aktion erforderlich sind. Man könnte sich mit der Frage auseinandersetzen, wie man mit den Dingen umgehen kann, die mich daran hindern, mein Ziel zu erreichen. Es ist eng mit dem Rahmenproblem verbunden und umgekehrt. Quantifizierung Logik: Die Quantifizierung legt die Menge der Exemplare im Bereich des Diskurses fest, die eine offene Formel erfüllen. Die beiden häufigsten Quantifizierungen bedeuten "für alle" und " es gibt". In arithmetic lassen sich Quantifitoren sagen, dass die natürlichen Zahlen für alle n (wo n eine natürliche Nummer ist), es gibt eine andere Nummer (Test, Nachfolger von n), die größer ist als n. Quantencomputer Verwendung von Quantenmechanischen Phänomenen wie Superposition und Entflechtung zur Ausführung der Berechnung. Ein Quantencomputer wird verwendet, um solche Berechnungen durchzuführen, die theoretische oder physisch umgesetzt werden können. Sprache Sprachen oder Datenanfragen (DQL) sind Computersprachen, die zur Abfrage von Anfragen in Datenbanken und Informationssystemen verwendet werden. Generell können Abfrage-Sprachen nach der Frage klassifiziert werden, ob sie in der Datenbank Abfrage-Sprachen oder Informationsanfragen sind. Unterschiedlich ist, dass eine Datenbank-Anfragesprache versucht, sachliche Antworten auf tatsächliche Fragen zu geben, während eine Informationsanfragensprache versucht, Dokumente zu finden, die für einen Bereich der Untersuchung relevant sind. R Programmierungssprache Programmsprache und freie Softwareumgebung für statistisches Rechen und Grafik, unterstützt durch die R Foundation for Statistical Computing. Die R-Sprache wird bei Statistikern und Datenminern zur Entwicklung statistischer Software und Datenanalyse weit verbreitet. Radialfunktionsnetz Im Bereich der mathematischen Modellierung ist ein Radikalfunktionsnetz ein künstliches Neuralnetz, das Radialfunktionen als Aktivierungsfunktionen nutzt. Die Leistung des Netzes ist eine lineare Kombination von Radialfunktionen der Inputs und neuronen Parametern. Radial-Basisfunktionsnetze haben viele Verwendungen, darunter Funktionsangleichung, Zeitvorhersage, Klassifizierung und Systemkontrolle. Erst 1988 wurden sie in einem Papier von Broomhead und Lowe formuliert, beide Forscher an den Royal Signalen und Radaranlagen. Zufallswald auch zufälliger Wald. Eine Kombination aus Lernmethoden zur Einstufung, Regression und anderen Aufgaben, die durch den Bau einer Vielzahl von Entscheidungsbäumen in der Ausbildung und die Erzeugung der Klasse, die die Art der Klassen (Klassenbildung) oder die Vorhersage (Regression) der einzelnen Bäume ist. Zufallsbeschluss Wälder korrigieren für die Einstellung der Überrüstung von Bäumen an ihre Ausbildungseinrichtung. Grundsystem In der Informationstechnologie ist ein mit Gründen versehenes System ein Software-System, das Schlussfolgerungen aus verfügbaren Kenntnissen unter Verwendung logischer Techniken wie Abzug und Einführung liefert. Mit Gründen versehene Systeme spielen bei der Umsetzung künstlicher Intelligenz und wissensbasierter Systeme eine wichtige Rolle. wiederkehrendes Neuralnetz (RNN)A Klasse künstlicher Neuralnetze, in denen die Verbindungen zwischen Knoten ein zielgerichtetes Diagramm bilden. Dies ermöglicht es, ein dynamisches Verhalten zu zeigen. Anders als Feedforward-Neural-Netze können RNNs ihren internen Staat (memory) nutzen, um Sequenzen von Inputs zu verarbeiten. Dies macht sie auf Aufgaben wie unsegmentierte, vernetzte Anerkennung oder Spracherkennung anwendbar. Region verbindet kalorienverstärktes Lernen (RL) Ein Bereich des maschinellen Lernens mit der Frage, wie Software-Beauftragte Maßnahmen in einem Umfeld treffen sollten, um einen Teil der kumulativen Belohnung zu maximieren. Verstärktes Lernen ist eines von drei Grundmodellen für maschinelles Lernen, neben dem beaufsichtigten Lernen und dem unkontrollierten Lernen. Es unterscheidet sich von der Überwachung des Lernens in diesem gekennzeichneten Input/Output-Fahrer müssen nicht vorgelegt werden, und suboptimale Maßnahmen müssen nicht ausdrücklich korrigiert werden. stattdessen wird der Schwerpunkt auf der Suche nach einem Gleichgewicht zwischen der Exploration (von unchartertem Gebiet) und der Nutzung (der aktuellen Kenntnisse) liegen. Speicher Rahmen für die Berechnung, die als Erweiterung der Neuralnetze angesehen werden können. In der Regel wird ein Inputsignal in ein festes (random) dynamisches System, das als Reservoir und die Dynamik des Reservoirs bezeichnet wird, in das ein Beitrag zu einer höheren Dimension aufgenommen wird. Dann wird ein einfacher Rückführungsmechanismus ausgebildet, um den Zustand des Reservoirs zu lesen und ihn auf die gewünschte Leistung zu legen. Hauptnutzen ist, dass die Ausbildung nur in der Lesephase durchgeführt wird und das Reservoir feststeht. Liquid-State-Maschinen und Echo-Staatsnetzen sind zwei große Arten von Speicher-.. Ressourcenbeschreibung Rahmen (RDF) Eine Familie von World Wide Web Consortium (W3C) Spezifikationen, die ursprünglich als Metadatendatenmodell konzipiert wurden. Es ist als allgemeine Methode für die konzeptuelle Beschreibung oder Modellierung von Informationen zu verwenden, die in Web-Ressourcen umgesetzt werden, wobei eine Vielzahl von Sprachnotierungen und Datenübertragungsformate verwendet werden. Sie wird auch in Anwendungen des Wissensmanagements eingesetzt. eingeschränkte Poszmann Maschinen (RBM)A generatives krchastic künstliches Neuralnetz, das eine Wahrscheinlichkeitsverteilung über seine Einsatzmöglichkeiten erfahren kann. Retegorithmus Ein Muster, der den Algorithmus für die Einführung von Systemen auf der Basis von Regeln entspricht. Der Algorithmus wurde entwickelt, um viele Regeln oder Muster für viele Gegenstände oder Fakten in einer Wissensbasis effizient anzuwenden. Es wird verwendet, um zu bestimmen, welche der Vorschriften des Systems auf der Grundlage seiner Daten speichern sollte. Robotik ein interdisziplinärer Bereich von Wissenschaft und Technik, der Maschinenbau, Elektrotechnik, Informationstechnik, Informatik und anderen umfasst. Robotik befasst sich mit der Konzeption, dem Bau, dem Betrieb und der Verwendung von Robotern sowie Computersystemen für ihre Kontrolle, sensorische Rückmeldung und der Informationsverarbeitung. Regelbasiertes System In der Computerwissenschaft wird ein regelbasiertes System genutzt, um Kenntnisse zu speichern und zu manipulieren, um Informationen sinnvoll zu interpretieren. Es wird oft in künstlichen Intelligenzanwendungen und Forschung eingesetzt. In der Regel wird das Begriffsbestimmungssystem auf Systeme angewandt, die menschliches Handwerk oder kumulierte Regelsets umfassen. Regelbasierte Systeme, die mit automatischen Regeln gebaut werden, wie z.B. regelbasiertes Maschinenlernen, sind normalerweise von dieser Systemart ausgeschlossen. Kraft In mathematischer Logik sind die Lebensfähigkeit und Gültigkeit grundlegende Begriffe von semantischen. Eine Formel ist zufriedenstellend, wenn es möglich ist, eine Auslegung (Modell) zu finden, die die Formel wahrnimmt. Eine Formel ist gültig, wenn alle Interpretationen die Formel wahren. Unzulänglichkeit und Ungültigkeit, d. h. eine Formel ist unzufrieden, wenn keine der Interpretationen die Formel tatsächlich darstellen und ungültig sind, wenn eine solche Auslegung die Formel falsch macht. Diese vier Begriffe sind miteinander in einer Weise verbunden, die genau dem Widerspruchsmerk von Aristotle entspricht. Suche nach Algorithmus Jeder Algorithmus, der das Suchproblem gelöst, nämlich die Speicherung von Informationen, die in einer Datenstruktur gespeichert sind, oder die im Suchraum eines Problembereichs berechnet werden, entweder mit diskreten oder kontinuierlichen Werten. Auswahl Phase eines genetischen Algorithmus, in dem einzelne Genome von einer Population für spätere Zucht (Nutzung des Crossover-Betreibers) ausgewählt werden. Selbstverwaltung Der Prozess, durch den Computersysteme ihre eigene Tätigkeit ohne menschliches Handeln verwalten. semantisches Netzwerk Netzwerk. Wissensgrundlage, die semantische Beziehungen zwischen Konzepten in einem Netzwerk repräsentiert. Dies wird oft als eine Form der Wissensvertretung verwendet. Es handelt sich um ein zielgerichtetes oder undirektiertes Diagramm, das aus Wirbelstoffen besteht, die Konzepte und Kanten repräsentieren, die semantische Beziehungen zwischen Konzepten, der Kartierung oder der Verbindung von semantischen Feldern darstellen. semantische Gründe Motoren, Regeln oder nur Grunder. Ein Teil der Software kann logische Konsequenzen aus einer Reihe geltender Fakten oder Axioms ziehen. Der Begriff eines semantischen Grundsaspekts, der von einer Anteilnahmemaschine ausgeht, indem ein reicheres System zur Zusammenarbeit geschaffen wird. Häufig werden die Regeln für die Gleichgültigkeit durch eine Ontologiesprache und oft eine Beschreibungslogiksprache festgelegt. Viele Grundgeber verwenden erste vorschriftsmäßige Logik, um die Gründe zu erfüllen; in der Regel führt sie zu einer Spedition und Rückwärtskette. semantische Abfrage Anfragen und Analyse von assoziativen und Kontextcharakter. semantische Anfragen ermöglichen die Erfassung sowohl expliziter als auch implizit abgeleiteter Informationen auf der Grundlage von kooperativen, semantischen und strukturellen Daten. Sie zielen darauf ab, genaue Ergebnisse (möglicherweise die Unterscheidungsauswahl eines einzigen Informationsstücks) zu liefern oder mehr fuzzy- und breitoffene Fragen durch eine Kombination aus Mustern und digitalen Gründen zu beantworten.semantische In der Programmiersprache-Sprachtheorie ist semantisches der Bereich mit der strengen mathematischen Studie über die Bedeutung von Programmiersprachen. Er bewertet so die Bedeutung von praktikablen, von einer bestimmten Programmsprache definierten, von der jeweiligen Programmiersprache geprägten, maßgeblichen Elementen. In einem solchen Fall, dass die Bewertung aus praktikablen Invaliden bestehen würde, wäre das Ergebnis nichtig. Sepsis beschreibt die Prozesse, die ein Computer folgt, wenn ein Programm in dieser spezifischen Sprache durchgeführt wird. Dies lässt sich durch die Beschreibung der Beziehung zwischen dem Input und der Produktion eines Programms oder eine Erläuterung der Art und Weise, wie das Programm auf einer bestimmten Plattform ausgeführt wird, zeigen, wodurch ein Rechenmodell geschaffen wird. Sensor Fusion Kombination von Sensordaten oder Daten aus unterschiedlichen Quellen, so dass die daraus resultierenden Informationen weniger Unsicherheit haben als möglich, wenn diese Quellen einzeln verwendet werden. Trennung Ausweitung der Hoare Logik, eine Art Grund für Programme. Die Behauptungssprache der Trennungslogik ist ein Sonderfall der Logik der geschilderten Auswirkungen (BI). ähnliches Lernen Ein Bereich des überwachten maschinellen Lernens in der künstlichen Intelligenz. Es ist eng mit Regression und Klassifizierung verknüpft, aber das Ziel besteht darin, aus einer ähnlichen Funktion zu lernen, die Maßnahmen, wie ähnliche oder verwandte zwei Gegenstände sind. In Empfehlungssystemen, visuelle Identitätsverfolgung, Gesichtsverifikation und Sprecherprüfung hat sie Bewerbungen. simulierte Annobel (SA) Eine probabilistische Technik zur Angleichung der globalen Optimierung einer bestimmten Funktion. Konkret ist es ein Metahetourismus, um die globale Optimierung in einem großen Suchraum für ein Optimierungsproblem anzunähern. Konzept In der künstlichen Intelligenzforschung baut der Ansatz Wirkstoffe auf, die darauf ausgelegt sind, sich in ihrer Umwelt erfolgreich zu verhalten. Dies erfordert die Konzipierung von AI "von der Bottom-up" durch Konzentration auf die grundlegenden, skeptischen und motorischen Fähigkeiten, die zum Überleben erforderlich sind. In diesem Ansatz liegt viel niedrigere Priorität für abstrakte Grund- oder Problemlösungsfähigkeiten. Lage Logik formalismus, der für die Darstellung und Begründung von dynamischen Bereichen bestimmt ist. Auswahl der linearen Definite-Klausel Entschließung Lediglich SLD Entschließung. Die Grundregel der Gleichgültigkeit in der Logikplanung. Es ist eine Verfeinerung der Auflösung, die sowohl für eine solide als auch für die Rückführung von Hornklauseln vollständig ist. Software Eine Sammlung von Daten oder Computeranweisungen, die den Computer über die Arbeit informieren. Im Gegensatz zur physischen Hardware, von der das System gebaut wird und die Arbeit tatsächlich führt. Computer- und Softwaretechnik sind alle Informationen, die von Computersystemen, Programmen und Daten verarbeitet werden. Computersoftware umfasst Computerprogramme, Bibliotheken und verwandte nicht geschäftsführende Daten wie Online-Dokumente oder digitale Medien. Software Engineering Anwendung der Technik auf die Entwicklung von Software in einer systematischen Methode. Raumordnung Bereich der künstlichen Intelligenz, die sich aus den Bereichen Computerwissenschaft, kognitive Wissenschaft und kognitive Psychologie ergeben. theoretic Ziel – auf der kognitiven Seite – setzt sich die Vertretung und die Begründung von räumlichen Kenntnissen ein. Das angewandte Ziel – auf der Computerseite – setzt sich für die Entwicklung von Hochleistungskontrollsystemen von automata ein, um Zeit und Raum zu schiffen und zu verstehen. SPARQLAn RDF Abfragesprache – d. h. eine semantische Abfragesprache für Datenbanken – können Daten, die im Rahmen der Ressourcenbeschreibung (RDF) gespeichert sind, abgerufen werden. Spracherkennung Interdisziplinärer Teilbereich von rechnerischen Sprachen, die Methoden und Technologien entwickeln, die die Anerkennung und Übersetzung der gesprochenen Sprache durch Computer ermöglichen. Sie ist auch als automatische Sprachanerkennung (ASR), Anerkennung von Computern oder Rede zum Text (STT). Wissen und Forschung in den Bereichen Sprache, Informatik und Elektrotechnik. spirierendes Neuralnetz (SNN)Ein künstliches Neuralnetz, das ein natürliches Neuralnetz näher rückt. Neben dem neuronalen und synaptischen Staat enthalten SNNs das Konzept der Zeit in ihr Betriebsmodell. Staat In der Informationstechnologie und der Computerwissenschaft wird ein Programm als unerläßlich bezeichnet, wenn es darauf abzielt, frühere Ereignisse oder Interaktionen der Nutzer zu vergessen; die Erinnerungsinformationen sind der Zustand des Systems. statistische Einstufung In den Bereichen Maschinenbau und Statistik ist die Einstufung das Problem, zu ermitteln, welche einer Reihe von Kategorien (Teilpopulationen) eine neue Beobachtung gehört, auf der Grundlage eines Fortbildungspakets von Daten mit Beobachtungen (oder Instanzen), deren Kategorie bekannt ist. Beispiele sind die E-Mail an die Spam- oder Nicht-Spam-Klasse und die Diagnose an einen bestimmten Patienten aufgrund der beobachteten Merkmale des Patienten (geschlecht, Blutdruck, Vorhandensein oder Fehlen bestimmter Symptome usw.). Klassifikation ist ein Beispiel für Mustererkennung. statistisches Verhältnis (SRL)A Teildiszipline künstlicher Intelligenz und Maschinenlernen, die mit Domänenmodellen behaftet sind, die sowohl Unsicherheit (die mit statistischen Methoden behandelt werden können) als auch komplexe, miteinander verbundene Strukturen aufweisen. Hinweis darauf, dass die SRL manchmal als verwandter Maschinenbau (RML) in der Literatur bezeichnet wird. In der Regel werden die in der SRL-Nutzung (ein Teil) entwickelten Formalismen der Wissensvertretung zur allgemeinen Beschreibung der jeweiligen Eigenschaften einer Domäne (universale Quantifizierung) und zu probabilistischen grafischen Modellen (wie Bayesische Netze oder Markov-Netze) zur Modellierung der Unsicherheit entwickelt; einige bauen auch auf die Methoden der induktiven Planung auf. krktische Optimierung (SO)Any Optimierungsmethode, die zufällige Variablen erzeugt und verwendet. Für krchtische Probleme erscheinen die Zufallsvariablen in der Formulierung des Optimierungsproblems selbst, das zufällige objektive Funktionen oder zufällige Zwänge beinhaltet. Stochastic Optimierungsmethoden umfassen auch Methoden mit zufälligem Iterate. Manche kryktische Optimierungsmethoden verwenden Zufallsstiche, um senergetische Probleme zu lösen, die beide Begriffe der krchtischen Optimierung kombinieren. Stochastic Optimierungsmethoden allgemeinisieren deterministische Methoden für deterministische Probleme. krytische semantische Analyse Ein Ansatz, der in der Computerwissenschaft als semantische Komponente des natürlichen Sprachverständnisses verwendet wird. Stochastic Modelle verwenden in der Regel die Definition von Teilen von Wörtern als grundlegende semantische Einheiten für die semantischen Modelle und in einigen Fällen einen zweischichtigen Ansatz. Problem Solver (STRIPS) Gegenstand von Experten Superintelligence Ein hypothetisches Erreger, das die Intelligenz weit über dem der hellsten und am meisten begabten Menschen hinausgeht. Supernachrichten können auch auf ein Eigentum von Problemlösungssystemen (z.B. hochintelligente Sprach-Übersetzer oder technische Assistenten) verweisen, ob diese hochrangigen intellektuellen Kompetenzen in Agenten verankert sind, die innerhalb der physischen Welt handeln. Eine Super-Intelligence kann oder kann nicht durch eine Intelligenz Explosion entstehen und mit einer technologischen Einzigartigkeit verbunden sein. Überwachung des Lernens Aufgabe des Maschinenlernens ist es, eine Funktion zu erlernen, die einen Input auf der Grundlage von Input-Output- Paaren bereitstellt. Es unterscheidet eine Funktion von etikettierten Schulungsdaten, die aus einer Reihe von Ausbildungsbeispielen bestehen. Jedes Beispiel ist ein Paar, das aus einem Eingangsobjekt (normalerweise ein Vektor) und einem gewünschten Output-Wert (auch als Überwachungssignal bezeichnet) besteht. Ein überwachter Lerngorithmus untersucht die Schulungsdaten und produziert eine in Auftrag gegebene Funktion, die für die Kartierung neuer Beispiele verwendet werden kann. Ein optimales Szenario ermöglicht es dem Algorithmus, die Klassenetiketten für uneen Instanzen korrekt zu bestimmen. Dies erfordert, dass der Lerngorithmus von den Ausbildungsdaten auf eine vertretbare Weise verbreitet wird (siehe induktive Verzerrung). Fördermaschinen In Maschinen- und Lernprozessen werden unterstützende Maschinen (SVM, auch unterstützende Netzwerke) mit zugehörigen Lernalgorithmen überwacht, die Daten zur Einstufung und Regressionsanalyse analysieren. skeptische Intelligenz (SI) Das kollektive Verhalten dezentraler, selbst organisierter Systeme, entweder natürlicher oder künstlicher Art. Der Ausdruck wurde im Zusammenhang mit zellulären Robotersystemen eingeführt. symbolische künstliche Intelligenz Begriff für die Sammlung aller Methoden in der künstlichen Intelligenzforschung, die sich auf symbolische (menschlich lesbare) Darstellungen von Problemen, Logik und Suche stützen. synthetische Intelligenz (SI) Eine Alternative für künstliche Intelligenz, die betont, dass die Intelligenz von Maschinen weder eine Nachahmung noch auf irgendeiner Weise künstlich sein muss; sie kann eine echte Form der Intelligenz sein. Systeme der Neurowissenschaften Teildiszipline der Neurowissenschaften und Systembiologie, die die Struktur und Funktion der Neuralkreise und -systeme untersucht. Es handelt sich um einen Rahmenvertrag, der eine Reihe von Studienbereichen umfasst, mit denen Nervenzellen sich verhalten, wenn sie miteinander verbunden sind, um Neuralwege, Neuralkreisläufe und größere Gehirnnetze zu bilden. T-Technik bloß die Einzigartigkeit. Ein hypothetischer Punkt in der Zukunft, wenn das technologische Wachstum unkontrollierbar und unumkehrbar wird, was zu unzulänglichen Veränderungen der menschlichen Zivilisation führt. zeitlicher Unterschied Klasse der modellfreien Verbesserung der Lernmethoden, die von der aktuellen Schätzung der Wertfunktion lernen. Diese Methodenproben aus der Umwelt, wie z.B. Monte Carlo-Methoden, werden auf der Grundlage aktueller Schätzungen aktualisiert, wie dynamische Programmierungsmethoden. Systemtheorie Theorie der Gehirnfunktion (insbesondere des Cerebellum), die ein mathematisches Modell für die Umwandlung von sensorischen weltzeitkoordinierungen in Motorkoordinationen und umgekehrt durch zerebellar neuronale Netze bietet. Die Theorie wurde als Geometrisierung der Gehirnfunktion (vor allem des zentralen Nervensystems) entwickelt, bei der die zehnter eingesetzt werden. Tensor Fluss Eine kostenlose und offene Software-Bibliothek für den Datenfluss und die unterschiedliche Programmierung über eine Reihe von Aufgaben. Es ist eine symbolische Mathematikbibliothek und wird auch für Anwendungen des maschinenlesbaren Lernens wie Neuralnetze genutzt. theoretische Computerwissenschaft (TCS)A Untergruppe der allgemeinen Computerwissenschaft und Mathematik, die sich auf mathematische Themen des Informatikwesens konzentriert und die Rechentheorie umfasst. Theorie der Berechnung theoretische Informatik und Mathematik ist die Rechentheorie, die sich mit der Frage befasst, wie effiziente Probleme auf einem Rechenmodell gelöst werden können, wobei ein Algorithmus verwendet wird. Das Feld ist in drei große Zweige unterteilt: automata Theorie und Sprachen, Komputability Theorie und Rechentechnik, die mit der Frage verknüpft sind: "Was sind die grundlegenden Fähigkeiten und Grenzen von Computern?" Probenahme A he Tourist für die Auswahl von Maßnahmen, die das Problem der Exploration im multiarmierten Bandenproblem angehen. Es besteht darin, die Maßnahme zu wählen, die die erwartete Belohnung im Hinblick auf eine zufällige Überzeugung maximiert. Komplexität Die rechnerische Komplexität, die die Menge der Zeit beschreibt, die sie benötigt, um einen Algorithmus zu führen. Komplexität der Zeit wird allgemein geschätzt, indem die Anzahl der vom Algorithmus durchgeführten elementaren Operationen berücksichtigt wird, wobei die Tatsache, dass jede elementare Operation eine feste Menge Zeit zur Durchführung hat. So werden die Menge der Zeit und die Anzahl der vom Algorithmus durchgeführten elementaren Operationen zu unterschiedlichsten Faktoren geführt. Transhumanismus Abbreviated H+ oder h+.An internationaler philosophischer Bewegung, die sich für die Umgestaltung des menschlichen Zustands einsetzt, indem sie hochentwickelte Technologien entwickelt und verbreitet, um den Menschen intellect und Physiologie zu stärken. Übergangssystem In theoretischer Informatik ist ein Übergangssystem ein Konzept, das in der Berechnungsstudie verwendet wird. Es wird verwendet, um das mögliche Verhalten einzelner Systeme zu beschreiben. Es besteht aus Staaten und Übergangen zwischen Staaten, die mit Etiketten gekennzeichnet werden können, die aus einem Set ausgewählt werden; das gleiche Etikett kann auf mehr als einem Übergang erscheinen. Wenn das Etikett ein einziges Zeichen ist, ist das System im Wesentlichen nicht gekennzeichnet, und eine einfachere Definition, die die Etiketten enthält, ist möglich. Baum Baumsuche. Eine Form von Graph-Traversal und bezieht sich auf den Besuchsprozess (Kontrolle und/oder Aktualisierung) in einer Baumdatenstruktur genau einmal. Solche Traversals werden von der Reihenfolge klassifiziert, in der die Knoten besucht werden. tatsächliche quantifizierte Loyola-Formel In der rechnerischen Komplexitätstheorie ist die Sprache TQBF eine formale Sprache, die sich aus den wirklich quantifizierten Formulierungen von Boolean zusammensetzt. A (vollständig) quantifizierte Hilean-Formel ist eine Formel in quantifizierter Propositionallogik, bei der jede Variablen (oder gebunden) quantifiziert wird, die zu Beginn der Strafe entweder vorhanden oder universelle Quantifizatoren verwenden. Eine solche Formel entspricht entweder tatsächlich oder falsch (da es keine freien Variablen gibt). Kommt eine solche Formel zu wahren, so ist diese Formel in der Sprache TQBF. Es ist auch bekannt als QSAT (Quanifikationsat). Turing Test Ein Test einer Maschine, die in der Lage ist, intelligentes Verhalten zu zeigen, das dem von Alan Turing im Jahr 1950 entwickelten oder unzerstörbaren menschlichen Menschen entspricht. Laut dem Vorschlag, dass ein menschlicher Evaluator natürliche Sprachgespräche zwischen einem Menschen und einer Maschine beurteilen würde, die menschliche Reaktionen auslösen soll. Der Evaluator wäre sich bewusst, dass eine der beiden Partner im Gespräch eine Maschine ist, und alle Teilnehmer würden voneinander getrennt. Das Gespräch wäre nur auf einen Textkanal wie eine Computer-Diagnostik und Bildschirm beschränkt, so dass das Ergebnis nicht von der Fähigkeit der Maschine abhängt, Worte als Rede zu machen. Kann der Evaluator die Maschine vom Menschen nicht zuverlässig sagen, wird die Maschine aufgefordert, den Test zu durchlaufen. Die Testergebnisse hängen nicht von der Fähigkeit der Maschine ab, korrekte Antworten auf Fragen zu geben, sondern nur, wie eng ihre Antworten denen eines Menschen entsprechen. Typsystem In den Programmierungssprachen gibt es eine Reihe von Regeln, die eine Immobilie namens Art an die verschiedenen Entwürfe eines Computerprogramms, wie Variablen, Ausdrucken, Funktionen oder Module, vergeben. Diese Arten formalisieren und durchsetzen die ansonsten impliziten Kategorien, die der Programmierer für Algen-Datentypen, Datenstrukturen oder andere Komponenten verwendet (z.B. "array of Float", "Funktionsrückkehr boolean"). Hauptzweck eines Typsystems ist es, die Möglichkeiten für Fehler in Computerprogrammen zu verringern, indem Schnittstellen zwischen verschiedenen Teilen eines Computerprogramms festgelegt und anschließend überprüft werden, ob die Teile in kohärenter Weise miteinander verbunden sind. Diese Überprüfung kann statischer (auf der Grundlage einer Zusammenstellungszeit), dynamischer (auf der Basis) oder als Kombination statischer und dynamischer Kontrollen erfolgen. Typsysteme haben auch andere Zwecke, wie z.B. das Ausdrücken von Geschäftsregeln, wodurch bestimmte Zusammenstellungsoptimierungen ermöglicht werden, die eine mehrfache Versendung ermöglichen, eine Form der Dokumentation usw. U unüberwachtes Lernen Eine Art von Selbstorganisation Hebbian-Lernen, die dazu beiträgt, bisher unbekannte Muster in Daten ohne bestehende Etiketten zu finden. Es ist auch als Selbstorganisierung bekannt und ermöglicht die Modellierungswahrscheinlichverweigerung bestimmter Inputs. Es ist eine der drei wichtigsten Kategorien von Maschinenlernen, zusammen mit überwachtem und verstärktem Lernen. Halbgesteuertes Lernen wurde ebenfalls beschrieben und ist eine Hybridisierung der überwachten und unkontrollierten Techniken. V Visionsverarbeitungseinheit (VPU)A Typ von Mikroprozessor zur Beschleunigung der maschinenlesbaren Aufgaben. Wertabwägungen vollständig – ähnlich einem AI-vollen Problem, ist ein Problem, bei dem das AI-Kontrollproblem vollständig gelöst werden muss. W WatsonA fragwürdiges Computersystem, das in der Lage ist, Fragen in der natürlichen Sprache zu beantworten, die von einem Forschungsteam unter Leitung des Hauptprüfers David Ferrucci entwickelt wurden. Watson wurde nach dem ersten CEO von IBM, Industrialist Thomas J. Watson, benannt. schwache AI ebenfalls enge AI. Künstliche Intelligenz, die sich auf eine enge Aufgabe konzentriert. World Wide Web Consortium (W3C) Die wichtigste internationale Normorganisation für das World Wide Web (abbreviated und W3). Lesen Sie auch künstliche Intelligenz-Beschreibungen.