OpenAI ist ein Forschungslabor für künstliche Intelligenz (KI), bestehend aus dem gemeinnützigen Unternehmen OpenAI LP und seinem Mutterunternehmen, dem gemeinnützigen OpenAI Inc. Das Unternehmen, als Konkurrent für DeepMind, führt Forschung auf dem Gebiet der KI mit dem erklärte Ziel, freundliche KI in einer Weise zu fördern und zu entwickeln, die der Menschheit insgesamt zugute kommt. Die Organisation wurde Ende 2015 in San Francisco von Elon Musk, Sam Altman und anderen gegründet, die gemeinsam 1 Milliarde US$ gepfändet haben. Musk trat im Februar 2018 aus dem Vorstand zurück, blieb aber ein Spender. 2019 erhielt OpenAI LP eine Investition von Microsoft in Höhe von 1 Mrd. US-Dollar. Geschichte Im Oktober 2015 kündigten Elon Musk, Sam Altman und andere Investoren die Gründung von OpenAI an und verlieh dem Unternehmen über 1 Mrd. US-Dollar. Die Organisation erklärte, sie würden "frei mit anderen Institutionen und Forschern zusammenarbeiten", indem sie ihre Patente und Forschung für die Öffentlichkeit zugänglich machen. Am 27. April 2016 veröffentlichte OpenAI eine öffentliche Beta von "OpenAI Gym", seine Plattform für die Verstärkung der Lernforschung. Am 5. Dezember 2016 veröffentlichte OpenAI Universe, eine Software-Plattform zur Messung und Ausbildung der allgemeinen Intelligenz einer KI über das weltweite Angebot von Spielen, Websites und anderen Anwendungen. Am 21. Februar 2018 trat Musk seinen Vorstand zurück, indem er "ein potenzieller zukünftiger Konflikt (interessant) mit Tesla AI-Entwicklung für selbstfahrende Autos zitierte, aber ein Spender blieb. Im Jahr 2019 wechselte OpenAI von Non-Profit zu For-Profit. Das Unternehmen verteilte Eigenkapital an seine Mitarbeiter und arbeitete mit Microsoft Corporation zusammen, die ein Investitionspaket von 1 Mrd. US$ in das Unternehmen angekündigt. OpenAI kündigte seine Absicht an, seine Technologien kommerziell zu lizenzieren, mit Microsoft als seinem bevorzugten Partner. Seit 2020 hat OpenAI seinen Hauptsitz in San Franciscos Mission District und teilt das ehemalige Gebäude der Pioneer Trunk Factory mit Neuralink, einem anderen von Musk gegründeten Unternehmen. Im Juni 2020 kündigte OpenAI GPT-3 an, ein Sprachmodell, das auf Billionen von Wörtern aus dem Internet trainiert wurde. Es gab auch bekannt, dass eine zugehörige API, genannt einfach "die API", das Herz des ersten kommerziellen Produkts bilden würde. GPT-3 richtet sich an natürliche Sprachbeantwortung von Fragen, kann aber auch zwischen Sprachen übersetzen und konsistent improvisierten Text erzeugen. Teilnehmer CEO: Sam Altman, ehemaliger Vorsitzender des Startup-Beschleunigers Y Combinator Ilya Sutskever, Research Director, ein ehemaliger Google-Experte für maschinelles Lernen CTO: Greg Brockman, ehemalige CTO, 3. Mitarbeiter von StripeAndere Träger des Projekts sind: Reid Hoffman, Linked Mitbegründer Peter Thiel, PayPal Mitbegründer Jessica Livingston, Gründungspartner von Y CombinatorCompanies: Infosys, einer der indischen IT-Unternehmen Microsofts Cloud Services Division Die Gruppe begann Anfang Januar 2016 mit neun Forschern. Laut Wired traf sich Brockman mit Yoshua Bengio, einem der "Gründerväter" der tiefen Lernbewegung, und erstellte eine Liste der "besten Forscher auf dem Gebiet". Microsofts Peter Lee erklärte, dass die Kosten eines Top-KI-Forschers die Kosten einer Top-NFL-Quartalback-Prospekt. Während OpenAI Corporate-Level (anstatt Non-Profit-Level)-Gehälter zahlt, zahlt es derzeit keine AI-Forscher-Gehälter vergleichbar mit denen von Facebook oder Google. Dennoch sagte Sutskever, dass er bereit war, Google für OpenAI zu verlassen "teilweise wegen der sehr starken Gruppe von Menschen und, in sehr großem Umfang, wegen seiner Mission. " Brockman sagte: "Das Beste, was ich mir vorstellen konnte, war, dass die Menschheit näher an den Bau echter KI in sicherer Weise heranrückt." OpenAI-Forscher Wojciech Zaremba sagte, dass er "borderline crazy" Angebote von zwei bis drei Mal seinen Marktwert, um OpenAI statt. Motive Einige Wissenschaftler, wie Stephen Hawking und Stuart Russell, haben Bedenken artikuliert, dass, wenn fortgeschrittene KI irgendwann die Fähigkeit gewinnt, sich mit einer immer zunehmenden Rate neu zu gestalten, eine unaufhaltsame "Intelligence Explosion" zu menschlichem Aussterben führen könnte. Musk charakterisiert KI als die "größte existentielle Bedrohung der Menschheit". Die Gründer von OpenAI haben sie als gemeinnützige Organisation strukturiert, damit sie ihre Forschung auf die Schaffung eines positiven langfristigen menschlichen Einflusses konzentrieren können. Musk und Altman haben erklärt, dass sie zum Teil von Bedenken über das existentielle Risiko durch künstliche allgemeine Intelligenz motiviert sind. OpenAI sagt: "Es ist schwer zu fathom, wie viel KI auf menschlicher Ebene die Gesellschaft profitieren könnte", und dass es ebenso schwierig ist, "wie viel es die Gesellschaft beschädigen könnte, wenn sie falsch gebaut oder verwendet wird". Die Sicherheitsforschung kann nicht sicher verschoben werden: "wegen der überraschenden Geschichte von KI ist es schwer vorherzusagen, wann KI auf menschlicher Ebene in Reichweite geraten könnte." OpenAI sagt, dass KI "eine Erweiterung des individuellen menschlichen Willens und im Geiste der Freiheit, so breit und gleichmäßig verteilt wie möglich sein könnte", und die Stimmung wurde anderswo in Bezug auf eine potenziell enorme Klasse von KI-fähigen Produkten ausgedrückt: "Sind wir wirklich bereit, unsere Gesellschaft von autonomen Software- und Hardware-Agenten infiltrieren zu lassen, deren Einzelheiten der Bedienung nur einigen wenigen bekannt sind? Natürlich nicht." Der Co-Vorsitzende Sam Altman erwartet, dass das jahrzehntelange Projekt die menschliche Intelligenz übertrifft. Vishal Sikka, ehemaliger CEO von Infosys, erklärte, dass eine Offenheit, in der der Bemühen "Ergebnisse im Allgemeinen im Interesse der Menschheit hervorbringen würde" eine grundlegende Voraussetzung für seine Unterstützung sei, und dass OpenAI "sehr gut mit unseren langfristigen Werten" und deren "Bemühung, eine gezielte Arbeit zu leisten". Cade Metz von Wired schlägt vor, dass Unternehmen wie Amazon durch den Wunsch motiviert werden, Open-Source-Software und Daten zu verwenden, um das Spielfeld gegen Unternehmen wie Google und Facebook, die enorme Lieferungen von proprietären Daten. Altman sagt, dass Y Combinator-Unternehmen ihre Daten mit OpenAI teilen werden. Im Jahr 2019 wurde OpenAI zum Gewinnunternehmen namens OpenAI LP, um zusätzliche Finanzierungen zu sichern, während sie von einer gemeinnützigen Organisation namens OpenAI Inc in einer Struktur, die OpenAI Calls Capped-Profit, zuvor eine 501(c)(3 gemeinnützige Organisation. Strategie Musk stellte die Frage: "Was ist das Beste, was wir tun können, um sicherzustellen, dass die Zukunft gut ist? Wir könnten auf den Seiten sitzen oder wir können Regulierungsaufsicht fördern, oder wir könnten mit der richtigen Struktur mit Menschen teilnehmen, die sich auf eine sichere und für die Menschheit günstige Art und Weise um die Entwicklung von KI kümmern. "Musk erkannte an, dass "es immer ein Risiko ist, dass wir beim Versuch, die (freundliche) KI voranzutreiben, die Sache schaffen können, von der wir betroffen sind", aber die beste Verteidigung ist "so viele Menschen wie möglich zu befähigen, KI zu haben. Wenn jeder KI Kräfte hat, gibt es keine Person oder eine kleine Gruppe von Personen, die KI Supermacht haben können. " Muskand Altmans kontroverse Strategie, das Risiko zu reduzieren, dass KI einen Gesamtschaden verursachen wird, indem sie allen KI geben, unter denen, die sich mit existentiellen Risiken durch künstliche Intelligenz beschäftigen, kontrovers ist. Der Philosoph Nick Bostrom ist skeptisch für Musk's Ansatz: "Wenn du einen Knopf hast, der die Welt schlecht machen könnte, willst du ihn nicht jedem geben." Während eines 2016 Gesprächs über die technologische Einzigartigkeit sagte Altman, dass "wir nicht planen, alle unsere Quellcode freizugeben" und erwähnte einen Plan, "große Schwänze der Welt zu wählen Vertreter zu einem neuen Governance-Board". Greg Brockman sagte: "Unser Ziel jetzt. ist, das Beste zu tun, was es zu tun hat. Es ist etwas vage." Umgekehrt wurde die anfängliche Entscheidung von OpenAI, GPT-2 wegen des Wunsches "auf der Seite der Vorsicht" in Anwesenheit eines möglichen Missbrauchs zurückzuhalten, von Befürwortern der Offenheit kritisiert. Delip Rao, ein Experte für Textgenerierung, sagte: "Ich glaube nicht, dass [OpenAI] genug Zeit damit verbrachte, [GPT-2] tatsächlich gefährlich war." Andere Kritiker argumentierten, dass offene Veröffentlichung notwendig ist, um die Forschung zu replizieren und mit Gegenmaßnahmen zu kommen. Im Steuerjahr 2017 verbrachte OpenAI allein auf Cloud Computing 7,9 Millionen US$ oder ein Viertel seiner Funktionsaufwendungen. Im Vergleich dazu waren die Gesamtaufwendungen von DeepMind im Jahr 2017 viel größer als 442 Millionen US-Dollar. Im Sommer 2018 benötigte das Training von OpenAI's Dota 2 Bots für mehrere Wochen 128.000 CPUs und 256 GPUs von Google. Laut OpenAI ermöglicht das im März 2019 angenommene Capped-Profit-Modell OpenAI LP legal Investitionen aus Venture-Fonds anzuziehen und zusätzlich Mitarbeiterbeteiligungen im Unternehmen zu gewähren. Ziel ist, dass sie sagen können: "Ich gehe auf Open AI, aber langfristig wird es uns nicht als Familie nachteilig sein." Viele Top-Wissenschaftler arbeiten für Google Brain, DeepMind oder Facebook, Inc., die Aktienoptionen anbieten, die eine gemeinnützige nicht in der Lage wäre. Im Juni 2019 erhöhte OpenAI LP eine Milliarde von Microsoft, eine Summe, die OpenAI plant, "innerhalb von fünf Jahren und möglicherweise viel schneller ausgegeben haben". Altman hat erklärt, dass selbst eine Milliarde Dollar sich als unzureichend erweisen kann und dass das Labor letztendlich "mehr Kapital als jede Non-Profit jemals erhöht" benötigt, um AGI zu erreichen. Der Übergang von einem gemeinnützigen zu einem capped-profit-Unternehmen wurde mit Skeptizismus von Oren Etzioni vom gemeinnützigen Allen Institute for AI angesehen, der zugestimmt hat, dass es schwierig ist, Spitzenforscher zu einem gemeinnützigen Non-Profit zu erwecken, aber sagte: "Ich stimme der Vorstellung nicht zu, dass ein Non-Profit nicht konkurrieren kann" und auf erfolgreiche Low-Budget-Projekte von OpenAI und anderen. "Wenn größer und besser finanziert war immer besser, dann wäre IBM noch Nummer eins. " Nach dem Übergang ist die öffentliche Offenlegung der Vergütung der Top-Mitarbeiter bei OpenAI LP nicht mehr gesetzlich vorgeschrieben. Der gemeinnützige OpenAI Inc. ist der einzige kontrollierende Anteilseigner von OpenAI LP. OpenAI LP, obwohl es sich um ein gemeinnütziges Unternehmen handelt, behält sich eine formale fiduziäre Verantwortung für die gemeinnützige Charter von OpenAI. Eine Mehrheit des Vorstands der OpenAI Inc. wird davon abgehalten, finanzielle Beteiligungen an OpenAI LP zu haben. Darüber hinaus werden Minderheitsmitglieder, die an OpenAI LP beteiligt sind, aufgrund von Interessenkonflikten von bestimmten Stimmen befreit. Einige Forscher haben argumentiert, dass OpenAI LPs Wechsel zum gemeinnützigen Status unvereinbar mit den Forderungen von OpenAI ist, AI zu demokratisieren. Ein Journalist in Vice News schrieb, dass "in der Regel konnten wir uns nie auf Risikokapitalisten verlassen, um die Menschheit zu verbessern." Produkte und Anwendungen Die Forschung von OpenAI konzentriert sich tendenziell auf das Verstärkungslernen. OpenAI wird als wichtiger Konkurrent für DeepMind angesehen. Gymnasium Gym zielt darauf ab, einen leicht einzurichtenden, allgemein-intelligence-Benchmark mit einer Vielzahl von unterschiedlichen Umgebungen zu bieten – was auch immer, aber breiter als, die ImageNet Large Scale Visual Recognition Challenge in der überwachten Lernforschung verwendet – und das hofft, die Art und Weise zu standardisieren, in der Umgebungen in AI-Forschungspublikationen definiert werden, so dass veröffentlichte Forschung leichter reproduzierbar wird. Das Projekt behauptet, dem Benutzer eine einfache Schnittstelle zur Verfügung zu stellen. Ab Juni 2017 kann Gym nur mit Python verwendet werden. Ab September 2017 wurde die Dokumentationsstelle Gym nicht gepflegt, und die aktive Arbeit konzentrierte sich stattdessen auf ihre GitHub Seite. Das ist nicht möglich. In RoboSumo fehlten virtuelle humanoide Metalearning-Roboter zunächst an Kenntnissen, wie man sogar gehen kann, und angesichts der Ziele des Lernens, um sich herum zu bewegen, und das Gegenmittel aus dem Ring schieben. Durch diesen adversarialen Lernprozess lernen die Agenten, sich an wechselnde Bedingungen anzupassen; wenn ein Agent aus dieser virtuellen Umgebung entfernt und in einer neuen virtuellen Umgebung mit hohen Winden platziert wird, bleiben die Agententräger aufrecht, was darauf hindeutet, dass es gelernt hatte, wie man in einer verallgemeinerten Weise ausgleicht. OpenAIs Igor Mordatch argumentiert für diesen Wettbewerb zwischen Agenten können eine Intelligenz "Arms-Rennen" schaffen, die die Fähigkeit eines Agenten erhöhen, zu funktionieren, auch außerhalb des Kontexts des Wettbewerbs. Debate GameIn 2018 startete OpenAI das Debate Game, das Maschinen lehrt, Spielzeugprobleme vor einem menschlichen Richter zu diskutieren. Ziel ist es, zu untersuchen, ob ein solcher Ansatz bei der Prüfung von KI-Entscheidungen und bei der Entwicklung von erklärender KI helfen kann. Dactyl Dactyl nutzt maschinelles Lernen, um einen Roboter Shadow Hand von Grund auf zu trainieren, mit dem gleichen Bewehrungs-Learning-Algorithmus-Code, den OpenAI Five verwendet. Die Roboterhand wird vollständig in physikalisch ungenauer Simulation ausgebildet. Generative Modelle GPT Das Originalpapier über generatives Vortraining (GPT) eines Sprachmodells wurde von Alec Radford und Kollegen verfasst und am 11. Juni 2018 auf der OpenAI-Website veröffentlicht. Es zeigte, wie ein generatives Sprachmodell in der Lage ist, Weltwissen zu erwerben und lange Abhängigkeiten zu verarbeiten, indem es auf einem vielfältigen Korpus mit langen Abschnitten zusammenhängender Texte vorschult. GPT-2Generativ Vortrainierter Transformer 2, bekannt durch seine abgekürzte Form GPT-2, ist ein ununterbrochenes Transformator Sprachmodell und der Nachfolger von GPT. GPT-2 wurde im Februar 2019 erstmals bekannt gegeben, wobei nur begrenzte Demonstrativversionen ursprünglich an die Öffentlichkeit veröffentlicht wurden. Die vollständige Version von GPT-2 wurde nicht sofort aus Sorge über potenziellen Missbrauch freigegeben, einschließlich Anwendungen zum Schreiben gefälschter Nachrichten. Einige Experten äußerten Skepsis, dass GPT-2 eine erhebliche Bedrohung darstellte. Das Allen Institut für Künstliche Intelligenz reagierte auf GPT-2 mit einem Tool, um "neue gefälschte Nachrichten" zu erkennen. Andere Forscher, wie Jeremy Howard, warnten davor, "die Technologie zu vollenden, Twitter, E-Mail und das Web mit einer vernünftigen, kontextgerechten Prosa, die alle andere Sprache ertrinken und nicht filtern könnte". Im November 2019 veröffentlichte OpenAI die komplette Version des GPT-2 Sprachmodells. Mehrere Websites führen interaktive Demonstrationen verschiedener Instanzen von GPT-2 und anderen Transformatorenmodellen. Die Autoren von GPT-2 argumentieren, dass es sich bei den unübertroffenen Sprachmodellen um allgemeine Lerner handelt, die von GPT-2 illustriert wurden, um hochmoderne Genauigkeit und Perplexität auf 7 von 8 Null-Shot-Aufgaben zu erreichen (d.h. das Modell wurde nicht weiter auf irgendwelche aufgabenspezifischen Input-Output-Beispiele geschult). Der Korpus, auf dem er geschult wurde, WebText, enthält etwas mehr als 8 Millionen Dokumente für insgesamt 40 GB Text von URLs, die in Reddit-Einreichungen mit mindestens 3 Upvotes geteilt wurden. Es vermeidet bestimmte Probleme, die Vokabeln mit Wort-Tokens durch die Verwendung von Byte-Paar-Codierung. Dies ermöglicht es, jede Zeichenfolge durch Kodierung sowohl einzelner Zeichen als auch mehrerer Zeichen zu repräsentieren. GPT-3Generativ Pre-trained Transformer 3, bekannt durch seine verkürzte Form GPT-3, ist ein unübertroffenes Transformer Sprachmodell und der Nachfolger von GPT-2. Es wurde erstmals im Mai 2020 beschrieben. OpenAI erklärte, dass die Vollversion von GPT-3 175 Milliarden Parameter enthält, zwei Größenordnungen größer als die 1,5 Milliarden Parameter in der Vollversion von GPT-2 (obwohl auch GPT-3 Modelle mit nur 125 Millionen Parametern ausgebildet wurden). OpenAI erklärte, dass GPT-3 bei bestimmten Meta-Lernaufgaben erfolgreich sei. Es kann den Zweck eines einzigen Eingangs-Ausgangspaares verallgemeinern. Das Papier gibt ein Beispiel für Übersetzungs- und sprachübergreifendes Transferlernen zwischen Englisch und Rumänisch und zwischen Englisch und Deutsch. GPT-3 verbesserte Benchmark-Ergebnisse gegenüber GPT-2. OpenAI warnte darauf, dass solche Skalierung von Sprachmodellen sich nähern oder auf die grundlegenden Fähigkeitsbeschränkungen von prädiktiven Sprachmodellen stößt. Vortraining GPT-3 benötigte mehrere tausend Petaflop/s-Tage der Berechnung, verglichen mit zehnen von petaflop/s-days für das volle GPT-2 Modell. Wie das seines Vorgängers wurde das voll ausgebildete Modell der GPT-3 nicht sofort aus Gründen eines möglichen Missbrauchs an die Öffentlichkeit freigegeben, obwohl OpenAI plante, den Zugang über eine bezahlte Cloud-API nach einer zweimonatigen kostenlosen privaten Beta zu ermöglichen, die im Juni 2020 begann. Am 23. September 2020 wurde GPT-3 ausschließlich an Microsoft lizenziert. Music OpenAI's MuseNet (2019) ist ein tiefes neurales Netz, das ausgebildet ist, um anschließende Noten in MIDI-Musikdateien vorherzusagen. Es kann Songs mit zehn verschiedenen Instrumenten in fünfzehn verschiedenen Stilen generieren. Laut The Verge beginnt ein von MuseNet generiertes Lied eher vernünftig, fällt dann in Chaos, je länger es spielt. OpenAI's Jukebox (2020) ist ein Open-Source-Algorithmus, um Musik mit Gesang zu erzeugen. Nach dem Training an 1,2 Millionen Samples akzeptiert das System ein Genre, einen Künstler und einen Snippet von Texten und gibt Songmuster aus. OpenAI sagte die Songs "zeigt lokale musikalische Kohärenz, folgt traditionellen Akkordmustern" aber erkannte, dass die Songs "familiar größere musikalische Strukturen wie Chöre, die wiederholen" fehlen und dass "es eine signifikante Lücke" zwischen Jukebox und human-generierter Musik gibt. Die Verge sagte "Es ist technologisch beeindruckend, auch wenn die Ergebnisse wie schlaue Versionen von Songs klingen, die sich vielleicht vertraut fühlen", während Business Insider sagte "überraschenderweise, einige der resultierenden Songs sind eingängig und solide legitim." API Im Juni 2020, OpenAI kündigte eine Mehrzweck-API an, die es sagte, war "für den Zugriff auf neue AI-Modelle von OpenAI entwickelt" zu lassen Entwickler auf sie für "jede englische Sprache AI-Task." DALL-E und CLIP DALL-E ist ein Transformer-Modell, das Bilder aus Textbeschreibungen erstellt, die von OpenAI im Januar 2021 offenbart wurden. CLIP tut das Gegenteil: Es erstellt eine Beschreibung für ein bestimmtes Bild. DALL-E verwendet eine 12-Billion-Parameter-Version von GPT-3, um natürliche Spracheingänge zu interpretieren (z.B. "eine grüne Ledertasche, die wie ein Pentagon geformt ist" oder "eine isometrische Ansicht einer traurigen Capybara") und entsprechende Bilder zu erzeugen. Es ist in der Lage, Bilder von realistischen Objekten ("ein Glasfenster mit einem Bild einer blauen Erdbeere") sowie Objekte zu erstellen, die in der Realität nicht existieren ("ein Würfel mit der Textur eines Porcupine"). Ab März 2021 ist keine API oder Code verfügbar. Im März 2021 OpenAI veröffentlichte ein Papier mit dem Titel Multimodal Neuronen in künstlichen neuronalen Netzwerken, wo sie eine detaillierte Analyse der CLIP (und GPT) Modelle und ihrer Schwachstellen zeigten. Die neue Art von Angriffen auf solche Modelle wurde in dieser Arbeit beschrieben. Wir beziehen uns auf diese Angriffe als typografische Angriffe. Wir sind der Ansicht, dass Angriffe, wie sie oben beschrieben sind, nicht nur ein akademisches Anliegen sind. Durch die Nutzung der Fähigkeit des Modells, Text robust zu lesen, finden wir, dass selbst Fotos von handschriftlichen Text oft das Modell täuschen können. Mikroskop OpenAI Mikroskop ist eine Sammlung von Visualisierungen jeder signifikanten Schicht und Neuron von acht verschiedenen neuronalen Netzwerkmodellen, die oft in der Interpretationsfähigkeit untersucht werden. Mikroskop wurde für eine einfache Analyse der Merkmale erstellt, die sich in diesen neuronalen Netzwerken bilden. Die Modelle enthalten sind AlexNet, VGG 19, verschiedene Versionen von Inception und verschiedene Versionen von CLIP Resnet. Videospiel-Bots und Benchmarks OpenAI Five OpenAI Five ist der Name eines Teams von fünf OpenAI-kuratierten Bots, die in dem wettbewerbsfähigen Fünf-fünf-Fünf-Videospiel Dota 2 verwendet werden, die lernen, gegen menschliche Spieler auf einem hohen Geschick Ebene vollständig durch Test-und-Fehler-Algorithmen spielen. Bevor sie ein Team von fünf wurde, fand die erste öffentliche Demonstration auf der The International 2017 statt, das jährliche Premiere-Meisterschaftsturnier für das Spiel, wo Dendi, ein professioneller ukrainischer Spieler, gegen einen Bot in einem live 1v1 Matchup verloren. Nach dem Spiel, CTO Greg Brockman erklärte, dass der Bot gelernt hatte, zwei Wochen in Echtzeit gegen sich selbst zu spielen, und dass die Lernsoftware ein Schritt in Richtung der Erstellung von Software war, die komplexe Aufgaben wie einen Chirurg bewältigen kann. Das System nutzt eine Form des Verstärkungslernens, wie die Bots im Laufe der Zeit lernen, indem sie Hunderte von Malen pro Tag für Monate gegen sich selbst spielen und für Aktionen wie das Töten eines Feindes und das Erreichen von Kartenzielen belohnt werden. Bis Juni 2018 erweiterte sich die Fähigkeit der Bots, als Vollteam von fünf zu spielen und sie konnten Teams von Amateur- und Semiprofessionellen Spielern besiegen. Auf der International 2018, OpenAI Five spielte in zwei Ausstellungsspiele gegen professionelle Spieler, aber endete beide Spiele zu verlieren. Im April 2019 besiegte OpenAI Five OG, die amtierenden Weltmeister des Spiels zur Zeit, 2:0 in einem Live-Ausstellungsspiel in San Francisco. Das letzte öffentliche Aussehen der Bots kam später in diesem Monat, wo sie in 42,729 Gesamtspiele in einem viertägigen offenen Online-Wettbewerb gespielt, gewinnen 99,4% dieser Spiele.GYM Zurück zur Übersicht Retro ist eine Plattform für die Stärkung der Lernforschung über Spiele. Gym Retro wird verwendet, um Forschung über RL Algorithmen und Studie Verallgemeinerung. Die Forschung in RL hat sich vor allem auf die Optimierung von Agenten zur Lösung einzelner Aufgaben konzentriert. Gym Retro gibt die Möglichkeit, zwischen Spielen mit ähnlichen Konzepten, aber verschiedenen Erscheinungen zu verallgemeinern. Siehe auch Hinweise Referenzen Externe Links Offizielle Website