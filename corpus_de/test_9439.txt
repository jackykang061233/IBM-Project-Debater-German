AlphaGo ist ein Computerprogramm, das das Brettspiel Go.It spielt, wurde von DeepMind Technologies entwickelt, die später von Google erworben wurde. Nachfolgende Versionen von AlphaGo wurden immer mächtiger, darunter eine Version, die unter dem Namen Master konkurrierte. Nach dem Ausscheiden aus dem Wettbewerbsspiel gelang AlphaGo Master durch eine noch leistungsstärkere Version namens AlphaGo Zero, die völlig selbstfahrend war, ohne von menschlichen Spielen zu lernen. AlphaGo Zero wurde dann in ein Programm namens AlphaZero verallgemeinert, das zusätzliche Spiele spielte, darunter Schach und Shigi. Alpha Zero ist wiederum durch ein Programm namens MuZero erfolgreich, das lernt, ohne die Regeln gelehrt zu werden. AlphaGo und seine Nachfolger nutzen einen Monte Carlo Baum-Suchalgorithmus, um seine Bewegungen basierend auf Kenntnissen zu finden, die zuvor durch maschinelles Lernen erworben wurden, und zwar durch ein künstliches neuronales Netzwerk (eine tiefe Lernmethode) durch umfangreiches Training, sowohl vom menschlichen als auch vom Computerspiel. Ein neuronales Netzwerk wird ausgebildet, um die besten Bewegungen und die Gewinnprozentsätze dieser Bewegungen zu identifizieren. Dieses neuronale Netzwerk verbessert die Stärke der Baumsuche, was zu einer stärkeren Auswahl in der nächsten Iteration führt. Im Oktober 2015, in einem Kampf gegen Fan Hui, der ursprüngliche AlphaGo wurde der erste Computer Go Programm, um einen menschlichen Profi zu schlagen Gehen Sie Spieler ohne Handicap auf einem Full-Size 19×19 Board. Im März 2016, es schlug Lee Sedol in einem fünf-Spiel-Spiel, das erste Mal ein Computer-Go-Programm hat einen 9-dan-Profi ohne Behinderung geschlagen. Obwohl es Lee Sedol im vierten Spiel verloren, Lee trat im letzten Spiel zurück, gab eine endgültige Punktzahl von 4 Spielen zu 1 zugunsten von AlphaGo.In Anerkennung des Sieges wurde AlphaGo eine Ehrenmarke 9-dan von der Korea Baduk Association ausgezeichnet. Die Vorführung und das Herausforderungsspiel mit Lee Sedol wurden in einem Dokumentarfilm dokumentiert, der auch AlphaGo genannt wurde, unter der Leitung von Greg Kohs. Der Sieg von AlphaGo wurde am 22. Dezember 2016 von Science als einer der Breakthrough of the Year runners-up gewählt. Auf der Future of Go Summit 2017 schlug die Master-Version von AlphaGo Ke Jie, der damals auf der Welt rangierte Spieler, in einem Dreispiel, danach wurde AlphaGo von der chinesischen Weiqi Association promoviert. Nach dem Spiel zwischen AlphaGo und Ke Jie trat DeepMind in den Ruhestand AlphaGo, während weiterhin AI-Forschung in anderen Bereichen. Der selbstfahrende AlphaGo Zero erreichte einen 100–0-Sieg gegen die frühe wettbewerbsfähige Version von AlphaGo, und sein Nachfolger AlphaZero wird derzeit als der weltweit führende Spieler in Go sowie möglicherweise in Schach wahrgenommen. Geschichte Go wird für Computer als viel schwieriger angesehen, als andere Spiele wie Schach zu gewinnen, weil sein viel größerer Verzweigungsfaktor es verbietend schwierig macht, traditionelle AI-Methoden wie Alpha-Beta-Pruning, Baum-Traversal und heuristische Suche zu verwenden. Fast zwei Jahrzehnte nach IBM Computer Deep Blue schlagen Welt-Chassis-Champion Garry Kasparov im Jahr 1997 Spiel, die stärksten Gehen Sie Programme mit künstlichen Intelligenz Techniken nur erreicht über Amateur 5-dan Ebene und konnte noch nicht schlagen ein Profi Gehen Sie Spieler ohne Handicap. Im Jahr 2012, das Software-Programm Zen, läuft auf einem vier PC-Cluster, schlagen Masaki Takemiya (9p) zweimal bei fünf- und vier-Stein-Handicaps. Im Jahr 2013 schlug Crazy Stone Yoshio Ishida (9p) bei einem Vier-Stein-Handicap. Laut DeepMinds David Silver, dem Alpha Go-Forschungsprojekt wurde um 2014 gegründet, um zu testen, wie gut ein neuronales Netzwerk mit Deep Learning bei Go.AlphaGo konkurrieren kann eine signifikante Verbesserung gegenüber früheren Go-Programmen. In 500 Spielen gegen andere verfügbar Go Programme, einschließlich Crazy Stone und Zen, Alpha Gehen Sie auf einem einzigen Computer laufen gewonnen alles außer einem. In einem ähnlichen Matchup, AlphaGo Laufen auf mehreren Computern gewann alle 500 Spiele gegen andere Go-Programme gespielt, und 77% der Spiele gespielt gegen AlphaGo Laufen auf einem einzigen Computer. Die verteilte Version im Oktober 2015 nutzte 1,202 CPUs und 176 GPUs. Match gegen Fan Hui Im Oktober 2015, die verteilte Version von AlphaGo besiegte den European Go Champion Fan Hui, ein 2-dan (von 9 dan möglich) Profi, fünf bis null. Dies war das erste Mal ein Computer Go Programm hatte einen professionellen menschlichen Spieler auf einem Full-Size-Board ohne Behinderung geschlagen. Die Ankündigung der Nachricht wurde bis zum 27. Januar 2016 verzögert, um mit der Veröffentlichung eines Papiers in der Zeitschrift Nature zusammenzuarbeiten, in der die verwendeten Algorithmen beschrieben wurden. Spiel gegen Lee Sedol AlphaGo gespielt Südkoreaner Profi Go Spieler Lee Sedol, Rang 9-dan, einer der besten Spieler bei Go, mit fünf Spielen im Four Seasons Hotel in Seoul, Südkorea am 9, 10, 12, 13, und 15 März 2016, die video-streamed live. Aus fünf Spielen gewann AlphaGo vier Spiele und Lee gewann das vierte Spiel, das ihn als der einzige menschliche Spieler aufgezeichnet, der AlphaGo in all seinen 74 offiziellen Spielen schlug. AlphaGo lief auf Googles Cloud Computing mit seinen Servern in den Vereinigten Staaten. Das Spiel verwendete chinesische Regeln mit einem 7,5-Punkt komi, und jede Seite hatte zwei Stunden Denken Zeit plus drei 60-sek. byoyomi Perioden. Die Version von AlphaGo spielen gegen Lee nutzte eine ähnliche Menge an Rechenleistung wie im Fan Hui-Spiel verwendet. Der Economist berichtete, dass es 1,920 CPUs und 280 GPUs verwendet. Zum Zeitpunkt des Spiels, Lee Sedol hatte die zweithöchste Anzahl von Go-Internationale Meisterschaft Siege in der Welt nach Südkoreanischer Spieler Lee Changho, der die Weltmeisterschaft Titel für 16 Jahre gehalten. Da es keine einzige offizielle Rankingmethode auf internationaler Ebene gibt Die Rankings können unter den Quellen variieren. Während er manchmal als Top eingestuft wurde, rangierten einige Quellen Lee Sedol als viertbester Spieler der Welt zur Zeit. AlphaGo wurde nicht speziell auf Lee geschult, noch wurde entwickelt, um mit bestimmten menschlichen Spielern konkurrieren. Die ersten drei Spiele wurden von AlphaGo nach Rücktritten von Lee gewonnen. Jedoch, Lee schlug AlphaGo im vierten Spiel, gewinnen durch Rücktritt bei Bewegung 180. Alpha Gehen Sie dann weiter, um einen vierten Sieg zu erreichen, gewinnen Sie das fünfte Spiel durch Rücktritt. Der Preis betrug 1 Million US$. Seit Alpha Gehen Sie vier von fünf und damit die Serie gewonnen, wird der Preis an Wohltätigkeitsorganisationen gespendet, darunter UNICEF. Lee Sedol erhielt $150.000 für die Teilnahme an allen fünf Spielen und eine zusätzliche $20.000 für seinen Sieg in Spiel 4. Im Juni 2016, bei einer Präsentation an einer Universität in den Niederlanden, Aja Huang, einer der Deep Mind Team, ergab, dass sie die logische Schwäche, die während des 4. Spiels zwischen AlphaGo und Lee aufgetreten, und dass nach Bewegung 78 (die wurde die "Götte Bewegung" von vielen Profis gegraben,) würde es spielen wie beabsichtigt und halten Black's Vorteil. Vor dem Verschieben 78, Alpha Go war im Laufe des Spiels führen, aber Lees Bewegung verursachte die Rechenkräfte des Programms umgelenkt und verwirrt zu werden. Huang erklärte, Alpha Go's politisches Netzwerk, die genaueste Bewegung Ordnung und Fortsetzung zu finden, nicht genau führen Alpha Gehen Sie, um die richtige Fortsetzung nach der Bewegung 78 zu machen, da sein Wert-Netzwerk nicht bestimmen Lees 78. Bewegung als die wahrscheinlichste, und daher, wenn die Bewegung gemacht Alpha Go konnte die richtige Anpassung an die logische Fortsetzung nicht vornehmen. Sixty online Spiele Am 29. Dezember 2016 begann ein neues Konto auf dem Tygem-Server namens Magister (in der chinesischen Version des Servers als Magist angezeigt) aus Südkorea Spiele mit professionellen Spielern zu spielen. Er änderte seinen Kontonamen am 30. Dezember an Master und zog dann am 1. Januar 2017 zum FoxGo Server. Am 4. Januar bestätigte DeepMind, dass der Magister und der Master beide von einer aktualisierten Version von AlphaGo gespielt wurden, genannt AlphaGo Master. Ab dem 5. Januar 2017 war AlphaGo Masters Online-Record 60 Gewinne und 0 Verluste, einschließlich drei Siege über Go's Top-Spieler, Ke Jie, die im Voraus, dass Master war eine Version von AlphaGo.Nach dem Verlust an Master, Gu Li bot eine Bounty von 100.000 Yuan (US$14,400) an den ersten menschlichen Spieler, der Master besiegen konnte. Meister spielte im Tempo von 10 Spielen pro Tag. Viele vermuteten schnell, dass es ein KI-Spieler wegen wenig oder nicht zwischen den Spielen. Zu seinen Gegnern zählen viele Weltmeister wie Ke Jie, Park Jeong-hwan, Yuta Iyama, Tuo Jiaxi, Mi Yuting, Shi Yue, Chen Yaoye, Li Qincheng, Gu Li, Chang Hao, Tang Weixing, Fan Tingyu, Zhou Ruiyang, Jiang Weijie, Chou Xiaon-Yang Yonghu Alle 60 Spiele außer einem waren schnell besetzte Spiele mit drei 20 oder 30 Sekunden byo-yomi. Der Meister bot an, die byo-yomi auf eine Minute zu verlängern, wenn mit Nie Weiping unter Berücksichtigung seines Alters spielen. Nach dem Sieg seines 59. Spiels hat sich der Meister im Chatraum offenbart, um von Dr. Aja Huang des DeepMind Teams kontrolliert zu werden, dann änderte seine Nationalität in das Vereinigte Königreich. Nach Abschluss dieser Spiele, sagte der Mitbegründer von Google DeepMind, Demis Hassabis, in einem Tweet, "wir freuen uns auf einige offizielle, Full-Live-Spiele später [2017] in Zusammenarbeit mit Go Organisationen und Experten zu spielen. Go-Experten waren beeindruckt von der Leistung des Programms und seinem nichtmenschlichen Spielstil; Ke Jie sagte, dass "Nach der Menschheit verbrachte Tausende von Jahren unsere Taktik, Computer sagen uns, dass Menschen völlig falsch... Ich würde so weit gehen zu sagen, dass kein Mensch den Rand der Wahrheit von Go berührt hat." Zukunft von Go SummitIn der Zukunft von Go Summit in Wuzhen im Mai 2017, AlphaGo Master spielte drei Spiele mit Ke Jie, die Welt No.1 Platzierte Spieler, sowie zwei Spiele mit mehreren Top-chinesischen Profis, ein Paar Go Spiel und ein gegen ein gemeinsames Team von fünf menschlichen Spielern. Google DeepMind bot 1,5 Millionen Dollar Gewinnerpreise für das Dreispiel zwischen Ke Jie und Master, während die verlorene Seite 300.000 Dollar. Der Meister gewann alle drei Spiele gegen Ke Jie, danach wurde AlphaGo von der chinesischen Weiqi Association profis 9-dan ausgezeichnet. Nachdem sie ihre Drei-Spiel-Spiel gegen Ke Jie, die Top-bewertete Welt Go-Spieler, AlphaGo zog in den Ruhestand. DeepMind entbunden auch das Team, das an dem Spiel arbeitete, um sich auf AI-Forschung in anderen Bereichen zu konzentrieren. Nach dem Gipfel veröffentlichte Deepmind 50 volle Länge AlphaGo vs AlphaGo Spiele, als Geschenk an die Go Community. AlphaGo Zero und Alpha Null Alpha Go's Team veröffentlichte am 19. Oktober 2017 einen Artikel in der Zeitschrift Nature und stellte AlphaGo Zero vor, eine Version ohne menschliche Daten und stärker als jede bisherige human-champion-defeating Version. Durch das Spielen gegen sich übertraf AlphaGo Zero die Stärke von AlphaGo Lee in drei Tagen, indem er 100 Spiele auf 0 gewann, erreichte das Niveau von AlphaGo Master in 21 Tagen und übertraf alle alten Versionen in 40 Tagen. In einem am 5. Dezember 2017 auf arXiv veröffentlichten Papier behauptete DeepMind, dass es AlphaGo Zeros Ansatz in einen einzigen AlphaZero-Algorithmus verallgemeinerte, der innerhalb von 24 Stunden eine übermenschliche Ebene des Spiels in den Schachspielen, shogi und Go durch die Niederlage von Welt-Champion-Programmen, Stockfish, Elmo und 3-Tage-Version von AlphaGo Zero in jedem Fall erreichte. LehrwerkzeugAm 11. Dezember 2017 veröffentlichte DeepMind Alpha Gehen Sie Lehr-Tool auf seiner Website, um Gewinnraten von verschiedenen zu analysieren Gehen Sie Öffnungen, wie von AlphaGo Master berechnet. Das Lehrwerkzeug sammelt 6.000 Gehen Sie Öffnungen von 230.000 menschlichen Spielen, die jeweils mit 10.000.000 Simulationen von AlphaGo Master analysiert wurden. Viele der Öffnungen umfassen menschliche Bewegungsvorschläge. Versionen Eine frühe Version von AlphaGo wurde auf Hardware mit verschiedenen Anzahl von CPUs und GPUs getestet, die im asynchronen oder verteilten Modus laufen. Jedem Schritt wurden zwei Sekunden nachgedacht. Die resultierenden Elo Bewertungen sind unten aufgeführt. In den Spielen mit mehr Zeit pro Bewegung werden höhere Bewertungen erreicht. Im Mai 2016 enthüllte Google seine eigene proprietäre Hardware "Tensor-Verarbeitungseinheiten", die es bereits in mehreren internen Projekten bei Google eingesetzt hatte, einschließlich der AlphaGo-Match gegen Lee Sedol. In der Zukunft von Go Summit im Mai 2017, DeepMind offengelegt, dass die Version von AlphaGo in diesem Summit verwendet wurde AlphaGo Master, und ergab, dass es die Stärke der verschiedenen Versionen der Software gemessen hatte. AlphaGo Lee, die Version gegen Lee, könnte AlphaGo Fan geben, die Version in AlphaGo vs. Fan Hui, drei Steine, und AlphaGo Master war sogar drei Steine stärker. AlgorithmAs 2016, Alpha Go's Algorithmus verwendet eine Kombination aus maschinellem Lernen und Baum-Suchtechniken, kombiniert mit umfangreichem Training, sowohl vom menschlichen als auch vom Computerspiel. Es verwendet Monte Carlo Baumsuche, geführt von einem "Wert-Netzwerk" und einem "Politik-Netzwerk", beide mit tiefen neuronalen Netzwerk-Technologie implementiert. Auf die Eingabe wird eine begrenzte Menge spielerspezifischer Merkmalsdetektionsvorverarbeitung (z.B. um hervorzuheben, ob eine Bewegung mit einem Nakade-Muster übereinstimmt) angewendet, bevor sie an die neuronalen Netze gesendet wird. Die neuronalen Netzwerke des Systems wurden zunächst von menschlichem Gameplay-Know-how überwunden. AlphaGo wurde zunächst ausgebildet, um menschliches Spiel zu imitieren, indem er versuchte, die Bewegungen von Expertenspielern aus aufgezeichneten historischen Spielen zu entsprechen, mit einer Datenbank von rund 30 Millionen Bewegungen. Nachdem es einen gewissen Grad an Kompetenz erreicht hatte, wurde es weiter trainiert, indem man große Anzahl von Spielen gegen andere Instanzen von sich selbst spielen, indem man Verstärkung lernen, um sein Spiel zu verbessern. Um die Zeit seines Gegners missachtend zu verschwenden, wird das Programm speziell programmiert, um zurückzutreten, wenn seine Bewertung der Gewinnwahrscheinlichkeit unter eine bestimmte Schwelle fällt; für das Spiel gegen Lee wurde die Rücktrittsschwelle auf 20 % gesetzt Stil des Spiels Toby Manning, der Spielreferent für AlphaGo vs. Fan Hui, hat den Stil des Programms als konservativ beschrieben". AlphaGo's Spielstil begünstigt eine größere Wahrscheinlichkeit des Gewinnens durch weniger Punkte über weniger Wahrscheinlichkeit des Gewinnens durch mehr Punkte. Seine Strategie, seine Gewinnwahrscheinlichkeit zu maximieren, unterscheidet sich von dem, was menschliche Spieler tun, was ist, um territoriale Gewinne zu maximieren, und erklärt einige seiner seltsam aussehenden Bewegungen. Es macht eine Menge Öffnungsbewegungen, die nie oder selten von Menschen gemacht wurden, während viele Zweitlinien-Eröffnungsbewegungen vermeiden, die Menschen gerne machen. Es mag Schulterschläge zu verwenden, besonders wenn der Gegner über konzentriert ist. Der Sieg der AI Community AlphaGo im März 2016 war ein wichtiger Meilenstein in der künstlichen Intelligenzforschung. Go war zuvor als schwieriges Problem beim maschinellen Lernen angesehen worden, das für die Technologie der Zeit außer Reichweite sein sollte. Die meisten Experten dachten So leistungsstark wie Alpha Go war mindestens fünf Jahre entfernt; einige Experten dachten, dass es mindestens ein weiteres Jahrzehnt dauern würde, bevor Computer Go Champions schlagen würden. Die meisten Beobachter zu Beginn der 2016 Spiele erwartete Lee zu schlagen AlphaGo.With Spiele wie Schecker (das wurde durch das Chinook erwischt Spieler-Team gelöst,) Schach, und jetzt Go von Computern gewonnen, Siege bei beliebten Brettspielen können nicht mehr als wichtige Meilensteine für künstliche Intelligenz in der Weise, dass sie verwendet. Deep Blues Murray Campbell namens Alpha Go's Sieg "das Ende einer Ära. Brettspiele sind mehr oder weniger getan und es ist Zeit, weiter zu bewegen. " Im Vergleich zu Deep Blue oder Watson sind die zugrunde liegenden Algorithmen von AlphaGo möglicherweise allgemeiner und können Beweise dafür sein, dass die wissenschaftliche Gemeinschaft Fortschritte in Richtung künstlicher allgemeiner Intelligenz macht. Einige Kommentatoren glauben, dass der Sieg von AlphaGo eine gute Gelegenheit für die Gesellschaft macht, sich auf die möglichen zukünftigen Auswirkungen von Maschinen mit allgemeinem Zweck Intelligenz vorzubereiten. Wie von Unternehmer Guy Suter, Alpha Geh nur weiß, wie man Go spielt und keine allgemeine Intelligenz besitzt; ["Es] konnte nicht nur einen Morgen aufwachen und entscheiden, dass es lernen will, wie man Waffen verwendet." KI-Forscher Stuart Russell sagte, dass KI-Systeme wie AlphaGo schneller vorangekommen sind und stärker werden als erwartet, und wir müssen daher Methoden entwickeln, um sicherzustellen, dass sie "unter menschlicher Kontrolle bleiben". Einige Gelehrte, wie Stephen Hawking, warnten (im Mai 2015 vor den Spielen), dass einige zukünftige selbstverbessernde KI tatsächliche allgemeine Intelligenz gewinnen könnte, was zu einer unerwarteten KI-Übernahme führte; andere Gelehrte sind nicht einverstanden: KI-Experte Jean-Gabriel Ganascia glaubt, dass "Dings wie 'gemeinsamer Sinn' niemals reproduzierbar sein könnten", und sagt "Ich weiß nicht, warum wir über Ängste sprechen würden. Im Gegenteil, das erhöht Hoffnungen in vielen Bereichen wie Gesundheit und Raumerforschung." Der Informatiker Richard Sutton sagte: "Ich glaube nicht, dass die Leute Angst haben sollten, aber ich denke, die Leute sollten darauf achten. "In China, Alpha Go war ein "Sputnik Moment", der die chinesische Regierung davon überzeugte, die Finanzierung für künstliche Intelligenz zu priorisieren und dramatisch zu erhöhen. Im Jahr 2017 erhielt das DeepMind AlphaGo-Team die erste IJCAI Marvin Minsky-Medaille für herausragende Leistungen in KI." AlphaGo ist eine wunderbare Leistung und ein perfektes Beispiel für das, was die Minsky-Medaille initiiert wurde, um zu erkennen", sagte Professor Michael Wooldridge, Vorsitzender des IJCAI Awards Committee. "Was IJCAI besonders beeindruckte, war, dass AlphaGo das erreicht, was es durch eine brillante Kombination von klassischen KI-Techniken sowie die modernsten maschinellen Lerntechniken, mit denen DeepMind so eng verbunden ist, macht. Es ist eine atemberaubende Demonstration der zeitgenössischen KI, und wir freuen uns, sie mit dieser Auszeichnung erkennen zu können." Go community Go ist ein beliebtes Spiel in China, Japan und Korea, und die 2016 Spiele wurden von vielleicht hundert Millionen Menschen weltweit beobachtet. Viele Top Go-Spieler charakterisiert AlphaGo's unorthodoxe spielt wie scheinbar fragwürdige Bewegungen, die zunächst auf Plünderungen gefesselt, aber im Hindsight Sinn gemacht: "Alle aber die besten Go-Spieler Handwerk ihre Stil durch Nachahmung Top-Spieler. AlphaGo scheint völlig originelle Bewegungen zu haben, die es selbst schafft." AlphaGo schien unerwartet viel stärker geworden zu sein, auch wenn im Vergleich zu seiner Oktober 2015 Spiel wo ein Computer hatte ein Go-Profi zum ersten Mal jemals ohne den Vorteil einer Handicap geschlagen. Am Tag nach Lees erster Niederlage sagte Jeong Ahram, der führende Korrespondent für eine der größten Tageszeitungen Südkoreas, "die letzte Nacht war sehr düster...Viele Menschen tranken Alkohol." Die Korea Baduk Association, die Organisation, die überwacht Gehen Sie Profis in Südkorea, vergeben AlphaGo einen Ehrentitel für 9-dan, um kreative Fähigkeiten zu zeigen und den Fortschritt des Spiels voranzutreiben. Chinas Ke Jie, ein 18-Jähriger, allgemein als die weltbeste anerkannt Go-Spieler zu der Zeit, zunächst behauptet, dass er in der Lage sein würde, AlphaGo zu schlagen, aber abgelehnt, gegen sie zu spielen, aus Angst, dass es "kopieren meinen Stil". Als die Spiele weitergingen, ging Ke Jie hin und her und sagte, dass "es sehr wahrscheinlich ist, dass ich (könnte) verlieren" nach der Analyse der ersten drei Spiele, aber wieder Vertrauen nach AlphaGo zeigt Fehler im vierten Spiel. Toby Manning, der Schiedsrichter von AlphaGo's Spiel gegen Fan Hui, und Hajin Lee, Generalsekretär der International Go Federation, beide Grund, dass in der Zukunft, Go-Spieler erhalten Hilfe von Computern zu lernen, was sie falsch gemacht in Spielen und verbessern ihre Fähigkeiten. Nach Spiel zwei, Lee sagte, er fühlte sich sprachlos: "Von Anfang des Spiels konnte ich nie eine Oberhand für einen einzigen Schritt verwalten. Es war AlphaGos Gesamtsieg. "Lee entschuldigte sich für seine Verluste, nach Spiel drei, dass "Ich habe die Fähigkeiten von AlphaGo missachtet und fühlte machtlos. "Er betonte, dass die Niederlage "Lee Se-dols Niederlage" und "nicht eine Niederlage der Menschheit". Lee sagte, sein eventueller Verlust an eine Maschine sei unvermeidlich, aber sagte, "Roboter werden nie die Schönheit des Spiels verstehen, wie wir Menschen tun. " Lee nannte sein Spiel vier Sieg einen "preislosen Sieg, den ich (wollen für nichts austauschen." Ähnliche Systeme Facebook hat auch an seinem eigenen Go-Playing-System Darkforest gearbeitet, auch auf der Kombination von maschinellem Lernen und Monte Carlo Baumsuche.Obwohl ein starker Spieler gegen anderen Computer Go Programme, Anfang 2016, hatte es noch nicht besiegt einen professionellen menschlichen Spieler. Darkforest hat zu CrazyStone und Zen verloren und wird geschätzt, um von ähnlicher Stärke zu CrazyStone und Zen.DeepZenGo, ein System entwickelt mit Unterstützung von Video-Sharing-Website Dwango und der Universität Tokio, verloren 2–1 im November 2016 zu Go master Cho Chikun, die den Rekord für die größte Anzahl von Go Titel gewinnt in Japan. Als Grundlage für eine neue Methode zur Berechnung potenzieller pharmazeutischer Arzneimittelmoleküle nannte ein 2018 in Nature veröffentlichtes Papier AlphaGo. Beispielspiel AlphaGo Master (weiß) v.Tang Weixing (31. Dezember 2016), Alpha Gehen Sie durch Rücktritt gewonnen. Weiß 36 wurde weit gelobt. Die Auswirkungen auf Go Der AlphaGo Dokumentarfilm erhob Hoffnungen, dass Lee Sedol und Fan Hui von ihrer Erfahrung im AlphaGo-Spiel profitiert hätten, aber ab Mai 2018 wurden ihre Bewertungen wenig verändert; Lee Sedol wurde auf Platz 11 der Welt und Fan Hui 545. Am 19. November 2019 kündigte Lee seinen Ruhestand aus dem professionellen Spiel an und argumentierte, dass er aufgrund der zunehmenden Dominanz von AI niemals der Top-Gesamtspieler von Go sein könne. Lee bezeichnete sie als "eine Einheit, die nicht besiegt werden kann". Siehe auch Referenzen Externe Links Medien im Zusammenhang mit AlphaGo bei Wikimedia Commons Zitate im Zusammenhang mit AlphaGo bei Wikiquote Offizielle Website AlphaGo wiki in Sensei's Library, einschließlich Links zu AlphaGo-Spielen AlphaGo-Seite, mit Archiv und Spielen Geschätzt 2017 Bewertung von Alpha Go