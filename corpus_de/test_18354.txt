Ein Multicore-Verarbeiter ist ein Computer-Verarbeiter auf einem einzigen integrierten Schaltkreis mit zwei oder mehreren getrennten Verarbeitungseinheiten, die als Kern bezeichnet werden, von denen jeder die Programmanleitung gelesen und ausgeführt. Die Anweisungen sind gewöhnliche CPU-Anweisungen (wie Addition, Umzugsdaten und Zweigniederlassung), aber der einzige Prozessor kann gleichzeitig Anweisungen zu separaten Kernen durchführen, die die Gesamtgeschwindigkeit für Programme erhöhen, die mehrjährige oder andere parallele Rechentechniken unterstützen. Hersteller integrieren in der Regel die Kerne auf ein integriertes Schaltkreis (bekannt als Chip Multiprozessor oder CMP) oder auf mehrere Diäten in einem einzigen Chippaket. Die derzeit in fast allen persönlichen Computern verwendeten Mikroprozessoren sind Multicore. Ein Multi-core-Verarbeiter führt die Multi-Verarbeitung in einem einzigen physischen Paket durch. Designer können in einem Multi-core-Gerät eng oder locker sein. Kerne können oder können sich beispielsweise nicht über die Klärchen austauschen, und sie können die Kommunikation zwischen Kernen übertragen oder gemeinsam nutzen. Gemeinsame Netztopologien, die für die Verbindungskerne verwendet werden, umfassen Bus, Ring, zweidimensionale Maschen und Kreuzbar. Homogene Multicore-Systeme umfassen nur identische Kerne; heterogene Multicore-Systeme verfügen über Kerne, die nicht identisch sind (z.B. groß). LITTLE hat heterogene Kerne, die die gleiche Anleitung besitzen, während AMD beschleunigte Verarbeitungseinheiten Kerne haben, die die gleiche Anleitung nicht teilen. Genau wie bei Einzelprozessorensystemen können Kerne in Multicore-Systemen Architekturen wie VLIW, Superscalar, Vektor oder Multithreading umsetzen. Multi-core-Verarbeiter werden in vielen Anwendungsbereichen weit verbreitet, darunter allgemeine Nutzung, eingebettet, Netz, digitale Signalverarbeitung (DSP) und Grafik (GPU). Kern zählen zu sogar Dutzenden, und für Spezialchips über 10 000 und in Supercomputern (d. h. Chipcluster) kann die Zählung über 10 Millionen gehen. Die Verbesserung der Leistung, die durch die Verwendung eines Multi-core-Verarbeiters erzielt wird, hängt sehr stark von den verwendeten Software-Algorithmen und ihrer Umsetzung ab. Insbesondere sind mögliche Gewinne durch den Bruchteil der Software begrenzt, der parallel zu mehreren Kernen betrieben werden kann; dieser Effekt wird durch das Gesetz von Amdahl beschrieben. Im besten Fall können so genannte peinlich parallele Probleme Geschwindigkeiten in der Nähe der Anzahl der Kerne auftreten, oder sogar noch mehr, wenn das Problem so aufgeteilt ist, dass es innerhalb der K(en) des Kerns passt, so dass die Nutzung viel langsamerer primärer Systemspeicher vermieden wird. Die meisten Anwendungen werden jedoch nicht so viel beschleunigt, es sei denn, die Programmteilnehmer investieren eine verbietbare Menge an Anstrengungen zur Wiederherstellung des gesamten Problems. Parallelisierung der Software ist ein wichtiges Thema der Forschung. Kointegration von Multiprozessor-Anwendungen bietet Flexibilität bei der Gestaltung der Netzarchitektur. Anpassungsfähigkeit innerhalb paralleler Modelle ist ein weiteres Merkmal der Systeme, die diese Protokolle verwenden. Terminologie Multi-core und Dual-core beziehen sich am häufigsten auf eine Art zentrale Verarbeitungseinheit (CPU), werden aber manchmal auch auf digitale Signalverarbeiter (DSP) und System auf einem Chip (SoC) angewendet. Die Begriffe werden in der Regel nur für Multi-core-Mikroprozessoren verwendet, die in der gleichen integrierten Schaltkreise hergestellt werden; separate Mikroprozessor-Diagnose im gleichen Paket werden in der Regel durch einen anderen Namen wie das Multi-Chip-Modul bezeichnet. In diesem Artikel werden die Bedingungen multi-core und Dual-core für CPUs verwendet, die auf demselben integrierten Schaltkreis hergestellt werden, es sei denn, anders. Im Gegensatz zu Multi-core-Systemen bezieht sich der Begriff Multi-CPU auf mehrere physisch getrennte Verarbeitungseinheiten (die häufig spezielle Schaltkreise enthalten, um die Kommunikation zwischen einander zu erleichtern). Viele Kern- und massive Multicore-Bedingungen werden manchmal verwendet, um Multi-core-Architekturen mit einer besonders hohen Anzahl von Kernen (höchstens tausende) zu beschreiben. Manche Systeme verwenden viele weichen Mikroprozessorkerne, die auf einem einzigen RPGA platziert werden. Jeder Kern kann als "Semiconduktor intellektuelles Eigentum" sowie als CPUkern betrachtet werden. Entwicklung Obwohl die Fertigungstechnik verbessert, die Größe der einzelnen Tore verringert, werden die physischen Grenzen der Halbleiter-Mikroelektronik zu einem wichtigen Designanliegen geworden. Diese physischen Grenzen können zu erheblichen Problemen bei der Hitzeverarmung und Datensynchronisierung führen. Verschiedene andere Methoden werden zur Verbesserung der Leistungsfähigkeit der CPU verwendet. Manche Anweisungslehrmethoden (ILP) wie Superscalar Pipelining sind für viele Anwendungen geeignet, sind aber für andere, die einen schwierigen Code enthalten, ineffizient. Viele Anwendungen sind besser geeignet, um Parallelismus (TLP)-Methoden auf Gewindeebene einzuführen, und mehrere unabhängige CPUs werden häufig verwendet, um das System insgesamt zu erhöhen. Eine Kombination aus erhöhter verfügbarem Raum (due to raffinierte Fertigungsabläufe) und der Nachfrage nach mehr TLP führten zur Entwicklung von Multicore-Prozessoren. Kommerzielle Anreize mehrere Geschäftsmotiven fördern die Entwicklung von Multi-core-Architekturen. Jahrzehntelang war es möglich, die Leistung einer CPU zu verbessern, indem der Bereich des integrierten Schaltkreises (IC) verringert wurde, der die Kosten pro Gerät auf der IC verringerte. Alternativ könnten für denselben Kreislaufbereich mehr Transistoren in das Design verwendet werden, das die Funktionalität erhöht, insbesondere für komplexe Unterrichtsformen (CISC)-Architekturen. In den Jahrzehnten des späten zwanzigsten Jahrhunderts stiegen die Preise auch um die Größenordnung von mehreren Megahertz in den 80er Jahren auf mehrere Gigaertz in den frühen 2000er Jahren. Da sich die Geschwindigkeitsverbesserungen verlangsamten, wurde eine verstärkte Verwendung von Parallel-. in Form von Multicore-Verarbeitern angestrebt, um die Gesamtleistung der Verarbeitung zu verbessern. Mehr Kerne wurden auf dem gleichen CPU-Chip verwendet, was wiederum zu einem besseren Vertrieb von CPU-Chips mit zwei oder mehr Kernen führen könnte. Intel hat beispielsweise einen 48-core-Verarbeiter für die Forschung im Cloud Computing produziert; jeder Kern hat eine x86 Architektur. Technische Faktoren Da Computerhersteller seit langem symmetrische Multi-Verarbeitung (SMP)-Designer mit getrennten CPUs umgesetzt haben, sind die Fragen im Zusammenhang mit der Umsetzung der Multicore-Verarbeitungsarchitektur und der Unterstützung durch Software bekannt. Zusätzlich: Mit einem bewährten Design ohne architektonische Veränderungen verringert sich das Designrisiko erheblich. Für die Allgemeinzweckverarbeiter kommt viel der Motivation für Multi-core-Verarbeitung zu einer deutlich rückläufigen Leistung der Verarbeiter bei der Erhöhung der Betriebsfrequenz. Dies ist auf drei Faktoren zurückzuführen: Gedächtnismauer; zunehmende Kluft zwischen Prozessor und Speichergeschwindigkeiten. Man drängt auf eine größere Größe der Klärgrößen, um die späte Erinnerung zu verschleiern. Nur in dem Maße, in dem die Speicherbreite nicht die Leistungsengpässe ist. ILP Wand; die zunehmende Schwierigkeit, genügend Parallelismus in einem einzigen Anleitungsstrom zu finden, um einen leistungsfähigen einzigen Prozessor zu halten. Kraftwand; der Trend des exponentiellen Anstiegs der Kraft (und damit auch die exponentielle Erhöhung der Wärme) mit jeder faktoriellen Erhöhung der Betriebsfrequenz. Dieser Anstieg lässt sich durch die Verringerung des Prozessors verringern, indem kleinere Spuren für dieselbe Logik verwendet werden. Die Stromwand stellt Produktions-, Systemdesign- und Einsatzprobleme dar, die angesichts der rückläufigen Leistungsgewinne aufgrund der Gedächtniswand und der ILP-Baumauer nicht gerechtfertigt sind. Um weiterhin regelmäßige Leistungsverbesserungen für allgemein-zweckgebundene Prozessoren durchzuführen, haben sich Hersteller wie Intel und AMD zu Multicore-Designern entwickelt, die niedrigeren Produktionskosten für höhere Leistung in einigen Anwendungen und Systemen opfern. Multi-core-Architekturen werden entwickelt, aber so sind die Alternativen. Ein besonders starker Anhänger für etablierte Märkte ist die weitere Integration von Peripheriefunktionen in den Chip. Vorteile Die Nähe von mehreren CPUkernen derselben Ernährung ermöglicht es der CO2-Kohäsionskreise, mit einer viel höheren Taktgeschwindigkeit zu arbeiten, als was möglich ist, wenn die Signale außerhalb des Chips reisen müssen. Kombination einer gleichwertigen Kombination CPUs auf einer einzigen Diät verbessern die Leistung von snoop (alternative: Bus snooping). Kurz gesagt, dies bedeutet, dass die Signale zwischen verschiedenen CPUs mit kürzeren Entfernungen und damit die Signale weniger abbauen. Mehr Daten, die in einer bestimmten Zeit zu übermitteln sind, können diese höherwertigen Signale kürzer sein und müssen nicht wiederholt werden. Annahme, dass die Ernährung physisch in das Paket passen kann, erfordern Multi-core-Prozessoren viel weniger Druckplatten (PCB) als Multi-Chip-SMP-Designer. Ein Zwei-Kern-Verarbeiter nutzt auch etwas weniger Strom als zwei gekoppelte Ein-Kern-Verarbeiter, vor allem wegen der geringeren Leistung, die erforderlich ist, um Signale außerhalb des Chips zu transportieren. Darüber hinaus teilen die Kerne einige Schaltkreise wie L2 Cache und die Schnittstelle zum Front-Bus (FSB). Multi-core-Design kann in Bezug auf konkurrierende Technologien für das verfügbare Silicium-Lebensgebiet die nachgewiesenen CPU-Grundbibliotheken verwenden und ein Produkt mit einem geringeren Risiko von Designfehlern erzeugen als ein neues, umfassenderes Design. Hinzu kommt, dass mehr Cache von einer rückläufigen Rendite betroffen ist. Multicore Chips ermöglichen auch höhere Leistung bei niedrigerer Energie. Dies kann ein wichtiger Faktor für mobile Geräte sein, die auf Batterien arbeiten. Da jedes Kernstück in einer Multi-core-Prozessor-Architektur in der Regel energieeffizienter ist, wird der Chip effizienter als ein einziger groß angelegter monolithischer Kern. Dies ermöglicht eine höhere Leistung mit weniger Energie. Eine Herausforderung in diesem Zusammenhang ist jedoch die zusätzliche Überbuchung des Parallelcodes. Nachteile Maximierung der Nutzung der von Multi-core-Verarbeitern bereitgestellten Rechenressourcen erfordert Anpassungen sowohl an die Unterstützung des Betriebssystems (OS) als auch an die bestehende Software. Darüber hinaus hängt die Fähigkeit von Multi-core-Verarbeitern zur Erhöhung der Anwendungsleistung von der Verwendung von mehreren Gewinden innerhalb von Anwendungen ab. Integration eines Multi-core-Chips kann die Erträge aus der Chipherstellung senken. Sie sind auch schwieriger, thermischer als weniger schwer zu verwalten. Intel hat dieses erste Problem teilweise bekämpft, indem es seine vier-core-Designer durch die Kombination zweier Zwei-Kern auf einer einzigen Ernährung mit einem einheitlichen Cache zusammenbringt, so dass alle zwei Doppel-Kerne verwendet werden können, anstatt vier Kerne auf einer einzigen Ernährung zu produzieren und alle vier zu arbeiten, um eine vier-Kern-Prozessor zu produzieren. Letztlich können einzelne CPU-Designer eine bessere Nutzung der Siliciumoberflächenfläche als Multiverarbeitungskerne bewirken, so dass ein Entwicklungsengagement für diese Architektur das Risiko von Obsoleszenz birgt. Letztlich ist die Rohverarbeitungsleistung nicht der einzige Druck auf die Systemleistung. Zwei Verarbeitungskerne, die denselben Systembus- und Speicherbreiten teilen, beschränken den wirklichen Leistungsvorteil. In einem Bericht von 2009, Dr. Ni zeigte, dass, wenn ein einziger Kern in der Nähe von Speicherbandbreiten begrenzt ist, dann in Doppelkern 30 % bis 70 % verbessern könnte; wenn die Speicherbreite kein Problem ist, dann ist eine Verbesserung um 90 % zu erwarten; allerdings ist das Gesetz von Amdahl zweifelhaft. Für eine Anwendung, die zwei CPUs benutzte, um den Betrieb schneller auf einem einzigen Kern zu beenden, wenn die Kommunikation zwischen den CPUs der Begrenzungsfaktor war, der sich auf über 100 % erhöhen würde. Hardware Trends Die Entwicklung des Verarbeiters hat zu einer immer stärkeren Zahl von Kernen geführt, da Prozessoren mit Hunderten oder sogar Tausenden von Kernen theoretisch möglich werden. Multi-core-Chips mit gleichzeitiger Multithreading, Memory-on-Chip und speziellen heterogenen (oder asymmetrischen) Kernen versprechen weitere Leistung und Effizienzsteigerungen, insbesondere bei der Verarbeitung von Multimedia-, Anerkennungs- und Vernetzungsanwendungen. z.B. ein Großteil. LITTLE Kern umfasst einen leistungsstarken Kern (genannte große) und einen Low-power- Kern (wie LITTLE). Es gibt auch einen Trend zur Verbesserung der Energieeffizienz, indem sie sich auf leistungs-per-watt mit fortgeschrittenem Fein- oder ultra-Bluminium-Strommanagement und dynamischer Spannungs- und Frequenzskalation (d. h. Laptop-Computer und tragbare Medien) konzentrieren. Chips, die von Anfang an für eine große Anzahl von Kernen entwickelt wurden (und nicht aus einheitlichen Kernmodellen entwickelt wurden) werden manchmal als viele Kern-Designer bezeichnet, wobei qualitative Unterschiede hervorgehoben werden. Architektur Zusammensetzung und Gleichgewicht der Kerne in der Multi-core-Architektur zeigen große Vielfalt. Manche Architekturen verwenden ein Kerndesign konsequent (homogen), während andere eine Mischung verschiedener Kerne verwenden, die jeweils für eine andere, heterogene Rolle optimiert werden. Wie mehrere Kerne umgesetzt und integriert werden, beeinträchtigen sowohl die Programmierfähigkeiten des Entwicklers als auch die Erwartungen der Verbraucher an Apps und Interaktivität gegenüber dem Gerät. Ein als Octa-core beworbenes Gerät wird nur unabhängige Kerne haben, wenn es als echtes Octa-core oder ähnliches Styling beworben wird, anstatt nur zwei Sätze von vier Kernen mit festen Geschwindigkeiten zu sein. Der Artikel "CPU Designer diskutieren Multicore Future" von Rick Merritt, EE Times 2008, enthält diese Kommentare: Chuck Moore [...] vorgeschlagene Computer sollten wie Cellphones sein, wobei eine Vielzahl von Spezialkernen verwendet werden sollten, um modulare Software zu betreiben, die von einer hochrangig besetzten Anwendungsplanungsschnittstelle vorgesehen ist. Atsushi Hasegawa, ein Senior-Ingenieur in Erneuerungsas, wurde allgemein vereinbart. Er schlug vor, dass die Nutzung vieler Spezialkerne, die im Konzert arbeiten, ein gutes Modell für künftige Multicore-Designs ist. [...] Anant Agarwal, Gründer und Chief Executive of Startup Fliesenra nahmen die opposing view. Er sagte, Multi-core-Chips müssen homogene Sammlungen von allgemeinen Zweckkernen sein, um das Softwaremodell einfach zu halten. Softwareeffekte Eine überholte Version eines Anti-Virus-App kann einen neuen Faden für einen Scanprozess schaffen, während der Leitfäden des Benutzers (z.B. die Rücknahme) abwarten. In solchen Fällen ist eine Multi-core-Architektur von geringem Nutzen für die Anwendung selbst, weil der einzelne Faden, der alle schweren Heben und die Unfähigkeit, die Arbeit gleichmäßig über mehrere Kernbereiche hinweg abzuwägen. Programmierung wirklich multithreadierter Code erfordert häufig eine komplexe Koordination von Gewinden und kann durch die Verwechslung von Daten, die zwischen den Fadenn geteilt werden, leicht und schwierige Nachprüfungsfehler leicht einführen (siehe Gewindesicherheit). Infolgedessen ist ein solcher Kodex viel schwieriger zu debug als ein einheitlicher Code, wenn er Pausen. In Anbetracht der relativen Seltenheit der Verbrauchernachfrage für den maximalen Einsatz von Computer-Hardware wurde ein Mangel an Motivation für verbraucherorientierte Anwendungen wahrgenommen. Kodierte Aufgaben wie die Entschlüsselung der entropy-Kodizes, die in Videocodes verwendet werden, sind auch nicht möglich, parallel zu wirken, da jedes Ergebnis verwendet wird, um das nächste Ergebnis des entropy decodes zu schaffen. Angesichts des zunehmenden Schwerpunkts auf der Multi-core-Chip-Design, das sich aus den schweren Wärme- und Stromverbrauchsproblemen ergibt, die durch eine weitere signifikante Zunahme der Prozessor-Geschwindigkeiten verursacht werden, dürfte das Ausmaß, in dem die Software multipliziert werden kann, um diese neuen Chips zu nutzen, wahrscheinlich der größte Druck auf die Computerleistung in Zukunft sein. Wenn Entwickler nicht in der Lage sind, Software zu entwerfen, um die von mehreren Kernen bereitgestellten Ressourcen vollständig zu nutzen, dann werden sie letztlich eine unüberwindbare Leistungsobergrenze erreichen. Der Telekommunikationsmarkt war eines der ersten, die ein neues Design paralleler Datenpath-Paketverarbeitung brauchten, weil diese Multicore-Verarbeiter für die Datenpathie und das Kontrollflugzeug sehr schnell angenommen wurden. Diese MPUs werden die traditionellen Netzwerk-Verarbeiter ersetzen, die auf Eigen-Mikrocode oder Piocode basieren. Parallele Programmierungstechniken können von mehreren Kernen direkt profitieren. Manche parallele Programmierungsmodelle wie Cilk Plus, OpenMP, OpenHMPP, FastFlow, Skandium, MPI und Erlang können auf Multi-core-Plattformen verwendet werden. Intel hat eine neue abstraktion für C+ Parallelismus namens TBB eingeführt. Weitere Forschungsanstrengungen umfassen den Codeplay Sieve System, die Cray-Schulung, die Sun-Brücke und die IBM-X10. Multi-core-Verarbeitung hat auch die Fähigkeit der modernen Entwicklung von Rechensoftware beeinträchtigt. Entwickler-Programmierung in neueren Sprachen könnten finden, dass ihre modernen Sprachen keine Multicore-Funktionen unterstützen. Danach müssen numerische Bibliotheken in Sprachen wie C und Fortran, die Mathematikberechnungen schneller als neuere Sprachen wie C#.Intels MKL und AMD's ACML durchführen, in diesen Muttersprachen geschrieben und die Multi-core-Verarbeitung nutzen. Überbrückung der Antragsbelastung durch die Verarbeiter kann problematisch sein, insbesondere wenn sie unterschiedliche Leistungsmerkmale aufweisen. Es gibt verschiedene konzeptuelle Modelle zum Umgang mit dem Problem, z.B. mit einer Koordinierungssprache und programmatischen Bausteinen (Programmierung von Bibliotheken oder höheren Funktionen). Jeder Block kann eine andere einheimische Umsetzung für jede Prozessorart haben. Nutzer wählen einfach die Nutzung dieser abstrakten Anwendungen und ein intelligenter Mitarbeiter die beste Umsetzung auf der Grundlage des Kontextes. Verwaltung von Währungen übernimmt bei der Entwicklung paralleler Anwendungen eine zentrale Rolle. Die grundlegenden Schritte bei der Konzeption paralleler Anwendungen sind: Trennwand Die Trennphase eines Entwurfs zielt darauf ab, Möglichkeiten für Parallelausführung zu eröffnen. In diesem Zusammenhang liegt der Schwerpunkt auf der Festlegung einer großen Anzahl kleiner Aufgaben, um zu erwirtschaften, was als verhängungshemmendes Problem bezeichnet wird. Kommunikation Die durch eine Teilung entstandenen Aufgaben dienen der laufenden Ausführung, können aber im Allgemeinen nicht unabhängig ausführen. Die in einer Aufgabe durchzuführende Berechnung erfordert in der Regel Daten, die mit einer anderen Aufgabe verbunden sind. Daten müssen dann zwischen den Aufgaben übertragen werden, um die Berechnung zu ermöglichen. Dieser Informationsfluss ist in der Kommunikationsphase eines Entwurfs angegeben. Agglomeration In der dritten Phase bewegt sich die Entwicklung von der abstrakten auf das Beton. Entwickler, die in den Trenn- und Kommunikationsphasen getroffen werden, um einen Algorithmus zu erhalten, der effizient auf einigen Klassen paralleler Computer ausgeführt wird. Insbesondere sind die Entwickler der Meinung, ob es sinnvoll ist, die in der Teilungsphase ermittelten Aufgaben zu kombinieren oder zu agglomerate, um eine geringere Anzahl von Aufgaben, die je größer sind. Sie bestimmen auch, ob es sinnvoll ist, Daten und Berechnung zu replizieren. Kartografie In der vierten und letzten Phase der Konzeption paralleler Algorithmen legen die Entwickler fest, wo jede Aufgabe auszuführen ist. Dieses Kartierungsproblem entsteht nicht bei uniprozessoren oder auf gemeinsamen Computern, die automatische Aufgabenplanung anbieten. Andererseits sind Multicore-Verarbeiter auf der Serverseite ideal, weil sie es vielen Nutzern ermöglichen, sich gleichzeitig an eine Website zu verbinden und unabhängige Rollen zu haben. Hierdurch können Web-Server und Anwendungsserver, die viel besseren Durchsatz haben, genutzt werden. Lizenzanbieter können einige Software "per Prozessor"lizenzieren. Dies kann zu Unklarheit führen, weil ein Verarbeiter entweder aus einem einzigen Kern oder einer Kombination von Kernen bestehen kann. Anfangs nutzte Microsoft für einige seiner Unternehmenssoftware ein System zur Erteilung von Lizenzen für Per-Socket. Jedoch hat Microsoft für einige Software wie BizSoft Server 2013 SQL Server 2014 und Windows Server 2016 auf per-core-Lizenzen verlagert. Oracle Corporation zählt AMD X2 oder Intel Dual-core CPU als einziger Prozessor, nutzt aber andere Parameter für andere Arten, insbesondere für Prozessoren mit mehr als zwei Kernbereichen. Horizontale Anwendungen Embedded Computing ist in einem Bereich der Prozessortechnik tätig, der sich von dem der Mainstream-PCs unterscheidet. In diesem Zusammenhang gelten auch dieselben technologischen Antriebe für Multicore. In vielen Fällen ist die Anwendung ein natürlicher Bestandteil für Multicore-Technologien, wenn die Aufgabe zwischen den verschiedenen Verarbeitern leicht aufgeteilt werden kann. Darüber hinaus werden eingebettete Software in der Regel für eine spezielle Hardware- Freisetzung entwickelt, die Fragen der Softwareübertragbarkeit, des Altcodes oder der Unterstützung unabhängiger Entwickler weniger kritisch macht als der Fall für PC oder Unternehmen.Infolgedessen ist es für Entwickler einfacher, neue Technologien zu übernehmen und dadurch eine größere Vielfalt an Multicore-Verarbeitungsarchitekturen und Lieferanten zu schaffen. Netzverarbeiter Seit 2010 sind Multi-core-Netzverarbeiter mit Unternehmen wie Freescale Semiconductor, Cavium Networks, Wintegra und Broadcom alle Herstellungsprodukte mit acht Prozessoren. Für den Systementwickler besteht eine zentrale Herausforderung darin, alle Kerne dieser Geräte zu nutzen, um eine maximale Vernetzungsleistung auf der Systemebene zu erreichen, trotz der Leistungsbegrenzungen, die in einem symmetrischen Mehrverarbeitungssystem (SMP) enthalten sind. Unternehmen wie 6WIND bieten eine tragbare Paketverarbeitungssoftware an, die so ausgelegt ist, dass das Netzwerkdatenflugzeug in einem schnellen Umfeld außerhalb des Betriebssystems des Netzwerks läuft. digitale Signalverarbeitung In der digitalen Signalverarbeitung gilt derselbe Trend: Texas Instruments verfügt über die drei wichtigsten TMS320C6488 und vier Kern-TMS320C5441, Freier Maßstab der vier Kern- MSC8144 und 6-core MSC8156 (und beide haben erklärt, sie arbeiten an acht Kern-Nachfolgern). Neue Einträge umfassen die Sturm-1-Familie von Stream Prozessoren, Inc mit 40 und 80 allgemeinem Zweck ALUs pro Chip, alle programmierbar in C als SIMD-Motor und PicoChip mit dreihunderttausenden Prozessoren auf einer einzigen Ernährung, die sich auf Kommunikationsanwendungen konzentriert. Heterogene Systeme In heterogener Rechen, wo ein System mehr als eine Art von Prozessoren oder Kernen verwendet, werden Multicore-Lösungen immer häufiger: Xilinx Zynq UltraScale+ MPSoC verfügt über ein Vierkern ARM Cortex-A53 und Dual-core ARM Cortex-R5. Software-Lösungen wie OpenAMP werden genutzt, um mit interprozessorer Kommunikation zu helfen. Mobile Geräte können die ARM-Groß verwenden. LITTLE Architektur. Hardware-Beispiele kommerzielle Anpassungeva Epiphany, eine vielkerne Prozessorarchitektur, die bis zu 4096 Prozessoren auf-Chip ermöglicht, obwohl nur eine 16 Kernversion kommerziell produziert wurde. Aeroflex Gaisler LEON3, ein Multi-core SPARC, der auch in einer schuldversprechenden Version existiert. Ageia PhysX, eine Multi-core-physik-Verarbeitungseinheit. Ambric Am2045, ein 336-corely Parallelprozessor Array (MPPA)AMD A-Serien, Doppel-, Triple-,- und Vierkern beschleunigter Prozessoreinheiten (APU). Athlon 64 FX und Athlon 64 X2 Single- und Dual-core-Prozessoren. Athlon II, Dual-, Triple-,- und Vierkern-Chip-Verarbeiter. FX-Serien, vier-,6- und 8-core-Desktop-Verarbeiter. Opteron, Einzel-, Vier-,6 8,- 12,- und 16-core Server/Workstation Prozessoren. Phenom, Doppel-, Triple-,- und Vierkern-Verarbeiter. Phenom II, Dual,- Triple,-Quad,- und 6-core Desktop-Verarbeiter. Sempron, Einzel-, Doppel-,- und Vierkern-Zugänge. Turion, Single- und Dual-core Laptop-Verarbeiter. Ryzen, Dual,-vier,- 6,- 8,- 12,- 16,- 24,- 32,- und 64-core Desktop, mobile und eingebettete Plattformverarbeiter. Epyc, vier,- 8,- 12,- 16,- 24,- 32,- und 64-core Server und eingebettete Prozessoren. Motorroller und FeuerStream Multi-core CPU/GPGPU (10 Kerne, 16 5-issue breite Superscalar-Verarbeiter pro Kern). Analog Devices Blackfin BF561, ein symmetrischer Dual-core-Verarbeiter ARMcore MPcore ist ein vollständig komplexes Multi-core-Container für ARM11 MPcore und ARM Cortex-A9 MP Cores, das für hochleistungsfähige eingebettete und Unterhaltungsanwendungen bestimmt ist. ASOCS ModemX, bis zu 128 Kerne, drahtlose Anwendungen. Prat Systems Vega 1, ein 24-core-Verarbeiter, der 2005 veröffentlicht wurde. Vega 2, ein 48-core-Verarbeiter, der 2006 veröffentlicht wurde. Vega 3, ein 54-core-Verarbeiter, wurde 2008 veröffentlicht. Broadcom Sibyte SB1250, SB1255, SB1455; BCM 2836 Vier-core ARM SoC (für die Raspberry Pi 2) Cadence Design Systems TensilicaXtensa LX6, verfügbar in einer Dual-core-Konformität in Espressif Systems ESP32 ClearSpeed CGT700, 192-core-Verarbeiter, der 2008 veröffentlicht wurde (32/64-bit/s; Integer ALU). Filmtechnik CT3400 und CT3600, beide Multicore-Anbieter. Cavium Networks Octeon, ein 32-core MIPS MPU. Coherent Logix hx3100 Prozessor, ein 100-Kern-/GPP-Verarbeiter. Freescale Semiconductor QorIQ-Reihenverarbeiter bis zu 8 Kerne, Power ISA MPU.3,00-Packard PA-8800 und PA-8900, zwei Kern- PA-RISC-Verarbeiter. IBM POWER4, ein Dual-core PowerPC-Verarbeiter, der 2001 veröffentlicht wurde. FRA5, ein Dual-core PowerPC-Verarbeiter, der 2004 veröffentlicht wurde. FRA6, ein Dual-core PowerPC-Verarbeiter, der 2007 veröffentlicht wurde. AIR7, ein 4,6,8-core PowerPC-Verarbeiter, der 2010 veröffentlicht wurde. FRA8, ein 12-core PowerPC-Verarbeiter, wurde 2013 veröffentlicht. FRA9, ein 12- oder 24-core PowerPC-Verarbeiter, veröffentlicht im Jahr 2017 FRA10, ein 15 oder 30-core PowerPC-Verarbeiter, der im Jahr 2020 freigegeben wurde.PowerPC 970MP, ein Dual-core PowerPC-Verarbeiter, der im Apple Power Mac G5 verwendet wird. Xenon, ein Triple-core, SMT-fähig, PowerPC-Mikroprozessor in der Microsoft-Spielkonsole 360.z10, ein Vierkern-Z/Architecture-Verarbeiter, veröffentlicht 2008z196, ein Vierkern-Z/Architecture-Verarbeiter, der im Jahr 2010 veröffentlicht wurde. EC12, ein sechs-core-Z/Architecture-Verarbeiter, der im Jahr 2012 veröffentlicht wurde, ein Achtkern-Z/Architecture-Verarbeiter, der im Jahr 2015 veröffentlicht wurde. Infineon AURIX Donau, ein Dual-core, MIPS-basierter, Home Gateway-Verarbeiter. Intel Atom, Single, Dual-core, Vierkern, 8,- 12,- und 16-core-Verarbeiter für Netbooks, Netops, eingebettete Anwendungen und mobile Internetgeräte (MIDs). Atom SoC (System auf einem Chip), Single-core, Dual-core und Vierkern-Verarbeiter für Smartphones und Tablets. Celeron, der erste Dual-core (und später vier-Kern)-Verarbeiter für den haushalts-/entry-Markt. Core Duo, ein Dual-core-Verarbeiter. Kern 2 Duo, ein Dual-core-Verarbeiter. Kern 2 Quad, 2 Dual-core-Lebene in einem Multi-Chip-Modul verpackt. Core i3, Core i5, Core i7 und Core i9, eine Familie von Dual,- Vier-,6 8-,10-,12 14,- 16,- und 18-core-Verarbeitern, und der Nachfolger von Core 2 Duo und Core 2 Quad. Itanium, Single, Dual-core, Vierkern und 8-core-Verarbeiter. Generatoren, Einzel-, Doppel- und Vierkern-Verarbeiter für den Markteintritt. Teraflos Research Chip (Polaris), ein 3,16 GHz, 80-core-Verarbeiter- Prototyp, der das ursprünglich angemeldete Unternehmen 2011 veröffentlichen würde. Latex Dual,-vier,6 8-,10-,12 14-,15 16,- 18,- 20,- 22,- 24,- 26,- 28,- 32,- 48,- und 56-core-Verarbeiter. Weiß Phi57-,60-,61-,64 68,- und 72-core-Verarbeiter. IntellaSys SEAforth 40C18, ein 40-core-Verarbeiter. SEAforth24, ein 24-core-Verarbeiter, der von Charles H. Moore entworfen wurde. Kalray MPPA-256, 256-core-Verarbeiter, veröffentlicht 2012 (256 Usable VLIW Kerns, Network-on-Chip (NoC), 32/64-bit-Max 754 konform FPU)Netic Microsystems XLP, ein 32-core-, Vier-Jahres-MIPS64.XLR, ein Acht-core-, Vier-thread-MIPS64-Verarbeiter. Armaturenbrett, ein Achtkern-, Vier-Jahres-MIPS64-Verarbeiter. KWK 9 Multi-core-Prozessoren (8 Kerne, 16 scalar Stream Prozessoren pro Kern). Motor 200 Multi-core-Prozessoren (10 Kerne, 24 scalar Stream Prozessoren pro Kern). Tesla Multi-core GPGPU (10 Kerne, 24 scalar rationeller Prozessoren pro Kern). RTX 3090 (10496 CUDA Kerns, GPGPU Kerns und andere spezialisierte Kerne). Parallax Propeller P8X32, ein acht-core-Mikro-Betreiber.picoChip PC200 Serie 200–300 Kerne pro Gerät für DSP & Wireless. Vielfalt HAL-Reihen eng miteinander verbunden 16-256 Kerne, L1 gemeinsamer Speicher, Hardware synchronisierter Prozessor. Rapport Kilocore KC256, ein 257-core-Mikro-Kontrolle mit einem PowerPC- Kern und 256 8-bit "Verarbeitungselemente". SiCortex "SiCortex node" hat sechs MIPS64 Kerne auf einem einzigen Chip. Sony/IBM/Toshiba's Cell Prozessor, ein neun-core-Verarbeiter mit einem allgemeinen Zweck PowerPC Kern und acht spezialisierten SPUs (Synergistic Processing Unit) optimiert für Vektoroperationen in der Sony-Software 3. Sun Microsystems MAJC 5200, zwei-core VLIW Prozessor. UltraSPARC IV und UltraSPARC IV,+ Dual-core-Verarbeiter. UltraSPARC T1, ein Achtkern, 32-thread Prozessor. UltraSPARC T2, ein acht-core-, 64-concurrent-thread-Verarbeiter. UltraSPARC T3, ein sechzehn-core, 128-concurrent-thread-Verarbeiter. SPARC T4, ein Achtkern, 64-concurrent-thread-Verarbeiter.SPARC T5, ein sechzehn-core, 128-concurrent-thread-Verarbeiter. Sunway Sunway SW26010, ein 260-core-Verarbeiter in der Sunway TaihuLight. Texas Instruments TMS320C80 MVP, ein fünf Kern-Multimedia-Video-Verarbeiter. TMS320TMS320C66, 2.4,8 Kerngeschäftskreis. Kennra TILE64, ein 64-core 32-bit-Verarbeiter. TILE-Gx, ein 72-core 64-bit-Verarbeiter. XMOS Software definiert Silikon Vier-Kernte XS1-G4. Free OpenSPARC Bachelor MIT, 16-core-Car-Verarbeiter University of California, Davis, asynchrone Bandbreite einfacher Prozessoren (AsAP) 36-core 610 MHz AsAP 167-core 1.2 GHz AsAP2 University of Washington, Wellencalar Prozessor University of Texas, Austin, TRIPS-Verarbeiter Linköping University, Schweden, ePUMA-Verarbeiter UC Davis, Kilocore, 1000 Kern 1,78 GHz für einen 32 nm IBM-Prozess Benchmarks Forschung und Entwicklung von Multicore-Verarbeitern vergleichen häufig viele Optionen und Benchmarks werden entwickelt, um solche Bewertungen zu unterstützen. Benchmarks umfassen SPLASH-2, PARSEC und COSMIC für heterogene Systeme. Siehe auch Hinweise ^ Digital Signalverarbeiter (DSPs) haben mehr Kernarchitekturen für viel länger als große allgemeine Zweckgesellschaften genutzt. Ein typisches Beispiel für eine DSP-spezifische Umsetzung wäre eine Kombination aus einer RISC-Prozessor und einer MPU. Dies ermöglicht die Gestaltung von Produkten, die einen allgemeinen Zweckverarbeiter für Benutzerschnittstellen und einen ISP für Echtzeit-Datenverarbeitung erfordern; diese Art von Design ist in Mobiltelefonen üblich. In anderen Anwendungen hat sich eine wachsende Zahl von Unternehmen mit sehr vielen Prozessoren entwickelt. Zwei Arten von Betriebssystemen sind in der Lage, einen Doppel-CPU-Multiprozessor zu verwenden: aufgeteilte Mehrverarbeitung und symmetrische Multiverarbeitung (SMP). In einer geteilten Architektur arbeiten alle CPUschuhe in getrennte Segmente des physischen Gedächtnisses und arbeiten unabhängig voneinander; in einem SMP OS arbeiten die Verarbeiter in einem gemeinsamen Raum, führen die Faden innerhalb des OS selbst aus. Verweise auf weitere Lesung Khondker S. Hasan, Nicolas G. Grounds, John K. Antonio (Juli 2011). Vorurteilende CPU Verfügbarkeit eines Multi-core-Vertriebs Java Threads.17. International Conference on Parallel and Distributed Processing Techniken and Applications (PDPTA-11). Las Vegas, Nevada, USA.pp.551–557.CS1 Hauptt: Verwendung von Autorenparametern (link) Khondker S. Hasan, John Antonio, Sridhar Radhakrishnan (Februar 2014). Modell für die Vorurteilung der Effizienz der Multicore-Verarbeitung. International Conference on High Performance Computerarchitektur (HPCA-14) Orlando, FL, USA. doi:10.13140/RG.2.1.3051.9207.CS1 Hauptt: verwendet Autorenparameter (link) Externe Links "Was ist ein Prozessor?" MakeUseOf "Behinderte Schritte zu Multicore" –Embedinged Computing Design "Multicore Is Bad News for Supercomputers" –IEEE-Frequenz Architecting-Lösungen für die vielecore Zukunft, veröffentlicht am 19. Februar 2010 (mehr als eine tote Verbindung in der Rückseite)