Beim maschinellen Lernen ist das Lern- oder Repräsentations-Erlernen eine Reihe von Techniken, die es einem System ermöglicht, automatisch die für die Merkmalserkennung oder Klassifizierung von Rohdaten erforderlichen Darstellungen zu erkennen. Dies ersetzt die manuelle Feature-Engineering und ermöglicht es einer Maschine, die Funktionen zu lernen und sie zu verwenden, um eine bestimmte Aufgabe auszuführen. Feature-Lernen wird durch die Tatsache motiviert, dass maschinelle Lernaufgaben wie Klassifizierung häufig Eingaben erfordern, die mathematisch und rechnerisch bequem zu verarbeiten sind. Allerdings haben Echtzeitdaten wie Bilder, Video- und Sensordaten nicht ergeben, um bestimmte Merkmale algorithmisch zu definieren. Eine Alternative besteht darin, solche Merkmale oder Darstellungen durch Prüfung zu entdecken, ohne sich auf explizite Algorithmen zu verlassen. Feature-Lernen kann entweder überwacht oder nicht überwacht werden. Im beaufsichtigten Feature-Lernen werden Funktionen mit markierten Eingabedaten erlernt. Beispiele sind beaufsichtigte neuronale Netze, Mehrschicht-Perceptron und (überwachtes) Wörterbuch-Erlernen. Beim ununterbrochenen Feature-Lernen werden Funktionen mit unmarkierten Eingabedaten erlernt. Beispiele sind Wörterbuchlernen, unabhängige Komponentenanalyse, Autoencoder, Matrix Factorization und verschiedene Formen der Clustering. Supervised Supervised Feature Learning ist das Lernen von Funktionen aus markierten Daten. Das Datenlabel ermöglicht es dem System, einen Fehlerterm zu berechnen, inwieweit das System das Etikett nicht produziert, was dann als Feedback zur Korrektur des Lernprozesses verwendet werden kann (Reduzieren/Minimieren des Fehlers). Zu den Ansätzen gehören: Das beaufsichtigte Wörterbuchlernen entwickelt aus den Eingabedaten einen Satz (diktiv) von repräsentativen Elementen, so dass jeder Datenpunkt als gewichtete Summe der repräsentativen Elemente dargestellt werden kann. Die Wörterbuchelemente und die Gewichte können durch Minimierung des mittleren Repräsentationsfehlers (über die Eingangsdaten) zusammen mit L1 Regulierung auf den Gewichten gefunden werden, um eine Sparsität zu ermöglichen (d.h. die Darstellung jedes Datenpunktes hat nur wenige Nullgewichte). Überwachtes Wörterbuch-Erlernen nutzt sowohl die Struktur, die den Eingabedaten zugrunde liegt, als auch die Etiketten zur Optimierung der Wörterbuchelemente. Diese beaufsichtigte Wörterbuchlerntechnik wendet beispielsweise Wörterbuchlernen auf Klassifikationsprobleme durch gemeinsame Optimierung der Wörterbuchelemente, Gewichte zur Darstellung von Datenpunkten und Parameter des Klassifikators auf Basis der Eingabedaten an. Insbesondere wird ein Minimierungsproblem formuliert, bei dem die objektive Funktion aus dem Klassifikationsfehler, dem Darstellungsfehler, einer L1-Regalisation auf den repräsentierenden Gewichten für jeden Datenpunkt (um eine spärliche Darstellung von Daten zu ermöglichen) und einer L2-Regalisation auf den Parametern des Klassifikators besteht. Neural-Netzwerke Neural-Netzwerke sind eine Familie von Lernalgorithmen, die ein Netzwerk aus mehreren Schichten von miteinander verbundenen Knoten verwenden. Es wird vom tierischen Nervensystem inspiriert, wo die Knoten als Neuronen angesehen werden und Kanten als Synapsen betrachtet werden. Jede Kante hat ein zugehöriges Gewicht, und das Netzwerk definiert Rechenregeln für die Weitergabe von Eingangsdaten aus der Eingangsschicht des Netzes an die Ausgangsschicht. Eine Netzwerkfunktion, die einem neuronalen Netz zugeordnet ist, charakterisiert den Zusammenhang zwischen Eingangs- und Ausgangsschichten, der durch die Gewichte parametriert wird. Mit entsprechend definierten Netzwerkfunktionen können verschiedene Lernaufgaben durch Minimierung einer Kostenfunktion über die Netzwerkfunktion (Gewichte) ausgeführt werden. Mehrschichtige neuronale Netze können zur Durchführung von Merkmalslern verwendet werden, da sie eine Darstellung ihres Eingangs an der/den versteckten Schicht(en) erfahren, die anschließend zur Klassifikation oder Regression an der Ausgangsschicht verwendet wird. Die beliebteste Netzwerkarchitektur dieser Art ist Siamese-Netzwerke. Unsupervised Unsupervised Feature Learning ist das Erlernen von Features aus unmarkierten Daten. Das Ziel des unübertroffenen Feature-Erlernens ist es oft, Low-dimensionale Features zu entdecken, die eine Struktur erfassen, die den hochdimensionalen Eingabedaten zugrunde liegt. Wenn das Feature-Lernen in unübertroffener Weise durchgeführt wird, ermöglicht es eine Form von semisupervised-Lernen, in der dann Merkmale, die von einem unmarkierten Datensatz gelernt werden, verwendet werden, um die Leistung in einer überwachten Einstellung mit markierten Daten zu verbessern. Im Folgenden werden mehrere Ansätze vorgestellt. K-Means Clustering K-Means Clustering ist ein Ansatz für die Vektorquantisierung. Insbesondere bei einem Satz von n Vektoren gruppenweise k-Means-Cluster in k-Cluster (d.h. Subsets) derart, dass jeder Vektor mit dem engsten Mittelwert zum Cluster gehört.Das Problem ist rechnerisch NP-hart, obwohl suboptimale gierige Algorithmen entwickelt wurden. K-Means-Clustering kann verwendet werden, um einen unmarkierten Satz von Eingaben in k-Cluster zu gruppieren, und dann verwenden Sie die Schwerpunkte dieser Cluster, um Features zu erzeugen. Diese Merkmale können auf verschiedene Weise hergestellt werden. Am einfachsten ist es, k binäre Eigenschaften zu jeder Probe hinzuzufügen, wobei jedes Merkmal j einen Wert hat, der jth centroid von k-Means gelernt ist die am nächsten der betrachteten Probe. Es ist auch möglich, die Abstände zu den Clustern als Merkmale zu verwenden, vielleicht nach der Transformation durch eine radiale Basisfunktion (eine Technik, die verwendet wurde, um RBF-Netzwerke zu trainieren). Coates und Ng beachten, dass sich bestimmte Varianten von k-Means ähnlich wie Sparse-Codierung Algorithmen verhalten. Coates, Lee und Ng fanden in einer vergleichenden Auswertung von ununterbrochenen Lernmethoden heraus, dass k-Means Clustering mit einer entsprechenden Transformation die kürzlich erfundenen Auto-Encoder und RBMs auf einer Bildklassifikationsaufgabe übertrifft. K-Means verbessert auch die Leistung im Bereich der NLP, speziell für die Namens-Entity-Erkennung; dort konkurrieren sie mit Brown Clustering, sowie mit verteilten Wortdarstellungen (auch als neurale Worteinbettungen bekannt). Hauptkomponentenanalyse Hauptkomponentenanalyse (PCA) wird oft zur Dimensionsreduktion verwendet. Bei einem unmarkierten Satz von n Eingangsdatenvektoren erzeugt PCA p (was wesentlich kleiner ist als die Dimension der Eingangsdaten), rechte Einzelvektoren entsprechend den p größten Einzelwerten der Datenmatrix, wobei die kth-Reihe der Datenmatrix der kth-Eingangsdatenvektor ist, der um das Probenmittel des Eingangs verschoben wird (d.h. das Subtrahieren des Probenmittels aus dem Datenvektor). Entsprechend sind diese Einzelvektoren die den p größten Eigenwerten der Probenkovarianzmatrix der Eingangsvektoren entsprechenden Eigenvektoren. Diese p Einzelvektoren sind die aus den Eingangsdaten erlernten Merkmalsvektoren, die Richtungen darstellen, entlang derer die Daten die größten Variationen aufweisen. PCA ist ein linearer Lernansatz, da die p Einzelvektoren lineare Funktionen der Datenmatrix sind. Die Einzelvektoren können über einen einfachen Algorithmus mit P iterationen erzeugt werden. Bei der Ith Iteration wird die Projektion der Datenmatrix auf den (i-1). Eigenvektor subtrahiert und der ith-Singleularvektor als der rechte Einzelvektor entsprechend dem größten Singular der Restdatenmatrix gefunden. PCA hat mehrere Einschränkungen. Zunächst geht davon aus, dass die Richtungen mit großer Varianz von größtem Interesse sind, was nicht der Fall sein kann. PCA basiert nur auf orthogonalen Transformationen der ursprünglichen Daten, und es nutzt nur die ersten und zweiten Ordnung Momente der Daten, die die Datenverteilung nicht gut charakterisieren können. Weiterhin kann PCA die Dimension nur dann effektiv reduzieren, wenn die Eingabedatenvektoren korreliert werden (was zu wenigen dominanten Eigenwerten führt). Lokale lineare Einbettung Lokale lineare Einbettung (LLE) ist ein nichtlinearer Lernansatz zur Erzeugung von niedrigdimensionalen, benachbarten Darstellungen von (unmarkierten) hochdimensionären Input. Der Ansatz wurde von Roweis und Saul (2000) vorgeschlagen. Die allgemeine Idee von LLE ist es, die ursprünglichen hochdimensionalen Daten unter Verwendung von niedrigeren Dimensionspunkten zu rekonstruieren und dabei einige geometrische Eigenschaften der Nachbarschaften im ursprünglichen Datensatz zu erhalten. LLE besteht aus zwei großen Schritten. Der erste Schritt ist für die Nachbarhaltung, wobei jeder Eingabedatenpunkt Xi wird als gewichtete Summe von K nächsten Nachbardatenpunkten rekonstruiert, und die optimalen Gewichte werden durch Minimierung des durchschnittlichen quadratischen Rekonstruktionsfehlers (d.h. Differenz zwischen einem Eingabepunkt und seiner Rekonstruktion) unter der Beschränkung gefunden, dass die mit jedem Punkt verbundenen Gewichte zu einem zusammenfassen. Der zweite Schritt ist für "Dimensionsreduktion", indem man Vektoren in einem tieferen Raum sucht, die den Darstellungsfehler mit den optimierten Gewichten im ersten Schritt minimiert. Beachten Sie, dass im ersten Schritt die Gewichte mit festen Daten optimiert werden, die als kleinstes Quadrat Problem gelöst werden können. Im zweiten Schritt werden unterdimensionale Punkte mit festen Gewichten optimiert, die über eine spärliche Eigenwertzersetzung gelöst werden können. Die im ersten Schritt erhaltenen Rekonstruktionsgewichte erfassen die "intrinsischen geometrischen Eigenschaften" einer Nachbarschaft in den Eingabedaten. Es wird davon ausgegangen, dass auf einem glatten, unterdimensionalen Verteiler Originaldaten liegen und die durch die Gewichte der Originaldaten erfassten "intrinsischen geometrischen Eigenschaften" auch auf dem Verteiler zu erwarten sind.Deshalb werden im zweiten Schritt von LLE die gleichen Gewichte verwendet. Im Vergleich zu PCA ist LLE stärker in der Nutzung der zugrunde liegenden Datenstruktur. Unabhängige Komponentenanalyse Unabhängige Komponentenanalyse (ICA) ist eine Technik zur Bildung einer Datendarstellung mit einer gewichteten Summe unabhängiger nicht-gossischer Komponenten. Die Annahme von nicht-Gaussian wird verhängt, da die Gewichte nicht eindeutig bestimmt werden können, wenn alle Komponenten der Gaussischen Verteilung folgen. Unsupervised Wörterbuch Lernen Unsupervised Wörterbuch Lernen nutzt nicht Datenlabels und nutzt die Struktur, die den Daten zur Optimierung von Wörterbuchelementen zugrunde liegt. Ein Beispiel für unübertroffenes Wörterbuchlernen ist eine sparsame Codierung, die Basisfunktionen (diktionäre Elemente) zur Datendarstellung aus unmarkierten Eingabedaten erlernen soll. Sparse Codierung kann verwendet werden, um überkomplete Wörterbücher zu lernen, wobei die Anzahl der Wörterbuchelemente größer ist als die Größe der Eingabedaten. Aharon et al.proposed algorithm K-SVD zum Erlernen eines Wörterbuchs von Elementen, die eine spärliche Darstellung ermöglichen. Mehrschichtige/tiefe Architekturen Die hierarchische Architektur des biologischen neuronalen Systems inspiriert tiefe Lernarchitekturen zum Feature-Learning durch Stapeln mehrerer Schichten von Lernknoten. Diese Architekturen sind oft auf der Annahme der verteilten Darstellung ausgelegt: beobachtete Daten werden durch die Interaktionen vieler verschiedener Faktoren auf mehreren Ebenen erzeugt. In einer tiefen Lernarchitektur kann der Ausgang jeder Zwischenschicht als Darstellung der ursprünglichen Eingabedaten angesehen werden. Jeder Pegel verwendet die von der vorherigen Pegel erzeugte Darstellung als Eingabe und erzeugt neue Darstellungen als Ausgabe, die dann höheren Pegeln zugeführt wird. Der Eingang an der unteren Schicht ist Rohdaten, und der Ausgang der letzten Schicht ist das letzte niederdimensionale Merkmal oder die Darstellung. Eingeschränkte Boltzmann-Maschine Eingeschränkte Boltzmann-Maschinen (RBM) werden häufig als Baustein für mehrschichtige Lernarchitekturen eingesetzt. Ein RBM kann durch ein ungeschütztes Bipartit-Diagramm dargestellt werden, das aus einer Gruppe von binären versteckten Variablen, einer Gruppe von sichtbaren Variablen und Kanten besteht, die die versteckten und sichtbaren Knoten verbinden. Es ist ein Sonderfall der allgemeineren Boltzmann-Maschinen mit der Beschränkung von nicht intranode-Verbindungen. Jede Kante in einem RBM ist mit einem Gewicht verbunden. Die Gewichte definieren zusammen mit den Verbindungen eine Energiefunktion, anhand derer eine gemeinsame Verteilung von sichtbaren und versteckten Knoten gebildet werden kann. Basierend auf der Topologie des RBM sind die versteckten (sichtbaren) Variablen unabhängig, bedingt durch die sichtbaren (versteckten) Variablen. Diese bedingte Unabhängigkeit erleichtert Berechnungen. Ein RBM kann als eine einzelne Schichtarchitektur für ununterbrochenes Feature Lernen angesehen werden. Insbesondere entsprechen die sichtbaren Größen Eingangsdaten, und die versteckten Größen entsprechen Merkmalsdetektoren. Die Gewichte können trainiert werden, indem die Wahrscheinlichkeit von sichtbaren Variablen mit Hintons kontrastiver Divergenz (CD) Algorithmus maximiert wird. Im allgemeinen Training RBM durch Lösen des Maximierungsproblems führt zu nicht-sparsamen Darstellungen. Sparse RBM wurde vorgeschlagen, Sparse Repräsentationen zu ermöglichen. Die Idee besteht darin, in der objektiven Funktion der Datenwahrscheinlichkeit einen Regularisierungsterm hinzuzufügen, der die Abweichung der erwarteten versteckten Variablen von einer kleinen Konstante p {\displaystyle p} penalisiert. AutoencoderEin Autoencoder bestehend aus einem Encoder und einem Decoder ist ein Paradigma für tiefe Lernarchitekturen. Ein Beispiel wird von Hinton und Salakhutdinov bereitgestellt, wo der Encoder Rohdaten (z.B. Bild) als Eingabe verwendet und Feature oder Darstellung als Ausgabe erzeugt und der Decoder das extrahierte Feature vom Encoder als Eingabe verwendet und die ursprünglichen Eingangsrohdaten als Ausgabe rekonstruiert. Der Encoder und Decoder sind durch Stapeln mehrerer Schichten von RBMs aufgebaut. Die an der Architektur beteiligten Parameter wurden ursprünglich gierig schichtweise geschult: Nach Erlernen einer Schicht von Merkmalsdetektoren werden sie als sichtbare Variablen zur Ausbildung des entsprechenden RBM zugeführt. Aktuelle Ansätze gelten typischerweise End-to-End-Training mit stochastischen Gradientenabstiegsmethoden. Das Training kann wiederholt werden, bis einige Haltekriterien erfüllt sind. Siehe auch Automatisiertes maschinelles Lernen (AutoML) Basisfunktion Deep Learning Feature Erkennung (Computer Vision)Feature Extraktion Kernel Trick Vector quantization Variational autoencoder == Referenzen ==