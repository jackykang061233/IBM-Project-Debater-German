In der Mathematik ist der Spiral-Optimierungs-Algorithmus (SPO) eine metaheuristische inspiriert von Spiralphänomenen in der Natur. Der erste SPO-Algorithmus wurde für eine zweidimensionale, nicht eingeschränkte Optimierung basierend auf zweidimensionalen Spiralmodellen vorgeschlagen. Dies wurde durch Verallgemeinerung des zweidimensionalen Spiralmodells zu einem n-dimensionalen Spiralmodell auf n-dimensionale Probleme erweitert. Für den SPO-Algorithmus gibt es effektive Einstellungen: die periodische Abwärtsrichtungseinstellung und die Konvergenzeinstellung. Metapher Die Motivation, sich auf Spiralphänomene zu konzentrieren, war die Erkenntnis, dass die Dynamik, die logarithmische Spiralen erzeugen, das Diversifizierungs- und Intensivierungsverhalten teilen. Das Diversifizierungsverhalten kann für eine globale Suche (Exploration) arbeiten und das Verstärkungsverhalten ermöglicht eine intensive Suche um eine aktuelle gefundene gute Lösung (Exploitation). Algorithmen Der SPO-Algorithmus ist ein Multipoint-Suchalgorithmus, der keinen objektiven Funktionsgradienten aufweist, der mehrere Spiralmodelle verwendet, die als deterministische dynamische Systeme beschrieben werden können. Als Suchpunkte folgen logarithmische Spiraltrajektorien in Richtung des gemeinsamen Zentrums, definiert als der aktuelle beste Punkt, können bessere Lösungen gefunden werden und das gemeinsame Zentrum kann aktualisiert werden. Der allgemeine SPO-Algorithmus für ein Minimierungsproblem unter der maximalen Iteration k max {\displaystyle k_{\max } ist wie folgt: 0) Setzen Sie die Anzahl der Suchpunkte m ≥ 2 {\displaystyle m\geq 2} und die maximale Iterationszahl k max {\displaystyle k_{\max }.1) Legen Sie die ersten Suchpunkte x i (0 ) ε R n (i = 1 , ... , m ) {\displaystyle x_{i}(0)\in \mathbb {R} {\c} {\c} {\c}} {\c}}} {\c}}} {\c}}}} {\c}}}} {\displaystyle x^{\star ) 4) Aktualisieren Sie das Zentrum: x ⋆ (k + 1 ) = { x i b( k + 1 ) ) {_i=1,\ldots ,m}\{f(x_{i}(k+1) .5) Set k := k + 1 {\displaystyle k:=k+1} .If k = k max {\displaystyle k=k_{\max }} dann beendet und ausgegeben x ⋆ (k) {\displaystyle x^{\star (k) .Anderweise, zurück Einstellung Die Suchleistung hängt von der Einstellung der Verbunddrehmatrix R (θ ) {\displaystyle R(\theta )}, der Schrittrate r (k ) {\displaystyle r(k}) und den Anfangspunkten x i (0 ) (i = 1 , ... , m ) {\displaystyle x_{i}(0)~(i=1,\ldots ,m}) ab. Die folgenden Einstellungen sind neu und effektiv. Einstellung 1 (Periodic Descent Direction Setting)Diese Einstellung ist eine effektive Einstellung für hohe Dimensionsprobleme unter der maximalen Iteration k max {\displaystyle k_{\max }} . Die Bedingungen auf R ( θ ) {\displaystyle R(\theta )} und x i ( 0 ) ( i = 1 , ..., m ) {\displaystyle x_{i}(0)~(i=1,\ldots ,m}) sorgen zusammen dafür, dass die Spiralmodelle periodisch Abstiegsrichtungen erzeugen.Die Bedingung von r (k ) {\displaystyle r(k}) funktioniert, um die periodischen Abstiegsrichtungen unter dem Suchterminal k max {\displaystyle k_{\max } zu nutzen. Set R ( θ ) {\displaystyle R(\theta )} wie folgt: R ( θ ) = [ 0 n - 1 ⊤ - 1 I n - 1 0 n - 1 ; ) wobei I n - 1 {\displaystyle I_{n-1} die (n - 1 ) × ( n - 1 ) {\displaystyle (n-1)\times (n-1}) Identitätsmatrix und 0 n - 1 {\displaystyle 0_{n-1} der (n - 1 ) × 1\displaystyle (n-1)\times 1} null Vektor ist. ,,,,, ,,, , , , , , n , n , n , n , n , n , n , n , n , n , m )Beachten Sie, dass diese Bedingung fast alle durch eine zufällige Platzierung zufrieden ist und somit keine Überprüfung tatsächlich in Ordnung ist. Setzen Sie r (k ) {\displaystyle r(k}) bei Schritt 2) wie folgt ein: r (k ) = r = δ k max (constant value) {\displaystyle r(k)={\sqrt[{k_{\\}]delta }\~text{(constant value} bei einem ausreichend kleinen δ > 0 {\displaystyle \delta >0} wie δ = 1 / k max {\displaystyle \delta =1/k_{\max } oder δ = 10 - 3 {\displaystyle \delta =10^{-3} . Einstellung 2 (Convergence Setting)Diese Einstellung sorgt dafür, dass der SPO-Algorithmus zu einem stationären Punkt unter der maximalen Iteration k max = ∞\displaystyle k_{\max }=\infty } konvergiert. Die Einstellungen R ( θ ) {\displaystyle R(\theta )} und die Anfangspunkte x i ( 0 ) (i = 1 , ..., m ) {\displaystyle x_{i}(0)~(i=1,\ldots ,m}) sind mit der obigen Einstellung 1 identisch. Die Einstellung von r (k ) {\displaystyle r(k}) ist wie folgt. r (k ) {\displaystyle r(k}) bei Schritt 2) wie folgt: r (k ) = { 1 (k ⋆ ≤ k ⋆ + 2 n - 1 ) , h ( k ≥ k }+2n-1),\h&(k\geqq k^{\star +2n),\end{cases, bei denen k ⋆ {\displaystyle k^\star } eine Iteration ist, wenn das Zentrum neu in Schritt 4) und h = δ 2 n, δ ε (0, 1 ) =0.5} .Dann müssen wir die folgenden Regeln über k ⋆ {\displaystyle k^{\star } zum Algorithm hinzufügen:•(Schritt 1) k ⋆ = 0 {\displaystyle k^{\star =0 .•(Schritt 4)Wenn x \ ⋆ (k + 1 ≠ x ⋆ (k ) {\displaystyle x^{\star }(k+1)k ⋆ = k + 1 = k+1. Zukunft Die Algorithmen mit den obigen Einstellungen sind deterministisch. Mit einigen zufälligen Operationen macht dieser Algorithmus für die globale Optimierung leistungsstark. Cruz-Duarte et al.demonstrated it, indem es stochastische Störungen in Spiral suchen Trajektorien einschließt. Diese Tür bleibt jedoch offen für weitere Studien. Um eine angemessene Balance zwischen Diversifizierung und Verstärkungsspiralen in Abhängigkeit von der Zielproblemklasse zu finden (einschließlich k max {\displaystyle k_{\max }}) ist wichtig, um die Leistung zu verbessern. Erweiterte Arbeiten Viele erweiterte Studien wurden an der SPO aufgrund ihrer einfachen Struktur und ihres Konzepts durchgeführt; diese Studien haben dazu beigetragen, ihre globale Suchleistung zu verbessern und neue Anwendungen vorzuschlagen. = Referenzen ==