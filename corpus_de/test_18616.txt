Video ist ein elektronisches Medium für die Erfassung, Kopie, Wiedergabe, Rundfunk und Anzeige der Bewegung visueller Medien. Video wurde zunächst für mechanische Fernsehsysteme entwickelt, die schnell durch Kathodenstrahlröhren (CRT)-Systeme ersetzt wurden, die später durch flache Panel-Anzeigen mehrerer Arten ersetzt wurden. Videosysteme unterscheiden sich in der Anzeige-Resolution, dem Aspektverhältnis, der Auffrischungsrate, der Farbfähigkeit und anderen Qualitäten. Analoge und digitale Varianten bestehen und können auf einer Vielzahl von Medien, einschließlich Rundfunk, Magnetband, optische Scheiben, Computerdateien und Netzstreaming, durchgeführt werden. Kurzes Video Videotechnik wurde zunächst für mechanische Fernsehsysteme entwickelt, die schnell durch Kathodenstrahlröhren (CRT) ersetzt wurden, aber seitdem wurden mehrere neue Technologien für Videobildschirme entwickelt. Video war ursprünglich ausschließlich eine Live-Technologie. Charles Ginsburg führte ein Ampex-Forschungsteam durch, das einen der ersten praktischen Videobandrekorder (VTR) entwickelt. Im Jahr 1951 hat das erste VTR Live-Bilder von Fernsehkameras erfasst, indem es das elektrische Signal der Kamera auf Magnet-Video-Engineering schrieb. Videorekorder wurden 1956 für 500.000 US$ verkauft, und Videobänder kosteten 300 $ pro Stunde. Jedoch sind die Preise im Laufe der Jahre allmählich gesunken; 1971 begann Sony mit dem Verkauf von Videocassettenschreiber (VCR) Decks und Banden in den Verbrauchermarkt. Digital Video Die Nutzung digitaler Techniken in Video hat digitales Video entwickelt. Es konnte zunächst nicht mit analogem Video konkurrieren, weil digitales unkomprimiertes Video, das unpraktisch hohe Bitraten erfordert, früh war. Konkretes digitales Video wurde mit einer diskreten Kosin-Modierung (DCT) möglich, einem Verlustkompressionsprozess, der in den frühen 70er Jahren entwickelt wurde. DCT-Kodierung wurde in den späten 80er Jahren in Bewegung gebracht, beginnend mit H.261, dem ersten Standard für digitale Videocode. Digital Video war später in der Lage, die Qualität zu erhöhen und schließlich viel niedrigere Kosten als früher analoge Technologie. Nach der Erfindung der DVD im Jahr 1997 und später der Blu-ray Disc im Jahr 2006 wurden der Verkauf von Video- und Aufzeichnungsgeräten gebremst. Fortschritte in der Computertechnik ermöglichen sogar preiswerte persönliche Computer und Smartphones, digitales Video zu erfassen, zu bearbeiten und zu übertragen, die Kosten der Videoproduktion weiter zu senken, so dass die Programmhersteller und Rundfunkanstalten zu einer bürokratischen Produktion gelangen können. Durch die Einführung des digitalen Rundfunks und der anschließenden digitalen Fernsehumstellung wird in den meisten Teilen der Welt analoges Video zum Status einer alten Technologie relegiert. Im Jahr 2015, mit zunehmender Nutzung von hochauflösenden Videokameras mit verbesserter dynamischen Bandbreite und Farbgamuts und hochdynamischen digitalen Zwischendatenformaten mit verbesserter Farbtiefe, ist moderne digitale Videotechnik mit digitaler Filmtechnik verbunden. Merkmale der Videoströme Anzahl der Rahmen pro Sekunde, die Anzahl der immer noch Bilder pro Stück Video, reicht von sechs oder acht Rahmen pro Sekunde (Rahmen/s) für alte mechanische Kameras bis 120 oder mehr Rahmen pro Sekunde für neue professionelle Kameras. PAL-Normen (Europa, Asien, Australien, usw.). und SECAM (Frankreich, Russland, Teile Afrikas usw.). 25 Rahmen/s, während NTSC-Normen (USA, Kanada, Japan, usw.) festgelegt sind. 29.97 Rahmen/s. Film wird auf der langsameren Rahmenrate von 24 Rahmen pro Sekunde gedrängt, was den Prozess der Übertragung eines Filmbildes auf Video erschwert. Mindestrahmensatz, um eine bequeme Illusion eines sich bewegenden Bildes zu erreichen, beträgt etwa sechzehn Rahmen pro Sekunde. Interlaced vs progressives Video kann interlaciert oder progressiv sein. Jede Auffrischungsfrist aktualisiert alle Scanlinien in jedem Rahmen in der Sequenz. Bei der Anzeige eines lokal progressiven Rundfunk- oder Aufzeichnungssignals ist das Ergebnis eine optimale räumliche Auflösung sowohl der stationären als auch der beweglichen Teile des Bildes. Interlacing wurde als Weg entwickelt, um die Fingerabdrücke in frühen mechanischen und CRT-Videobildschirmen zu reduzieren, ohne die Zahl der vollständigen Rahmen pro Sekunde zu erhöhen. Interlacing behält sich detailliert vor und erfordert niedrigere Bandbreiten im Vergleich zum progressiven Scan. In interlaced Video werden die horizontalen Scanlinien jedes kompletten Rahmens behandelt, als wenn sie in Folge aufgezählt werden und in zwei Bereichen gefangen werden: ein ungewohntes Feld (Oberfeld) bestehend aus den ungezahlten Linien und sogar einem Feld (niedriger Bereich) bestehend aus den sogar Nummernlinien. Analoge Bildschirmgeräte, die jeden Rahmen reproduzieren, verdoppeln den Rahmensatz insofern, als der Gesamt-Klinner betroffen ist. Wenn das Bild-Aufnahmegerät die Felder zu einer Zeit erwirbt, anstatt einen vollständigen Rahmen nach der Erfassung aufzuteilen, wird der Bewegungsrahmen effektiv verdoppelt, was zu einer reibungsloseren, lebensähnlichen Vervielfältigung schnell bewegender Teile des Bildes führt, wenn er auf einer interlacierten CRT-Anzeige zu sehen ist. NTSC, PAL und SECAM sind interlacierte Formate. Abbreviierte Video-Resolutionsspezifikationen enthalten häufig eine, um Interlacing anzugeben. Beispiel: PAL-Video-Format wird häufig als 576i50 beschrieben, wo 576 die Gesamtzahl der horizontalen Scanlinien angegeben, d. h. die Interlacing- und 50-Punkte (Halbrahmen) pro Sekunde. Bei der Anzeige eines inländischen interlacierten Signals auf einem progressiven Scan-Gerät wird die räumliche Auflösung durch einfache Liniesdosierung – Artifacts, wie z.B. das Einstecken oder comb Wirkungen in bewegliche Teile des Bildes abgeschwächt, es sei denn, eine spezielle Signalverarbeitung beseitigt sie. Ein Verfahren, das als Deinterlacing bekannt ist, kann die Anzeige eines interlacierten Videosignals aus analoger, DVD oder Satellitenquelle auf einem progressiven Scangerät wie einem LCD-Fernsehgerät, einem digitalen Videoprojekt oder einem Plasmapanel optimieren. Klarterlacing kann jedoch keine Videoqualität produzieren, die dem tatsächlichen progressiven Scan-Quelle-Material entspricht. Leistungspunkteverhältnis beschreibt die Verhältnismäßigkeit zwischen der Breite und der Höhe der Videobildschirme und Videobildelemente. Alle populären Videoformate sind rechteckig und können daher durch ein Verhältnis zwischen Breite und Höhe beschrieben werden. Verhältnisbreite für ein traditionelles Fernsehbildschirm ist 4:3 oder etwa 1,33:1. High-Definition-Fernsehen verwenden einen Aspekt von 16:9 oder etwa 1.78:1. Das Verhältnis eines vollständigen 35 mm Filmrahmens mit dem Film (auch bekannt als Akademieverhältnis) beträgt 1.375:1. Pixels auf Computerbildschirmen sind in der Regel quadratisch, aber die in digitalen Video verwendeten Pixel verfügen oft über nicht-Grenzwerte, wie die in den Varianten der CCIR 601 Digital Video Standard und die entsprechenden aamorphen Breitbildschirmformate. Die 720 von 480 Pixel raster verwendet dünne Pixel auf einer 4:3-Dissionsbilanz und Fettspiegel auf einer 16:9-Anzeige. Die Popularität von Video auf Mobiltelefonen hat zu einem Wachstum des vertikalen Video geführt. Mary Meeker, Partnerin im Silicon Valley-Risikokapitalunternehmen Kleiner Perkins Caufield & Byers, hob das Wachstum der vertikalen Videoaufnahme in ihrem Internet Trends Report 2015 hervor – von 5 % des Videoschauers im Jahr 2010 auf 29 % im Jahr 2015. vertikale Videowerbungen wie die Podcasts werden in ihren gesamten neunmal häufiger als Landschafts-Video-Anzeigen beobachtet. Farbmodell und Tiefe Das Farbmodell der Videofarbe-Vertretung und Karten mit codierten Farbwerten für sichtbare Farben, die durch das System hergestellt werden. In der Regel wird YIQ in NTSC-Fernsehen verwendet, YUV wird in PAL-Fernsehen, YDb Dr wird von SECAM TV und YCb verwendet Cr wird für digitales Video verwendet. Die Anzahl der verschiedenen Farben kann ein Pixel darstellen, hängt von der Farbtiefe ab, die in der Anzahl der Bits pro Pixel ausgedrückt wird. Ein gemeinsamer Weg, um die Menge der Daten, die im digitalen Video benötigt werden, zu reduzieren, ist durch Chroma Subsampling (z.B. 4:4:4, 4:2:2, usw.). Da das menschliche Auge weniger empfindlich auf Details in Farbe als Helligkeit ist, werden die luminierenden Daten für alle Pixel beibehalten, während die Chrominance-Daten für eine Reihe von Pixeln in einem Block durchschnittlich und für alle von ihnen dasselbe Wert verwendet werden. Dies führt zum Beispiel zu einer 50%igen Senkung der Chrominance-Daten unter Verwendung von zwei Blöcken (4:2:2) oder 75 % unter Verwendung von vier Blöcken (4:2:0). Dieser Prozess verringert nicht die Anzahl möglicher Farbwerte, die angezeigt werden können, sondern verringert die Anzahl der einzelnen Punkte, auf denen sich die Farbänderungen ändern. Videoqualität Videoqualität lässt sich anhand formaler Parameter wie Spitzensignal-to-noiseverhältnis (PSNR) oder durch subjektive Video-Qualitätsbewertung anhand einer Sachverständigenbeobachtung messen. Viele subjektive Videoqualitätsmethoden werden in der ITU-T-Empfehlung BT.500 beschrieben. Eine der standardisierten Methoden ist die Doppelanreizungsskala (DSIS). In DSIS betrachtet jeder Sachverständigen ein unbeschränktes Referenzvideo, gefolgt von einer beeinträchtigten Version des gleichen Videos. Der Sachverständigen führt dann ein eingeschränktes Video mit einer Skala von "Verbesserungen sind unannehmbar" bis "Verbesserungen sind sehr schädlich". Video-Kompression (digital nur) Unkomprimiertes Video liefert höchste Qualität, aber mit einer sehr hohen Datenquote. Eine Vielzahl von Methoden werden verwendet, um Videoströme zu komprimieren, mit den wirksamsten, die eine Gruppe von Bildern (GOP) verwenden, um räumliche und zeitliche Entlassungen zu reduzieren. Im Großen und Ganzen wird die räumliche Entlassung durch die Eintragung von Unterschieden zwischen Teilen eines einzigen Rahmens verringert; diese Aufgabe ist als intraframe-Kompression bekannt und ist eng mit Bildkompression verbunden. Gleichzeitig können die zeitlichen Entlassungen durch die Eintragung von Unterschieden zwischen den Rahmenbedingungen verringert werden; diese Aufgabe ist als Interframe-Kompression bekannt, einschließlich Bewegungsausgleich und andere Techniken. Die häufigsten modernen Kompressionsstandards sind MPEG-2, die für DVD, Blu-ray und Satellitenfernsehen verwendet werden, und MPEG-4, die für AVCHD, Mobiltelefone (3GP) und Internet verwendet werden. Stereokopisches Stereokopisches Video für 3d-Filme und andere Anwendungen können mit verschiedenen Methoden dargestellt werden: Zwei Kanäle: ein richtiger Kanal für das richtige Auge und ein linken Kanal für das linken Auge. Beide Kanäle können gleichzeitig mit leichter polarisierenden Filter 90 Grad Off-Achsen auf zwei Videoprojektoren angesehen werden. Diese getrennt polarisierten Kanäle werden mit geeigneten Polarisierungsfiltern mit Augenglasen angesehen. Analy 3D, wo ein Kanal überlaid mit zwei farbverschlüsselten Schichten ist. Diese linken und rechten Schichttechnik wird gelegentlich für die Übertragung oder die jüngsten aalytischen Freisetzungen von 3D-Filmen auf DVD verwendet. Einfache rote/zyklische Kunststoffbrillen stellen die Mittel dar, um die Bilder einzeln zu betrachten, um eine Stereokopie des Inhalts zu bilden. Ein Kanal mit wechselndem linken und richtigen Rahmen für das entsprechende Auge, wobei LCD-brillenfenster, die mit dem Video wechseln, um das Bild in jedes Auge abzubauen, so sieht das geeignete Auge den richtigen Rahmen. Diese Methode ist am häufigsten in Computer-Wirkungsanwendungen wie einem Cave-automatischen virtuellen Umfeld üblich, verringert aber einen wirksamen Videorahmen um zwei. Formaten unterschiedlicher Ebenen der Videoübertragung und -speicherung bieten jeweils eigene Formaten an, um sich von ihnen zu entscheiden. Für die Übertragung gibt es ein physisches Verbindungs- und Signalprotokoll (siehe Liste der Videoanschlüsse). Eine bestimmte physische Verbindung kann bestimmte Anzeigestandards erfüllen, die eine bestimmte Auffrischungsrate, die Anzeige und den Farbraum angeben. Viele analoge und digitale Aufzeichnungsformate sind in Gebrauch, und digitale Videoclips können auch auf einem Computer-Dateisystem gespeichert werden, das über eigene Formate verfügt. Neben dem von der Datenspeichereinrichtung oder dem Übertragungsmedium verwendeten physischen Format muss das Netz von ihnen und Nullen, die versandt werden, in einem bestimmten digitalen Videocode-Format sein, dessen Anzahl verfügbar ist (siehe Liste der Videocodeformate). Analoges Video Analog-Video ist ein Videosignal, das durch ein oder mehrere analoge Signale repräsentiert ist. Analoge Farb-Videosignale umfassen Luminance, Helligkeit (Y) und Chrominance (C). In Verbindung mit einem Kanal, wie es der Fall ist, unter anderem mit NTSC, PAL und SECAM, wird es als zusammengesetztes Video bezeichnet. Analoges Video kann in separaten Kanälen durchgeführt werden, wie in zwei Sendern S-Video (YC) und Multi-Channel-Komponenten-Videoformate. Analoges Video wird sowohl in den Anwendungen der Unterhaltungs- als auch in der professionellen Fernsehproduktion verwendet. Digital Video Digital Videosignalformate wurden angenommen, darunter serielle digitale Schnittstelle (SDI), digitale visuelle Schnittstelle (DVI), High-Definition Multimedia Interface (HDMI) und Displayport Interface. Transportmedium Video kann in einer Vielzahl von Möglichkeiten übertragen oder transportiert werden, darunter drahtloses terrestrisches Fernsehen als analoges oder digitales Signal, coaxialkabel in einem geschlossenen Kreislaufsystem als analoges Signal. Rundfunk- oder Studiokameras verwenden ein einziges oder Dual-Coaxial-Kabelsystem mit serieller digitaler Schnittstelle (SDI). Liste der Video-Anschlüsse für Informationen über physische Verbindungen und entsprechende Signalnormen. Video kann über Netze und andere gemeinsame digitale Kommunikationsverbindungen transportiert werden, z.B. mit dem MPEG-Transportstrom, SMPTE 2022 und SMPTE 2110. Display-Standards Digitalfernsehen Digitalfernsehen Digital Broadcasting (DVB) – Europe ISDB – Japan ISDB-Tb – nutzt das MPEG-4-Video-Format – Brasilien, Argentinien Digital Broadcasting (DMB) – Korea Analog-Fernsehnormen: flächenbezogenes Farbsystem (FCKWS) – USA, Russland; obsoletexedxedxedxedxedxed (MAC) – Europe – CDMsole, USA, USA, Russland – CDMsole, USA, USA, USA, USA, Russland – CDMsole, Japan – USA – USA – USA – CDMhole, Japan – USA – CDMhole. Brasilien, Argentinien PALplus – PAL-Erweiterung, Europa RS-343 (militärische Republik) SECAM – Frankreich, ehemalige Sowjetunion, Zentralafrikanisches CCIR System B CCIR System G CCIR System H CCIR System I CCIR System MAn analoges Videoformat besteht aus mehr Informationen als dem sichtbaren Inhalt des Rahmens. Vorab und nach dem Bild sind Linien und Pixel mit Metadaten und Synchronisierung. Diese Umgebungsmarge ist bekannt als Leerlauf oder leere Region; die horizontale und vertikale Front und Hintertür sind die Bausteine des Leerlaufs. Computer Display-Standards enthalten eine Kombination aus Aspektverhältnis, Anzeigegröße, Anzeigeauflösung, Farbtiefe und Auffrischungsrate. Eine Liste gemeinsamer Entschließungen ist verfügbar. Erfassung des frühen Fernsehens war fast ausschließlich ein Live-Medikament mit einigen Programmen, die für den Vertrieb historischer Zwecke mit Kinekop auf den Film gebracht wurden. Im Jahr 1951 wurde der analoge Videobandschreiber eingeführt. In ungefährer Reihenfolge. Alle aufgelisteten Formate wurden an Rundfunkanstalten, Videoproduzenten oder Verbraucher verkauft oder waren von historischer Bedeutung (VERA). Digital Videobandrekorder boten im Vergleich zu Analogrekordern bessere Qualität an. Optical Storage Mediums boten eine Alternative, vor allem in Verbraucheranwendungen, zu Massenbandformaten an. Blu-ray Disc (Sony)China Blue High-Definition Disc (CBHD) DVD (Resional Disc, DVD Forum)Profesional Disc Universal Media Disc (UMD) Verstärkte Bandbreite (EVD, chinesischer staatlich geförderter)HD DVD (NEC und Toshiba) HD-VMD Capacitance Electronic Disc Laser (MCA und Philips) Electronic Disc (Teldec und Telefunken VHD (JVC) Digitalformate Lesen Sie auch allgemeine Video-Video-Bildschirm-Aufnahme-Software-Bezeichnungen Externe Links Video als Kunst auf Curlie Video als Medienproduktion im Curlie Programmer-Leitfaden zu Videosystemen: eingehende technische Informationen zu 480i, 576i, 1080i, 720p usw. Formatbeschreibungen für Bilder – www.digitalpserv.gov