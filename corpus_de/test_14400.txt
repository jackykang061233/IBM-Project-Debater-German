Dies ist eine chronologisch geordnete Liste von Metapher-basierten Metaheuristiken und Swarm Intelligence Algorithmen. Algorithmen Simulated Annealing (Kirkpatrick et al,. 1983)Simulated Annealing (SA) ist eine probabilistische Technik, die von einer Wärmebehandlungsmethode in der Metallurgie inspiriert ist. Es wird oft verwendet, wenn der Suchraum diskret ist (z.B. alle Touren, die einen bestimmten Satz von Städten besuchen.) Bei Problemen, bei denen das genaue globale Optimum weniger wichtig ist als ein akzeptables lokales Optimum in fester Zeit zu finden, kann eine simulierte Glühung gegenüber Alternativen wie Gradientenabstieg bevorzugt sein. Simulierte Glühung interpretiert langsame Abkühlung als langsame Abnahme der Wahrscheinlichkeit, schlechtere Lösungen zu akzeptieren, da sie den Lösungsraum erforscht. Schlimmere Lösungen zu akzeptieren, ist ein Grundgedanke der Metaheuristik, weil es eine umfassendere Suche nach der optimalen Lösung ermöglicht. Ant-Kolonie-Optimierung (Dorigo, 1992)Der ant-Kolonie-Optimierungsalgorithmus (ACO) ist eine probabilistische Technik zur Lösung von Rechenproblemen, die reduziert werden können, um gute Wege durch Graphen zu finden. Ursprünglich von Marco Dorigo 1992 in seiner Doktorarbeit vorgeschlagen, zielte der erste Algorithmus auf die Suche nach einem optimalen Weg in einem Diagramm, basierend auf dem Verhalten von Ameisen, die einen Pfad zwischen ihrer Kolonie und einer Quelle von Nahrung suchen. Die ursprüngliche Idee hat sich seither diversifiziert, um eine breitere Klasse von numerischen Problemen zu lösen, und dadurch sind mehrere Probleme entstanden, die sich auf verschiedene Aspekte des Verhaltens von Ameisen beziehen. Aus einer breiteren Perspektive führt ACO eine modellbasierte Suche durch und teilt einige Ähnlichkeiten mit der Schätzung der Distributionsalgorithmen. Partikel-Schwarm-Optimierung (Kennedy & Eberhart, 1995) Partikel-Schwarm-Optimierung (PSO) ist eine rechnerische Methode, die ein Problem dadurch optimiert, dass es versucht, eine Kandidatenlösung in Bezug auf ein bestimmtes Maß an Qualität zu verbessern. Es löst ein Problem, indem es eine Bevölkerung von Kandidatenlösungen, hier gegrabene Partikel, und diese Partikel im Suchraum nach einfachen mathematischen Formeln über die Position und Geschwindigkeit des Partikels herum bewegt. Jede Partikelbewegung wird durch ihre lokale bekannteste Position beeinflusst, wird aber auch zu den bekanntesten Positionen im Suchraum geführt, die als bessere Positionen von anderen Partikeln aktualisiert werden. Dies wird erwartet, dass der Schwarm zu den besten Lösungen zu bewegen. PSO ist ursprünglich Kennedy, Eberhart und Shi zugeordnet und diente als stilisierte Darstellung der Bewegung von Organismen in einer Vogelschleuse oder Fischschule als erstes zur Simulation des sozialen Verhaltens. Der Algorithmus wurde vereinfacht und es wurde beobachtet, dass die Optimierung durchgeführt wird. Das Buch von Kennedy und Eberhart beschreibt viele philosophische Aspekte der PSO und der swarm Intelligence. Eine umfangreiche Erhebung über PSO-Anwendungen wird von Poli erstellt. Kürzlich wurde eine umfassende Überprüfung über theoretische und experimentelle Arbeiten an PSO von Bonyadi und Michalewicz veröffentlicht. Harmony-Suche (Geem, Kim & Loganathan, 2001) Harmony-Suche ist ein Phänomen-mimicking metaheuristic vorgestellt im Jahr 2001 von Zong Woo Geem, Joong Hoon Kim und G. V. Loganathan. Die Harmonie-Suche ist inspiriert vom Improvisationsprozess von Jazzmusikern. Ein Papier behauptete, dass Harmoniesuche als ein besonderer Fall des Evolution Strategies-Algorithmus erwiesen ist. Ein neuer Artikel argumentiert jedoch, dass die Struktur der Evolutionsstrategien anders ist als die der Harmoniesuche. Die Harmony-Suche (HS) ist ein relativ einfacher und dennoch effizienter evolutionärer Algorithmus. Im HS-Algorithmus wird eine Reihe von möglichen Lösungen zufällig generiert (genanntes Harmony-Speicher). Eine neue Lösung wird erzeugt, indem man alle Lösungen im Harmony-Speicher (anstatt nur zwei wie in GA) verwendet und wenn diese neue Lösung besser ist als die schlimmste Lösung im Harmony-Speicher, die schlechteste Lösung wird durch diese neue Lösung ersetzt. Die Wirksamkeit und Vorteile von HS wurden in verschiedenen Anwendungen wie Konstruktion von kommunalen Wasserverteilungsnetzen, Konstruktion, Last-Versand-Problem in der Elektrotechnik, Multi-Ziel-Optimierung, Roustering-Probleme, Clustering und Klassifizierung und Merkmalsauswahl gezeigt. Eine detaillierte Erhebung über Anwendungen von HS finden Sie in und Anwendungen von HS im Datenbergbau. Künstlicher Bienenkoloniealgorithmus (Karaboga, 2005)Künstlicher Bienenkoloniealgorithmus ist ein metaheuristischer Algorithmus, der 2005 von Karaboga eingeführt wurde und das Futterverhalten von Honigbienenen simuliert. Der ABC-Algorithmus verfügt über drei Phasen: Bee, Onlooker-Bier und Scout-Bier. In den angewandten Bienen- und Onlookerbienphasen nutzen Bienen die Quellen durch lokale Recherchen in der Nachbarschaft der auf der Grundlage der deterministischen Selektion in der angewandten Bienenphase und der probabilistischen Selektion in der Onlookerbienphase ausgewählten Lösungen. In der Pfadfinderphase, die eine Analogie ist, erschöpfte Nahrungsquellen im Futterprozess zu verlassen, werden Lösungen, die für den Suchfortschritt nicht mehr von Vorteil sind, aufgegeben und neue Lösungen werden anstelle von ihnen eingesetzt, um neue Regionen im Suchraum zu erkunden. Der Algorithmus verfügt über eine ausgewogene Explorations- und Verwertungsfähigkeit. Bienenalgorithmus (Pham, 2005) Der Bienenalgorithmus in seiner Grundformulierung wurde 2005 von Pham und seinen Mitarbeitern erstellt und in den folgenden Jahren weiter verfeinert. Der Algorithmus, der auf das Nachahmungsverhalten von Honigbienen modelliert ist, kombiniert die globale explorative Suche mit lokaler Exploitativsuche. Eine kleine Anzahl von künstlichen Bienen (Scouts) erforscht zufällig den Lösungsraum (Umwelt) für Lösungen von hoher Fitness (hoch rentable Nahrungsquellen), während der Großteil der Bevölkerungssuche (harvest) die Nachbarschaft der fittest Lösungen sucht, die nach dem Fitness-Optimum suchen. Ein deterministisches Rekrutierungsverfahren, das den Waggle-Tanz von biologischen Bienen simuliert, dient dazu, die Ergebnisse der Scouts an die Forager zu übermitteln und die Forager je nach der Eignung der für die lokale Suche ausgewählten Nachbarschaften zu verteilen. Sobald die Suche in der Nachbarschaft einer Lösung stagniert, gilt das lokale Fitness-Optimum als zu finden, und die Website wird verlassen. Zusammengefasst sucht das Bienen-Algorithm gleichzeitig die vielversprechendsten Regionen des Lösungsraums, während es auf der Suche nach neuen günstigen Regionen kontinuierlich abläuft. Glowworm Schwarmoptimierung (Krishnanand & Ghose, 2005) Die Glimmschwarm-Optimierung ist ein auf dem Verhalten von Glimmwurms (auch bekannt als Brandfliegen oder Blitz-Bugs) entwickelter Swarm Intelligence-Optimierungsalgorithmus. Der GSO-Algorithmus wurde von K.N Krishnanand und Debasish Ghose im Jahr 2005 am Leit-, Kontroll- und Entscheidungs-Systemlabor im Institut für Luft- und Raumfahrttechnik am indischen Institut für Wissenschaft, Bangalore, Indien entwickelt und eingeführt. Das Verhaltensmuster von Glimmwürmern, das für diesen Algorithmus verwendet wird, ist die offensichtliche Fähigkeit der Glimmwürmer, die Intensität der Luciferin-Emission zu ändern und so an verschiedenen Intensitäten zu leuchten. Durch den GSO-Algorithmus leuchten die Agenten in etwa proportional zu dem zu optimierenden Funktionswert. Es wird angenommen, dass Glühwürmer heller Intensitäten Glühwürmer anziehen, die eine geringere Intensität aufweisen. Der zweite wesentliche Teil des Algorithmus enthält einen dynamischen Entscheidungsbereich, durch den die Wirkung von fernen Glimmwürmern reduziert wird, wenn ein Glimmwurm eine ausreichende Anzahl von Nachbarn hat oder der Bereich über den Wahrnehmungsbereich der Glimmwurms hinausgeht. Der Teil 2 des Algorithmus unterscheidet sich von anderen evolutionären multimodalen Optimierungsalgorithmen. Es ist dieser Schritt, der es erlaubt, Glimmschwarmen automatisch in Untergruppen zu unterteilen, die dann gleichzeitig mehrere lokale Opima konvergieren können, Diese Eigenschaft des Algorithmus ermöglicht es, mehrere Peaks einer multimodalen Funktion zu identifizieren und macht es zu einem Teil der evolutionären multimodalen Optimierungsalgorithmen Familie. Shuffled Froschsprung-Algorithmus (Eusuff, Lansey & Pasha, 2006) Der Shuffled Froschsprungalgorithmus ist ein Optimierungsalgorithmus, der in der künstlichen Intelligenz verwendet wird. Es ist vergleichbar mit einem genetischen Algorithmus. Cat Swarm Optimization (Chu, Tsai und Pan, 2006) Der Katzenschwarm-Optimierungsalgorithmus, der Optimierungsprobleme löst und vom Verhalten von Katzen inspiriert ist. Es ist ähnlich wie andere Swarm-Optimierungsalgorithmen wie die Ant Colony-Optimierung oder Partikel-Swarm-Optimierung Algorithmen. Suche und Verfolgung, zwei gemeinsame Verhalten von Katzen, bilden die beiden Sub-Modelle des Algorithmus. Der Suchmodus ist inspiriert vom Verhalten einer Katze im Ruhezustand, die sucht, wo man sich als Nächstes bewegt. Im Suchmodus wählt es mehrere Kandidatenpunkte aus und wählt dann eine aus, um zufällig zu bewegen, die Wahrscheinlichkeit der Auswahl von Punkten zu erhöhen, die einen höheren Fitnesswert haben. Der Tracing-Modus ist inspiriert von einer Katze, die ein bestimmtes Ziel verfolgt. In diesem Modus wird die Katze versuchen, mit dem besten Fitnesswert in Richtung Position zu bewegen. Die Katzen bewegen sich im Such- und Tracing-Modus weiter, bis eine Abschlussbedingung erfüllt ist. Imperialistischer Wettbewerbsalgorithmus (Atashpaz-Gargari & Lucas, 2007) Der imperialistische Wettbewerbsalgorithmus ist eine rechnerische Methode, die verwendet wird, um Optimierungsprobleme verschiedener Typen zu lösen. Wie die meisten der Methoden im Bereich der evolutionären Berechnung, benötigt ICA nicht den Gradienten der Funktion in seinem Optimierungsprozess. Aus einer bestimmten Sicht kann ICA als soziales Gegenstück von genetischen Algorithmen (GAs) betrachtet werden. ICA ist das mathematische Modell und die Computersimulation der menschlichen sozialen Evolution, während GAs auf der biologischen Evolution der Spezies basieren. Dieser Algorithmus beginnt, indem eine Reihe von zufälligen Kandidatenlösungen im Suchraum des Optimierungsproblems generiert wird. Die generierten Zufallspunkte werden als Ausgangsländer bezeichnet. Länder in diesem Algorithmus sind das Gegenstück von Chromosomen in GAs und Partikeln in Partikel-Swarm-Optimierung (PSO) und es ist eine Reihe von Werten einer Kandidaten-Lösung von Optimierung Problem. Die Kostenfunktion des Optimierungsproblems bestimmt die Leistung jedes Landes. Auf der Grundlage ihrer Macht werden einige der besten Ausgangsländer (die Länder mit dem geringsten Kosten-Funktionswert), Imperialisten und beginnen, die Kontrolle über andere Länder (die Kolonien) und bilden die ersten Reiche. Zwei Hauptakteure dieses Algorithmus sind Assimilation und Revolution. Assimilation macht die Kolonien jedes Reiches näher an den imperialistischen Staat im Raum der sozialpolitischen Merkmale (Optimierung Suchraum). Die Revolution bewirkt plötzlich zufällige Veränderungen in der Position einiger Länder im Suchraum. Während der Assimilation und Revolution könnte eine Kolonie eine bessere Position erreichen und die Möglichkeit haben, die Kontrolle über das gesamte Reich zu übernehmen und den aktuellen imperialistischen Staat des Reiches zu ersetzen. Imperialistische Konkurrenz ist ein weiterer Teil dieses Algorithmus. Alle Reiche versuchen, dieses Spiel zu gewinnen und Besitz von Kolonien anderer Reiche. In jedem Schritt des Algorithmus, basierend auf ihrer Macht, haben alle Reiche die Möglichkeit, die Kontrolle eines oder mehrerer der Kolonien des schwächsten Reiches zu nehmen. Algorithm setzt sich mit den genannten Schritten fort (Assimilation, Revolution, Wettbewerb), bis eine Stopbedingung erfüllt ist. Die vorstehenden Schritte können als den folgenden Pseudocode zusammengefasst werden.0)Define-Zielfunktion: f ( x ) , x = ( x 1 , x 2 , ... , x d ) ; \{displaystyle f(\mathbf {x},\)quad \mathbf {x} (x_{1},x_{2},\dots x_{d};\) 1) Initialisierung des Algorithmus. Generieren Sie eine zufällige Lösung im Suchraum und erstellen Sie erste Reiche. 2) Assimilation: Kolonien bewegen sich in verschiedene Richtungen zu imperialistischen Staaten. 3) Revolution: Zufällige Veränderungen treten in den Merkmalen einiger Länder auf. 4) Positionswechsel zwischen einer Kolonie und Imperialist. Eine Kolonie mit einer besseren Position als der Imperialist hat die Chance, die Kontrolle des Reiches durch den Ersatz des bestehenden Imperialisten zu übernehmen. 5) Imperialistischer Wettbewerb: Alle Imperialisten konkurrieren um den Besitz von Kolonien untereinander. 6) Beseitigen Sie die Machtlosen Reiche. Schwache Reiche verlieren allmählich ihre Macht und sie werden schließlich eliminiert. 7) Wenn die Stop-Zustand erfüllt ist, stoppen Sie, wenn nicht zu 2.8) End River Formationsdynamik (Rabanal, Rodríguez & Rubio, 2007) Flussbildungsdynamik basiert auf der Nachahmung, wie Wasser Flüsse bildet, indem er Boden und Ablagerung von Sedimenten (die Tropfen wirken als Schwarm). Nach Tropfen verwandeln die Landschaft durch die Erhöhung/Abbau der Höhenlage, Lösungen werden in Form von Pfaden abnehmender Höhen gegeben. Es werden zunehmende Gradienten aufgebaut, und diese Gradienten werden durch nachfolgende Tropfen zu neuen Gradienten zusammengesetzt und die besten verstärken. Diese heuristische Optimierungsmethode wurde 2007 von Rabanal et al. Die Anwendbarkeit von RFD auf andere NP-komplete Probleme wurde untersucht, und der Algorithmus wurde auf Felder wie Routing und Roboternavigation angewendet. Die wichtigsten Anwendungen der RFD finden Sie in einer detaillierten Umfrage. Intelligenter Wassertropfen-Algorithmus (Shah-Hosseini, 2007)Intelligenter Wassertropfen-Algorithmus enthält einige wesentliche Elemente der natürlichen Wassertropfen und Aktionen und Reaktionen, die zwischen dem Bett des Flusses und den Wassertropfen, die innerhalb. Die IWD wurde 2007 erstmals für das Reisevertriebsproblem eingeführt. Fast jeder IWD-Algorithmus besteht aus zwei Teilen: einem Diagramm, das die Rolle des verteilten Speichers spielt, auf dem Böden verschiedener Kanten erhalten bleiben, und dem bewegten Teil des IWD-Algorithmus, der eine Reihe von intelligenten Wassertropfen ist. Diese intelligenten Wassertropfen (IWDs) konkurrieren und kooperieren, um bessere Lösungen zu finden und durch die Veränderung der Böden des Graphen werden die Wege zu besseren Lösungen greifbar. Es wird erwähnt, dass die IWD-basierten Algorithmen mindestens zwei IWDs zur Arbeit benötigen. Der IWD-Algorithmus hat zwei Arten von Parametern: statische und dynamische Parameter. Statische Parameter sind während des Prozesses des IWD-Algorithmus konstant. Dynamische Parameter werden nach jeder Iteration des IWD-Algorithmus wieder initialisiert. Der Pseudo-Code eines IWD-basierten Algorithmus kann in acht Schritten angegeben werden: 1) Statische Parameter initialisation a) Problemdarstellung in Form eines Diagramms b) Einstellwerte für statische Parameter2) Dynamische Parameter initialisation: Boden und Geschwindigkeit von IWDs 3) Verteilung der IWDs auf die Graphik des Problems 4) Lösungskonstruktion durch IWDs zusammen mit Boden und Geschwindigkeit Aktualisierung a) Lokale Bodenaktualisierung auf dem Graph b) Boden und Geschwindigkeit Aktualisierung auf den IWDs 5)Lokale Suche über jede IWD-Lösung (optional) 6)Globale Bodenaktualisierung 7) Gesamtbeste Lösungsaktualisierung 8) Gehen Sie zu Schritt 2, es sei denn, die Kündigungsbedingung ist zufrieden Gravitations-Suchalgorithmus (Rashedi, Nezamabadi-pour & Saryazdi, 2009) Ein gravitationaler Suchalgorithmus basiert auf dem Gesetz der Schwerkraft und dem Begriff der Masseninteraktionen. Der GSA-Algorithmus verwendet die Theorie der Newtonischen Physik und seine Suchermittel sind die Sammlung von Massen. In der GSA gibt es ein isoliertes Massensystem. Mit der Schwerkraft kann jede Masse im System die Situation anderer Massen sehen. Die Gravitationskraft ist daher eine Möglichkeit, Informationen zwischen verschiedenen Massen zu übertragen (Rashedi, Nezamabadi-Pour und Saryazdi 2009). In der GSA werden Agenten als Objekte betrachtet und ihre Leistung wird durch ihre Massen gemessen. Alle diese Objekte ziehen sich durch eine Schwerkraft an, und diese Kraft bewirkt eine Bewegung aller Objekte zu den Objekten mit schwereren Massen. Schwerere Massen entsprechen besseren Lösungen des Problems. Die Position des Mittels entspricht einer Lösung des Problems und seine Masse wird mit einer Fitnessfunktion bestimmt. Durch Zeitverfall werden Massen von der schwersten Masse angezogen, die im Suchraum idealerweise eine optimale Lösung darstellen würde. Die GSA könnte als isoliertes Massensystem betrachtet werden. Es ist wie eine kleine künstliche Massenwelt, die den neutonischen Gesetzen der Gravitation und Bewegung gehorcht. Eine multiobjektive Variante von GSA, genannt MOGSA, wurde erstmals von Hassanzadeh et al.in 2010 vorgeschlagen. Cuckoo-Suche (Yang & Deb, 2009)In der Betriebsforschung ist die Kuckuckuck-Suche ein Optimierungsalgorithmus, den Xin-she Yang und Suash Deb 2009 entwickelt haben. Es wurde inspiriert von dem obligate Brutparasitism einiger Kuckuckspezies, indem sie ihre Eier in die Nester anderer Wirtsvögel (Andere Arten) legen. Wenn ein Wirtsvogel entdeckt, dass die Eier nicht ihre eigenen sind, wird es sie aus dem Nest werfen, oder das Nest verlassen und ein neues bauen. Das Prinzip der Kuckuckus-Suche ist, Eier (neu gefundene Lösungen) in Nester zu setzen und die besten als Kandidaten für die nächste Generation zu halten. Die neuen Lösungen können zufällig verworfen werden (Eier werden aus dem Nest geworfen). Bat algorithm(Yang, 2010) Bat-Algorithmus ist ein swarm-intelligence-basierter Algorithmus, inspiriert durch das Echolokationsverhalten von Mikrobaten. BA bilanziert automatisch die Exploration (Langstreckensprünge rund um den globalen Suchraum, um zu vermeiden, um sich um ein lokales Maximum zu stecken) mit der Ausbeutung (in genauerer Näherem um bekannte gute Lösungen, um lokale Maxima zu finden) durch Steuerung von Lautheit und Pulsemissionsraten simulierter Fledermäuse im mehrdimensionalen Suchraum. Spiraloptimierung (SPO) Algorithmus(Tamura & Yasuda 2011, 2016-2017) Der Spiraloptimierungs-Algorithmus (SPO) ist ein unkompliziertes Suchkonzept, das von Spiralphänomenen in der Natur inspiriert ist. Die Motivation, sich auf Spiralphänomene zu konzentrieren, war die Erkenntnis, dass die Dynamik, die logarithmische Spiralen erzeugen, das Diversifizierungs- und Intensivierungsverhalten teilen. Das Diversifizierungsverhalten kann für eine globale Suche (Exploration) arbeiten und das Verstärkungsverhalten ermöglicht eine intensive Suche um eine aktuelle gefundene gute Lösung (Exploitation). Der SPO-Algorithmus ist ein Multipoint-Suchalgorithmus, der keinen objektiven Funktionsgradienten aufweist, der mehrere Spiralmodelle verwendet, die als deterministische dynamische Systeme beschrieben werden können. Da Suchpunkte logarithmische Spiraltrajektorien in Richtung des gemeinsamen Zentrums folgen, definiert als der aktuelle beste Punkt, können bessere Lösungen gefunden werden und das gemeinsame Zentrum kann aktualisiert werden. Flower Bestäubungsalgorithmus(Yang, 2012) Flower Bestäubungsalgorithmus ist ein metaheuristischer Algorithmus, der von Xin-She Yang entwickelt wurde, basierend auf dem Bestäubungsprozess von Blütenpflanzen. Dieser Algorithmus hat 4 Regeln oder Annahmen: Biotische und Cross-Pollination gilt als globaler Bestäubungsprozess mit Bestäubern, die Levy-Flüge durchführen. Abiotischer und Selbstpollinierung werden als lokale Bestäubung betrachtet. Blumenkonstanz kann als Reproduktionswahrscheinlichkeit proportional zur Ähnlichkeit von zwei Blumen betrachtet werden. Lokale und globale Bestäubung wird durch eine Schaltwahrscheinlichkeit p ε [0, 1 ] \{displaystyle p\in [0,1}] gesteuert. Aufgrund der physikalischen Nähe und anderer Faktoren wie Wind kann lokale Bestäubung einen signifikanten Anteil q in den gesamten Bestäubungsaktivitäten haben. Diese Regeln können in folgende Aktualisierungsgleichungen übersetzt werden: x i t + 1 = x i t + L ( x i t - g χ ) \{displaystyle * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * x i t + 1 = x i t+ ε ( x i t - x k t ) \{displaystyle * *********************************************************************************************** (x_{i}{t}-x_{k}^{t) wobei x i t \{displaystyle x_{i}^{t der Lösungsvektor ist und g χ \{displaystyle g*}_{ der aktuelle, bisher bei der Iteration am besten gefunden wird. Die Schaltwahrscheinlichkeit zwischen zwei Gleichungen während der Iterationen ist p \{displaystyle p} . Zusätzlich ist ε \{displaystyle \epsilon } eine zufällige Zahl, die aus einer einheitlichen Verteilung gezogen wird. L \{displaystyle L} ist eine Schrittgröße aus einer Lévy-Verteilung gezogen. Flüge von Lévy Lévy Schritte ist ein leistungsfähiges zufälliges Gehen, da sowohl globale als auch lokale Suchfunktionen gleichzeitig durchgeführt werden können. Im Gegensatz zu den Standard-Flom-Wanderungen haben Lévy-Flüge gelegentlich lange Sprünge, die es dem Algorithmus ermöglichen, alle lokalen Täler auszuspringen. Lévy Stufen folgen der folgenden Annäherung: L ∼ 1 s 1 + β , \{displaystyle L\sim \{frac 1}{s^{1+\beta }},}, wo β \{displaystyle \beta } der Lévy Exponent ist. Es kann schwierig sein, Lévy-Schritte richtig zu zeichnen, und eine einfache Möglichkeit, Lévy-Flüge s \{displaystyle s} ist, zwei normale Distributionen u \{displaystyle u} und v \{displaystyle v} durch eine Transformation s = u | v | 1 + β , \{displaystyle s={frac u}{\\\\\\\\\\\\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\ Heterogene verteilte Bienen Algorithm (Tkach et al,. 2013)Der Heterogene Distributed Bees Algorithm (HDBA) auch als Modified Distributed Bees Algorithm (MDBA) bekannt, ist ein multiagent metaheuristischer Algorithmus, der 2013 von Tkach und seinen Mitarbeitern eingeführt wurde und als Teil seiner PhD-Dissertation entwickelt wurde. HDBA nutzt probabilistische Technik, die sich vom Futterverhalten der Bienen inspirieren lässt. Es ermöglicht, kombinatorische Optimierungsprobleme mit mehreren heterogenen Mitteln zu lösen, die unterschiedliche Fähigkeiten und Leistungen besitzen. Der endgültige Entscheidungsmechanismus verwendet eine Radwahlregel, wobei jeder Agent eine Wahrscheinlichkeit hat, mit der er eine Lösung wählt. Es wurde zunächst für den Fall heterogener Sensoren im Zielerkennungsproblem zur Verbesserung der Systemleistung durch Korrelieren der Dienstfunktion der Sensoren mit dem Wert ihrer Leistungen angewendet. Anschließend wurde es erfolgreich auf andere Probleme angewendet, darunter das Problem der Zuordnung von Polizeibeamten zu Straftatfällen und der Herstellung von augenblicklichen Lösungen für das Wanderverkäuferproblem. Künstlicher Ökosystemalgorithmus (Baczyński, 2013)Künstlicher Ökosystemalgorithmus (AEA) ist eine probabilistische Optimierungsmethode, die von einigen Phänomenen inspiriert wird, die in natürlichen Ökosystemen vorkommen. Beziehungen zwischen den einzelnen Personen werden sowohl durch ihre gegenseitigen Beziehungen innerhalb einer einzigen Gruppe als auch durch die Beziehungen zwischen den einzelnen Personen, die zu verschiedenen Gruppen gehören, als Teil des ökologischen Systems modelliert. Es gibt drei Hauptarten von Organismen: Pflanzen, Herbivoren und Raubtiere. Alle Arten von Organismen reproduzieren (über und mutieren) innerhalb ihrer eigenen Spezies. Als Methode enthält es einige Evolutionary Algorithmen und PSO-Elemente mit zusätzlichen Erweiterungen. Es ist ziemlich kompliziert, aber es hat sich bewährt, sowohl kontinuierliche als auch kombinatorische Optimierungsprobleme zu lösen. Cooperative Group Optimization (2014)Cooperative Group Optimization (CGO) System ist ein metaheuristischer Rahmen für die Implementierung von Algorithmeninstanzen durch die Integration der Vorteile der kooperativen Gruppe und des Low-Level-Algorithmus-Portfolios. Nach dem naturgetreuen Paradigma einer Genossenschaftsgruppe erforschen die Agenten nicht nur parallel zu ihrem individuellen Gedächtnis, sondern kooperieren auch mit ihren Kollegen durch den Gruppenspeicher. Jeder Agent verfügt über ein Portfolio von (heterogenen) eingebetteten Suchheuristiken (ESHs), in denen jede ESH die Gruppe in einen eigenständigen CGO-Fall treiben kann, und hybride CGO-Fälle in einem algorithmischen Raum können durch Low-Level-Kooperative Suche unter einem Algorithmus-Portfolio (von ESHs) durch individuelles Speicher-Sharing definiert werden. Der Optimierungsprozess könnte auch durch die Kodierung von Wissen in der Suchlandschaft durch einen passiven Gruppenführer erleichtert werden. Es wurde sowohl auf numerische als auch kombinatorische Optimierungsprobleme angewendet. Künstliche Schwarm-Intelligenz (Rosenberg, 2014) Künstliche Schwarm-Intelligenz bezieht sich auf ein in Echtzeit geschlossenes System menschlicher Nutzer, das über das Internet verbunden ist und in einem Rahmen strukturiert ist, der nach natürlichen Schwarmen so modelliert ist, dass es die kollektive Weisheit der Gruppe als eine einheitliche, aufkommende Intelligenz hervorruft. Auf diese Weise können menschliche Schwarme Fragen beantworten, Vorhersagen machen, Entscheidungen treffen und Probleme lösen, indem sie gemeinsam eine Vielzahl von Optionen erforscht und auf bevorzugte Lösungen synchron zusammenwirken. Die von Dr. Louis Rosenberg im Jahr 2014 erfundene ASI-Methodik ist für ihre Fähigkeit, genaue kollektive Vorhersagen zu machen, die die einzelnen Mitglieder des Schwarms übertreffen. Im Jahr 2016 wurde eine künstliche Kriegsgeheimnis von Unanimous A.I von einem Reporter herausgefordert, die Gewinner des Kentucky Derby vorherzusagen, und erfolgreich die ersten vier Pferde, um 540 bis 1 Quoten zu schlagen. Kollisionskörperoptimierung (Kaveh und Mahdavi, 2014) Der CBO-Algorithmus wurde 2014 von Kaveh und Mahdavi erstellt, basierend auf den Gesetzen von Dynamik und Energie. Dieser Algorithmus hängt nicht von einem internen Parameter ab und es ist auch extrem einfach, in verschiedenen Arten von Problemen im Engineering zu implementieren und zu verwenden und zu verwenden. Duelist Algorithm (Biyanto, 2016)Duelist-Algorithmus bezieht sich auf einen Gen-basierten Optimierungs-Algorithmus ähnlich Genetic Algorithms. Duelist Algorithm beginnt mit einem ersten Satz von Duelists. Das Duell ist, den Gewinner und Verlierer zu bestimmen. Der Verlierer lernt vom Sieger, während der Sieger versuchen ihre neue Fähigkeiten oder Technik, die ihre Kampffähigkeit verbessern kann. Einige Duellisten mit höchsten Kampffähigkeiten werden als Champion bezeichnet. Der Champion trainiert eine neue Duelist wie ihre Fähigkeiten. Die neue Duelist wird als Vertreterin eines jeden Champions am Turnier teilnehmen. Alle Duelist werden neu bewertet, und die Duelists mit schlimmsten Kampffähigkeiten werden eliminiert, um die Menge der Duelists zu erhalten. Harris Falkenoptimierung (Heidari et al.,. 2019)Harris hawks Optimierer (HHO) inspiriert die Jagdstrategien von Harriss Falke und entweichende Muster von Kaninchen in der Natur. Killer Whale Algorithm (Biyanto, 2016)Killer Whale Algorithm ist ein Algorithmus, der vom Killer Whale Life inspiriert wird. Die Philosophie des Algorithmus ist die Muster der Bewegung Killer Whale in der Beute Jagd und Killer Wal soziale Struktur. Die Neuheit dieses Algorithmus beinhaltet "Memorize-Fähigkeit" von Killer Whale im Algorithmus. Rain Water Algorithm (Biyanto, 2017) "Physische Bewegungen von Regentropfen durch die Nutzung von Newton's Law Motion" wurde die Autoren inspiriert, diesen Algorithmus zu schaffen. Jeder Regentropfen stellt als zufällige Werte optimierter Variablen dar, die sich in Masse und Höhe unterscheiden. Es wird auf den Boden fallen, indem es "die freie Fallbewegung" mit der Geschwindigkeit ist Quadratwurzel der Schwerkraft Beschleunigung Zeiterhöhung. Die nächste Bewegung ist "gleichmäßig beschleunigte Bewegung" entlang der Regentropfenfahrt, um den niedrigsten Platz am Boden zu erreichen. Der niedrigste Platz im Boden ist eine objektive Funktion dieses Algorithmus. Maß and Energy Balances Algorithm (Biyanto, 2018) Massen- und Energiebilanzen ist eine grundlegende "Gesetze der Physik", die besagt, dass Masse weder produziert noch zerstört werden kann. Es ist nur konserviert. Ebenso grundlegend ist das Gesetz zur Erhaltung der Energie. Obwohl sich Energie in Form ändern kann, kann sie auch nicht erzeugt oder zerstört werden. Die Schönheit dieses Algorithmus ist die Fähigkeit, die globale optimale Lösung zu erreichen, indem gleichzeitig entweder "minimieren und maximieren Sie die Suchmethode". Hydrologischer Kreislauf Algorithm (Wedyan et al,. 2017) Ein neuer, naturinspirierter Optimierungsalgorithmus namens Hydrologischer Kreislauf Algorithm (HCA) wird auf der Grundlage der kontinuierlichen Bewegung von Wasser in der Natur vorgeschlagen. Im HCA durchläuft eine Wassertropfensammlung verschiedene hydrologische Wasserkreislaufstufen, wie Strömung, Verdampfung, Kondensation und Fällung. Jede Phase spielt eine wichtige Rolle bei der Entwicklung von Lösungen und der Vermeidung vorzeitiger Konvergenz. Die HCA teilt Informationen durch direkte und indirekte Kommunikation unter den Wassertropfen, was die Lösungsqualität verbessert. HCA bietet einen alternativen Ansatz, um verschiedene Arten von Optimierungsproblemen zu bewältigen sowie einen Gesamtrahmen für wasserbasierte Partikelalgorithmen im Allgemeinen. Kaiser Pinguins Colony (Harifi et al,. 2019) Dieser Algorithmus ist ein neuer metaheuristischer Algorithmus, der von dem Verhalten von Kaiserpinguinen inspiriert ist, die in der Antarktis leben. EPC wird durch die Körperwärmestrahlung der Pinguine und ihre spiralförmige Bewegung in ihrer Kolonie gesteuert. Die Kaiserpinguine in der Kolonie versuchen, die entsprechende Wärme zu erzeugen und ihre Körpertemperatur zu regulieren, und diese Wärme wird durch die Bewegung der Pinguine vollständig koordiniert und kontrolliert. Momentum Balance Algorithm (MBA) (Biyanto et al.,. 2019)Momentum Balance ist eine von drei grundlegenden "Gesetzen der Physik", die sagt Masse, Energie und Dynamik ist nur konserviert. Die Auslastung der Impulsbilanz wurde in vielen Anwendungen vorgeschlagen. In dieser Forschung wurde die Schwungbilanz angenommen, um die perfekt elastische Kollision zu erhalten. Bei einer idealen, perfekt elastischen Kollision gibt es keine kinetischen Energieverluste in andere Formen wie potentielle Energie, Wärme und Lärm. Die Schönheit dieses Algorithmus ist einfach so einfach wie deterministische Optimierungsalgorithmen, aber der Momentum Balance Algorithmus hat die Fähigkeit, die globale optimale Lösung zu erreichen. Shuffled Shepherd Optimization Algorithm (SSOA) (Kaveh und Zaerreza, 2020) Dieses Verfahren ist ein neuer multi-community meta-heuristischer Optimierungsalgorithmus. In diesem Algorithmus, Die Mittel werden zunächst in Multi-Kommunitäten getrennt und der Optimierungsprozess wird dann durchgeführt, um das Verhalten eines Hirten in der Natur, der auf jeder Gemeinschaft arbeitet, nachzuahmen. Ein Mayfly-Optimierungsalgorithmus (MA) (Zervoudakis & Tsafarakis, 2020) Der Mayfly-Optimierungsalgorithmus wurde entwickelt, um sowohl kontinuierliche als auch diskrete Optimierungsprobleme zu lösen und ist vom Flugverhalten und dem Gegenprozess von Mayfs inspiriert. Die Prozesse des nuptialen Tanzes und des zufälligen Fluges verbessern das Gleichgewicht zwischen den Explorations- und Ausbeutungseigenschaften des Algorithmus und unterstützen seine Flucht aus lokalen Opima. Die Leistung des Mayfly-Algorithmus ist überlegen, die von anderen beliebten Metaheuristiken wie PSO, DE, GA und FA in Bezug auf Konvergenzrate und Konvergenzgeschwindigkeit. Politischer Optimizer (PO) (Qamar Askari, Irfan Younas & Mehreen Saeed, 2020) Politischer Optimizer (PO) ist ein menschlicher Sozialverhaltens-basierter Algorithmus, der von einem mehrparteiigen politischen System inspiriert wird. Die Quelle der Inspiration wird als eine Reihe von 5 Phasen formuliert: Parteibildung und Wahlkreis Zuteilung, Parteiwechsel, Wahlkampf, Wahlen zwischen Parteien und parlamentarische Angelegenheiten. PO hat zwei einzigartige Merkmale: logische Teilung der Bevölkerung, um jeder Kandidatenlösung und der neuzeitlich-pätesten Positionsaktualisierungsstrategie (RPPUS) eine doppelte Rolle zuzuordnen. PO zeigt hervorragende Leistung gegen 15 bekannte Metaheuristiken für 50 unimodale und multimodale Benchmark-Funktionen und 4 technische Probleme. Heap-Based Optimizer (HBO) (Qamar Askari, Mehreen Saeed, Irfan Younas, 2020) HBO ist eine humane sozialverhaltensbasierte Metaheuristik, die von der Corporate Rank Hierarchie und Interaktion zwischen den in der Hierarchie arrangierten Mitarbeitern inspiriert ist. Die Einzigartigkeit von HBO ist die Nutzung der Heap-Datenstruktur, um die hierarchische Anordnung der Mitarbeiter und die Einführung eines Parameters (γ) zu modellieren, um alternativ Exploration und Ausbeutung zu integrieren. Darüber hinaus werden drei Gleichungen, die für drei Phasen von HBO abgeleitet werden, probabilistisch zu einer Bilanzexploration und -ausbeutung zusammengefasst. HBO zeigt enorme Leistung für 97 Benchmarks und 3 Maschinenbauprobleme. Forensischer Untersuchungsalgorithmus (FBI) (JS Chou und NM Nguyen, 2020) Die Hauptmotivation für die Entwicklung eines neuen Algorithmus ist seine Fähigkeit, verschiedene Optimierungsprobleme effektiv und effizient zu lösen. Ein neuartiges Optimierungsverfahren, der forensbasierte Untersuchungsalgorithmus (FBI), wird entwickelt, um globale Lösungen für kontinuierliche nichtlineare Funktionen mit geringem Rechenaufwand und hoher Genauigkeit zu ermitteln. Das FBI ist inspiriert von dem verdächtigen Untersuchungs-Ort-Angriffsprozess von Polizisten. Hauptmerkmale des FBI: (1) Das FBI ist ein parametrierfreier Optimierungsalgorithmus; (2) das FBI hat bemerkenswert die bekannten und neu entwickelten Algorithmen überholt; (3) das FBI hat kurze Rechenzeit und erreicht schnell die optimalen Lösungen bei der Lösung von Problemen; (4) das FBI ist wirksam bei der Lösung hochdimensionaler Probleme (D=1000;) und (5) die FBI-Struktur hat zwei Teams, die Exploration und Ausbeutung gut ausgleichen. Details finden Sie unter: Chou J-S, Nguyen N-M, FBI inspirierte Meta-Optimierung, Applied Soft Computing, 2020:106339, ISSN 1568-4946, https://doi.org/10.1016/j.asoc.2020.106339 Jellyfish Search (JS) (JS Chou und DN Truong, 2021) Jellyfish Search (JS) Optimizer ist vom Verhalten von Quallen im Ozean inspiriert. Die Simulation des Suchverhaltens von Quallen beinhaltet ihre Folge des Meeresstroms, ihre Bewegungen innerhalb eines Quallenschwarms (Aktivbewegungen und passive Bewegungen), einen Zeitregelmechanismus zum Schalten zwischen diesen Bewegungen und ihre Konvergenz in Quallenblüten. Der neue Algorithmus wird auf Benchmark-Funktionen und Optimierungsproblemen erfolgreich getestet. Insbesondere hat JS nur zwei Kontrollparameter, die Bevölkerungsgröße und Anzahl der Iterationen sind. Daher ist JS sehr einfach zu bedienen und möglicherweise ein ausgezeichneter metaheuristischer Algorithmus zur Lösung von Optimierungsproblemen. Golden Eagle Optimizer (GEO) (Mohammadi-Balani et al,. 2020)Golden Eagle Optimizer (GEO) ist ein bevölkerungsbasierter, waffe-intelligent natur inspirierter metaheuristischer Algorithmus, der durch das Jagdverhalten von goldenen Adlern entsteht. Der Algorithmus modelliert dieses Verhalten, indem der Geschwindigkeitsvektor von goldenen Adlern in Komponenten unterteilt wird: a) Angriffsvektor und b) Kreuzvektor. Der Angriffsvektor für jeden goldenen Adler (Suchmittel) beginnt an der aktuellen Position den goldenen Adler und endet an der Stelle des Prey in der Erinnerung jedes goldenen Adlers. Das Prey für jeden goldenen Adler ist der beste Ort, den er bisher besucht hat. Goldene Adler kreisen um die Beute in hypothetischen Hypersphären. Der Kreuzfahrtvektor ist ein Vektor, der für jeden goldenen Adler zur hypothetischen Hypersphäre tangent. Das Originalpapier enthält sowohl ein- als auch mehrobjektive Versionen des Algorithmus. Quellcode, Toolbox und grafische Benutzeroberfläche für Golden Eagle Optimizer (GEO) und Multi-Objective Golden Eagle Optimizer (MOGEO) werden ebenfalls für MATLAB entwickelt. Kritik an der Metaphermethodik Während einzelne metaphorinspirierte Metaheuristiken bemerkenswert effektive Lösungen für spezifische Probleme hervorgebracht haben, haben Metapher-inspirierte Metaheuristiken im Allgemeinen Kritik in der Forschungsgemeinschaft angezogen, weil sie ihr Mangel an Effektivität oder Neuheit hinter einer aufwendigen Metapher verbergen. Kenneth Sörensen merkte an, dass: In den letzten Jahren hat der Bereich der kombinatorischen Optimierung einen wahren Tsunami neuartiger metaheuristischer Methoden erlebt, die meisten von ihnen auf einer Metapher eines natürlichen oder manngemachten Prozesses basieren. Das Verhalten von nahezu jeder Art von Insekten, der Fluss von Wasser, Musiker, die zusammen spielen – es scheint, dass keine Idee zu weit gefegt ist, um als Inspiration zu dienen, noch eine weitere Metaheuristik zu starten. [I] wird argumentieren, dass diese Linie der Forschung droht, den Bereich der Metaheuristik von der wissenschaftlichen Strenge weg zu führen. Sörensen und Glover erklärten: Eine große (und zunehmende) Anzahl von Publikationen konzentriert sich auf die Entwicklung neuer metaheuristischer Rahmenwerke auf der Grundlage von Metaphern. Die Liste der natürlichen oder künstlichen Prozesse, die als Grundlage für einen metaheuristischen Rahmen verwendet wurden, umfasst nun so vielfältige Prozesse wie Bakterienforstung, Flussbildung, Biogeographie, Musiker, die zusammen spielen, Elektromagnetismus, Schwerkraft, Kolonisierung durch ein Reich, Minenstrahlen, Ligameisterschaften, Wolken und so weiter. Eine wichtige Unterkategorie findet sich in Metaheuristiken auf Basis des tierischen Verhaltens. Ameisen, Bienen, Fledermäuse, Wölfe, Katzen, Fliege, Adler, Delfine, Frösche, Lachs, Geier, Termiten, Fliegen und viele andere, wurden alle verwendet, um eine neue Metaheuristik zu inspirieren[]. In der Regel ist die Veröffentlichung von Beiträgen zu Metapher-basierten Metaheuristiken auf Zeitschriften und Konferenzen beschränkt, aber einige jüngste Ausnahmen zu dieser Regel sind zu finden. Sörensen (2013) gibt an, dass die Forschung in dieser Richtung grundsätzlich fehlerhaft ist. Vor allem betont der Autor, dass die Neuheit der zugrunde liegenden Metapher den resultierenden Rahmenroman nicht automatisch macht". Im Gegenteil, es gibt immer mehr Beweise, dass sehr wenige der metaphorbasierten Methoden in jedem interessanten Sinne neu sind. Springers Journal of Heuristics hat ihre redaktionelle Politik dahingehend aktualisiert, dass: Die Bereitstellung neuer Paradigmen ist nur akzeptabel, wenn sie innovative Grundideen enthalten, wie sie in klassischen Rahmen wie genetische Algorithmen eingebettet sind, tabusuche und simulierte Annealing. Das Journal of Heuristics vermeidet die Veröffentlichung von Artikeln, die alte Ideen in Methoden umpacken und einbetten, die behauptet werden, auf Metaphern von natürlichen oder künstlichen Systemen und Prozessen basieren. Diese so genannten neuartigen Methoden verwenden Analogien, die sich von intelligenten Wassertropfen, Musikern, die Jazz, imperialistische Gesellschaften, Liepfrogs, Kangaroos, allen Arten von Swarmen und Insekten und sogar Minenblasprozessen (Sörensen, 2013) reichen. Wenn ein Forscher eine Metapher verwendet, um seine eigenen Ideen über eine neue Methode zu stimulieren, muss das Verfahren dennoch in metaphorfreie Sprache übersetzt werden, so dass die angewandten Strategien klar verstanden werden können und ihre Neuheit deutlich sichtbar gemacht wird. (Siehe die Artikel 2 und 3 unten.) Metaphern sind billig und einfach zu kommen. Ihre Verwendung zu "Fensterkleid" eine Methode ist nicht akzeptabel[]". Implementierungen sollten durch die Verwendung von Standard-Optimierungsterminologie erläutert werden, wo eine Lösung als Lösung bezeichnet wird und nicht etwas anderes mit einer obskuren Metapher (z.B. Harmonie, Fliegen, Fledermäuse, Länder usw.)[...] Das Journal of Heuristics unterstützt Sörensensens Ansicht, dass metaphorbasierte „neue“ Methoden nicht veröffentlicht werden sollten, wenn sie keinen Beitrag zu ihrem Bereich nachweisen können. Die Umbenennung bestehender Konzepte zählt nicht als Beitrag. Auch wenn diese Methoden oft als „neu“ bezeichnet werden, präsentieren viele keine neuen Ideen, außer der gelegentlichen Randvariante einer bereits bestehenden Methodik. Diese Methoden sollten nicht den Zeitschriftenraum von wirklich innovativen Ideen und Forschung. Da sie nicht den Standard-Optimierungsvokabular verwenden, sind sie unnötig schwer zu verstehen. Die Politik der Springer Zeitschrift 4OR - A Quarterly Journal of Operations Research heißt: Die Betonung auf wissenschaftlicher Strenge und auf Innovation bedeutet insbesondere, dass die Zeitschrift keine Artikel publiziert, die einfach verkleidete Varianten bekannter Methoden ohne ausreichende Validierung vorschlagen (z.B. Metaheuristiken, die allein auf der Grundlage metaphorischer Vergleiche mit natürlichen oder künstlichen Systemen und Prozessen als wirksam erachtet werden). Neue Methoden müssen in metaphorfreier Sprache präsentiert werden, indem sie ihre Beziehung zu klassischen Paradigmen aufbauen. Ihre Eigenschaften müssen auf der Grundlage wissenschaftlich überzeugender Argumente festgelegt werden: mathematische Beweise, kontrollierte Experimente, objektive Vergleiche usw. Siehe auch Swarm Intelligence # Algorithms Hinweise Referenzen Sörensen, Kenneth; Sevaux, Marc; Glover, Fred (2017-01-16)."Eine Geschichte der Metaheuristik" (PDF.) In Martí, Rafael; Panos, Pardalos; Resende, Mauricio (Hrsg.). Handbuch der Heuristik.Springer.ISBN 978-3-319-07123-7.Sörensen, Kenneth (2015)."Metaheuristik-die Metapher exponiert". International Transactions in Operational Research.22: 3–18.CiteSeerX 10.1.1.470.3422.doi:10.1111/itor.12001. Lones, Michael A. (2014)."Metaheuristik in natur inspirierten Algorithmen". Proceedings of the 2014 Konferenzbegleiter auf Genetische und evolutionäre Rechenbegleiter - GECCO Comp '14.pp.1419–22.CiteSeerX 10.1.1.699.1825.doi:10.1145/2598394.2609841.ISBN 9781450328814.S2CID 14997975. Fister, Iztok; Yang, Xin-She; Fister, Iztok; Brest, Janez; Fister, Dušan (2013)."Ein kurzer Überblick über Natur inspirierte Algorithmen zur Optimierung". Elektrotehniški Vestnik.arXiv:1307.4186 Externe Links Evolutionary Computation Bestiary – ein zungenin-cheek-Konto aller seltsamen, sogar bizarren metaphorbasierten Metaheuristiken da draußen in der weiten Welt des wissenschaftlichen Verlags The Science Matrix's List of Metaheuristic – eine vollständige Liste von metaheuristischen Algorithmen. Die Liste kann einfach nach Name, Autor oder Jahr filtern und gibt den Link zur Hauptveröffentlichung jedes Algorithmus.