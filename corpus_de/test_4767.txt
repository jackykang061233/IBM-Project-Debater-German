Bootstrap Aggregating, auch als Bindeglied (von Sprinttrap Aggregating) bezeichnet, ist ein maschinenlesbares Meta-algorithm, das die Stabilität und Genauigkeit von maschinenlesbaren Lernalgorithmen, die in statistischer Einstufung und Regression verwendet werden. Es verringert auch die Varianz und hilft, Überrüstung zu vermeiden. Obwohl es in der Regel auf die Entscheidung Baummethoden angewendet wird, kann es mit jeder Art von Methode verwendet werden. Baging ist ein Sonderfall des durchschnittlichen Konzepts. Beschreibung der Technik aufgrund einer Standard-Ausbildungseinrichtung D Memestyle D} der Größe n erzeugt die Beatmung m neue Ausbildungssets D i {\displaystyle D_{i}, jeder Größe n′, durch Probenahme von D einheitlich und mit Ersatz. Durch die Probenahme mit Ersatz können einige Beobachtungen in jedem D i {\displaystyle D_{i} wiederholen.Wenn n′=n, dann für große n der Set D i {\displaystyle D_{i} wird erwartet, dass der Bruchteil (1 - 1/e) (≈63,2) % der einzigartigen Beispiele von D, der Rest ist doppelt. Diese Art der Probe ist als Stichprobe bekannt. Sampling mit Ersatz gewährleistet, dass jeder Bootstrap von seinen Peers unabhängig ist, da er bei der Probenahme nicht auf frühere ausgewählte Proben angewiesen ist. M-Modelle werden dann mit den oben genannten m Bootstrap-Proben ausgestattet und mit dem durchschnittlichen Output (für Regression) oder der Abstimmung (zur Einstufung) kombiniert. Baging führt zu „Verbesserungen für instabile Verfahren“, die zum Beispiel künstliche Neuralnetze, Klassifikations- und Regressionsbäume und die Auswahl in linearer Regression umfassen. Man zeigte sich, dass man das Vorbildlernen verbessern konnte. Andererseits kann es die Leistung stabiler Methoden wie K-Nearest-Nachbarn leicht beeinträchtigen. Prozess des Algorithmus Originaldatenset Der ursprüngliche Datensatz enthält mehrere Einträge von Proben von s1 bis s5. Jede Probe hat fünf Merkmale (Gen 1 bis Gene 5). Alle Proben werden als Ja oder Nein für ein Einstufungsproblem gekennzeichnet. Schaffung von färöten Datensets In Anbetracht der oben genannten Tabelle, um eine neue Probe einzuordnen, muss zunächst ein gehobener Datenset mit den Daten des Originaldatenset erstellt werden. In der Regel ist das Set der Originaldatenset oder kleiner. In diesem Beispiel ist die Größe fünf (s1 über s5). Es wird eine zufällige Auswahl von Proben aus dem Originaldatenset erstellt. Wiederholungen sind zulässig. Jegliche Proben, die nicht für die Sprinttraed Dataset ausgewählt werden, werden in einem separaten Datensatz namens Out-of-bag-Datenset platziert. Siehe unten ein Beispiel Sprints. Es hat fünf Einträge (gleiche Größe wie die ursprüngliche Datenset). Es gibt doppelte Einträge wie zwei s3, da die Einträge zufällig mit Ersatz ausgewählt werden. Dieser Schritt wird wiederholen, um m Bootstraed Datasets zu generieren. Schaffung von Bäumen Ein Beschlussbaum wird für jeden Bootstrappen mit zufällig ausgewählten Spaltenwerten geschaffen, um die Knoten aufzuspalten. Anklage gegen mehrere Entscheidungsbäume Wenn eine neue Stichprobe in die Tabelle aufgenommen wird, wird der gehobene Datensatz verwendet, um den Wert des neuen Eintrags zu bestimmen. Die neue Probe wird im Zufallswald getestet, der von jedem gehobenen Datenset erstellt wird, und jeder Baum stellt einen Klassenwert für die neue Probe. Für die Einstufung wird ein Verfahren zur Stimmabgabe verwendet, um das Endergebnis zu bestimmen, bei dem das Ergebnis, das am häufigsten durch den Zufallswald hergestellt wurde, das Ergebnis für die Probe ist. Zur Regression wird der durchschnittliche Klassenwert der Bäume zugewiesen. Nach Prüfung der Probe im Zufallswald wird ein Klassenwert der Probe zugewiesen und in die Tabelle aufgenommen. Algorithm (Klassenbildung) Für die Einstufung verwenden Sie eine Ausbildungseinrichtung D WELLdisplaystyle D} , Inducer I HANAdisplaystyle I} und die Anzahl der Sprint-Probens m Memedisplaystyle m} als Input. Produktion einer Klasse C   {\displaystyle C C*} als Output-Set m {\displaystyle m} neue Ausbildungssets D i HANAstyle D_{i} , von D Memestyle D} mit Ersatzklasse C i {\displaystyle C_{i} werden aus jedem Set D i {\displaystyle D_{i} mit I Memedisplaystyle I} hergestellt, um die Einstufung von D i {\displaystyle D_{i} zu bestimmen Letztlich wird C {\ {\displaystyle C C*} durch Verwendung der zuvor geschaffenen Klassenzeichen C i {\displaystyle C_{i} auf der ursprünglichen Datenreihe D Memestyle D} , die am häufigsten von den Unterklassen C i {\displaystyle C_{i} vorhergesagte Einstufung ist die letzte Klassifikation für i = 1 bis m { D' = Sprint Stichproben von D (sam mit Ersatz) Ci(D) = I(D) * * * * * * * Beispiel: Ozondaten Um die Grundprinzipien der Beatmung zu verdeutlichen, ist unten eine Analyse der Beziehung zwischen Ozon und Temperatur (Daten von Rousseeuw und Leroy (1986) in R. Die Beziehung zwischen Temperatur und Ozon scheint in diesem Datensatz nicht linear zu sein, basierend auf der Zersplitterung. mathematische Beschreibung dieser Beziehung werden LOESS-Führer (mit Bandbreite 0,5) verwendet. Mehr als der Aufbau eines einzigen glatteren für die vollständigen Daten wurden 100 Bootstrap Proben entnommen. Jede Probe besteht aus einem zufälligen Teil der ursprünglichen Daten und hält einen Blick auf die Verteilung und Variabilität des Master Set. Für jeden Sprinttrap-Test war ein LOESS-Blätter fit. Vorhersagen dieser 100 glatteren wurden dann über die Datenpalette hinweg erstellt. Die schwarzen Linien stellen diese ursprünglichen Vorhersagen dar. In ihren Prognosen fehlt es an einer Einigung und ist tendenziell zu überlasten, um ihre Datenpunkte zu überlasten: dies wird durch den fragwürdigen Fluss der Linien deutlich. Indem wir den Durchschnitt von 100 glatteren, die jeweils einem Teil der ursprünglichen Daten entsprechen, kommen wir zu einem Könger (rote Linie). Der Fluss der roten Linie ist stabil und entspricht nicht übermäßig allen Datenpunkten (s). Vorteile und Nachteile Vorteile: Viele schwache Lernende, die in der Regel einen einzigen Lernenden über das gesamte Set auslösen, und haben weniger überhöhte Unterschiede in Hochvarianz-Datensets. Kann parallel durchgeführt werden, da jeder einzelne Sprint auf eigenem Weg vor der Kombination verarbeitet werden kann Nachteile: In einer mit hohen Verzerrungen versehenen Daten wird die Beatmung auch hohe Verzerrungen in ihrer Gesamtheit ausüben Verlust der Auslegungsfähigkeit eines Modells. Kann je nach Datensetgeschichte berechnet werden Das Konzept der Sprinttrap Aggregation ist aus dem Konzept von Sprinttrapping abgeleitet, das von der Firma Scott Efron entwickelt wurde. Bootstrap Aggregating wurde von Leo Breiman vorgeschlagen, die auch den abgekürzten Begriffsbeutel (Pappe Aggregating) gelobt haben. Breiman entwickelte 1994 das Konzept der Auffüllung, um die Einstufung durch die Kombination von Klassifikationen von zufällig erzeugten Ausbildungssets zu verbessern. Er argumentierte: "Wenn sich das Lernangebot erheblich verändern kann, kann die Vorhersehbarkeit dadurch verbessert werden. Siehe auch Förderung (meta-algorithm)Bootstrapping (statistics) Kreuzvalidierung (statistische) Fehler-Abfall-Abfall zufällige Subspace-Methode (Vertriebsbeutelung)Resamped-effektivanalyse: Klassifikations- und Regressionsbäume BezugnahmeFurther Breiman, Leo (1996). "Hervorhersagen". Maschinenbau.24 (2): 123-140.CiteSeerX 10.1.1.32.9399.doi:10.1007/BF00058655.S2CID 47328136. Alfaro, E, Gámez, M. und García, N. (2012)."adabag: Ein R-Paket für die Einstufung mit AdaBoost. M1, AdaBoost-SAMME und Bagging. Kotsiantis, Sotiris (2014). " Lösungsansätze für Klassifikationsprobleme: eine Umfrage. Wissen Eng.review.29 (1): 78–100.doi:10.1017/S0269888913000313.Boehmke, Southampton; Greenwell, Barry. Hands-On-Maschine Learning with R. Chapman & Hall.pp.191–202.ISBN K.: 0038-49568-5.A bin die Tasche, sack oder mit Vorrichtungen, die in der Regel von der amerikanischen Subkultur von Dornos verwendet werden. A Bindegestiff war ein anderer Name für ein Dorno, der eine Bindegewissheit ausübte. Das Bindegeflecht ist kollidierend bekannt als die "Brustnket", insbesondere innerhalb der Nordosten-Gemeinschaft. Laut James Bstart in seinem Roman, A Life for the Stars, war ein Schlupf, der ein anderer Hemmschuh für die Bindegewissheit heimsuchte, so dass das Kolloquium steif. In der modernen populären Kultur wird die Bindegelässe als Aufkleber mit Geweben oder einer Decken, die rund ein Ende für die Ausführung von Gegenständen ist, dargestellt, wobei die gesamte Bandbreite über die Schulter ausgeführt wird. Diese übertragene Kraft auf die Schulter, die eine längere Lebensdauer und einen komfortablen Griff ermöglichte, vor allem mit größeren Lasten. Insbesondere in Karikaturen haben die Säcke der Bindehaut in der Regel ein Polizei- oder Bandanna-Design. In der Praxis kann jedoch das Bindegebirge viele Formen annehmen. Ein Beispiel für die Aufkleber-Grenze ist in der Abbildung zu sehen The Runaway, der von Norman Rockwell für die Abdeckung des 19. September 1958, Ausgabe der Samstagabendpost erstellt wurde. Obwohl Bindegefälle selten mehr verwendet werden, sind sie in der populären Kultur immer noch weit verbreitet als aachronismus. Der Begriff Bindegedanke kann vom deutschen Wörter, d. h. etwas, das in einem Decken und an einem Strang für die Ausführung (vgl. Original Middle Dutch bundel) eingebaut wurde oder als Hafenmanteau von Bindemittel und Spindel entstanden ist. Pulverpack Bin How ist auch ein Begriff, der in Forensics verwendet wird. Es ist der Name für ein Stück Papier, das in ein Paket oder eine Packung zusammengefasst ist, um Spuren zu halten: Haare, Fasern oder Pulver. Danchmal wird Bindegewiss verwendet, um ein kleines Paket von pulverhaltigen Arzneimitteln zu beschreiben. Siehe auch die Verwendung von Verweisen auf die Außenbeziehungen „Folding a Paper Bin How“, 2017, National Forensic Technology Training Center, [1] „Paper Evidence“ 2014 VDFS, Virginia,[2]