Mathematik und Computerwissenschaften ist ein Algorithmus (Zuhören) eine finite Sequenz klar definierter, computerimplementierbarer Anweisungen, die in der Regel eine Klasse von spezifischen Problemen lösen oder eine Berechnung durchführen. Algorithms sind immer unmissverständlich und werden als Spezifikationen für die Ausführung von Berechnungen, Datenverarbeitung, automatisierte Begründung und andere Aufgaben verwendet. Kontrastlich ist ein ertourismus eine Technik, die bei der Problemlösung eingesetzt wird, die praktische Methoden und/oder verschiedene Schätzungen verwendet, um Lösungen zu finden, die nicht optimal sein können, aber angesichts der Umstände ausreichend sind. In einer wirksamen Methode kann ein Algorithmus innerhalb eines Finite-Niveaus und einer klar definierten formalen Sprache zur Berechnung einer Funktion ausgedrückt werden. Anhand eines ersten Staates und eines ersten Inputs (perhaps leer) beschreiben die Anweisungen eine Berechnung, die bei der Ausführung durch eine finite Anzahl von gut definierten, aufeinanderfolgenden Staaten weiterverfolgt und in einem endgültigen Endestaat erstellt wird. Der Übergang von einem Staat zum nächsten ist nicht unbedingt deterministisch; einige Algorithmen, die als zufällige Algorithmen bekannt sind, enthalten zufällige Beiträge. Das Konzept des Algorithmus existiert seit der Antike. ArithmeticAlgorithmen wie ein Teilgorithmus wurden von antiken mathematicians c. 2500 BC und ägyptischen Säugetieren c. 1550 BC. Griechische Säugetiere verwendeten später Algorithmen in 240 BC in der Belagerung von Eratosthenes zur Ermittlung der Hauptnummern und des Euclidean-Algorithmus zur Ermittlung des größten gemeinsamen Diavisors von zwei Nummern. Arabische Säugetiere wie Al-Kindi im 9. Jahrhundert verwendeten Kryptografische Algorithmen für Code-rot, basierend auf der Frequenzanalyse. Der Wortgorithmus selbst wird aus dem Namen des 9. Jahrhunderts mathematician Muammaammadā al-Khwārizmī abgeleitet, dessen nisba (ident von Khwarazm) als Algoritmi bezeichnet wurde. Eine partielle formalisierung des modernen Konzepts des Algorithmus begann mit dem Versuch, das von David Hilbert im Jahr 1983 vorgelegte Problems (Entscheidungsproblem) zu lösen. spätere Formalisierungen wurden als Versuch konzipiert, "effektive Kalkbarkeit" oder "effektive Methode" zu definieren. Diese Formalisierungen umfassen die Gödel-Herbrand-Kleene-recursive Funktionen von 1930, 1934 und 1935, die Lambda von Alonzo Church von 1936, Emil Post-Formulation 1 von 1936 und Alan Turing's Turing Maschinen von 1936-37 und 1939. EtymologyDer Algorithmus hat seine Wurzeln in der lateinischen Sprache, die seine geografische Herkunft, den Namen des Persischen mathematicianischen Volkes Muhammad Musa al-Khwarizmi zu Algorismus bezeichnet. Al-Khwārizmī (Arabisiertes Persisches  c c.780–850) war ein mathematischer, Astronomischer, Geographer und Wissenschaftler im Haus der Weisheit in Baghdad, deren Name bedeutet, dass "der heimische von Khwarazm" eine Region ist, die heute in Usbekistan gehört. Rund 825, al-Khwarizmi schrieb eine arabische Sprache, die sich mit dem Hindu-Arabischen Numeralsystem befasste, das im zwölften Jahrhundert in Lateinamerika übersetzt wurde. Das Papier beginnt mit dem Satz Dixit Algorizmi '(Thus Spake Al-Khwarizmi)', wo Algorizmi den Namen des Übersetzers Al-Khwarizmi war. Al-Khwarizmi war der am häufigsten lesende mathematician in Europa im späten Mittleren Alter, vor allem durch einen anderen seiner Bücher, dem Algebra. Ende des mittelalterlichen lateinischen Algorismus, die Korruption seines Namens, bedeutete einfach das "Dezimal-Nummer-System". Im 15. Jahrhundert, unter dem Einfluss des griechischen Wortes  Greek (arithmos), Nummer (vgl. arithmetic), wurde das lateinische Wort auf den Algorithmus verändert, und der entsprechende englische Begriffsgorithmus wird zunächst im 17. Jahrhundert getestet; der moderne Sinn wurde im 19. Jahrhundert eingeführt. Englisch wurde zunächst in etwa 1230 und dann von Chaucer in 1391 verwendet. Englisch hat den französischen Begriff angenommen, aber es war nicht bis Ende des 19. Jahrhunderts, dass der Algorithmus in der Bedeutung, die er in modernem Englisch hat, übernahm. Eine weitere frühzeitige Verwendung des Wortes ist von 1240 in einem Handbuch mit dem Titel Carmen de Algorismo, bestehend aus Alexandre de Villedieu. Es beginnt mit: Haec algorismus ars praesens dicitur, in qua / Talibus Indorum Fruuimur bis quinque figuris. was bedeutet: Algorismus ist die Art, mit der wir derzeit diese indischen Zahlen verwenden, die zweimal fünf Mal betragen. Das Poem ist eine Reihe von hundert Linien lang und fasst die Art der Berechnung mit dem neuen Stilierten Indischen Index (Tali Indorum) oder Hindu-Nummern zusammen. informelle Definition Eine informelle Definition könnte "eine Reihe von Regeln sein, die eine Reihe von Operationen genau definieren", die alle Computerprogramme (einschließlich Programme, die nicht numerische Berechnungen durchführen) und (z.B. alle vorgeschriebenen bürokratischen Verfahren oder Kochbuchrezepte umfassen. Insgesamt ist ein Programm nur ein Algorithmus, wenn es schließlich gestoppt – auch wenn unendliche Schleifen manchmal wünschenswert sein können. Ein modellisches Beispiel eines Algorithmus ist der Euclidean-Algorithmus, der verwendet wird, um den maximalen gemeinsamen Diavisor von zwei Zahlen zu bestimmen; ein Beispiel (Es gibt andere) wird von der Flussdiagramm oben und als Beispiel in einem späteren Abschnitt beschrieben. Alain & 1974 bietet 1999 in der folgenden Notlage eine informelle Bedeutung des Wortesgorithmus: Kein Mensch kann schnell genug oder lang genug oder klein genug verschreiben ( †) klein und kleiner ohne Grenzen ... Sie versuchen, Moleküle, Atome, Elektronen) zu schreiben, um alle Mitglieder eines numerischen unendlichen Satzes aufzulisten, der mit der Angabe ihrer Namen, einem nach einer anderen, in manchen Notation angegeben ist. Jedoch kann der Mensch etwas gleichermaßen nützlich machen, wenn bestimmte numerische unendliche Sätze: Sie können explizite Anweisungen für die Bestimmung des nth-Mitglieds des Set geben, für willkürliche Floite n.Suchanweisungen sind in einer Form, in der sie von einer Computermaschine oder von einem Menschen folgen könnten, der nur sehr einfache Operationen auf Symbolen durchführen kann. Ein „enumerisch unbegrenzter Satz“ ist eine, deren Elemente in einen einzigen Briefwechsel mit den Zahlen eingebracht werden können. Loyola und Jeffrey sagen daher, dass ein Algorithmus Anweisungen für einen Prozess enthält, der Outputnummern aus einer willkürlichen Input-Intensität oder -Zahlen hervorbringt, die in der Theorie sehr groß sein können. Beispiel: ein Algorithmus kann eine mathematische Formel wie y = m + n (d. h. zwei willkürliche "inputative Variablen" m und n, die ein Output y produzieren), aber die Versuche verschiedener Autoren, den Begriff zu definieren, zeigen, dass das Wort viel mehr als das bedeutet, was auf der Reihenfolge (z.B. Konkrete Anweisungen (in einer Sprache, die von "der Computer" für einen schnellen, effizienten, guten Prozess verstanden wird, der den Übergang von "der Computer" (Maschinen oder Menschen, die mit den notwendigen internen Informations- und Fähigkeiten ausgestattet sind), um zu finden, zu verschlüsseln und dann willkürliche Inputs/Symbole m und n, Symbolen + und = ... zu verarbeiten und effektiv in angemessener Zeit Output-integer y an einem bestimmten Ort und in einem bestimmten Format zu produzieren. Das Konzept des Algorithmus wird auch verwendet, um den Begriff der Entscheidungsfähigkeit zu definieren – ein Begriff, der von zentraler Bedeutung ist, um zu erklären, wie die formalen Systeme aus einem kleinen Satz von Axioms und Regeln beginnen. Logik: Die Zeit, die ein Algorithmus vollständig benötigt, kann nicht gemessen werden, da es offenbar nicht mit der üblichen physischen Dimension zusammenhängt. Aus solchen Unsicherheiten, die die laufende Arbeit prägen, ergibt sich die fehlende Verfügbarkeit eines Algorithmen, der sowohl Beton (in gewissem Maße) als auch abstrakte Nutzung des Begriffs entspricht. Formalisierung Algorithms sind für die Art und Weise, wie Computer verarbeiten. Viele Computerprogramme enthalten Algorithmen, die die spezifischen Anweisungen eines Computers beschreiben sollten – in einer bestimmten Reihenfolge –, um eine bestimmte Aufgabe auszuführen, wie etwa die Berechnung der Gehaltskontrollen der Arbeitnehmer oder die Berichtskarten von Druckstudenten. So kann ein Algorithmus als jede Reihe von Operationen angesehen werden, die von einem Turing-vollen System simuliert werden können. Autorinnen und Autorinnen, die dies geltend machen, sind Minsky (1967,) Kato (1987) und Guritsch (2000): Minsky: „Aber wir werden auch mit Turing ... behaupten, dass ein Verfahren, das natürlich als wirksam bezeichnet werden könnte, tatsächlich durch eine (einfache) Maschine realisiert werden kann. Obwohl dies vielleicht extrem erscheinen mag, sind die Argumente ... in ihren Gunsten schwer zu refute. Gurevich: "... Turing's informelles Argument für seine Arbeit rechtfertigt ein stärkeres Erkennen: Jeder Algorithmus kann von einer Turing-Maschine simuliert werden ... Laut dem "Baby [1987" ist ein Algorithmus ein von einer Turing-Maschine definiertes Rechenverfahren. Turing-Maschinen können Berechnungsverfahren festlegen, die nicht enden. Die informellen Definitionen von Algorithmen erfordern in der Regel, dass der Algorithmus immer endet. Diese Anforderung stellt die Aufgabe dar, zu entscheiden, ob ein förmliches Verfahren ein Algorithmus ist, der im allgemeinen Fall nicht möglich ist – was einem wichtigen theorem der Komputierbarkeitstheorie bekannt ist, das als Hindernis bezeichnet wird. In der Regel, wenn ein Algorithmus mit Verarbeitungsdaten verbunden ist, können Daten von einer Inputquelle, schriftlich an ein Outputgerät und für die weitere Verarbeitung gespeichert werden. gespeicherte Daten werden als Teil des internen Zustands der Einheit angesehen, die den Algorithmus ausübt. In der Praxis wird der Staat in einem oder mehreren Datenstrukturen gelagert. Für einige dieser Berechnungsverfahren muss der Algorithmus streng definiert werden: in der Weise, wie er in allen möglichen Umständen anwendbar ist. Dies bedeutet, dass alle bedingten Schritte systematisch behandelt werden müssen, falls Einzelfall; die Kriterien für jeden Fall müssen klar sein (und komparierbar). Da ein Algorithmus eine genaue Liste präziser Schritte ist, ist die Reihenfolge der Berechnung für das Funktionieren des Algorithmus immer entscheidend. In der Regel wird davon ausgegangen, dass die Anweisungen ausdrücklich aufgeführt werden und als Ausgangspunkt "von oben" bezeichnet und "nach unten" bezeichnet werden – eine Idee, die durch den Kontrollfluss förmlicher beschrieben wird. Bisher hat die Diskussion über die formalisierung eines Algorithmus die Räumlichkeiten der zwingend vorgeschriebenen Programmierung übernommen. Dies ist die häufigste Konzeption – eine, die versucht, eine Aufgabe in bestimmten, mechanischen Mitteln zu beschreiben. Kennzeichnend für diese Konzeption formalisierter Algorithmen ist die Zuteilungsoperation, die den Wert einer variablen Größe legt. Es ist ein Grundpfeiler des Gedächtnisses. Ein Beispiel für eine solche Zuteilung finden Sie unten. Für einige andere Konzeptionen, die ein Algorithmus darstellen, siehe die funktionelle Programmierung und die Programmierung der Logik. Erkennung von Algorithmen Algorithms können in vielen Arten von Notation ausgedrückt werden, darunter natürliche Sprachen, Pseudocode, Flussdiagramme, drakoncharts, Programmiersprachen oder Kontrolltabellen (verarbeitet durch Dolmetscher). Natursprachliche Ausdrucke von Algorithmen sind in der Regel Verbose und Unklarheit und werden selten für komplexe oder technische Algorithmen verwendet. Pseudocode, Flussdiagramme, drakon-Charts und Kontrolltabellen sind strukturiert, um Algorithmen auszudrücken, die viele der in den auf der natürlichen Sprache beruhenden Unklarheiten vermeiden. Programmiersprachen sind in erster Linie für die Angabe von Algorithmen in einer Form bestimmt, die von einem Computer ausgeführt werden kann, aber häufig als Mittel zur Definition oder Dokumentation von Algorithmen verwendet werden. Es gibt eine Vielzahl von Darstellungen möglich und eine kann ein bestimmtes Turing-Maschine-Programm als eine Reihe von Maschinentabellen (siehe finite-state maschine, State Transition Table and Control Table for more), als Flussdiagramme und drakon-Charts (siehe Staatsdiagramm für mehr) oder als Form des rudimentären Maschinencodes oder Montagecodes „Gerüchte“ (siehe Turing-Maschine für mehr). Darstellungen von Algorithmen können in drei akzeptierten Stufen der Turing-Maschine-Bemessung nachstehend aufgeführt werden: 1 Hochrangige Beschreibung "...prose to beschreiben einen Algorithmus, wobei die Umsetzungsdetails ignoriert werden. Auf dieser Ebene müssen wir nicht erwähnen, wie die Maschine ihre Bürokratie oder Kopf verwaltet. 2 Durchführungsbeschreibung "...prose zur Bestimmung der Art und Weise, wie die Turing-Maschine ihren Kopf verwendet, und der Art, wie sie Daten über den bürokratischen Aufwand speichert. Auf dieser Ebene geben wir keine Angaben zu Staaten oder Übergangsfunktionen. "3 Formalbeschreibung Die meisten detaillierten, "niedrigsten Ebenen" gibt dem "staatlichen Tisch" der Turing Maschine. Beispiel für den einfachen Algorithmus "M+n" in allen drei Ebenen, siehe Algorithm#Examples. Design Algorithm Design bezieht sich auf eine Methode oder einen mathematischen Prozess für Problemlösungs- und Engineering-Algorithmen. Die Konzeption von Algorithmen ist Teil vieler Lösungstheorien der Betriebsforschung, wie dynamische Programmierung und Spaltung. Techniken zur Konzipierung und Umsetzung von Algorithmen-Designs werden auch Algorithmen-Designmuster genannt, wobei Beispiele wie das Muster und das Dekorator-Muster gehören. Eines der wichtigsten Aspekte des Algorithmen-Designs ist die Ressourceneffizienz (Zeit-, Speichernutzung); die große O-Zulassung wird verwendet, um z.B. die Laufzeit des Algorithmus als Größe seiner Inputerhöhungen zu beschreiben. Typische Schritte bei der Entwicklung von Algorithmen: Problemdefinition Entwicklung einer Modellspezifikation des Algorithmus, der einen Algorithmus entwickelt Überprüfung der Richtigkeit der Algorithmusanalyse der Durchführung von Algorithmen-Programmen zur Prüfung der Dokumentationsvorbereitung sollen die meisten Algorithmen als Computerprogramme umgesetzt werden. Algorithmen werden jedoch auch mit anderen Mitteln umgesetzt, wie etwa in einem biologischen Neuralnetz (z.B. das menschliche Gehirn, das ein Rithmetik oder ein Insekten sucht, in einem Elektrokreis oder in einem mechanischen Gerät). Computeralgorithmen In Computersystemen ist ein Algorithmus im Wesentlichen eine Art Logik, die von Softwareentwicklern geschrieben wird, um wirksam für den geplanten Zielcomputer(n) sein zu können, um aus gegebenem (perhaps null) Input zu produzieren. Ein optimaler Algorithmus, auch in alten Hardware, würde schnellere Ergebnisse erzielen als ein nichtoptimaler (hohe Zeitkomplex) Algorithmus für denselben Zweck, der in effizienteren Hardware betrieben wird; weshalb Algorithmen wie Computer-Hardware als Technologie gelten. " Lokale (compact) Programme, gute (fast) Programme: Kurz gesagt in Knuth und genau in Chaitin: Knuth: "... wir wollen gute Algorithmen in etwas locker definiertem ästhetischen Sinn. Ein Kriterium ... ist die Länge der Zeit, die zur Ausführung des Algorithmus getroffen wurde .... Andere Kriterien sind die Anpassungsfähigkeit des Algorithmus an Computer, seine Einfachheit und Eleganz usw."Chaitin: "... ein Programm ist ehrgeizig, mit dem ich das kleinste mögliche Programm für die Herstellung der Produktion bedeutet, das es tut", präfaces seine Definition mit: "Ich kann nicht nachweisen, dass ein Programm ehrgeizig ist" – ein Nachweis, dass ein Nachweis das Eindämmungsproblem (ibid) lösen würde. Algorithm versus Funktion komutabel durch einen Algorithmus: Für eine bestimmte Funktion können mehrere Algorithmen vorhanden sein. Dies ist wahr, auch ohne die verfügbare Anleitung, die dem Programmteilnehmer zur Verfügung gestellt wird. Rogers weist darauf hin, dass "Es ist ... wichtig, zwischen dem Begriff des Algorithmus, d.h. dem Verfahren und dem Begriff der Funktion zu unterscheiden, der durch den Algorithmus komutierbar ist, d.h. die Kartierung, die im Verfahren erzielt wird. Die gleiche Funktion kann mehrere verschiedene Algorithmen haben." Leider kann es zu einem Abspiel zwischen der Leistungsfähigkeit (Geschwindigkeit) und der Eleganz (Kompactness) kommen – ein elegantes Programm kann mehr Schritte unternehmen, um eine Berechnung zu erzielen als eine weniger ehrgeizig. Beispiel dafür, dass Euclid-Algorithmus verwendet wird, erscheint unten. Computer (und Komputors), Modelle der Berechnung: Ein Computer (oder ein menschliches Komputor) ist eine eingeschränkte Art von Maschinen, einem unterschiedslosen deterministischen mechanischen Gerät, das seine Anweisungen blind erfüllt. Melzak's und Lambeks Modelle haben diesen Begriff auf vier Elemente reduziert: (i) getrennte, Unterscheidungsstandorte, (ii) diskrete, unauffällige Gegensätze (iii) einen Agenten und (iv) eine Liste von Anweisungen, die im Vergleich zur Fähigkeit des Agenten wirksam sind. Minsky beschreibt in seinem "Very einfachen Basiss für Komputability" eine größere kongensionelle Variante des Abacus-Modells von Lambek. Minsky's Werkzeugmaschinen wird durch seine fünf (oder sechs, je nachdem, wie man zählt) Anweisungen getrennt, es sei denn, eine Bedingung für IF-THEN GOTO oder ein bedingungsloses GOTO-Veränderungsprogramm kommt aus der Sequenz. Neben den Maschinen von HALT umfasst Minsky drei Aufgaben (Replacement, Substitution): ZERO (z.B. den durch 0:L · 0 ersetzten Standort), SUCCESSOR (z.B. L ← L+1) und DECREMENT (z.B. L · L · − 1). Selten muss ein Programm-Abschreibungscode mit einer solchen begrenzten Unterrichtsform. Minsky zeigt jedoch (wie Melzak und Lambek), dass seine Maschine Turing mit nur vier allgemeinen Arten von Anweisungen ist: Kondition GOTO, bedingungslose GOTO, Zuteilung/Replacement/Substitution und HALT. Manche verschiedene Zuteilungsanleitungen (z.B. DECREMENT, INCREMENT und ZERO/CLEAR/EMPTY für eine Minsker Maschine) sind jedoch auch für Turing-Vervollständigung erforderlich; ihre genaue Spezifikation ist etwas bis zum Designer. Das bedingungslose GOTO ist eine gute Sache; es kann durch die Paraphierung eines eigenverantwortlichen Standorts auf Null gebaut werden, z.B. die Anleitung " Z · 0 "; danach ist die Anleitung IF Z=0 THEN GOTO XXX bedingungslos. Simulation eines Algorithmus: Computer (Komputor) Sprache: Knuth berät den Leser, dass "der beste Weg ist, einen Algorithmus zu lernen, um ihn zu versuchen . . sofort mit einem Beispiel zu bestrafen und zu arbeiten." Aber was ist eine Simulation oder Ausführung der Realität? Der Programmierer muss den Algorithmus in eine Sprache übersetzen, die der Simulator/Computer/Komputor effektiv ausführen kann. Stein gibt ein Beispiel dafür: Wenn die Wurzeln einer quadratischen Formel berechnet werden, muss der Komputor wissen, wie man eine Quadratwurzel annimmt. Wenn sie nicht, dann muss der Algorithmus, um wirksam zu sein, eine Reihe von Regeln für die Gewinnung einer Quadratwurzel vorsehen. Dies bedeutet, dass der Programmierer eine Sprache kennen muss, die im Verhältnis zum Zielcomputer (Computer/Komputor) wirksam ist. Welches Modell sollte für die Simulation verwendet werden? Van Emde Pips stellt fest, dass "selbst wenn wir die Komplexitätstheorie auf abstrakten anstelle von Betonmaschinen stützen, die Schiedsbarkeit der Auswahl eines Modells bleibt. Es ist an diesem Punkt, dass der Begriff der Simulation eintritt." Wann die Geschwindigkeit gemessen wird, sind die Anweisungen festgelegt. Zum Beispiel würde das Subprogramm in Euclids Algorithmus, um den Rest zu berechnen, viel schneller ausführen, wenn der Programmteilnehmer einen modulatorischen Unterricht nicht nur Subtraction (oder schlimmer: nur die Dekration von Minsky). Strukturierte Programmierung, canonische Strukturen: Per die Kirche – Ermöglichung der Thesis, jeder Algorithmus kann durch ein Modell berechnet werden, das bekannte Turing vollständig ist, und die Demonstrationen von Minsky erfordern nur vier Unterrichtstypen – bedingungslose GOTO, bedingungslose GOTO, Zuteilung, HALT. Kemeny und Kurtz weisen darauf hin, dass ein Programmanbieter zwar nicht vorherrschende Verwendung bedingungsloser GOTOs und bedingter IF-THEN GOTOs in "spaghetti-Code" mit nur diesen Anweisungen schreiben kann; andererseits ist es auch möglich, schlecht strukturierte Programme in einer strukturierten Sprache zu schreiben. Tausworthe erweitert die drei klassisch-Jacopini canonischen Strukturen: SEQUENCE, IF-THEN-ELSE und WHILE-DO, zwei weitere: DO-WHILE und CASE. Ein zusätzlicher Nutzen eines strukturierten Programms besteht darin, dass es sich anhand eines mathematischen Vorsteuerabzugs als Nachweise für die Richtigkeit angibt. Canonische Flussdiagramme: Der grafische Aide namens Flussdiagramm bietet eine Möglichkeit, einen Algorithmus zu beschreiben und zu dokumentieren (und ein Computerprogramm eines). Wie der Programmfluss einer Minsky-Maschine beginnt ein Flussdiagramm immer an der Spitze einer Seite und geht zurück. Ihre primären Symbole sind nur vier: die zielgerichtete Säule, die den Programmfluss, das Retwinkel (SEQUENCE, GOTO), den Diamanten (IF-THEN-ELSE) und den Punkt (OR-tie). Die bayerisch-Jacopini canonischen Strukturen bestehen aus diesen einfachen Formen. Substrukturs können in Remateles bestehen, aber nur, wenn ein einziger Ausstieg aus der Superstruktur auftritt. Die Symbole und ihre Verwendung zum Aufbau der canonischen Strukturen werden im Diagramm dargestellt. Beispiele Eines der einfachen Algorithmen ist es, die größte Zahl in einer Liste von Nummern der Zufallsordnung zu finden. Suche nach der Lösung erfordert die Suche nach jeder Nummer in der Liste. Aus diesem Grund folgt ein einfacher Algorithmus, der in einer hochrangigen Beschreibung in englischer Prose angegeben werden kann: Wenn es keine Nummern im Set gibt, gibt es keine höchste Zahl.Assume die erste Nummer im Set ist die größte Zahl im Set. Jede verbleibende Zahl im Set: Wenn diese Zahl größer ist als die derzeitige größte Zahl, hält diese Zahl für die größte Zahl im Set. Wenn es keine Nummern gibt, die in dem gesetzten Satz übersteigen, ist die aktuelle größte Zahl der Set.(Quasi-)formal Beschreibung: Schriftlich in Prose, aber viel näher an der hochrangigsten Sprache eines Computerprogramms, ist folgendes die formellere Kodierung des Algorithmus in Pseudocode oder pidgin Code: Euclid-Algorithmus Euclid's Algorithmus, um den größten gemeinsamen Diavisor (GCD) auf zwei Zahlen zu berechnen, die als Proposition II in Buch VII ("Elementary Number") seiner Elemente erscheinen. Euclid stellt daher das Problem dar: "Die zweistelligen Zahlen, die nicht zu einem anderen gehören, um ihre größte gemeinsame Maßnahme zu finden". Er definiert "Eine Nummer [zu] eine Vielzahl von Einheiten:" eine Zählnummer, eine positive Zahl, die nicht Null enthält. Maßgeblich ist es, eine kürzere Messlänge je nach (q-mal) Länge zu legen, bis der verbleibende Teil r weniger ist als die kürzere Länge. In modernen Worten, Rest r = l − q×s, q is the quotient, oder Rest r ist die Modalitäten, die Zahl-fractional-Teile nach der Spaltung. Für die Euclid-Methode müssen die Ausgangslängen zwei Anforderungen erfüllen: (i) die Länge darf nicht Null sein, und (ii) die Subtraction muss ordnungsgemäß sein; d. h. ein Test muss sicherstellen, dass die kleineren der beiden Nummern von den größeren (oder die beiden können so gleichwertig sein, dass ihre Subtraction-Erträge Null sind). Euclid's ursprüngliches Beweis fügt ein drittes Erfordernis hinzu: Die beiden Längen dürfen nicht von zentraler Bedeutung sein. Euclid verlangte dies, damit er einen Rückführungs-Ad absurdum-Beweis erstellen könnte, dass die gemeinsame Maßnahme der beiden Nummern tatsächlich die größte ist. Obwohl Nicomachus-Algorithmus die gleiche ist wie Euclid, wenn die Zahlen zu einem anderen sind, führt sie die Nummer 1 für ihre gemeinsame Maßnahme. Man muss also genau sein, der folgende ist wirklich Nicomachus-Algorithmus. Computersprache für Euclid-Algorithmus Nur wenige Unterrichtstypen sind erforderlich, um den Algorithmus von Euclid auszuführen – einige logische Tests (Bedingungen GOTO), bedingungslose GOTO, Zuteilung (Replacement) und Subtraction. Kennzeichnend für einen Standort sind die oberen Buchstaben, z.B. S, A usw. Die unterschiedliche Menge (Nummer) in einem Standort ist in niedrigeren Buchstaben (s) und (normalerweise) im Zusammenhang mit dem Namen des Standorts geschrieben. Standort L zu Beginn könnte die Zahl l = 3009 enthalten. gesetzgebendes Programm für Euclid-Algorithmus Der folgende Algorithmus ist als Knuth vierstufige Version von Euclid und Nicomachus konzipiert, sondern nutzt nicht die Teilung, um die restlichen zu finden, sondern nutzt die aufeinanderfolgenden Unterbreitungen der kürzeren Längen von der verbleibenden Länge bis r weniger als s. Die in Fettleibigkeit gezeigte hochrangige Beschreibung wird von Knuth 1973 angepasst:2–4 INPUT: 1 [Into zwei Standorte L und S legen die Zahlen l und s vor, die die beiden Längen ausmachen:] INPUT L, S 2 [Initialisieren R: machen die verbleibende Länge r der Start-/Initial-/Inputlänge l:] R ← L E0:[Ensurer ≥ s] 3 [Die kleinere Zahl der beiden Nummern ist in S und dem größeren in R:] IF R.  THE  THE, der Inhalt der L ist die größere Zahl, die über die Austauschstufen 4, 5 und 6: GOTO Schritt 7 ELSE tauscht den Inhalt von R und S. 4 L · R (dieser erste Schritt ist überflüssig, aber ist nützlich für spätere Diskussionen.5 R 6 S ·  L L1:[Find Rest:] Bis die verbleibende Länge in R weniger als die kürzeren Längen in S ist, bremst die Messnummer in S von der restlichen Länge in R. 7 IF S > R THEN die Messung so GOTO 10 ELSE-Maßnahmen wieder, 8 R − S 9 [Remainder-link:] GOTO 7. E2:[I die restliche Null?] EITHER (i) die letzte Maßnahme war genau, der Rest in R ist Null, und das Programm kann gestoppt werden, OR (ii) der Algorithmus muss weiter: Die letzte Maßnahme blieb in R weniger als die Messnummer S. 10IF R = 0THEN getan, so GOTO Schritt 15 ELSE CONTI Schritt 11 E3:[Interchange s and r:] Schalenfrüchte von Euclid. Rest r zu messen, was früher kleiner war; L dient als vorübergehender Standort. 11 L ← R 12 R · S13 S  · L 14 [Repeat des Messverfahrens:] GOTO 7 OUTPUT: 15 [Done. S enthält die größte gemeinsame Abkürzung:] PRINT S DONE: 16 HALT, END, STOP. Ein elegantes Programm für Euclid-Algorithmus Die folgende Version des Euclid-Algorithmus erfordert nur sechs Kernanweisungen, um zu tun, was dreizehn von Inelegant zu tun haben; Verschlechterung verlangt, dass Inelegant mehr Anweisungen benötigt. Kennzeichnend für den Zustrom der Einzigartigkeit ist der Artikel. In der (unstrukturd) Grundsprache, die Schritte sind angegeben, und die Anleitung LET [] = [] ist der Auftrag, der durch ← symbolisiert wird. Wie beeindruckende Werke: Ein äußerer "Euclid-Sender"-Senderwechsel zurück und zwischen zwei Gliedern, einer A-Liste B-Anschluß, der eine · A − B berechnet, und ein B ≤ A-Sender, der B · B −A berechnet. Diese Werke, weil der Minuend M bei letzterem weniger als dem Subtrahend S(Difference = Minuend − Subtrahend) entspricht, kann der Minuend (die neue Messlänge) werden, und der Subtrahend kann zum neuen r (die zu messende Länge) werden, d. h. zum Sinn der Subtraction-Rückkehren. Die folgende Version kann mit Programmiersprachen aus der C-Familie verwendet werden: Prüfung der Euclid-Algorithmen Liegt ein Algorithmus, was sein Autor tun möchte? Manche Testfälle geben in der Regel ein gewisses Vertrauen in die Kernfunktion. Tests reichen jedoch nicht aus. Für Testfälle verwendet eine Quelle 3009 und 884. Knuth schlug 40902, 24140 vor. Ein weiterer interessanter Fall ist die zwei relativ primären Nummern 14157 und 5950. "außergewöhnliche Fälle" müssen jedoch ermittelt und getestet werden. Will Inelegant ordnungsgemäß funktionieren, wenn R= S, S= R, R = S?Ditto für Elegante: B= A, A > B, A = B? (Ja bis alle). Was passiert, wenn eine Nummer Null ist, sind beide Nummern Null?("Inelegant berechnet in allen Fällen für alle Fälle; Nagelberechnungen für A = 0). Was geschieht, wenn negative Zahlen eingegeben werden? Fractionale Zahlen? Wenn die Inputnummern, d. h. die durch den Algorithmus/Programm berechnete Funktion, nur positive Zahlen einschließlich Null umfassen, dann weisen die Fehler auf Null darauf hin, dass der Algorithmus (und das Programm, das es sofort gibt) eine partielle Funktion anstelle einer Gesamtfunktion ist. Ein bemerkenswertes Versagen aufgrund von Ausnahmen ist das Raketenversagen von Ariane 5 Flug 501 (Juni 4, 1996). Nachweis der Programmgenauigkeit durch mathematische Einführung: Knuth zeigt die Anwendung des mathematischen Abzugs auf eine erweiterte Variante des Euclid-Algorithmus und schlägt "eine allgemeine Methode vor, die für die Gültigkeit eines jeden Algorithmus gilt". Tausworthe schlägt vor, dass eine Maßnahme der Komplexität eines Programms die Länge seines korrekten Nachweises ist. Messung und Verbesserung der Euclid-Algorithmen (Kompactness) im Vergleich zu Goodness (Geschwindigkeit): Nur sechs Kernanweisungen sind der eindeutige Gewinner, verglichen mit Inelegant bei dreizehn Anweisungen. Inelegant ist jedoch schneller (in weniger Schritten kommt es bei HALT an). Algorithm-Analyse zeigt, warum dies der Fall ist: Maßgeblich ist in jedem Subtraction-Anschluß zwei bedingte Tests, während Inelegant nur einen. Da der Algorithmus (normalerweise) viele Schleifmittel erfordert, wird im Durchschnitt viel Zeit verschwendet, um einen "B = 0?"-Test, der nur nach der restlichen Berechnung benötigt wird. Können die Algorithmen verbessert werden? Sobald der Programmteilnehmer ein Programm anfertigt und wirksam ist“, d. h. er berechnet die von seinem Autor geplante Funktion – die Frage wird verbessert? Durch die Beseitigung von fünf Schritten kann die Verdichtung von Inelegant verbessert werden. Chaitin hat jedoch bewiesen, dass ein Algorithmus nicht durch einen allgemeinisierten Algorithmus automatisiert werden kann; vielmehr kann er nur erwirtschaftlich gemacht werden; d. h. durch erschöpfende Suche (Beispiele, die bei Busy beaver zu finden sind), Test und Fehler, klugkeit, Einblick, Anwendung induktiver Begründung usw. Beobachtung, dass Schritte 4, 5 und 6 wiederholt werden in Schritten 11, 12 und 13 Vergleich mit einer eleganten bietet einen Hinweis darauf, dass diese Schritte zusammen mit Schritten 2 und 3 beseitigt werden können. Dies verringert die Anzahl der Kernanweisungen von Thiirteen auf acht, was sie "more eleganter" macht. Die Geschwindigkeit der Spezialität kann dadurch verbessert werden, dass der B=0?"-Test außerhalb der beiden Subtraction-Anschlüsse stattfindet. Diese Änderung verlangt die Ergänzung von drei Anweisungen (B = 0?,A = 0,? GOTO). Künftig werden die Beispielnummern schneller berechnet; ob dies immer der Fall für bestimmte A, B und R ist, würde S eine ausführliche Analyse erfordern. Algorithmie-Analyse Häufig ist es wichtig zu wissen, wie viel einer bestimmten Ressource (wie Zeit oder Lagerung) für einen bestimmten Algorithmus theoretisch erforderlich ist. Methoden wurden für die Analyse von Algorithmen entwickelt, um solche quantitativen Antworten (Schätzungen) zu erhalten; z.B. hat der oben erwähnte Sortierungsgorithmus eine Zeitbedingung von O(n), wobei die große Onotation mit n als Länge der Liste verwendet wird. Jedenfalls muss der Algorithmus nur zwei Werte vergessen: die bislang größte Zahl und die aktuelle Position in der Inputliste. Es wird daher gesagt, dass O(1) eine Raumfahrtpflicht hat, wenn der für die Speicherung der Eingangsnummern erforderliche Raum nicht gezählt wird oder O(n) wenn er gezählt wird. Unterschiedliche Algorithmen können die gleiche Aufgabe mit einer anderen Reihe von Anweisungen in weniger oder mehr Zeit, Raum oder Aufwand abschließen als andere. Beispielsweise stellt ein binärer Suchgorithmus (mit Kosten O(Log n) ) eine sequente Suche (Kosten O(n) ) dar, wenn es für Tafeln verwendet wird. Formal versus empirische Die Analyse und die Untersuchung von Algorithmen ist eine Disziplin der Computerwissenschaft und wird häufig ohne die Verwendung einer bestimmten Programmierungssprache oder -umsetzung angewandt. In diesem Sinne ähnelt die Algorithmenanalyse anderen mathematischen Disziplinen, da sie sich auf die zugrunde liegenden Eigenschaften des Algorithmus konzentriert und nicht auf die Besonderheiten einer bestimmten Umsetzung. In der Regel wird Pseudocode zur Analyse verwendet, da es die einfache und allgemeinste Vertretung ist. Letztendlich werden die meisten Algorithmen jedoch in der Regel auf bestimmten Hardware-/Software-Plattformen angewendet, und ihre Algorithmuseffizienz wird schließlich anhand eines echten Code getestet. Für die Lösung eines "one off"-Problems kann die Effizienz eines bestimmten Algorithmus keine nennenswerten Folgen haben (unweniger n ist extrem groß), aber für Algorithmen, die für eine schnelle interaktive, kommerzielle oder langfristige wissenschaftliche Nutzung ausgelegt sind, kann es kritisch sein. Knapp von kleinen bis großen n gibt es häufig ineffiziente Algorithmen, die ansonsten befremdet sind. Empirische Tests sind sinnvoll, weil sie unerwartete Wechselwirkungen, die die Leistung beeinflussen, entdecken können. Benchmarks können verwendet werden, um vor/nach möglichen Verbesserungen an einem Algorithmus nach der Programmoptimierung zu vergleichen. Empirische Tests können die formale Analyse nicht ersetzen, obwohl und sind nicht verharmlos, fair durchzuführen. Leistungsfähigkeit Um die möglichen Verbesserungen auch in etablierten Algorithmen zu veranschaulichen, kann eine jüngste bedeutende Innovation im Zusammenhang mit FFT-Algorithmen (die im Bereich der Bildverarbeitung verwendet werden) die Bearbeitungszeit für Anwendungen wie medizinische Abbildung um bis zu 1000 Mal verkürzen. Insgesamt hängen Geschwindigkeitsverbesserungen von besonderen Eigenschaften des Problems ab, das in praktischen Anwendungen sehr üblich ist. Geschwindigkeiten dieses Ausmaßes ermöglichen Rechengeräte, die eine umfassende Nutzung der Bildverarbeitung (wie digitale Kameras und medizinische Geräte) ermöglichen, um weniger Strom zu verbrauchen. Klassifikation Es gibt verschiedene Möglichkeiten, Algorithmen zu kategorisieren, jeweils mit eigenen Verdiensten. Umsetzung durch Ein Weg, Algorithmen zu kategorisieren, ist mit Hilfe der Umsetzung. Konkursion Ein recursiver Algorithmus ist eines, der sich wiederholt auf einen bestimmten Zustand (auch bekannt als Kündigungsbedingung) bezieht, der eine Methode ist, die für die funktionelle Programmierung üblich ist. Iterative Algorithmen verwenden wiederholte Konstruktionen wie Schleifen und manchmal zusätzliche Datenstrukturen wie Stapels, um die angegebenen Probleme zu lösen. Manche Probleme sind natürlich für eine Umsetzung oder die andere geeignet. Turme von Hanoi werden beispielsweise durch eine konsequente Umsetzung gut verstanden. Jede recursive Version hat eine gleichwertige (aber vielleicht mehr oder weniger komplexe) iterative Version und umgekehrt. Logik Ein Algorithmus kann als kontrollierter logischer Abzug angesehen werden. Dieser Begriff kann als: Algorithm = Logik + Kontrolle ausgedrückt werden. In der Logik-Komponente werden die in der Berechnung verwendeten Axioms und die Kontrollkomponente bestimmt, wie der Abzug auf die Axiom angewendet wird. Hierbei handelt es sich um die Grundlage für das Paradigmenprogramm. In rein Logik-Programmsprachen ist die Kontrollkomponente festgelegt und die Algorithmen werden nur durch die Lieferung der Logikkomponente angegeben. Rechtsmittel gegen diesen Ansatz sind die eleganten semantischen Substanzen: eine Änderung der Axioms stellt eine klar definierte Veränderung im Algorithmus her. Seriennummer, parallel oder verteilt Algorithms werden in der Regel mit der Annahme diskutiert, dass Computer, die zu einem Zeitpunkt eine Anleitung eines Algorithmus ausführen, ausführen. Diese Computer werden manchmal als Seriencomputer bezeichnet. Ein Algorithmus, der für ein solches Umfeld entworfen wurde, wird als ein serieller Algorithmus bezeichnet, im Gegensatz zu Parallelalgorithmen oder verteilten Algorithmen. Parallele Algorithmen nutzen Computerarchitekturen, bei denen mehrere Prozessoren gleichzeitig auf ein Problem arbeiten können, während verteilte Algorithmen mehrere Maschinen im Zusammenhang mit einem Computernetz verwenden. Parallele oder verteilte Algorithmen spalten das Problem in symmetrischere oder asymmetrische Subprobleme und sammeln die Ergebnisse zusammen. Der Ressourcenverbrauch in solchen Algorithmen ist nicht nur Verarbeiterzyklen auf den einzelnen Prozessoren, sondern auch die Kommunikation zwischen den Verarbeitern. Manche Arten von Algorithmen können effizient eingesetzt werden, aber ihre Kommunikation ist teuer. Iterative Algorithmen sind in der Regel parallel. Manche Probleme haben keine Parallelalgorithmen und werden inhärente Probleme genannt. Deterministische oder nichtdeterministische Deterministische Algorithmen lösen das Problem mit genauer Entscheidung in jedem Schritt des Algorithmus, während nicht-deterministische Algorithmen Probleme lösen, obwohl typische Ermutungen durch die Verwendung von Hetourismus genauer gemacht werden. Klar oder ungefähr Obwohl viele Algorithmen eine genaue Lösung erreichen, suchen Annäherungsgorithmen eine Annäherung an die wahre Lösung. Die Angleichung kann erreicht werden, indem entweder eine deterministische oder zufällige Strategie verwendet wird. Solche Algorithmen haben praktischen Wert für viele schwierige Probleme. Eines der Beispiele für einen ungefähren Algorithmus ist das Knapsack-Problem, bei dem es eine Reihe von Punkten gibt. Ihr Ziel ist es, die Schlupflöcher zupacken, um den größtmöglichen Gesamtwert zu erreichen. Jeder Punkt hat ein gewisses Gewicht und einen gewissen Wert. Gesamtgewicht, das ausgeführt werden kann, ist nicht mehr als eine bestimmte fixe Nummer X.So, die Lösung muss Gewicht und Wert berücksichtigen. Quantengorithmus Sie laufen auf einem realistischen Modell der Quantenberechnung. In der Regel wird der Begriff für solche Algorithmen verwendet, die inhärent erscheinen oder einige wesentliche Elemente des Quantencomputers wie Quanten- oder Quantenwinkel verwenden. Indem sie Paradigmen entwickeln, ist die Einstufung von Algorithmen durch ihre Designmethodik oder Paradigma. Es gibt eine Reihe von Paradigmen, die jeweils voneinander abweichen. Jede dieser Kategorien umfasst zudem viele verschiedene Arten von Algorithmen. Manche gemeinsame Paradigmen sind: Bruteforce oder erschöpfende Suche Dies ist die naive Methode, jede mögliche Lösung zu finden, die am besten ist. Kluft und Eroberung Ein Kluft- und Eroberungsgorithmus verringert wiederholt ein Problem auf ein oder mehrere kleinere Fälle desselben Problems (normalerweise wiederaufgenommen), bis die Fälle leicht zu lösen sind. Ein solches Beispiel der Kluft und der Eroberung wird zusammengelegt. Sortierung kann auf jedem Segment der Daten erfolgen, nachdem Daten in Segmente aufgeteilt werden und alle Daten in der Pufferphase zusammengefasst werden können. Eine einfachere Variante der Kluft und der Eroberung wird als Reduktions- und Eroberungsgorithmus bezeichnet, der ein identisches Subproblem gelöst und die Lösung dieses Problems nutzt. Kluft und erobern das Problem in mehrere Teilprobleme, so dass die Ausgangsphase komplexer ist als die Verringerung und die Eroberung von Algorithmen. Ein Beispiel für einen Rückgang und den Eroberungsgorithmus ist der binäre Suchgorithmus. Suche und E-Nummer Viele Probleme (wie z.B. gleiches Schach) lassen sich als Probleme auf Graphen modellieren. In einem Diagramm-Explosionsgorithmus sind Regeln für den Übergang zu einem Diagramm festgelegt und für solche Probleme nützlich. Diese Kategorie umfasst auch Suchalgorithmen, Zweigniederlassung und gebundene Nummerierung und Rückführung. Randomisierter Algorithmus solche Algorithmen wählen zufällig (oder pseudo-randomly). Sie können sehr nützlich sein, um etwa Lösungen für Probleme zu finden, bei denen genaue Lösungen gefunden werden können (siehe unten). In einigen dieser Probleme ist bekannt, dass die schnellste Annäherung einige Zufallsfälle einschließt. Ob zufällige Algorithmen mit Polynomialzeit-Komplexität die schnellsten Algorithmen für einige Probleme sind eine offene Frage, die als P-versus NP-Problem bekannt ist. Es gibt zwei große Klassen solcher Algorithmen: Monte Carlo-Algorithmen kommen mit hoher Wahrscheinlichkeit zurück. E.g RP ist die Unterklasse dieser, die in der polynomischen Zeit läuft. Las Vegas-Algorithmen zurückkehren immer die richtige Antwort, aber ihre Betriebszeit ist nur probabilistrikt, z.B. ZPP. Verringerung der Komplexität In dieser Technik geht es darum, ein schwieriges Problem zu lösen, indem wir es in ein besseres bekanntes Problem verwandeln, für das wir (sehr) asymmetrische optimale Algorithmen haben. Ziel ist es, einen Reduktionsgorithmus zu finden, dessen Komplexität nicht von dem daraus resultierenden verringerten Algorithmus dominiert. Zum Beispiel ein Auswahlgorithmus für die Feststellung der Medien in einer unverfälschten Liste beinhaltet die erste Sortierung der Liste (der teure Teil) und zieht dann das mittlere Element in der nachstehenden Liste (der billige Teil). Diese Technik ist auch als Umwandlung und Eroberung bekannt. Rückverfolgung In diesem Ansatz werden mehrere Lösungen inkrementiert und aufgegeben, wenn festgestellt wird, dass sie nicht zu einer gültigen Lösung führen können. Optimierungsprobleme Optimierungsprobleme gibt es eine spezifischere Einstufung von Algorithmen; ein Algorithmus für solche Probleme kann in eine oder mehrere der oben beschriebenen allgemeinen Kategorien sowie in eine der folgenden Kategorien fallen: Lineare Programmierung Bei der Suche nach optimalen Lösungen für eine lineare Funktion, die an lineare Chancengleichheit und Ungleichheiten gebunden ist, können die Probleme des Problems direkt bei der Produktion optimaler Lösungen genutzt werden. Es gibt Algorithmen, die jedes Problem in dieser Kategorie lösen können, wie der populäre einfache Algorithmen. Probleme, die mit linearer Programmplanung gelöst werden können, sind das maximale Durchflussproblem für zielgerichtete Graphen. Wenn ein Problem darüber hinaus verlangt, dass ein oder mehrere der Unbekannten eine ganze Zahl sein müssen, dann wird es in der Numerierung klassifiziert. Ein linearer Programmierungsgorithmus kann ein solches Problem lösen, wenn nachgewiesen werden kann, dass alle Beschränkungen für die Zahlwerte oberflächlich sind, d. h. die Lösungen erfüllen diese Beschränkungen ohnehin. In der Regel wird ein spezieller Algorithmus oder ein Algorithmus verwendet, der ungefähre Lösungen findet, je nach Schwierigkeit des Problems. Dynamische Programmierung Wenn ein Problem optimale Substrukturs aufweist – eine optimale Lösung für ein Problem lässt sich aus optimalen Lösungen bis zu Subproblemen – und Überschneidungen von Subproblemen, d. h. die gleichen Subprobleme werden verwendet, um viele verschiedene Problemfälle zu lösen, ein schnellerer Ansatz, der als dynamische Programmierung bezeichnet wird, vermeidet Recomputing-Lösungen, die bereits berechnet wurden. Zum Beispiel lässt sich der Jamie-Warshall-Algorithmus, der kürzeste Weg zu einem Ziel von einem vertex in einem gewichteten Diagramm finden, indem er den kürzesten Weg zum Ziel aller angrenzenden Wirbeltiere nutzt. Dynamische Programmierung und Kommunikation gehen zusammen.Hauptunterschied zwischen dynamischer Programmierung und Trennung und Eroberung ist, dass SubProbleme mehr oder weniger unabhängig von der Kluft und der Eroberung sind, während sich die Subproblematik im dynamischen Programm überlappt. Der Unterschied zwischen dynamischer Programmplanung und unkomplizierter Neuversetzung ist in der Ausprägung oder Vereinheitlichung von erneuten Anrufen. Wenn SubProbleme unabhängig sind und es keine Wiederholung gibt, hilft die Memoization nicht; daher ist eine dynamische Programmierung keine Lösung für alle komplexen Probleme. Durch die Nutzung von Memoization oder die Aufrechterhaltung eines bereits gelösten Subproblems verringert die dynamische Programmierung die exponentielle Natur vieler Probleme in der Polynomialkomplexität. Der Griedy-Methode A Griedy-Algorith ist ähnlich wie ein dynamischer Programmierungsgorithmus, der durch die Prüfung von Unterstrukturen in diesem Fall nicht des Problems, sondern einer bestimmten Lösung funktioniert. solche Algorithmen beginnen mit einer Lösung, die in gewisser Weise hergestellt oder gebaut werden kann, und verbessern sie durch geringfügige Änderungen. Bei einigen Problemen können sie die beste Lösung finden, während für andere, die an lokalem Optima hindern, Lösungen finden, die nicht durch den Algorithmus verbessert werden können, aber nicht optimal sind. Die beliebteste Verwendung von Griedy-Algorithmen ist die Suche nach dem minimalen Laubbaum, bei dem die optimale Lösung mit dieser Methode möglich ist. Huffman Baum, Kruskal, Prim, Sollin sind Griedy-Algorithmen, die dieses Optimierungsproblem lösen können. He touristische Methode In Optimierungsproblemen kann er touristische Algorithmen verwendet werden, um eine Lösung in der Nähe der optimalen Lösung in Fällen zu finden, in denen die optimale Lösung unpraktisch ist. Diese Algorithmen funktionieren, indem sie näher und näher an die beste Lösung herankommen, wie sie voranschreiten. Grundsätzlich werden sie, wenn sie für eine unbegrenzte Zeit laufen, die beste Lösung finden. Ihre Leistung ist, dass sie in relativ kurzer Zeit eine Lösung finden können, die sehr nahe der optimalen Lösung ist. solche Algorithmen umfassen lokale Suche, Tabu-Suche, simulierte Annobel und genetische Algorithmen. Manche von ihnen, wie simulierte Annobel, sind nichtdeterministische Algorithmen, während andere wie die Tabu-Suche deterministisch sind. Wenn eine Bindung an den Fehler der nichtoptimalen Lösung bekannt ist, wird der Algorithmus weiter als Annäherungsgorithmus eingestuft. Studienbereich Jeder Bereich der Wissenschaft hat eigene Probleme und benötigt effiziente Algorithmen. Probleme in einem Bereich werden häufig zusammen untersucht. Manche Beispielklassen sind Suchalgorithmen, Sortierungsgorithmen, numerische Algorithmen, Graphiken, Algorithmen, Rechengorithmen, Kombination von Algorithmen, Medizinalgorithmen, maschinellem Lernen, Kryptographie, Datenverschlüsselung und Parsing-Methoden. Felde überschneiden sich tendenziell, und die Algorithmen-Vorschüsse in einem Bereich können die anderer, manchmal völlig ungebundener, Felder verbessern. Beispielsweise wurde eine dynamische Programmplanung für die Optimierung des Ressourcenverbrauchs in der Industrie entwickelt, doch wird nun zur Lösung einer breiten Palette von Problemen in vielen Bereichen verwendet. Komplexität Algorithms kann durch die Menge der Zeit, die sie im Vergleich zu ihrer Eingangsgröße ausfüllen müssen: Dauer: Wenn die Zeit, die der Algorithmus benötigt, gleich ist, unabhängig von der Eingangsgröße. E.g Zugang zu einem breiten Element. Logarithmic time: Wenn die Zeit eine Logarithmiefunktion der Eingangsgröße ist. E.g binäre Suchegorithmus. Lineare Zeit: wenn die Zeit proportional zur Eingangsgröße ist. E.g der Traverse einer Liste. Polynomialzeit: wenn die Zeit eine Kraft der Eingangsgröße ist. E.g der blasenartige Algorithmus hat kalkuläre Zeitkomplexe. Exponential time: Wenn die Zeit eine exponentielle Funktion der Eingangsgröße ist. E.g Brute-force-Suche. Manche Probleme haben möglicherweise mehrere Algorithmen unterschiedlicher Komplexität, während andere Probleme keine Algorithmen oder keine bekannten effizienten Algorithmen aufweisen könnten. Es gibt auch Kartierungen von Problemen zu anderen Problemen. Aus diesem Grund wurde festgestellt, dass es besser geeignet ist, die Probleme selbst anstelle der Algorithmen in Gleichwertigkeitsklassen einzustufen, die auf der Komplexität der besten möglichen Algorithmen für sie basieren. Kontinuierliche Algorithmen Bei der Anwendung auf den Text-Algorithmus kann Folgendes bedeuten: Ein Algorithmus, der auf Daten verwendet, die kontinuierliche Mengen repräsentieren, obwohl diese Daten durch diskrete Angleichungen vertreten sind – solche Algorithmen werden in numerischer Analyse untersucht; oder ein Algorithmus in Form einer differenzierten, kontinuierlich auf Daten basierenden Formel, die auf einem analogen Computer läuft. Rechtsfragen Algorithms sind selbst nicht in der Regel patentierbar. In den Vereinigten Staaten ist ein Anspruch, der allein aus einfachen Manipulationen von abstrakten Konzepten, Nummern oder Signalen besteht, keine Prozesse (USPTO 2006) und daher Algorithmen nicht patentierbar (wie in Gottschalk v. Benson). Konkrete Anwendungen von Algorithmen sind manchmal patentierbar. beispielsweise in Diamond v. Diehr, die Anwendung eines einfachen Feedbackgorithmus auf Beihilfen bei der Eindämmung von synthetischem Kautschuk wurde als patentierbar angesehen. Patentierung von Software ist sehr umstritten, und es gibt hoch kritisierte Patente, die Algorithmen, insbesondere Datenkompressions-Algorithmen, wie das LZW-Patent von Unisys, enthalten. Darüber hinaus haben einige Kryptografen Exportbeschränkungen (siehe Ausfuhr von Kryptographie). Geschichte: Entwicklung des Begriffs des Algorithmus im Nahen Osten In der mittelalterlichen Mathematik der antiken Mesopotamia (moderner Irak) werden die frühesten Algorithmen gefunden. In der Nähe von Baghdad und von rund 2.500 BC fand eine Sumerische Tontablette den frühesten Teilgorithmus. Während der Hammurabi-Antriebskraft rund 1800-1600 BC, Kambodschaische Tontabletten beschrieben Algorithmen für Rechenformeln. Algorithms wurden auch in der archäologischen Astronomie verwendet. Kambodschaische Tontabletten beschreiben und beschäftigen algorische Verfahren, um die Zeit und den Ort der bedeutenden lettischen Ereignisse zu berechnen. Algorithms für arithmetic finden sich auch in der alten ägyptischen Mathematik, die aus der Rhind-Dimension Papyrus ca. 1550 BC. Algorithms wurden später in der alten Hellenistischen Mathematik verwendet. Zwei Beispiele sind die Sieve von Eratosthenes, die in der Einführung bis Arithmetic von Nicomachus und dem Euclidean-Algorithmus beschrieben wurde, der zuerst in Euclid-Elementen (c. 300 BC) beschrieben wurde. Unterscheidungsfähige Symbole Tally-marks: Um ihre Herden, ihre Säcke von Getreide und ihr Geld zu halten, die alten, die mit der gleichen Wirkung verwendet werden: Anreicherung von Steinen oder Zeichen auf Aufklebern oder eigene Symbole in Ton. Durch die Verwendung von Symbolen und Symbolen in der arabischen und ägyptischen Sprache, schließlich die Roman Ziffern und die Entacus entwickelten sich (Dilson, p. 16–41). Tally-Marke erscheinen in unary numeral system arithmetic, das in Turing-Maschine- und Post-Turing-Maschinenrechner verwendet wird. Manipulation von Symbolen als "Ortinhaber" für Zahlen: Al-jabr im 9. Jahrhundert. Die Begriffe Algorismus und Algorithmus stammen aus dem Namen al-Khwārizmī, während der Begriff Al-jabr aus dem Buch Al-jabr abgeleitet wird. In Europa wurde der Wortgorithmus ursprünglich verwendet, um auf die von Al-Khwarizmi verwendeten Regeln und Techniken zur Lösung von Al-Khwarizmien zu verweisen, bevor er später auf alle Regeln oder Techniken verweist. Letztendlich kam dies zu dem Schluss, dass der kalkulierbare Indikator (ca 1680): Ein gutes Jahrhundert und ein halbes vor seiner Zeit schlug die Leibniz eine Logik vor, die die Regeln für die Entfaltung logischer Konzepte in der Weise festlegt, die die Regeln für die Entfaltung der Nummern präzisiert. Kryptografische Algorithmen Der erste Kryptographie-Algorithmus für den Entvorhering verschlüsselten Code wurde von Al-Kindi, einem 9. Jahrhundert arabischen mathematician, in einem Roman On Deciphering Cryptographies entwickelt. Er gab die erste Beschreibung der Entschlüsselung nach Häufigkeitsanalyse, dem frühesten kodierenden Algorithmus. mechanische Kontrivierungen mit bestimmten Staaten In der Uhr: Danmarker würdigt die Erfindung der gewichteten Uhr als "Die wichtige Erfindung [von Europa im Nahen Alter"] insbesondere die Entgehung, die uns mit dem Zecken und dem Enten einer mechanischen Uhr bietet. "Die genaue automatische Maschine" führte sofort zu "mechanischen automata" Anfang des 13. Jahrhunderts und schließlich zu "Chole-Maschinen" – die unterschiedlichen Motor- und Analysemotoren von Charles Babbage und Grafes Ada Lovelace, Mitte des 19. Jahrhunderts. Lovelace wird mit der ersten Erstellung eines Algorithmus, der für die Verarbeitung auf einem computer- -Bexge's analytischen Motor bestimmt ist, dem ersten Gerät, der anstelle eines Rechenrechners ein realer Turing-voller Computer angesehen wird, gutgeschrieben und wird manchmal als "Erstprogrammr" bezeichnet, obwohl eine vollständige Umsetzung des zweiten Geräts von Babbage bis Jahrzehnte nach ihrer Lebensdauer nicht realisiert werden soll. Logische Maschinen 25 – Stanley Jevons' "logische Abacus" und "logische Maschinen:" Das technische Problem war es, bei der Vorlage in einer ähnlichen Form wie Karnaugh-Karten zu reduzieren. Jevons (1880) beschreibt zunächst einen einfachen Abschlag von "Slips von Holz, die mit Försen versehen sind, so dass jeder Teil oder Klasse der [logischen] Kombinationen mechanisch ausgeschöpft werden kann. In jüngster Zeit habe ich jedoch das System auf ein vollständig mechanisches Formular reduziert und so den gesamten indirekten Prozess der Gleichgültigkeit in dem, was als "logistisches Werkzeug" bezeichnet werden könnte, mit "bestimmten beweglichen Holzstangen" und "auf dem Fuß sind 21 Schlüssel wie die eines Klaviers [ etc] ". Mit dieser Maschine könnte er ein "syllogismus oder ein anderes einfaches Argument" analysieren. Diese Maschine, die er im Jahr 2000 vor den Kollegen der Royal Society vorgestellt hat. Andere Logik John Venn, in seinem 1881 Symbolic Logic, hat sich diese Bemühungen jedoch als unheilvolles Auge gewandelt: "Ich habe keine hohe Schätzung des Interesses oder der Bedeutung, was manchmal als logische Maschinen bezeichnet werden, scheint mir nicht zu sehen, dass alle Kontrivances, die derzeit bekannt sind oder wahrscheinlich den Namen logischer Maschinen wirklich verdienen," mehr bei Algorithm Charakterisierungen. Aber nicht, er werde auch "ein Plan etwas analog, I Apprehend, an Prof. Jevons entacus [.And] [a]gain, entsprechend Prof. Jevons logische Maschine, die folgende Kontrivance kann beschrieben werden. Ich rufe es nur als logisch-diagram-Maschine an. aber ich bin davon überzeugt, dass es sehr alles tun könnte, was vernünftigerweise von jeder logischen Maschine erwartet werden kann." spiral, helmerith karten, Telegraphie und Telefony – die elektromechanische Relais: Bell und Newell (1971) weisen darauf hin, dass der Vorläufer für die Schroerith-Karten (punchkarten, 1887) und "Telefon-Transfer-Technologien" die Wurzeln eines Baums sind, der zur Entwicklung der ersten Computer führt. Mitte des 19. Jahrhunderts war der Telegraph, der Vorläufer des Telefons, in der ganzen Welt, seine diskrete und Unterscheidungskraft, die die Schrift als "dots and Dashes" bezeichnete. Bis Ende des 19. Jahrhunderts war der Zeckenband (ca-24s) im Einsatz, wie die Verwendung von kirith-Karten in der Volkszählung der U.S. Dann kam der Teleprinter (ca.19) mit seiner gestreckten Papierverwendung von Baudot Code auf Bürokratie. Telefon-Switching-Netze elektromechanischer Relais (entschlossen 1835) standen hinter der Arbeit von George Stibitz (1937), dem Erfinder des digitalen Zusatzgeräts. Als er in Bell Laboratories arbeitete, beobachtete er die "burdensome"-Nutzung von mechanischen Rechenrechnern mit Getrieben. " Er war ein Abend im Jahr 1937, um seine Idee zu testen... Stibitz hat ein binäres Zusatzgerät aufgebaut. Davis (2000) weist auf die besondere Bedeutung des elektromechanischen Relais (mit seinen zwei "gemeinsamen Staaten" offen und geschlossen): Erst mit der Entwicklung, angefangen in den 1930er Jahren, elektromechanischer Rechenrechner mit elektrischen Relais, wurden Maschinen gebaut, die den Anwendungsbereich von B-Hage haben. Mathematik im 19. Jahrhundert bis zum Mitte des 20. Jahrhunderts Symbolen und Regeln: Kurzum folgend reduzierte die Mathematik von George JAle (1847, 1854), Gottlob Frege (1879) und Giuseppe Peano (1888-1889) eine Reihe von Symbolen, die durch Regeln missbraucht werden. Peano's Die Grundsätze der Arithmetic, die durch eine neue Methode (1888) vorgestellt wurden, waren "der erste Versuch, Mathematik in einer symbolischen Sprache zu besticken". Heijenoort gibt Frege (1879) diese Krone: Frege's ist "die wichtigste einzelne Arbeit, die je in Logik geschrieben wurde. .in der wir eine "formulasprache" sehen, die eine lingua- Charakterica ist, eine Sprache, die mit besonderen Symbolen geschrieben ist, "für reiner Gedanken", die frei von rhetorischen Verzierungen ... aus bestimmten Symbolen, die nach klaren Regeln missbraucht werden. Die Arbeit von Frege wurde weiter vereinfacht und von Alfred North Whitehead und Bertrand Russell in ihrem Principia KPMG (1910-1913) vervollständigt. Paradoxe: Gleichzeitig gab es in der Literatur mehrere beunruhigende Paradoxe, insbesondere das Burali-Forti- Paradox (1897), das Russell Paradox (1902-03) und das Richard Paradox. Die ergebnisführenden Überlegungen führten zu dem Papier von Kurt Gödel (1931) – er verdeutlicht insbesondere das Paradox des Liars – was die Wiedereinziehungsregeln auf Zahlen vollständig verringert. Wirksamkeit: In einem Bemühen um die Lösung des Problems, das genau von Hilbert im Jahr 1929 definiert wurde, wurde zunächst festgelegt, was durch eine "effektive Methode" oder "effektive Berechnung" oder eine "effektive Reifung" (d. h. eine Berechnung, die Erfolg hätte). Nach dem raschen Nachlass gab es folgendes: Alonzo Church, Stephen Kleene und J.B Rosser's .-calité, eine rigorose Definition der "allgemeinen Recursion" von der Arbeit von Gödel, die auf Vorschläge von Jacques Herbrand (vgl.Gödel's Reden von 1934) und anschließende Vereinfachungen durch Kleene. Nachweis der Kirche, dass das Problems unolvierbar war, die Definition der effektiven Reifung von Emil Post als Arbeitnehmerin nach einer Liste der Anweisungen, die sich aus einer Reihe von Räumen ergeben, zu verschieben oder durchzusetzen, entweder ein Papier oder ein Papier zu löschen oder das Papier zu beobachten und eine ja-no-Entscheidung über die nächste Anleitung zu treffen. Alan Turing hat den Nachweis erbracht, dass das Problems durch die Verwendung seiner "a-[automat]-Maschine" undurchlässig war – in Wirklichkeit fast identisch mit der Formulierung der Post, J. Barkley Rosser Definition der "effektiven Methode" in Bezug auf "a-Maschine". Kleene's Vorschlag eines Vorläufers für "Curch thesis", den er "Thesis I" und einige Jahre später Kleene's Renaming seine Thesis "Church's Thesis" und schlug "Turing's Thesis" vor. Emil Post (1936) und Alan Turing (1936-37, 1939)Emil Post (1936) bezeichneten die Maßnahmen eines Computers (menschlicherweise) wie folgt: ".zwei Konzepte sind betroffen: die eines Symbolraums, in dem die Arbeit vor dem Problem zu beantworten ist, und ein festes, unalterliches Regelwerk. Sein Symbolraum wäre "eine zweiseitige unendliche Sequenz von Räumen oder Boxen... In diesem Symbolraum, der in der Lage ist, sich in einer Box zu befinden und in einer Zeit zu betreiben....a Box ist, um zwei mögliche Bedingungen zuzulassen, d.h. leer oder unklar zu sein und eine einzige Marke in dieser Form zu haben, einen vertikalen Schlag. " Eine Box ist zu vereinzelt und wird als Ausgangspunkt bezeichnet. .ein spezifisches Problem wird in symbolischer Form durch eine finite Anzahl von Boxen [i.e, INPUT] mit einem Schlaganfall gekennzeichnet. Ebenso soll die Antwort [i.e, OUTPUT] in symbolischer Form von einer solchen Konfiguration gekennzeichneter Boxen erhalten... "Eine Reihe von Leitlinien, die für ein allgemeines Problem gelten, legt bei jedem spezifischen Problem einen deterministischen Prozess fest. Dieser Prozess endet nur, wenn es um die Richtung des Typs geht (C ) [i.e, STOP]). Mehr auf Post-Turing-Maschine Alan Turings vor der Arbeit von Stibitz (1937); es ist unbekannt, ob Stibitz über die Arbeit von Turing wusste. Turings Biographer glaubte, dass Turing von einem jugendfreundlichen Modell Gebrauch gemacht hat: „Alan hatte den Traum der Erfindung von Typautoren als Jungen; Frau Turing hatte einen Typautor, und er konnte sich wohl mit der Frage beginnen, was durch die Angabe eines Typautors bedeutete. Angesichts der Prävalenz des Morse-Codes und der Telegraphie, des Zeckenbandapparats und der Teletypautoren könnten wir alle beeinflussen. Turing – das Modell der Berechnung wird nun als Turing-Maschine bezeichnet, wie es Post, mit einer Analyse eines menschlichen Computers, der sich auf eine einfache Form von Grundhandlungen und "staatlichen Geistes" behebt. Er setzt jedoch einen Schritt weiter und schafft eine Maschine als Modell für die Berechnung der Nummern. " Computer wird normalerweise mit bestimmten Symbolen auf Papier gemacht. Wir können dieses Papier in Quadrate wie ein Kinderbuch zusammenfassen... Ich gehe davon aus, dass die Berechnung auf einemdimensionalen Papier durchgeführt wird, d.h. auf einem bürokratischen Teil in Quadrate. Ich werde auch davon ausgehen, dass die Anzahl der Symbole, die gedruckt werden können, finite... "Das Verhalten des Computers zu jedem Zeitpunkt wird von den Symbolen bestimmt, die er beobachtet, und seinem "Stand" zu diesem Zeitpunkt. Man kann davon ausgehen, dass es ein B an die Anzahl der Symbole oder Quadrate gibt, die der Computer zu einem Zeitpunkt beachten kann. Wenn er mehr beobachten möchte, muss er aufeinanderfolgende Beobachtungen zurückgreifen. Wir werden auch davon ausgehen, dass die Zahl der Staaten, die berücksichtigt werden müssen, finite ist... "Wir sehen uns vor, dass die von dem Computer durchgeführten Operationen in "einfache Operationen" aufgeteilt werden, die so elementar sind, dass es ihnen nicht einfach ist, sich weiter auseinanderzusetzen. "Verringerungserträge: "Die einfachen Operationen müssen daher folgendes umfassen: ("a) Änderungen des Symbols auf einem der beobachteten Quadrate ("b) Veränderungen eines der Quadrate, die in einem der zuvor beobachteten Quadrate auf einem anderen Quadratmeter zu beobachten sind. " Man kann sein, dass einige dieser Veränderungen zwangsläufig einen Mentalitätswandel geltend machen. Die allgemeinste Einzelaktion muss daher einer der folgenden sein: ("A") mögliche Änderung (a) des Symbols zusammen mit einer möglichen Änderung des Zustands. „B) Eine mögliche Änderung (b) der beobachteten Quadrate sowie eine mögliche Änderung des Geisteszustands“ können wir jetzt eine Maschine für die Arbeit dieses Computers einrichten. " Afew Jahre später hat Turing seine Analyse (Thesis, Definition) mit diesem gewalttätigen Ausdruck erweitert: "Eine Funktion wird als "effektiv kalkulierbar" bezeichnet, wenn ihre Werte durch einen rein mechanischen Prozess gefunden werden können. Obwohl es recht einfach ist, diese Idee zu verstehen, ist es aber wünschenswert, einige noch klarere, mathematische Definitionen zu haben [.he er diskutiert die Geschichte der Definition ziemlich viel wie oben in Bezug auf Gödel, Herbrand, Kleene, Kirche, Turing und Post] . Wir können diese Erklärung wörtlich annehmen, indem wir ein rein mechanisches Verfahren verstehen, das von einer Maschine durchgeführt werden könnte. Es ist möglich, eine mathematische Beschreibung der Strukturen dieser Maschinen in einer bestimmten normalen Form zu geben. Die Entwicklung dieser Ideen führt zu der Definition einer vernachlässigbaren Funktion des Autors und zur Ermittlung der Komputierbarkeit † mit einer wirksamen Reifung ... . Wir verwenden den Ausdruck "komputable Funktion", um eine von einer Maschine kalkulierbare Funktion zu schaffen, und wir lassen uns "effektiv kalkulierbar" auf die harmonische Idee verweisen, ohne dass eine dieser Definitionen genau definiert wird. J.B Rosser (1939) und S.C Kleene (1943) J. Barkley Rosser definiert eine „effektive [mathematische] Methode“ auf folgende Weise (Grundisierung hinzugefügt): „"Effective Methode" wird hier im eher besonderen Sinne einer Methode verwendet, die genau bestimmt ist und die bestimmte Antwort in einer finiteten Zahl von Schritten herstellt. Mit dieser besonderen Bedeutung wurden bisher drei verschiedene präzise Definitionen gegeben. [Diese Fußnote #; siehe Diskussion unmittelbar unten]. Kurz gesagt, dass eine wirksame Lösung für bestimmte Probleme besteht, wenn eine Maschine aufgebaut werden kann, die dann ein Problem des Set mit keinem menschlichen Eingriff lösen kann, der über die Aufnahme der Frage hinausgeht und (lateer) die Antwort lesen wird.Alle drei Definitionen sind gleichwertig, so dass es keine Materie ist, die einer verwendet wird. Darüber hinaus ist die Tatsache, dass alle drei gleichwertig sind, ein sehr starkes Argument für die Richtigkeit jeder." (Roser 1939226)Roser Fußnote Nr. 5 verweist auf die Arbeit von (1) Kirche und Kleene und deren Definition von of-Definability, insbesondere die Nutzung der Kirche in ihrem undurchlässigen Problem der Grund-Nummerntheorie (1936); (2) Herbrand und Gödel und ihre Verwendung von Recursionen insbesondere in seinem berühmten Papier Kurzbeschreibungen von Principia KPMG und verwandten Systemen I (1931); und (3) Post (1936) und Turing (1936-37) in ihren Rechenmodellen. Stephen C. Kleene definiert als seine jetzt bekannte "Thesis I", die als Kirche bekannt ist, um die Lage zu gewährleisten. Aber er hatte dies im folgenden Kontext (gefesselt in Original): "12.Algorithmie Theorien... In der Einführung einer vollständigen Algorithmentheorie, was wir tun, um ein Verfahren zu beschreiben, das für jede Reihe von Werten der unabhängigen Variablen geeignet ist, das Verfahren notwendigerweise zu beenden und in einer Weise, dass wir aus dem Ergebnis eine eindeutige Antwort lesen können, ja oder nein, auf die Frage, "das Prädikatwert gilt?" (Kleene 1964:273) Geschichte nach 1950 wurden eine Reihe von Anstrengungen unternommen, um die Definition des Algorithmus weiter zu verfeinern, und die Aktivität ist aufgrund von Problemen, insbesondere der Mathematikstiftung (vor allem der Kirche) und der Philosophie des Geistes (insbesondere von Argumenten über künstliche Intelligenz). Mehr siehe Algorithm Charakterisierungen. Siehe auch Literatur Weitere Lesung Außenbeziehungen Algorithm, Veröffentlichung von Mathematik, EMS Presse, 2001 [1994] Algorithms bei Curlie Weisstein, Eric W."Algorithm. MathWorld. Wörterbuch der Algorithms und Datenstrukturen – National Institute of Standards and TechnologyAlgorithm repositories Stony Brook Algorithm Register – Staatliche Universität New York bei Stony Brook sammeln Algorithms of the ACM – Association for Computing MaschinenThe Stanford GraphBase – Universität Stanford