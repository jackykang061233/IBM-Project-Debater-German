JPEG oder JPG (JAY-peg) ist eine häufig verwendete Methode der verlustfreien Kompression für digitale Bilder, insbesondere für Bilder, die durch digitale Fotografie erzeugt werden. Der Grad der Kompression kann eingestellt werden, so dass eine wählbare Abschaltung zwischen Speichergröße und Bildqualität ermöglicht. JPEG erreicht in der Regel 10:1 Kompression mit wenig wahrnehmbaren Verlust in Bildqualität. Seit seiner Einführung im Jahr 1992 ist JPEG der weltweit am weitesten verbreitete Bildkompressionsstandard und das am weitesten verbreitete digitale Bildformat, mit mehreren Milliarden JPEG-Bildern, die jeden Tag ab 2015 erstellt wurden. Der Begriff JPEG ist ein Initialismus/Akronym für die Joint Photographic Experts Group, die 1992 den Standard geschaffen hat. Basis für JPEG ist die diskrete Cosin-Transformation (DCT), eine verlustreiche Bildkompressionstechnik, die von Nasir Ahmed 1972 erstmals vorgeschlagen wurde. JPEG war weitgehend verantwortlich für die Verbreitung digitaler Bilder und digitaler Fotos im Internet und später sozialer Medien. Die JPEG-Kompression wird in einer Reihe von Bilddateiformaten verwendet. JPEG/Exif ist das häufigste Bildformat, das von Digitalkameras und anderen fotografischen Bildaufnahmegeräten verwendet wird; zusammen mit JPEG/JFIF ist es das häufigste Format, um fotografische Bilder im World Wide Web zu speichern und zu übertragen. Diese Formatvariationen werden oft nicht unterschieden und werden einfach JPEG genannt. Der MIME-Medientyp für JPEG ist Bild/Jpeg, mit Ausnahme von älteren Internet Explorer-Versionen, die eine MIME-Typ von Bild/Pjpeg beim Hochladen von JPEG-Bildern bietet. JPEG-Dateien haben in der Regel eine Dateinamen-Erweiterung von .jpgor jpeg. JPEG/JFIF unterstützt eine maximale Bildgröße von 65,535×65,535 Pixeln, also bis zu 4 Gigapixel für ein Seitenverhältnis von 1:1. Im Jahr 2000 stellte die JPEG-Gruppe ein Format vor, das als Nachfolger JPEG 2000 gedacht war, aber es konnte nicht das Original JPEG als dominanter Bildstandard ersetzen. Geschichte Hintergrund Die im Jahr 1992 veröffentlichte Original-JPEG-Spezifikation implementiert Verfahren aus verschiedenen früheren Forschungsarbeiten und Patenten, die von der CCITT (heute ITU-T, über die ITU-T Study Group 16) und Joint Photographic Experts Group zitiert werden. Die Hauptbasis für den verlustigen Kompressionsalgorithmus von JPEG ist die diskrete Cosinus-Transformation (DCT), die 1972 von Nasir Ahmed als Bildkompressionstechnik vorgeschlagen wurde. Ahmed entwickelte einen praktischen DCT-Algorithmus mit T. Natarajan der Kansas State University und K. R. Rao der University of Texas in Arlington 1973. Ihr Halbnal 1974 Papier wird in der JPEG-Spezifikation zitiert, zusammen mit mehreren späteren Forschungsarbeiten, die weitere Arbeiten an DCT, einschließlich einer 1977 Papier von Wen-Hsiung Chen, C.H Smith und S.C Fralick, die einen schnellen DCT-Algorithmus beschrieben, sowie eine 1978 Papier von N.J Narasinha und S.C Fralick, und eine 1984 Papier von B.G Lee. Die Spezifikation zitiert auch ein Papier von Wen-Hsiung Chen und W.K Pratt von 1984 als Einfluss auf seinen Quantisierungsalgorithmus, und David A. Huffmans 1952 Papier für seinen Huffman Codierungsalgorithmus. Die JPEG-Spezifikation zitiert Patente mehrerer Unternehmen. Die folgenden Patente bildeten die Grundlage für ihren arithmetischen Codierungsalgorithmus. IBM US Patent 4,652,856 – 4. Februar 1986 – Kottappuram M. A. Mohiuddin und Jorma J. Rissanen – Multiplikationsfreies Multi-alphabet-Arithmetic Code U.S Patent 4,905,297 – 27. Februar 1990 – G. Langdon, J.L Mitchell, W.B Pennebaker, und Jorma J. Rissanen – Arithmetische Kodierungs-Encoder- und Decoder-System U.S Patent 4,935.882 – 19. Juni 1990 – W.B Pennebaker und J.L Mitchell – Probability Adaptation für arithmetische Kodierer Mitsubishi Electric JP H02202267 (1021672) – 21. Januar 1989 – Toshihiro Kimura, Shigenori Kino, Fumitaka Ono, Masayuki Yoshida – Coding-System JP H03247123 (2-46275) – 26. Februar 1990 – Fumitaka Ono, Tomohiro Kimura, Masayuki Yoshida und Shigenori Kino – Coding-Gerät und CodierungsmethodeDie JP-Paten JP Weitere als Patentinhaber bezeichnete Unternehmen sind AT&T (zwei Patente) und Canon Inc. Abwesenheit aus der Liste ist US-Patent 4.698,672 eingereicht von Compression Labs' Wen-Hsiung Chen und Daniel J. Klenke im Oktober 1986. Das Patent beschreibt einen DCT-basierten Bildkompressionsalgorithmus und wäre später im Jahr 2002 eine Kontroversitätsursache (siehe Patentumstritten unten). In der JPEG-Spezifikation wurden jedoch zwei frühere Forschungsarbeiten von Wen-Hsiung Chen genannt, die 1977 und 1984 veröffentlicht wurden. JPEG Standard JPEG steht für Joint Photographic Experts Group, den Namen des Ausschusses, der den JPEG-Standard und auch andere noch bildgebende Standards erstellt hat. Das Joint stand für ISO TC97 WG8 und CCITT SGVIII. 1986 gegründet, entwickelte die Gruppe den JPEG-Standard in den späten 1980er Jahren. Unter mehreren von ihnen untersuchten Transformations-Kodierungstechniken wählten sie die diskrete Cosin-Transformation (DCT), wie sie bei weitem die effizienteste praktische Kompressionstechnik war. Die Gruppe veröffentlichte 1992 den JPEG-Standard. Im Jahr 1987 wurde ISO TC 97 ISO/IEC JTC1 und 1992 wurde CCITT ITU-T. Derzeit auf der JTC1-Seite, JPEG ist eine von zwei Untergruppen des ISO/IEC Joint Technical Committee 1, Unterkomitee 29, Arbeitsgruppe 1 (ISO/IEC JTC 1/SC 29/WG 1) – als Codierung von stillen Bildern. Auf der ITU-T-Seite ist ITU-T SG16 der jeweilige Körper. Die ursprüngliche JPEG-Gruppe wurde 1986 organisiert und veröffentlichte 1992 den ersten JPEG-Standard, der im September 1992 als ITU-T-Empfehlung T.81 und 1994 als ISO/IEC 10918-1 genehmigt wurde. Der JPEG-Standard gibt den Codec an, der definiert, wie ein Bild in einen Bytes-Stream komprimiert und wieder in ein Bild dekomprimiert wird, nicht aber das Dateiformat, das verwendet wird, um diesen Stream zu enthalten. Die Exif- und JFIF-Standards definieren die häufig verwendeten Dateiformate für den Austausch von JPEG-komprimierten Bildern. JPEG-Standards werden formal als Informationstechnologie bezeichnet – Digitale Kompression und Codierung von kontinuierlichen Ton Stillbildern. ISO/IEC 10918 besteht aus folgenden Teilen: Ecma International TR/98 gibt das JPEG File Interchange Format (JFIF;) die erste Ausgabe wurde im Juni 2009 veröffentlicht. Patentstreitigkeiten Im Jahr 2002 behauptete Forgent Networks, dass es sich im Besitz und durchsetze Patentrechte auf der JPEG-Technologie, die sich aus einem am 27. Oktober 1986 eingereichten Patent ergeben und am 6. Oktober 1987 erteilt wurde: US-Patent 4,698,672 von Compression Labs' Wen-Hsiung Chen und Daniel J. Klenke. Während Forgent damals keine Compression Labs besaß, verkaufte Chen später Compression Labs an Forgent, bevor Chen für Cisco weiter arbeitete. Dies führte dazu, dass Forgent das Eigentum über das Patent erworben hat. Die Ankündigung von Forgent 2002 hat einen Furor geschaffen, der an Unisyss Versuche erinnert, seine Rechte gegenüber dem GIF-Bildverdichtungsstandard zu behaupten. Das JPEG-Komitee untersuchte 2002 die Patentansprüche und war der Meinung, dass sie durch den Stand der Technik ungültig gemacht wurden, eine Sicht, die von verschiedenen Experten geteilt wurde. Das Patent beschreibt einen Bildkompressionsalgorithmus basierend auf der diskreten Cosinus-Transformation (DCT) eine verlustige Bildkompressionstechnik, die aus einem Papier von 1974 von Nasir Ahmed, T. Natarajan und K. R. Rao stammt. Wen-Hsiung Chen entwickelte ihre DCT-Technik weiter und beschreibt einen schnellen DCT-Algorithmus in einem 1977 Papier mit C.H Smith und S.C Fralick. Die JPEG-Spezifikation von 1992 zitiert sowohl das Papier von 1974 Ahmed als auch das Papier von 1977 Chen für seinen DCT-Algorithmus sowie ein Papier von 1984 von Chen und W.K Pratt für seinen Quantisierungsalgorithmus. Compression Labs wurde von Chen gegründet und war das erste Unternehmen, das DCT-Technologie vermarktet. Als Chen 1986 sein Patent für einen DCT-basierten Bildkompressionsalgorithmus mit Klenke eingereicht hatte, war der Großteil dessen, was später der JPEG-Standard werden würde, bereits in der Vorliteratur formuliert worden. Auch JPEG-Vertreter Richard Clark behauptete, dass Chen selbst in einem der JPEG-Komitees saß, aber Forgent leugnete diese Behauptung. Zwischen 2002 und 2004 konnte Forgent durch Lizenzierung ihres Patents an rund 30 Unternehmen rund 105 Millionen US-Dollar erhalten. Im April 2004 verklagte Forgent 31 weitere Unternehmen, um weitere Lizenzzahlungen durchzusetzen. Im Juli des gleichen Jahres reichte ein Konsortium von 21 großen Computerfirmen einen Gegenangriff ein, mit dem Ziel, das Patent zu ungültig zu machen. Darüber hinaus startete Microsoft im April 2005 eine separate Klage gegen Forgent. Im Februar 2006 stimmte das Patent- und Markenamt der Vereinigten Staaten zu, das JPEG-Patent von Forgent auf Antrag der Stiftung für öffentliches Patent erneut zu prüfen. Am 26. Mai 2006 fand die USPTO das Patent nach dem Stand der Technik ungültig. Die USPTO stellte auch fest, dass Forgent vom Stand der Technik wusste, aber sie vermeidet absichtlich das Patentamt zu erklären. Dies macht jede Beschwerde, das Patent in hohem Maße unwahrscheinlich wieder zu behaupten, erfolgreich zu sein. Forgent besitzt auch ein ähnliches Patent, das 1994 vom Europäischen Patentamt erteilt wurde, obwohl es unklar ist, wie durchsetzbar es ist. Ab dem 27. Oktober 2006 scheint die 20-jährige Laufzeit des US-Patents abgelaufen zu sein, und im November 2006 hat Forgent beschlossen, die Durchsetzung von Patentansprüchen gegen die Verwendung des JPEG-Standards aufzugeben. Das JPEG-Komitee hat als eines seiner ausdrücklichen Ziele, dass ihre Standards (insbesondere ihre Basismethoden) ohne Bezahlung von Lizenzgebühren implementierbar sind und entsprechende Lizenzrechte für ihren JPEG 2000-Standard von über 20 großen Organisationen gesichert haben. Ab August 2007 behauptete ein anderes Unternehmen, Global Patent Holdings, LLC, dass sein 1993 ausgestelltes Patent (US Patent 5,253,341) durch das Herunterladen von JPEG-Bildern auf einer Website oder per E-Mail verletzt wird. Wenn nicht ungültig, könnte dieses Patent auf jede Webseite, die JPEG-Bilder zeigt, gelten. Das Patent wurde von 2000 bis 2007 vom US-Patent- und Markenamt neu geprüft; im Juli 2007 hat das Patentamt alle ursprünglichen Patentansprüche des Patents widerrufen, aber festgestellt, dass ein zusätzlicher Anspruch von Global Patent Holdings (Anspruch 17) gültig war. Global Patent Holdings reichte dann eine Reihe von Klagen auf der Grundlage des Patentanspruchs 17 ein. In seinen ersten beiden Klagen nach der Reexamination, beide in Chicago, Illinois, Global Patent Holdings verklagt die Green Bay Packers, CDW, Motorola, Apple, Orbitz, Officemax, Caterpillar, Kraft und Peapod als Angeklagte. Eine dritte Klage wurde am 5. Dezember 2007 in South Florida gegen ADT Security Services, AutoNation, Florida Crystals Corp, eingereicht. HearUSA, MovieTickets.com, Ocwen Financial Corp. und Tire Kingdom, und eine vierte Klage am 8. Januar 2008, in South Florida gegen das Boca Raton Resort & Club. Eine fünfte Klage wurde gegen Global Patent Holdings in Nevada eingereicht. Diese Klage wurde von Zappos.com, Inc. eingereicht, die angeblich von Global Patent Holdings bedroht war, und eine gerichtliche Erklärung suchte, dass das "341 Patent ungültig und nicht verletzt ist. Global Patent Holdings hatte auch das "341-Patent"-Patent verwendet, um Kritiker von breiten Softwarepatenten zu verklagen oder zu bedrohen, darunter Gregory Aharonian und der anonyme Betreiber eines Website-Blogs, der als "Patent Troll Tracker" bekannt ist. Am 21. Dezember 2007 forderte der Patentanwalt Vernon Francissen von Chicago das US-Patent- und Markenamt auf, den einzigen Restanspruch des "341 Patents auf der Grundlage des neuen Standes der Technik neu zu prüfen. Am 5. März 2008 vereinbarte das US-Patent- und Markenamt, das "341-Patent neu zu prüfen, wobei der neue Stand der Technik erhebliche neue Fragen bezüglich der Gültigkeit des Patents aufgeworfen hat. Angesichts der Neuprüfung haben die angeklagten Verletzer in vier der fünf anhängigen Klagen Klagen Klagen eingereicht, um ihre Fälle bis zum Abschluss der Überprüfung des Patents und des Markenamts des Patents "341" auszusetzen (zurückhalten). Am 23. April 2008 erteilte Illinois, ein Richter, der über die beiden Klagen in Chicago presidiert, die Klagen in diesen Fällen. Am 22. Juli 2008 veröffentlichte das Patentamt die erste "Büroaktion" der zweiten Reexaminierung, die auf neunzehn separaten Gründen ungültig ist. Am 24. November 2009 wurde ein Reexaminationszertifikat ausgestellt, das alle Ansprüche aufheben konnte. Ab 2011 und Anfang 2013 begann ein Unternehmen namens Princeton Digital Image Corporation mit Sitz in Eastern Texas, eine große Anzahl von Unternehmen für angebliche Verletzung von US-Patent 4,813,056 zu verklagen. Princeton behauptet, dass der JPEG-Bildverdichtungsstandard das '056 Patent verletzt und hat große Anzahl von Websites, Einzelhändlern, Kamera- und Geräteherstellern und Wiederverkäufern verklagt. Das Patent wurde ursprünglich im Besitz und dem General Electric zugewiesen. Das Patent ist im Dezember 2007 abgelaufen, aber Princeton hat große Anzahl von Unternehmen wegen "Beschäftigung" dieses Patents angeklagt. (Unter den US-Patentgesetzen kann ein Patentinhaber bis zu sechs Jahren vor der Einreichung eines Klageverfahrens für "Beschäftigungsverletzung" verklagen, so dass Princeton theoretisch bis Dezember 2013 Unternehmen weiterverklagen konnte.) Seit März 2013 hatte Princeton Anzüge in New York und Delaware gegen mehr als 55 Unternehmen. Die Beteiligung von General Electric an dem Anzug ist unbekannt, obwohl die gerichtlichen Aufzeichnungen angeben, dass sie das Patent für Princeton im Jahr 2009 erteilt und bestimmte Rechte im Patent behält. Typische Verwendung Der JPEG Kompressionsalgorithmus arbeitet am besten auf Fotografien und Bildern mit glatten Variationen von Ton und Farbe. Es wird am besten für Farben und Graustufen-Nebenbilder verwendet, aber nicht für binäre Bilder. Für die Web-Nutzung, wo die Verringerung der Menge der Daten für ein Bild verwendet ist wichtig für die ansprechende Präsentation, JPEG Kompression Vorteile machen JPEG beliebt. JPEG/Exif ist auch das häufigste Format, das von Digitalkameras gespeichert wird. JPEG eignet sich jedoch nicht gut für Linienzeichnungen und andere textuelle oder ikonische Grafiken, bei denen die scharfen Kontraste zwischen benachbarten Pixeln spürbare Artefakte verursachen können. Solche Bilder werden besser in einem verlustfreien Grafikformat wie TIFF, GIF oder PNG gespeichert, und während der JPEG-Standard einen verlustfreien Codierungsmodus umfasst, wird der Modus nicht in vielen Produkten unterstützt, weil die Unfruchtbarkeit seiner Kompressionsschema im Vergleich zu anderen verlustfreien Formaten. Die ISO hat hierzu ein eigenes Dateiformat JPEG-LS entwickelt. Da JPEG ein verlustbehaftetes Kompressionsverfahren ist, das die Bildtreue reduziert, ist es für eine genaue Wiedergabe von Abbildungsdaten unangemessen (z.B. einige wissenschaftliche und medizinische Bildgebungsanwendungen und bestimmte technische Bildbearbeitungsarbeiten). JPEG-Dateien sind auch nicht gut geeignet, um mehrere Bearbeitungen zu unterziehen, da einige Bildqualität jedes Mal, wenn das Bild rekomprimiert wird, verloren geht – siehe digitale Erzeugungsverlust für Details. Um Bildinformationsverlust bei der sequentiellen und repetitiven Bearbeitung zu verhindern, kann die erste Bearbeitung in einem verlustfreien Format gespeichert werden, anschließend in diesem Format bearbeitet und anschließend als JPEG für die Distribution veröffentlicht werden. JPEG Kompression JPEG verwendet eine verlustige Form der Kompression basierend auf der diskreten Cosinus-Transformation (DCT). Diese mathematische Operation wandelt jeden Frame/Feld der Videoquelle aus der räumlichen (2D)-Domäne in den Frequenzbereich (a.k.a transform domain) um. Ein perzeptuelles Modell, das lose auf dem menschlichen psychovisuellen System basiert, verworfen hochfrequente Informationen, d.h. scharfe Übergänge in der Intensität und Farbton. In der Transformationsdomäne wird der Prozess der Informationsreduzierung als Quantisierung bezeichnet. Einfacher ausgedrückt ist die Quantisierung ein Verfahren zur optimalen Reduktion einer großen Anzahlskala (mit unterschiedlichen Vorkommen jeder Zahl) in eine kleinere, und die Transformationsdomäne ist eine bequeme Darstellung des Bildes, weil die hochfrequenten Koeffizienten, die weniger zum Gesamtbild beitragen als andere Koeffizienten, charakteristisch kleine Werte mit hoher Kompressibilität sind. Die quantisierten Koeffizienten werden dann sequenziert und verlustfrei in den Ausgangsbitstrom verpackt. Fast alle Software-Implementierungen von JPEG erlauben die Benutzerkontrolle über das Kompressionsverhältnis (sowie andere optionale Parameter), so dass der Benutzer Bildqualität für kleinere Dateigröße abtauschen kann. In Embedded-Anwendungen (wie MiniDV, die ein ähnliches DCT-Kompressionsschema verwendet), werden die Parameter für die Anwendung vorgewählt und fixiert. Das Kompressionsverfahren ist in der Regel verlustig, d.h., dass einige ursprüngliche Bildinformationen verloren gehen und nicht wiederhergestellt werden können, was die Bildqualität beeinflussen könnte. Es gibt einen optionalen verlustfreien Modus im JPEG-Standard. Dieser Modus ist jedoch nicht in Produkten weit verbreitet. Es gibt auch ein interlaced Progressive JPEG-Format, in dem Daten in mehreren Durchgängen von progressiv höherem Detail komprimiert werden. Dies ist ideal für große Bilder, die während des Downloads über eine langsame Verbindung angezeigt werden, so dass eine vernünftige Vorschau nach dem Empfang nur eines Teils der Daten. Unterstützung für progressive JPEGs ist jedoch nicht universell. Wenn progressive JPEGs von Programmen empfangen werden, die sie nicht unterstützen (wie Versionen von Internet Explorer vor Windows 7) zeigt die Software das Bild erst, nachdem sie vollständig heruntergeladen wurde. Eine Anzahl von Änderungen an einem JPEG-Bild kann verlustfrei (d.h. ohne Rekompression und den damit verbundenen Qualitätsverlust) ausgeführt werden, solange die Bildgröße ein Vielfaches von 1 MCU-Block (Minimum Coded Unit) ist (in beiden Richtungen üblicherweise 16 Pixel, für 4:2:0 chroma Subsampling). Zu den Einsatzmöglichkeiten gehören: jpegtran und seine GUI, Jpegcrop. IrfanView mit "JPG Lossless Crop (PlugIn") und "JPG Lossless Rotation (PlugIn), die die Installation des JPG_TRANSFORM Plugins erfordern. FastStone Image Viewer mit "Lossless Crop to File" und "JPEG Lossless Rotate". XnViewMP mit "JPEG verlustlosen Transformationen". ACDSee unterstützt verlustfreie Rotation (aber nicht verlustfreies Ernten) mit seiner Option "Force verlustfreie JPEG-Operationen". Blöcke können in 90-Grad-Inkrementen gedreht werden, in horizontalen, vertikalen und diagonalen Achsen umgelenkt und im Bild herum bewegt werden. Nicht alle Blöcke aus dem Originalbild müssen in der modifizierten verwendet werden. Die obere und linke Kante eines JPEG-Bildes muss auf einer 8 × 8 Pixel-Blockgrenze liegen, die untere und rechte Kante muss dies jedoch nicht tun. Dies begrenzt die möglichen verlustfreien Erntevorgänge und verhindert auch Flips und Rotationen eines Bildes, dessen untere oder rechte Kante nicht auf einer Blockgrenze für alle Kanäle liegt (weil die Kante oben oder links enden würde, wo – wie erwähnt – eine Blockgrenze obligatorisch ist). Rotationen, bei denen die Bildbreite und die Höhe nicht ein Vielfaches von 8 oder 16 (je nach Chroma-Unterabtastung) sind nicht verlustfrei. Durch Drehen eines solchen Bildes werden die Blöcke recomputiert, was zu Qualitätsverlusten führt. Bei der Verwendung von verlustfreiem Erntegut, wenn die Unterseite oder die rechte Seite des Erntegutgebietes nicht an einer Blockgrenze liegt, werden die übrigen Daten aus den teilbenutzten Blöcken noch in der Erntegutdatei vorliegen und wiederhergestellt werden können. Es ist auch möglich, zwischen Basis- und Progressive-Formate ohne Qualitätsverlust umzuwandeln, da der einzige Unterschied die Reihenfolge ist, in der die Koeffizienten in der Datei platziert werden. Weiterhin können mehrere JPEG-Bilder verlustfrei verbunden werden, solange sie mit gleicher Qualität gespeichert wurden und die Kanten mit Blockgrenzen zusammenfallen. JPEG Dateien Das als "JPEG Interchange Format" (JIF) bekannte Dateiformat ist in Anhang B der Norm angegeben. Dieses reine Dateiformat wird jedoch selten verwendet, vor allem wegen der Schwierigkeit, Encoder und Decoder zu programmieren, die alle Aspekte des Standards voll umsetzen und aufgrund bestimmter Mängel des Standards: Farbraumdefinition Komponenten-Unterabtastung Registrierung Pixel Aspekt-Verhältnis Definition. Mehrere zusätzliche Standards haben sich entwickelt, um diese Probleme zu behandeln. Die erste davon, veröffentlicht im Jahr 1992, war das JPEG File Interchange Format (oder JFIF), gefolgt in den letzten Jahren durch Exchangeable image file format (Exif) und ICC Farbprofile. Beide dieser Formate verwenden das tatsächliche JIF-byte-Layout, bestehend aus verschiedenen Markern, aber zusätzlich eine der Erweiterungspunkte des JIF-Standards, nämlich die Anwendungsmarker: JFIF verwendet APP0, während Exif APP1 verwendet. Innerhalb dieser Segmente der Datei, die für die zukünftige Verwendung im JIF-Standard übrig geblieben sind und nicht von ihm gelesen werden, fügen diese Standards spezifische Metadaten hinzu. So ist JFIF in gewisser Weise eine Cut-down-Version des JIF-Standards, indem es bestimmte Einschränkungen (z.B. nicht alle verschiedenen Codierungsmodi zulassen), während es auf andere Weise eine Erweiterung von JIF aufgrund der zusätzlichen Metadaten ist. Die Dokumentation der ursprünglichen JFIF-Standardzustände: JPEG File Interchange Format ist ein minimales Dateiformat, mit dem JPEG Bitstreams zwischen einer Vielzahl von Plattformen und Anwendungen ausgetauscht werden können.Dieses minimale Format enthält keine der erweiterten Funktionen, die in der TIFF JPEG-Spezifikation oder in jedem Anwendungs-spezifischen Dateiformat gefunden wurden. Auch sollte es für den einzigen Zweck dieses vereinfachten Formats nicht sein, den Austausch von JPEG komprimierten Bildern zu ermöglichen. Bilddateien, die JPEG-Komprimierung verwenden, werden häufig als "JPEG-Dateien" bezeichnet und in Varianten des JIF-Bildformats gespeichert. Die meisten Bilderfassungsgeräte (wie Digitalkameras), die JPEG ausgeben, erstellen tatsächlich Dateien im Exif-Format, das Format, auf das die Kameraindustrie für Metadatenaustausch standardisiert ist. Da der Exif-Standard hingegen keine Farbprofile erlaubt, speichert die meisten Bildbearbeitungssoftware-Stores JPEG im JFIF-Format und umfasst auch das APP1-Segment aus der Exif-Datei, um die Metadaten nahezu konform einzubinden; der JFIF-Standard wird etwas flexibel interpretiert. Streng genommen sind die JFIF- und Exif-Standards unvereinbar, da jeder angibt, dass sein Markersegment (APP0 bzw. APP1) zuerst erscheint. In der Praxis enthalten die meisten JPEG-Dateien ein JFIF-Markersegment, das dem Exif-Header vorangeht. Dies ermöglicht älteren Lesern, das ältere Format JFIF-Segment korrekt zu handhaben, während neuere Leser auch das folgende Exif-Segment decodieren, weniger streng darüber, dass es zuerst erscheinen muss. JPEG Dateinamen Erweiterungen Die häufigsten Dateinamen-Erweiterungen für Dateien mit JPEG-Kompression sind .jpgand .jpeg, obwohl .jpe, .jfif und .jif verwendet werden. Es ist auch möglich, dass JPEG-Daten in andere Dateitypen eingebettet werden – TIFF kodierte Dateien oft ein JPEG-Bild als Miniaturbild des Hauptbildes einbetten; und MP3 Dateien können ein JPEG der Cover-Art im ID3v2-Tag enthalten. Farbprofil Viele JPEG-Dateien haben ein ICC-Farbprofil (Farbraum) eingeprägt. Häufig verwendete Farbprofile umfassen sRGB und Adobe RGB. Da diese Farbräume eine nichtlineare Transformation verwenden, beträgt der dynamische Bereich einer 8-Bit-JPG-Datei etwa 11 Stopps; siehe Gammakurve. Syntax und Struktur Ein JPEG-Bild besteht aus einer Sequenz von Segmenten, die jeweils mit einem Marker beginnen, von denen jeder mit einem 0xFF-Byte beginnt, gefolgt von einem Byte, der angibt, welche Art von Marker es ist. Einige Marker bestehen aus nur diesen zwei Bytes; andere folgen zwei Bytes (hoher dann niedrig), die die Länge der Marker-spezifischen Nutzdaten angeben, die folgt.( Die Länge umfasst die beiden Bytes für die Länge, nicht aber die beiden Bytes für den Marker.) Einige Marker werden von entropiecodierten Daten gefolgt; die Länge eines solchen Markers umfasst nicht die entropiecodierten Daten. Beachten Sie, dass aufeinanderfolgende 0xFF-Bytes als Füllbytes für Polsterzwecke verwendet werden, obwohl diese Füllbytepadding nur für Markierungen stattfinden sollte, die unmittelbar nach entropiecodierten Scandaten (siehe JPEG Spezifikation Abschnitt B.1.1.2 und E.1.2 für Details; speziell "In allen Fällen, in denen Marker nach den komprimierten Daten angehängt werden, können optionale 0xFF-Füllbytes dem Marker vorangehen"). Innerhalb der entropiecodierten Daten wird nach einem 0xFF-Byte vor dem nächsten Byte ein 0x00-Byte durch den Encoder eingefügt, so dass es nicht zu einem Marker kommt, der keine beabsichtigt ist, um die Fehler zu verhindern. Decoder müssen diese 0x00 Byte überspringen. Diese Technik, genannt Byte-Stopfen (siehe JPEG-Spezifikation Abschnitt F.1.2.3,) wird nur auf die entropiecodierten Daten angewendet, nicht auf Marker-Payload-Daten. Beachten Sie jedoch, dass entropiecodierte Daten einige eigene Marker haben; speziell die Reset-Marker (0xD0 bis 0xD7,), die verwendet werden, um unabhängige Bruchstücke von entropiecodierten Daten zu isolieren, um eine parallele Decodierung zu ermöglichen, und Encoder sind frei, diese Reset-Marker in regelmäßigen Abständen einzufügen (obwohl nicht alle Encoder dies tun.) Es gibt andere Start Of Frame-Marker, die andere Arten von JPEG-Codierungen vorstellen. Da mehrere Anbieter den gleichen APPn-Markertyp verwenden können, beginnen anwendungsspezifische Marker oft mit einem Standard- oder Herstellernamen (z.B. Exif oder Adobe) oder einem anderen Identifikationszeichen. Bei einem Neustart-Marker werden Block-zu-Block-Prädiktor-Variablen zurückgesetzt und der Bitstream auf eine Byte-Grenz synchronisiert. Restart-Marker bieten Mittel zur Wiederherstellung nach Bitstream-Fehler, wie Übertragung über ein unzuverlässiges Netzwerk oder Datei Korruption. Da die Abläufe von Makroblöcken zwischen Neustartmarkern unabhängig voneinander decodiert werden können, können diese parallel decodiert werden. JPEG Codec Beispiel Obwohl eine JPEG-Datei auf verschiedene Weise codiert werden kann, am häufigsten wird sie mit JFIF-Encoding durchgeführt. Der Codierungsprozess besteht aus mehreren Schritten: Die Darstellung der Farben im Bild wird in Y'CBCR umgewandelt, bestehend aus einer Helligkeit repräsentierenden Lumakomponente (Y,') und zwei Chroma-Komponenten (CB und CR), die Farbe repräsentieren. Dieser Schritt ist manchmal übersprungen. Die Auflösung der Chroma-Daten wird in der Regel um den Faktor 2 oder 3 reduziert. Dies spiegelt die Tatsache wider, dass das Auge weniger empfindlich auf feine Farbdetails ist als auf feine Helligkeitsdetails. Das Bild wird in Blöcke von 8 x 8 Pixeln aufgeteilt, und für jeden Block durchläuft jede der Y-, CB- und CR-Daten die diskrete Cosinustransformation (DCT). Eine DCT ist ähnlich einer Fourier-Transformation in dem Sinne, dass sie eine Art räumliches Frequenzspektrum erzeugt. Die Amplituden der Frequenzkomponenten werden quantisiert. Die menschliche Vision ist viel empfindlicher gegenüber kleinen Farb- oder Helligkeitsschwankungen über große Bereiche als der Stärke von hochfrequenten Helligkeitsschwankungen. Daher werden die Größen der Hochfrequenzkomponenten mit geringerer Genauigkeit gespeichert als die niederfrequenten Komponenten. Die Qualitätseinstellung des Encoders (z.B. 50 oder 95 in einer Skala von 0–100 in der Bibliothek der Unabhängigen JPEG-Gruppe) wirkt sich insofern aus, als die Auflösung jeder Frequenzkomponente reduziert wird. Wird eine zu geringe Qualitätseinstellung verwendet, werden die Hochfrequenzkomponenten insgesamt verworfen. Die resultierenden Daten für alle 8×8 Blöcke werden mit einem verlustfreien Algorithmus, einer Variante der Huffman-Codierung, weiter komprimiert. Der Decodiervorgang rückt diese Schritte außer der Quantisierung zurück, weil er irreversibel ist. Im übrigen werden die Kodierungs- und Decodierverfahren näher beschrieben. Viele der Optionen im JPEG-Standard werden nicht häufig verwendet, und wie oben erwähnt, verwendet die meisten Bildsoftware das einfachere JFIF-Format beim Erstellen einer JPEG-Datei, die unter anderem die Codierung Methode angibt. Hier ist eine kurze Beschreibung einer der häufigeren Methoden der Codierung bei der Anwendung auf einen Eingang, der 24 Bit pro Pixel (jeweils rot, grün und blau) hat. Diese spezielle Option ist ein verlustfreies Datenkompressionsverfahren. Farbraumtransformation Zunächst sollte das Bild von RGB in einen anderen Farbraum namens Y'CBCR (oder informell YCbCr) umgewandelt werden. Es weist drei Komponenten Y,' CB und CR auf: die Y'-Komponente stellt die Helligkeit eines Pixels dar, und die CB- und CR-Komponenten stellen die Chrominanz dar (in blaue und rote Komponenten zerlegt). Dies ist im Grunde der gleiche Farbraum wie durch digitales Farbfernsehen sowie digitales Video einschließlich Video DVDs verwendet, und ist ähnlich wie die Farbe in analogem PAL-Video und MAC dargestellt (aber nicht durch analoge NTSC, die den YIQ-Farbraum verwendet). Die Y'CBCR-Farbraumumwandlung ermöglicht eine größere Kompression ohne nennenswerte Wirkung auf die Wahrnehmungsbildqualität (oder eine größere Wahrnehmungsbildqualität für dieselbe Kompression). Die Komprimierung ist effizienter, da die Helligkeitsinformation, die für die endgültige Wahrnehmungsqualität des Bildes wichtiger ist, auf einen einzigen Kanal beschränkt ist. Dies entspricht näher der Wahrnehmung der Farbe im menschlichen Sichtsystem. Die Farbtransformation verbessert auch die Komprimierung durch statistische Dekorrelation. Eine bestimmte Konvertierung in Y'CBCR ist im JFIF-Standard angegeben und sollte für die resultierende JPEG-Datei durchgeführt werden, um eine maximale Kompatibilität zu haben. Einige JPEG-Implementierungen im Modus "höchste Qualität" wenden diesen Schritt jedoch nicht an und halten stattdessen die Farbinformationen im RGB-Farbmodell, wo das Bild in separaten Kanälen für rote, grüne und blaue Helligkeitskomponenten gespeichert wird. Dies führt zu einer weniger effizienten Kompression und würde nicht wahrscheinlich verwendet werden, wenn die Dateigröße besonders wichtig ist. Nach oben Durch die Dichte an farb- und hellempfindlichen Rezeptoren im menschlichen Auge kann der Mensch in der Helligkeit eines Bildes (die Y'-Komponente) deutlich feiner als in der Farbsättigung eines Bildes (die Cb- und Cr-Komponenten) sehen. Mit diesem Wissen können Encoder so konstruiert werden, dass sie Bilder effizienter komprimieren. Die Transformation in das Y'CBCR-Farbmodell ermöglicht den nächsten üblichen Schritt, der die räumliche Auflösung der Cb- und Cr-Komponenten (untersampling oder "chroma subsampling") reduziert. Die für JPEG-Bilder üblichen Verhältnisse, bei denen die Downsampling für JPEG-Bilder durchgeführt wird, betragen 4:4:4 (keine Downsampling,) 4:2:2 (Reduktion um den Faktor 2 in horizontaler Richtung), oder (meistens) 4:2:0 (Reduktion um den Faktor 2 in horizontaler und vertikaler Richtung). Für den Rest des Kompressionsprozesses werden Y', Cb und Cr getrennt und in sehr ähnlicher Weise verarbeitet. Blockaufteilung Nach der Subsampling muss jeder Kanal in 8 x 8 Blöcke aufgeteilt werden. Je nach Chroma-Subsampling ergibt diese minimale kodierte Einheit (MCU) Blöcke der Größe 8×8 (4:4:4 – keine Subsampling,) 16×8 (4:2:2,) oder am häufigsten 16×16 (4:2:0). In der Videokompression werden MCUs Makroblöcke genannt. Wenn die Daten für einen Kanal keine ganze Anzahl von Blöcken darstellen, muss der Encoder den restlichen Bereich der unvollständigen Blöcke mit einer Form von Dummy-Daten füllen. Das Befüllen der Kanten mit fester Farbe (z.B. schwarz) kann entlang des sichtbaren Teils der Grenze zu ringförmigen Artefakten führen; das Wiederholen der Kantenpixel ist eine gemeinsame Technik, die solche Artefakte reduziert (aber nicht notwendigerweise beseitigt), und es können auch anspruchsvollere Grenzfülltechniken angewendet werden. Diskrete Cosinus-Transformation Nächster wird jeder 8×8 Block jeder Komponente (Y, Cb, Cr) unter Verwendung einer normierten, zweidimensionalen Typ-II diskreten Cosinus-Transformation (DCT) in eine frequenzdomain-Repräsentation umgewandelt. Die DCT wird manchmal als "Typ-II DCT" im Kontext einer Transformationsfamilie wie in diskreter Cosinustransformation bezeichnet und die entsprechende Inverse (IDCT) als "Typ-III DCT" bezeichnet. Ein solches 8 x 8-Bit-Unterbild kann beispielsweise sein: Vor der Berechnung des DCT des 8 x 8-Blocks werden seine Werte von einem positiven Bereich auf einen Nullpunkt verschoben. Für ein 8-Bit-Bild fällt jeder Eintrag im ursprünglichen Block in den Bereich [0, 255] \{displaystyle [0,255}] .Der Mittelpunkt des Bereichs (hier der Wert 128) wird von jedem Eintrag subtrahiert, um einen Datenbereich zu erzeugen, der auf Null zentriert ist, so dass der geänderte Bereich folgt [Dieser Bereich ist 128 , 127 ] \{displaystyle -[128,127}] . Dieser Schritt führt zu folgenden Werten: Der nächste Schritt ist die zweidimensionale DCT zu nehmen, die gegeben ist durch: wobei u \{displaystyle \} die horizontale Raumfrequenz ist, für die Zahlen 0 ≤ u < 8 \{displaystyle \ 0\leq u<8} ist. Wenn wir diese Transformation auf unserer Matrix oben durchführen, erhalten wir folgende (gerundet auf die nächsten zwei Ziffern jenseits des Dezimalpunktes:) Beachten Sie den oberen linken Eckeingang mit der ziemlich großen Größe. Dies ist der DC-Koeffizient (auch als Konstantkomponente bezeichnet), der den Grundton für den gesamten Block definiert. Die restlichen 63 Koeffizienten sind die AC Koeffizienten (auch als Wechselkomponenten bezeichnet). Der Vorteil des DCT ist seine Tendenz, den größten Teil des Signals in einer Ecke des Ergebnisses zu aggregieren, wie oben zu erkennen ist. Der nachfolgende Quantisierungsschritt beschleunigt diesen Effekt bei gleichzeitiger Reduzierung der Gesamtgröße der DCT-Koeffizienten, was zu einem Signal führt, das sich in der Entropiestufe leicht komprimieren lässt. Die DCT erhöht zeitweise die Bittiefe der Daten, da die DCT-Koeffizienten eines 8-Bit/Komponenten-Bildes bis zu 11 oder mehr Bits (je nach Treue der DCT-Berechnung) speichern. Dies kann den Codec dazu zwingen, diese Koeffizienten zeitweilig mit 16-Bit-Nummern zu halten, wobei die Größe der Bilddarstellung an dieser Stelle verdoppelt wird; diese Werte werden typischerweise durch den Quantisierungsschritt auf 8-Bit-Werte reduziert. Die temporäre Vergrößerung in dieser Phase ist für die meisten JPEG-Implementierungen kein Leistungsbedenken, da typischerweise während des Bildcodierens oder Decodierens nur ein sehr kleiner Teil des Bildes in voller DCT-Form gespeichert wird. Menge Das menschliche Auge ist gut, kleine Helligkeitsunterschiede über einen relativ großen Bereich zu sehen, aber nicht so gut bei der Unterscheidung der exakten Stärke einer hochfrequenten Helligkeitsvariation. Dadurch kann die Informationsmenge in den Hochfrequenzkomponenten stark reduziert werden. Dies geschieht durch einfache Aufteilung jeder Komponente im Frequenzbereich durch eine Konstante für diese Komponente und anschließende Rundung auf die nächste ganze Zahl. Dieser Rundungsvorgang ist der einzige verlustbehaftete Betrieb im gesamten Prozess (außer Chroma-Unterstich), wenn die DCT-Rechnung mit ausreichend hoher Präzision durchgeführt wird. Hierdurch ist es typischerweise der Fall, dass viele der höheren Frequenzanteile auf Null gerundet sind und viele der übrigen zu kleinen positiven oder negativen Zahlen werden, die viele weniger Bits darstellen. Die Elemente in der Quantisierungsmatrix steuern das Kompressionsverhältnis, wobei größere Werte eine größere Kompression bewirken. Eine typische Quantisierungsmatrix (für eine Qualität von 50 % wie im Original JPEG Standard angegeben) ist wie folgt: Die quantisierten DCT-Koeffizienten werden berechnet, mit denen G \{displaystyle G} die unquantisierten DCT-Koeffizienten ist; Q \{displaystyle Q} ist die Quantisierungsmatrix oben; und B \{displaystyle B} sind die quantisierten DCT-Koeffizienten. Mit dieser Quantisierungsmatrix mit der DCT-Koeffizientenmatrix von oben ergibt sich: Beispielsweise mit -415 (dem DC-Koeffizienten) und Rundung auf die nächste ganze Zahl Hinweis, dass die meisten höherfrequenten Elemente des Subblocks (d.h. solche mit einer x- oder y-Raumfrequenz größer als 4) in Nullwerte quantisiert werden. Entropy Codierung Entropy Codierung ist eine spezielle Form der verlustfreien Datenkompression. Es besteht die Aufgabe, die Bildkomponenten in zickzackiger Reihenfolge unter Verwendung von Run-Länge-Codierung (RLE)-Algorithmus zu arrangieren, der ähnliche Frequenzen zusammen gruppent, Längen-Codierung Nullen eingibt und dann Huffman-Codierung auf dem linken. Der JPEG-Standard erlaubt es, aber nicht erforderlich, Decoder, die Verwendung von arithmetischen Codierung zu unterstützen, die der Huffman Codierung mathematisch überlegen ist. Dieses Feature wurde jedoch selten verwendet, da es historisch von Patenten abgedeckt war, die Lizenzen für Lizenzen benötigen, und weil es im Vergleich zu Huffman-Codierung langsamer zu kodieren und zu decodieren ist. Arithmetische Codierung macht typischerweise Dateien um 5–7% kleiner. Der bisher quantisierte DC-Koeffizient wird verwendet, um den aktuellen quantisierten DC-Koeffizienten vorherzusagen. Die Differenz zwischen den beiden ist anstatt des Istwerts kodiert. Die Codierung der 63 quantisierten Wechselstromkoeffizienten nutzt nicht eine solche Vorhersagedifferenzierung. Die Zickzack-Sequenz für die oben genannten quantisierten Koeffizienten ist im folgenden dargestellt. ( Das gezeigte Format ist nur für einfaches Verständnis/Betrachten.) , i, i, i, i, i Dieser Kodierungsmodus wird als Basiszeilensequenzcodierung bezeichnet.Baseline JPEG unterstützt auch die progressive Codierung. Während sequentielle Kodierung Koeffizienten eines einzelnen Blocks zu einem Zeitpunkt (zickzackartig) kodiert progressive Kodierung kodiert ähnlich positionierte Koeffizienten aller Blöcke in einem Go (als Scan bezeichnet), gefolgt von der nächsten Koeffizientenreihe aller Blöcke und so weiter. Wird das Bild beispielsweise in N 8×8 Blöcke B 0, B 1 , B 2 ,..., B n - 1 \{displaystyle B_{0}, B_{1}, B_{2},..., B_{n-1 , dann eine 3-scan progressive Codierung codiert DC-Komponente B i ( 0 , 0 ) \{display B_=0e. Es folgt der zweite Scan, der (die vier weitere Komponenten annimmt) B i ( 0, 1 ) \{displaystyle B_{i}(0,1) bis B i ( 1 , 1 ) \{displaystyle B_{i}(1,1) codiert, noch zickzackförmig. Die Koeffizientenfolge ist an dieser Stelle: B 0 (0, 1 ) , B 0 (1 , 0 ) , B 0 (2 , 0 ) , B 0 (1 , 1 ) , B 1 (0 , 1 ) , B 1 (1 , 0 ) , B N (Play, 0 ) , B N (1 ) Sind alle gleichgestellten Koeffizienten codiert, so ist die nächste zu kodierende Position die nächste in der Zickzack-Traversal, wie in der obigen Abbildung angegeben. Es hat sich gezeigt, dass die Basislinien-Strecken- JPEG-Codierung in der Regel eine bessere Komprimierung im Vergleich zu Basislinien-Sequential JPEG aufgrund der Fähigkeit, verschiedene Huffman-Tabellen (siehe unten) zu verwenden, die auf verschiedene Frequenzen auf jeden Scan oder Pass zugeschnitten sind (die ähnliche Positions-Koeffizienten enthält), obwohl die Differenz nicht zu groß ist. Im übrigen wird angenommen, dass das erzeugte Koeffizientenmuster auf sequentiellem Modus zurückzuführen ist. Um das oben generierte Koeffizientenmuster zu kodieren, verwendet JPEG Huffman-Encoding. Der JPEG-Standard bietet allgemeine Huffman-Tabellen, obwohl Encoder auch wählen können, um dynamisch Huffman-Tabellen zu erzeugen, die für die tatsächlichen Frequenzverteilungen in Bildern optimiert sind. Der Prozess der Kodierung der zickzack-quantisierten Daten beginnt mit einer Run-Länge-Codierung, wobei x der nicht-Null-quantisierte AC-Koeffizient ist. RUNLENGTH ist die Anzahl der Nullen, die vor diesem nicht-Null-AC-Koeffizienten kam. SIZE ist die Anzahl der Bits, die für die Darstellung von x erforderlich sind. AMPLITUDE ist die Bit-Repräsentation von x. Die Längencodierung funktioniert durch Prüfung jedes Nicht-Null-AC-Koeffizienten x und Bestimmung, wie viele Nullen vor dem vorherigen AC-Koeffizienten kamen. Mit diesen Informationen werden zwei Symbole erstellt: Sowohl RUNLENGTH als auch SIZE liegen auf demselben Byte, was bedeutet, dass jeder nur vier Bits Information enthält. Die höheren Bits befassen sich mit der Anzahl der Nullen, während die unteren Bits die Anzahl der Bits bezeichnen, die zur Kodierung des Wertes von x erforderlich sind. Dies hat die unmittelbare Implikation des Symbols 1 nur in der Lage, Informationen über die ersten 15 Nullen vor dem nicht-Null-AC-Koeffizienten zu speichern. JPEG definiert jedoch zwei spezielle Huffman-Codewörter. Man beendet die Sequenz vorzeitig, wenn die übrigen Koeffizienten Null (End-of-Block oder EOB) sind, und ein anderer für den Fall, dass der Lauf von Nullen über 15 hinausgeht, bevor ein nicht-Null-AC-Koeffizient erreicht wird. In einem solchen Fall, in dem 16 Nullen vor einem gegebenen nicht-Null-AC-Koeffizienten auftreten, ist Symbol 1 mit (15, 0)(0) codiert. Der Gesamtprozess wird solange fortgesetzt, bis EOB – mit (0, 0) bezeichnet – erreicht ist. Die in den Absätzen 1 und 2 genannten Kriterien sind in den Absätzen 1 und 2 aufgeführt. Siehe oben.) Von hier aus werden Frequenzberechnungen auf Vorkommen der Koeffizienten vorgenommen. In unserem Beispielblock sind die meisten quantisierten Koeffizienten kleine Zahlen, die nicht sofort durch einen Nullkoeffizienten vorangehen. Diese häufigeren Fälle werden durch kürzere Codewörter dargestellt. Kompressionsverhältnis und Artefakte Das resultierende Kompressionsverhältnis kann je nach Bedarf durch mehr oder weniger aggressive Divisoren in der Quantisierungsphase variiert werden. Zehn bis eine Kompression führt in der Regel zu einem Bild, das sich nicht durch das Auge vom Original unterscheiden lässt. Ein Kompressionsverhältnis von 100:1 ist in der Regel möglich, wird aber im Vergleich zum Original deutlich artefaktiert aussehen. Die entsprechende Kompression hängt von der Verwendung ab, auf die das Bild gesetzt wird. Diejenigen, die das World Wide Web nutzen, können mit den Unregelmäßigkeiten vertraut sein, die als Kompressionsartefakte bekannt sind, die in JPEG-Bildern auftreten, die die Form von Lärm um kontrastierende Kanten (insbesondere Kurven und Ecken) oder blockierende Bilder aufweisen können. Dies ist auf den Quantisierungsschritt des JPEG-Algorithmus zurückzuführen. Sie sind besonders um scharfe Ecken zwischen kontrastierenden Farben bemerkbar (Text ist ein gutes Beispiel, da es viele solcher Ecken enthält). Die analogen Artefakte im MPEG-Video werden als Moskitogeräusch bezeichnet, als die resultierende "Edelbeschäftigung" und Störpunkte, die sich im Laufe der Zeit verändern, ähneln Moskitos, die um das Objekt herumschwarmen. Diese Artefakte können durch die Wahl eines niedrigeren Niveaus der Kompression reduziert werden; sie können durch das Speichern eines Bildes mit einem verlustfreien Dateiformat völlig vermieden werden, obwohl dies zu einer größeren Dateigröße führt. Die mit Ray-Tracing-Programmen erstellten Bilder haben auf dem Gelände spürbare blockartige Formen. Bestimmte intensitätsarme Kompressionsartefakte können bei der einfachen Betrachtung der Bilder akzeptabel sein, können jedoch hervorgehoben werden, wenn das Bild anschließend verarbeitet wird, was in der Regel zu inakzeptabler Qualität führt. Betrachten Sie das nachfolgende Beispiel, um den Effekt der verlustigen Kompression auf einen Kantenerkennungs-Prozessschritt zu demonstrieren. Einige Programme ermöglichen es dem Benutzer, den Betrag zu variieren, um den einzelne Blöcke komprimiert werden. Stärkere Kompression wird auf Bereiche des Bildes angewendet, die weniger Artefakte zeigen. Auf diese Weise kann man die JPEG-Dateigröße mit weniger Qualitätsverlust manuell reduzieren. Da die Quantisierungsstufe immer zu einem Informationsverlust führt, ist JPEG-Standard immer ein verlustiger Kompressionscodec. (Die Informationen werden sowohl bei der Quantisierung als auch beim Runden der Floating-Point-Zahlen verloren.) Auch wenn die Quantisierungsmatrix eine Matrix von denen ist, werden im Rundungsschritt noch Informationen verloren gehen. Decoding Decoding, um das Bild anzuzeigen, besteht darin, dass alle oben in umgekehrt. Unter der DCT-Koeffizientenmatrix (nach dem Hinzufügen der Differenz des DC-Koeffizienten wieder ein) und der Aufnahme des Einlauf-Vorlaufproduktes mit der Quantisierungsmatrix von oben ergibt sich, dass die ursprüngliche DCT-Koeffizientenmatrix für den oberen linken Teil eng ähnelt. Der nächste Schritt ist die zweidimensionale inverse DCT (a 2D type-III DCT), die gegeben wird durch: wobei x \{displaystyle \ x} die Pixelzeile ist, für die ganze Zahlen 0 ≤ x < 8 \{displaystyle \ 0\leq x<8} . y \{displaystyle \ y} ist die Pixelspalte, für die ganze Zahlen 0 ≤ y < 8 \{displaystyle \ 0\leq y<8} . α ( u ) \{displaystyle \alpha (u}) ist wie oben definiert, für die ganze Zahlen 0 ≤ u < 8 \{displaystyle \ 0\leq u<8} . F u , v \{displaystyle \ F_{u,v} ist der rekonstruierte ungefähre Koeffizient an Koordinaten ( u , v ) . \{displaystyle \ (u,v}.) f x , y \{displaystyle \ f_{x,y} ist der rekonstruierte Pixelwert an Koordinaten ( x , y ) \{displaystyle \ (x,y}) Durch Verrunden der Ausgabe auf ganzzahlige Werte (da die Originale ganze Zahlenwerte hatten) entsteht ein Bild mit Werten (immer noch um 128 nach unten verschoben) und jedem Eintrag 128 hinzugefügt. Das ist das dekomprimierte Subimage. Im allgemeinen kann der Dekompressionsprozess Werte außerhalb des ursprünglichen Eingabebereichs von [0, 255 ] \{displaystyle [0,255}] erzeugen.Wenn dies geschieht, muss der Dekoder die Ausgabewerte so klammern, dass er sie in diesem Bereich hält, um ein Überlaufen bei der Speicherung des dekomprimierten Bildes mit der ursprünglichen Bittiefe zu verhindern. Das dekomprimierte Subbild kann mit dem ursprünglichen Subbild verglichen werden (siehe auch Bilder nach rechts), indem die Differenz (original - unkomprimiert) die folgenden Fehlerwerte ergibt: mit einem durchschnittlichen absoluten Fehler von etwa 5 Werten pro Pixel(d.h. 1 64 Σ x = 0 7 | e (x, y | | = 4.8750 \{display}} = 0 = 0 7 fra e) Erforderliche Präzisionscodierung und Decodierung der Konformität und damit Präzisionsanforderungen sind in ISO/IEC 10918-2, d.h. Teil 2 der JPEG-Spezifikation, angegeben. Diese Spezifikation erfordert beispielsweise, dass die (vorwärtstransformierten) DCT-Koeffizienten, die aus einem Bild einer JPEG-Implementierung unter Test gebildet werden, einen Fehler aufweisen, der innerhalb einer Quantisierungs-Bucket-Präzision im Vergleich zu Referenzkoeffizienten liegt. Zu diesem Zweck bietet ISO/IEC 10918-2 Testströme sowie die DCT-Koeffizienten an, auf die der Codestream decodiert wird. Ebenso definiert ISO/IEC 10918-2 Encoder-Präzisionen in Bezug auf einen maximal zulässigen Fehler in der DCT-Domain. Dies ist insofern ungewöhnlich, als viele andere Standards nur Decoderkonformität definieren und nur vom Encoder verlangen, einen syntaktisch korrekten Codestream zu erzeugen. Die in ISO/IEC 10918-2 gefundenen Testbilder sind (pseudo-) Zufallsmuster, um die schlimmsten Fälle zu überprüfen. Da ISO/IEC 10918-1 keine Farbräume definiert und weder die YCbCr zur RGB-Transformation von JFIF (jetzt ISO/IEC 10918-5) umfasst, kann die Genauigkeit der letzteren Transformation nicht durch ISO/IEC 10918-2 getestet werden. Um 8-Bit-Präzision pro Pixel-Komponenten-Ausgang zu unterstützen, werden typischerweise Dequantisierung und inverse DCT-Transformationen mit mindestens 14-Bit-Präzision in optimierten Decodern implementiert. Effekte von JPEG Kompressionsartefakten vermischen sich gut in Fotografien mit detaillierten ungleichmäßigen Texturen, wodurch höhere Kompressionsverhältnisse möglich sind. Beachten Sie, wie ein höheres Kompressionsverhältnis die hochfrequenten Texturen in der oberen linken Ecke des Bildes zuerst beeinflusst und wie die kontrastierenden Linien rauchiger werden. Das sehr hohe Kompressionsverhältnis wirkt sich stark auf die Qualität des Bildes aus, obwohl die Gesamtfarben und Bildform noch erkennbar sind. Die Präzision der Farben leidet jedoch weniger (für ein menschliches Auge) als die Genauigkeit der Konturen (bezogen auf Leuchtdichte). Dies rechtfertigt die Tatsache, dass zunächst Bilder in einem Farbmodell transformiert werden sollen, das die Luminanz von der chromatischen Information trennt, bevor die chromatischen Ebenen (die auch eine niedrigere Qualitätsquantisierung verwenden kann) subsampiert werden, um die Genauigkeit der Luminanzebene mit mehr Informationsbits zu erhalten. Musterfotos Für Informationen würde das unkomprimierte 24-Bit RGB-Bitmap-Bild unten (73,242 Pixel) 219,726 Bytes (ohne alle anderen Informations-Header) benötigen. Die unten angegebenen Dateien umfassen die internen JPEG-Informations-Header und einige Metadaten. Für qualitativ hochwertige Bilder (Q=100,) sind ca. 8,25 Bit pro Farbpixel erforderlich. Bei Grauwertbildern reicht ein Minimum von 6,5 Bit pro Pixel aus (eine vergleichbare Q=100 Qualitäts-Farbinformation benötigt etwa 25% mehr codierte Bits). Das höchste Qualitätsbild unten (Q=100) wird mit neun Bit pro Farbpixel kodiert, das mittlere Qualitätsbild (Q=25) verwendet ein Bit pro Farbpixel. Für die meisten Anwendungen sollte der Qualitätsfaktor nicht unter 0,75 Bit pro Pixel (Q = 12,5) gehen, wie durch das niederwertige Bild gezeigt. Das Bild bei niedrigster Qualität verwendet nur 0,13 Bit pro Pixel und zeigt sehr schlechte Farbe. Dies ist nützlich, wenn das Bild in einer signifikanten heruntergefahrenen Größe angezeigt wird. In Minguillón & Pujol (2001) wird ein Verfahren zur Erzeugung besserer Quantisierungsmatrizen für eine bestimmte Bildqualität mit PSNR anstelle des Q-Faktors beschrieben. Das mittlere Qualitätsfoto verwendet nur 4,3 % des für das unkomprimierte Bild benötigten Speicherplatzes, hat aber wenig spürbare Detailverluste oder sichtbare Artefakte. Wenn jedoch eine bestimmte Schwelle der Kompression überschritten wird, zeigen komprimierte Bilder zunehmend sichtbare Fehler. Siehe den Artikel zur Rate-Distortion-Theorie für eine mathematische Erklärung dieses Schwellwerteffekts. Eine besondere Einschränkung von JPEG ist dabei seine nicht überlappte 8×8 Blocktransformationsstruktur. Modernere Designs wie JPEG 2000 und JPEG XR zeigen einen anmutigeren Qualitätsabbau, da die Bitnutzung abnimmt – durch die Verwendung von Transformationen mit größerem räumlichen Ausmaß für die niedrigeren Frequenzkoeffizienten und durch die Verwendung von überlappenden Transformationsbasisfunktionen. Lossless weitere Kompression Von 2004 bis 2008 ergab sich neue Forschung über Möglichkeiten, die in JPEG-Bildern enthaltenen Daten weiter zu komprimieren, ohne das dargestellte Bild zu ändern. Dies hat Anwendungen in Szenarien, in denen das Originalbild nur im JPEG-Format verfügbar ist und dessen Größe für die Archivierung oder Übertragung reduziert werden muss. Standard-Allgemeine Gebrauchskompressionstools können JPEG-Dateien nicht signifikant komprimieren. Typischerweise nutzen solche Systeme Verbesserungen des naiven Schemas zur Kodierung von DCT-Koeffizienten, die nicht berücksichtigt werden: Korrelationen zwischen den Größen benachbarter Koeffizienten im gleichen Block; Korrelationen zwischen den Größen des gleichen Koeffizienten in benachbarten Blöcken; Korrelationen zwischen den Größen des gleichen Koeffizienten/Blocks in verschiedenen Kanälen; Die DC Koeffizienten, wenn sie zusammengenommen ähneln einer Downscale-Version des ursprünglichen Bildes multipliziert mit einem Skalierungsfaktor. Bekannte Systeme zur verlustfreien Kodierung von kontinuierlichen Tonbildern können angewendet werden, wodurch eine etwas bessere Kompression erreicht wird als die in JPEG verwendete Huffman-codierte DPCM. Einige Standard-, aber selten verwendete Optionen existieren bereits in JPEG, um die Effizienz der Codierung von DCT-Koeffizienten zu verbessern: die arithmetische Codierung Option, und die progressive Codierung Option (die geringere Bitraten erzeugt, weil Werte für jeden Koeffizienten unabhängig kodiert werden, und jeder Koeffizient eine deutlich andere Verteilung aufweist). Moderne Methoden haben sich auf diesen Techniken dadurch verbessert, dass Koeffizienten auf Gruppenkoeffizienten größerer Größe zusammen neu geordnet werden; mit benachbarten Koeffizienten und Blöcken, um neue Koeffizientenwerte vorherzusagen; Blöcke oder Koeffizienten zwischen einer kleinen Anzahl unabhängig kodierter Modelle basierend auf ihren Statistiken und benachbarten Werten; und zuletzt durch Decodieren von Blöcken, Prädiktion von nachfolgenden Blöcken im Raumbereich und anschließende Kodierung dieser zu Vorhersagen für DCT-Koeffizienten. Typischerweise können solche Methoden bestehende JPEG-Dateien zwischen 15 und 25 Prozent komprimieren und für JPEGs, die bei niedrigen Einstellungen komprimiert werden, können Verbesserungen von bis zu 65 % bewirken. Ein frei verfügbares Tool namens packJPG basiert auf dem Papier "Improved Redundancy Reduction for JPEG Files". Ein 2016 Papier mit dem Titel "JPEG auf Steroiden" mit ISO libjpeg zeigt, dass aktuelle Techniken, verlustig oder nicht, kann JPEG fast so effizient wie JPEG XR machen; mozjpeg verwenden ähnliche Techniken. JPEG XL ist ein neues Dateiformat, das eine JPEG mit einer effizienten Rückkonversion zu JPEG verlustfrei neu codieren kann. Abgeleitete Formate Für stereoskopische 3D JPEG Stereoskopische JPEG Stereoskop (JPS, Erweiterung .jps) ist ein JPEG-basiertes Format für stereoskopische Bilder. Sie weist eine Reihe von Konfigurationen auf, die im JPEG APP3 Markerfeld gespeichert sind, enthält jedoch in der Regel ein Bild mit doppelter Breite, das zwei Bilder gleicher Größe in kreuzgeätzter (d.h. linker Rahmen auf der rechten Bildhälfte und umgekehrt) nebeneinander angeordnet darstellt. Dieses Dateiformat kann als JPEG ohne spezielle Software angesehen werden oder für das Rendern in anderen Modi verarbeitet werden. JPEG Multi-Picture Format JPEG Multi-Picture Format (MPO, Erweiterung .mpo) ist ein JPEG-basiertes Format zum Speichern mehrerer Bilder in einer einzigen Datei. Es enthält zwei oder mehr JPEG-Dateien zusammen konkatiert. Es definiert auch ein JPEG APP2 Markersegment für die Bildbeschreibung. Verschiedene Geräte verwenden es, um 3D-Bilder zu speichern, wie Fujifilm FinePix Real 3D W1, HTC Evo 3D, JVC GY-HMZ1U AVCHD/MVC Erweiterung Camcorder, Nintendo 3DS, Sony PlayStation 3, Sony PlayStation Vita, Panasonic Lumix DMC-TZ20, DMC-TZ30, DMC-TZ60, DMC-TS4 (FT4, Andere Geräte verwenden es, um "Vorschaubilder" zu speichern, die auf einem TV angezeigt werden können. In den letzten Jahren, aufgrund der wachsenden Verwendung von stereoskopischen Bildern, wurde viel Aufwand von der wissenschaftlichen Gemeinschaft verbracht, Algorithmen für die stereoskopische Bildkompression zu entwickeln. JPEG XT JPEG XT (ISO/IEC 18477) wurde im Juni 2015 veröffentlicht; es erweitert das Basis- JPEG-Format mit Unterstützung für höhere Ganzzahl-Bit-Tiefen (bis 16 Bit), hohe dynamische Bereich Abbildung und Floating-Point-Codierung, verlustfreie Codierung und Alpha-Kanal-Codierung. Die Extensions sind rückwärts kompatibel mit dem Basis-JEG/JFIF-Dateiformat und dem 8-Bit-verlustigen komprimierten Bild. JPEG XT verwendet ein erweitertes Dateiformat basierend auf JFIF. Zur Modifizierung der JPEG 8-Bit-Basisschicht werden Dehnungsschichten verwendet und das hochauflösende Bild wiederhergestellt.Vorhandene Software ist vorwärtskompatibel und kann den JPEG XT Binärstrom lesen, obwohl er nur die Basis 8-Bit-Schicht decodieren würde. JPEG XL Seit August 2017 veröffentlichte JTC1/SC29/WG1 eine Reihe von Entwurfsvorschlägen zu JPEG XL – dem Bildkompressionsstandard der nächsten Generation mit wesentlich besserer Kompressionseffizienz (60% Verbesserung) im Vergleich zu JPEG. Der Standard wird erwartet, dass die noch immer Bildkompression Leistung von HEVC HM, Daala und WebP, und im Gegensatz zu früheren Bemühungen, JPEG zu ersetzen versucht, um verlustlos effizientere Rekompression Transport- und Speicheroption für traditionelle JPEG-Bilder zu bieten. Die Kernanforderungen umfassen Unterstützung für sehr hochauflösende Bilder (mindestens 40 MP,) 8–10 Bit pro Komponente, RGB/YCbCr/ICtCp Farbcodierung, animierte Bilder, alpha-Kanal-Codierung, Rec.709 Farbraum (sRGB) und Gamma-Funktion (2.4-Power,) Rec. 2100 breite Farb-Gamut-Farbraum (Rec. 2020) und hohe dynamische Reichweitenübertragungsfunktionen Der Standard sollte auch höhere Bittiefen (12–16 Bit ganze und schwimmende Punkt,) zusätzliche Farbräume und Transferfunktionen (wie Log C von Arri,) eingebettete Vorschaubilder, verlustfreie Alpha-Kanal-Kodierung, Bildbereich-Kodierung und Low-Complexity-Kodierung bieten. Alle patentierten Technologien würden lizenzfrei lizenziert. Die Vorschläge wurden bis September 2018 eingereicht, was zu einem Ausschussentwurf im Juli 2019 führte, mit dem aktuellen Datum der Zielveröffentlichung im Oktober 2019. Das Dateiformat (bitstream) wurde am 25. Dezember 2020 eingefroren, was bedeutet, dass das Format jetzt durch zukünftige Versionen dekodierbar ist. Inkompatible JPEG-Standards Die Joint Photography Experts Group ist auch verantwortlich für einige andere Formate mit dem JPEG-Namen, einschließlich JPEG 2000, JPEG XR und JPEG XS. Durchführung Eine sehr wichtige Implementierung eines JPEG-Codecs war die kostenlose Programmierbibliothek libjpeg der unabhängigen JPEG-Gruppe. Sie wurde 1991 erstmals veröffentlicht und war für den Erfolg des Standards von entscheidender Bedeutung. Neuere Versionen stellen proprietäre Erweiterungen vor, die die ABI-Kompatibilität mit früheren Versionen brach. In vielen prominenten Software-Projekten wurde libjpeg durch libjpeg-turbo ersetzt, die eine höhere Leistung, SIMD-Kompatibilität und Rückwärtskompatibilität mit den original libjpeg-Versionen bietet. Im März 2017 veröffentlichte Google das Open Source-Projekt Guetzli, das eine viel längere Kodierungszeit für kleinere Dateigröße abgibt (ähnlich dem, was Zopfli für PNG und andere verlustfreie Datenformate tut). ISO/IEC Die Joint Photography Experts Group unterhält eine Referenzsoftware-Implementierung, die sowohl die Basis JPEG (ISO/IEC 10918-1 und 18477–1) als auch JPEG XT-Erweiterungen (ISO/IEC 18477 Teile 2 und 6–9) als auch JPEG-LS (ISO/IEC 14495) kodieren kann. Siehe auch AVIF Better Portable Graphics, ein Format auf der Grundlage der Intra-frame-Kodierung des HEVC C-Cube, ein früher Implementierunger von JPEG in Chipform Vergleich von Grafikdateiformaten Vergleich von Layout-Engines (Grafik)Deblocking-Filter (Video), die ähnlichen Deblocking-Methoden könnte auf JPEG Design-Regel für Camera File System (DCF) angewendet werden Dateierweiterungen Graphics Editing Programm High Efficiency Image File Format, Bild Container Format für HEVC und andere Bildcodierungsformate JPEG Datei Interchange Format Lenna (Testbild), das traditionelle Standardbild, das verwendet wird, um Bildverarbeitungsalgorithmen zu testen Lossless Image Codec FELICS Motion JPEG Referenzen Externe Links JPEG Standard (JPEG ISO/IEC 10918-1 ITU-T Empfehlung T.81) bei W3 Experte Ein Leedger ist ein Buch oder eine Sammlung von Konten, in denen Kontotransaktionen erfasst werden. Jedes Konto verfügt über ein offenes oder vorübergehendes Guthaben, würde Transaktionen als Lastschrift oder Gutschrift in getrennten Spalten und dem End- oder Schlussguthaben erfassen. Überblick Der Leedger ist eine ständige Zusammenfassung aller Beträge, die in den Support-Journalen erfasst werden, die einzelne Transaktionen nach Datum auflisten. Jede Transaktion fließt von einem Journal zu einem oder mehreren Leadgers. Die Jahresabschlüsse eines Unternehmens werden aus Zusammenfassungssummen in den Leedern generiert. Ledgers umfassen: Verkaufsleiter, Aufzeichnungen Forderungen. Dieser Geschäftsleiter besteht aus den Finanztransaktionen, die von Kunden an das Unternehmen getätigt werden. Kauf Leedger registriert Geld für den Kauf durch das Unternehmen. Allgemeines Finanzbuch, das die fünf wichtigsten Kontotypen repräsentiert: Aktiva, Passiva, Einkommen, Aufwendungen und Kapital. Für jeden in einem Leisten aufgezeichneten Debit muss es eine entsprechende Gutschrift geben, so dass die Debits den Gutschriften in den Großsummen entsprechen. Arten auf der Grundlage von Zwecken Die drei Arten von Leisten sind die allgemeinen, Schuldner und Gläubiger. Der Generalleiter sammelt Informationen aus Zeitschriften. Jeden Monat werden alle Zeitschriften gezählt und an die General Ledger gepostet. Ziel des General Ledger ist es daher, die einzelnen in allen Zeitschriften aufgeführten Transaktionen zu organisieren und zusammenzufassen. Der Debtor Ledger sammelt Informationen aus dem Verkaufsjournal. Der Zweck der Debtors Ledger ist es, Wissen darüber zu liefern, welche Kunden Geld dem Geschäft schulden, und wie viel. Die Gläubiger Ledger akkumuliert Informationen aus der Käufzeitschrift. Der Zweck der Gläubiger Ledger ist es, Wissen darüber zu liefern, welchen Lieferanten das Unternehmen Geld schuldet und wie viel. Etymologie Der Begriff Leisten stammt aus dem englischen Dialekt bildet liggen oder leggen, was bedeutet "to lie or lay" (Niederlande: liggen oder leggen, Deutsch: liegen oder legen;) im Sinne ist es vom niederländischen materiellen Legger, richtig "ein Buch legen oder bleiben regelmäßig an einer Stelle". Ursprünglich war ein Bauleiter ein großes Buch der Schrift oder des Servicebuchs an einem Ort in der Kirche gehalten und offen zugänglich. Laut Charles Wriothesley's Chronicle (1538,) "Die Kurate sollten ein Buch der Bibel in englischer Sprache, der größten Band, ein Lektor in der gleichen Kirche für die Pfarrer zu lesen. " In Anwendung dieser ursprünglichen Bedeutung ist die kommerzielle Nutzung des Begriffs für das "Hauptbuch des Kontos" in einem Geschäftshaus. Siehe auch Bookkeeping Debits und credits Specialized Journals Final Accounts Distributed ledger, manchmal als gemeinsamer Leadger bezeichnet, ist ein Konsens von replizierten, geteilten und synchronisierten digitalen Daten geographisch über mehrere Standorte, Länder und/oder Institutionen verteilt. Hinweise Referenzen Dieser Artikel enthält Text aus einer Publikation, die jetzt in der öffentlichen Domain veröffentlicht wird: Chisholm, Hugh, ed.(1911)."Ledger". Encyclopædia Britannica (11th ed.). Cambridge University Press. Weiter lesen Business Owner's Toolkit: General Ledger von Wolters Kluwer General Ledger Einträge von NetMBA Business Knowledge Center