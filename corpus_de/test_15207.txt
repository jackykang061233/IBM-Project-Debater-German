Generativer vortrainierter Transformer 3 (GPT-3) ist ein autoregressives Sprachmodell, das tiefes Lernen verwendet, um humanähnlichen Text zu produzieren. Es ist das dritte Generation der Sprachvorhersage in der GPT-n-Serie (und der Nachfolger von GPT-2) erstellt von OpenAI, einem Labor für künstliche Intelligenz in San Francisco. Die Vollversion von GPT-3 hat eine Kapazität von 175 Milliarden maschinellen Lernparametern. GPT-3, die im Mai 2020 eingeführt wurde und ab Juli 2020 in Beta-Tests war, ist Teil einer Trend in der natürlichen Sprachverarbeitung (NLP) Systeme von vortrainierten Sprachdarstellungen. Vor der Veröffentlichung von GPT-3 war das größte Sprachmodell Microsofts Turing NLG, im Februar 2020 eingeführt, mit einer Kapazität von 17 Milliarden Parametern -weniger als ein Zehntel von GPT-3's. Die Qualität des von GPT-3 erzeugten Textes ist so hoch, dass es schwierig sein kann, festzustellen, ob es von einem Menschen geschrieben wurde, der sowohl Vorteile als auch Risiken hat. Dreißig OpenAI-Forscher und Ingenieure präsentierten das originale Papier vom 28. Mai 2020 mit GPT-3. In ihrem Beitrag warnten sie vor potenziellen Gefahren von GPT-3 und forderten die Forschung auf, das Risiko zu mindern. David Chalmers, ein australischer Philosoph, beschreibt GPT-3 als "eines der interessantesten und wichtigsten AI-Systeme, die jemals produziert wurden. "Microsoft hat am 22. September 2020 angekündigt, dass es exklusive Verwendung von GPT-3 lizenziert hatte; andere können noch die öffentliche API verwenden, um Ausgabe zu erhalten, aber nur Microsoft hat Zugang zu GPT-3 zugrunde liegenden Modell. Hintergrund Laut The Economist haben verbesserte Algorithmen, leistungsfähige Computer und eine Zunahme der digitalisierten Daten eine Revolution im maschinellen Lernen ausgelöst, mit neuen Techniken in den 2010er Jahren, die zu "schnellen Verbesserung der Aufgaben" einschließlich der Sprache manipulieren. Software-Modelle werden durch die Verwendung von Tausenden oder Millionen von Beispielen in einer "Struktur ... lose basierend auf der neuralen Architektur des Gehirns" gelernt. Eine Architektur, die in der natürlichen Sprachverarbeitung (NLP) verwendet wird, ist ein neuronales Netzwerk, das auf einem tiefen Lernmodell basiert, das 2017 erstmals vorgestellt wurde – der Transformer. GPT-n-Modelle basieren auf dieser Transformer-basierten Deep Learning Neuronal Network Architektur. Es gibt eine Reihe von NLP-Systemen, die in der Lage sind, Antworten auf Fragen zu verarbeiten, zu produzieren, zu organisieren, zu verbinden, zu kontrastieren, zu verstehen und zu generieren. Am 11. Juni 2018, Open KI-Forscher und Ingenieure veröffentlichten ihr Originalpapier über generative Modelle – Sprachmodelle – Künstliche Intelligenzsysteme –, die mit einem enormen und vielfältigen Korpus Text über Datensätze vortrainiert werden könnten, in einem Prozess, den sie als generatives Vortraining (GP) bezeichneten. Die Autoren beschrieb, wie das Sprachverständnis der Performances in der natürlichen Sprachverarbeitung (NLP) in GPT-n durch einen Prozess der "generativen Vorschulung eines Sprachmodells auf einem vielfältigen Korpus unmarkierten Text verbessert wurde, gefolgt von einer diskriminierenden Feinabstimmung über jede bestimmte Aufgabe. " Dies eliminierte die Notwendigkeit der menschlichen Überwachung und der zeitintensiven Handmarkierung. Im Februar 2020 stellte Microsoft seine Turing Natural Language Generation (T-NLG) vor, die dann das "größte Sprachmodell, das jemals bei 17 Milliarden Parametern veröffentlicht wurde." Es hat besser als jedes andere Sprachmodell an einer Vielzahl von Aufgaben durchgeführt, die zusammenfassende Texte und beantwortende Fragen enthalten. Fähigkeiten Am 28. Mai 2020 beschreibt ein arXiv-Vordruck einer Gruppe von 31 Ingenieuren und Forschern von OpenAI die Entwicklung von GPT-3, einem "state-of-the-art language model". Das Team erhöht die Kapazität von GPT-3 um mehr als zwei Größenordnungen von dem seiner Vorgänger, GPT-2, so dass GPT-3 das bisher größte nicht-sparse Sprachmodell. Da GPT-3 seinen Vorgängern strukturell ähnlich ist, wird seine höhere Genauigkeit auf seine erhöhte Kapazität und höhere Anzahl von Parametern zurückgeführt. Die Kapazität von GPT-3 ist zehnmal größer als die von Microsofts Turing NLG, dem nächstgrößten NLP-Modell. 60 Prozent des gewichteten Vortrainingsdatensatzes für GPT-3 stammen aus einer gefilterten Version von Common Crawl bestehend aus 410 Milliarden Byte-Paar-codierten Token. Andere Quellen sind 19 Milliarden Token von WebText2 repräsentiert 22% der gewichteten Gesamt, 12 Milliarden Token von Books1 repräsentiert 8,% 55 Milliarden Token von Books2 repräsentiert 8,% und 3 Milliarden Token aus Wikipedia repräsentiert 3 % GPT-3 wurde auf Hunderte von Milliarden von Wörtern ausgebildet und ist in der Lage, in CSS, JSX, Python, unter anderem zu kodieren. Da die Trainingsdaten von GPT-3 allumfassend waren, bedarf es keiner weiteren Ausbildung für unterschiedliche Sprachaufgaben.Die Trainingsdaten enthalten gelegentlich toxische Sprache und GPT-3 erzeugt gelegentlich giftige Sprache, da sie ihre Trainingsdaten nachahmen. Eine Studie der University of Washington ergab, dass GPT-3 toxische Sprache auf einem Toxizitätsniveau produziert, vergleichbar mit den ähnlichen natürlichen Sprachverarbeitungsmodellen von GPT-2 und CTRL. GPT-3 produzierte weniger giftige Sprache im Vergleich zu seinem Vorgängermodell GPT-1, obwohl es sowohl mehr Generationen als auch eine höhere Toxizität toxischer Sprache im Vergleich zu CTRL Wiki produzierte, ein Sprachmodell, das vollständig auf Wikipedia-Daten trainiert wurde. Am 11. Juni 2020 kündigte OpenAI an, dass Nutzer Zugang zu seiner benutzerfreundlichen GPT-3 API – einem "Maschinenlerntoolset" – beantragen können, um OpenAI "die Stärken und Grenzen" dieser neuen Technologie "erweitern". Die Einladung beschrieb, wie diese API eine allgemeine "Text in, Text out" Schnittstelle hatte, die fast "jegliche englische Sprachaufgabe" abschließen kann, anstatt der üblichen Single Use-Case. Nach Angaben eines Benutzers, der Zugang zu einer privaten frühen Veröffentlichung der OpenAI GPT-3 API hatte, war GPT-3 "eergisch gut" beim Schreiben "einfühlsam kohärenter Text" mit nur wenigen einfachen Aufforderungen. In einem ersten Experiment wurden 80 US-Themen gebeten, zu beurteilen, ob kurze ~200 Wörter Artikel von Menschen oder GPT-3 geschrieben wurden. Die Teilnehmer beurteilten falsch 48% der Zeit, nur etwas besser als zufälliges Erraten. Da GPT-3 "Nachrichtenartikel erzeugen kann, die menschliche Evaluatoren Schwierigkeiten haben, von Artikeln, die von Menschen geschrieben wurden, zu unterscheiden", hat GPT-3 das "potentielle, sowohl die nützlichen als auch schädlichen Anwendungen von Sprachmodellen voranzubringen". In ihrem Papier vom 28. Mai 2020 beschreiben die Forscher die potenziellen "schädlichen Auswirkungen von GPT-3", die "Missinformation, Spam, Phishing, Missbrauch von rechtlichen und Regierungsprozessen, betrügerische akademische Essay Schreiben und Social Engineering Pretexting" beinhalten. Die Autoren weisen auf diese Gefahren hin, um die Forschung über Risikominderung zu fordern. GPT-3 ist in der Lage, null-shot, wenig-shot und ein-shot-Learning durchzuführen. Bewertungen In einer Juli 2020-Rezension in The New York Times sagte Farhad Manjoo, dass GPT-3 die Fähigkeit, Computercode, Poesie und Prosa zu generieren, ist nicht nur erstaunlich, spooky und demütigend, sondern auch "mehr als ein wenig erschreckend". Daily Nous präsentierte eine Reihe von Artikeln von neun Philosophen auf GPT-3.Australischer Philosoph David Chalmers beschrieb GPT-3 als "eines der interessantesten und wichtigsten AI-Systeme, die jemals produziert wurden". Eine Rezension in Wired sagte, dass GPT-3 "entsprechende Chillen im Silicon Valley" sei. Die National Law Review sagte, dass GPT-3 ein "beeindruckender Schritt im größeren Prozess" sei, mit OpenAI und anderen "nützige Anwendungen für all diese Macht" zu finden, während sie "zu einer allgemeineren Intelligenz arbeiten". Ein Artikel in der MIT Technology Review, der von Deep Learning Kritiker Gary Marcus kuratiert wurde, sagte, dass GPT-3s "Verstehen der Welt oft ernst ist, was bedeutet, dass Sie nie wirklich vertrauen können, was es sagt." Nach Angaben der Autoren modelliert GPT-3 Beziehungen zwischen Wörtern ohne Verständnis der Bedeutung hinter jedem Wort. Jerome Pesenti, Leiter des Facebook-KI-Labors, sagte, GPT-3 sei unsicher und weist auf die sexistische, rassistische und andere voreingenommene und negative Sprache hin, die vom System erzeugt wurde, als es darum bat, Juden, Frauen, schwarze Menschen und den Holocaust zu diskutieren. Nabla, ein französisches Start-up, das sich auf die Gesundheitstechnologie spezialisiert hat, testete GPT-3 als medizinischer Chatbot, obwohl OpenAI selbst davor warnte. Wie erwartet zeigte GPT-3 mehrere Einschränkungen. Zum Beispiel hat die KI während der Prüfung von GPT-3 Antworten auf psychische Gesundheitsprobleme einen simulierten Patienten empfohlen, Selbstmord zu begehen. Noam Chomsky drückte seine Skepsis über den wissenschaftlichen Wert von GPT-3 aus: "Es ist kein Sprachmodell. Es funktioniert genauso gut für unmögliche Sprachen wie für tatsächliche Sprachen. Sie wird daher, wenn sie als Sprachmodell bestimmt ist, nach normalen wissenschaftlichen Kriterien widerlegt.[...] Vielleicht ist es nützlich für einen bestimmten Zweck, aber es scheint uns nichts über Sprache oder Wahrnehmung in der Regel zu sagen." Anwendungen GPT-3 wird in bestimmten Microsoft-Produkten verwendet, um konventionelle Sprache in formalen Computercode zu übersetzen. GPT-3 wurde von Andrew Mayne für AI Writer verwendet, der es Menschen ermöglicht, mit historischen Zahlen per E-Mail zu korrespondieren. GPT-3 wurde von Jason Rohrer in einem retro-themed Chatbot-Projekt namens "Projekt Dezember" verwendet, das online zugänglich ist und es Benutzern ermöglicht, mit mehreren KIs mit GPT-3 Technologie umzukehren. GPT-3 wurde von The Guardian verwendet, um einen Artikel über KI zu schreiben, der für Menschen harmlos ist.Es wurde einige Ideen gefüttert und acht verschiedene Essays produziert, die schließlich in einen Artikel vereinigt wurden. GPT-3 wird in AI Dungeon verwendet, die textbasierte Abenteuerspiele erzeugt. Der Bauherr von Controversy GPT-3, OpenAI, wurde 2015 zunächst als gemeinnütziger Verein gegründet. Im Jahr 2019 veröffentlichte OpenAI das Vorläufermodell von GPT-3 nicht öffentlich und brach aus den früheren Open-Source-Praktiken von OpenAI und betonte Bedenken, dass das Modell gefälschte Nachrichten verewigen würde. OpenAI veröffentlichte schließlich eine Version von GPT-2, die 8% der ursprünglichen Modellgröße war. Im selben Jahr restrukturierte OpenAI als gemeinnützige Gesellschaft. Im Jahr 2020 kündigte Microsoft die exklusive Lizenzierung von GPT-3 für Microsofts Produkte und Dienstleistungen nach einer Multi-Milliarden-Dollar-Investition in OpenAI an. Die Vereinbarung erlaubt OpenAI, eine öffentlich-rechtliche API anzubieten, so dass Benutzer Text an GPT-3 senden können, um die Ausgabe des Modells zu erhalten, aber nur Microsoft hat Zugriff auf den GPT-3 Quellcode. Große Sprachmodelle, wie GPT-3, sind von Googles AI-Ethik-Forschern für die Umweltauswirkungen von Training und Lagerung der Modelle kritisiert worden, detailliert in einem von Timnit Gebru und Emily M. Bender 2021 mitautorisierten Papier. Referenzen Externe Links Video: OpenAI GPT-3 - GoodAt Fast Everything!(Zwei Minutenbücher) Video: GPT3: Ein selbst größerer Sprachmodell (Computerphile) Video: GPT-3 vs Human Brain (Lex Fridman)