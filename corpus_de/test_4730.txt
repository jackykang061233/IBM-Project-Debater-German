In der Informatik- und Betriebsforschung ist ein genetischer Algorithmus (GA) eine Metaheuristik, die vom Prozess der natürlichen Selektion inspiriert ist, der zur größeren Klasse evolutionärer Algorithmen (EA) gehört. Genetische Algorithmen werden häufig verwendet, um qualitativ hochwertige Lösungen für Optimierungs- und Suchprobleme zu erzeugen, indem sie sich auf biologisch inspirierte Operatoren wie Mutation, Crossover und Selektion verlassen. Methodologie Optimierungsprobleme In einem genetischen Algorithmus wird eine Population von Kandidatenlösungen (individuen, Kreaturen oder Phenotypen) zu einem Optimierungsproblem zu besseren Lösungen entwickelt. Jede Kandidatenlösung hat eine Reihe von Eigenschaften (seinen Chromosomen oder Genotyp), die mutiert und verändert werden können; traditionell sind Lösungen in binären als Strings von 0s und 1s dargestellt, aber auch andere Codierungen sind möglich. Die Evolution beginnt in der Regel von einer Bevölkerung von zufällig erzeugten Individuen, und ist ein iterativer Prozess, mit der Bevölkerung in jeder Iteration genannt eine Generation. In jeder Generation wird die Fitness jedes Individuums in der Bevölkerung ausgewertet; die Fitness ist in der Regel der Wert der Zielfunktion im zu lösenden Optimierungsproblem. Je mehr fitte Individuen sind stochastisch ausgewählt aus der aktuellen Bevölkerung, und jedes Individuum wird modifiziert (rekombiniert und möglicherweise zufällig mutiert) zu einer neuen Generation. Die neue Generation von Kandidatenlösungen wird dann in der nächsten Iteration des Algorithmus verwendet. Üblicherweise endet der Algorithmus, wenn entweder eine maximale Anzahl von Generationen erzeugt wurde, oder ein zufriedenstellendes Fitnessniveau für die Bevölkerung erreicht wurde. Ein typischer genetischer Algorithmus erfordert: eine genetische Darstellung der Lösungsdomäne, eine Fitnessfunktion zur Auswertung der Lösungsdomäne. Eine Standarddarstellung jeder Kandidatenlösung ist als eine Reihe von Bits (auch Bit set oder Bit string genannt). Arrays anderer Typen und Strukturen können im Wesentlichen gleich eingesetzt werden. Die Haupteigenschaft, die diese genetischen Repräsentationen bequem macht, ist, dass ihre Teile aufgrund ihrer festen Größe leicht ausgerichtet sind, was einfache Crossover-Operationen erleichtert. Es können auch variable Längendarstellungen verwendet werden, wobei die Crossover-Implementierung in diesem Fall komplexer ist. Treeähnliche Darstellungen werden in der genetischen Programmierung erforscht und graphische Darstellungen werden in der evolutionären Programmierung erforscht; eine Mischung aus linearen Chromosomen und Bäumen wird in der Genexpressions-Programmierung erforscht. Sobald die genetische Repräsentation und die Fitnessfunktion definiert sind, wird eine GA eine Population von Lösungen initialisiert und dann durch wiederholte Anwendung der Mutations-, Crossover-, Inversions- und Selektionsoperatoren verbessert. Initialisierung Die Bevölkerungsgröße hängt von der Art des Problems ab, enthält aber in der Regel mehrere Hunderte oder Tausende von möglichen Lösungen. Oft wird die anfängliche Bevölkerung zufällig erzeugt, wodurch die gesamte Palette möglicher Lösungen (der Suchraum) ermöglicht wird. Gelegentlich können die Lösungen in Gebieten gesät werden, in denen optimale Lösungen gefunden werden können. Auswahl Während jeder aufeinanderfolgenden Generation wird ein Teil der vorhandenen Bevölkerung ausgewählt, um eine neue Generation zu züchten. Individuelle Lösungen werden durch einen Fitness-basierten Prozess ausgewählt, bei dem fitter Lösungen (gemessen durch eine Fitness-Funktion) typischerweise eher ausgewählt werden. Bestimmte Auswahlverfahren bewerten die Fitness jeder Lösung und wählen bevorzugt die besten Lösungen. Andere Methoden bewerten nur eine Stichprobe der Bevölkerung, da der frühere Prozess sehr zeitaufwendig sein kann. Die Fitnessfunktion wird über die genetische Darstellung definiert und misst die Qualität der dargestellten Lösung. Die Fitness-Funktion ist immer problematisch abhängig. Zum Beispiel will man im Knapsack-Problem den Gesamtwert von Gegenständen maximieren, die in einen Knapsack mit fester Kapazität eingesetzt werden können. Eine Darstellung einer Lösung kann eine Reihe von Bits sein, wobei jedes Bit ein anderes Objekt darstellt, und der Wert des Bits (0 oder 1) stellt dar, ob das Objekt im Rucksack ist oder nicht. Nicht jede solche Darstellung ist gültig, da die Größe der Objekte die Kapazität des Rucksacks überschreiten kann. Die Eignung der Lösung ist die Summe der Werte aller Objekte im Rucksack, wenn die Darstellung gültig ist, oder 0 anderweitig. Bei einigen Problemen ist es schwer oder gar nicht möglich, den Fitnessausdruck zu definieren; in diesen Fällen kann eine Simulation verwendet werden, um den Fitnessfunktionswert eines Phänotyps (z.B. rechnerische Fluiddynamik wird verwendet, um den Luftwiderstand eines Fahrzeugs zu bestimmen, dessen Form als Phänotyp kodiert wird) oder sogar interaktive genetische Algorithmen verwendet werden.Generelle Betreiber Der nächste Schritt besteht darin, eine zweite Generation von Lösungen zu erzeugen, die durch eine Kombination von genetischen Operatoren ausgewählt werden: Crossover (auch Rekombination genannt), Mutation. Für jede neue herzustellende Lösung wird ein Paar Elternlösungen zur Zucht aus dem zuvor ausgewählten Pool ausgewählt. Durch die Herstellung einer Kinderlösung mit den oben genannten Methoden der Überkreuzung und Mutation entsteht eine neue Lösung, die in der Regel viele der Eigenschaften seiner Eltern teilt". Für jedes neue Kind werden neue Eltern ausgewählt, und der Prozess wird fortgesetzt, bis eine neue Population von Lösungen entsprechender Größe erzeugt wird. Obwohl Reproduktionsmethoden, die auf der Verwendung von zwei Eltern basieren, sind mehr "Biologie inspiriert", einige Forschung deutet darauf hin, dass mehr als zwei Eltern qualitativ hochwertige Chromosomen erzeugen. Diese Prozesse führen letztlich zu einer Population der nächsten Generation von Chromosomen, die von der ersten Generation verschieden ist. In der Regel wird die durchschnittliche Fitness durch dieses Verfahren für die Bevölkerung erhöht haben, da nur die besten Organismen der ersten Generation zur Zucht ausgewählt werden, zusammen mit einem kleinen Anteil an weniger fit Lösungen. Diese weniger fitten Lösungen sorgen für genetische Vielfalt im genetischen Pool der Eltern und sorgen daher für die genetische Vielfalt der nachfolgenden Generation von Kindern. Die Stellungnahme wird über die Bedeutung von Crossover gegen Mutation geteilt. Es gibt viele Referenzen in Fogel (2006), die die Bedeutung der mutationsbasierten Suche unterstützen. Obwohl Crossover und Mutation als die wichtigsten genetischen Operatoren bekannt sind, können andere Operatoren wie Regrouping, Kolonisationsextinction oder Migration in genetischen Algorithmen verwendet werden. Es lohnt sich, Parameter wie die Mutationswahrscheinlichkeit, Crossover-Wahrscheinlichkeit und Populationsgröße zu bestimmen, um geeignete Einstellungen für die zu bearbeitende Problemklasse zu finden. Eine sehr kleine Mutationsrate kann zu genetischer Drift führen (die in der Natur nicht-ergodisch ist). Eine zu hohe Rekombinationsrate kann zu einer vorzeitigen Konvergenz des genetischen Algorithmus führen. Eine zu hohe Mutationsrate kann zu einem Verlust an guten Lösungen führen, es sei denn, elitäre Selektion wird eingesetzt. Eine ausreichende Populationsgröße gewährleistet eine ausreichende genetische Vielfalt für das jeweilige Problem, kann aber zu einer Verschwendung von Rechenressourcen führen, wenn sie auf einen Wert größer als erforderlich gesetzt wird. Heuristik Zusätzlich zu den oben genannten Hauptbetreibern können andere Heuristiken eingesetzt werden, um die Berechnung schneller oder robuster zu machen. Die Speziation heuristic penalisiert Crossover zwischen Kandidatenlösungen, die zu ähnlich sind; dies fördert die Bevölkerungsvielfalt und verhindert vorzeitige Konvergenz zu einer weniger optimalen Lösung. Kündigung Dieser Generationsvorgang wird solange wiederholt, bis eine Kündigungsbedingung erreicht ist. Gemeinsame Abschlussbedingungen sind: Es wird eine Lösung gefunden, die Mindestkriterien erfüllt. Die Fitness der höchsten Rangliste erreicht oder hat ein Plateau erreicht, so dass aufeinanderfolgende Iterationen nicht mehr bessere Ergebnisse erzielen. Die Gebäudeblockhypothese Genetische Algorithmen sind einfach zu implementieren, aber ihr Verhalten ist schwer zu verstehen. Insbesondere ist es schwierig zu verstehen, warum diese Algorithmen häufig Erfolg haben, Lösungen hoher Fitness bei Anwendung auf praktische Probleme zu erzeugen. Die Gebäudeblockhypothese (BBH) besteht aus: Eine Beschreibung einer Heuristik, die Anpassung durch die Identifizierung und Rekombinierung von "Bausteinen", d.h. niederer Ordnung, niedrig definierender Länge Schemata mit überdurchschnittlicher Fitness durchführt. Eine Hypothese, dass ein genetischer Algorithmus eine Anpassung durch implizite und effiziente Umsetzung dieser heuristischen. Goldberg beschreibt die heuristische wie folgt: "Schnorz, niedere Ordnung und hochpassende Schemata werden abgetastet, rekombiniert [überquert] und resampled zu Strings potenziell höherer Fitness. In gewisser Weise haben wir durch die Zusammenarbeit mit diesen jeweiligen Schemata [die Bausteine] die Komplexität unseres Problems reduziert; statt hochleistungsfähige Strings zu bauen, indem wir jede denkbare Kombination ausprobieren, bauen wir bessere und bessere Strings aus den besten Teillösungen vergangener Probenahmen. "Weil hochpassende Schemata mit geringer definierender Länge und geringer Ordnung eine so wichtige Rolle bei der Wirkung genetischer Algorithmen spielen, haben wir ihnen bereits einen besonderen Namen gegeben: Bausteine. So wie ein Kind durch die Anordnung von einfachen Holzblöcken prächtige Festungen schafft, so sucht ein genetischer Algorithmus durch die Gegenüberstellung von kurzer, niederer Ordnung, Hochleistungs-Schemata oder Bausteine in der Nähe einer optimalen Leistung." Trotz des Mangels an Konsens in Bezug auf die Gültigkeit der Gebäudeblock-Hypothese wurde sie im Laufe der Jahre konsequent ausgewertet und als Referenz verwendet. Viele Schätzungen von Verteilungsalgorithmen wurden beispielsweise vorgeschlagen, um eine Umgebung zu schaffen, in der die Hypothese halten würde. Obwohl gute Ergebnisse für einige Klassen von Problemen berichtet wurden, bleibt der Skeptizismus bezüglich der Allgemeinheit und/oder Praxis der Gebäudeblockhypothese als Erklärung für die GAs-Effizienz weiterhin bestehen. Tatsächlich gibt es eine angemessene Menge an Arbeit, die versucht, seine Einschränkungen aus der Perspektive der Schätzung von Verteilungsalgorithmen zu verstehen. Einschränkungen Es gibt Einschränkungen der Verwendung eines genetischen Algorithmus im Vergleich zu alternativen Optimierungsalgorithmen: Wiederholte Fitness-Funktionsauswertung für komplexe Probleme ist oft das verbietendste und begrenzende Segment künstlicher evolutionärer Algorithmen. Die optimale Lösung für komplexe hochdimensionale, multimodale Probleme zu finden, erfordert oft sehr teure Fitness-Funktionsauswertungen. In realen Weltproblemen wie strukturellen Optimierungsproblemen kann eine einzige Funktionsauswertung mehrere Stunden bis mehrere Tage der vollständigen Simulation erfordern. Typische Optimierungsverfahren können sich nicht mit solchen Arten von Problemen befassen. In diesem Fall kann es erforderlich sein, eine exakte Bewertung abzugeben und eine angenäherte Fitness zu verwenden, die rechnerisch effizient ist. Es zeigt sich, dass die Amalgamation von ungefähren Modellen eine der vielversprechendsten Ansätze sein kann, um GA zu überzeugen, komplexe reale Lebensprobleme zu lösen. Genetische Algorithmen skalieren nicht gut mit Komplexität. Das heißt, wo die Anzahl der Elemente, die einer Mutation ausgesetzt sind, groß ist, gibt es oft eine exponentielle Vergrößerung der Suchraumgröße. Dies macht es äußerst schwierig, die Technik auf Probleme wie die Konstruktion eines Motors, eines Hauses oder eines Flugzeugs zu verwenden. Um solche Probleme für die evolutionäre Suche lenkbar zu machen, müssen sie in die einfachste Darstellung zerlegt werden. Daher sehen wir in der Regel evolutionäre Algorithmen Kodierung Designs für Lüfterblätter anstelle von Motoren, Bauformen anstelle von detaillierten Bauplänen und Airfoils anstelle von ganzen Flugzeugdesigns. Das zweite Problem der Komplexität ist die Frage, wie Teile, die sich entwickelt haben, um gute Lösungen vor einer weiteren destruktiven Mutation darzustellen, insbesondere wenn ihre Fitness-Bewertung sie erfordert, gut mit anderen Teilen zu kombinieren. Die bessere Lösung ist nur im Vergleich zu anderen Lösungen. Dadurch ist das Stoppkriterium in jedem Problem nicht klar. In vielen Problemen, GAs neigen dazu, statt dem globalen Optimum des Problems auf lokale Optima oder sogar beliebige Punkte zu konvergieren. Dies bedeutet, dass es nicht "wissen, wie" kurzfristige Fitness zu opfern, um längerfristige Fitness zu gewinnen. Die Wahrscheinlichkeit dieses Auftretens hängt von der Form der Fitness-Landschaft ab: bestimmte Probleme können einen leichten Aufstieg zu einem globalen Optimum bieten, andere können es einfacher für die Funktion, die lokale Opima zu finden. Dieses Problem kann durch die Verwendung einer anderen Fitness-Funktion, die Erhöhung der Rate der Mutation, oder durch die Verwendung von Auswahltechniken, die eine vielfältige Bevölkerung von Lösungen, obwohl das No Free Lunch Theorem beweist, dass es keine allgemeine Lösung für dieses Problem. Eine gemeinsame Technik zur Erhaltung der Vielfalt besteht darin, eine "Nischenstrafe" zu verhängen, wobei jede Gruppe von Individuen mit ausreichender Ähnlichkeit (Nischenradius) eine Strafe hinzugefügt haben, die die Darstellung dieser Gruppe in späteren Generationen verkleinern wird, wodurch andere (weniger ähnliche) Individuen in der Bevölkerung aufrechterhalten werden können. Dieser Trick kann jedoch nicht wirksam sein, abhängig von der Landschaft des Problems. Eine andere mögliche Technik wäre, einen Teil der Bevölkerung einfach durch zufällig erzeugte Personen zu ersetzen, wenn die meisten der Bevölkerung zu ähnlich sind. Diversität ist in genetischen Algorithmen (und genetische Programmierung) wichtig, weil die Überquerung einer homogenen Population keine neuen Lösungen liefert. In Evolutionsstrategien und evolutionären Programmierungen ist Vielfalt aufgrund einer stärkeren Abhängigkeit von Mutation nicht wesentlich. Der Betrieb auf dynamischen Datensätzen ist schwierig, da Genome frühzeitig auf Lösungen konvergieren, die für spätere Daten nicht mehr gültig sind. Es wurden mehrere Methoden vorgeschlagen, um dies zu beheben, indem die genetische Vielfalt irgendwie erhöht wird und eine vorzeitige Konvergenz verhindert wird, entweder durch Erhöhung der Wahrscheinlichkeit der Mutation, wenn die Lösungsqualität sinkt (genannte ausgelöste Hypermutation), oder durch gelegentliche Einführung völlig neuer, zufällig generierter Elemente in den Genpool (sogenannte zufällige Einwanderer).Auch hier können Evolutionsstrategien und evolutionäre Programmierung mit einer sogenannten "Comma-Strategie" umgesetzt werden, in der Eltern nicht gepflegt werden und neue Eltern nur von Nachkommen ausgewählt werden. Dies kann bei dynamischen Problemen wirksamer sein. GAs kann nicht effektiv Probleme lösen, bei denen das einzige Fitness-Maßnahmegerät eine einzige rechte/falsche Maßnahme ist (wie Entscheidungsprobleme), da es keine Möglichkeit gibt, auf der Lösung zu konvergieren (kein Berg zu klettern). In diesen Fällen kann eine zufällige Suche eine Lösung so schnell wie eine GA finden. Wenn die Situation jedoch die Wiederholung des Erfolgs/Versagens-Tests ermöglicht (möglicherweise) verschiedene Ergebnisse, dann bietet das Verhältnis von Erfolgen zu Misserfolgen eine geeignete Fitnessmaßnahme. Bei bestimmten Optimierungsproblemen und Problemfällen können andere Optimierungsalgorithmen effizienter sein als genetische Algorithmen hinsichtlich der Geschwindigkeit der Konvergenz. Alternative und komplementäre Algorithmen umfassen Evolutionsstrategien, evolutionäre Programmierung, simulierte Glühung, Gausssische Anpassung, Bergsteigen und swarm Intelligence (z.B. Ant-Kolonie-Optimierung, Partikel-Swarm-Optimierung) und Methoden auf der ganzzahligen linearen Programmierung. Die Eignung genetischer Algorithmen hängt von der Wissensmenge des Problems ab; bekannte Probleme haben oft bessere, spezialisiertere Ansätze. Varianten Chromosomendarstellung Der einfachste Algorithmus stellt jedes Chromosom als Bit-String dar. Typischerweise können numerische Parameter durch ganze Zahlen dargestellt werden, obwohl es möglich ist, schwimmende Punktdarstellungen zu verwenden. Die schwimmende Punktdarstellung ist natürlich für Evolutionsstrategien und evolutionäre Programmierung. Der Begriff der wirklich bewerteten genetischen Algorithmen wurde angeboten, ist aber wirklich ein Irrtum, weil es nicht wirklich die Gebäudeblock-Theorie darstellt, die von John Henry Holland in den 1970er Jahren vorgeschlagen wurde. Diese Theorie ist jedoch nicht ohne Unterstützung, basierend auf theoretischen und experimentellen Ergebnissen (siehe unten). Der Grundalgorithmus führt Crossover und Mutation auf der Bitebene durch. Andere Varianten behandeln das Chromosom als eine Liste von Zahlen, die in eine Befehlstabelle, Knoten in einer verknüpften Liste, Hashes, Objekte oder eine andere denkbare Datenstruktur sind. Überkreuzung und Mutation werden zur Einhaltung von Datenelementgrenzen durchgeführt. Für die meisten Datentypen können spezifische Variationsoperatoren entwickelt werden. Unterschiedliche chromosomale Datentypen scheinen für verschiedene spezifische Problembereiche besser oder schlechter zu arbeiten. Bei Verwendung von Bit-String-Repräsentationen von Ganzzahlen wird häufig Gray-Codierung verwendet. Auf diese Weise können kleine Änderungen in der ganzen Zahl durch Mutationen oder Überkreuzungen leicht beeinflußt werden. Dies hat sich gezeigt, um eine vorzeitige Konvergenz an sogenannten Hammingwänden zu verhindern, bei denen zu viele gleichzeitige Mutationen (oder Crossover-Ereignisse) auftreten müssen, um das Chromosom zu einer besseren Lösung zu verändern. Andere Ansätze beinhalten die Verwendung von Arrays von echten Zahlen anstelle von Bit-Strings, um Chromosomen zu repräsentieren. Ergebnisse aus der Schemata-Theorie weisen darauf hin, dass im Allgemeinen umso kleiner das Alphabet, desto besser die Leistung, aber es war zunächst überraschend für Forscher, dass gute Ergebnisse aus der Verwendung von echten Chromosomen erhalten wurden. Dies wurde als die Menge von realen Werten in einer endlichen Population von Chromosomen als Bildung eines virtuellen Alphabets (wenn Auswahl und Rekombination dominant sind) mit einer viel niedrigeren Herzlichkeit erklärt, als aus einer schwimmenden Punktdarstellung zu erwarten wäre. Eine Erweiterung der Genetischen Algorithm zugänglichen Problemdomäne kann durch eine komplexere Codierung der Lösungspools erhalten werden, indem mehrere Arten heterogen kodierter Gene in ein Chromosom konkatiert werden. Dieser spezielle Ansatz ermöglicht die Lösung von Optimierungsproblemen, die für die Problemparameter stark unterschiedliche Definitionsdomänen erfordern. Beispielsweise kann bei Problemen der kaskadierten Steuerungsabstimmung die interne Schleifensteuerungsstruktur einem herkömmlichen Regler von drei Parametern angehören, während die externe Schleife einen sprachlichen Regler (z.B. ein Fuzzy-System) implementieren könnte, der eine in sich unterschiedliche Beschreibung aufweist. Diese spezielle Form der Codierung erfordert einen spezialisierten Crossover-Mechanismus, der das Chromosom nach Schnitt rekombiniert, und es ist ein nützliches Werkzeug für die Modellierung und Simulation komplexer adaptiver Systeme, insbesondere Evolutionsprozesse. Elisismus Eine praktische Variante des allgemeinen Prozesses des Aufbaus einer neuen Population besteht darin, den/die besten Organismen der aktuellen Generation auf die nächste, unveränderte zu übertragen. Diese Strategie ist als elitäre Auswahl bekannt und garantiert, dass die von der GA erhaltene Lösungsqualität von einer Generation zur nächsten nicht abnimmt.Parallele Implementierungen von genetischen Algorithmen kommen in zwei Geschmacksrichtungen. Coarse-grainierte parallele genetische Algorithmen nehmen eine Population auf jedem der Computerknoten und Migration von Individuen unter den Knoten an. Feinkörnige parallele genetische Algorithmen nehmen an jedem Prozessorknoten ein Individuum an, das mit benachbarten Individuen zur Auswahl und Wiedergabe wirkt. Andere Varianten, wie genetische Algorithmen für Online-Optimierungsprobleme, stellen Zeitabhängigkeit oder Geräusche in der Fitness-Funktion ein. Adaptive GAs Genetische Algorithmen mit adaptiven Parametern (adaptive genetische Algorithmen, AGAs) ist eine weitere signifikante und vielversprechende Variante genetischer Algorithmen. Die Wahrscheinlichkeiten von Crossover (pc) und Mutation (pm) bestimmen stark den Grad der Lösungsgenauigkeit und die Konvergenzgeschwindigkeit, die genetische Algorithmen erhalten können. Anstatt feste Werte von pc und pm zu verwenden, verwenden AGAs die Bevölkerungsinformationen in jeder Generation und passen die pc und pm adaptiv an, um die Bevölkerungsvielfalt zu erhalten sowie die Konvergenzkapazität zu erhalten. In AGA (Adaptive Genalgorithmus) hängt die Einstellung von pc und pm von den Fitnesswerten der Lösungen ab. In CAGA (Clustering-basierter adaptiver genetischer Algorithmus) hängt die Anpassung von pc und pm von diesen Optimierungszuständen ab. Es kann durchaus effektiv sein, GA mit anderen Optimierungsmethoden zu kombinieren. GA neigt dazu, allgemein gute globale Lösungen zu finden, aber ziemlich ineffizient, die letzten Mutationen zu finden, um das absolute Optimum zu finden. Andere Techniken (wie einfaches Bergsteigen) sind sehr effizient, um absolutes Optimum in einer begrenzten Region zu finden. Das Wechseln von GA und Bergsteigen kann die Effizienz von GA verbessern und gleichzeitig die mangelnde Robustheit des Bergsteigens überwinden. Dies bedeutet, dass die Regeln der genetischen Variation im natürlichen Fall eine andere Bedeutung haben können. Zum Beispiel – vorausgesetzt, dass Schritte in aufeinanderfolgender Reihenfolge gespeichert werden – kann die Überquerung eine Reihe von Schritten von mütterlicher DNA zusammenfassen, die eine Reihe von Schritten von der väterlichen DNA und so weiter hinzufügen. Dies ist wie das Hinzufügen von Vektoren, die wahrscheinlich einen Berg in der phenotypischen Landschaft folgen. So kann die Effizienz des Verfahrens um viele Größenordnungen erhöht werden. Darüber hinaus hat der Inversionsoperator die Möglichkeit, Schritte in aufeinanderfolgender Reihenfolge oder eine andere geeignete Ordnung zugunsten von Überleben oder Effizienz zu platzieren. Eine Variation, bei der die Bevölkerung als Ganzes entwickelt wird, anstatt ihre einzelnen Mitglieder, ist als Gen-Pool-Rekombination bekannt. Es wurden eine Reihe von Variationen entwickelt, um zu versuchen, die Leistung von GAs auf Probleme mit einem hohen Grad an Fitness-Epistasis zu verbessern, d.h. wo die Fitness einer Lösung aus interagierenden Teilmengen seiner Variablen besteht. Solche Algorithmen zielen darauf ab, diese nützlichen phenotypischen Interaktionen zu lernen (vor der Nutzung). Sie orientieren sich dabei an der Hypothese des Bausteins, um störende Rekombinationen adaptiv zu reduzieren. Beispiele für diesen Ansatz sind die mGA, GEMGA und LLGA. Problembereiche Probleme, die für die Lösung durch genetische Algorithmen besonders geeignet erscheinen, umfassen Zeit- und Terminierungsprobleme, und viele Terminierungssoftwarepakete basieren auf GAs. Die GAs wurden auch auf Technik angewendet. Genetische Algorithmen werden oft als Ansatz zur Lösung globaler Optimierungsprobleme eingesetzt. Als allgemeine Regel der Daumen-Genetikalgorithmen könnte nützlich sein in Problem-Domains, die eine komplexe Fitness-Landschaft als Mischen haben, d.h. Mutation in Kombination mit Crossover, ist entworfen, um die Bevölkerung weg von lokalen Opima zu bewegen, dass ein traditioneller Bergkletternalgorithmus stecken in. Beachten Sie, dass häufig verwendete Crossover-Betreiber keine einheitliche Bevölkerung ändern können. Mutation allein kann Ergonomie des gesamten genetischen Algorithmus-Prozesses (seen als Markov-Kette). Beispiele für Probleme, die durch genetische Algorithmen gelöst werden, sind: Spiegel, die Sonnenlicht auf einen Sonnenkollektor trichtern, Antennen, die darauf ausgelegt sind, Funksignale im Raum aufzunehmen, Wandermethoden für Computerfiguren, optimale Gestaltung aerodynamischer Körper in komplexen Strömungsfeldern In seinem Algorithm Design Manual berät Skiena gegen genetische Algorithmen für jede Aufgabe: [I]t ist ziemlich unnatürlich für Modellanwendungen in Bezug auf genetische Operatoren wie Mutation und Crossover auf Bitstrings. Die Pseudobiologie fügt eine weitere Komplexität zwischen Ihnen und Ihrem Problem hinzu. Zweitens nehmen genetische Algorithmen sehr lange Zeit auf nicht-trivialen Problemen.[...] [T] die Analogie zur Evolution – wo erhebliche Fortschritte erfordern [sic] Millionen von Jahren – kann durchaus angemessen sein]. Ich habe noch nie ein Problem erlebt, wo genetische Algorithmen mir den richtigen Weg schienen, es anzugreifen. Außerdem habe ich noch nie irgendwelche rechnerischen Ergebnisse gesehen, die mit genetischen Algorithmen berichtet wurden, die mich positiv beeindruckt haben. Halten Sie an, um zu simulieren Glühen für Ihre heuristischen Suche Voodoo Bedürfnisse. Geschichte Im Jahr 1950 schlug Alan Turing eine "Lernmaschine" vor, die die Prinzipien der Evolution parallele. Die Computersimulation der Evolution begann bereits 1954 mit der Arbeit von Nils Aall Barricelli, die den Computer am Institut für Fortgeschrittene Studie in Princeton, New Jersey, nutzte. Seine Veröffentlichung von 1954 war nicht sehr aufgefallen. Ab 1957 veröffentlichte der australische quantitative Genetiker Alex Fraser eine Reihe von Papieren über die Simulation von künstlicher Selektion von Organismen mit mehreren loci, die eine messbare Trait steuern. Von diesen Anfängen wurde die Computersimulation der Evolution durch Biologen in den frühen 1960er Jahren häufiger, und die Methoden wurden in Büchern von Fraser und Burnell (1970) und Crosby (1973) beschrieben. Frasers Simulationen enthielten alle wesentlichen Elemente moderner genetischer Algorithmen. Darüber hinaus veröffentlichte Hans-Joachim Bremermann in den 1960er Jahren eine Reihe von Papieren, die auch eine Bevölkerung von Lösung für Optimierungsprobleme, Rekombination, Mutation und Selektion einnahmen. Bremermanns Forschung umfasste auch die Elemente moderner genetischer Algorithmen. Zu den weiteren bemerkenswerten frühen Pionieren gehören Richard Friedberg, George Friedman und Michael Conrad. Viele frühe Papiere werden von Fogel (1998) nachgedruckt. Obwohl Barricelli, in seiner Arbeit berichtete er 1963, die Entwicklung der Fähigkeit, ein einfaches Spiel zu spielen, simuliert hatte, wurde die künstliche Evolution nur durch die Arbeit von Ingo Rechenberg und Hans-Paul Schwefel in den 1960er und frühen 1970er Jahren zu einer allgemein anerkannten Optimierungsmethode –Rechenbergs Gruppe konnte komplexe technische Probleme durch Evolutionsstrategien lösen. Ein weiterer Ansatz war die evolutionäre Programmiertechnik von Lawrence J. Fogel, die zur Erzeugung künstlicher Intelligenz vorgeschlagen wurde. Evolutionäre Programmierung ursprünglich verwendet Finite-Zustandsmaschinen für die Vorhersage von Umgebungen, und verwendet Variation und Auswahl, um die prädiktiven Logiken zu optimieren. Genetische Algorithmen wurden insbesondere durch die Arbeit von John Holland in den frühen 1970er-Jahren populär, und insbesondere sein Buch Adaptation in Natural and Artificial Systems (1975). Seine Arbeit entstand aus dem Studium der zellulären Automaten, unter der Leitung von Holland und seinen Studenten an der Universität Michigan. Holland führte einen formalisierten Rahmen für die Vorhersage der Qualität der nächsten Generation, bekannt als Holland's Schema Theorem. Die Forschung in GAs blieb bis Mitte der 1980er Jahre weitgehend theoretisch, als die erste Internationale Konferenz über genetische Algorithmen in Pittsburgh, Pennsylvania stattfand. Handelswaren In den späten 1980er Jahren begann General Electric mit dem Verkauf des weltweit ersten Genalgorithmus-Produkts, einem Mainframe-basierten Toolkit für industrielle Prozesse. 1989 veröffentlichte Axcelis, Inc. Evolver, das weltweit erste kommerzielle GA-Produkt für Desktop-Computer. Der New York Times-Technologieschreiber John Markoff schrieb 1990 über Evolver und blieb bis 1995 der einzige interaktive kommerzielle genetische Algorithmus. Evolver wurde 1997 an Palisade verkauft, in mehrere Sprachen übersetzt und ist derzeit in seiner 6. Version. Seit den 1990er Jahren hat MATLAB in drei derivatfreien Optimierungs-Huristikalgorithmen (simulierte Glühung, Partikelschwarmoptimierung, genetischer Algorithmus) und zwei direkten Suchalgorithmen (Simplexsuche, Mustersuche) aufgebaut. Ähnliche Techniken Stammfelder Genetische Algorithmen sind ein Unterfeld: Evolutionäre Algorithmen Evolutionary Computing Metaheuristics Stochastic Optimization Evolutionäre Algorithmen Evolutionäre Algorithmen ist ein Unterfeld des evolutionären Computings. Evolutionsstrategien (ES, siehe Rechenberg, 1994) entwickeln Einzelpersonen durch Mutation und Zwischen- oder diskrete Rekombination. ES-Algorithmen sind besonders entwickelt, um Probleme in der Realwert-Domain zu lösen. Sie verwenden Selbstanpassung, um die Kontrollparameter der Suche anzupassen. Die De-randomisierung der Selbstanpassung hat zur aktuellen Covariance Matrix Adaptation Evolution Strategy (CMA-ES) geführt. Evolutionäre Programmierung (EP) umfasst die Populationen von Lösungen mit vorwiegend Mutation und Auswahl und willkürliche Darstellungen.Sie verwenden die Selbstanpassung, um Parameter anzupassen, und können andere Variationsoperationen wie die Kombination von Informationen von mehreren Eltern umfassen. Die Schätzung des Verteilungsalgorithmus (EDA) ersetzt traditionelle Reproduktionsoperatoren durch modellgeführte Operatoren. Solche Modelle werden aus der Bevölkerung durch die Anwendung von maschinellen Lerntechniken erlernt und als probabilistische Grafikmodelle dargestellt, aus denen neue Lösungen aus geführtem Crossover abgetastet oder erzeugt werden können. Gene Expression Programmierung (GEP) verwendet auch Populationen von Computerprogrammen. Diese komplexen Computerprogramme werden in einfacheren linearen Chromosomen fester Länge kodiert, die anschließend als Expressionsbäume ausgedrückt werden. Expressionsbäume oder Computerprogramme entwickeln sich, weil die Chromosomen in ähnlicher Weise wie die kanonische GA Mutation und Rekombination erfahren. Aber dank der speziellen Organisation von GEP Chromosomen führen diese genetischen Modifikationen immer zu gültigen Computerprogrammen. Genetische Programmierung (GP) ist eine von John Koza populäre verwandte Technik, in der Computerprogramme anstatt Funktionsparameter optimiert werden. Genetische Programmierung verwendet häufig baumbasierte interne Datenstrukturen, um die Computerprogramme zur Anpassung anstelle der für genetische Algorithmen typischen Listenstrukturen darzustellen. GGA ist eine Evolution der GA, in der der Fokus von einzelnen Elementen, wie in klassischen GAs, zu Gruppen oder Untergruppen von Elementen verschoben wird. Die Idee hinter dieser von Emanuel Falkenauer vorgeschlagenen GA-Entwicklung ist, dass die Lösung einiger komplexer Probleme, a.k.a.clustering oder Partitioning-Probleme, bei denen eine Reihe von Gegenständen in eine ungemeinsame Gruppe von Gegenständen in optimaler Weise aufgeteilt werden muss, durch die Herstellung von Merkmalen der Gruppen von Gegenständen, die den Genen äquivalent sind, besser erreicht werden würde. Diese Art von Problemen umfassen bin Verpackung, Linienausgleich, Clustering in Bezug auf eine Entfernungsmaßnahme, gleiche Pfähle, etc., auf denen klassische GAs als schlecht durchzuführen erwiesen. Genen, die Gruppen äquivalent sind, implizieren Chromosomen, die im allgemeinen von variabler Länge sind, und spezielle genetische Operatoren, die ganze Gruppen von Gegenständen manipulieren. Insbesondere für die Bin-Verpackung ist eine mit dem Dominance Criterion von Martello und Toth hybridisierte GGA wahrscheinlich die bisher beste Technik. Interaktive evolutionäre Algorithmen sind evolutionäre Algorithmen, die menschliche Auswertung verwenden. Sie werden in der Regel auf Domänen angewendet, wo es schwer ist, eine rechnerische Fitness-Funktion zu entwerfen, zum Beispiel, sich entwickelnde Bilder, Musik, künstlerische Designs und Formen, um die ästhetische Präferenz der Benutzer zu passen. Swarm Intelligence Swarm Intelligence ist ein Unterfeld des evolutionären Computings. Ant Kolonie Optimierung (ACO) verwendet viele Ameisen (oder Agenten), die mit einem Pheromone-Modell ausgestattet sind, um den Lösungsraum zu durchqueren und lokal produktive Bereiche zu finden. Obwohl es sich um eine Schätzung des Verteilungsalgorithmus handelt, ist die Partikelschwarm-Optimierung (PSO) eine rechnerische Methode zur Multiparameter-Optimierung, die auch einen bevölkerungsbasierten Ansatz verwendet. Eine Population (Krieg) von Kandidatenlösungen (Teilchen) bewegt sich im Suchraum, und die Bewegung der Partikel wird sowohl durch ihre eigene bekannteste Position als auch die weltweit bekannteste Position von swarm beeinflusst. Wie genetische Algorithmen hängt die PSO-Methode vom Informationsaustausch zwischen Bevölkerungsmitgliedern ab. Bei einigen Problemen ist die PSO oft rechnerisch effizienter als die GAs, insbesondere bei untrainierten Problemen mit kontinuierlichen Variablen. Evolutionäre Algorithmen kombiniert mit Swarm Intelligence Mayfly Optimierungsalgorithmus (MA) kombiniert große Vorteile evolutionärer Algorithmen und swarm Intelligence Algorithmen. Andere evolutionäre Rechenalgorithmen Evolutionäre Berechnung ist ein Unterfeld der metaheuristischen Methoden. Memetischer Algorithmus (MA,) oft als hybrider genetischer Algorithmus u.a. bezeichnet, ist eine bevölkerungsbasierte Methode, bei der Lösungen auch lokalen Verbesserungsphasen unterliegen. Die Idee von memetischen Algorithmen kommt von Memen, die sich im Gegensatz zu Genen selbst anpassen können. In einigen Problembereichen wird gezeigt, dass sie effizienter sind als herkömmliche evolutionäre Algorithmen. Bacteriologische Algorithmen (BA) inspiriert von evolutionärer Ökologie und insbesondere bakteriologischer Anpassung. Evolutionäre Ökologie ist die Studie von lebenden Organismen im Kontext ihrer Umwelt, mit dem Ziel, zu entdecken, wie sie sich anpassen. Sein Grundgedanke ist, dass in einer heterogenen Umgebung nicht ein Individuum vorhanden ist, das in die gesamte Umgebung passt. Man muss also auf der Bevölkerungsebene begründen. Es wird auch angenommen, dass BAs erfolgreich auf komplexe Positionierungsprobleme (Antennen für Handys, Stadtplanung usw.) oder Datenabbau angewendet werden können.Der Kulturalgorithmus (CA) besteht aus der Populationskomponente, die fast identisch ist mit der des genetischen Algorithmus und darüber hinaus einer Wissenskomponente namens Glaubensraum. Differenzielle Evolution (DS) inspiriert durch Migration von Superorganismen. Für die Maximierung der Fertigungsausbeute von Signalverarbeitungssystemen ist eine Gausssche Anpassung (normale oder natürliche Anpassung, abgekürzte NA zur Vermeidung von Verwechslungen mit GA) vorgesehen. Es kann auch für eine normale parametrische Optimierung verwendet werden. Es basiert auf einem bestimmten Theorem, das für alle Regionen der Akzeptanz und alle Gaussian Distributionen gültig ist. Die Effizienz von NA beruht auf der Informationstheorie und einem bestimmten Theorie der Effizienz. Seine Effizienz ist definiert als Informationen geteilt durch die Arbeit, die benötigt wird, um die Informationen zu erhalten. Weil NA maximises Fitness und nicht die Fitness des Individuums bedeuten, wird die Landschaft geglättet, so dass Täler zwischen Spitzen verschwinden können. Daher hat es ein gewisses Ziel, lokale Spitzen in der Fitness-Landschaft zu vermeiden. NA ist auch gut beim Klettern von scharfen Knittern durch Anpassung der Momentenmatrix, weil NA die Störung (mittlere Information) des Gaussian gleichzeitig die mittlere Fitness konstant halten kann. Andere metaheuristische Methoden Metaheuristische Methoden fallen weitgehend in stochastische Optimierungsmethoden. Die Simulierte Glühung (SA) ist eine verwandte globale Optimierungstechnik, die den Suchraum durch die Prüfung von zufälligen Mutationen auf einer individuellen Lösung durchläuft. Eine Mutation, die die Fitness erhöht, wird immer akzeptiert. Eine Mutation, die die Fitness senkt, wird probabilistisch basierend auf der Differenz in der Fitness und einem abnehmenden Temperaturparameter angenommen. In SA parlance spricht man von der Suche nach der niedrigsten Energie statt der maximalen Fitness. SA kann auch innerhalb eines Standard-GA-Algorithmus verwendet werden, indem man mit einer relativ hohen Mutationsrate beginnt und sie im Laufe der Zeit entlang eines vorgegebenen Zeitplans abnimmt. Die Tabu-Suche (TS) ist ähnlich der simulierten Glühung, indem beide den Lösungsraum durch Testen von Mutationen einer einzelnen Lösung durchqueren. Während die simulierte Glühung nur eine mutierte Lösung erzeugt, erzeugt die tabusuche viele mutierte Lösungen und bewegt sich mit der niedrigsten Energie der generierten Lösungen. Um das Radfahren zu verhindern und eine größere Bewegung durch den Lösungsraum zu fördern, wird eine tabu-Liste von teilweisen oder vollständigen Lösungen gehalten. Es ist verboten, zu einer Lösung zu bewegen, die Elemente der tabu-Liste enthält, die aktualisiert wird, wenn die Lösung den Lösungsraum durchläuft. Extremale Optimierung (EO) Im Gegensatz zu GAs, die mit einer Bevölkerung von Kandidatenlösungen arbeiten, entwickelt EO eine einzige Lösung und macht lokale Änderungen an den schlimmsten Komponenten. Dies erfordert eine geeignete Darstellung, die es erlaubt, einzelne Lösungskomponenten einem Qualitätsmaß (Fitness) zuzuordnen. Das Prinzip hinter diesem Algorithmus ist das der aufstrebenden Verbesserung durch selektives Entfernen von qualitativ minderwertigen Komponenten und durch Ersatz durch eine zufällig ausgewählte Komponente. Dies steht entschieden im Widerspruch zu einer GA, die gute Lösungen für einen Versuch, bessere Lösungen zu machen. Andere stochastische Optimierungsmethoden Das Cross-Entropy (CE)-Verfahren erzeugt Kandidatenlösungen über eine parametrisierte Wahrscheinlichkeitsverteilung. Die Parameter werden über Kreuz-Entropie-Mineralisierung aktualisiert, um in der nächsten Iteration bessere Proben zu erzeugen. Reaktive Suchoptimierung (RSO) befürwortet die Integration von subsymbolischen maschinellen Lerntechniken in Suchheuristiken zur Lösung komplexer Optimierungsprobleme. Das Wort Reaktiv deutet auf eine bereite Antwort auf Ereignisse während der Suche durch eine interne Online-Feedbackschleife zur Selbstabstimmung kritischer Parameter hin. Zu den für Reactive Search interessanten Methoden gehören maschinelles Lernen und Statistiken, insbesondere Verstärkungslernen, aktives oder Abfragelernen, neuronale Netzwerke und Metaheuristiken. Siehe auch Genetische Programmierung Liste der genetischen Algorithmus-Anwendungen Genetische Algorithmen in der Signalverarbeitung (a.k.a.partikelfilter) Propagation of schemaUniversal Darwinism Metaheuristics Lernen Klassifikator SystemRulebasiertes maschinelles Lernen Referenzen Bibliographie Externe Links Ressourcen [1] Bietet eine Liste von Ressourcen im Bereich der genetischen Algorithmen Eine Übersicht über die Geschichte und Geschmack von Evolutionären Algorithmen Tutorials Genetische Algorithmen - Computer-Programme, die sich in einer Weise entwickeln, die der natürlichen Selektion ähneln, können komplexe Probleme lösen, auch ihre Schöpfer nicht vollständig verstehen Eine ausgezeichnete Einführung in die GA von John Holland und mit einem Antrag auf das Dilemma des Gefangenen Ein Online-Interaktives Genetisches Algorithm-Tutorial für einen Leser zu üben oder zu lernen, wie ein GA funktioniert: Lernen Sie Schritt für Schritt oder beobachten Sie die globale Konvergenz in Batch, ändern Sie die Bevölkerungsgröße, Crossover-Raten/bounds, Mutationsraten/bounds und Auswahlmechanismen und fügen Sie Einschränkungen hinzu.A Genetic Algorithm Tutorial von Darrell Whitley Computer Science Department Colorado State University Ein ausgezeichnetes Tutorial mit viel Theorie "Essentials of Metaheuristics", 2009 (225 p). Freier Text von Sean Luke. Globale Optimierung Algorithmen – Theorie und Anwendung Genetische Algorithmen in Python Tutorial mit der Intuition hinter GAs und Python Implementierung. Genetische Algorithmen entwickeln sich, um das Dilemma des Gefangenen zu lösen. Geschrieben von Robert Axelrod.