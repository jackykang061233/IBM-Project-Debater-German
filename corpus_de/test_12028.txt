Ein militärischer künstlicher Rüstungswettlauf ist ein Wettbewerb oder Waffenrennen zwischen zwei oder mehr Staaten, um ihre militärischen Kräfte mit der besten künstlichen Intelligenz (AI) ausgestattet zu haben. Seit Mitte 2010 haben viele Analysten die Entstehung eines solchen globalen Waffenrennens, der AI Arms Rasse, zwischen großen Befugnissen für eine bessere militärische AI, die mit den zunehmenden geopolitischen und militärischen Spannungen des Zweiten Kalten Krieges in Gang gesetzt werden. Kontext des AI-Waffenrennens ist der AI Kalte Krieg, in dem die Spannungen zwischen den USA und China zu einem Kalten Krieg führen, der im Bereich der AI-Technologie lagen. Terminologie Mehr im Großen und Ganzen ist jeder Wettbewerb für überlegene AI manchmal als „Arms Rasse“ definiert. Überschneidungen mit dem Streben nach einer beherrschenden Stellung in anderen Bereichen, vor allem weil ein Land wirtschaftliche und militärische Vorteile verfolgt. Risiken Stephen Cave of the Leverhulme Centre argumentiert, dass die Risiken eines AI-Konkurrents dreifach sind, wobei das erste Risiko geopolitische Auswirkungen haben könnte und die zweite zwei definitiv geopolitische Auswirkungen haben. Das erste Risiko besteht darin, dass auch wenn die Terminologie der Rasse nicht wettgemacht wurde, gefährlich ist. Die Rhetorik rund um den AI-Konkurrent und die Bedeutung, zuerst zu werden, begünstigen nicht die Art der erwogenen Beratung mit den beteiligten Inhabern, die für die Herstellung von AI-Technologien, die für die Gesellschaft am weitesten von Vorteil sind, erforderlich sind, um eine Rasse zu schaffen. Das zweite Risiko ist das AI-rennen selbst, ob das Rennen von einer Gruppe gewonnen wird. Infolge der Rhetorik und des wahrgenommenen Vorteils, die erste Entwicklung fortgeschrittener AI-Technologie zu sein, ergeben sich starke Anreize, Ecken auf Sicherheitserwägungen zu reduzieren, die wichtige Aspekte wie Unparteilichkeit und Fairness ausschließen könnten. Insbesondere wird die Wahrnehmung eines anderen Teams an der Spitze einer Pause durch andere Teams ermutigt, kurze Kürzungen vorzunehmen und ein AI-System einzuführen, das nicht bereit ist, das andere und die Gruppe, die das AI-System besitzen, schädigen kann. Paul Scharre warnte in der Außenpolitik, "Für jedes Land ist die tatsächliche Gefahr nicht, dass es seinen Wettbewerbern in der AI hinterhergeht, sondern dass die Wahrnehmung eines Wettlaufs alle dazu veranlassen wird, unsichere AI-Systeme zu nutzen. In ihrem Wunsch, gewinnen zu können, riskieren die Länder sich genauso wie ihre Gegner. " Nick Bostrom und andere entwickelten ein Modell, das weitere Beweise dafür liefert. Das Modell stellte fest, dass ein Team mit mehr Informationen über die Fähigkeiten anderer Teams mehr Risikobereitschaft und kurze Kürzungen bei der Entwicklung von AI-Systemen verursachte. Darüber hinaus ist das größere Risiko der Missachtung von Vorsichtsmaßnahmen und einer AI-Katastrophe größer. Eine andere Gefahr eines AI-Waffenrennens besteht darin, die Kontrolle der AI-Systeme zu verlieren, und das Risiko wird im Falle eines Wettrennens zu künstlichen allgemeinen Erkenntnissen verschärft, die Cave ein Existenzrisiko darstellen kann. Das dritte Risiko eines AI-Waffenrennens ist, wenn das Rennen tatsächlich von einer Gruppe gewonnen wird. Ein Beispiel für dieses Risiko ist die Konsolidierung von Kraft- und Technologievorteilen in den Händen einer Gruppe. Kommt eine Gruppe zu einer überlegenen AI-Technologie ["i]t nur zu dem Schluss, dass AI-fähige Fähigkeiten genutzt werden könnten, um unsere kritische Infrastruktur zu gefährden, Desinformationskampagnen und Lohnkrieg zu verstärken." Arms-race-Terminologie wird manchmal auch im Rahmen des Wettbewerbs für die wirtschaftliche beherrschende Stellung und "weichen Macht" verwendet, beispielsweise im November 2019 "Interim Report" der Nationalen Sicherheitskommission der Vereinigten Staaten über künstliche Intelligenz, wobei die Rolle der Diplomatie bei der Ausübung von China und Russland hervorgehoben wird, nimmt die Sprache eines wettbewerbsfähigen Waffenrennens an. Man stellt fest, dass die US-Militärität für die bestehende Weltordnung:11 von entscheidender Bedeutung ist und betont, dass die derzeitige US-Militation von AI, zusammen mit der Militarisierung von AI durch China und Russland, für geopolitische Zwecke ist.:1-2 Stances to militärisch künstlichen Intelligenz Russland General Viktor Bondarev, der Befehlshaber der russischen Lufttruppe, erklärte, dass Russland bereits im Februar 2017 auf AI-guided-Stellen arbeite, die sich für die Abschaltung von Zielen entscheiden könnten. Russlands Militärischem Industrieausschuss hat die Absicht genehmigt, bis 2030 30 Prozent der russischen Kampfkraft aus ferngesteuerten und AI-fähigen Robotikplattformen zu entlasten. [1] Berichte von staatlich geförderten russischen Medien über mögliche militärische Verwendungen von AI stiegen Mitte 2017 an. Im Mai 2017 erklärte der CEO der russischen Kronstadt-Gruppe, ein Verteidigungsunternehmer, dass " es bereits völlig autonome AI-Betriebssysteme gibt, die die Mittel für UAV-Cluster bereitstellen, wenn sie autonom Missionen durchführen, Aufgaben zwischen ihnen teilen und interagieren", und dass es unvermeidlich ist, dass "Säure von Drohnen" einen Tag über die Bekämpfungszonen fliegen. Russland hat mehrere autonome und halbautonomische Kampfsysteme getestet, wie das "neural Net"-Antimodul Kabatnik, mit einer Maschine, einer Kamera und einer AI, dass seine Entscheidungsträger ihre eigene Ausrichtung ohne menschliches Handeln geltend machen können. Im September 2017 erklärte der russische Präsident Vladimir Putin im Rahmen einer nationalen Wissenstagesadresse über eine Million Studierende in 16 000 russischen Schulen "Artificial Intelligence ist die Zukunft, nicht nur für Russland, sondern für alle Menschen... Wer immer in diesem Bereich führend wird, wird zur Regel der Welt. Putin sagte auch, dass es besser wäre, jeden einzigen Schauspieler, der ein Monopol erreicht, zu verhindern, aber dass Russland bei der AI seine „Technologie mit der übrigen Welt teilen würde, wie wir jetzt mit der Atom- und Atomtechnologie tun. Russland setzt eine Reihe von Organisationen ein, die der Entwicklung militärischer AI gewidmet sind. Im März 2018 veröffentlichte die russische Regierung eine 10-Punkte-Apotheke-Agenda, die die Einrichtung eines AI- und Big Data-Konsortiums, eines Fonds für Analytical Algorithms und Programme, eines staatlich unterstützten Ausbildungs- und Bildungsprogramms, eines speziellen AI-Labors und eines nationalen Zentrums für künstliche Intelligenz, unter anderem Initiativen. Russland hat außerdem vor kurzem eine Verteidigungsforschungsorganisation geschaffen, die rund dem DARPA entspricht, die sich für Autonomie und Robotik einsetzte, die Stiftung für fortgeschrittene Studien und eine jährliche Konferenz zum Thema "Robotisierung der Streitkräfte der Russischen Föderation" initiiert. " Russisches Militär hat eine Reihe von AI-Anwendungen untersucht, wobei der Schwerpunkt auf halbautonomen und autonomen Fahrzeugen liegt. Viktor Bondarev, Vorsitzender des Verteidigungs- und Sicherheitsausschusses des Föderationsrates, erklärte in einer offiziellen Erklärung vom 1. November 2017, dass "die umfangreichen Erkenntnisse einen Soldaten auf dem Schlachtfeld ersetzen können und ein Pilot in einem Flugzeug Cockpit darstellen können" und später bemerkte, dass "der Tag in der Nähe des Tages ist, wenn Fahrzeuge künstliche Intelligenz erhalten. " Bondarev machte diese Bemerkungen in unmittelbarer Nähe zum erfolgreichen Test von Nerehta, einem satzungslosen russischen Grundfahrzeug, das berichtete, dass "ausgeführte Fahrzeuge" nicht vorhanden sind. Russland plant die Nutzung von Nerehta als Forschungs- und Entwicklungsplattform für die AI und kann einen Tag das System zur Bekämpfung, zum Sammeln von Erkenntnissen oder Logistikfunktionen einsetzen. Russland hat auch berichtet, dass ein Kampfmodul für besatzungslose Bodenfahrzeuge, die in der Lage sind, autonome Zielkennzeichnung – und möglicherweise das Engagement – zu entwickeln – und plant, eine Reihe von AI-fähigen autonomen Systemen zu entwickeln. Darüber hinaus werden die russischen Militärpläne zur Einbeziehung von AI in  Besatzungslose Luft-, Marine- und Unterseefahrzeuge und zurzeit die Weiterentwicklung schwindender Fähigkeiten entwickelt. Sie untersucht auch innovative Verwendungen von AI für Abgelegenheit und elektronische Kriegsführung, einschließlich adaptiver Frequenz Hopping, Wellenformen und Gegenmaßnahmen. Russland hat auch umfassende Nutzung von AI-Technologien für häusliche Propaganda und Überwachung sowie für Informationsoperationen gegen die Vereinigten Staaten und die US- Verbündeten gemacht. Die russische Regierung hat ein Verbot der tohalischen autonomen Waffensysteme stark abgelehnt, wonach ein solches Verbot ignoriert werden könnte. China verfolgt eine strategische Politik der „military-civil Fusion“ auf der AI für die weltweite technologische Supremacy. Laut einem Bericht vom Februar 2019 von Gregory C. Allen des Center for a New American Security ist die including Chinas – einschließlich der führenden Führung von Xi Jinping – der Ansicht, dass die Zukunft des globalen militärischen und wirtschaftlichen Wettbewerbs entscheidend ist. chinesische Militärbeamte haben erklärt, dass ihr Ziel darin besteht, kommerzielle AI-Technologie zu integrieren, um "die Kluft zwischen dem chinesischen Militär und den weltweit fortgeschrittenen Mächten zu schließen". Die engen Verbindungen zwischen dem Silicon Valley und China und dem offenen Charakter der amerikanischen Forschungsgemeinschaft haben die am weitesten fortgeschrittenen AI-Technologie in China leicht zugänglich gemacht; außerdem hat die chinesische Industrie zahlreiche Heimtier AI-Ergebnisse ihrer eigenen, wie Baidu, die im Jahr 2015 einen bedeutenden chinesischen Sprachanerkennungs-Referenzwert erreicht. Laut dem Fahrplan von Peking soll bis 2030 eine 40 Milliarden $ AI-Industrie entstehen. Vor 2013 war das chinesische Verteidigungs Beschaffungswesen hauptsächlich auf einige Konglomeraten beschränkt; ab 2017 gibt es in China häufig sensible aufstrebende Technologien wie Drohnen und künstliche Intelligenz von privaten Start-up-Unternehmen. Ein chinesischer Staat hat zugesagt, 5 Mrd. Peking hat 2 Mrd. $ an einen AI-Entwicklungspark gebunden. Die Japan Times berichtete im Jahr 2018, dass jährliche private chinesische Investitionen in die AI unter 7 Milliarden $ pro Jahr liegen. AI-Startups in China erhielten im Jahr 2017 fast die Hälfte aller weltweiten Investitionen in AI-Startups; das chinesische Land hat fast fünfmal so viele AI-Patente wie amerikanische angemeldet. China hat 2016 ein Positionspapier veröffentlicht, in dem die Angemessenheit der bestehenden internationalen Rechtsvorschriften zur Bewältigung der Eventualität vollständig autonomer Waffen zum ersten ständigen Mitglied des US-Sicherheitsrates zur Lösung dieses Problems erörtert wird. Im Jahr 2018 rief Xi zu einer verstärkten internationalen Zusammenarbeit in der Grundlagenforschung auf. chinesische Beamte haben Bedenken geäußert, dass AI wie Drohnen zu einem versehentlichen Krieg führen könnten, insbesondere wenn internationale Normen fehlen. Im Jahr 2019 entschloss sich der ehemalige US-Außenminister Mark Esper in China, um Drohnen zu verkaufen, die Leben ohne menschliche Kontrolle ausüben können. United StatesIn 2014 stellte der ehemalige Verteidigungsminister Chuck Hagel die "Dritte Offset-Strategie" vor, die rasche Fortschritte bei der künstlichen Intelligenz die nächste Generation von Kriegen bestimmen wird. Laut Datenwissenschaft und Analysefirma Govini erhöhte das US-Verteidigungsministerium Investitionen in künstliche Intelligenz, große Daten und Cloud Computing von 5,6 Milliarden $ im Jahr 2011 auf 7,4 Milliarden $ im Jahr 2016. Jedoch stieg der zivile NSF-Haushalt für die AI im Jahr 2017 nicht an. Japan Times berichtete 2018, dass die privaten Investitionen der Vereinigten Staaten rund 70 Milliarden $ pro Jahr betragen. Laut dem „Interim Report“ der Nationalen Sicherheitskommission der Vereinigten Staaten vom November 2019 über künstliche Intelligenz bestätigte die AI eine entscheidende Rolle für die US-Technologie. Die U.S hat viele militärische AI-Bekämpfungsprogramme wie das autonome Kriegsschiff Sea Hunter, das für längere Zeiträume auf See ohne ein einziges Besatzungsmitglied bestimmt ist, und selbst in und außerhalb des Hafens. Laut einer vorläufigen US-Verteidigungsrichtlinie ist ab 2017 ein menschlicher Betreiber verpflichtet, im Anschluss an die Nutzung des menschlichen Lebens durch autonome Waffensysteme zu halten. Oktober 2019 veröffentlichte das Verteidigungsministerium der Vereinigten Staaten den Entwurf eines Berichts, in dem Grundsätze für den ethischen Einsatz künstlicher Erkenntnisse durch das Verteidigungsministerium empfohlen werden, die sicherstellen, dass ein Menschunternehmer immer in der Lage sein wird, die "schwarze Box" zu betrachten und den Prozess der tödlichen Kette zu verstehen. Jedoch ist ein wichtiges Anliegen, wie der Bericht umgesetzt wird. Projekt Maven ist ein Projekt mit dem Einsatz von Maschinen- und Ingenieurstalenten, um Menschen und Gegenstände in Drohnen Videos zu unterscheiden, die den Befehls- und Kontrollbehörden der Regierung in Echtzeit ermöglichen, sowie die Fähigkeit, Ziele ohne menschliches Engagement zu verfolgen, zu verfolgen und zu verfolgen. Berichten zufolge wird es kurz davor gehen, als ein AI- Waffensystem zu handeln, das auf selbstgestalteten Zielen beruht. Das Projekt wurde am 26. April 2017 in einem Memo vom Stellvertretenden Verteidigungsminister der Vereinigten Staaten eingerichtet. Auch bekannt als Algorithmic Warfare Cross funktionell Team ist es nach Lt. Gen. der United States Air Force Jack Shanahan im November 2017, einem Projekt "Designed to be this Pilot project, this wayPilot, das die Flammen vor künstlichen Erkenntnissen im Rest der [Defense] Abteilung anregt. Leiter der U.S Marine Corps Col. Drew Cukor sagte: "Die Menschen und Computer werden symmetrisch arbeiten, um die Fähigkeit der Waffensysteme zu erhöhen, um Objekte zu erkennen. " Im Juli 2017 erklärte Cukor auch, dass die Investition in einen "überprüfbaren Arbeitsablauf" durch die "rapid"-Behörden für etwa "die nächsten 36 Monate" vom Ministerium finanziert wurde. Vereinigtes Königreich Im Jahr 2015 lehnte die britische Regierung ein Verbot der tödlichen autonomen Waffen ab, in dem sie feststellte, dass "das internationale humanitäre Völkerrecht für diesen Bereich bereits ausreichende Vorschriften enthält", aber alle Waffen, die von britischen Streitkräften beschäftigt sind, "unter Kontrolle und Kontrolle" sein würden. Israels Harpy Antiradar „Fehlen und Vergessen“ ist so konzipiert, dass sie von Bodentruppen initiiert werden und autonom über einen Bereich fliegen, um Radar zu finden und zu vernichten, der vorab festgelegten Kriterien entspricht. Es wird erwartet, dass die Anwendung künstlicher Intelligenz auch in  Besatzungslosen Bodensystemen und Robotik-Fahrzeugen wie der Guardium MK III und späteren Versionen vorangebracht wird. Diese Roboterfahrzeuge werden in der Grenzverteidigung eingesetzt. Südkorea Die im Jahr 2010 vorgestellte südkoreanische Super aEgis II-Maschinewaffe sieht sowohl in Südkorea als auch im Nahen Osten vor. Es kann ein Ziel von 4 km ermitteln, verfolgen und zerstören. Obwohl die Technologie grundsätzlich ohne menschliche Intervention betrieben werden kann, werden in der Praxis Schutzvorkehrungen installiert, um manuelle Eingaben zu verlangen. Ein südkoreanischer Hersteller stellt fest, dass "Unsere Waffen nicht schlafen, wie Menschen müssen. Sie können in der dunklen, wie Menschen, sehen. Unsere Technologie schließt daher die Lücken in der Human-Fähigkeit ab“, und sie wollen „auf einen Ort, an dem unsere Software erkennen kann, ob ein Ziel Freund, Färger oder militärischer Art ist“. Europäische Union Das Europäische Parlament ist der Ansicht, dass der Mensch über die tödlichen autonomen Waffen über die Kontrolle und Entscheidungsfindung verfügen muss. Jedoch ist es an jedem Mitgliedstaat der Europäischen Union, ihren Standpunkt zur Verwendung autonomer Waffen zu bestimmen, und die gemischte Haltung der Mitgliedstaaten ist vielleicht der größte Hindernis für die Fähigkeit der Europäischen Union, autonome Waffen zu entwickeln. Manche Mitglieder wie Frankreich, Deutschland, Italien und Schweden entwickeln tödliche autonome Waffen. Manche Mitglieder sind nach wie vor über die Verwendung autonomer Militärwaffen und Österreich hat sogar dazu aufgerufen, die Verwendung solcher Waffen zu verbieten. Manche EU-Mitgliedstaaten haben sich entwickelt und entwickeln automatisierte Waffen. Deutschland hat ein aktives Schutzsystem, das aktive Verteidigungssystem, entwickelt, das auf eine Bedrohung reagieren kann, die in weniger als einem Millioslowen besteht. Italien plant, autonome Waffensysteme in ihre künftigen Militärpläne einzubeziehen. Trends Laut Siemens beliefen sich die weltweiten Militärausgaben für Robotik 2010 auf 5,1 Milliarden US$ und 2015 auf 7,5 Milliarden US$. China wurde in den 2010er Jahren zu einem Top-Player in der künstlichen Intelligenzforschung. Laut der Financial Times veröffentlichte China erstmals im Jahr 2016 mehr AI-Papiere als die gesamte Europäische Union. China hat die Vereinigten Staaten 2016 auf die Anzahl der AI-Papiere in den Top 5 % der genannten Papiere beschränkt, aber hinter der Europäischen Union verfehlt.23% der Forscher, die auf der US-amerikanischen Vereinigung für die Förderung der künstlichen Intelligenz (AAAI) im Jahr 2017 vorgestellt wurden, waren chinesische. Eric Schmidt, ehemaliger Präsident von Alphabet, hat vorhergesagt, dass China bis 2025 das führende Land der AI sein wird. Vorschläge für internationale Regulierung Die internationale Regulierung autonomer Waffen ist ein neues Thema für das Völkerrecht. AI Rüstungskontrolle wird wahrscheinlich die Institutionalisierung neuer internationaler Normen erfordern, die in wirksamen technischen Spezifikationen enthalten sind, zusammen mit aktiver Überwachung und informeller Diplomatie durch Expertengemeinschaften und einem rechtlichen und politischen Überprüfungsprozess. Anfang 2007 haben Wissenschaftler wie der AI-Professor Noel Haiey davor gewarnt, "ein aufstrebendes Waffenrennen zwischen den High-Tech-Ländern zu entwickeln, autonome U-Boote, Kampfflugzeuge, Kampfschiffe und Tanks zu entwickeln, die ihre eigenen Ziele finden und Gewalt ohne die Einbeziehung sinnvoller menschlicher Entscheidungen ausüben können". 2014 warnte der AI-Spezialisten Steve Omoternro, dass "ein autonomer Waffenrennen bereits stattfindet". Reisende Brundage der Universität Oxford hat argumentiert, ein AI-Waffenrennen könnte durch Diplomatie etwas abgeschwächt werden: „Wir sehen in den verschiedenen historischen Waffenrennen, die durch Zusammenarbeit und Dialog Dividenden zahlen können“. Mehr als hundert Experten haben im Jahr 2017 ein offenes Schreiben unterzeichnet, in dem die Vereinten Nationen aufgefordert werden, sich mit der Frage der tödlichen autonomen Waffen zu befassen; aber auf einer Tagung des UN-Übereinkommens über bestimmte Waffen (CCW) im November 2017 konnten die Diplomaten sich nicht auf die Definition dieser Waffen einigen. Der indische Botschafter und der Vorsitzende der CCW gaben an, dass eine Einigung über Regeln nach wie vor eine weite Perspektive darstellt. Seit 2017 haben zwanzigundzwanzig Länder ein vollständiges Verbot der tödlichen autonomen Waffen gefordert. Viele Experten glauben, dass Versuche, tödliche Roboter vollständig zu verbieten, wahrscheinlich scheitern. Laut einem Bericht von Harvard Belfer Center von 2017 ist die AI das Potenzial, als Kernwaffen zu verwandeln. In dem Bericht wird ferner argumentiert, dass "der erweiterte militärische Einsatz von AI wahrscheinlich unmöglich ist" und dass "das eher bescheidene Ziel eines sicheren und effizienten Technologiemanagements verfolgt werden muss", wie das Verbot des Übergangs von AI zu einem nuklearen Arsenal. Teil der Unpraktik ist, dass die Feststellung von Vertragsverletzungen äußerst schwierig wäre. Andere Reaktionen auf autonome WaffenA 2015 offenes Schreiben, in dem das Verbot der tödlichen automatischen Waffensysteme gefordert wird, wurden von zehntausenden Bürgerinnen und Bürgern unterzeichnet, darunter Wissenschaftler wie Physikaler Stephen Hawking, Tesla Magnat Elon Musk und Apples Steve Wozniak. Professor Noel Haiey der Universität Sheffield hat gewarnt, dass autonome Waffen unweigerlich in die Hände von terroristischen Gruppen wie dem Islamischen Staat fallen werden. Vereinigung Viele Western-Tech-Unternehmen sind unbesetzt, zu eng mit dem US-Militär verbunden zu sein, um den Zugang zum chinesischen Markt zu verlieren. Manche Forscher, wie DeepMind's Demis Hassabis, sind ideologisch gegen einen Beitrag zur militärischen Arbeit. Im Juni 2018 erklärten die Unternehmensquellen von Google, dass Top-Exekutiv Diane Greene den Mitarbeitern mitgeteilt hat, dass das Unternehmen nach Ablauf des aktuellen Vertrags im März 2019 keine Folgeprojekt Maven folgen würde. Lesen Sie auch die Magnete der künstlichen Intelligenz Kalt War Post-Cold War Ära der künstlichen allgemeinen Ethik der künstlichen IntelligenzCold WarSecond Kalten Krieg Space Race Nuclear Arms existierendes Risiko künstlicher allgemeiner Intelligenz globales Problem Lethal autonomer Waffe militärischer Roboter unmanned fight air Vehicle Referenzen Paul Scharre, "Killer Apps: Die Real Dangers of a AI Arms Rasse", vol. 98, no. 3(Mai/Juni 2019), pp.135–44 "Die heutigen AI-Technologien sind leistungsfähige, aber unzuverlässig. Regelnbasierte Systeme können sich nicht mit Umständen befassen, die ihre Programmteilnehmer nicht vorhersagen. Lernsysteme sind durch die Daten beschränkt, auf die sie ausgebildet wurden. AI-Versagen haben bereits zu Tragödie geführt. Fortgeschrittene Autopilotfunktionen in Autos, obwohl diesddsy unter einigen Umständen gut funktioniert, haben Autos ohne Warnung in LKW, Betonschranken und Autos angetrieben. In der falschen Situation gehen AI-Systeme von Supersmart bis hin zu Superdumb in einer sofortigen Situation.Wenn ein Feind versucht, ein AI-System zu manipulieren und zu ersticken, sind die Risiken noch größer. (p. 140.) Die Nationale Sicherheitskommission für künstliche Intelligenz (2019). Zwischenbericht. Washington, DC: Autor.