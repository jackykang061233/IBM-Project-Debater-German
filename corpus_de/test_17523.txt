Eine Gehirn-Computer-Schnittstelle (BCI), die manchmal als neurale Steuerschnittstelle (NCI,) Geist-Maschine-Schnittstelle (MMI,) direkte neurale Schnittstelle (DNI,) oder Gehirn-Maschine-Schnittstelle (BMI) bezeichnet wird, ist ein direkter Kommunikationspfad zwischen einem erweiterten oder verdrahteten Gehirn und einem externen Gerät. BCIs sind oft auf die Erforschung, Kartierung, Assistenz, Augmentierung oder Reparatur von menschlichen kognitiven oder sensorisch-motorischen Funktionen gerichtet. Die BCI-Forschung begann in den 1970er Jahren an der University of California, Los Angeles (UCLA) unter einem Stipendium der National Science Foundation, gefolgt von einem Vertrag von DARPA. Die nach dieser Forschung veröffentlichten Papiere zeichnen auch den ersten Auftritt der Expression Gehirn-Computer-Schnittstelle in der wissenschaftlichen Literatur. Durch die kortikale Plastizität des Gehirns können Signale von implantierten Prothesen nach der Anpassung vom Gehirn wie natürliche Sensor- oder Effektorkanäle behandelt werden. Nach jahrelanger Tierexperimentation erschien Mitte der 1990er Jahre die ersten im Menschen implantierten Neuroprothesen. In jüngster Zeit haben Studien in der Mensch-Computer-Interaktion über die Anwendung von maschinellem Lernen auf statistische zeitliche Merkmale, die aus den frontalen Daten (EEG-Gehirnwellen) extrahiert wurden, hohe Erfolge bei der Klassifizierung von mentalen Zuständen (Relaxed, Neutral, Konzentration) geistiger emotionaler Zustände (Negative, Neutral, Positive) und thalamocortical dysrhythmia. Geschichte Die Geschichte der Gehirn-Computer-Schnittstellen (BCIs) beginnt mit Hans Bergers Entdeckung der elektrischen Aktivität des menschlichen Gehirns und der Entwicklung der Elektroenzephalographie (EEG). Im Jahr 1924 war Berger der erste, der die menschliche Gehirnaktivität mittels EEG aufzeichnen konnte. Berger konnte die oszillatorische Aktivität wie Bergers Welle oder die Alphawelle (8–13 Hz) durch Analyse von EEG-Tracks identifizieren. Bergers erstes Aufnahmegerät war sehr rudimentär. Er setzte Silberdrähte unter die Kopfhaut seiner Patienten ein. Diese wurden später durch am Kopf des Patienten angebrachte Silberfolien durch Gummibänder ersetzt. Berger verbindet diese Sensoren mit einem Lippmann Kapillarelektrometer mit enttäuschenden Ergebnissen. Jedoch führten anspruchsvollere Messgeräte, wie das Siemens Doppelspulen-Aufzeichnungsgalvanometer, das elektrische Spannungen so klein wie ein Zehntausendstel Volt zeigte, zu Erfolg. Berger analysierte die Zusammenhänge von Veränderungen in seinen EEG-Wellendiagrammen mit Hirnerkrankungen. EEGs erlaubte völlig neue Möglichkeiten für die Forschung von menschlichen Gehirnaktivitäten. Obwohl der Begriff noch nicht geprägt war, war eines der frühesten Beispiele einer funktionierenden Gehirn-Maschine-Schnittstelle das Stück Music for Solo Performer (1965) des amerikanischen Komponisten Alvin Lucier. Das Stück nutzt EEG und analoge Signalverarbeitungshardware (Filter, Verstärker und eine Mischplatine), um akustische Schlaginstrumente zu stimulieren. Um das Stück durchzuführen, muss man Alphawellen erzeugen und damit die verschiedenen Schlaginstrumente über Lautsprecher abspielen, die nahe oder direkt auf die Instrumente selbst platziert werden. UCLA Professor Jacques Vidal prägte den Begriff BCI und produzierte die ersten peer-reviewed Publikationen zu diesem Thema. Vidal ist weithin als Erfinder von BCIs in der BCI-Gemeinschaft anerkannt, wie sich in zahlreichen peer-reviewed Artikeln, die das Feld überprüfen und diskutieren (z.B.,). Seine 1973 erschienene Zeitung erklärte die "BCI Challenge:" Kontrolle externer Objekte mit EEG-Signalen. Besonders betonte er, dass Contingent Negative Variation (CNV) Potenzial als Herausforderung für die BCI-Kontrolle. Das 1977 beschriebene Experiment Vidal war die erste Anwendung von BCI nach seiner BCI-Herausforderung von 1973. Es war eine nichtinvasive EEG (in der Tat Visual Evoked Potentials (VEP) Steuerung eines Cursor-ähnlichen grafischen Objekts auf einem Computerbildschirm. Die Demonstration war Bewegung in einem Labyrinth. Nach seinen frühen Beiträgen war Vidal nicht in der BCI-Forschung aktiv, noch BCI-Veranstaltungen wie Konferenzen, für viele Jahre. 2011 hielt er jedoch in Graz, Österreich, einen Vortrag, unterstützt vom Future BNCI-Projekt, der das erste BCI präsentierte, das eine stehende Ovation verdiente. Vidal wurde von seiner Frau Laryce Vidal begleitet, die zuvor an seinem ersten BCI-Projekt bei der UCLA arbeitete. 1988 wurde ein Bericht über die nichtinvasive EEG-Steuerung eines physikalischen Objekts, eines Roboters, vorgelegt. Das beschriebene Experiment war die EEG-Steuerung des Mehrfachstarts der Roboterbewegung entlang einer beliebigen Trajektorie, die durch eine auf einem Boden gezogene Linie definiert ist. Das Linienfolgeverhalten war das Standard-Roboterverhalten, das autonome Intelligenz und autonome Energiequelle nutzte. Dieser 1988 von Stevo Bozinovski, Mihail Sestakov und Liljana Bozinovska geschriebene Bericht war der erste über eine Robotersteuerung mit EEG. 1990 wurde ein Bericht über eine geschlossene Schleife, bidirektionale adaptive BCI Controlling Computer Summer durch ein anticipatory Gehirn Potential, das Contingent Negative Variation (CNV) Potential gegeben.Das Experiment beschreibt, wie ein von CNV manifestierter Erwartungszustand des Gehirns den S2-Buzzer im S1-S2-CNV-Paradigm in einer Rückkopplungsschleife steuert. Die gewonnene kognitive Welle, die das Erwartungslernen im Gehirn darstellt, wird als Elektroexpectogramm (EXG) bezeichnet. Das CNV-Gehirnpotenzial war Teil der BCI-Herausforderung, die Vidal in seinem 1973 erschienenen Papier präsentierte. Studien in 2010s schlugen die potenzielle Fähigkeit der Neuralstimulation vor, funktionell vernetzte und damit verbundene Verhaltensweisen durch Modulation molekularer Mechanismen der synaptischen Wirksamkeit wiederherzustellen. Dies öffnete die Tür für das Konzept, dass BCI-Technologien die Funktion neben der Funktionalität wiederherzustellen. Seit 2013 fördert DARPA die BCI-Technologie durch die BRAIN-Initiative, die u.a. die Arbeit der Universität Pittsburgh Medical Center, Paradromics, Brown und Synchron unterstützt. BCIs versus neuroprosthetics Neuroprosthetics ist ein Bereich der Neurowissenschaften mit neuronalen Prothesen, d.h. mit künstlichen Geräten, um die Funktion von gestörten Nervensystemen und Hirnproblemen zu ersetzen, oder von sensorischen Organen oder Organen selbst (Bladder, Membran, etc.). Seit Dezember 2010 wurden Cochlea-Implantate in rund 220.000 Menschen weltweit als neuroprothetisches Gerät implantiert. Es gibt auch mehrere neuroprothetische Geräte, die darauf abzielen, die Vision wiederherzustellen, einschließlich retinale Implantate. Das erste neuroprothetische Gerät war jedoch der Schrittmacher. Die Begriffe werden manchmal austauschbar verwendet. Neuroprothetik und BCIs versuchen, dieselben Ziele zu erreichen, wie die Wiederherstellung von Sehvermögen, Hörvermögen, Bewegung, Kommunikationsfähigkeit und sogar kognitive Funktion. Beide verwenden ähnliche experimentelle Methoden und chirurgische Techniken. Tier BCI-Forschung Mehrere Laboratorien haben es geschafft, Signale von Affen- und Rattenzerebralen Kortiken zu erfassen, um BCIs zu betreiben, um Bewegung zu erzeugen. Affen haben navigierte Computer-Cursors auf dem Bildschirm und befiehlte Roboterarme, um einfache Aufgaben zu erfüllen, indem sie einfach über die Aufgabe nachdenken und das visuelle Feedback sehen, aber ohne Motorleistung. Im Mai 2008 wurden in einer Reihe bekannter Fachzeitschriften und Zeitschriften Fotografien veröffentlicht, die einen Affen an der University of Pittsburgh Medical Center gezeigt haben, der einen Roboterarm durch Denken betreibt. Auch Schafe wurden verwendet, um BCI-Technologie zu bewerten, einschließlich Synchrons Stentrode. Im Jahr 2020 wurde Elon Musk's Neuralink erfolgreich in einem Schwein implantiert, das in einem angesehenen Webcast bekannt gegeben wurde. In 2021 Elon Musk gab bekannt, dass er einen Affen erfolgreich ermöglicht hatte, Videospiele mit Neuralinks Gerät zu spielen. Früharbeit 1969 zeigten die opernierenden Konditionierungsstudien von Fetz und Kollegen, am Regional Primate Research Center und Department of Physiology and Biophysics, University of Washington School of Medicine in Seattle, erstmals, dass Affen lernen konnten, die Ablenkung eines Biofeedback-Meterarms mit neuronaler Aktivität zu steuern. Ähnliche Arbeiten in den 1970er Jahren stellten fest, dass Affen schnell lernen konnten, die Brennraten einzelner und mehrerer Neuronen im Primärmotorkortex freiwillig zu kontrollieren, wenn sie für die Erzeugung geeigneter Muster von neuronaler Aktivität belohnt wurden. Studien, die Algorithmen entwickelt haben, um Bewegungen von Motorkortex-Neuronen rekonstruieren, die die Bewegung kontrollieren, stammen aus den 1970er Jahren. In den 1980er Jahren fand Apostolos Georgopoulos an der Johns Hopkins Universität eine mathematische Beziehung zwischen den elektrischen Reaktionen einzelner Motorkortex-Neuronen in Rhesus-Affen und der Richtung, in der sie ihre Arme bewegten (basierend auf einer Kosinusfunktion). Er fand auch, dass dispergierte Gruppen von Neuronen, in verschiedenen Bereichen des Affenhirns, kollektiv gesteuerte Motorbefehle, aber in der Lage war, die Schüsse von Neuronen in nur einem Bereich zu einer Zeit, wegen der technischen Einschränkungen durch seine Ausrüstung. Seit Mitte der 1990er Jahre hat sich die BCI rasch entwickelt. Mehrere Gruppen konnten komplexe Hirnmotor-Kortex-Signale durch Aufnahme von neuronalen Ensembles (Gruppen von Neuronen) erfassen und diese zur Steuerung externer Geräte verwenden. Prominente Forschungserfolge Kennedy und Yang Dan Phillip Kennedy (die später 1987 Neural Signale gründeten) und Kollegen bauten die erste intrakortikale Gehirn-Computer-Schnittstelle durch Implantation neurotrophischer Konuselektroden in Affen. 1999 entschlüsselten Forscher Yang Dan an der University of California, Berkeley entschlüsselte neuronale Schüsse, um Bilder von Katzen zu reproduzieren. Das Team nutzte eine Reihe von Elektroden, die in den Thalamus eingebettet sind (die den gesamten sensorischen Input des Gehirns integriert) von scharfäugigen Katzen.Forscher richteten 177 Gehirnzellen im thalamus lateralen Genikula-Kernbereich an, der Signale von der Netzhaut dekodiert. Die Katzen wurden acht Kurzfilme gezeigt und ihre Neuronfeuer wurden aufgezeichnet. Mit mathematischen Filtern decodierten die Forscher die Signale, um Filme zu erzeugen, von denen die Katzen sahen und in der Lage waren, erkennbare Szenen und bewegte Objekte zu rekonstruieren. Ähnliche Ergebnisse beim Menschen wurden seitdem von Forschern in Japan erreicht (siehe unten). Nicolelis Miguel Nicolelis, Professor an der Duke University, in Durham, North Carolina, war ein prominenter Vertreter der Verwendung mehrerer Elektroden, die über einen größeren Bereich des Gehirns verteilt wurden, um neuronale Signale zu erhalten, um eine BCI zu fahren. Nach anfänglichen Rattenstudien in den 1990er Jahren entwickelten Nicolelis und seine Kollegen BCIs, die die Gehirnaktivität in Eulenaffen decodierten und die Geräte zur Reproduktion von Affenbewegungen in Roboterarmen nutzten. Affen haben fortgeschrittenes Erreichen und Greifen Fähigkeiten und gute Handmanipulation Fähigkeiten, so dass sie ideale Testobjekte für diese Art von Arbeit. Im Jahr 2000 gelang es der Gruppe, eine BCI zu bauen, die Eulenaffenbewegungen reproduzierte, während der Affe einen Joystick betrieben oder zum Essen gelangte. Das BCI arbeitet in Echtzeit und könnte auch einen separaten Roboter ferngesteuert über das Internet-Protokoll steuern. Aber die Affen konnten den Arm nicht bewegen sehen und erhielten kein Feedback, ein sogenannter Open-Loop BCI. Spätere Experimente von Nicolelis mit Rhesusaffen gelang es, die Rückkopplungsschleife zu schließen und Affen zu erreichen und Bewegungen in einem Roboterarm zu erfassen. Rhesusaffen werden mit ihren tiefen Hintern und gefurchten Gehirnen als bessere Modelle für die menschliche Neurophysiologie betrachtet als Eulenaffen. Die Affen wurden ausgebildet, um Objekte auf einem Computerbildschirm zu erreichen und zu erfassen, indem sie einen Joystick manipulieren, während entsprechende Bewegungen durch einen Roboterarm versteckt wurden. Die Affen wurden später dem Roboter direkt gezeigt und erlernt, ihn zu kontrollieren, indem er seine Bewegungen betrachtete. Die BCI nutzte Geschwindigkeitsvorhersage, um die Erreichen von Bewegungen zu steuern und gleichzeitig vorhergesagte Handgreifkraft. 2011 zeigten O'Doherty und Kollegen eine BCI mit sensorischen Rückmeldungen mit Rhesusaffen. Der Affe steuerte die Position eines Avatararms während er sensorische Rückmeldungen durch direkte intrakortikale Stimulation (ICMS) im Armrepräsentationsbereich des sensorischen Kortex erhielt. Donoghue, Schwartz und Andersen Weitere Labore, die BCIs und Algorithmen entwickelt haben, die Neuronsignale entschlüsseln, sind das Carney Institute for Brain Science an der Brown University und die Labore von Andrew Schwartz an der Universität Pittsburgh und Richard Andersen an der Caltech. Diese Forscher konnten arbeitende BCIs produzieren, auch mit aufgezeichneten Signalen von weit weniger Neuronen als Nicolelis (15–30 Neuronen gegen 50–200 Neuronen). John Donoghues Labor am Carney Institute berichtete über die Ausbildung von Rhesus-Affen, um eine BCI zu verwenden, um visuelle Ziele auf einem Computerbildschirm (Closed-loop BCI) mit oder ohne Unterstützung eines Joysticks zu verfolgen. Schwartzs Gruppe hat ein BCI für dreidimensionales Tracking in der virtuellen Realität geschaffen und auch BCI-Steuerung in einem Roboterarm wiedergegeben. Die gleiche Gruppe schuf auch Schlagzeilen, als sie demonstrierten, dass ein Affe selbst Frucht- und Marschmallows mit einem Roboterarm, der von den eigenen Hirnsignalen des Tieres kontrolliert wird, füttern konnte. Andersens Gruppe verwendet Aufnahmen von Vorbeugungsaktivität aus der posterior parietalen Kortex in ihrem BCI, einschließlich Signale erstellt, wenn experimentelle Tiere erwartet eine Belohnung. Andere Forschung Neben der Vorhersage kinematischer und kinetischer Parameter von Gliedmaßenbewegungen werden BCIs entwickelt, die elektromyographische oder elektrische Aktivität der Muskeln von Primaten vorhersagen. Solche BCIs könnten verwendet werden, um die Mobilität in gelähmten Gliedern durch elektrisch anregende Muskeln wiederherzustellen. Miguel Nicolelis und Kollegen zeigten, dass die Aktivität großer neuraler Ensembles die Armposition vorhersagen kann. Diese Arbeit ermöglichte die Schaffung von BCIs, die die Absichten der Armbewegung lesen und in Bewegungen von künstlichen Aktoren übersetzen. Carmena und Kollegen programmierten die neurale Kodierung in einer BCI, die es einem Affen erlaubte, die Greifbewegungen durch einen Roboterarm zu kontrollieren. Lebedev und Kollegen argumentierten, dass Gehirnnetze reorganisieren, um eine neue Darstellung der robotischen Anhängung zusätzlich zur Darstellung der eigenen Gliedmaßen des Tieres zu schaffen. Im Jahr 2019 veröffentlichten Forscher von UCSF eine Studie, in der sie ein BCI demonstrierten, das das Potenzial hatte, Patienten mit Sprachstörungen durch neurologische Störungen zu helfen.Ihr BCI nutzte hochdichte Elektrokortikographie, um neuronale Aktivität aus dem Gehirn eines Patienten abzufangen und verwendete tiefe Lernmethoden zur Sprachsynthese. Im Jahr 2021 veröffentlichten Forscher derselben Gruppe eine Studie, die das Potenzial eines BCI zur Decodierung von Wörtern und Sätzen in einem anarthrischen Patienten zeigt, der seit über 15 Jahren nicht sprechen konnte. Die bisher größte Behinderung der BCI-Technologie ist die mangelnde Sensor-Modalität, die einen sicheren, präzisen und robusten Zugang zu Gehirnsignalen ermöglicht. Es ist jedoch denkbar oder sogar wahrscheinlich, dass ein solcher Sensor innerhalb der nächsten zwanzig Jahre entwickelt wird. Die Verwendung eines solchen Sensors sollte den Bereich der Kommunikationsfunktionen, die mit einem BCI bereitgestellt werden können, stark erweitern. Die Entwicklung und Implementierung eines BCI-Systems ist komplex und zeitaufwendig. Als Antwort auf dieses Problem hat Gerwin Schalk ein allgemeines Nutzungssystem für die BCI-Forschung entwickelt, genannt BCI2000. BCI2000 ist seit 2000 in einem Projekt unter der Leitung des Brain-Computer Interface R&D-Programms im Wadsworth Center des New York State Department of Health in Albany, New York, USA entwickelt worden. Ein neuer kabelloser Ansatz verwendet lichtvernetzte Ionenkanäle wie Channelrhodopsin, um die Aktivität genetisch definierter Teilmengen von Neuronen in vivo zu kontrollieren. Im Rahmen einer einfachen Lernaufgabe beeinflusste die Beleuchtung von transfizierten Zellen im somatosensorischen Kortex die Entscheidungsfindung von frei bewegenden Mäusen. Die Verwendung von BMIs hat auch zu einem tieferen Verständnis von neuronalen Netzwerken und dem zentralen Nervensystem geführt. Die Forschung hat gezeigt, dass trotz der Neigung der Neurowissenschaftler zu glauben, dass Neuronen die meisten Wirkung haben, wenn sie zusammenarbeiten, einzelne Neuronen durch die Verwendung von BMIs zu feuern auf einem Muster, das Primaten zu steuern Motorleistungen erlaubt. Die Verwendung von BMIs hat zur Entwicklung des einzigen Neuron-Insuffizienz-Prinzips geführt, das besagt, dass auch bei einer gut abgestimmten Brennrate einzelne Neuronen nur eine geringe Menge an Informationen tragen können und somit die höchste Genauigkeit durch Aufnahme von Schüssen des Kollektivens erreicht wird. Andere Prinzipien, die mit der Verwendung von BMIs entdeckt werden, sind das neuronale Multitasking-Prinzip, das neuronale Massenprinzip, das neuronale Degeneracy-Prinzip und das Plastizitätsprinzip. BCIs werden auch von Nutzern ohne Behinderungen angewendet. Eine nutzerzentrierte Kategorisierung von BCI-Ansätzen von Thorsten O. Zander und Christian Kothe führt den Begriff passive BCI ein. Neben aktiven und reaktiven BCI, die zur gezielten Steuerung verwendet werden, ermöglichen passive BCIs die Bewertung und Interpretation von Veränderungen im Benutzerzustand während der Mensch-Computer-Interaktion (HCI). In einer sekundären, impliziten Regelschleife passt sich das Computersystem seinem Benutzer an, was seine Bedienbarkeit im Allgemeinen verbessert. Neben BCI-Systemen, die neuronale Aktivität zum Antrieb externer Effektoren decodieren, können BCI-Systeme verwendet werden, um Signale von der Peripherie zu kodieren. Diese sensorischen BCI-Geräte ermöglichen Echtzeit-, verhaltensrelevante Entscheidungen auf Basis geschlossener neuronaler Stimulation. Der BCI AwardDer jährliche BCI Research Award wird in Anerkennung herausragender und innovativer Forschung im Bereich der Brain-Computer Interfaces vergeben. Jedes Jahr wird ein renommiertes Forschungslabor gebeten, die eingereichten Projekte zu beurteilen. Die Jury besteht aus weltweit führenden BCI-Experten, die vom Vergabelabor eingestellt wurden. Die Jury wählt zwölf Nominierten aus, wählt dann einen ersten, zweiten und dritten Platz Gewinner, der Preise von $ 3.000 $ 2.000 und $1.000 erhalten. Human BCI Forschung Invasive BCIs Invasive BCI erfordert eine Operation, um Elektroden unter Kopfhaut zu implantieren, um Gehirnsignale zu kommunizieren. Der Hauptvorteil besteht darin, eine genauere Lektüre zu gewährleisten; seine Unterseite enthält jedoch Nebenwirkungen von der Operation. Nach der Operation können Narbengewebe entstehen, die Gehirnsignale schwächer machen können. Darüber hinaus kann der Körper gemäß der Forschung von Abdulkader et al. (2015) die implantierten Elektroden nicht akzeptieren und dies kann einen medizinischen Zustand verursachen. Vision Invasive BCI-Forschung zielt darauf ab, beschädigte Sicht zu reparieren und bietet neue Funktionalität für Menschen mit Lähmung. Invasive BCIs werden während der Neurochirurgie direkt in die graue Materie des Gehirns implantiert. Da sie in der grauen Materie liegen, produzieren invasive Geräte die höchsten Qualitätssignale von BCI-Geräten, sind aber anfällig für Narbengewebeaufbau, wodurch das Signal schwächer oder gar nicht vorhanden wird, da der Körper auf ein fremdes Objekt im Gehirn reagiert. In der Vision-Wissenschaft wurden direkte Gehirnimplantate verwendet, um nicht-kongenitale (benötigte) Blindheit zu behandeln.Einer der ersten Wissenschaftler, die eine funktionierende Gehirnoberfläche zur Wiederherstellung der Sicht erzeugen, war Privatforscher William Dobelle. Dobelles erster Prototyp wurde 1978 in Jerry implantiert, ein Mann, der im Erwachsenenalter blind war. Auf Jerrys visuellen Kortex wurde eine einstrahlige BCI mit 68 Elektroden implantiert und es gelang Phosphene, das Empfinden des Sehens von Licht, herzustellen. Das System beinhaltete Kameras, die auf einer Brille montiert wurden, um Signale an das Implantat zu senden. Ursprünglich erlaubte das Implantat Jerry, Grautöne in einem begrenzten Sichtfeld bei einem niedrigen Rahmen zu sehen. Dies erforderte auch, dass er an einen Mainframe-Computer angeschlossen werden, aber schrumpfende Elektronik und schnellere Computer machten sein künstliches Auge tragbarer und ermöglichte es ihm jetzt, einfache Aufgaben nicht unterstützt. Im Jahr 2002 wurde Jens Naumann, auch im Erwachsenenalter verblendet, der erste in einer Reihe von 16 zahlenden Patienten, um Dobelles Implantat der zweiten Generation zu erhalten, und markierte eine der frühesten kommerziellen Verwendungen von BCIs. Das zweite Generationsgerät verwendet ein ausgefeilteres Implantat, das eine bessere Kartierung von Phosphenen in kohärente Vision ermöglicht. Phosphene verbreiten sich über das visuelle Feld in dem, was Forscher "die Sternen-Nacht-Effekt" nennen. Unmittelbar nach seinem Implantat konnte Jens seine unvollkommen restaurierte Vision nutzen, um ein Auto langsam um den Parkplatz des Forschungsinstituts zu fahren. Leider starb Dobelle 2004, bevor seine Prozesse und Entwicklungen dokumentiert wurden. Anschließend, als Mr. Naumann und die anderen Patienten im Programm Probleme mit ihrer Vision hatten, gab es keine Erleichterung und sie verloren schließlich wieder ihren Blick. Naumann schrieb über seine Erfahrung mit Dobelle's Arbeit in Search for Paradise: A Patient's Account of the Artificial Vision Experiment und ist zurück in seinen Bauernhof in Southeast Ontario, Kanada, um seine normalen Aktivitäten wieder aufzunehmen. Die Bewegung BCIs, die sich auf die Neuroprothetik des Motors konzentriert, zielt darauf ab, entweder die Bewegung in Menschen mit Lähmung wiederherzustellen oder Geräte bereitzustellen, die sie unterstützen, wie Schnittstellen mit Computern oder Roboterarmen. Forscher der Emory University in Atlanta, unter der Leitung von Philip Kennedy und Roy Bakay, wurden zunächst ein Gehirnimplantat in einem Menschen installiert, der Signale von hoher Qualität erzeugte, um Bewegung zu simulieren. Ihr Patient, Johnny Ray (1944–2002), erlitt nach einem Hirnstammschlag im Jahr 1997 unter einem "verriegelten Syndrom". Rays Implantat wurde 1998 installiert und er lebte lange genug, um mit dem Implantat zu arbeiten, schließlich zu lernen, einen Computer-Cursor zu steuern; er starb 2002 eines Gehirn-Aneurysmus. Tetrapleg Matt Nagle wurde die erste Person, die eine künstliche Hand mit einem BCI im Jahr 2005 im Rahmen der ersten neunmonatigen humanen Studie von Cyberkinetics's BrainGate Chip-Implantation kontrollierte. Implantiert in Nagles rechtem vorzentralem Gyrus (Bereich des Motorkortex für Armbewegung), erlaubte das 96-Elektrode-BrainGate-Implantat Nagle, einen Roboterarm zu steuern, indem es über die Bewegung seiner Hand sowie einen Computer-Cursor, Lichter und TV nachdenkt. Ein Jahr später erhielt Professor Jonathan Wolpaw den Preis der Altran Foundation for Innovation, um eine Gehirn-Computer-Schnittstelle mit Elektroden auf der Oberfläche des Schädels zu entwickeln, anstatt direkt im Gehirn. Vor kurzem haben Forscherteams der BrainGate-Gruppe an der Brown University und einer Gruppe unter der Leitung von University of Pittsburgh Medical Center, beide in Zusammenarbeit mit der United States Department of Veterans Affairs, weitere Erfolge bei der direkten Kontrolle von roboterprothetischen Gliedmaßen mit vielen Freiheitsgraden unter Verwendung von direkten Verbindungen zu Neuronen in der Motorrinde von Patienten mit Tetraplegie gezeigt. Communication Im Mai 2021 berichtete ein Team der Stanford University einen erfolgreichen Nachweis-of-concept-Test, der es einem quadraplegischen Teilnehmer ermöglichte, englische Sätze auf etwa 86 Zeichen pro Minute einzugeben. Der Teilnehmer stellte sich vor, seine Hand in Schreibbriefe zu bewegen, und das System führte Handschrifterkennung auf im Motorkortex detektierten elektrischen Signalen durch. Ein im Juli 2021 veröffentlichter Bericht berichtete, dass ein gelähmter Patient 15 Wörter pro Minute mit einem Gehirnimplantat kommunizieren konnte, das Motorneuronen analysierte, die zuvor den Gesangstrakt kontrollierten. Teilinvasive BCIs Teilinvasive BCI-Geräte werden innerhalb des Schädels implantiert, liegen aber außerhalb des Gehirns und nicht innerhalb der grauen Materie. Sie erzeugen bessere Auflösungssignale als nicht-invasive BCIs, bei denen das Knochengewebe des craniums Signale ablenkt und verformt und ein geringeres Risiko für die Bildung von Narbengewebe im Gehirn als vollständig invasive BCIs hat.Es gab präklinische Demonstration von intrakortikalen BCIs aus dem Schlaganfall perilesional cortex. Interventionelle Neurologie Der größte Fortschritt bei teilweise invasiven BCIs entstand im Bereich der interventionellen Neurologie. Elon Musk erwähnte das Potenzial dafür 2016, verfolgte es aber nie. In der Zwischenzeit hatten 2010 mit der University of Melbourne verbundene Forscher eine BCI entwickelt, die über das Gefäßsystem eingefügt werden könnte. Der australische Neurologe Thomas Oxley (Mount Sinai Hospital) konzipierte die Idee für dieses BCI, genannt Stentrode und hat Finanzierung von DARPA erhalten. Präklinische Studien haben die Technik bei Schafen bewertet. Im November 2020 konnten zwei Teilnehmer, die an der amyotrophen lateralen Sklerose leiden, ein Betriebssystem drahtlos auf Text, E-Mail, Shop und Bank steuern, indem sie direkt durch die Gehirn-Computer-Schnittstelle Stentrode dachten, wobei erstmals eine Gehirn-Computer-Schnittstelle über die Blutgefäße des Patienten implantiert wurde, wodurch die Notwendigkeit offener Gehirnchirurgie beseitigt wurde. ECoG Elektrocorticography (ECoG) misst die elektrische Aktivität des unter dem Schädel genommenen Gehirns in ähnlicher Weise der nicht-invasiven Elektroenzephalographie, aber die Elektroden sind in einem dünnen Kunststoff-Pad eingebettet, der oberhalb des Kortex unter dem Dura Mater platziert ist. ECoG-Technologien wurden 2004 von Eric Leuthardt und Daniel Moran von der Washington University in St. Louis zum ersten Mal im Menschen promoviert. In einem späteren Versuch ermöglichten die Forscher einem Teenager-Junge, Space Invaders mit seinem ECoG-Implantat zu spielen. Diese Forschung zeigt, dass die Kontrolle schnell ist, minimales Training erfordert, und kann ein idealer Kompromiss in Bezug auf Signaltreue und Grad der Invasivität sein. Signale können subdural oder epidural sein, werden aber nicht innerhalb des Gehirnparenchymas selbst genommen. Sie wurde erst vor kurzem aufgrund des begrenzten Zugangs von Fächern nicht umfassend untersucht. Derzeit ist die einzige Möglichkeit, das Signal für die Studie zu erwerben, durch die Verwendung von Patienten, die eine invasive Überwachung zur Lokalisierung und Resektion eines epileptogenen Fokus erfordern. ECoG ist eine sehr vielversprechende intermediäre BCI-Modalität, da sie eine höhere räumliche Auflösung, ein besseres Signal-zu-Rausch-Verhältnis, einen größeren Frequenzbereich und weniger Trainingsanforderungen als hautaufgezeichnetes EEG hat und gleichzeitig geringere technische Schwierigkeiten, ein geringeres klinisches Risiko und wahrscheinlich eine höhere Langzeitstabilität als die intrakortikale Ein-Neuron-Aufzeichnung aufweist. Dieses Merkmalsprofil und der jüngste Nachweis des hohen Kontrollniveaus mit minimalen Trainingsanforderungen zeigen Potenziale für eine reale Weltanwendung für Menschen mit Behinderungen. Leicht reaktive Bildgebung BCI-Geräte befinden sich noch im Bereich der Theorie. Nicht-invasive BCIs Es gab auch Experimente bei Menschen mit nicht-invasiven Neuroimaging-Technologien als Schnittstellen. Die wesentliche Mehrheit der veröffentlichten BCI-Arbeit umfasst nichtinvasive EEG-basierte BCIs. Nichtinvasive EEG-basierte Technologien und Schnittstellen wurden für eine Vielzahl von Anwendungen eingesetzt. Obwohl EEG-basierte Schnittstellen einfach zu tragen sind und keine Operation erfordern, haben sie eine relativ schlechte räumliche Auflösung und können nicht effektiv höherfrequente Signale verwenden, weil der Schädel die von den Neuronen erzeugten elektromagnetischen Wellen dämpft, dispergiert und verschwimmt. EEG-basierte Schnittstellen erfordern auch einige Zeit und Mühe vor jeder Nutzungssitzung, während nicht-EEG-basierte, sowie invasive, keine Vorbenutzerausbildung erfordern. Insgesamt hängt die beste BCI für jeden Anwender von zahlreichen Faktoren ab. Nicht-EEG-basierte Mensch-Computer-Schnittstelle Elektrookulographie (EOG) 1989 wurde über die Steuerung eines mobilen Roboters durch Augenbewegung mittels Elektrookulographie (EOG)-Signale berichtet. Ein mobiler Roboter wurde von einem Start zu einem Zielpunkt mit fünf EOG-Befehlen angetrieben, wie vorwärts, rückwärts, links, rechts und stoppen. Die EOG als Herausforderung, externe Objekte zu kontrollieren, wurde von Vidal in seinem Papier von 1973 vorgestellt. Ein Artikel von 2016 beschreibt ein völlig neues Kommunikationsgerät und eine nicht-eEG-basierte Mensch-Computer-Schnittstelle, die keine visuelle Fixierung erfordert, oder die Fähigkeit, die Augen überhaupt zu bewegen. Die Schnittstelle basiert auf verdecktem Interesse, indem man die Aufmerksamkeit auf einen ausgewählten Buchstaben auf einer virtuellen Tastatur richtet, ohne dass man die Augen bewegen muss, um direkt auf den Buchstaben zu schauen. Jeder Brief hat einen eigenen (Hintergrund-)Kreis, der in der Helligkeit anders als alle anderen Buchstaben schwingt. Die Briefauswahl basiert auf der besten Passform zwischen unbeabsichtigter Pupillen-Größe-Schwingung und dem Helligkeitsschwingungsmuster des Hintergrundkreises.Die Genauigkeit wird zusätzlich durch die mentale Probenahme der Wörter hell und dunkel, synchron zu den Helligkeitsübergängen des Briefkreises verbessert. Funktionelle Nahinfrarotspektroskopie 2014 und 2017 konnte ein BCI mit funktioneller Nah-Infrarot-Spektroskopie für eingesperrte Patienten mit amyotropher lateraler Sklerose (ALS) einige grundlegende Fähigkeit der Patienten wiederherzustellen, mit anderen Menschen zu kommunizieren. Elektroenzephalographie (EEG)-basierte Hirncomputer-Schnittstellen Nach Angaben der BCI-Herausforderung von Vidal im Jahr 1973 enthielten die ersten Berichte über nicht-invasives Vorgehen die Kontrolle eines Cursors in 2D mit VEP (Vidal 1977,) Steuerung eines Summers mit CNV (Bozinovska et al. 1988, 1990,) Steuerung eines physikalischen Objekts, eines Roboters unter Verwendung eines Hirnrhythmus alpha) (Bozinovski et al. 1988,) Steuerung eines auf einem Bildschirm geschriebenen mit Pwell (F300). In den frühen Tagen der BCI-Forschung war eine weitere wesentliche Barriere für die Verwendung von Elektroencephalographie (EEG) als Gehirn-Computer-Schnittstelle die umfangreiche Schulung erforderlich, bevor Anwender die Technologie arbeiten können. So trainierte Niels Birbaumer in Experimenten ab Mitte der 1990er Jahre an der Universität Tübingen in Deutschland stark gelähmte Menschen, die langsamen kortikalen Potentiale in ihrem EEG so weit selbst zu regulieren, dass diese Signale als binäres Signal zur Steuerung eines Computerkursors verwendet werden könnten. ( Birbaumer hatte früher ausgebildete Epileptik, um drohende Passungen durch Steuerung dieser Niederspannungswelle zu verhindern.) Das Experiment sah zehn Patienten ausgebildet, um einen Computer-Cursor zu bewegen, indem sie ihre Gehirnwellen steuern. Der Prozess war langsam, erforderte mehr als eine Stunde für Patienten zu schreiben 100 Zeichen mit dem Cursor, während Training oft viele Monate dauerte. Allerdings wurde der langsame kortikale Potenzialansatz für BCIs in einigen Jahren nicht genutzt, da andere Ansätze wenig oder keine Ausbildung erfordern, schneller und genauer sind und für einen größeren Anteil der Nutzer arbeiten. Ein weiterer Forschungsparameter ist die Art der oszillatorischen Aktivität, die gemessen wird. Gert Pfurtscheller gründete das BCI Lab 1991 und leitete seine Forschungsergebnisse auf der Motoren-Image in der ersten Online-BCI basierend auf oszillatorischen Features und Klassifikatoren. Gemeinsam mit Birbaumer und Jonathan Wolpaw an der New York State University konzentrierten sie sich auf die Entwicklung von Technologie, die es Benutzern ermöglichen würde, die Gehirnsignale zu wählen, die sie am einfachsten fanden, um eine BCI zu betreiben, einschließlich Schlamm- und Beta-Rhythmen. Ein weiterer Parameter ist die Methode der Rückkopplung, die in Untersuchungen von P300-Signalen gezeigt wird. Muster von P300-Wellen werden unfreiwillig (stimulus-feedback) generiert, wenn Menschen etwas sehen, das sie erkennen und BCIs erlauben, Kategorien von Gedanken zu entschlüsseln, ohne zuerst Patienten zu trainieren. Die oben beschriebenen Biofeedback-Methoden erfordern dagegen das Erlernen von Hirnwellen, so dass die resultierende Gehirnaktivität nachgewiesen werden kann. Im Jahr 2005 wurde er über die EEG-Emulation digitaler Regelkreise für BCI berichtet, mit Beispiel eines CNV-Flip-Flops. 2009 wurde mit einem CNV-Flip-Flop eine nichtinvasive EEG-Steuerung eines Roboterarms gemeldet. Im Jahr 2011 wurde die Kontrolle von zwei Roboterarmen lösen Tower of Hanoi Aufgabe mit drei Festplatten mit einem CNV-Flip-Flop berichtet. 2015 wurde die EEG-Emulation eines Schmidt-Triggers, Flip-Flops, Demultiplexer und Modems beschrieben. Während eine EEG-basierte Gehirn-Computer-Schnittstelle von einer Reihe von Forschungslabors umfassend verfolgt wurde, schlagen jüngste Fortschritte von Bin He und seinem Team an der Universität von Minnesota das Potenzial einer EEG-basierten Gehirn-Computer-Schnittstelle vor, um Aufgaben in der Nähe der invasiven Gehirn-Computer-Schnittstelle zu erfüllen. Mit fortschrittlichen funktionellen Neuroimaging einschließlich BOLD funktionellen MRT und EEG-Quellenbildgebung identifizierten Bin He und Mitarbeiter die Kovariation und Co-Lokalisation elektrophysiologischer und hämodynamischer Signale, die durch Motor-Imagination induziert wurden. Von einem neuroimaging-Ansatz und einem Trainingsprotokoll verwiesen Bin He und Mitarbeiter die Fähigkeit einer nicht-invasiven EEG-basierten Gehirn-Computer-Schnittstelle, den Flug eines virtuellen Hubschraubers in 3-dimensionalem Raum, basierend auf Motor-Imagination, zu steuern. Im Juni 2013 wurde bekannt gegeben, dass Bin He die Technik entwickelt hatte, um einen Fernsteuerungshubschrauber durch einen Hindernislauf zu führen. Neben einer auf Hirnwellen basierenden Hirncomputer-Schnittstelle, wie sie von Kopfhaut-EEG-Elektroden aufgezeichnet wurde, erforschten Bin He und Mitarbeiter eine virtuelle EEG-Signal-basierte Gehirn-Computer-Schnittstelle, indem sie das EEG-Inverse-Problem zunächst lösten und anschließend das resultierende virtuelle EEG für Hirn-Computer-Schnittstellenaufgaben nutzten.Gut kontrollierte Studien schlugen die Vorteile einer solchen Source-Analyse basierten Gehirn-Computer-Schnittstelle vor. Eine Studie aus dem Jahr 2014 ergab, dass schwer motorisch beeinträchtigte Patienten schneller und zuverlässiger mit nicht-invasivem EEG BCI kommunizieren konnten als mit jedem muskelbasierten Kommunikationskanal. Eine 2016 Studie ergab, dass das Emotiv EPOC-Gerät für Steuerungsaufgaben mit der Aufmerksamkeits-/Meditationsebene oder der Augenblinkung besser geeignet sein kann als das Neurosky MindWave-Gerät. Eine Studie von 2019 ergab, dass die Anwendung von evolutionären Algorithmen die EEG-State-Klassifikation mit einem nicht-invasiven Muse-Gerät verbessern konnte, wodurch eine hochwertige Klassifizierung von Daten ermöglicht wird, die von einem billigen EEG-Sensorgerät der Verbraucherklasse erfasst werden. Trockene aktive Elektrodenanordnungen In den frühen 1990er-Jahren zeigte Babak Taheri, an der University of California, Davis die ersten Single- und auch Mehrkanal-Trocken-Aktivelektroden-Arrays mit Mikrobearbeitung. Die Einkanal-Trocken-EEG-Elektrodenkonstruktion und Ergebnisse wurden 1994 veröffentlicht. Die Arrayed-Elektrode zeigte sich auch im Vergleich zu Silber/Silberchlorid-Elektroden gut. Das Gerät bestand aus vier Standorten von Sensoren mit integrierter Elektronik, um Geräusche durch Impedanzanpassung zu reduzieren. Die Vorteile solcher Elektroden sind: (1) kein Elektrolyt verwendet, (2) keine Hautaufbereitung, (3) deutlich reduzierte Sensorgröße und (4) Kompatibilität mit EEG-Überwachungssystemen. Das aktive Elektrodenarray ist ein integriertes System aus einer Reihe von kapazitiven Sensoren mit lokalen integrierten Schaltkreisen, die in einem Paket mit Batterien untergebracht sind, um die Schaltung zu betreiben. Dieser Integrationsgrad war erforderlich, um die von der Elektrode erhaltene Funktionsleistung zu erreichen. Die Elektrode wurde an einer elektrischen Prüfbank und an Menschen in vier Modalitäten der EEG-Aktivität getestet, nämlich: (1) spontane EEG, (2) sensorische ereignisbezogene Potentiale, (3) Hirnstammpotentiale und (4) kognitive ereignisbezogene Potentiale. Die Leistung der Trockenelektrode im Vergleich zu den Standard-Naßelektroden in Bezug auf die Hautpräparation, keine Gelanforderungen (trocken) und ein höheres Signal-Rausch-Verhältnis. 1999 nutzten Forscher der Case Western Reserve University, in Cleveland, Ohio, unter der Leitung von Hunter Peckham, 64-Elektrode EEG-Skullcap, um begrenzte Handbewegungen auf quadriplegic Jim Jatich zurückzugeben. Da Jatich sich auf einfache, aber entgegengesetzte Konzepte wie Up und Down konzentrierte, wurde sein Beta-Rhythmus-EEG-Ausgang mit Software analysiert, um Muster im Rauschen zu identifizieren. Ein Grundmuster wurde identifiziert und verwendet, um einen Schalter zu steuern: Überdurchschnittliche Aktivität wurde eingestellt, unter dem Durchschnitt ab. Neben der Möglichkeit, Jatich einen Computer-Cursor zu steuern, wurden die Signale auch verwendet, um die Nerven-Controller in seine Hände eingebettet zu fahren, eine Bewegung wiederherzustellen. SSVEP mobile EEG BCIsIn 2009 wurde das NCTU Brain-Computer-Interface-Kopfband gemeldet. Die Forscher, die dieses BCI-Kopfband entwickelt haben, entwickelten auch mikroelektromechanisches System auf Siliziumbasis (MEMS) trockene Elektroden für die Anwendung in nicht-haarigen Stellen des Körpers. Diese Elektroden wurden an der DAQ-Platte im Kopfband mit Schnappelektrodenhaltern befestigt. Das Signalverarbeitungsmodul gemessen Alpha-Aktivität und das Bluetooth-fähige Telefon bewerteten die Aufmerksamkeit und Kapazität der Patienten für die kognitive Leistung. Als das Thema drowsy wurde, schickte das Telefon das Feedback an den Bediener, um sie zu rösten. Diese Forschung wurde vom National Science Council, Taiwan, R.O.C, NSC, National Chiao-Tung University, Taiwans Ministerium für Bildung, und dem US Army Research Laboratory unterstützt. Im Jahr 2011 berichteten Forscher eine zelluläre BCI mit der Fähigkeit, EEG-Daten einzunehmen und in einen Befehl umzuwandeln, um das Telefon zum Ringen zu bringen. Diese Forschung wurde teilweise von Abraxis Bioscience LLP, dem US Army Research Laboratory und dem Army Research Office unterstützt. Die entwickelte Technologie war ein verschleißfähiges System bestehend aus einem vierkanaligen Bio-Signalerfassungs-/Verstärkeungsmodul, einem drahtlosen Übertragungsmodul und einem Bluetooth-fähigen Handy. Die Elektroden wurden so platziert, dass sie stationäre visuell evozierte Potentiale (SSVEP) aufnehmen. SSVEPs sind elektrische Reaktionen auf flackernde visuelle Reize mit Repetitionsraten über 6 Hz, die am besten in den parietalen und okzipitalen Kopfhautbereichen der visuellen Kortex zu finden sind. Es wurde berichtet, dass mit diesem BCI-Setup alle Studienteilnehmer in der Lage waren, den Anruf mit minimaler Praxis in natürlichen Umgebungen zu initiieren. Die Wissenschaftler behaupten, dass ihre Studien mit einem einzigen Kanal schnelle Fourier-Transformation (FFT) und mehrere Kanalsystem kanonische Korrelationsanalyse (CCA) Algorithmus unterstützen die Kapazität von mobilen BCIs.Der CCA-Algorithmus wurde in anderen Experimenten angewendet, die BCIs mit beanspruchter hoher Leistung in Genauigkeit sowie Geschwindigkeit untersuchen. Während die zelluläre BCI-Technologie entwickelt wurde, um einen Telefonanruf von SSVEPs zu initiieren, sagten die Forscher, dass sie für andere Anwendungen übersetzt werden kann, wie die Aufnahme von sensorimotorischen mu/beta-Rhythmen als motor-imagery-basierte BCI. Im Jahr 2013 wurden vergleichende Tests auf Android-Handy, Tablet und Computer basierten BCIs durchgeführt, die die Leistungsspektrumdichte der resultierenden EEG SSVEPs analysierten. Die genannten Ziele dieser Studie, die Wissenschaftler teils vom U.S. Army Research Laboratory unterstützten, waren, "die Praxisfähigkeit, Portabilität und Ubiquity eines SSVEP-basierten BCI für den täglichen Gebrauch zu erhöhen". Zitrusfrüchte Es wurde berichtet, dass die Stimulationsfrequenz auf allen Medien genau war, obwohl das Signal des Mobiltelefons eine gewisse Instabilität gezeigt hat. Die Amplituden der SSVEPs für Laptop und Tablet wurden auch als größer als die des Handys gemeldet. Diese beiden qualitativen Charakterisierungen wurden als Indikatoren für die Durchführbarkeit eines mobilen Reiz BCI vorgeschlagen. Einschränkungen Im Jahr 2011 erklärten die Forscher, dass weitere Arbeiten auf einfache Bedienung, Leistung Robustheit, reduzieren Hardware- und Softwarekosten. Eine der Schwierigkeiten mit EEG-Lesen ist die große Anfälligkeit für Bewegung Artefakte. In den meisten der zuvor beschriebenen Forschungsprojekte wurden die Teilnehmer gebeten, still zu sitzen, Kopf- und Augenbewegungen so weit wie möglich zu reduzieren und Messungen im Labor durchzuführen. Da jedoch die betonte Anwendung dieser Initiativen bei der Schaffung eines mobilen Geräts für den täglichen Gebrauch war, musste die Technologie in Bewegung getestet werden. Im Jahr 2013 haben Forscher die mobile EEG-basierte BCI-Technologie getestet und SSVEPs von Teilnehmern gemessen, als sie auf einem Laufband mit unterschiedlichen Geschwindigkeiten liefen. Diese Forschung wurde vom Büro für Marineforschung, Army Research Office und dem US Army Research Laboratory unterstützt. Es wurde festgestellt, dass die SSVEP-Erkennbarkeit mit CCA mit der Geschwindigkeitserhöhung verringert wurde. Da sich die unabhängige Komponentenanalyse (ICA) als effizient erwiesen hatte, EEG-Signale vom Rauschen zu trennen, extrahierten die Wissenschaftler ICA auf CCA EEG-Daten. Sie erklärten, die CCA-Daten mit und ohne ICA-Verarbeitung seien ähnlich. Sie kamen daher zu dem Schluss, dass CCA unabhängig eine Robustheit gegenüber Bewegungsartefakten demonstrierte, die darauf hindeutet, dass es sich bei BCIs um einen nützlichen Algorithmus handelt, der in realen Weltbedingungen eingesetzt wird. Im Jahr 2020 nutzten Forscher der University of California ein Rechensystem im Zusammenhang mit Gehirn-Maschine-Schnittstellen, um Gehirnwellen in Sätze zu übersetzen. Ihre Dekodierung war jedoch auf 30 bis 50 Sätze beschränkt, obwohl die Wortfehlerquoten so niedrig waren wie 3 % Prothese und Umweltkontrolle Nicht-invasive BCIs wurden auch angewendet, um die Gehirnkontrolle von prothetischen Ober- und Unterextremitätsgeräten bei Personen mit Lähmung zu ermöglichen. Zum Beispiel demonstrierte Gert Pfurtscheller der Technischen Universität Graz und Kollegen ein BCI-gesteuertes funktionelles elektrisches Stimulationssystem zur Wiederherstellung der oberen Extremitätsbewegungen in einer Person mit Tetraplegie durch Rückenmarksverletzung. Zwischen 2012 und 2013 haben Forscher der University of California, Irvine zum ersten Mal gezeigt, dass es möglich ist, BCI-Technologie zu verwenden, um Gehirn-gesteuertes Gehen nach Rückenmarksverletzung wiederherzustellen. In ihrer Rückenmarksverletzungsstudie konnte eine Person mit Paraplegie eine BCI-robotische Gait-Orthese betreiben, um die grundlegende Gehirn-kontrollierte Ambulation wiederherzustellen. Im Jahr 2009 nutzte Alex Blainey, ein unabhängiger Forscher mit Sitz in Großbritannien, erfolgreich die Emotiv EPOC, um einen Roboterarm mit 5 Achsen zu steuern. Er ging dann weiter, um mehrere Demonstrations-Gedanken kontrollierte Rollstühle und Hausautomation zu machen, die von Menschen mit eingeschränkter oder keine Motorsteuerung wie solche mit Paraplegie und zerebraler Palsy betrieben werden konnte. Die von DARPA finanzierte Forschung zur militärischen Nutzung von BCIs ist seit den 1970er Jahren in Gang gekommen. Der aktuelle Forschungsschwerpunkt ist die nutzer-to-user-Kommunikation durch Analyse von neuronalen Signalen. DIY und Open Source BCIIn 2001 wurde das OpenEEG-Projekt von einer Gruppe von DIY Neurowissenschaftlern und Ingenieuren initiiert. Das ModularEEG war das primäre Gerät, das von der OpenEEG Community erstellt wurde; es war eine 6-Kanal-Signalerfassungsplatine, die zwischen $200 und $400 kosten, um zu Hause zu machen. Das OpenEEG Projekt markierte einen signifikanten Moment in der Entstehung von DIY Gehirn-Computer-Interface. Im Jahr 2010 veröffentlichte die Frontier Nerds von NYUs ITP-Programm ein gründliches Tutorial mit dem Titel How To Hack Toy EEGs.Das Tutorial, das die Gedanken vieler budding DIY BCI-Enthusiasten rührte, zeigte, wie man einen einzigen Kanal zu Hause EEG mit einem Arduino und einem Mattel Mindflex zu einem sehr günstigen Preis zu schaffen. Dieses Tutorial verstärkt die DIY BCI Bewegung. Im Jahr 2013 entstand OpenBCI aus einer DARPA-Anklärung und anschließender Kickstarter-Kampagne. Sie schufen ein hochwertiges, Open-Source 8-Kanal-EEG-Akquisitionsboard, bekannt als das 32bit Board, das für weniger als 500 $ im Handel war. Zwei Jahre später schufen sie das erste 3D-gedruckte EEG Headset, das als Ultracortex bekannt ist, sowie ein 4-Kanal-EEG-Akquisitionsboard, bekannt als Ganglion Board, das für unter 100 $ im Handel war. MEG und MRI Magnetoencephalographie (MEG) und funktionelle Magnetresonanztomographie (fMRI) wurden beide erfolgreich als nicht-invasive BCIs eingesetzt. In einem weit verbreiteten Experiment erlaubte fMRI, dass zwei Benutzer gescannt wurden, um Pong in Echtzeit zu spielen, indem sie ihre hämodynamische Reaktion oder Gehirnblutfluss durch Biofeedback-Techniken verändern. fMRI Messungen von hämodynamischen Reaktionen in Echtzeit wurden auch verwendet, um Roboterarme mit einer sieben Sekunden langen Verzögerung zwischen Denken und Bewegung zu steuern. Im Jahr 2008 in der Advanced Telecommunications Research (ATR) Computational Neuroscience Laboratories in Kyoto, Japan entwickelt, erlaubten die Wissenschaftler, Bilder direkt aus dem Gehirn zu rekonstruieren und auf einem Computer in Schwarz und Weiß mit einer Auflösung von 10x10 Pixeln anzuzeigen. Der Artikel, der diese Leistungen verkündete, war die Titelgeschichte der Zeitschrift Neuron vom 10. Dezember 2008. Im Jahr 2011 veröffentlichten Forscher von UC Berkeley eine Studie, die eine Zweit-Sekunden-Rekonstruktion von Videos, die von den Themen der Studie beobachtet werden, aus fMRI-Daten. Dies wurde erreicht, indem ein statistisches Modell über visuelle Muster in den Videos, die den Subjekten gezeigt wurden, auf die Gehirnaktivität erstellt wurde, die durch die Beobachtung der Videos verursacht wurde. Dieses Modell wurde dann verwendet, um die 100 einsekunden Video-Segmente in einer Datenbank von 18 Millionen Sekunden zufälligen YouTube-Videos, deren visuelle Muster am engsten die Gehirnaktivität, die bei einem neuen Video aufgezeichnet wurde, angepasst. Diese 100 Einsekunden-Video-Extrakte wurden dann zu einem Moashed-up-Bild kombiniert, das dem zu beobachtenden Video ähnelte. BCI-Kontrollstrategien für die Neurogaming Motor-Bildung Motor-Bilder sind die Vorstellungen der Bewegung verschiedener Körperteile, die zu einer sensorimotorischen Kortex-Aktivierung führen, die sensorimotorische Schwingungen im EEG moduliert. Dies kann durch die BCI erkannt werden, um die Absicht eines Benutzers zu mindern. Motor-Bilder benötigen typischerweise eine Reihe von Trainingseinheiten, bevor eine akzeptable Kontrolle des BCI erworben wird. Diese Schulungen können mehrere Stunden dauern, bis die Anwender die Technik mit akzeptabler Präzision konsequent einsetzen können. Unabhängig von der Dauer der Schulung sind die Benutzer nicht in der Lage, das Kontrollschema zu beherrschen. Dies führt zu einem sehr langsamen Tempo des Gameplays. Vor kurzem wurden fortschrittliche maschinelle Lernmethoden entwickelt, um ein fachspezifisches Modell zur Erfassung der Leistung von Motorbildern zu berechnen. Der Top-Performance-Algorithmus von BCI Competition IV Datensatz 2 für Motor-Bilder ist das Filter Bank Common Spatial Pattern, entwickelt von Ang et al.from A*STAR, Singapur.) Bio/neurofeedback für passive BCI Designs Biofeedback wird verwendet, um die geistige Entspannung eines Subjekts zu überwachen. In einigen Fällen überwacht Biofeedback keine Elektroenzephalographie (EEG), sondern Körperparameter wie Elektromyographie (EMG), galvanische Hautbeständigkeit (GSR,) und Herzfrequenzvariabilität (HRV). Viele Biofeedback-Systeme werden verwendet, um bestimmte Störungen wie Aufmerksamkeitsdefizit Hyperaktivitätsstörung (ADHD,) Schlafprobleme bei Kindern, Zähne Schleifen und chronischen Schmerzen zu behandeln. EEG-Biofeedback-Systeme überwachen typischerweise vier verschiedene Bänder (theta: 4–7 Hz, alpha:8–12 Hz, SMR: 12–15 Hz, Beta: 15–18 Hz) und fordern das Subjekt, sie zu kontrollieren. Passive BCI beinhaltet die Verwendung von BCI zur Anreicherung von Mensch-Maschine-Interaktion mit impliziten Informationen über den Zustand des tatsächlichen Benutzers, z.B. Simulationen, um zu erkennen, wann Benutzer planen, Bremsen während eines Notwagen-Stoppvorgangs zu schieben. Spielentwickler mit passiven BCIs müssen erkennen, dass durch Wiederholung der Spielstufen der kognitive Zustand des Benutzers verändert oder angepasst wird. Innerhalb des ersten Levelspiels reagiert der Benutzer auf die Dinge anders als während des zweiten Spiels: So wird der Benutzer weniger überrascht sein, wenn er/sie es erwartet. Visual evoked potential (VEP)A VEP ist ein elektrisches Potential, das nach einer Art visueller Reize aufgezeichnet wird.Es gibt verschiedene Arten von VEPs. Steady-state visuell evoked Potentiale (SSVEPs) nutzen Potentiale, die durch die Spannung der Netzhaut erzeugt werden, unter Verwendung von visuellen Reize, die bei bestimmten Frequenzen moduliert wird. Die Reize von SSVEP werden oft aus alternierenden Checkerboard-Mustern gebildet und verwenden manchmal einfach blinkende Bilder. Die Frequenz der Phasenumkehr des verwendeten Reizs kann im Spektrum eines EEG deutlich unterschieden werden, was die Detektion von SSVEP-Stimmen relativ einfach macht. SSVEP hat sich in vielen BCI-Systemen als erfolgreich erwiesen. Dies ist auf mehrere Faktoren zurückzuführen, ist das Signal elicited in so großer Bevölkerung messbar, wie die transiente VEP und Blink-Bewegung und elektrokardiographische Artefakte die überwachten Frequenzen nicht beeinflussen. Darüber hinaus ist das SSVEP-Signal außergewöhnlich robust; die topographische Organisation der primären visuellen Kortex ist so, dass eine breitere Fläche von dem zentralen oder fovialen Bereich des visuellen Feldes abweicht. SSVEP hat jedoch mehrere Probleme. Da SSVEPs blinkende Reize verwenden, um die Absicht eines Benutzers zu mindern, muss der Benutzer eines der blinkenden oder iterierenden Symbole betrachten, um mit dem System zu interagieren. Es ist daher wahrscheinlich, dass die Symbole irritierend und unangenehm werden könnten, während längerer Spielsitzungen zu verwenden, die oft mehr als eine Stunde dauern können, die möglicherweise kein ideales Gameplay sein kann. Eine andere Art von VEP, die mit Anwendungen verwendet wird, ist das P300-Potential. Das ereignisbezogene P300-Potential ist ein positiver Peak im EEG, der bei etwa 300 ms nach dem Auftreten eines Zielstimulus (ein Reiz, auf den der Benutzer wartet oder sucht) oder ungerade Ballstimuli auftritt. Die P300-Amplitude nimmt ab, da die Zielstimuli und die ignorierten Reize ähnlicher werden. Der P300 soll sich auf einen höheren Aufmerksamkeitsprozess oder eine orientierende Reaktion mit P300 beziehen, da ein Steuerungssystem den Vorteil hat, dass der Teilnehmer nur begrenzte Schulungen besuchen muss. Die erste Anwendung des P300-Modells war die P300-Matrix. In diesem System würde ein Thema einen Brief aus einem Raster von 6 mit 6 Buchstaben und Zahlen wählen. Die Zeilen und Spalten des Rasters blitzten sequentiell und jedes Mal, wenn der ausgewählte "Auswahlbrief" beleuchtet wurde, wurde der P300 des Benutzers (potenziell) elicited. Allerdings war der Kommunikationsprozess bei etwa 17 Zeichen pro Minute recht langsam. Die P300 ist eine BCI, die eine diskrete Auswahl anstatt eine kontinuierliche Steuerung bietet. Der Vorteil der P300-Nutzung innerhalb von Spielen ist, dass der Spieler sich nicht selbst lehren muss, wie man ein völlig neues Steuerungssystem verwendet und so nur kurze Trainingsinstanzen durchführen muss, um die Gameplay-Mechanik und die grundlegende Verwendung des BCI-Paradigmus zu lernen. Synthetische Telepathie/silente Kommunikation In einer US-Armee-Initiative von 6,3 Millionen US-Millionen, Geräte für die telepathische Kommunikation zu erfinden, konnte Gerwin Schalk, in einem Stipendium von 2,2 Millionen US-Dollar unterschrieben, die Verwendung von ECoG-Signalen die in gesprochenen und vorgestellten Wörter eingebetteten Vokale und Konsonanten diskriminieren, Licht auf die verschiedenen Mechanismen, die mit der Produktion von Vokalen und Konsonanten verbunden sind, und die Grundlage für die Gehirn-basierte Kommunikation mit der vorgestellt werden könnten. Im Jahr 2002 hatte Kevin Warwick eine Reihe von 100 Elektroden in sein Nervensystem gefeuert, um sein Nervensystem ins Internet zu verbinden, um Verbesserungsmöglichkeiten zu untersuchen. Damit hat Warwick erfolgreich eine Reihe von Experimenten durchgeführt. Mit Elektroden, die auch in das Nervensystem seiner Frau implantiert wurden, führten sie das erste direkte elektronische Kommunikationsexperiment zwischen den Nervensystemen zweier Menschen durch. Eine weitere Gruppe von Forschern konnte eine bewusste Gehirn-zu-Hirn-Kommunikation zwischen zwei Personen erreichen, die durch eine Distanz mit nicht-invasiver Technologie getrennt wurden, die mit der Kopfhaut der Teilnehmer in Kontakt war. Die Wörter wurden durch binäre Ströme mit den Sequenzen von 0's und 1's durch den imaginären Motoreingang der die Information emittierenden Person kodiert. Als Ergebnis dieses Experiments wurden pseudo-random Bits der Informationen mit codierten Wörtern hola (hi auf Spanisch) und ciao (auf Wiedersehen auf Italienisch) übertragen und zwischen Menschen, die durch eine Distanz voneinander getrennt sind, mit blockierten Motor- und sensorischen Systemen übertragen, die keine Wahrscheinlichkeit dafür haben. [2] Die Forschung an synthetischer Telepathie mit Subvocalisierung findet an der University of California, Irvine unter Leitung von Wissenschaftler Mike D'Zmura statt. Die erste solche Kommunikation fand in den 1960er Jahren mit EEG statt, um Morse-Code mit Gehirn alpha-Wellen zu erstellen.Mit EEG zu kommunizieren gedachte Sprache ist weniger genau als die invasive Methode, eine Elektrode zwischen dem Schädel und dem Gehirn zu platzieren. Am 27. Februar 2013 hat die Gruppe mit Miguel Nicolelis an der Duke University und IINN-ELS die Gehirne von zwei Ratten mit elektronischen Schnittstellen erfolgreich verbunden, die es ihnen erlaubten, direkt Informationen in der ersten direkten Gehirn-zu-Hirn-Schnittstelle zu teilen. Zellkultur-BCIs Forscher haben Geräte zur Schnittstelle mit neuronalen Zellen und ganzen neuronalen Netzwerken in Kulturen außerhalb von Tieren gebaut. Neben der Weiterentwicklung der Forschung auf tierimplantierbaren Geräten haben sich Experimente auf kultiviertes neuronales Gewebe auf die Entwicklung von Problemlösungsnetzwerken, die Konstruktion von Basisrechnern und die Manipulation von Robotergeräten konzentriert. Die Forschung an Techniken zur Stimulation und Aufnahme einzelner Neuronen auf Halbleiterchips wird manchmal als Neuroelektronik oder Neurochips bezeichnet. Die Entwicklung des ersten arbeitenden Neurochips wurde von einem Caltech-Team unter der Leitung von Jerome Pine und Michael Maher 1997 behauptet. Der Caltech-Chip hatte Platz für 16 Neuronen. 2003 begann ein Team unter der Leitung von Theodore Berger an der University of Southern California, an einem Neurochip zu arbeiten, der als künstlicher oder prothetischer Hippocampus fungierte. Der Neurochip wurde entwickelt, um in Ratten-Gehirnen zu arbeiten und war als Prototyp für die evtl. Weiterentwicklung der höheren Gehirnprothese gedacht. Der Hippocampus wurde gewählt, weil er der am meisten bestellte und strukturierte Teil des Gehirns ist und der am meisten untersuchte Bereich ist. Seine Funktion ist es, Erfahrungen für die Speicherung als langfristige Erinnerungen anderswo im Gehirn zu kodieren. Im Jahr 2004 benutzte Thomas DeMarse an der University of Florida eine Kultur von 25.000 Neuronen aus dem Gehirn einer Ratte, um einen F-22 Kampfflugzeugsimulator zu fliegen. Nach der Sammlung wurden die kortikalen Neuronen in einer Petrischale kultiviert und begannen schnell, sich wieder zu einem lebenden neuronalen Netzwerk zu verbinden. Die Zellen wurden über ein Raster von 60 Elektroden angeordnet und zur Steuerung der Pech- und Gierfunktionen des Simulators verwendet. Der Schwerpunkt der Studie lag auf dem Verständnis, wie das menschliche Gehirn rechnerische Aufgaben auf zellulärer Ebene durchführt und lernt. Ethische Erwägungen Quellen: Nutzer-zentrierte Probleme Langzeiteffekte für den Benutzer bleiben weitgehend unbekannt. Erhalt einer fundierten Zustimmung von Menschen, die Schwierigkeiten haben, zu kommunizieren. Die Folgen der BCI-Technologie für die Lebensqualität von Patienten und ihren Familien. Gesunde Nebenwirkungen (z.B. Neurofeedback von sensorimotorischem Rhythmustraining wird berichtet, um die Schlafqualität zu beeinflussen). Therapeutische Anwendungen und deren potentieller Missbrauch. Sicherheitsrisiken Nicht-Konvertibilität einiger der Veränderungen des Gehirns Rechtliche und soziale Aspekte der Rechenschaftspflicht und Verantwortung: behauptet, dass der Einfluss von BCIs den freien Willen überwiegt und die Kontrolle über sensorisch-motorische Handlungen unternimmt, behauptet, dass die kognitive Absicht aufgrund einer BCI-Störung ungenau übersetzt wurde. Persönlichkeitsveränderungen, die durch tiefe Hirnstimulation verursacht werden. Was den Zustand des Cyborg zu werden - mit Teilen des Körpers, die leben und Teile, die mechanisch sind. Fragen Persönlichkeit: Was bedeutet es, ein Mensch zu sein? Verschwimmen der Trennung zwischen Mensch und Maschine und Unfähigkeit, zwischen menschlichen vs. maschinengesteuerten Aktionen zu unterscheiden. Verwendung der Technologie in fortgeschrittenen Verhörtechniken durch Regierungsbehörden. Selektive Verbesserung und soziale Schichtung. Fragen der Forschungsethik, die beim Fortschreiten von Tierversuchen bis zur Anwendung in menschlichen Fächern entstehen. Moralfragen Lesen und Datenschutz. Tracking und "tagging system" Verstanden. Bewegungssteuerung Emotionskontrolle In ihrer derzeitigen Form werden die meisten BCIs weit von den oben betrachteten ethischen Fragen entfernt. Sie sind tatsächlich ähnlich wie Korrekturtherapien in Funktion. Clausen erklärte 2009, dass "BCIs ethische Herausforderungen stellen, aber diese sind konzeptuell ähnlich denen, die Bioethiker für andere Bereiche der Therapie angesprochen haben". Darüber hinaus schlägt er vor, dass Bioethik gut vorbereitet ist, um sich mit den Fragen, die mit BCI-Technologien entstehen, zu beschäftigen. Haselager und Kollegen wiesen darauf hin, dass die Erwartungen an die Wirksamkeit und den Wert von BCI bei der ethischen Analyse eine große Rolle spielen und wie sich BCI-Wissenschaftler an die Medien wenden sollten. Darüber hinaus können Standardprotokolle implementiert werden, um ethisch fundierte, fundierte Verfahren mit eingeschlossenen Patienten zu gewährleisten. Der Fall von BCIs hat heute Parallelen in der Medizin, wie seine Evolution. Ähnlich wie die pharmazeutische Wissenschaft als Balance für Beeinträchtigungen begann und wird jetzt verwendet, um den Fokus zu erhöhen und die Notwendigkeit für den Schlaf zu reduzieren, BCIs wird wahrscheinlich allmählich von Therapien zu Verbesserungen transformieren.In der BCI-Gemeinschaft werden Anstrengungen unternommen, um einen Konsens über ethische Leitlinien für BCI-Forschung, Entwicklung und Verbreitung zu schaffen. kostengünstige BCI-basierte Schnittstellen Vor kurzem haben eine Reihe von Unternehmen die Medizinklasse EEG-Technologie (und in einem Fall, NeuroSky, wieder aufgebaut die Technologie von Grund auf) kostengünstige BCIs zu schaffen. Diese Technologie wurde in Spielzeug und Gaming-Geräte gebaut; einige dieser Spielzeuge waren wie die NeuroSky und Mattel MindFlex äußerst erfolgreich. Im Jahr 2006 patentierte Sony ein neuronales Schnittstellensystem, mit dem Radiowellen Signale in der neuronalen Cortex beeinflussen können. 2007 veröffentlichte NeuroSky den ersten erschwinglichen Konsument EEG zusammen mit dem Spiel NeuroBoy. Dies war auch das erste große EEG-Gerät, um trockene Sensorik zu verwenden. 2008 OCZ Technologie entwickelte ein Gerät für den Einsatz in Videospielen, das sich vor allem auf die Elektromyographie stützt. 2008 gab Final Fantasy Entwickler Square Enix bekannt, dass es mit NeuroSky zusammenarbeitete, um ein Spiel zu schaffen, Judecca. 2009 hat Mattel mit NeuroSky zusammengearbeitet, um den Mindflex freizugeben, ein Spiel, das ein EEG benutzte, um einen Ball durch einen Hinderniskurs zu steuern. Es ist mit Abstand der beste Verkauf Verbraucher basiert EEG bis heute. 2009 Onkel Milton Industries hat mit NeuroSky zusammengearbeitet, um den Star Wars Force Trainer freizulassen, ein Spiel, das entworfen wurde, um die Illusion des Besitzes der Kraft zu schaffen. 2009 veröffentlichte Emotiv das EPOC, ein 14-Kanal-EEG-Gerät, das 4 mentale Zustände, 13 bewusste Zustände, Gesichtsausdrücke und Kopfbewegungen lesen kann. Das EPOC ist das erste kommerzielle BCI zur Verwendung von trockener Sensortechnologie, die mit einer Kochsalzlösung für eine bessere Verbindung gedämpft werden kann. Im November 2011 Zeitmagazin ausgewählt Necomimi produziert von Neurowear als eine der besten Erfindungen des Jahres. Das Unternehmen gab bekannt, dass es erwartet, eine Consumer-Version des Kleidungsstücks, bestehend aus katzenartigen Ohren, die von einem Gehirn-Wellen-Reader von NeuroSky im Frühjahr 2012 gesteuert. Im Februar 2014 Sie Shall Walk (eine gemeinnützige Organisation, die auf dem Bau von Exoskeletons, gegrabenen LIFESUITs, für Paraplegics und Quadriplegics fixiert ist) begann eine Partnerschaft mit James W. Shakarji über die Entwicklung einer drahtlosen BCI. 2016 entwickelte eine Gruppe von Hobbyisten ein Open-Source-BCI-Board, das neurale Signale an den Audio-Jack eines Smartphones sendet und die Kosten für die Einstiegsstufe BCI auf £20 reduziert. Basisdiagnostik-Software ist für Android-Geräte sowie eine Texteingabe-App für Unity verfügbar. 2018 konzentrierte sich das Compassionate AI Lab, eine gemeinnützige Organisation, auf die Verwendung von Verstärkungslernen und anderen KI-Techniken, um behinderten Menschen zu helfen. Zukunftsziele Ein Konsortium bestehend aus 12 europäischen Partnern hat einen Fahrplan zur Unterstützung der Europäischen Kommission in ihren Förderentscheidungen für das neue Rahmenprogramm Horizon 2020 abgeschlossen. Das von der Europäischen Kommission geförderte Projekt begann im November 2013 und veröffentlichte im April 2015 einen Fahrplan. Eine 2015 veröffentlichte Publikation unter Leitung von Dr. Clemens Brunner beschreibt einige der Analysen und Errungenschaften dieses Projekts sowie die aufstrebende Brain-Computer Interface Society. Zum Beispiel hat dieser Artikel die Arbeit in diesem Projekt überprüft, dass weitere definierte BCIs und Anwendungen, erforschte aktuelle Trends, diskutierte ethische Fragen und bewertete verschiedene Richtungen für neue BCIs. Wie der Artikel feststellt, erweitert und unterstützt die neue Roadmap die Empfehlungen des von Dr. Brendan Allison verwalteten Zukunfts-BNCI-Projekts, das erhebliche Begeisterung für aufstrebende BCI-Richtungen vermittelt. Auch andere jüngste Publikationen haben zukünftige BCI-Anweisungen für neue Gruppen behinderter Nutzer (z.B.) erforscht. Einige prominente Beispiele sind unten zusammengefasst. Bewusstseinsstörungen (DOC) Einige Personen haben eine Bewusstseinsstörung (DOC). Dieser Zustand ist definiert, um Personen mit Koma, sowie Personen in einem vegetativen Zustand (VS) oder minimal bewussten Zustand (MCS) einzuschließen. Neue BCI-Forschung zielt darauf ab, Menschen mit DOC auf verschiedene Weise zu helfen. Ein Hauptziel ist es, Patienten zu identifizieren, die in der Lage sind, grundlegende kognitive Aufgaben zu erfüllen, was natürlich zu einer Änderung ihrer Diagnose führen würde. Das heißt, einige Personen, die mit DOC diagnostiziert werden, können in der Tat in der Lage sein, Informationen zu verarbeiten und wichtige Lebensentscheidungen zu treffen (z.B., ob man Therapie sucht, wo man leben kann, und ihre Ansichten über End-of-Life-Entscheidungen in Bezug auf sie). Einige Personen, die mit DOC diagnostiziert werden, sterben aufgrund von End-of-life-Entscheidungen, die von Familienmitgliedern getroffen werden können, die aufrichtig das Gefühl haben, dass dies im besten Interesse des Patienten ist. Angesichts der neuen Aussicht, dass diese Patienten ihre Ansichten zu dieser Entscheidung abgeben können, scheint es einen starken ethischen Druck zu geben, um diese Forschungsrichtung zu entwickeln, um sicherzustellen, dass DOC-Patienten die Möglichkeit erhalten, zu entscheiden, ob sie leben wollen.Diese und andere Artikel beschreiben neue Herausforderungen und Lösungen, um BCI-Technologie zu nutzen, um Personen mit DOC zu helfen. Eine große Herausforderung ist, dass diese Patienten BCIs nicht auf der Grundlage von Vision verwenden können. Daher verlassen sich neue Werkzeuge auf auditive und/oder vibrotaktile Reize. Patienten können Kopfhörer und/oder vibrotaktile Stimulatoren tragen, die an den Handgelenken, Hals, Bein und/oder anderen Orten platziert sind. Eine andere Herausforderung ist, dass Patienten in und aus dem Bewusstsein verblassen und nur zu bestimmten Zeiten kommunizieren können. Dies kann in der Tat eine Ursache für eine falsche Diagnose sein. Einige Patienten können nur in der Lage sein, auf die Anfragen von Ärzten während einiger Stunden pro Tag zu reagieren (die möglicherweise nicht vorhersehbar sein könnten) und somit während der Diagnose nicht reagieren. Daher verlassen sich neue Methoden auf Werkzeuge, die in Feldeinstellungen leicht zu bedienen sind, auch ohne kompetente Hilfe, so dass Familienmitglieder und andere Personen ohne medizinischen oder technischen Hintergrund sie immer noch nutzen können. Dies reduziert die Kosten, Zeit, Bedarf an Fachwissen und andere Belastungen mit DOC-Bewertung. Automatisierte Werkzeuge können einfache Fragen stellen, die Patienten leicht beantworten können, wie "Ist Ihr Vater George genannt?" oder "Wurden Sie in den USA geboren? "Automatisierte Instruktionen informieren Patienten, dass sie Ja oder Nein vermitteln können, indem sie beispielsweise ihre Aufmerksamkeit auf Reize am rechten vs. linken Handgelenk fokussieren. Diese fokussierte Aufmerksamkeit führt zu zuverlässigen Veränderungen in EEG-Mustern, die dazu beitragen können, dass der Patient kommunizieren kann. Die Ergebnisse konnten Ärzten und Therapeuten vorgelegt werden, die zu einer überarbeiteten Diagnose und Therapie führen könnten. Darüber hinaus könnten diese Patienten dann mit BCI-basierten Kommunikationstools versorgt werden, die ihnen helfen könnten, grundlegende Bedürfnisse zu vermitteln, Bettposition und HVAC (Heizung, Lüftung und Klimatisierung) einzustellen und sie anderweitig befähigen, wichtige Lebensentscheidungen zu treffen und zu kommunizieren. Motorrückgewinnung Menschen können einige ihrer Fähigkeit verlieren, sich aufgrund vieler Ursachen zu bewegen, wie Schlaganfall oder Verletzung. Mehrere Gruppen haben Systeme und Methoden für die Motorrückgewinnung untersucht, die BCIs umfassen. Bei diesem Ansatz misst ein BCI die motorische Aktivität, während der Patient Bewegungen wie ein Therapeut vorstellt oder versucht. Die BCI kann zwei Vorteile bieten: (1) Wenn die BCI angibt, dass ein Patient keine korrekte Bewegung vorstellt (Nichteinhaltung), dann könnte die BCI den Patienten und Therapeuten informieren; und (2) Belohnung Feedback wie Funktionsstimulation oder die Bewegung eines virtuellen Avatars hängt auch von der korrekten Bewegungsdarstellung des Patienten ab. Bisher haben sich die BCIs für die Motorrückgewinnung auf das EEG angewiesen, um die Motoraufnahme des Patienten zu messen. Allerdings haben Studien auch fMRI verwendet, um verschiedene Veränderungen im Gehirn zu untersuchen, wie Personen BCI-basierte Schlaganfall-Rehabilitierung Ausbildung. Zukünftige Systeme können die fMRI und andere Maßnahmen zur Echtzeitsteuerung, wie funktionellen Nahinfrarot, wahrscheinlich in Tandem mit EEGs umfassen. Nicht-invasive Hirnstimulation wurde auch in Kombination mit BCIs zur Motorrückgewinnung erforscht. Im Jahr 2016 veröffentlichten Wissenschaftler der Universität Melbourne präklinische Nachweis-of-concept-Daten in Bezug auf eine potenzielle Plattform für Gehirn-Computer-Schnittstellen-Technologien für Patienten mit Lähmung entwickelt, um die Kontrolle externer Geräte wie Roboter-Lebenskörper, Computer und Exoskeletons durch die Übertragung von Gehirnaktivität zu erleichtern. Klinische Studien sind derzeit im Gange. Functional Brains Kartierung Jedes Jahr werden rund 400.000 Menschen während der Neurochirurgie Gehirnkartierungen durchlaufen. Dieses Verfahren ist oft für Menschen mit Tumoren oder Epilepsie erforderlich, die nicht auf Medikamente reagieren. Während dieses Vorgangs werden Elektroden auf das Gehirn gelegt, um die Standorte von Strukturen und Funktionsbereichen genau zu identifizieren. Die Patienten können während der Neurochirurgie wach sein und gebeten werden, bestimmte Aufgaben, wie bewegte Finger oder wiederholte Wörter, auszuführen. Dies ist erforderlich, damit Chirurgen nur das gewünschte Gewebe entfernen können, während andere Bereiche, wie kritische Bewegungs- oder Sprachbereiche, gespart werden. Das Entfernen zu viel Hirngewebe kann dauerhafte Schäden verursachen, während das Entfernen zu wenig Gewebe den zugrunde liegenden Zustand unbehandelt lassen und zusätzliche Neurochirurgie erfordern. So besteht ein starkes Bedürfnis, sowohl Methoden als auch Systeme zu verbessern, um das Gehirn so effektiv wie möglich abzubilden. In mehreren neueren Publikationen haben BCI-Forschungsexperten und medizinische Ärzte zusammengearbeitet, um neue Wege zu erkunden, um die BCI-Technologie zur Verbesserung der neurochirurgischen Kartierung zu nutzen. Diese Arbeit konzentriert sich weitgehend auf eine hohe Gammaaktivität, die mit nicht-invasiven Mitteln schwer zu erkennen ist. Die Ergebnisse haben zu verbesserten Methoden zur Identifizierung von Schlüsselbereichen für Bewegung, Sprache und andere Funktionen geführt.Ein neuer Artikel behandelt Fortschritte in der funktionellen Gehirn-Mapping und fasst einen Workshop zusammen. Flexible Geräte Flexible Elektronik sind Polymere oder andere flexible Materialien (z.B. Seide, Pentacen, PDMS, Parylene, Polyimid), die schaltungstechnisch gedruckt werden; die flexible Natur der organischen Hintergrundmaterialien, die die Elektronik zur Biegung ermöglichen, und die Herstellungsverfahren, mit denen diese Geräte hergestellt werden, ähneln denen, die zur Herstellung integrierter Schaltungen und mikroelektromechanischer Systeme (MEMS) verwendet werden. Die flexible Elektronik wurde zunächst in den 1960er und 1970er Jahren entwickelt, aber das Forschungsinteresse nahm Mitte der 2000er Jahre zu. Neural Staub Neural Staub ist ein Begriff verwendet, um auf Millimeter-Size-Geräte, die als kabellos betriebene Nervensensoren betrieben wurden, die in einem 2011 Papier der University of California, Berkeley Wireless Research Center vorgeschlagen wurden, die sowohl die Herausforderungen als auch die herausragenden Vorteile der Schaffung einer dauerhaften drahtlosen BCI beschreiben. In einem vorgeschlagenen Modell des neuronalen Staubsensors erlaubte das Transistormodell eine Methode zur Trennung zwischen lokalen Feldpotentialen und Aktionspotentialspitzen, die einen stark diversifizierten Datenreichtum aus den Aufnahmen ermöglichen würde. Siehe auch Hinweise ReferenzenWeiter lesen Brouse, Andrew. "A Young Person's Guide to Brainwave Music: Vierzig Jahre Audio aus dem menschlichen EEG".eContact! 14.2 – Biotechnologische Leistungspraxis / Pratiques de performance biotechnologique (Juli 2012). Montréal: CEC.Gupta, Cota Navin und Ramaswamy Palanappian. "Hochfrequenz-Elektroencephalogramm in Visual and Auditory-Based Brain-Computer Interface Designs verwenden".eContact!14.2 – Biotechnologische Leistungspraxis / Pratiques de performance biotechnologique (Juli 2012). Montréal: CEC.Ouzounian, Gascia."The Biomuse Trio in Conversation: Ein Interview mit R. Benjamin Knapp und Eric Lyon".eContact! 14.2 – Biotechnologische Leistungspraxis / Pratiques de performance biotechnologique (Juli 2012). Montréal: CEC. Externe Links Das Projekt entsperren