Das Argument des chinesischen Raums ist, dass ein digitaler Computer, der ein Programm durchführt, kein Denken, Verständnis oder Bewusstsein haben kann, unabhängig davon, wie intelligentes oder menschliches Programm das Computerverhalten ausüben kann. John Searle wurde in seinem Papier, "Minds, Gehirn und Programme" vorgestellt, das 1980 in den Bereichen Tier- und Gehirnwissenschaften veröffentlicht wurde. Ähnliche Argumente wurden von Wolfgang Leibniz (1714), Anatoly Dneprov (1961,) Lawrence Davis (1974) und Ned Block (1978) vorgestellt. Searle wurde in den Jahren seit weitem diskutiert. Kernstück des Arguments von Searle ist ein Experiment, das als chinesischer Raum bekannt ist. Das Argument richtet sich gegen die philosophischen Positionen des funktionellen und rechnerischen Charakters, die der Ansicht sind, dass der Geist als Informationsaustauschsystem angesehen werden kann, das auf formalen Symbolen funktioniert und dass die Simulation eines bestimmten psychischen Staates für seine Anwesenheit ausreicht. Konkret zielt das Argument darauf ab, eine Position Searle appelliert an eine starke AI: "Der geeignete programmierte Computer mit den richtigen Inputs und Outputs würde dadurch in genau dem gleichen Sinne, dass Menschen denken. " Obwohl es ursprünglich als Reaktion auf die Aussagen von künstlichen Intelligenz (AI)-Forschern vorgelegt wurde, ist es kein Argument gegen die Ziele der allgemeinen AI-Forschung, da sie keine Grenzen in der Höhe des intelligenten Verhaltens einer Maschine zeigen. Das Argument gilt nur für digitale Computer, die Programme durchführen und nicht für Maschinen im Allgemeinen gelten. chinesisches Zimmer dachten, dass Searles Denkversuch mit dieser hypothetischen Prämisse beginnt: Es ist zu erwarten, dass künstliche Intelligenzforschung gelungen ist, einen Computer zu bauen, der sich mit China vertraut. Sie nimmt chinesische Zeichen als Input an und produziert nach den Anweisungen eines Computerprogramms andere chinesische Zeichen, die es als Output präsentiert. Searle erklärt, dass dieser Computer seine Aufgabe so überzeugend erfüllt, dass er den Turing-Test gut führt: er überzeugt einen menschlichen chinesischen Sprecher, dass das Programm selbst ein lebender chinesischer Sprecher ist. Für alle Fragen, die die Person fragt, stellt sie angemessene Antworten vor, so dass jeder chinesische Sprecher davon überzeugt sein würde, dass sie mit einem anderen chinesischen Volk sprechen. Searle will dies beantworten: ist das maschinenlesbare China? Or ist es einfach, die Fähigkeit, China zu verstehen? Searle ruft die erste Position "starke AI" und die "weak AI" auf. Searle setzt daraufhin voraus, dass er in einem geschlossenen Raum ist und mit einer englischen Version des Computerprogramms zusammen mit ausreichenden Papieren, Bleistiften, Erlöschern und dem Versand von Kabinetten ein Buch geführt hat. Searle könnte chinesische Zeichen durch einen Slot in der Tür erhalten, sie nach den Anweisungen des Programms verarbeiten und chinesische Zeichen als Output produzieren. Wenn der Computer den Turing-Test auf diese Weise beendet hatte, sagt er, er würde dies auch tun, indem er das Programm manuell durchführt. Searle behauptet, dass es keinen wesentlichen Unterschied zwischen den Rollen des Computers und selbst im Experiment gibt. Jedes Programm folgt einfach einem Schritt, bei dem ein Verhalten hergestellt wird, das dann vom Nutzer als Nachweis intelligenter Gespräche interpretiert wird. Searle selbst wäre jedoch nicht in der Lage, das Gespräch zu verstehen.("Ich spreche nicht von einem Wort von Chinesen", so er. Er argumentiert daher, dass der Computer nicht in der Lage wäre, das Gespräch entweder zu verstehen. Searle argumentiert, dass wir ohne Verständnis (oder Absichtserklärung) nicht beschreiben können, was die Maschine als Denkweise tut und, da sie nicht der Meinung ist, nicht in irgendeinem Sinne des Wortes zu denken. Er kommt daher zu dem Schluss, dass die "starke AI"-Hygie falsch ist. Marian Wolfram machte ein ähnliches Argument in 1714 gegen Mechanismus (die Position, die der Geist ist eine Maschine und nichts mehr). Leibniz nutzte das Experiment der Ausweitung des Gehirns bis zur Größe einer Mühle. Kupfer stellte fest, dass es schwierig ist, sich zu vorstellen, dass ein Bewusstsein, der in der Lage ist, nur mechanische Prozesse zu entwickeln. russischer Cyberneticist Anatoly Dneprov machte 1961 in Form der kurzen Geschichte "The Game" ein weitgehend identisches Argument. In diesem Fall handelt es sich um ein Stadien von Menschen als Schalt- und Speicherzellen, die ein Programm zur Umsetzung eines Satzes von Portugiesisch, einer Sprache, die keiner von ihnen kennt. Das Spiel wurde von einer "Professor Zarubin" organisiert, um die Frage "Kan mathematische Maschinen denken?" Dneprov schreibt "der einzige Weg, um zu beweisen, dass Maschinen sich selbst in eine Maschine verwandeln können und Ihren Denkprozess prüfen können", und er folge, wie Searle, "Wir haben bewiesen, dass selbst die perfekte Simulation des Maschinendenkens nicht der Denkprozess selbst ist". Lawrence Davis stellte 1974 vor, das Gehirn mit Telefonleitungen und Büros, die von Menschen beschäftigt sind, zu vervollständigen, und 1978 die gesamte Bevölkerung Chinas, die an einer solchen Gehirnsimulation beteiligt ist. Dieses Experiment ist das China Gehirn, auch die "chinesische Nation" oder das "chinesische Zentrum". Searle wurde in seinem Papier "Minds, Brains und Programme" aus dem Jahr 1980 aufgenommen, das in der Tier- und Gehirnwissenschaften veröffentlicht wurde. Letztlich wurde er zum "wichtigsten Zielartikel" mit einer enormen Anzahl von Kommentaren und Antworten in den folgenden Jahrzehnten, und Searle hat das Argument in vielen Papieren, populären Artikeln und Büchern weiterhin verteidigt und verfeinert. David Cole schreibt vor, dass "das chinesische Zimmerargument wahrscheinlich das am häufigsten diskutierte philosophische Argument der kognitiven Wissenschaft in den letzten 25 Jahren darstellt. Die meisten Diskussionen bestehen aus Versuchen, sie zu refute. "Die überwältigende Mehrheit" nimmt BBS-Presser Stevan Harnad zur Kenntnis, "dass der chinesische Raum der Argument falsch ist". Das Volumen der Literatur, die um sie gewachsen ist, inspirierte Pat Hayes, zu dem Schluss zu kommen, dass der Bereich der kognitiven Wissenschaft neu definiert werden sollte als "das laufende Forschungsprogramm zur Darstellung des chinesischen Raums von Searle". Searles Argument ist nach Harnad "ein klassisches in kognitiver Wissenschaft" geworden. Varol Akman stimmt und hat das Originalpapier als "vorbildlich für philosophische Klarheit und Reinheit" bezeichnet. Philosophie Obwohl das chinesische Raumgut ursprünglich als Reaktion auf die Aussagen von künstlichen Intelligenzforschern präsentiert wurde, sind die Philosophen gekommen, es als wichtiger Bestandteil der Philosophie zu betrachten. Es ist eine Herausforderung für den funktionellen Charakter und die rechnerische Theorie des Denkens und steht im Zusammenhang mit solchen Fragen wie dem Problem der Denkweise, dem Problem anderer Köpfe, dem Symbolproblem und dem harten Bewusstseinsproblem. Starke AI Searle nannte eine philosophische Position, die er "starke AI:" fordert: " Der geeignete Computer, der mit den richtigen Inputs und Outputs programmiert ist, hätte somit einen Blick in genau denselben Sinne, dass Menschen Gedanken haben. Die Definition hängt von der Unterscheidung zwischen der Vereinheitlichung eines Geistes und der tatsächlichen Wahrnehmung ab. Searle schreibt, dass "nach starken AI die richtige Simulation wirklich ein Geist ist. Laut Weak AI ist die richtige Simulation ein Modell des Geistes. " In einigen der Aussagen von Nachwuchswissenschaftlern und Analysten ist der Anspruch implizit. Zum Beispiel erklärte der AI-Gründer Herbert A. Simon 1955, dass " es in den Weltmaschinen gibt, die denken, lernen und schaffen". Simon, zusammen mit Allen Newell und Cliff Shaw, behauptete nach Abschluss des ersten AI-Programms, der Logic Theorist, dass sie "die Furnier-Krise-Probleme lösen und erklären, wie ein System, das aus Materie besteht, die Eigenschaften des Geistes haben kann. " John Haugeland schrieb, dass "AI nur den echten Artikel möchte: Maschinen mit Köpfen, im vollen und ländlichen Sinne. Dies ist nicht wissenschaftliche Fiktion, sondern echte Wissenschaft, die auf einer theoretischen Konzeption basiert, wie sie es wagt: Wir sind an der Wurzel, Computer selbst. " Searle schreibt auch folgende Forderungen an die Befürworter starker AI vor: AI-Systeme können genutzt werden, um den Geist zu erklären; die Untersuchung des Gehirns ist für die Untersuchung des Geistes unerheblich; und das Turing-Test ist geeignet, um die Existenz von psychischen Staaten zu ermitteln. Starke AI als rechnerisch oder funktionalismus Searle hat in jüngster Zeit das Argument des chinesischen Raums "starke AI" als "Computer funktionellismus" (als Begriff, den er Daniel Dennett erhält) ermittelt. Funktionismus ist eine Position in der modernen Philosophie des Geistes, die feststellt, dass wir psychische Phänomene (wie Überzeugungen, Wünsche und Wahrnehmungen) definieren können, indem sie ihre Funktionen in Bezug aufeinander und die Außenwelt beschreiben. Da ein Computerprogramm die funktionellen Beziehungen zwischen Symbolen genau repräsentieren kann, kann ein Computer psychische Phänomene haben, wenn es das richtige Programm nach funktionellem Charakter läuft. Stevan Harnad argumentiert, dass Searles Darstellungen starker AI als "erkennbare Tenets von Rechenismus, eine Position (unwie "starke AI") reformiert werden können, die von vielen Denkern tatsächlich gehalten wird und daher ein Wert auf die Refutinge. Computationalismus ist die Position in der Philosophie des Geistes, die argumentiert, dass der Geist als Informationsverarbeitungssystem genau beschrieben werden kann. Jeder der folgenden, nach Harnad, ist ein Zehntel des Rechenismus: Psychische Staaten sind rechnerische Staaten (das heißt, warum Computer psychische Staaten haben und helfen, den Geist zu erklären); Computational Staaten sind Umsetzungsunabhängig – in anderen Worten, es ist die Software, die den rechnerischen Staat bestimmt, nicht die Hardware (das heißt, warum das Gehirn, die Hardware ist irrelevant); und da die Umsetzung unwichtig ist, sind die einzigen empirischen Daten, die die Systemfunktionen betreffen; daher ist der Turingtest endgültig. Starke biologische Naturism Searle hält eine philosophische Position, die er "biologischer Naturismus:" fordert, dass das Bewusstsein und das Verständnis spezifische biologische Maschinen erfordern, die in Gehirnen gefunden werden. Er schreibt "brains bedenken" und "tatsächliche menschliche psychische Phänomene [are] hängen von den tatsächlichen physikalischen und chemischen Eigenschaften des menschlichen Gehirns ab. Searle argumentiert, dass diese Maschinen (die dem Neurowissenschaften als "neural korrelatives Bewusstsein" bekannt sind) über einige ursächliche Befugnisse verfügen müssen, die die menschliche Wahrnehmung ermöglichen. Searle Überzeugung, dass diese Befugnisse vorhanden sind, wurde kritisiert. Searle ist nicht mit dem Begriff einverstanden, dass Maschinen Bewusstsein und Verständnis haben können, da er "wir genau solche Maschinen sind". Searle stellt fest, dass das Gehirn in der Tat eine Maschine ist, aber dass das Gehirn Bewusstsein und Verständnis durch Maschinen schafft, die nicht per Computer sind. Kommt die Neurowissenschaften in der Lage, den mechanischen Prozess zu isolieren, der zu Bewusstsein führt, gewährt Searle, dass es möglich sein könnte, Maschinen zu schaffen, die Bewusstsein und Verständnis haben. Ohne die erforderlichen Maschinen ist Searle jedoch nicht der Meinung, dass das Bewusstsein entstehen kann. biologischen Naturismus bedeutet, dass man nicht bestimmen kann, ob die Erfahrung des Bewusstseins nur durch die Prüfung, wie ein System funktioniert, auftritt, weil die spezifischen Maschinen des Gehirns unerlässlich sind. biologischer Naturismus ist daher direkt gegen Verhaltens- und funktionellismus (einschließlich „Computer funktionellismus“ oder „starke AI“) gerichtet. Biologischer Naturismus ähnelt der Identitätstheorie (die Position, die psychische Staaten "identisch" oder "aus" neurologischer Ereignisse sind), aber Searle hat spezifische technische Einwände gegen die Identitätstheorie. Meerrle biologischen Naturismus und starker AI stehen sowohl gegenüber Cartesian Dualismus, der klassischen Idee, dass das Gehirn und der Geist aus verschiedenen Stoffen hergestellt werden. Searle hält eine starke biologische Vielfalt von Dualismus an und schrieb, dass "starke AI nur aufgrund der doppeltistischen Annahme sinnvoll ist, dass das Gehirn, wo der Geist betroffen ist, nicht betroffen ist. Kenntnis der ursprünglichen Präsentation von Searle betonte das Verständnis", d.h. geistige Staaten mit der Absichtserklärung von Philosophen, und nicht direkt andere eng verbundene Ideen wie das Bewusstsein. In jüngeren Präsentationen Searle hat das Bewusstsein als echtes Ziel des Arguments aufgenommen. Kaffe Modelle des Bewusstseins reichen nicht aus. Das Rechenmodell für das Bewusstsein steht in der gleichen Weise zum Bewusstsein, dass das Rechenmodell eines beliebigen Teils der modellierten Domain steht. Kein Grund dafür, dass das rechnerische Modell von Regenstürmen in London uns alle nass verlassen wird. Aber sie machen den Fehler, darauf zu achten, dass das Rechenmodell des Bewusstseins etwas bewusst ist. In beiden Fällen ist es derselbe Fehler. David Chalmers schreibt "es ist ziemlich klar, dass das Bewusstsein in der Wurzel des chinesischen Raums liegt". Colin McGinn argumentiert, dass der chinesische Raum starke Beweise dafür liefert, dass das harte Bewusstseinsproblem grundsätzlich unlöslich ist. Es geht nicht darum, ob eine Maschine sich bewusst sein kann, sondern ob sie (oder alles andere für diese Sache) bewusst sein kann. Klar ist, dass jede andere Methode, die die Insassen eines chinesischen Raums vorschreibt, dieselben Schwierigkeiten hat wie der Austausch von Fragen und Antworten in China. Es ist einfach nicht möglich zu sein, ob eine bewusste Agentur oder eine gewisse kluge Simulation in dem Raum wohnt. Searle argumentiert, dass dies nur für einen Beobachter außerhalb des Raums gilt. Ganzer Punkt des Gedankenversuchs ist es, eine Person im Raum zu stellen, in dem sie die Tätigkeit des Bewusstseins unmittelbar beobachten können. Searle behauptet, dass er von seinem Vantage-Point im Raum nichts sehen kann, dass es unerheblich sein könnte, das Bewusstsein zu schärfen, außer selbst, und er hat klar keinen Sinn, der chinesische Sprache sprechen kann. angewandte Ethik Patrick Hew nutzte das chinesische Zimmerargument, um die Anforderungen militärischer Befehls- und Kontrollsysteme zu entschärfen, wenn sie die Moral des Befehlers erhalten. Er machte eine Analogie zwischen einem Befehlsführer in ihrem Kommandozentrum und der Person im chinesischen Raum und analysierte sie in einer Lesung der Fälle von Pflicht- und Unwissenheit von Aristotle. Informationen könnten "verwandelt" von Bedeutung zu Symbolen und manipuliert werden, aber die moralische Agentur könnte untergraben werden, wenn es unzureichende 'up-Umwandlung' gab. Hew nannte Beispiele aus dem USS-Konflikt-Unfall. Informatik Das Argument des chinesischen Raums ist in erster Linie ein Argument in der Philosophie des Geistes, und beide große Computerwissenschaftler und künstliche Intelligenzforscher halten es für unerheblich. Mehrere Konzepte, die von Computerwissenschaftlern entwickelt wurden, sind jedoch unerlässlich, um das Argument zu verstehen, einschließlich der symbolischen Verarbeitung, Turingmaschinen, Turing Vollständigkeit und des Turing-Tests. Starke AI gegenüber AI-Forschung Searle wird in der Regel nicht als Frage für die AI-Forschung angesehen. Stuart Russell und Peter Norvig weisen darauf hin, dass die meisten AI-Forscher nicht über die starke AI Hypothesis – solange das Programm funktioniert, nicht darauf achten, ob Sie eine Simulation von Erkenntnissen oder echten Erkenntnissen fordern. Kernaufgabe der künstlichen Intelligenzforschung ist nur die Schaffung sinnvoller Systeme, die intelligent handeln, und es ist nicht Sache, wenn die Intelligenz einfach eine Simulation ist. Searle ist nicht der Meinung, dass die AI-Forschung Maschinen schaffen kann, die in der Lage sind, ein äußerst intelligentes Verhalten zu betreiben. Das Argument des chinesischen Raums eröffnet die Möglichkeit, dass eine digitale Maschine aufgebaut werden könnte, die intelligenter als eine Person ist, aber keine Denk- oder Absichtserklärung in derselben Weise hat, die Gehirn tun. Searle's "starke AI" sollte nicht mit "starken AI" verwechselt werden, wie es von Ray Kurzweil und anderen Futuristen definiert ist, die den Begriff verwenden, maschinelle Erkenntnisse zu beschreiben, die Rivalen oder Überschreiten der menschlichen Intelligenz. Kurzweil ist in erster Linie mit der von der Maschine gezeigten Menge an Intelligenz besorgt, während das Argument von Searle hierfür keine Grenzen gesetzt hat. Searle argumentiert, dass selbst eine Superintelligente Maschine nicht unbedingt einen Geist und Bewusstsein haben würde. Stresstests Der chinesische Raum führt eine Version des Turing-Tests durch. Alan Turing hat den Test 1950 eingeführt, um die Frage zu beantworten, "Ketten denken?" In der Standardversion setzt ein menschlicher Richter in einem natürlichen Sprachgespräch mit einem menschlichen und einer Maschine ein, die darauf abzielt, Leistungen zu erzielen, die von einem menschlichen Wesen unentschlossen sind. Alle Teilnehmer sind voneinander getrennt. Kann der Richter die Maschine vom Menschen nicht zuverlässig sagen, wird die Maschine aufgefordert, den Test zu übergeben. Letztlich betrachtete man jeden möglichen Widerspruch zum Vorschlag "Maschinen können denken" und stellte fest, dass es einfache, offensichtliche Antworten gibt, wenn die Frage auf diese Weise de-mysiert wird. Er hatte jedoch nicht die Absicht, den Test für das Vorhandensein von Bewusstsein oder Verständnis zu messen." Er glaube nicht, dass dies für die von ihm angesprochenen Probleme relevant sei. Er schrieb: Ich möchte nicht den Eindruck erwecken, dass ich glaube, es gibt keinerlei Einblicke in das Bewusstsein. Zum Beispiel gibt es ein Paradox, das mit jedem Versuch verbunden ist, es zu finden. Ich glaube aber nicht, dass diese Geheimnisse unbedingt gelöst werden müssen, bevor wir die Frage beantworten können, mit der wir uns in diesem Papier befassen. To Searle, als Philosoph, der in der Natur des Geistes und des Bewusstseins untersucht, sind die entsprechenden Geheimnisse. Der chinesische Raum soll zeigen, dass der Turing-Test nicht ausreicht, um die Präsenz des Bewusstseins zu erkennen, auch wenn sich der Raum als bewusster Geist verhalten oder funktionieren würde. Symbolverarbeitung Der chinesische Raum (und alle modernen Computer) missbraucht physische Gegenstände, um Berechnungen durchzuführen und Simulationen durchzuführen. AI-Forscher Allen Newell und Herbert A. Simon nannte diese Art von Maschinen ein physikalisches Symbolsystem. Es entspricht auch den im Bereich der mathematischen Logik verwendeten formalen Systemen. Searle unterstreicht die Tatsache, dass diese Art von Symbolmanipulation Syntactic ist (die einen Begriff aus der Studie von Catania abschließt). In dem Computer werden die Symbole, die eine Form von DNA-Vorschriften verwenden, ohne das Wissen über die semantischen Eigenschaften des Symbols (d. h. ihre Bedeutung). Newell und Simon hatten gelobt, dass ein physikalisches Symbolsystem (wie ein digitaler Computer) alle notwendigen Maschinen für "allgemeine intelligente Maßnahmen" oder, wie es heute bekannt ist, künstliche allgemeine Intelligenz hatte. Sie gliedern dies als philosophische Position, das physikalische Symbolsystem hypothesis: "Ein physikalisches Symbolsystem hat die notwendigen und ausreichenden Mittel für allgemeine intelligente Maßnahmen. " Das Argument des chinesischen Raums macht dies nicht aus, weil es in Bezug auf "intelligente Maßnahmen" definiert wird, d.h. das externe Verhalten der Maschine, statt das Vorhandensein oder Fehlen von Verständnis, Bewusstsein und Geist. Chinesischer Raum und Turing Vollständigkeit Der chinesische Raum verfügt über ein ähnliches Design wie ein moderner Computer. Es verfügt über eine von WhatsApp-Architektur, die aus einem Programm (das Buch der Anweisungen), einem gewissen Gedächtnis (die Papiere und die Dateien), einer CPU, die den Anweisungen (der Mann) folgt, und einem Mittel zur Abschreibung von Symbolen in Erinnerung (der Bleistift und der Emittent). Eine Maschine mit diesem Design ist in der theoretischen Computerwissenschaft als "Vollendung" bekannt, weil sie über die notwendigen Maschinen verfügt, um alle Berechnungen durchzuführen, die ein Turing-Maschine tun kann, und daher ist es in der Lage, eine schrittweise Simulation aller anderen digitalen Maschinen durchzuführen, da genügend Speicher und Zeit. Alan Turing schreibt, „alle digitalen Computer sind in einem vernünftigen Maße gleichwertig“. Die weithin akzeptierte Kirche – das ist der Ansicht, dass jede Funktion, die durch ein wirksames Verfahren komparierbar ist, durch eine Turing-Maschine komparabel ist. Die Turing-Überwachung des chinesischen Raums bedeutet, dass alles andere digitale Computer tun kann (wenn auch viel langsamer). Wenn der chinesische Raum nicht oder nicht ein chinesischer Sprache enthalten kann, kann kein anderer digitaler Computer einen Gedanken machen. Manche Antworten auf Searle beginnen mit der Argumentation, dass der Raum, wie beschrieben, kein chinesischer Geist haben kann.Argumente dieser Form nach Stevan Harnad sind "keine Refutation (aber eher eine Bestätigung) des chinesischen Raums, da diese Argumente tatsächlich bedeuten, dass keine digitalen Computer denken. Es gibt einige Kritiker, wie Hanoch Ben-Yami, die argumentieren, dass der chinesische Raum nicht alle Fähigkeiten eines digitalen Computers simuliert, wie es in der Lage ist, die aktuelle Zeit zu bestimmen. Ein vollständiges Argument Searle hat eine formellere Version des Arguments erstellt, das der chinesische Raum ist. 1984 stellte er die erste Version vor. Die nachstehende Version ist ab 1990. Der einzige Teil des Arguments, das umstritten sein sollte, ist A3 und es ist der Punkt, dass der chinesische Raum für die Prüfung bestimmt ist. Er beginnt mit drei Axioms: (A1) "Programme sind formal (syntactic). In einem Programm wird die DNA verwendet, um Symbolen zu manipulieren und die semantischen der Symbole nicht zu berücksichtigen. Sie weiß, wo sie die Symbole setzen und wie sie umkehren, aber sie wissen nicht, was sie für oder was sie bedeuten. Für das Programm sind die Symbole nur physische Gegenstände wie andere.(A2) „Minds haben geistige Inhalte (Entik)“. Im Gegensatz zu den von einem Programm verwendeten Symbolen haben unsere Gedanken Sinn: Sie vertreten Dinge und wissen, was es ist.(A3) „Syntax von sich selbst ist weder für semantische Zwecke noch ausreichend. Dies ist das, was der chinesische Raum für den Nachweis hat: Der chinesische Raum verfügt über eine DNA (da es einen Mann gibt, in dem sich die Symbole umziehen). Der chinesische Raum hat keine semantischen (derzeit gibt es laut Searle keine oder nichts im Raum, in dem sich die Symbole verstehen. Es reicht daher, dass die DNA nicht ausgestaltet wird. Searle stellt fest, dass diese direkt zu diesem Schluss führen: (C1) Programme sind weder für die Einstellung noch ausreichend. Es sollte ohne Kontroversen aus den ersten drei folgen: Programme haben keine semantischen. Programme verfügen nur über eine Kombination, und die DNA ist für semantische Stoffe unzureichend. Jeder Geist hat semantisches. Keine Programme sind daher Gedanken. Es geht darum, zu zeigen, dass künstliche Intelligenz niemals eine Maschine mit einem Geist produzieren kann, indem sie Programme, die Symbole manipulieren, schreiben. Im übrigen geht es um ein anderes Thema. Ist das menschliche Gehirn ein Programm? In anderen Worten ist die Rechentheorie des Geistes korrekt? Er beginnt mit einemxiom, der den grundlegenden modernen wissenschaftlichen Konsens über Gehirn und Köpfe zum Ausdruck bringen soll: (A4) Gehirns führen Köpfe. Searle behauptet, dass wir sofort und uneinheitlich davon ausgehen können, dass: (C2)Any anderes System, das in der Lage ist, Köpfe zu verursachen, überhöhte Befugnisse (mindestens) verfügen müssen, die denen der Gehirn entsprechen. Gehirne müssen etwas haben, das eine Denkweise verursacht. Wissenschaft muss noch genau bestimmen, was es ist, aber es muss vorhanden sein, denn es gibt Köpfe. Searle ruft es "kausale Befugnisse" auf, ist unabhängig vom Gehirn, um einen Geist zu schaffen. Wenn nichts anderes ein Gefühl haben kann, muss es "equivalente kausalische Befugnisse" haben. Aus diesem Grund entwirft er die weiteren Schlussfolgerungen: (C3)Any artifact, die psychische Phänomene, ein künstliches Gehirn hervorgebracht haben, müßte in der Lage sein, die spezifischen ursächlichen Kompetenzen von Gehirnen zu verdoppeln, und es könnte nicht tun, dass gerade ein förmliches Programm läuft. Dies folgt aus C1 und C2: Es kann kein Programm zu einem Geist führen, und "equivalente kausalische Kompetenzen" stellen Köpfe her, folgt, dass Programme nicht "equivalente kausale Befugnisse" haben."(C4)Die Art und Weise, wie menschliche Gehirne tatsächlich psychische Phänomene erzeugen, kann nicht allein durch ein Computerprogramm. Da Programme nicht "equivalente kausalische Befugnisse" "equivalente kausalische Kompetenzen" schaffen Köpfe, und Gehirn stellen Köpfe her, folgt es, dass Gehirn keine Programme zur Erstellung von Denkansätzen verwenden. Kommentare zu dem Argument von Searle können nach dem, was sie vorweisen, klassifiziert werden: Personen, die chinesische Sprache sprechen Diejenigen, die zeigen, wie sinnlose Symbole sinnvoll sind Diejenigen, die vorschlagen, dass der chinesische Raum in irgendeiner Weise neu gestaltet werden sollte, was behauptet, dass das Argument von Searle irreführend ist, die argumentieren, dass das Argument falsche Annahmen zu subjektiven Erfahrungen macht und daher nichts von den Argumenten (Robot und Gehirnsimulation, z.B.) in mehrere Kategorien eingreift. Systeme und Antworten auf virtuelles Denken: Diese Antworten versuchen, die Frage zu beantworten: denn der Mann im Raum spricht nicht von China, wo ist der Geist, der tut? In diesen Antworten geht es um die wichtigsten ontologischen Fragen des Geistes gegenüber Körper und Simulation gegenüber der Realität. Alle Antworten, die den Geist im Raum erkennen, sind Versionen der "Systemantwort". Systemantwort Die grundlegende Version macht deutlich, dass es das "Whole System" ist, das China versteht. Obwohl der Mann nur Englisch versteht, wenn er mit dem Programm kombiniert wird, bilden sie ein System, das China verstehen kann. "Here, das Verständnis ist nicht der bloßen Person zugeschrieben; vielmehr ist es dem gesamten System zuzuschreiben, dessen Teil er ist", erklärt Searle. Die Tatsache, dass der Mensch China nicht versteht, ist irrelevant, weil es nur das System als Ganzes ist. Searle weist darauf hin, dass (in dieser einfachen Version der Antwort) das System nichts mehr ist als eine Sammlung gewöhnlicher materieller Gegenstände; es verleiht ihm die Befugnis, "die Verbindung dieser Person und des Papiers" zu verstehen, ohne dass alles getan wird, um zu erklären, wie diese Steine zu einem bewussten Denkprozess geworden sind. Searle argumentiert, dass keine vernünftige Person mit der Antwort zufrieden sein sollte, es sei denn, sie sind "unter der Ideologie"; Um diese Antwort fern plausibel zu sein, muss man sie annehmen, dass das Bewusstsein das Produkt eines Informationsverarbeitungssystems sein kann und nicht die tatsächliche Biologie des Gehirns erfordert. Searle reagiert dann mit der Vereinfachung dieser Liste von Gegenständen: er fragt, was passiert, wenn der Mann die Regeln erstickt und alles in seinem Kopf hält? Dann besteht das gesamte System aus einem einzigen Gegenstand: der Mensch selbst. Searle argumentiert, dass das System China nicht verstehen könne, wenn der Mensch nicht weiß, weil das System jetzt "das System" und "der Mann" beide genau denselben Gegenstand beschreiben. Kritik an der Reaktion von Searle argumentiert, dass das Programm den Menschen erlaubt hat, zwei Köpfe in einem Kopf zu haben. Wenn wir eine Art der Datenverarbeitung übernehmen, kann die Rechentheorie zwei Berechnungen berücksichtigen, die einmal auftreten, nämlich (1) die Berechnung für die Universalprogrammierbarkeit (die von der Person und den Druckstoffen unabhängig von jedem bestimmten Programminhalt betrieben wird) und (2) die Berechnung der Turing-Maschine, die durch das Programm beschrieben wird (die durch alle, einschließlich des spezifischen Programms, sofort verwendet wird). Die Berechnungstheorie erklärt daher die offene Möglichkeit, dass die zweite Berechnung im chinesischen Raum ein menschliches separiertes semantisches Verständnis der chinesischen Inputs auslösen könnte. Der Schwerpunkt liegt auf der Turing-Maschine statt auf der Person. Aus Sicht von Searle ist dieses Argument jedoch kreisförmig. Die Frage ist, ob das Bewusstsein eine Form der Informationsverarbeitung ist, und diese Antwort verlangt, dass wir diese Annahme machen. Mehr anspruchsvollere Versionen der Systeme antworten, um genauer zu ermitteln, was "das System" ist und in welcher Weise sie beschreiben. Laut diesen Antworten könnte das "Anmerken, das Chinesisch spricht" so sein, wie: die Software, ein Programm, ein "fortgehendes Programm", eine Simulation des "neural korrelativen Bewusstseins", das "funktionelle System", ein "vereinfachtes Denken", ein "emergentes Eigentum" oder "ein virtuelles Denken" (Marvin Minsky's Version der Systeme, unten beschrieben). Antwort auf den virtuellen Geist In der Computerwissenschaft wird der Begriff virtuellen verwendet, um ein in einem Computer (oder Computernetz) vorhandenes Objekt zu beschreiben, nur weil Software es gibt. Objekte innerhalb von Computern (einschließlich Dateien, Merkblätter und so auf) sind alle virtuellen Objekte, außer für die elektronischen Komponenten des Computers. Minsky argumentiert auch, ein Computer kann einen Geist enthalten, der praktisch im gleichen Sinne wie virtuelle Maschinen, virtuelle Gemeinschaften und virtuelle Realität ist. David Cole stellt fest, dass zwei Simulationen gleichzeitig auf einem System durchgeführt werden könnten, um die Unterscheidung zwischen den oben genannten einfachen Systemen und der virtuellen Antwort zu klären. Obwohl es nur ein System gibt, kann es mehrere "virtuale Köpfe" geben, so dass das System nicht der Geist sein kann. Searle reagiert darauf, dass ein solcher Geist am besten eine Simulation ist und schreibt: "Nos setzt voraus, dass Computersimulationen eines fünfarmigen Feuers die Nachbarschaft im Niedergang oder eine Computersimulation eines Regensturms uns alle erschüttern werden. " Nicholas Angstn reagiert darauf, dass die Simulation für einige Dinge genauso gut ist wie wirklich. " Wenn wir die Taschenrechnerfunktion auf einem Desktop-Computer aufsuchen, erscheint das Bild eines Taschenrechners auf dem Bildschirm. Wir beklagen nicht, dass "es nicht wirklich ein Rechner ist", denn die physikalischen Eigenschaften des Geräts sind nicht betroffen. Die Frage ist der Mensch wie der Taschenrechner, der im Wesentlichen aus Informationen besteht? Oder ist der Geist wie der Regensturm, etwas anderes als ein Computer und nicht realisierbar in voller Computersimulation? Seit Jahrzehnten hat diese Frage der Simulation AI-Forscher und Philosophen dazu geführt, zu prüfen, ob der Begriff „synthetische Intelligenz“ besser geeignet ist als die gemeinsame Beschreibung solcher Erkenntnisse als künstlicher Natur. " Diese Antworten liefern eine Erklärung von genau dem, was China versteht. Wenn es etwas neben dem Mann im Raum gibt, der China verstehen kann, kann Searle nicht argumentieren, dass (1) der Mann nicht China verstehen kann, weshalb (2) nichts im Raum ist. Laut denen, die diese Antwort abgeben, zeigt das Argument von Searle nicht, dass "starke AI" falsch ist. Diese Antworten liefern selbst keine Beweise dafür, dass eine starke AI wahr ist. Sie zeigen nicht, dass das System (oder der virtuelle Geist) China versteht, andere als die hypothetische Prämisse, dass es den Turing Test führt. Searle argumentiert, dass der chinesische Raum, wenn wir starke AI fern plausibel betrachten wollen, ein Beispiel ist, das eine Erklärung erfordert, und es ist schwierig oder unmöglich zu erklären, wie das Bewusstsein aus dem Raum entstehen könnte oder wie das System das Bewusstsein hätte. Searle schreibt "die Systeme beantworten einfach die Frage, indem sie darauf bestanden, dass das System China verstehen muss" und damit die Frage oder Hoffnung ungleichmäßig zirkuliert. Roboter und semantische Antworten: Feststellung der Bedeutung Was die Person im Raum betrifft, sind die Symbole einfach sinnlos. Kommt der chinesische Raum wirklich zu verstehen, was er sagt, dann müssen die Symbole ihre Bedeutung von irgendwo wahrnehmen. Diese Argumente versuchen, die Symbole an die von ihnen symbolisierten Dinge zu verbinden. In diesen Antworten geht es um die Bedenken von Searle in Bezug auf die Absichtsmäßigkeit, symbolisieren Sie Boden und die DNA gegenüber semantischen. Roboter reagierte darauf, dass statt eines Raums das Programm in einen Roboter aufgenommen wurde, der mit seiner Umwelt umkehren und interagieren könnte. Dies würde eine "kausale Verbindung" zwischen den Symbolen und deren Darstellung ermöglichen. Kommentare von Hans Moravec: "Wenn wir einen Roboter auf ein mit Gründen versehenes Programm umstellen könnten, brauchen wir nicht mehr eine Person, um die Bedeutung mehr zu verleihen: es würde aus der Welt kommen. " Searle antwortet, dass einige der Beiträge direkt von einer Kamera auf einem Roboter stammen, und einige der Outputs wurden verwendet, um die Waffen und Beine des Roboters zu manipulieren. Jedoch verfolgt die Person im Raum immer noch die Regeln und weiß nicht, was die Symbole bedeuten. Searle schreibt "he nicht, was in die Augen des Roboters fällt" (Siehe den Raum der Mary für ein ähnliches Denkversuch). Man kann sagen, dass der Raum, wie Searle beschreibt, mit der Welt verbunden ist: durch die chinesischen Redner, dass er mit und durch die Programmträger, die die Wissensbasis in seinem Dateikabinett entworfen haben. Die Symbole sind bereits sinnvoll, sie sind für ihn gerade nicht sinnvoll. Searle sagt, dass die Symbole nur eine abgeleitete Bedeutung haben, wie die Bedeutung der Worte in Bücher. Die Bedeutung der Symbole hängt vom bewussten Verständnis der chinesischen Redner und der Programmteilnehmer außerhalb des Raums ab. Das Zimmer wie ein Buch hat kein eigenes Verständnis. Know-how / Kontextantwort Manche haben argumentiert, dass die Bedeutung der Symbole aus einem umfassenden Hintergrund der im Programm enthaltenen gemeinsamen Kenntnisse und der Anmeldeschränke kommen würde. Dies wäre ein Kontext, der den Symbolen ihre Bedeutung verleihen würde. Searle ist sich darin einig, dass dieser Hintergrund existiert, aber er stimmt nicht zu, dass er in Programme eingebaut werden kann. Hubert Dreyfus hat auch die Idee kritisiert, dass der Hintergrund symbolisch repräsentiert werden kann. Jede dieser Vorschläge ist die Antwort von Searle: keine Frage, wie viel Wissen in das Programm geschrieben wird und nicht, wie das Programm mit der Welt verknüpft ist, ist er nach Regeln immer noch im Raum enthalten. Seine Handlungen sind syntierbar und dies kann ihm nie erklären, was die Symbole stehen. Searle schreibt „syntax ist für semantische Stoffe unzureichend. „Wie immer, für diejenigen, die akzeptieren, dass die Maßnahmen von Searle einen Geist simuliert, der von seinem eigenen getrennt ist, ist die wichtige Frage nicht, was die Symbole für Searle bedeuten, was wichtig ist, was sie für die virtuelle Idee bedeuten. Searle ist zwar im Raum gefangen, aber das virtuelle Denken ist nicht: es ist an die Außenwelt durch die chinesischen Redner angeschlossen, es spricht über die Programmteilnehmer, die ihr weltweites Wissen vermitteln, und über die Kameras und andere Sensoren, die Roboter liefern können. Gehirnsimulation und verwandte Antworten: Umgestaltung des Raums Diese Argumente sind alle Versionen der Systeme, die eine bestimmte Art von System als wichtig bezeichnen; sie erkennen einige besondere Technologien an, die ein Verständnis in einer Maschine schaffen würden. () Der Roboter und die „gemeinsamen Kenntnisse“ sind ebenfalls eine bestimmte Art von System als wichtig. Brain  Simulator reagiert darauf, dass das Programm im Detail die Aktion jedes Neuronen im Gehirn eines chinesischen Sprechers im Detail simuliert. Dies stärkt die Untufung, dass es keinen signifikanten Unterschied zwischen dem Betrieb des Programms und dem Betrieb eines lebenden menschlichen Gehirns gibt. Searle antwortet, dass eine solche Simulation die wichtigen Merkmale des Gehirns nicht – die Kausal- und Absichtsstaaten enthält. Searle ist ein Anlaß dafür, dass "menschliche psychische Phänomene [are] von den tatsächlichen physikalischen und chemischen Eigenschaften des menschlichen Gehirns abhängig sind." Darüber hinaus argumentiert er:[I]magine, der anstelle eines monolingualen Mannes in einem von uns gestrichenen Symbol eine Reihe von Wasserrohren mit Ventilen verbindet. Wenn der Mann die chinesischen Symbole erhält, sieht er in dem Programm, das in englischer Sprache geschrieben ist, die ihn abschalten müssen. Jede Wasserverbindung entspricht einem Konsortium im chinesischen Gehirn, und das gesamte System wird so stark gefestigt, dass nach dem Einsatz aller richtigen Fänge, die nach dem Wenden auf alle richtigen Balken, die chinesischen Antworten am Ende der Serie von Rohren. Wo ist das Verständnis in diesem System? China ergreift als Input, er simuliert die formale Struktur der Synaps des chinesischen Gehirns und verleiht dem chinesischen Land als Output. Man verstehe aber nicht, und weder die Wasserrohre noch die Wasserrohre, und wenn wir versucht werden, was ich der absurden Ansicht ist, dass eine gewisse Verbindung von Menschen und Wasserrohren verstehen, daran erinnern, dass der Mensch grundsätzlich die formale Struktur der Wasserrohren umkehren und alle "Neuron-Firings" in seiner Vorstellung tun kann. Zwei Variationen der Gehirn- Simulator-Beantwortung sind das China Gehirn und das Hirnreplacement-Szenario. China Gehirn Was, wenn wir jeden Bürger von China auffordern, einen Neuron zu simulieren, wobei das Telefonsystem die Verbindungen zwischen Axons und Dendriten simuliert? In dieser Version scheint es offensichtlich, dass keine Person verstehen würde, was das Gehirn sagen könnte. Es ist auch offensichtlich, dass dieses System funktionell gleichwertig wäre, wenn das Bewusstsein eine Funktion hat, würde dieses System bewusst sein. Brain-Ersatz-Szenario In diesem Zusammenhang sind wir gefragt, dass Ingenieure einen kleinen Computer entwickelt haben, der die Aktion eines einzelnen Neuronen simuliert. Was würde passieren, wenn wir zu einer Zeit einen Neuron ersetzen? Legt man ein, würde nichts tun, um sich bewusst zu machen. Legt man alle von ihnen ab, würde einen digitalen Computer schaffen, der ein Gehirn simuliert. Wenn Searle richtig ist, muss das Bewusstsein während des Verfahrens verschwinden (entweder nach und nach). Kritiker von Searle argumentieren, dass es während des Verfahrens keinen Sinn geben würde, wenn er geltend machen kann, dass bewusstes Bewusstsein endet und sinnlose Simulation beginnt. Searle erwartet, dass Sie die Kontrolle Ihres externen Verhaltens durch die Gehirnprothese "Sie finden, auf Ihre gesamte Amazement, verlieren. Sie finden zum Beispiel, dass Sie, wenn die Ärzte Ihre Vision testen, sagen, dass wir vor Ihnen ein rotes Objekt halten; wir sagen uns, was Sie sehen. Sie wollen nicht "Ich kann nichts sehen. Ich werde völlig blind.“ Sie hören jedoch Ihre Stimme in einer Weise, die völlig außerhalb Ihrer Kontrolle ist, "Ich sehe einen roten Gegenstand vor mir"[]. [Y]unser bewusste Erfahrung schrumpft langsam zu nichts, während Ihr externes observables Verhalten unverändert bleibt.“(Siehe Schiff von diesemus für einen ähnlichen Denkversuch). Anschluss Antworten In engem Zusammenhang mit der Gehirn- Simulator-Beantwortung behauptet dies, dass eine massive Parallelanbindungsarchitektur in der Lage wäre, zu verstehen. Kombinationslösung Mit dieser Antwort kombiniert der Roboter mit der Gehirnsimulationslösung, was darauf hindeutet, dass eine Gehirnsimulation, die mit der Welt über einen Roboter verbunden ist, einen Blick haben könnte. Viele Mansionen / warten bis zum nächsten Jahr Künftige bessere Technologie wird es ermöglichen, Computer zu verstehen. Searle ist sich darin einig, dass dies möglich ist, hält aber diesen Punkt für irrelevant. Searle ist sich darin einig, dass es Muster geben könnte, die eine Maschine zum Verständnis führen würden. Diese Argumente (und die Roboter- oder die gemeinsame Wissensanalyse) erkennen einige spezielle Technologien an, die dazu beitragen würden, ein Verständnis in einer Maschine zu schaffen. Sie können auf zweierlei Weise ausgelegt werden: entweder behaupten (1) Diese Technologie ist für das Bewusstsein erforderlich, der chinesische Raum ist nicht oder kann diese Technologie nicht umsetzen, weshalb der chinesische Raum den Turing-Test nicht oder (auch wenn es getan hat) nicht bewusst hätte. Oder sie können behaupten, dass (2) es einfacher ist, zu sehen, dass der chinesische Raum einen Geist hat, wenn wir diese Technologie als Mittel zur Schaffung dieser Technologie verstehen. In einem ersten Fall, in dem Merkmale wie ein Roboter oder eine Anschlussarchitektur erforderlich sind, behauptet Searle, dass eine starke AI (wie er sie versteht) aufgegeben wurde. Der chinesische Raum verfügt über alle Elemente einer Turing-Vollmaschine und ist somit in der Lage, jede digitale Berechnung zu vereinfachen. Wenn Searle Raum den Turing-Test nicht passieren kann, gibt es keine andere digitale Technologie, die den Turing-Test anpassen könnte. Wenn der Raum von Searle den Turing-Test passieren könnte, aber immer noch keinen Sinn hat, reicht der Turing-Test nicht aus, um festzustellen, ob der Raum einen Blick hat. Entweder verleugnet sie eine oder andere Positionen Searle ist der Ansicht, dass er sein Argument als "starke AI" bezeichnet. Insbesondere verleugnet das Gehirn die starke AI, wenn sie davon ausgehen, dass es keine einfachere Möglichkeit gibt, den Geist zu beschreiben als ein Programm zu erstellen, das genauso wie das Gehirn ist. Ich denke an die Idee einer starken AI, dass wir nicht wissen müssen, wie das Gehirn funktioniert, um zu wissen, wie der Geist funktioniert." Kommt die Berechnung nicht zu einer Erklärung des menschlichen Geistes, so hat die starke AI nach Searle gescheitert. Andere Kritiker sind der Ansicht, dass das von Searle beschriebene Zimmer in der Tat einen Blick hat, aber sie argumentieren, dass es schwierig ist, die Beschreibung von Searle korrekt zu sehen, aber irreführend. Indem sie den Raum realistischer umgestalten, hoffen sie, dies offensichtlicher zu machen. In diesem Fall werden diese Argumente als Appelle zur Unterweisung verwendet (siehe nächsten Abschnitt). Konkret kann der Raum einfach wie leicht umgestaltet werden, um unsere Studien zu schwächen. Ned Blockhead Argument deutet darauf hin, dass das Programm in der Theorie in einen einfachen Überblick über die Regeln der Form "wenn der Nutzer S schreibt, mit P und Goto X antworten könnte". Jedes Programm kann grundsätzlich in dieser Form neugeschrieben werden, selbst eine Gehirnsimulation. Im Blockhead-Szenario ist der gesamte geistige Staat im Brief X verborgen, der eine Gedächtnisadresse darstellt – eine Zahl, die mit der nächsten Regel verbunden ist. Es ist schwer zu erkennen, dass eine unmittelbare bewusste Erfahrung eines jeden in einer einzigen großen Zahl erfasst werden kann, doch genau das ist genau das, was "starke AI"-Anforderungen betrifft. Auf der anderen Seite würde ein solcher Nachschlagstisch weitgehend (zu dem Zeitpunkt, zu dem es physisch unmöglich ist), und die Staaten könnten daher äußerst spezifisch sein. Searle argumentiert, dass das Programm zwar schriftlich ist oder aber die Maschine mit der Welt verbunden ist, doch wird der Geist durch eine einfache, schrittweise digitale Maschine (oder Maschinen) simuliert. Diese Maschinen sind immer genauso wie der Mann im Raum: Sie verstehen nichts und sprechen nicht mit China. Sie sind einfach feindlich und wissen, was sie bedeuten. Searle schreibt: "Ich kann ein formelles Programm haben, das Sie mögen, aber ich verstehe noch nichts. Geschwindigkeit und Komplexität: Appelle zur Unterweisung Die folgenden Argumente (und die intuitiven Interpretationen der oben genannten Argumente) erklären nicht direkt, wie ein chinesischer Gedanken im Raum von Searle existieren könnte, oder wie die Symbole, die er angreift, sinnvoll werden könnten. Indem sie Zweifel an der Ausbildung von Searle aufwerfen, unterstützen sie jedoch andere Positionen wie das System und die Roboterantworten. Wenn diese Argumente akzeptiert werden, hindern Searle daran, zu behaupten, dass sein Abschluss offensichtlich ist, indem er die Voraussetzungen für seine Sicherheit untergraben. Mehrere Kritiker sind der Ansicht, dass das Argument von Searle ausschließlich auf Studien beruht. Ned Block schreibt "Searle's Argument hängt davon ab, ob bestimmte Unternehmen nicht denken. " Daniel Dennett beschreibt das Argument des chinesischen Raums als irreführende "Intuitionpumpe" und schreibt "Searle's Gedankenversuch, illegal, auf Ihrem Fall zu einfach, ein unerheblicher Fall und die offensichtliche Schlussfolgerung daraus. " Manche der oben genannten Argumente funktionieren auch als Appelle zur Intuation, insbesondere diejenigen, die es zu tun scheinen, scheinen plausibel zu sein, dass der chinesische Raum einen Geist enthält, der den Roboter, das gemeinsame Wissen, die Gehirnsimulation und die zugehörigen Antworten einschließt. Mehrere der oben genannten Antworten befassen sich auch mit dem spezifischen Problem der Komplexität. In seiner Antwort wird betont, dass ein künstliches, künstliches Intelligenzsystem so komplex und miteinander verbunden sein muss wie das menschliche Gehirn. In der gemeinsamen Antwort wird betont, dass jedes Programm, das einen Turingtest verabschiedet hat, "eine extraordinierte, anspruchsvolle und multilayerierte System sein muss, das mit 'Weltkenntnisse' und Meta-Knowledge und Meta-meta-Knowledge verknüpft ist", so Daniel Dennett. Geschwindigkeit und Komplexität Die Geschwindigkeit, bei der menschliche Gehirnprozessinformationen (um einige Schätzungen) 100 Milliarden Operationen pro Sekunde sind. Mehrere Kritiker weisen darauf hin, dass der Mann im Raum wahrscheinlich Millionen von Jahren nehmen würde, um auf eine einfache Frage zu reagieren, und würden "filierende Kabinette" von Astronomen erfordern. Dies bringt die Klarheit der Seelle in Zweifel. Eine besonders lebhafte Version der Geschwindigkeit und Komplexität ist von Paul und Patricia Churchland. Sie schlagen dieses analoge Experiment vor: Lichtsaal von Kircheland: Der "Consider ein dunkles Zimmer mit einem Mann, der einen Magnet hält oder einen beladenen Gegenstand hat. Liegt der Mensch den Magnet auf und nach unten, so wird er nach der Theorie von Maxwell zur künstlichen Luminance (AL) einen Verbreitungskreis elektromagnetischer Wellen einleiten und wird daher Licht sein. Aber wie alle von uns, die mit Magneten oder berechneten Kugeln gut wissen müssen, ihre Kräfte (oder alle anderen Kräfte in diesem Bereich), auch wenn man in Bewegung geht, schaffen überhaupt keine Luminance. Man ist nicht denkbar, dass Sie wirkliche Luminance nur durch die Bewegung von Kräften rund! " Das Problem ist, dass er den Magnet auflegen und etwas wie 450 Billionen Mal pro Sekunde verringern müsste, um etwas zu sehen. Stevan Harnad ist kritisch für schnelle und komplexe Antworten, wenn sie über die Behandlung unserer Studien hinausgehen. Er schreibt "Einige hat einen zügigen und zeitlichen Anbau gemacht, der feststellt, dass der rechnerische Übergang ins geistige Zeitalter, wenn er beschleunigt auf die richtige Geschwindigkeit hinführt. Man sollte klar sein, dass es sich nicht um eine Widersprüchlichkeit handelt, sondern nur um eine Ad-hoc-Diagnose (wie die Ansicht ist, dass es nur eine Frage der Ratifizierung bis zum richtigen Grad der Komplexität ist). "Searle argumentiert, dass seine Kritiker auch auf Unterweisungen angewiesen sind, aber seine Gedanken der Gegner haben keine empirische Grundlage. Er schreibt vor, dass eine Person, um die "Systemantwort" als fern plausibel zu betrachten, "unter der Kontrolle einer Ideologie" sein muss. Das System reagiert nur dann sinnvoll (auf Searle), wenn man davon ausgeht, dass jedes System das Bewusstsein haben kann, nur weil es ein System mit dem richtigen Verhalten und funktionellen Teilen ist. Diese Annahme, die er argumentiert, ist angesichts unserer Erfahrungen mit dem Bewusstsein nicht zehnbar. Andere Köpfe und Spiele: Bedeutungslosigkeit mehrere Antworten argumentieren, dass das Argument von Searle irrelevant sei, weil seine Annahmen über Geist und Bewusstsein fehlerhaft sind. Searle ist der Ansicht, dass Menschen ihr Bewusstsein, ihre Absichtserklärung und die Natur des Geistes jeden Tag unmittelbar kennen und dass diese Erfahrung des Bewusstseins nicht in Frage gestellt wird. Er schreibt vor, dass wir "die Realität und die Wissensfähigkeit des Geistes vorbringen müssen. " Diese Antworten stellen die Frage, ob Searle mit seinem eigenen Bewusstseinserfahrung gerechtfertigt ist, um festzustellen, dass es mehr als mechanische Symbolverarbeitung ist. Insbesondere die anderen Köpfe sprachen sich dafür aus, dass wir unsere Erfahrungen mit dem Bewusstsein nicht nutzen können, um Fragen zu anderen Köpfen (auch im Hinblick auf einen Computer) zu beantworten, und die Antwort von Epiphenomena argumentiert, dass das Bewusstsein von Searle nicht in dem Sinne existiert, dass Searle es für sich hält. Andere Worte In dieser Antwort wird darauf hingewiesen, dass das Argument von Searle eine Version des Problems anderer Köpfe ist, die auf Maschinen angewendet werden. Man kann nicht bestimmen, ob die subjektive Erfahrung anderer Menschen die gleiche ist wie unsere eigene. Wir können ihr Verhalten nur untersuchen (d.h. indem wir ihnen unseren eigenen Turing Test geben). Kritiker von Searle argumentieren, dass er den chinesischen Raum zu einem höheren Standard hält als wir eine gewöhnliche Person halten würden. Nilss schreibt "Wenn ein Programm so funktioniert, als ob es sich vervielfacht hat, würden die meisten von uns sagen, dass es tatsächlich ist, sich zu vermehren. Ich weiß, dass Searle nur dann befischen kann, wenn er tief über diese Fragen nachdenken würde. Aber selbst wenn ich mit ihm nicht einverstanden bin, ist seine Simulation ziemlich gut, so dass ich bereit bin, ihn mit wirklichem Denken zu betrauen." AlanTuring erwartet das Argument von Searle (das er 1950 "The Argument of Knowledgeness" nannte) und stellt die anderen Köpfe vor. Er wies darauf hin, dass die Menschen nie das Problem anderer Köpfe im Umgang mit ihnen betrachten. Er schreibt vor, dass "anstatt ständig über diesen Punkt zu sprechen ist, dass es üblich ist, das ordentliche Übereinkommen zu haben, dass alle denken." Der Turing-Test erweitert lediglich dieses "Polite-Übereinkommen" auf Maschinen. Er will nicht das Problem anderer Köpfe (für Maschinen oder Personen) lösen, und er denke nicht, wir müssen. Eliminative Materialismus reagiert auf mehrere Philosophen, dass das Bewusstsein, wie Searle beschreibt, nicht existiert. Diese Position wird manchmal als eliminativer Materialismus bezeichnet: Die Ansicht, dass das Bewusstsein ein Grundstück ist, das auf eine rein mechanische Beschreibung reduziert werden kann, und dass unsere Erfahrungen mit dem Bewusstsein, wie Daniel Dennett sie beschreibt, eine "Nutzerin Illusion". Andere geistige Eigenschaften, wie die ursprüngliche Absichtserklärung (auch „Gemeinsam“, „Inhalte“ und „semantische Charakter“), werden häufig als etwas Besonderes über Überzeugungen und andere Haltungen angesehen. Eliminatives Materialismus hält fest, dass propositionale Haltungen wie Überzeugungen und Wünsche, unter anderem vorsätzliche geistige Staaten, die Inhalte haben, nicht existieren. eliminativer Materialismus ist das richtige wissenschaftliche Konto der menschlichen Kodierung, dann muss die Annahme des chinesischen Raumsvorbringens abgelehnt werden, dass "sie haben geistige Inhalte (semantics)" abzulehnen sind. Stuart Russell und Peter Norvig argumentieren, dass wir, wenn wir die Absichtsbeschreibung von Searle akzeptieren, das Bewusstsein und den Geist akzeptieren müssen, dass das Bewusstsein Epiphenomenal ist: dass es "nicht Schatten" gibt, dass es in der Außenwelt nicht nachweisbar ist. Man vertrat die Auffassung, dass Searle über die "Kenntlichkeit des Geistes" und in seiner Überzeugung, dass es "kausale Eigenschaften" in unseren Neuronen gibt, die das Denken begründen. Sie weisen darauf hin, dass diese ursächlichen Eigenschaften von Searle nicht von außen erkannt werden können, ansonsten konnte der chinesische Raum den Turingtest nicht passieren – die Menschen außerhalb hätten in der Lage sein, dort einen chinesischen Sprecher zu melden, indem sie ihre ursächlichen Eigenschaften erkennen. Da sie nicht kausale Eigenschaften erkennen können, können sie das Bestehen des Geistes nicht erkennen. Kurz gesagt: Searle's "causale Eigenschaften" und Bewusstsein selbst sind nicht erkennbar, und alles, die nicht entdeckt werden können, existiert nicht oder ist nicht. Daniel Dennett stellt diese Verlängerung auf das Argument Epiphenomena vor. Lieetts Antwort von der natürlichen Auswahl, die von einigen Mutationen geboren wird, dass ein Menschen geboren wird, der nicht über Searle "kausale Eigenschaften" verfügt, aber dennoch genau wie ein Mensch handelt.( Diese Art von Tieren wird als "Spiel" in Gedankenversuchen in der Philosophie des Geistes bezeichnet. Dieses neue Tier würde sich genauso wie jedes andere menschliche und schließlich mehr dieser Spielballons aufbringen. Natürliche Auswahl würde die Schneeballons begünstigen, da ihr Design (wir könnten) etwas einfacher ist. Letztendlich würde der Mensch sterben. Wenn Searle also richtig ist, ist es am wahrscheinlichsten, dass Menschen (wie wir heute sehen) tatsächlich Spielballe sind, die sich dennoch bewusst sind. Man kann nicht wissen, ob wir alle Spiele sind oder nicht. Selbst wenn wir alle Snacks sind, würden wir nach wie vor glauben, dass wir nicht sind. Searle lehnt sich mit dieser Analyse ab und argumentiert, dass "die Untersuchung des Geistes mit solchen Tatsachen beginnt, wie die Menschen Überzeugungen haben, während Thermostate, Telefone und zusätzliche Maschinen nicht . Was wir wollen wissen, ist, was den Blick von Thermostaten und Lebern unterscheidet. " Er sieht es als offensichtlich an, dass wir die Präsenz des Bewusstseins erkennen und diese Antworten abweisen können. Antwort von Newton auf Laser Mike Alder argumentiert, das gesamte Argument sei unfreiwillig, denn es ist nicht nur die Unterscheidung zwischen der Vereinfachung eines Geistes und einer sinnlosen Definition, sondern es ist auch irrelevant, weil keine Versuche oder sogar vorgeschlagen werden können, zwischen den beiden zu unterscheiden. Englische Antwort Margaret Boden lieferte diese Antwort in ihrem Papier "Escaping aus dem chinesischen Raum". " In diesem Zusammenhang schlägt sie vor, dass selbst wenn die Person im Raum den chinesischen Raum nicht kennt, nicht bedeutet sie, dass es im Raum kein Verständnis gibt. Die Person im Raum versteht mindestens das Regelbuch, das zur Bereitstellung von Output-Anmeldungen verwendet wird. Kultur in der populären Kultur Das Argument des chinesischen Raums ist ein zentrales Konzept in Peter Watts Romans Blindsight und (in geringerem Maße) Echopraxia. Es ist auch ein zentrales Thema im Videospiel Virtue’s Letzte Reward und verbindet sich mit dem Konzept des Spiel. In der Saison 4 des amerikanischen Verbrechens Numb3rs gibt es einen kurzen Bezug zum chinesischen Raum. Der chinesische Raum ist auch der Name eines britischen unabhängigen Videospiel-Entwicklungsstudios, das am besten für die Arbeit an experimentellen First-Person-Spielen, wie dem All's Gone to the Rapture, oder Liebe Esther, bekannt ist. Im Videospiel 2016 Der Turing Test erklärt der chinesische Raum für Denkversuche dem Spieler durch eine AI. Siehe auch Computational Modelle des Sprachenerwerbs Emergent Verhalten Nr. echte Scotsman Philosophische Spiele Sorites paradoxe synthetische Intelligenz I Am einen Bericht über die Anrechnung der allgemeinen Darstellungen des Arguments: "chinesischer Raum". Internet Veröffentlichung der Philosophie. Chinesischer Raum-Sache. Wissenschaftsbibliothek der Philosophie, chinesischer Raum, Mark Rosenfelder Quellen, die John Searle betreffen: chinesisches Raumgut von John Searle auf Scholarpä The Chinesischer Raum-Sache, Teil 4 des zweiten September 1999 Interviews mit Searle Philosophie und den Habits des kritischen Denkens in der Geschichte John R. Searle, „Was Ihr Computer Können nicht wissen“ (Überprüfung von Luciano Floridi, Die vierte Revolution: Wie die Infosphäre Is Reshaping Human Wirklichkeit, Oxford University Press, 2014 und Nick Bostrom, Superintelligence: Paths, Dangers, Strategien, University Press, 2014), The New York Review von Büchern (I. Kritiker des Arguments: Eine Flüchtlingseigenschaft von John Searle "chinesischer Raum-Eigenschaft" Archivd 2010-02-03 auf dem Wegback-Maschine, von Bob Murphy Kugel, P. (2004). " Der chinesische Raum ist ein Problem." Verhaltens- und Gehirnwissenschaften.27.doi:10.1017/S0140525X04210044.S2CID 56032408. PDF auf der Homepage des Autors, kritisches Papier auf der Grundlage der Annahme, dass die CR ihre Beiträge (die in China sind) nicht verwenden kann, um ihr Programm (das ist in englischer Sprache) zu ändern. Wolfram Schmied (2004)." chinesisches Zimmer von Searle"arXiv:cs.AI/0403009. John Preston und Mark Bischof, "Gutes in den chinesischen Raum", Oxford University Press, 2002. Kapitel von John Searle, Roger Penrose, Stevan Harnad und Kevin Warwick. Margaret Boden, "Escap aus dem chinesischen Raum"," Kognitive Forschungspapiere Nr. CSRP 092, University of Sussex, School of Kognitive Wissenschaften, 1987, 5.7071, Online PDF, "Auszüge aus einem Kapitel" in der damals unveröffentlichten "Computermodelle of Mind: : Computational Approaches in Theoretische Psychologie", ISBN 0-521-24868-X (1988); in Boden (ed)" Presse, 1989, Kapitel 6; gedruckt in Heil, S.253–266 (1988) (möglicherweise überbrückt); J. Heil (ed.)Philosophy of Mind: Ein Leitfaden und Anthology", Oxford University Press, 2004, Seiten 253–266 (diese Version ist in "Artificial Intelligence in Psychologie")