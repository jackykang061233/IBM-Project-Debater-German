Die Regulierung von künstlicher Intelligenz ist die Entwicklung von Politiken und Gesetzen des öffentlichen Sektors zur Förderung und Regulierung künstlicher Intelligenz (KI); sie ist daher mit der breiteren Regulierung von Algorithmen verbunden. Die regulatorische und politische Landschaft für KI ist ein aufstrebendes Thema in den Zuständigkeiten weltweit, einschließlich in der Europäischen Union und supranationalen Gremien wie IEEE, OECD und anderen. Zwischen 2016-2019 wurde eine Welle von AI Ethics Guidelines veröffentlicht, um die soziale Kontrolle über die Technologie zu erhalten. Die Verordnung gilt sowohl für die Förderung der KI als auch für die Bewältigung der damit verbundenen Risiken. Die KI-Regelung durch Mechanismen wie Review Boards kann auch als soziale Mittel angesehen werden, um das KI-Kontrollproblem zu lösen. Hintergrund 2017 Elon Musk forderte die Regulierung der KI-Entwicklung. Laut NPR war der Tesla-CEO "klarerweise nicht begeistert", um für staatliche Kontrolle zu plädieren, die seine eigene Branche beeinflussen könnte, aber glaubte, dass die Risiken völlig ohne Aufsicht zu hoch sind: "Normalerweise sind die Art und Weise Vorschriften eingerichtet, wenn ein Haufen von schlechten Dingen passieren, gibt es einen öffentlichen Sektor, und nach vielen Jahren ist eine Regulierungsbehörde eingerichtet, um diese Branche zu regulieren. Es dauert ewig. Das war in der Vergangenheit schlecht, aber nicht etwas, das ein grundlegendes Risiko für die Existenz der Zivilisation darstellte". In Reaktion auf einige Politiker drückten Skepsis über die Weisheit der Regulierung einer Technologie, die noch in der Entwicklung ist. Der Intel-CEO Brian Krzanich sagte, dass KI in seiner Kindheit ist und dass es zu früh ist, die Technologie zu regulieren. Anstatt die Technologie selbst zu regulieren, schlugen einige Wissenschaftler vor, gemeinsame Normen zu entwickeln, einschließlich Anforderungen für die Prüfung und Transparenz von Algorithmen, möglicherweise in Kombination mit einer gewissen Form der Garantie. Perspektiven Die Regulierung künstlicher Intelligenz ist die Entwicklung der Politiken und Gesetze des öffentlichen Sektors zur Förderung und Regulierung von KI. Die Verordnung wird jetzt allgemein als notwendig erachtet, um KI zu fördern und damit verbundene Risiken zu bewältigen. Öffentliche Verwaltung und politische Überlegungen konzentrieren sich im allgemeinen auf die technischen und wirtschaftlichen Auswirkungen und auf vertrauenswürdige und menschenzentrierte KI-Systeme, obwohl auch die Regulierung künstlicher Superintelligenzen berücksichtigt wird. Der grundlegende Ansatz zur Regulierung konzentriert sich auf die Risiken und Voreingenommenheiten von AIs zugrunde liegender Technologie, d.h. Bildverarbeitungsalgorithmen, auf der Ebene der Eingangsdaten, der Algorithmustests und des Entscheidungsmodells sowie auf die Frage, ob für potenzielle Empfänger der Technologie Erläuterungen von Voreingenommenheiten im Code verständlich und für die Hersteller technisch machbar sind, zu vermitteln. Die KI-Verordnung könnte von Grundprinzipien abgeleitet werden. Ein 2020 Berkman Klein Center for Internet & Society Meta-Review bestehender Prinzipien, wie die Asilomar-Prinzipien und die Peking-Prinzipien, identifizierte acht solcher Grundprinzipien: Privatsphäre, Rechenschaftspflicht, Sicherheit und Sicherheit, Transparenz und Erklärbarkeit, Fairness und Nichtdiskriminierung, menschliche Kontrolle der Technologie, berufliche Verantwortung und Achtung der menschlichen Werte. Das KI-Recht und die Vorschriften wurden in drei Hauptthemen unterteilt: Governance von autonomen Geheimdienstsystemen, Verantwortung und Rechenschaftspflicht für die Systeme sowie Datenschutz- und Sicherheitsfragen. Ein Ansatz der öffentlichen Verwaltung sieht eine Beziehung zwischen KI-Gesetz und Regulierung, die Ethik der KI und der "AI-Gesellschaft", definiert als Arbeitskräftesubstitution und -transformation, soziale Akzeptanz und Vertrauen in die KI, und die Transformation von Mensch zu Maschine Interaktion. Die Entwicklung von Strategien des öffentlichen Sektors für die Verwaltung und Regulierung von KI gilt auf lokaler, nationaler und internationaler Ebene und in unterschiedlichen Bereichen als notwendig, von der öffentlichen Verwaltung und Rechenschaftspflicht bis zur Strafverfolgung, der Gesundheitsversorgung (insbesondere dem Konzept einer menschlichen Garantie), dem Finanzsektor, der Robotik, autonomen Fahrzeugen, der militärischen und nationalen Sicherheit und dem internationalen Recht. Als Reaktion auf das KI-Kontrollproblem kann die KI-Verordnung als positive soziale Mittel betrachtet werden, um das KI-Kontrollproblem zu bewältigen, d.h. die Notwendigkeit, langfristig nützliche KI zu gewährleisten, wobei andere soziale Reaktionen wie nichts oder Banning als unpraktisch betrachtet werden und Ansätze wie die Verbesserung der menschlichen Fähigkeiten durch Transhumanismus-Ansätze wie Gehirn-Computer-Schnittstellen als potenziell komplementär betrachtet werden. Die Verordnung über die Erforschung künstlicher allgemeiner Intelligenz (AGI) konzentriert sich auf die Rolle von Revisionstafeln, von Universität oder Unternehmen auf internationale Ebene und auf die Förderung der Forschung zu sicherer KI, zusammen mit der Möglichkeit von differentiellen intellektuellen Fortschritten (Prioritisierung risikomindernder Strategien zur KI-Entwicklung) oder die Durchführung internationaler Massenüberwachung zur Durchführung von AGI-Regeln. Zum Beispiel ist die "AGI Nanny" eine vorgeschlagene Strategie, die möglicherweise unter der Kontrolle der Menschheit steht, um die Schaffung einer gefährlichen Superintelligenz zu verhindern und andere große Bedrohungen für das menschliche Wohlbefinden, wie die Subversion des globalen Finanzsystems, anzugehen, bis eine Superintelligenz sicher geschaffen werden kann. Es beinhaltet die Schaffung eines intelligenteren als-menschlichen, aber nicht überintelligenten, künstlichen allgemeinen Geheimdienstes, das mit einem großen Überwachungsnetzwerk verbunden ist, mit dem Ziel, die Menschheit zu überwachen und sie vor Gefahr zu schützen." Die Verordnung der bewussten, ethisch bewussten AGIs konzentriert sich darauf, sie mit der bestehenden menschlichen Gesellschaft zu integrieren und kann in Erwägungen ihres Rechtsstandes und ihrer moralischen Rechte aufgeteilt werden. Die KI-Verordnung wurde als restriktiv angesehen, mit dem Risiko, die Entwicklung von AGI zu verhindern. Globale Leitlinien Die Entwicklung eines Global Governance Board zur Regulierung der KI-Entwicklung wurde bereits 2017 vorgeschlagen. Im Dezember 2018 kündigten Kanada und Frankreich Pläne für ein G7-gestütztes internationales Panel zur künstlichen Intelligenz an, das auf dem Internationalen Panel zum Klimawandel modelliert wurde, um die globalen Auswirkungen von KI auf Menschen und Volkswirtschaften zu untersuchen und AI-Entwicklung zu steuern. Im Jahr 2019 wurde das Panel umbenannt die Global Partnership on AI, aber es ist noch von den Vereinigten Staaten unterstützt werden. Die OECD-Empfehlungen zu KI wurden im Mai 2019 und die G20 AI-Prinzipien im Juni 2019 angenommen. Im September 2019 veröffentlichte das Weltwirtschaftsforum zehn "Aid Government Procurement Guidelines". Im Februar 2020 veröffentlichte die Europäische Union ihr Strategiepapier zur Förderung und Regulierung von KI. Bei den Vereinten Nationen haben mehrere Organisationen begonnen, Aspekte der KI-Verordnung und -Politik zu fördern und zu diskutieren, darunter das UNICRI-Zentrum für KI und Robotik. Auf der 40. Sitzung der UNESCO im November 2019 begann die Organisation einen zweijährigen Prozess, um ein "globales Standard-Setting-Instrument über Ethik der künstlichen Intelligenz" zu erreichen. Um dieses Ziel zu verfolgen, haben UNESCO-Foren und Konferenzen zu KI stattgefunden, um Stakeholder-Ansichten zu sammeln. Der jüngste Entwurf einer Empfehlung zur Ethik der KI der UNESCO-Ad-hoc-Expertengruppe wurde im September 2020 veröffentlicht und enthält eine Aufforderung zur Einreichung von legislativen Lücken. Regionale und nationale Regulierung Die regulatorische und politische Landschaft für KI ist ein aufstrebendes Thema in den Zuständigkeiten weltweit, auch in der Europäischen Union und Russland. Seit Anfang 2016 haben viele nationale, regionale und internationale Behörden begonnen, Strategien, Aktionspläne und Politikpapiere über KI zu verabschieden. Diese Dokumente umfassen eine breite Palette von Themen wie Regulierung und Governance sowie Industriestrategie, Forschung, Talent und Infrastruktur. China Die Verordnung über KI in China richtet sich vor allem an den Staatsrat der PRC am 8. Juli 2017 "A Next Generation Artificial Intelligence Development Plan" (State Council Document No. 35), in dem das Zentralkomitee der Kommunistischen Partei Chinas und der Staatsrat der Volksrepublik China die Regierungsorgane Chinas zur Förderung der KI-Entwicklung aufforderten. Die Verordnung der Fragen der ethischen und rechtlichen Unterstützung für die Entwicklung von KI ist nascent, aber die Politik gewährleistet die staatliche Kontrolle der chinesischen Unternehmen und über wertvolle Daten, einschließlich der Speicherung von Daten über chinesische Nutzer innerhalb des Landes und der obligatorischen Verwendung der nationalen Standards der Volksrepublik China für KI, einschließlich über große Daten, Cloud Computing und industrielle Software. EuroparatDer Europarat (CoE) ist eine internationale Organisation, die die Demokratie der Menschenrechte und die Rechtsstaatlichkeit fördert und 47 Mitgliedsstaaten umfasst, darunter alle 29 Unterzeichner der Kooperationserklärung der Europäischen Union 2018 über künstliche Intelligenz. Der AdR hat einen gemeinsamen Rechtsraum geschaffen, in dem die Mitglieder eine gesetzliche Verpflichtung haben, Rechte zu garantieren, wie sie in der Europäischen Menschenrechtskonvention festgelegt sind. Konkret in Bezug auf die KI: "Der Europarat hat das Ziel, die sich kreuzenden Bereiche zwischen KI und unseren Normen für Menschenrechte, Demokratie und Rechtsstaatlichkeit zu identifizieren und relevante Standard- oder Kapazitätsaufbaulösungen zu entwickeln." Die große Zahl der relevanten Dokumente, die vom CoE identifiziert wurden, umfasst Leitlinien, Charta, Papiere, Berichte und Strategien. Die Autoren dieser KI-Verordnungsdokumente sind nicht auf einen Sektor der Gesellschaft beschränkt und umfassen Organisationen, Unternehmen, Körper und Nationalstaaten. Die meisten Länder der Europäischen Union (EU) haben ihre eigenen nationalen Strategien zur Regulierung von KI, aber diese sind weitgehend konvergent. Die Europäische Union wird von einer europäischen Strategie für künstliche Intelligenz geleitet, die von einer hochrangigen Expertengruppe für künstliche Intelligenz unterstützt wird. Im April 2019 veröffentlichte die Europäische Kommission ihre Ethik-Leitlinien für vertrauenswürdige Künstliche Intelligenz (KI), die darauf mit ihren Politik- und Investitionsempfehlungen für vertrauenswürdige Künstliche Intelligenz im Juni 2019 folgten. Die hochrangige Expertengruppe der EU-Kommission für Künstliche Intelligenz arbeitet an vertrauenswürdiger KI, und die Kommission hat Berichte über die Sicherheits- und Haftungsaspekte von KI und über die Ethik von automatisierten Fahrzeugen herausgegeben. Im Jahr 2020 ersuchte die EU-Kommission um Stellungnahme zu einem Vorschlag für eine spezifische KI-Gesetzgebung, und dieser Prozess läuft fort. Am 2. Februar 2020 veröffentlichte die Europäische Kommission ihr Weißbuch über künstliche Intelligenz - Ein europäischer Ansatz für Exzellenz und Vertrauen. Das Weißbuch besteht aus zwei Hauptbausteinen, einem „ecosystem of excellence“ und einem „ecosystem of trust“. Letzteres beschreibt den Ansatz der EU für einen Regulierungsrahmen für KI. In ihrem vorgeschlagenen Ansatz unterscheidet sich die Kommission zwischen hochgefährlichen und nicht hochgefährdeten KI-Anwendungen. Erster sollte im Rahmen eines künftigen EU-Rechtsrahmens sein. Ob dies im Prinzip durch zwei kumulative Kriterien, kritische Sektoren und kritische Verwendung bestimmt werden könnte. Folgende Schlüsselanforderungen werden für hochgefährdete KI-Anwendungen berücksichtigt: Anforderungen an Schulungsdaten; Daten- und Datenerfassung; Informationspflichten; Anforderungen an Robustheit und Genauigkeit; menschliche Aufsicht; und spezifische Anforderungen an spezifische KI-Anwendungen, wie sie zum Zwecke der diametralen Identifizierung verwendet werden. KI-Anwendungen, die nicht als „Hochrisiko“ eingestuft werden, könnten durch ein freiwilliges Kennzeichnungssystem geregelt werden. In Bezug auf die Einhaltung und Durchsetzung betrachtet die Kommission die vorherigen Konformitätsbewertungen, die "Verfahren zur Prüfung, Prüfung oder Zertifizierung" und/oder "Kontrollen der Algorithmen und der in der Entwicklungsphase verwendeten Datensätze" umfassen könnten. Eine europäische Governance-Struktur für KI in Form eines Rahmens für die Zusammenarbeit der nationalen zuständigen Behörden könnte die Umsetzung des Rechtsrahmens erleichtern. Am 14. April 2021 wurde ein Entwurf von Januar 2021 online verliest, bevor die Kommission ihre offizielle "Vorlage für eine Verordnung zur Festlegung harmonisierter Regeln für künstliche Intelligenz (Künstlerisches Intelligenzgesetz") eine Woche später vorgelegt hat. Dazu gehört ein Vermögen des risikobasierten Ansatzes 2020. Vereinigtes Königreich Das Vereinigte Königreich unterstützte die Anwendung und Entwicklung von KI im Geschäft über die Digital Economy Strategie 2015-2018, die Anfang 2015 von Innovate UK im Rahmen der UK Digital Strategy vorgestellt wurde. Im öffentlichen Bereich wurde von der Abteilung für Digital, Kultur, Medien und Sport, über die Datenethik und das Alan Turing Institute, über die verantwortungsvolle Gestaltung und Umsetzung von KI-Systemen beraten. In Bezug auf Cybersicherheit hat das National Cyber Security Centre Leitlinien zu „Intelligente Sicherheitstools“ herausgegeben. Die US-Diskussionen zur Regulierung von KI in den Vereinigten Staaten haben Themen wie die Aktualität der Regulierung von KI, die Art des föderalen Regulierungsrahmens, um KI zu regieren und zu fördern, einschließlich was Agentur führen sollte, die Regulierungs- und Regierungsbefugnisse dieser Agentur, und wie man Vorschriften angesichts der sich schnell ändernden Technologie, sowie die Rollen von staatlichen Regierungen und Gerichten aktualisieren. Bereits 2016 hatte die Obama-Regierung begonnen, sich auf die Risiken und Vorschriften für künstliche Intelligenz zu konzentrieren. In einem Bericht mit dem Titel Preparing For the Future of Artificial Intelligence hat der National Science and Technology Council einen Präzedenzfall gesetzt, damit Forscher weiterhin neue KI-Technologien mit wenigen Einschränkungen entwickeln können. In dem Bericht heißt es, dass "der Ansatz zur Regulierung von AI-fähigen Produkten zum Schutz der öffentlichen Sicherheit durch Bewertung der Aspekte des Risikos informiert werden sollte...". Diese Risiken wären der Hauptgrund dafür, jede Form von Regulierung zu schaffen, vorausgesetzt, dass eine bestehende Verordnung nicht für die KI-Technologie gelten würde. Der erste Hauptbericht war der nationale Strategieplan für künstliche Intelligenz. Am 13. August 2018 wurde in Abschnitt 1051 des Fiskaljahres 2019 John S. McCain National Defense Authorization Act (P.L 115-232) die National Security Commission on Artificial Intelligence eingerichtet, "die Methoden und Mittel zu berücksichtigen, die notwendig sind, um die Entwicklung von künstlicher Intelligenz, maschinellem Lernen und damit verbundenen Technologien zu fördern, um den nationalen Sicherheits- und Verteidigungsbedarf der Vereinigten Staaten umfassend zu berücksichtigen". Die Kontrolle der sicherheitsrelevanten KI wird von der National Security Commission on Artificial Intelligence bereitgestellt. Das Artificial Intelligence Initiative Act (S.1558) ist eine Gesetzesvorlage, die eine föderale Initiative zur Beschleunigung der Forschung und Entwicklung auf KI für unter anderem die wirtschaftliche und nationale Sicherheit der Vereinigten Staaten einrichten würde. Am 7. Januar 2019 veröffentlichte das Weiße Haus nach einer Executive Order zur Aufrechterhaltung der amerikanischen Leadership in Künstliche Intelligenz einen Leitfaden für die Regulierung von künstlichen Intelligenz-Anwendungen, der zehn Prinzipien für die Agenturen der Vereinigten Staaten umfasst, wenn es entscheidet, ob und wie man die KI reguliert. Als Antwort hat das National Institute of Standards and Technology ein Positionspapier veröffentlicht, die National Security Commission on Artificial Intelligence hat einen Bericht veröffentlicht, und das Defense Innovation Board hat Empfehlungen zur ethischen Verwendung von AI abgegeben. Ein Jahr später forderte die Verwaltung in einem anderen Entwurf ihres Leitfadens für die Regulierung von künstlichen Intelligenzanwendungen Stellung. Weitere spezifische Einrichtungen, die an der Regulierung von KI arbeiten, sind die Food and Drug Administration, die Wege geschaffen hat, um die Einbindung von KI in die medizinische Bildgebung zu regulieren. Rechtsfragen im Zusammenhang mit tödlichen autonomen Waffensystemen (LAWS), insbesondere der Einhaltung der Gesetze des bewaffneten Konflikts, wurden seit 2013 im Rahmen des Übereinkommens über bestimmte konventionelle Waffen diskutiert. Insbesondere fanden in den Jahren 2014, 2015 und 2016 informelle Treffen von Experten statt und 2016 wurde eine Gruppe von Regierungsexperten (GGE) ernannt, um die Frage 2016 weiter zu diskutieren. 2018 wurde eine Reihe von Leitsätzen zu LAWS verabschiedet, die von der GGE auf LAWS bestätigt wurden. Im Jahr 2016 veröffentlichte China ein Positionspapier, in dem die Angemessenheit des bestehenden internationalen Rechts in Frage gestellt wurde, um die Fälschung vollautonomer Waffen anzusprechen, das erste ständige Mitglied des Sicherheitsrates der U.N. zu werden, um das Problem zu lösen und zu Vorschlägen für die globale Regulierung zu führen. Die Möglichkeit eines Moratoriums oder eines vorbeugenden Verbots der Entwicklung und Nutzung von LAWS wurde auch mehrfach von anderen nationalen Delegationen des Übereinkommens über bestimmte konventionelle Waffen erhoben und wird von der Kampagne zum Stoppen von Killer Robots - eine Koalition von Nichtregierungsorganisationen - stark befürwortet. Die US-Regierung behauptet, dass das derzeitige internationale humanitäre Gesetz in der Lage ist, die Entwicklung oder Nutzung von LAWS zu regulieren, und das US-Militär hat keine LAWS in seinem Inventar. Siehe auch Künstliche Intelligenz Künstliche Intelligenz Waffen Rennen Künstliche Intelligenz Steuerung Problem Künstliche Intelligenz in der Regierung Ethik der künstlichen Intelligenz Regierung durch Algorithmus Regulierung von Algorithmen == Referenzen ==