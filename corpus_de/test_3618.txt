Das World Wide Web (WWW), allgemein bekannt als Web, ist ein Informationssystem, in dem Dokumente und andere Web-Ressourcen von Uniform Resource Locators (URLs, wie https://example.com) identifiziert werden, die durch Hyperlinks miteinander verknüpft werden können und über das Internet zugänglich sind. Die Ressourcen des Webs werden über das Hypertext Transfer Protocol (HTTP) übertragen, können von Benutzern durch eine Software-Anwendung namens Webbrowser aufgerufen und von einer Software-Anwendung, die als Webserver bezeichnet wird, veröffentlicht werden. Die Welt Web ist nicht gleichbedeutend mit dem Internet, das das Web seit über zwei Jahrzehnten in irgendeiner Form vorveröffentlicht hat und auf dem Technologien das Web aufgebaut ist. Der englische Wissenschaftler Tim Berners-Lee erfand 1989 das World Wide Web. Er schrieb 1990 den ersten Webbrowser, während er am CERN bei Genf, Schweiz, tätig war. Der Browser wurde außerhalb des CERN an andere Forschungseinrichtungen ab Januar 1991, und dann an die breite Öffentlichkeit im August 1991 veröffentlicht. Das Web fing an, den täglichen Gebrauch 1993–4 einzugeben, als Webseiten für den allgemeinen Gebrauch zur Verfügung standen. Das World Wide Web ist zentral für die Entwicklung des Informationszeitalters, und ist das primäre Werkzeug Milliarden von Menschen verwenden, um im Internet zu interagieren. Web-Ressourcen können jede Art von heruntergeladenen Medien sein, aber Webseiten sind Hypertext-Dokumente formatiert in Hypertext Markup Language (HTML). Spezielle HTML-Syntax zeigt eingebettete Hyperlinks mit URLs an, die es Benutzern ermöglichen, auf andere Webressourcen zu navigieren. Zusätzlich zu Text können Webseiten Verweise auf Bilder, Video-, Audio- und Softwarekomponenten enthalten, die entweder im Webbrowser des Benutzers angezeigt oder intern ausgeführt werden, um Seiten oder Streams von Multimedia-Inhalte zu rendern. Mehrere Web-Ressourcen mit einem gemeinsamen Thema und in der Regel ein gemeinsamer Domain-Name bilden eine Website. Websites werden in Computern gespeichert, die einen Webserver betreiben, das ist ein Programm, das auf Anfragen reagiert, die über das Internet von Web-Browsern ausgeführt werden, die auf dem Computer eines Nutzers laufen. Webseiteninhalte können von einem Verleger oder interaktiv von nutzergenerierten Inhalten bereitgestellt werden. Websites werden für eine Vielzahl von informativen, Unterhaltung, kommerziellen und staatlichen Gründen bereitgestellt. Geschichte Das zugrunde liegende Konzept von Hypertext entstand aus früheren Projekten der 1960er Jahre, wie dem Hypertext Editing System (HES) der Brown University, dem Projekt Xanadu von Ted Nelson und dem oN-Line System von Douglas Engelbart (NLS). Beide Nelson und Engelbart waren wiederum inspiriert von Vannevar Bushs Mikrofilm-basiertem Memex, der im Essay "As We May Think" von 1945 beschrieben wurde. Tim Berners-Lees Vision eines globalen vernetzten Informationssystems wurde in der zweiten Hälfte der 1980er Jahre eine Möglichkeit. Bis 1985 begann das globale Internet, in Europa zu proliferieren und das Domain Name System (auf dem der einheitliche Ressourcensucher gebaut wird) entstand. 1988 wurde die erste direkte IP-Verbindung zwischen Europa und Nordamerika hergestellt und Berners-Lee begann offen über die Möglichkeit eines webähnlichen Systems am CERN zu diskutieren. Bei der Arbeit am CERN wurde Berners-Lee mit den Ineffizienzen und Schwierigkeiten frustriert, die durch die Suche nach Informationen auf verschiedenen Computern entstehen. Am 12. März 1989 legte er ein Memorandum mit dem Titel "Informationsmanagement: A Proposal" an das Management am CERN für ein System namens Mesh, das auf ENQUIRE, ein Datenbank- und Softwareprojekt, das er im Jahr 1980 gebaut hatte, referierte, das den Begriff Web verwendet und ein aufwendigeres Informationsmanagementsystem auf der Grundlage von Links als Text eingebettet beschrieben: "Imagine, dann, die Referenzen in diesem Dokument alle mit der Netzwerkadresse des Lesens assoziiert werden konnten, die sie, dass, dass sie auf, dass, dass sie auf, Ein solches System, erklärte er, könnte auf die Verwendung einer der vorhandenen Bedeutungen des Wort-Hypertextes verwiesen werden, ein Begriff, den er in den 1950er Jahren sagte. Es gibt keinen Grund, der Vorschlag geht weiter, warum solche Hypertext-Links Multimedia-Dokumente einschließlich Grafiken, Sprache und Video nicht umfassen konnten, so dass Berners-Lee weiter geht, um den Begriff Hypermedia zu verwenden. Mit Hilfe seiner Kollegin und seines Mit-Hypertext-Enthusiasten Robert Cailliau veröffentlichte er am 12. November 1990 einen formalen Vorschlag, ein "Hypertext-Projekt" namens WorldWideWeb (ein Wort, abgekürzt W3) als Web von "Hypertext-Dokumenten" zu erstellen, die von Browsern mit einer Client-Server-Architektur betrachtet werden. An diesem Punkt waren HTML und HTTP bereits seit etwa zwei Monaten in der Entwicklung und der erste Webserver war etwa einen Monat nach Abschluss seines ersten erfolgreichen Tests. Dieser Vorschlag schätzte, dass innerhalb von drei Monaten ein Lektüre-only-Web entwickelt werden würde und dass es sechs Monate dauern würde, um "die Schaffung neuer Links und neues Material von Lesern, [so dass] Autorschaft wird universal" sowie "die automatische Meldung eines Lesers, wenn neues Material von Interesse für ihn / sie verfügbar geworden ist". Während das Read-Only-Ziel erfüllt wurde, dauerte die zugängliche Autorschaft von Webinhalten länger zu reifen, mit dem Wiki-Konzept, WebDAV, Blogs, Web 2.0 und RSS/Atom. Der Vorschlag wurde nach dem SGML-Reader Dynatext von Electronic Book Technology, einem Spin-off vom Institut für Forschung in Information und Wissenschaft an der Brown University, modelliert. Das von CERN lizenzierte Dynatext-System war ein wichtiger Player in der Erweiterung von SGML ISO 8879:1986 auf Hypermedia innerhalb von HyTime, aber es wurde als zu teuer angesehen und hatte eine unangemessene Lizenzierungspolitik für den Einsatz in der allgemeinen Hochenergie-Physik-Gemeinschaft, nämlich eine Gebühr für jedes Dokument und jede Dokumentänderung. A NeXT Computer wurde von Berners-Lee als der weltweit erste Webserver verwendet und auch den ersten Webbrowser im Jahr 1990 zu schreiben. Bis Weihnachten 1990 hatte Berners-Lee alle notwendigen Werkzeuge für ein funktionierendes Web gebaut: der erste Webbrowser (WorldWideWeb, der auch Web-Editor war) und der erste Webserver. Die erste Website, die das Projekt selbst beschreibt, wurde am 20. Dezember 1990 veröffentlicht. Die erste Seite kann verloren gehen, aber Paul Jones von UNC-Chapel Hill in North Carolina angekündigt im Mai 2013, Berners-Lee gab ihm, was er sagt, ist die älteste bekannte Webseite während eines Besuchs von UNC im Jahre 1991. Jones hat es auf einem magneto-optischen Laufwerk und auf seinem NeXT-Computer gespeichert. Am 6. August 1991 veröffentlichte Berners-Lee eine kurze Zusammenfassung des World Wide Web-Projekts auf der Newsgroup alt.hypertext. Dieses Datum ist manchmal mit der öffentlichen Verfügbarkeit der ersten Webserver verwechselt, die Monate zuvor aufgetreten waren. Als ein weiteres Beispiel für diese Verwirrung berichteten mehrere Nachrichtenmedien, dass das erste Foto im Web von Berners-Lee im Jahr 1992 veröffentlicht wurde, ein Bild der CERN-Hausband Les Horribles Cernettes von Silvano de Gennaro; Gennaro hat diese Geschichte verworfen, indem es schreibt, dass Medien "wir unsere Worte um den billigen Sensationswillen zu verzerren". Der erste Server außerhalb Europas wurde im Dezember 1991 im Stanford Linear Accelerator Center (SLAC) in Palo Alto, Kalifornien installiert, um die SPIRES-HEP-Datenbank zu hosten. Berners-Lees Durchbruch war, Hypertext im Internet zu heiraten. In seinem Buch Weaving The Web erklärt er, dass er den beiden technischen Gemeinschaften wiederholt vorgeschlagen hatte, dass eine Ehe zwischen den beiden Technologien möglich war. Aber als niemand seine Einladung aufnahm, nahm er schließlich das Projekt selbst an. Dabei entwickelte er drei wesentliche Technologien: ein System global einzigartiger Identifikatoren für Ressourcen im Web und anderswo, die universelle Dokumentenkennung (UDI), später als einheitlicher Ressourcenortator (URL) und einheitlicher Ressourcenkennung (URI); die Verlagssprache Hypertext Markup Language (HTML); das Hypertext Transfer Protocol (HTTP). Die Welt Web hatte mehrere Unterschiede von anderen Hypertext-Systemen zur Zeit zur Verfügung. Das Web benötigte nur unidirektionale Links und nicht bidirektionale, so dass es möglich ist, dass jemand mit einer anderen Ressource ohne Handlung durch den Eigentümer dieser Ressource verlinkt. Es verringerte auch deutlich die Schwierigkeit, Webserver und Browser zu implementieren (im Vergleich zu früheren Systemen), präsentierte aber wiederum das chronische Problem der Link rot. Im Gegensatz zu Vorgängern wie HyperCard war das World Wide Web nicht proprietär, so dass es möglich ist, Server und Clients unabhängig zu entwickeln und Erweiterungen ohne Lizenzbeschränkungen hinzuzufügen. Am 30. April 1993 kündigte CERN an, dass das World Wide Web für jeden frei sein würde, ohne Gebühren zu zahlen. Zwei Monate nach der Ankündigung, dass die Server-Implementierung des Gopher-Protokolls nicht mehr gebrauchsfrei war, hat dies eine schnelle Verschiebung von Gopher und in Richtung Web bewirkt. Ein früher populärer Webbrowser war ViolaWWW für Unix und das X Window System. Das Web fing an, die allgemeine Nutzung in 1993–4, wenn Webseiten für den täglichen Gebrauch begann, verfügbar zu werden. Historiker sind sich allgemein einig, dass ein Wendepunkt für das Web mit der Einführung von Mosaic begann 1993, ein grafischer Web-Browser entwickelt am National Center for Supercomputing Applications an der Universität Illinois an Urbana-Champaign (NCSA-UIUC). Die Entwicklung wurde von Marc Andreessen geleitet, während die Finanzierung aus der US High-Performance Computing and Communications Initiative und dem High Performance Computing Act von 1991 stammte, einer von mehreren von US Senator Al Gore initiierten Computing-Entwicklungen. Vor der Veröffentlichung von Mosaic wurden Grafiken nicht häufig mit Text auf Webseiten gemischt, und das Web war weniger beliebt als ältere Protokolle wie Gopher und Wide Area Information Servers (WAIS). Die grafische Benutzeroberfläche von Mosaic ermöglichte es dem Web, das beliebteste Protokoll im Internet zu werden. Das World Wide Web Consortium (W3C) wurde von Tim Berners-Lee gegründet, nachdem er im Oktober 1994 die Europäische Organisation für Kernforschung (CERN) verlassen hatte. Es wurde am Massachusetts Institute of Technology Laboratory for Computer Science (MIT/LCS) mit Unterstützung der Defense Advanced Research Projects Agency (DARPA) gegründet, die das Internet vorangebracht hatte; ein Jahr später wurde ein zweiter Standort an der INRIA (ein französisches nationales Computerforschungslabor) mit Unterstützung der GD InfSo der Europäischen Kommission gegründet und 1996 wurde an der Keio University ein dritter Kontinentalstandort in Japan geschaffen. Bis Ende 1994 war die Gesamtzahl der Webseiten noch relativ gering, aber viele bemerkenswerte Webseiten waren bereits aktiv, die die beliebtesten Dienste der heutigen Zeit vorausgesagt oder inspiriert haben. Vernetzt durch das Internet, wurden andere Websites auf der ganzen Welt erstellt. Diese motivierte internationale Standardsentwicklung für Protokolle und Formatierung. Berners-Lee blieb weiterhin daran beteiligt, die Entwicklung von Web-Standards, wie die Markup-Sprachen zu komponieren Web-Seiten und er befürwortete seine Vision eines Semantischen Web. Das World Wide Web ermöglichte die Verbreitung von Informationen über das Internet durch ein einfach zu bedienendes und flexibles Format. Es spielte somit eine wichtige Rolle bei der Popularisierung der Nutzung des Internets. Obwohl die beiden Begriffe manchmal in der beliebten Nutzung beschränkt sind, ist World Wide Web nicht gleichbedeutend mit Internet. Das Web ist ein Informationsraum mit hyperlinkten Dokumenten und anderen Ressourcen, die durch ihre URIs identifiziert werden. Es wird sowohl als Client- als auch als Server-Software mit Internet-Protokollen wie TCP/IP und HTTP implementiert. Berners-Lee wurde 2004 von Queen Elizabeth II für "Dienste zur globalen Entwicklung des Internets" geritten. Er hat seine Erfindung nie patentiert. Funktion Die Begriffe Internet und WorldWide Web werden oft ohne viel Unterschied verwendet. Die beiden Begriffe bedeuten jedoch nicht dasselbe. Das Internet ist ein globales System vernetzter Computernetze. Im Gegensatz dazu ist das World Wide Web eine globale Sammlung von Dokumenten und anderen Ressourcen, die durch Hyperlinks und URIs verbunden sind. Web-Ressourcen werden über HTTP oder HTTPS aufgerufen, die auf Anwendungsebene Internet-Protokolle sind, die die Transportprotokolle des Internets verwenden. Die Ansicht einer Webseite auf dem World Wide Web beginnt in der Regel entweder indem Sie die URL der Seite in einen Webbrowser eingeben oder einen Hyperlink zu dieser Seite oder Ressource verfolgen. Der Webbrowser leitet dann eine Reihe von Hintergrundkommunikationsnachrichten ein, um die angeforderte Seite zu holen und anzuzeigen. In den 1990er Jahren, mit einem Browser, um Web-Seiten zu sehen – und von einer Web-Seite zu einer anderen durch Hyperlinks zu bewegen – wurde als Surfen, "Web-Surfen" (nach Channel-Surfen) oder "Navigating the Web" bekannt. Frühe Studien dieses neuen Verhaltens untersuchten Benutzermuster bei der Verwendung von Webbrowsern. Eine Studie zum Beispiel fand fünf Benutzermuster: exploratives Surfen, Fenstersurfen, entwickeltes Surfen, begrenzte Navigation und gezielte Navigation. Das folgende Beispiel zeigt die Funktionsweise eines Webbrowsers beim Zugriff auf eine Seite auf der URL http://example.org/home.html. Der Browser löst den Servernamen der URL (example.org) in eine Internet Protocol-Adresse über das global verteilte Domain Name System (DNS). Dieser Lookup gibt eine IP-Adresse wie 203.0.113.4 oder 2001:db8:2e::7334 zurück. Der Browser fordert dann die Ressource, indem er eine HTTP-Anfrage über das Internet an den Computer an dieser Adresse sendet. Es fordert den Dienst von einer bestimmten TCP-Portnummer an, die für den HTTP-Service bekannt ist, so dass der empfangende Host eine HTTP-Anfrage von anderen Netzwerkprotokollen unterscheiden kann, die es sein kann. HTTP verwendet normalerweise Portnummer 80 und für HTTPS verwendet es normalerweise Portnummer 443. Der Inhalt der HTTP-Anfrage kann so einfach sein wie zwei Textzeilen: Der Computer, der die HTTP-Anforderung erhält, liefert sie an Webserver-Software, die auf Anfragen auf Port 80 zuhört. Wenn der Webserver die Anforderung erfüllen kann, sendet er eine HTTP-Antwort an den Browser, der Erfolg anzeigt: gefolgt von dem Inhalt der angeforderten Seite. Hypertext Markup Language (HTML) für eine grundlegende Webseite könnte so aussehen: Der Web-Browser parsiert das HTML und interpretiert die Markierung <(Titel>, <p> für Absatz, und solche), die die Wörter umgibt, um den Text auf dem Bildschirm zu formatieren. Viele Webseiten verwenden HTML, um die URLs anderer Ressourcen wie Bilder, andere eingebettete Medien, Skripte, die das Seitenverhalten beeinflussen, und Cascading Style Sheets zu verweisen, die das Seitenlayout beeinflussen. Der Browser stellt zusätzliche HTTP-Anfragen an den Webserver für diese anderen Internet-Medientypen vor. Da er seinen Inhalt vom Webserver erhält, stellt der Browser die Seite nach Maßgabe seines HTML und dieser zusätzlichen Ressourcen schrittweise auf den Bildschirm. HTML Hypertext Markup Language (HTML) ist die Standard-Markup-Sprache für die Erstellung von Webseiten und Webanwendungen. Mit Cascading Style Sheets (CSS) und JavaScript bildet es eine Triade von Ecksteintechnologien für das World Wide Web. Webbrowser erhalten HTML-Dokumente von einem Webserver oder von lokalem Speicher und machen die Dokumente in Multimedia-Webseiten. HTML beschreibt die Struktur einer Webseite semantisch und ursprünglich enthalten Cues für das Erscheinungsbild des Dokuments. HTML-Elemente sind die Bausteine von HTML-Seiten. Mit HTML-Konstrukten können Bilder und andere Objekte wie interaktive Formulare in die Rendered-Seite eingebettet werden. HTML bietet eine Möglichkeit, strukturierte Dokumente zu erstellen, indem es strukturelle Semantik für Text wie Überschriften, Absätze, Listen, Links, Zitate und andere Elemente angibt. HTML-Elemente werden durch Tags delineiert, geschrieben mit Winkelwinkeln. Tags wie <img /> und <input /> führen direkt Inhalt in die Seite ein. Andere Tags wie <p> Surround und liefern Informationen über Dokumenttext und können andere Tags als Subelemente enthalten. Browser zeigen nicht die HTML-Tags, sondern verwenden sie, um den Inhalt der Seite zu interpretieren. HTML kann Programme einfügen, die in einer Skriptsprache wie JavaScript geschrieben werden, die das Verhalten und den Inhalt der Webseiten beeinflusst. Inclusion of CSS definiert das Aussehen und Layout von Inhalten. Das World Wide Web Consortium (W3C), Betreuer der HTML- und CSS-Standards, hat die Verwendung von CSS über explizite Präsentation HTML seit 1997 gefördert. Verknüpfung Die meisten Webseiten enthalten Hyperlinks zu anderen verwandten Seiten und vielleicht zum Herunterladen von Dateien, Quelldokumenten, Definitionen und anderen Web-Ressourcen. Im zugrunde liegenden HTML sieht ein Hyperlink so aus: <a href="http://example.org/home.html">Example.org Homepage</a> Eine solche Sammlung nützlicher, verwandter Ressourcen, die über Hypertext-Links miteinander verbunden sind, wird ein Web der Informationen gegraben. Die Veröffentlichung im Internet schuf, was Tim Berners-Lee im November 1990 erstmals das WorldWideWeb (in seiner ursprünglichen CamelCase, die später verworfen wurde) nannte. Die Hyperlink-Struktur des Webs wird durch das Webgraph beschrieben: Die Knoten des Webgraphs entsprechen den Webseiten (oder URLs) den zwischen ihnen gerichteten Kanten zu den Hyperlinks. Im Laufe der Zeit werden viele Web-Ressourcen, auf die Hyperlinks hingewiesen werden, verschwinden, verlagern oder durch verschiedene Inhalte ersetzt. Dies macht Hyperlinks veraltet, ein Phänomen, das in einigen Kreisen als Link rot bezeichnet wird, und die von ihm betroffenen Hyperlinks werden oft als tote Links bezeichnet. Die ephemere Natur des Internets hat viele Anstrengungen zur Archivierung von Webseiten ausgelöst. Das seit 1996 aktive Internet-Archiv ist die bekannteste dieser Bemühungen. WWW-Präfix Viele Hostnamen, die für das World Wide Web verwendet werden, beginnen mit www aufgrund der langjährigen Praxis der Benennung von Internet-Hosts nach den Dienstleistungen, die sie bieten. Der Hostname eines Webservers ist oft www, in der gleichen Weise, dass es für einen FTP-Server ftp sein kann, und Nachrichten oder nntp für einen Usenet-Nachrichtenserver. Diese Hostnamen erscheinen wie Domain Name System (DNS) oder Subdomainnamen, wie unter www.example.com. Die Nutzung von www ist nicht durch einen technischen oder politischen Standard erforderlich und viele Webseiten verwenden ihn nicht; der erste Webserver war nxoc01.cern.ch. Laut Paolo Palazzi, der zusammen mit Tim Berners-Lee am CERN arbeitete, war die beliebte Nutzung von www als Subdomain versehentlich; die World Wide Web-Projektseite sollte unter www.cern.ch veröffentlicht werden, während info.cern.ch die CERN-Homepage sein sollte, die DNS-Einträge wurden jedoch nie umgeschaltet, und die Praxis, www auf den Website-Namen einer Institution zu übertragen, wurde anschließend kopiert. Viele etablierte Websites nutzen das Präfix noch, oder sie verwenden andere Subdomainnamen wie www2, sicher oder en für besondere Zwecke. Viele solcher Webserver werden so eingerichtet, dass sowohl der Haupt-Domain-Name (z.B. example.com) als auch die www-Subdomain (z.B. www.example.com) auf die gleiche Website verweisen; andere benötigen ein Formular oder das andere, oder sie können auf verschiedene Websites abbilden. Die Verwendung eines Subdomain-Namens ist nützlich, um den eingehenden Web-Verkehr zu laden, indem Sie einen CNAME-Datensatz erstellen, der auf einen Cluster von Webservern verweist. Da derzeit nur eine Subdomain in einem CNAME verwendet werden kann, kann das gleiche Ergebnis durch die Verwendung der bloßen Domänenwurzel nicht erreicht werden. Wenn ein Benutzer einen unvollständigen Domainnamen an einen Webbrowser in seinem Adressleiste-Eingabefeld eingibt, versuchen einige Webbrowser automatisch, das Präfix www zu Beginn und möglicherweise .com, .org und .net" am Ende hinzuzufügen, je nachdem, was fehlt. Beispielsweise kann die Eingabe von microsoft auf http://www.microsoft.com und openoffice auf http://www.openoffice.org transformiert werden. Diese Funktion begann in frühen Versionen von Firefox, als es noch hatte den Arbeitstitel Firebird Anfang 2003, von einer früheren Praxis in Browsern wie Lynx. Es wird berichtet, dass Microsoft 2008 ein US-Patent für dieselbe Idee, aber nur für mobile Geräte erteilt wurde. In Englisch wird www in der Regel als doppel-u doppel-u doppel-u gelesen. Einige Benutzer verkünden es dub-dub-dub, insbesondere in Neuseeland. Stephen Fry, in seiner Podgram-Serie von Podcasts, gibt es wuh wuh wuh wuh. Der englische Schriftsteller Douglas Adams einmal in The Independent am Sonntag (1999:) "Das World Wide Web ist das einzige, was ich weiß, dessen verkürzte Form dreimal länger dauert, um zu sagen, als was es kurz ist." In Mandarin Chinesisch, World Wide Web wird häufig über eine phono-semantische Anpassung an wàn wéi wđönng übersetzt, die www erfüllt und wörtlich bedeutet "myriad dimensional net", eine Übersetzung, die das Designkonzept und die Verbreitung des World Wide Web widerspiegelt. Tim Berners-Lee's Web-space sagt, dass World Wide Web offiziell als drei separate Wörter, jedes Kapitalisiert, ohne intervenierende Bindestriche geschrieben wird. Die Nutzung des www-Präfixes wurde abgenommen, vor allem, wenn Web 2.0 Web-Anwendungen suchte, um ihre Domain-Namen zu markieren und sie leicht auszusprechen.Da das mobile Web in Popularität gewachsen ist, werden Dienste wie Gmail.com, Outlook.com, Myspace.com, Facebook.com und Twitter.com am häufigsten erwähnt, ohne dass www."(oder, in der Tat, .com) auf die Domain hinzugefügt wird. Scheme-Spezifikatoren Die Schema-Spezifikatoren http:/ und https:/ zu Beginn eines Web URI beziehen sich auf Hypertext Transfer Protocol bzw. HTTP Secure. Sie geben das Kommunikationsprotokoll an, um für die Anfrage und Antwort zu verwenden. Das HTTP-Protokoll ist grundlegend für den Betrieb des World Wide Web, und die hinzugefügte Verschlüsselungsschicht in HTTPS ist wesentlich, wenn Browser vertrauliche Daten wie Passwörter oder Bankinformationen senden oder abrufen. Web-Browser stellen in der Regel automatisch http:/ an nutzergespeicherte URIs vor, wenn weggelassen. Seiten Eine Webseite (auch als Webseite geschrieben) ist ein Dokument, das für das World Wide Web und Web-Browser geeignet ist. Ein Webbrowser zeigt eine Webseite auf einem Monitor oder einem mobilen Gerät an. Der Begriff Webseite bezieht sich in der Regel auf das, was sichtbar ist, kann sich aber auch auf den Inhalt der Computerdatei selbst beziehen, was in der Regel eine Textdatei mit Hypertext ist, die in HTML oder einer vergleichbaren Markupsprache geschrieben ist. Typische Webseiten bieten Hypertext für das Surfen auf andere Webseiten über Hyperlinks, oft als Links bezeichnet. Web-Browser müssen häufig auf mehrere Web-Ressource-Elemente zugreifen, wie z.B. Stylesheets, Skripte und Bilder lesen, während sie jede Webseite präsentieren. Ein Webbrowser kann auf einem Netzwerk eine Webseite von einem Remote-Webserver abrufen. Der Webserver kann den Zugriff auf ein privates Netzwerk wie ein Intranet beschränken. Der Webbrowser verwendet das Hypertext Transfer Protocol (HTTP), um solche Anfragen an den Webserver zu stellen. Eine statische Webseite wird genau wie gespeichert als Webinhalt im Dateisystem des Webservers ausgeliefert. Im Gegensatz dazu wird eine dynamische Webseite durch eine Webanwendung erzeugt, die üblicherweise von serverseitiger Software angetrieben wird. Dynamische Webseiten werden verwendet, wenn jeder Benutzer ganz andere Informationen benötigen kann, zum Beispiel Bank-Websites, Web-E-Mails usw. Statische Seite Eine statische Seite (manchmal eine flache Seite/stationäre Seite genannt) ist eine Webseite, die dem Benutzer genau wie gespeichert geliefert wird, im Gegensatz zu dynamischen Webseiten, die von einer Web-Anwendung erzeugt werden. Folglich zeigt eine statische Webseite für alle Benutzer dieselben Informationen, von allen Kontexten, vorbehaltlich moderner Fähigkeiten eines Webservers, um den Inhaltstyp oder die Sprache des Dokuments zu verhandeln, in dem solche Versionen verfügbar sind und der Server dazu konfiguriert ist. Dynamische Seiten Eine serverseitige dynamische Web-Seite ist eine Web-Seite, deren Konstruktion von einem anwendungsserververarbeitenden serverseitigen Skript gesteuert wird. In der serverseitigen Skriptierung bestimmen Parameter, wie die Montage jeder neuen Webseite abläuft, einschließlich der Einrichtung einer Client-Seitenbearbeitung. Eine clientseitige dynamische Webseite verarbeitet die Webseite mithilfe von JavaScript, die im Browser ausgeführt wird. JavaScript-Programme können mit dem Dokument über Document Object Model oder DOM interagieren, um den Seitenzustand abzufragen und zu ändern. Die gleichen clientseitigen Techniken können dann das DOM dynamisch aktualisieren oder in gleicher Weise ändern. Eine dynamische Webseite wird dann vom Benutzer oder von einem Computerprogramm neu geladen, um einige variable Inhalte zu ändern. Die Aktualisierungsinformationen könnten vom Server oder von Änderungen, die auf die DOM dieser Seite vorgenommen wurden, stammen. Dies kann oder darf die Browser-Geschichte nicht brechen oder eine gespeicherte Version erstellen, um zurück zu gehen, aber ein dynamisches Web-Seiten-Update mit Ajax-Technologien wird weder eine Seite erstellen, um zurück zu gehen, noch die Web-Browsing-Geschichte vor der angezeigten Seite zu klopfen. Mit Ajax-Technologien erhält der Endbenutzer eine dynamische Seite, die als einzelne Seite im Webbrowser verwaltet wird, während der tatsächliche Webinhalt auf dieser Seite variiert werden kann. Die Ajax-Engine sitzt nur auf dem Browser, der Teile seiner DOM, die DOM, für seinen Client, von einem Anwendungsserver anfordert. Dynamic HTML, oder DHTML, ist der Begriff für Technologien und Methoden, die verwendet werden, um Web-Seiten zu erstellen, die nicht statische Webseiten sind, obwohl es aus dem gängigen Gebrauch seit der Popularisierung von AJAX gefallen ist, ein Begriff, der jetzt selbst selten verwendet wird. Client-side-scripting, serverseitiges Skripting oder eine Kombination dieser machen das dynamische Weberlebnis in einem Browser. JavaScript ist eine Scripting-Sprache, die 1995 von Brendan Eich, dann von Netscape, für die Nutzung innerhalb von Webseiten entwickelt wurde. Die standardisierte Version ist ECMAScript. Um Webseiten interaktiver zu machen, verwenden einige Web-Anwendungen auch JavaScript-Techniken wie Ajax (asynchrones JavaScript und XML). Clientseitiges Skript wird mit der Seite geliefert, die zusätzliche HTTP-Anfragen an den Server stellen kann, entweder in Reaktion auf Benutzeraktionen wie Mausbewegungen oder Klicks, oder basierend auf verstrichener Zeit. Die Antworten des Servers werden verwendet, um die aktuelle Seite zu ändern, anstatt eine neue Seite mit jeder Antwort zu erstellen, so dass der Server nur begrenzte, inkrementelle Informationen bereitstellen muss. Mehrere Ajax-Anfragen können gleichzeitig bearbeitet werden, und Benutzer können mit der Seite interagieren, während Daten abgerufen werden. Webseiten können auch regelmäßig den Server abfragen, um zu überprüfen, ob neue Informationen verfügbar sind. Webseite Eine Website ist eine Sammlung von verwandten Web-Ressourcen, einschließlich Web-Seiten, Multimedia-Inhalte, die typischerweise mit einem gemeinsamen Domain-Namen identifiziert und auf mindestens einem Web-Server veröffentlicht. Bemerkenswerte Beispiele sind wikipedia.org, google.com und amazon.com. Eine Website kann über ein öffentliches Internet Protocol (IP)-Netzwerk, wie das Internet, oder ein privates lokales Netzwerk (LAN) zugänglich sein, indem ein einheitlicher Ressourcenlokator (URL) bezeichnet wird, der die Website identifiziert. Websites können viele Funktionen haben und können in verschiedenen Moden verwendet werden; eine Website kann eine persönliche Website, eine Unternehmenswebsite für ein Unternehmen, eine Regierung Website, eine Organisation Website, etc. sein. Websites sind in der Regel einem bestimmten Thema oder Zweck gewidmet, von Unterhaltung und Social Networking bis hin zu Nachrichten und Bildung. Alle öffentlich zugänglichen Websites bilden gemeinsam das World Wide Web, während private Websites, wie die Website eines Unternehmens für seine Mitarbeiter, sind in der Regel Teil eines Intranets. Webseiten, die die Bausteine von Webseiten sind, sind Dokumente, die typischerweise im Klartext mit Formatierungsbefehlen von Hypertext Markup Language (HTML, XHTML) intersperiert sind. Sie können Elemente von anderen Websites mit geeigneten Markup-Dankern enthalten. Web-Seiten werden mit dem Hypertext Transfer Protocol (HTTP) aufgerufen und transportiert, das optional Verschlüsselung (HTTP Secure, HTTPS) verwenden kann, um Sicherheit und Privatsphäre für den Benutzer bereitzustellen. Die Anwendung des Nutzers, oft ein Webbrowser, macht den Seiteninhalt entsprechend seiner HTML-Markup-Anweisungen auf ein Display-Terminal. Hyperlinking zwischen Webseiten vermittelt dem Leser die Seitenstruktur und führt die Navigation der Seite, die oft mit einer Home-Seite beginnt, die ein Verzeichnis der Webseiteninhalte enthält. Einige Webseiten erfordern die Registrierung von Benutzern oder das Abo zum Zugriff auf Inhalte. Beispiele für Abonnement-Websites sind viele Business-Websites, Nachrichten-Websites, akademische Journal-Websites, Gaming-Websites, Datei-Sharing-Websites, Nachrichten-Boards, web-basierte E-Mail, Social-Networking-Websites, Websites, die Echtzeit-Aktien-Marktdaten bereitstellen, sowie Websites, die verschiedene andere Dienste anbieten. Endbenutzer können auf Websites auf einer Reihe von Geräten zugreifen, darunter Desktop- und Laptop-Computer, Tablet-Computer, Smartphones und Smart-TVs. Browser Ein Webbrowser (gemeinsam als Browser bezeichnet) ist ein Softwarebenutzer für den Zugriff auf Informationen im World Wide Web. Um mit dem Server einer Website zu verbinden und ihre Seiten anzuzeigen, muss ein Benutzer ein Web-Browser-Programm haben. Dies ist das Programm, das der Benutzer zum Herunterladen, Format und Anzeigen einer Webseite auf dem Computer des Benutzers läuft. Ein Webbrowser hat neben dem Auffinden, Anzeigen und Bewegen zwischen Webseiten in der Regel Funktionen wie das Halten von Lesezeichen, die Aufnahmegeschichte, das Verwalten von Cookies (siehe unten) und Home-Seiten und kann Einrichtungen für die Aufnahme von Passwörtern für die Anmeldung in Webseiten haben. Die beliebtesten Browser sind Chrome, Firefox, Safari, Internet Explorer und Edge. Server Ein Webserver ist Server-Software oder Hardware, die der Ausführung dieser Software gewidmet ist, die World Wide Web-Client-Anfragen erfüllen kann. Ein Webserver kann im Allgemeinen eine oder mehrere Websites enthalten. Ein Webserver verarbeitet eingehende Netzwerkanfragen über HTTP und mehrere andere verwandte Protokolle. Die primäre Funktion eines Webservers besteht darin, Webseiten an Clients zu speichern, zu verarbeiten und zu liefern. Die Kommunikation zwischen Client und Server erfolgt über das Hypertext Transfer Protocol (HTTP). Seiten werden am häufigsten HTML-Dokumente geliefert, die neben dem Textinhalt Bilder, Stylesheets und Skripte enthalten können. Ein Nutzer-Agent, üblicherweise ein Web-Browser oder Web-Crawler, initiiert die Kommunikation, indem er eine Anfrage für eine bestimmte Ressource unter Verwendung von HTTP stellt und der Server mit dem Inhalt dieser Ressource oder einer Fehlermeldung reagiert, wenn dies nicht möglich ist. Die Ressource ist in der Regel eine reale Datei auf dem sekundären Speicher des Servers, aber dies ist nicht notwendigerweise der Fall und hängt davon ab, wie der Webserver implementiert ist. Während die primäre Funktion ist, Inhalte zu bedienen, beinhaltet eine vollständige Implementierung von HTTP auch Möglichkeiten, Inhalte von Clients zu empfangen. Diese Funktion wird für die Einreichung von Webformularen verwendet, einschließlich des Hochladens von Dateien. Viele generische Webserver unterstützen auch das serverseitige Skripting mit Active Server Pages (ASP), PHP (Hypertext Preprocessor) oder anderen Skriptsprachen. Das bedeutet, dass das Verhalten des Webservers in separaten Dateien Scriptiert werden kann, während die eigentliche Serversoftware unverändert bleibt. Üblicherweise wird diese Funktion verwendet, um HTML-Dokumente dynamisch (auf-the-fly) im Gegensatz zur Rückgabe statischer Dokumente zu erzeugen. Der erste wird hauptsächlich zum Abrufen oder Modifizieren von Informationen aus Datenbanken verwendet. Letzteres ist in der Regel viel schneller und einfacher geätzt, kann aber nicht dynamische Inhalte liefern. Webserver finden sich häufig auch eingebettet in Geräte wie Drucker, Router, Webcams und dienen nur einem lokalen Netzwerk. Der Webserver kann dann als Teil eines Systems zur Überwachung oder Verwaltung des betreffenden Gerätes verwendet werden. Dies bedeutet in der Regel, dass keine zusätzliche Software auf dem Client-Computer installiert werden muss, da nur ein Web-Browser benötigt wird (die jetzt mit den meisten Betriebssystemen enthalten ist). Cookies Ein HTTP-Cookie (auch Web-Cookie, Internet-Cookie, Browser-Cookie oder einfach Cookie genannt) ist ein kleines Stück von Daten, die von einer Website gesendet und auf dem Computer des Nutzers während des Browsers des Nutzers gespeichert werden. Cookies wurden entwickelt, um ein zuverlässiger Mechanismus für Webseiten zu sein, um Stateful-Informationen (wie im Warenkorb hinzugefügte Artikel in einem Online-Shop) zu merken oder die Browser-Aktivität des Nutzers aufzuzeichnen (einschließlich Klicken bestimmter Schaltflächen, Anmelden oder Aufzeichnen, welche Seiten in der Vergangenheit besucht wurden). Sie können auch verwendet werden, um beliebige Informationen zu speichern, die der Benutzer zuvor in Formularfelder wie Namen, Adressen, Passwörter und Kreditkartennummern eingegeben hat. Cookies erfüllen wesentliche Funktionen im modernen Web. Möglicherweise sind Authentifizierungs-Cookies die häufigste Methode, die von Webservern verwendet wird, um zu wissen, ob der Benutzer eingeloggt ist oder nicht, und mit welchem Konto sie eingeloggt sind. Ohne einen solchen Mechanismus würde die Website nicht wissen, ob Sie eine Seite mit sensiblen Informationen senden oder den Benutzer dazu verpflichten, sich durch Einloggen zu authentifizieren. Die Sicherheit eines Authentifizierungs-Cookies hängt in der Regel von der Sicherheit der ausstellenden Website und des Webbrowsers des Nutzers ab und davon, ob die Cookie-Daten verschlüsselt werden. Sicherheitslücken können es erlauben, dass die Daten eines Cookies von einem Hacker gelesen werden, der verwendet wird, um Zugriff auf die Nutzerdaten zu gewinnen oder genutzt wird, um Zugriff (mit den Anmeldeinformationen des Nutzers) auf die Website zu gewinnen, auf die das Cookie gehört (siehe Cross-Site-Skripting und Cross-Site-Anforderung für Beispiele). Tracking-Cookies, insbesondere Tracking-Cookies von Drittanbietern, werden häufig verwendet, um langfristige Aufzeichnungen der Browser-Geschichte von Individuen zu erstellen – ein potenzielles Datenschutz-Bedenken, das europäische und US-Gesetzgeber dazu veranlasste, 2011 Maßnahmen zu ergreifen. Das europäische Recht erfordert, dass alle Websites, die die Mitgliedstaaten der Europäischen Union ansprechen, von Nutzern "informierte Zustimmung" erhalten, bevor sie nicht wesentliche Cookies auf ihrem Gerät speichern. Google Project Zero-Forscher Jan Horn beschreibt, wie Cookies von Vermittlern wie Wi-Fi Hotspot Providern gelesen werden können. Er empfiehlt, den Browser unter solchen Umständen im Incognito-Modus zu verwenden. Suchmaschine Eine Web-Suchmaschine oder Internet-Suchmaschine ist ein Software-System, das entwickelt ist, um Web-Suche (Internet-Suche) durchzuführen, was bedeutet, das World Wide Web systematisch für bestimmte Informationen in einer Web-Suchanfrage spezifiziert zu suchen. Die Suchergebnisse werden in der Regel in einer Zeile von Ergebnissen dargestellt, oft als Suchmaschinen-Ergebnisse (SERPs) bezeichnet. Die Informationen können eine Mischung aus Webseiten, Bildern, Videos, Infografiken, Artikeln, Forschungspapieren und anderen Arten von Dateien sein. Einige Suchmaschinen auch Minendaten in Datenbanken oder offenen Verzeichnissen. Im Gegensatz zu Web-Verzeichnern, die nur von menschlichen Redakteuren gehalten werden, halten Suchmaschinen auch Echtzeit-Informationen, indem ein Algorithmus auf einem Web-Crawler ausgeführt wird. Internetinhalte, die nicht von einer Web-Suchmaschine durchsucht werden können, werden im allgemeinen als Deep Web bezeichnet. Tiefes Web Das tiefe Web, unsichtbares Web oder verstecktes Web sind Teile des World Wide Web, dessen Inhalte nicht von Standard-Web-Suchmaschinen indiziert werden. Der entgegengesetzte Begriff zum tiefen Web ist die Oberflächenbahn, die für jeden zugänglich ist, der das Internet nutzt. Informatik Michael K. Bergman wird mit der Prägung des Begriffs Deep Web im Jahr 2001 als Suchbegriff ausgezeichnet. Der Inhalt des tiefen Webs ist hinter HTTP-Formularen versteckt und umfasst viele sehr häufige Verwendungen wie Web-Mail, Online-Banking und Dienstleistungen, die Nutzer zahlen müssen, und die durch eine Paywall, wie Video auf Anfrage, einige Online-Magazine und Zeitungen, unter anderem geschützt ist. Der Inhalt des tiefen Webs kann durch eine direkte URL oder IP-Adresse lokalisiert und aufgerufen werden und kann ein Passwort oder einen anderen Sicherheitszugriff über die öffentliche Website-Seite benötigen. Caching Ein Web-Cache ist ein Server-Computer, der sich entweder im öffentlichen Internet befindet, oder innerhalb eines Unternehmens, das kürzlich auf Webseiten zugreifen kann, um die Antwortzeit für Benutzer zu verbessern, wenn der gleiche Inhalt innerhalb einer bestimmten Zeit nach der ursprünglichen Anfrage angefordert wird. Die meisten Webbrowser implementieren auch einen Browser-Cache, indem sie kürzlich gewonnene Daten an ein lokales Datenspeichergerät schreiben. HTTP-Anfragen durch einen Browser können nur nach Daten verlangen, die sich seit dem letzten Zugriff geändert haben. Webseiten und Ressourcen können Ablaufinformationen enthalten, um das Cache zu kontrollieren, um sensible Daten, wie z.B. im Online-Banking, zu sichern oder häufig aktualisierte Websites wie Nachrichtenmedien zu erleichtern. Selbst Websites mit hochdynamischen Inhalten können es ermöglichen, Grundressourcen nur gelegentlich zu aktualisieren. Web-Site-Designer finden es sinnvoll, Ressourcen wie CSS-Daten und JavaScript in ein paar Site-wide-Dateien zusammenzufassen, so dass sie effizient geätzt werden können. Enterprise Firewalls oft Cache Web-Ressourcen, die von einem Benutzer zum Nutzen vieler Benutzer angefordert werden. Einige Suchmaschinen speichern Cache-Inhalte von häufig aufgerufenen Websites. Sicherheit Für Kriminelle ist das Web ein Ort, um Malware zu verbreiten und in eine Reihe von Cyber-Kriminellen, einschließlich (aber nicht beschränkt auf) Identitätsdiebstahl, Betrug, Spionage und Intelligenz sammeln. Web-basierte Sicherheitslücken übersteigen jetzt die traditionellen Computer-Sicherheitsbedenken, und wie von Google gemessen, etwa eine in zehn Webseiten kann bösartigen Code enthalten. Die meisten webbasierten Angriffe finden auf legitimen Websites statt, und die meisten, gemessen von Sophos, werden in den Vereinigten Staaten, China und Russland gehostet. Die häufigste aller Malware-Bedrohungen ist SQL-Injektion Angriffe auf Websites. Durch HTML und URIs war das Web verletzlich gegen Angriffe wie Cross-Site-Skripting (XSS), die mit der Einführung von JavaScript kam und wurden durch Web 2.0 und Ajax Web-Design, das die Verwendung von Skripten begünstigt, zu einem gewissen Grad verschärft. Heute sind 70% aller Webseiten offen für XSS-Angriffe auf ihre Nutzer. Phishing ist eine weitere gemeinsame Bedrohung für das Web. Im Februar 2013, RSA (die Sicherheitsabteilung von EMC) geschätzt die globalen Verluste aus Phishing auf $1,5 Milliarden im Jahr 2012. Zwei der bekannten Phishing-Methoden sind Covert Redirect und Open Redirect. Vorgeschlagene Lösungen variieren. Große Sicherheitsunternehmen wie McAfee entwerfen bereits Governance- und Compliance-Suiten, um Post-9/11-Verordnungen zu erfüllen, und einige, wie Finjan, haben eine aktive Echtzeit-Inspektion von Programmiercode und alle Inhalte unabhängig von seiner Quelle empfohlen. Einige haben argumentiert, dass für Unternehmen zu sehen Web-Sicherheit als Business-Möglichkeit statt als Kostenzentrum, während andere fordern, "unsicheres, immer auf digitale Rechte Management" in der Infrastruktur durchgesetzt, um die Hunderte von Unternehmen zu ersetzen, die Daten und Netzwerke sichern. Jonathan Zittrain hat gesagt, dass Nutzer die Verantwortung für die Rechensicherheit teilen ist weit bevorzugt, um das Internet zu blockieren. Datenschutz Jedes Mal, wenn ein Client eine Webseite anfordert, kann der Server die IP-Adresse der Anfrage identifizieren. Webserver protokollieren in der Regel IP-Adressen in einer Protokolldatei. Auch, wenn nicht darauf gesetzt, dies zu tun, die meisten Web-Browser protokollieren angeforderte Webseiten in einer sichtbaren Geschichte Feature, und in der Regel speichern viele der Inhalte lokal. Sofern die Server-Browser-Kommunikation HTTPS-Verschlüsselung verwendet, reisen Web-Anfragen und -Antworte im Klartext über das Internet und können von Zwischensystemen betrachtet, aufgezeichnet und geätzt werden. Eine weitere Möglichkeit, persönliche identifizierbare Informationen zu verstecken, besteht darin, ein virtuelles privates Netzwerk zu nutzen. Ein VPN verschlüsselt den Online-Verkehr und maskiert die ursprüngliche IP-Adresse, die die Wahrscheinlichkeit einer Benutzeridentifikation senkt. Wenn eine Webseite nachfragt und der Nutzer liefert, können persönlich identifizierbare Informationen – wie deren echter Name, Adresse, E-Mail-Adresse, etc.web-basierte Unternehmen den aktuellen Webverkehr mit dieser Person verknüpfen. Wenn die Website HTTP-Cookies, Benutzername und Passwort-Authentifizierung oder andere Tracking-Techniken verwendet, kann sie andere Web-Besuche vor und nach auf die angegebenen identifizierbaren Informationen beziehen. Auf diese Weise ist es möglich, dass eine webbasierte Organisation ein Profil der einzelnen Personen entwickelt und baut, die ihre Website oder Standorte nutzen. Es kann in der Lage sein, eine Aufzeichnung für eine Person zu erstellen, die Informationen über ihre Freizeitaktivitäten, ihre Einkaufsinteressen, ihren Beruf und andere Aspekte ihres demografischen Profils enthält. Diese Profile sind von potenziellem Interesse für Vermarkter, Werbetreibende und andere. Je nach den Bedingungen und Bedingungen der Website und den lokalen Gesetzen, die Informationen aus diesen Profilen anwenden, können verkauft, geteilt oder an andere Organisationen weitergegeben werden, ohne dass der Nutzer informiert wird. Für viele gewöhnliche Menschen bedeutet dies wenig mehr als einige unerwartete E-Mails in ihrem Posteingang oder einige unheimlich relevante Werbung auf einer zukünftigen Webseite. Für andere kann es bedeuten, dass die Zeit, die ein ungewöhnliches Interesse verschwendet wird, zu einem Umsturz des weiteren gezielten Marketings führen kann, das unwillkommen sein kann. Strafverfolgung, Gegen-Terrorismus und Spionageagenturen können auch Personen identifizieren, Ziel und verfolgen, die auf ihren Interessen oder Interessen auf dem Web basieren.Social Networking-Websites in der Regel versuchen, Benutzer zu nutzen, um ihre realen Namen, Interessen und Standorte, anstatt Pseudonymen, wie ihre Führungskräfte glauben, dass dies macht die Social-Networking-Erfahrung attraktiver für Nutzer. Andererseits können hochgeladene Fotografien oder unbewachte Aussagen einem Individuum identifiziert werden, der diese Belichtung bereuen kann. Arbeitgeber, Schulen, Eltern und andere Verwandte können von Aspekten der sozialen Netzwerk-Profile beeinflusst werden, wie Textbeiträge oder digitale Fotos, dass die Buchungsindividuen für diese Publikum nicht beabsichtigt. Online-Bullen können persönliche Informationen nutzen, um Benutzer zu schikanieren oder zu stalken. Moderne Social Networking-Websites ermöglichen eine feinkörnige Kontrolle der Datenschutzeinstellungen für jede einzelne Buchung, aber diese können komplex und nicht einfach zu finden oder zu verwenden, insbesondere für Anfänger.Fotos und Videos, die auf Websites veröffentlicht wurden, haben besondere Probleme verursacht, da sie das Gesicht einer Person zu einem Online-Profil hinzufügen können. Mit moderner und potenzieller Gesichtserkennungstechnologie kann es dann möglich sein, dieses Gesicht mit anderen, zuvor anonymen Bildern, Ereignissen und Szenarien zu verbinden, die anderswo abgebildet wurden. Durch Bild-Caching, Spiegelung und Kopieren ist es schwierig, ein Bild aus dem World Wide Web zu entfernen. Normen Web-Standards umfassen viele interdependente Standards und Spezifikationen, von denen einige Aspekte des Internets regieren, nicht nur das World Wide Web. Auch wenn nicht web-fokussiert, solche Standards direkt oder indirekt beeinflussen die Entwicklung und Verwaltung von Websites und Web-Services. Zu den Überlegungen gehören die Interoperabilität, Zugänglichkeit und Usability von Webseiten und Webseiten. Web-Standards im weiteren Sinne bestehen aus folgenden: Empfehlungen des World Wide Web Consortium (W3C) "Living Standard" der Web Hypertext Application Technology Working Group (WHATWG)Request for Comments (RFC) Dokumente der Internet Engineering Task Force (IETF) Die von Ecma International (früher ECMA) herausgegebenen Standards der International Organization for Standardization (ISO) Standards (International Organization for Standardization (ISO) Standards, die von der Unicode Consortium Name und den von der Internet Assigned Numbers Authority (IANA)Web Standards verwalteten Nummern-Registern veröffentlicht wurden, sind keine festen Regeln, sondern eine ständig weiterentwickelte Reihe von technischen Spezifikationen von Web-Technologien. Web-Standards werden von Standards-Organisationen entwickelt – Gruppen von interessierten und oft konkurrierenden Parteien, die mit der Aufgabe der Standardisierung gechartert sind – keine Technologien entwickelt und erklärt, ein Standard von einem einzelnen oder Unternehmen zu sein. Es ist von entscheidender Bedeutung, diese Spezifikationen zu unterscheiden, die von denen entwickelt werden, die bereits den endgültigen Entwicklungsstatus erreicht haben (bei W3C-Spezifikationen, dem höchsten Reifeniveau). Zugänglichkeit Es gibt Methoden für den Zugriff auf das Internet in alternativen Medien und Formaten, um die Nutzung durch Menschen mit Behinderungen zu erleichtern. Diese Behinderungen können visuell, auditiv, körperlich, sprachbezogen, kognitiv, neurologische oder eine Kombination sein. Barrierefreiheitsmerkmale helfen auch Menschen mit vorübergehenden Behinderungen, wie einem gebrochenen Arm oder alternden Benutzern, wenn ihre Fähigkeiten sich ändern. Das Internet erhält Informationen sowie die Bereitstellung von Informationen und die Interaktion mit der Gesellschaft. Das World Wide Web Consortium behauptet, dass es wesentlich ist, dass das Web zugänglich ist, so dass es für Menschen mit Behinderungen gleichberechtigten Zugang und Chancengleichheit bieten kann. Tim Berners-Lee einmal bemerkt, "Die Macht des Internets ist in seiner Universalität. Der Zugang von allen unabhängig von der Behinderung ist ein wesentlicher Aspekt. " Viele Länder regulieren die Zugänglichkeit des Internets als Voraussetzung für Webseiten. Die internationale Zusammenarbeit in der W3C Web Accessibility Initiative führte zu einfachen Richtlinien, mit denen Webinhalts-Autoren sowie Softwareentwickler das Web für Personen zugänglich machen können, die die Assistenztechnologie nutzen können oder nicht. Internationalisierung Die W3C Internationalisierung Aktivität versichert, dass Webtechnologie in allen Sprachen, Skripten und Kulturen arbeitet. Ab 2004 oder 2005 übertraf Unicode den Boden und schließlich im Dezember 2007 sowohl ASCII als auch Western European als die am häufigsten verwendete Zeichencodierung des Webs. Ursprünglich erlaubte RFC 3986 Ressourcen von URI in einer Teilmenge von US-ASCII zu identifizieren. RFC 3987 erlaubt mehr Zeichen – jedes Zeichen im Universal Character Set – und jetzt kann eine Ressource von IRI in jeder Sprache identifiziert werden. Siehe auch Referenzen Weiter lesen Berners-Lee, Tim; Bray, Tim; Connolly, Dan; Cotton, Paul; Fielding, Roy; Jeckle, Mario; Lilley, Chris; Mendelsohn, Noah; Orchard, David; Walsh, Norman; Williams, Stuart (15. Dezember 2004). " Architektur des World Wide Web, Volume One".Version 20041215.W3C Berners-Lee, Tim (August 1996). "Das World Wide Web: Vergangenheit, Gegenwart und Zukunft". Brügger, Niels, ed, Web25: Histories aus den ersten 25 Jahren des World Wide Web (Peter Lang, 2017). Feld, R;. Gettys, J;. Mogul, J;. Frystyk, H;. Masinter, L;. Leach, P;. Berners-Lee, T. (Juni 1999)." Hypertext Transfer Protocol – HTTP/1.1".Request For Comments 2616.Informationswissenschaften Institut. Niels Brügger, ed.Web History (2010) 362 Seiten; Historische Perspektive im World Wide Web, einschließlich Themen der Kultur, Inhalt und Erhaltung. Polo, Luciano (2003)." Weltweite Webtechnologie Architektur: Eine konzeptuelle Analyse". Neue Geräte. Skau, H.O (März 1990)."The World Wide Web and Health Information". Neue Geräte. Externe Links Die erste Website Early-Archiv der ersten Website Internet-Statistik: Wachstum und Nutzung des Internets und das Internet Living Internet Eine umfassende Geschichte des Internets, einschließlich der World Wide Web Web Design und Entwicklung bei Curlie WorldWide Web Consortium (W3C) W3CRecommendations Reduce "World Wide Web Size Täglich geschätzte Größe des World Wide Web Antonio A. Casilli, Einige Elemente für eine Soziologie der Online Der Erdős Webgraph Server bietet wöchentlich aktualisierte Diagrammdarstellung eines stetig wachsenden Anteils des WWWDer 25. Jahrestag des World Wide Web ist ein animiertes Video, das von USAID und TechChange produziert wird und die Rolle des WWW bei der Bewältigung extremer Armut erforscht Phone OS 2 ist die zweite große Version des iOS-Betriebssystems, das von Apple Inc. entwickelt wurde. Es war die erste Version von iOS, um Drittanbieter-Anwendungen über den App Store zu unterstützen. I Phone OS 2.2.1 war die letzte Version des iPhone OS 2. Es wurde von iPhone OS 3 am 17. Juni 2009 erfolgreich. I Telefon OS 2.0 wurde am 11. Juli 2008 mit der Veröffentlichung des iPhone 3G verfügbar. Geräte mit iPhone OS 1 sind auf diese Version aufrüstbar. Diese Version von iOS führt den App Store ein und stellt Anwendungen von Drittanbietern für das iPhone und iPod Touch zur Verfügung. Vor der öffentlichen Veröffentlichung von iPhone OS 2.0 hielt Apple eine Keynote-Event, um das iPhone OS Software Development Kit (SDK) an Entwickler bekannt zu geben. Ursprünglich wurde es genannt 1.2 Apps Dock History iPhone OS 2 wurde auf der Apple Worldwide Developers Conference Keynote Adresse am 9. Juni 2008 eingeführt. I Phone OS 2.0 wurde am 11. Juli 2008 veröffentlicht. Es wurde zusammen mit dem iPhone 3G veröffentlicht und lief auch auf dem iPhone der ersten Generation. Funktionen von App Store aktualisieren Die bemerkenswerteste Funktion des iPhone OS 2 war der App Store. Bevor diese Funktion eingeführt wurde, war die einzige Möglichkeit, benutzerdefinierte Anwendungen auf dem Gerät zu installieren, über Jailbreaking, die stark entmutigt und von Apple unterstützt wird. Bei der Einführung des App Stores wurden 500 Anwendungen zum Download angeboten, obwohl dieser Betrag seitdem dramatisch angewachsen ist. Der App Store hat ab 2016 mehr als 2 Millionen Apps. Post Die Mail-App hatte ein Makeover, mit Push-E-Mails, die eine immer-on-Fähigkeit. Es unterstützt auch Microsoft Office-Anhänge, sowie iWork-Anhänge. Andere neue Funktionen, einschließlich Unterstützung für BCC, mehrere E-Mail löschen, und die Fähigkeit, eine ausgehende E-Mail auszuwählen. Ansprechpartner Die Contacts App verfügt nun über ein neues Home-Bildschirm-Symbol, das nur auf iPod Touch verfügbar ist. Zusammen mit der Veröffentlichung ist die Möglichkeit, Kontakte zu suchen, ohne durchsucht zu werden ein-für-ein, sowie SIM-Kontakte Importfähigkeit. Karten Neue Funktionen wurden der Maps App im iPhone OS 2.2 Software-Update hinzugefügt. Zu den hinzugefügten Features gehören die Aufnahme von Google Street View, die Richtungen zu öffentlichen Verkehrsmitteln und während des Gehens, und die Fähigkeit, die Adresse eines Drop-Pin anzuzeigen. Rechner Wenn das Gerät im Landschaftsmodus ist, zeigt die Rechner-App einen wissenschaftlichen Rechner an. Außerdem wird das App-Symbol aktualisiert. Einstellungen Einstellungen Einstellungen hatten nun die Möglichkeit, Wifi wieder einzuschalten, während im Flugzeugmodus, sowie die Möglichkeit, die Standortdienste innerhalb der App ein- und auszuschalten. Reception Rene Ritchie at iMore sagte: "Overall, iPhone Firmware 2.0 ist eine atemberaubende Leistung, die wirklich das iPhone mit dem Apple II und Mac als eine der großen Revolutionen in der modernen Technologie auf Par gesetzt. Es nimmt es über einfache Telefon + iPod, oder sogar Smartphone, und macht es zum führenden Kotender für die nächste große Verschiebung in Computing. " Sie kritisierten es jedoch für Stabilitätsfragen und allgemeine Schwindel. Macworld sagte: "Die iPhone 2.0-Software ist voller der Art von Verbesserungen, die Sie von einem Apple-Produkt der zweiten Generation erwarten würden. Das iPhone OS ist immer noch nicht perfekt, und wir wünschen, dass Apple einige lingernde Mängel angesprochen hat, aber es ist ein willkommener Schritt für das, was bereits wohl die beste mobile Plattform auf dem Markt war". iPod Touch Preis iPhone OS 2 Kosten $9.95 für iPod Touch Benutzer; es war kostenlos für iPhone Benutzer. Unterstützte Geräte Referenzen Externe Links iPhone OS 2 auf der Wayback-Maschine (archiviert am 12. September 2008)