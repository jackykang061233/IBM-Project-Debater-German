Das Future of Life Institute (FLI) ist eine gemeinnützige Forschungseinrichtung und eine außerbetriebliche Organisation im Boston-Bereich, die zur Minderung existentieller Risiken gegenüber der Menschheit, insbesondere existentielles Risiko durch fortgeschrittene künstliche Intelligenz (KI) arbeitet. Zu seinen Gründern gehören der MIT-Kosmologe Max Tegmark und der Skype-Mitbegründer Jaan Tallinn, und sein Beraterrat umfasst Unternehmer Elon Musk. Hintergrund FLIs Mission ist es, Forschung und Initiativen zur Sicherung des Lebens zu analysieren und zu unterstützen und optimistische Zukunftsvisionen zu entwickeln, einschließlich positiver Wege für die Menschheit, ihren Kurs in Reaktion auf neue Technologien und Herausforderungen zu lenken. Die FLI konzentriert sich insbesondere auf die potenziellen Risiken für die Menschheit aus der Entwicklung von human- oder superintelligenter künstlicher allgemeiner Intelligenz (AGI). Das Institut wurde im März 2014 von dem MIT-Kosmologen Max Tegmark, Skype-Mitbegründer Jaan Tallinn, Harvard-Absolvent Student und International Mathematical Olympiad (IMO) Medaillenist Viktoriya Krakovna,Boston University Absolvent Meia Chita-Tegmark (Tegmarks Frau) und UCSC Physiker Anthony Aguirre gegründet. Der 14-Personen-Wissenschaftsbeirat des Instituts umfasst 12 Männer und 2 Frauen und umfasst Informatiker Stuart J. Russell und Francesca Rossi, Biologe George Church, Kosmologin Saul Perlmutter, Astrophysiker Sandra Faber, theoretischer Physiker Frank Wilczek, Unternehmer Elon Musk, und Schauspieler und Wissenschaftskommunikatoren Alan Alda und Morgan Freeman (sowie Kosmologin Stephen Hawking 2018). Veranstaltungen Am 24. Mai 2014 veranstaltete das Future of Life Institute seine Eröffnungsveranstaltung am MIT: eine Podiumsdiskussion über "The Future of Technology: Benefits and Risks", moderiert von Alan Alda. Die Podiumsdiskussionisten waren der synthetische Biologe George Church, der Genetiker Ting Wu, der Ökonom Andrew McAfee, der Physiker und Nobel Laureate Frank Wilczek und der Skype Mitbegründer Jaan Tallinn. Die Diskussion umfasste eine breite Palette von Themen aus der Zukunft der Bio-Engineering und der persönlichen Genetik zu autonomen Waffen, AI-Ethik und der Singularität. Am 2. bis 5. Januar 2015 organisierte FLI in Puerto Rico die Konferenz "Die Zukunft der KI: Chancen und Herausforderungen", die die weltweit führenden KI-Builder aus Wissenschaft und Industrie zusammenführte, um sich gegenseitig und Experten in Wirtschaft, Recht und Ethik zu engagieren. Ziel war es, vielversprechende Forschungsrichtungen zu identifizieren, die dazu beitragen können, die zukünftigen Vorteile von KI zu maximieren. Auf der Konferenz, die später von Stephen Hawking, Elon Musk, und vielen Experten für künstliche Intelligenz unterzeichnet wurde, hat das Institut einen offenen Brief zur KI-Sicherheit im Kreis geführt. Am 5. bis 8. Januar 2017 organisierte FLI die Beneficial AI-Konferenz in Asilomar, Kalifornien, eine private Versammlung dessen, was die New York Times "heavy hitters of A.I" nannte (einschließlich Yann LeCun, Elon Musk und Nick Bostrom). Das Institut veröffentlichte eine Reihe von Prinzipien für verantwortungsvolle KI-Entwicklung, die aus der Diskussion auf der Konferenz, unterschrieben von Yoshua Bengio, Yann LeCun, und viele andere KI-Forscher. Am 4. Januar 2019 organisierte FLI die Beneficial AGI Konferenz in Puerto Rico. Dieses Treffen konzentrierte sich auf langfristige Fragen, um sicherzustellen, dass die künstliche allgemeine Intelligenz für die Menschheit von Vorteil ist. Globales Forschungsprogramm Am 15. Januar 2015 kündigte das Future of Life Institute an, dass Elon Musk 10 Millionen US-Dollar gespendet hatte, um eine globale KI-Forschung zu finanzieren. Am 22. Januar 2015 veröffentlichte die FLI einen Antrag auf Vorschläge von Wissenschaftlern in akademischen und anderen gemeinnützigen Einrichtungen. Im Gegensatz zu typischen KI-Forschung konzentriert sich dieses Programm darauf, KI sicherer oder vorteilhafter für die Gesellschaft zu machen, anstatt nur mächtiger. Am 1. Juli 2015 wurden insgesamt 7 Millionen $ an 37 Forschungsprojekte vergeben. In den Medien protestieren USA und Alliierten U.N. Gespräche mit Verbot von Kernwaffen in der New York Times "Is Artificial Intelligence a Threat?" in der Chronik der Hochschulbildung, einschließlich Interviews mit FLI Gründer Max Tegmark, Jaan Tallinn und Viktoriya Krakovna." Aber was würde das Ende der Menschheit für mich bedeuten?" ein Interview mit Max Tegmark über die Ideen hinter FLI im Atlantik. "Transcending Complacency on Superintelligent Machines", eine op-ed in der Huffington Post von Max Tegmark, Stephen Hawking, Frank Wilczek und Stuart J. Russell auf dem Film Transcendence."Top 23 Einzeilen aus einem Panel Diskussion, die mich eine verrückte Idee" in Diana Crow Science. "Ein offener Brief an alle, die in Angst vor künstlicher Intelligenz geraten sind", beinhaltet "Forschungsprioritäten für robuste und beneidenswerte Künstliche Intelligenz: ein Open Letter" der FLI Michael del Castillo (15. Januar 2015). " Startup Branding verbirgt nicht apokalyptische Untertöne von Brief unterschrieben von Elon Musk". Starten Sie Business Journal. Edd Gent (21. Januar 2015)."Ex Machina Film fragt: Ist AI-Forschung in sicheren Händen?". Technik und Technologie. Archiviert vom Original am 26. Januar 2015. Erschienen am 26. Januar 2015."Creating Künstliche Intelligenz" auf PBS Siehe auch Future of Humanity Institute Centre for the Study of Existential Risk Global Katastrophenrisiko Leverhulme Centre for the Future of Intelligence Machine Intelligence Research Institute Vasily Arkhipov, "Der Mann, der die Welt gerettet hat" Referenzen Externe Links Offizielle Website