Stochastic lauf (oftened bis Ende) ist eine iterative Methode zur Optimierung einer objektiven Funktion mit geeigneten Eigenschaften (z.B. unterschiedlicher oder subdifferenzierbarer) Eigenschaften. Es kann als eine katastrophale Annäherung der Absterbenoptimierung angesehen werden, da sie die tatsächliche Differenz (ber dem gesamten Datensatz berechnet) durch eine Schätzung ersetzt (von einem zufällig ausgewählten Teil der Daten berechnet). Insbesondere bei hochdimensionalen Optimierungsproblemen verringert dies die rechnerische Belastung, wodurch schnellere Iterationen im Handel für eine niedrigere Konvergenzquote erreicht werden. Obwohl die Grundidee hinter der energetischen Annäherung wieder auf den Robbins-Monro-Algorithmus der 1950er Jahre zurückverfolgt werden kann, ist die Stettichung zu einer wichtigen Optimierungsmethode geworden. Hintergrund sowohl statistischer Schätzung als auch maschinelles Lernen betrachten das Problem der Minimierung einer objektiven Funktion, die in Form einer Summe besteht: Q ( w ) = 1 n  i i = 1 n Q i ( w ) , {\displaystyle Q(w)= {\n 1sum i=1}^{n}Q_{i}(w), wo der Parameter w {\displaystyle Q(w) . } schätzt wird. Jede Zusammenfassung Q i WELLdisplaystyle Q_{i} ist in der Regel mit der i {\displaystyle i} -th Beobachtung in den für die Schulung verwendeten Daten verbunden. Klassische Statistiken ergeben sich in mindestens Quadratmetern und in der höchstwahrscheinlichen Schätzung (für unabhängige Beobachtungen). Die allgemeine Klasse der Erreger, die sich als Erreger von Summen ergeben, wird als M-Schätzer bezeichnet. In Statistiken wurde jedoch schon lange erkannt, dass eine sogar lokale Minimierung zu restriktiv für einige Probleme der höchstwahrscheinlichen Schätzung ist. zeitgenössische statistische Helfer betrachten daher häufig ortsfeste Punkte der Wahrscheinlichkeitsfunktion (oder Nullen ihrer Derivate, der Bewertungsfunktion und anderer Abschätzungsformen). Das Problem der Summenminimierung stellt sich auch auf eine empirische Risikominimierung. In diesem Fall ist Q i ( w ) Memestyle Q_{i}(w) der Wert der Verlustfunktion bei i {\displaystyle i} -th Beispiel und Q ( w ) KINGstyle Q(w)} das empirische Risiko. Bei der Verwendung zur Minimierung der oben genannten Funktion würde ein Standard (oder eine Charge)-Rückgangsmethode folgende Werte erfüllen: w := ·  w Q ( w ) = w η  i i = 1    i Q i = 1 n  i Q i ( w ) , ggiodisplaystyle w:=w-\nabla Q(w)=w-Fitfracggioeta {n}}\sum _i=1}\nabla Q_{i}(w), wo η KINGstyle \eta } eine Sprunggröße ist (in manchen Fällen die Lernrate im Maschinenbau). In vielen Fällen haben die Zusammenfassungen eine einfache Form, die eine kostengünstige Bewertung der Summe und der Summenhöhe ermöglicht. In Statistiken beispielsweise ermöglichen ein-Parameter exoniale Familien wirtschaftliche Bewertungen und ziehungsbedingte Bewertungen. In anderen Fällen kann bei der Bewertung der Summe jedoch eine kostspielige Bewertung der Verluste aus allen Zusammenfassungen erforderlich sein. Wenn die Ausbildungseinrichtung enorm ist und keine einfachen Formeln vorhanden sind, wird die Bewertung der Unzulänglichkeiten sehr teuer, da die Bewertung der Kluft alle Rücklagen der Zusammenfassungen und Funktionen bewertet. Um die rechnerischen Kosten bei jeder Iteration zu verankern, werden die Stämmen-Rückgangsproben zu einem Teil von Zusammenfassungen und Funktionen in jedem Schritt zusammengefasst. Dies ist sehr wirksam im Falle groß angelegter maschinenlesbarer Lernprobleme. Iterative Methode In Stämmen (oder Online-Rückgang) wird der tatsächliche Wert von Q ( w ) displaystyle Q(w)} mit einem einzigen Beispiel angeglichen: w : · .  i Q i ( w ) . KINGstyle w:=w-\eta \nabla Q_{i}(w) Da der Algorithmus durch die Ausbildungseinrichtung ausläuft, führt er die oben genannte Aktualisierung für jedes Ausbildungsbeispiel durch. Mehrere Fahrten können über die Ausbildung bis zur Konvergenz des Algorithmus vorgenommen werden. Wenn dies geschieht, können die Daten für jeden Pass gestrichen werden, um Zyklen zu verhindern. Typische Umsetzungen können eine anpassbare Lernrate verwenden, um den Algorithmus zu konvergieren. In Pseudocode können folgende Stämmchen ermittelt werden: Ein Kompromiß zwischen der Rechenleistung und der Neigung zu einem einzigen Beispiel besteht darin, die Kluft gegen mehr als ein Ausbildungsbeispiel (sogenannte Mini-batch) zu berechnen. Dies kann deutlich besser als die beschriebene tatsächliche katastrophale Abneigung sein, weil der Code die Vektorisationsbibliotheken nutzen kann, anstatt jeden Schritt getrennt zu gestalten. Man kann auch zu einer reibungsloseren Konvergenz führen, da die bei jedem Schritt ermittelte Verschlechterung über mehr Ausbildungsbeispiele durchschnittlich ist. Mit den Theorien der Konvex-minimierung und der energetischen Annäherung wurde die Konvergenz der Stettin-Rückgang analysiert. Kurz gesagt, wenn die Lernraten   WELLdisplaystyle \eta } mit einer angemessenen Rate sinken und relativ milde Annahmen aufweisen, konvergieren sich die Stämmen des Abgangs nahezu sicher auf ein globales Minimum, wenn die objektive Funktion konvex oder pseudoconvex ist und ansonsten fast sicher auf ein lokales Minimum abgestimmt wird. Dies ist eine Folge des Robbins – Siegmund theorem. Beispiel Lassen Sie uns anschreiben, dass wir eine gerade Linie y ^ = w 1 + w 2 x displaystyle WELLhat y!=\!w_{1}+w_{2}x zu einer Ausbildung, die mit Beobachtungen ( x 1 , x 2 , ... , x n ) cudisplaystyle (x_{1},x_{2},\ldots ,x_{n)} und den entsprechenden Reaktionen ( y 1 ^ , y 2 ^ , ... n ^ ) KINGstyle {\hat1,}}}1 y1,}}}, y2 {2, y, y 2  y,  y ) ) ) )  y )  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  y  Die zu minimierende Funktion ist: Q ( w ) =  i i = 1 n Q i ( w ) =  i i = 1 n ( y i ^ − y i) 2 =  i i = 1 n (w 1 + w 2 x i − y i ) 2 . KINGstyle Q(w)=\sum i=1}^{n}Q_{i}(w)=\sum _i=1}^{n(n{\(Gethat) y_{i}}}-y_{i}\right)^{2} i=1}\n)left(w_{1}+w_{2}x_{i}-y_{i)right)2.2. Letzte Linie des oben genannten Pseudocodes für dieses spezifische Problem wird: [w 1 w 2 ] [w 1 w 2 ] [    w w 1 ( w 1 + w 2 x i − y i ) 2 )  2 w 2 ( w 1 + w 2 x i − y i ) 2 ] = [w 1 w 2 ] -  [ [ 2] 2 x i - y i ) 2 x i ( w 1 + w 2 x i - y i ) ] . Memedisplaystyle beginnt{bmatrix}w_{1}\\w_{2}\end{b Matrix::=}w_{1}\\w_{b Matrix}}-\eta beginnen 7.8partial {\}partial w_{1)(w_{1}+w_{2}x_{i}-y_{i})^{2}\\{\frac 7.8partial {\}partial w_{2)(w_{1}+w_{2}x_{i}-y_{i})^{2}\end{bmatrix== faserbegin{b Matrix}w_{1}\\w_{2}\end{b Matrix}}-\eta beginnen{bmatrix}2(w_{1}+w_{2}x_{i}-y_{i})\\2x_{i}(w_{1}+w_{2}x_{i}-y_{i})\end{b Matrix. Hinweis darauf, dass in jedem Iteration (auch als Aktualisierung bezeichnet) nur die auf einem einzigen Punkt x i displaystyle x_{i} bewerteten Unterschiede bewertet werden, anstatt auf der Serie aller Proben zu bewerten. Im Vergleich zu Standard (Batch)Abfall Descent ist, dass nur ein Teil der Daten aus dem Datenset verwendet wird, um den Schritt zu berechnen, und das Datenstück wird in jedem Schritt randomisiert. Nichtable Anwendungen Stochastic gradient sind ein populärer Algorithmus für die Ausbildung einer breiten Palette von Modellen im Maschinenbau, einschließlich (linearer) Unterstützung von Vektormaschinen, logistische Regression (siehe, z.B. Vowpal Wabbit) und grafische Modelle. Zusammen mit dem Rückpropagation-Algorithmus ist es der de facto Standardgorithmus für die Ausbildung künstlicher Neuralnetze. Ihre Verwendung wurde auch in der Geophysik-Gemeinschaft berichtet, insbesondere bei Anwendungen der vollständigen Umlenkung von Wellenform (FWI). Stochastic  Abstammung konkurrieren mit dem L-BFGS-Algorithmus, der ebenfalls weit verbreitet ist. Stochastic  Abstammung wurde seit mindestens 1960 für die Ausbildung linearer Regressionsmodelle verwendet, die ursprünglich unter dem NamenADALINE. Ein weiterer katastrophaler Abgangsgorithmus ist der am wenigsten geeignete Filter (LMS). Verlängerungen und Varianten Viele Verbesserungen auf dem Basisgestein-Rückganggorithmus wurden vorgeschlagen und verwendet. Insbesondere im Bereich des Maschinenlernens wurde die Notwendigkeit, eine Lernrate (Schrittgröße) festzulegen, als problematisch anerkannt. Dieser Parameter kann zu hoch sein, um den Algorithmus zu voneinander zu unterscheiden; die Festlegung ist zu gering, führt zu langsam zu Konvergenz. Eine konzeptuelle einfache Erweiterung des blutigen Bewegungsabgangs macht die Lernrate eine abnehmende Funktion, die die Iteration Nummer t enthält und einen Lernkursplan vorgibt, so dass die ersten Erreger große Veränderungen der Parameter verursachen, während die späteren nur Feinabstimmungen vornehmen. Diese Fahrpläne sind seit der Arbeit von MacQueen auf k-means Clustering bekannt. Konkrete Leitlinien für die Auswahl der Stufengröße in mehreren Varianten von 2001 werden von Spall bereitgestellt. implizite Aktualisierungen (ISGD)A, die früher erwähnt wurden, sind in der Regel die klassische katastrophale Abneigung gegenüber der Lernrate .. Schnell Konvergenz erfordert große Lernraten, die jedoch eine numerische Instabilität bewirken können. Das Problem kann weitgehend gelöst werden, indem implizite Aktualisierungen berücksichtigt werden, bei denen die Stächsische Kluft an der nächsten Iterate gemessen wird, anstatt die aktuelle: w n e w : ·  d . Q i ( w n e w ) . KINGstyle w^{\rm neue.:=w.rm {old}}-\eta \nabla Q_{i}(w^{\rm {new)}. Diese Formel ist implizit, da w n e w Memedisplaystyle w wrm {new} auf beiden Seiten der Gleichung erscheint. Es ist eine katastrophale Form der Proximal-Rückgangsmethode, da die Aktualisierung auch als: w n e w := arg  w min w { Q i ( w ) + 1 2  | | w − w o l d | 2 } .KINGstyle w^{\rm {neue::=\arg \min w}\{Q_{i}(w)+Währungfrac 1}{2\eta * * * * Beispiel: mindestens Quadrate mit Merkmalen x 1 , ... , x n  R R p HANAstyle x_{1},\ldots ,x_{n}\in \bb {R} {^p} und Beobachtungen y 1 , ... n   R {\displaystyle y_{1},\ldots ,y_{n}\in \ Mathematikbb {R} } . Wir wollen Folgendes lösen: w  j j = 1 n ( y j − x j ́ w ) 2 , Memedisplaystyle \min {_w jsum j=1}^{n}(y_{j}-x_{j}'w)^{2, wo x j ́ w = x j 1 + x j , 2 w 2 + . . . + x j , p w faser . x_{j}'w=x_{j1}w_{1}+x_{j,2}_{2}+2,00x_{j,p} weist auf das Innenprodukt hin. Hinweis darauf, dass x WELLdisplaystyle x} als erstes Element für die Aufnahme eines Abfangens haben könnte. Klassische Stämmen-Rückgang führt wie folgt aus: w n e w = w o l + η ( y i − x i ́ w o l d ) x i livstyle w wrm neue}}=w^{\rm {old}}+\eta (y_{i}-x_{i}'w^{\rm alt))x_{i, wo i {\displaystyle i} einheitlich zwischen 1 und n {\displaystyle n} .Alobwohl theoretische Konvergenz dieses Verfahrens unter relativ milden Annahmen geschieht, kann das Verfahren in der Praxis recht instabil sein. Insbesondere, wenn   Memedisplaystyle \eta } nicht spezifiziert ist, so dass ich  i x i x i ́ {\displaystyle I-\eta x_{i}x_{i]x_{i' große absolute Eigenwerte mit hoher Wahrscheinlichkeit hat, kann das Verfahren numerisch innerhalb einiger Iterationsarten variieren. Im Gegensatz dazu können implizite Stärkung (kurz als ISGD) in geschlossenen Zügen gelöst werden, wie: w n e w = w n +  1 1 +  | 1 +  | | x i | 2 ( y i − x i ́ w o l ) x d ). 7.8displaystyle w^{\rm neue}}=w^{\rm alte++ggiofrac WELLeta  1+\eta x_{i}||2((y_{i}-x_{i}'w oldrm alt))x_{i Dieses Verfahren bleibt numerisch stabil für alle . HANAdisplaystyle \eta }, da die Lernrate nun normalisiert ist. Ein solcher Vergleich zwischen klassischem und implizitem Stchastic-Rückgang im mindestens Quadratmeter-Problem ist sehr ähnlich wie der Vergleich zwischen mindestens mittleren Quadraten (LMS) und normalisierter, mindestens mittlerer Quadratfilter (NLMS). Obwohl eine geschlossene Lösung für ISGD nur in mindestens Quadratmetern möglich ist, kann das Verfahren in einer Vielzahl von Modellen effizient umgesetzt werden. Konkret wird davon ausgegangen, dass Q i ( w ) Memestyle Q_{i}(w) nur durch lineare Kombination mit Merkmalen x i {\displaystyle x_{i} , so dass wir ∇ w Q i (w) = − q ( x i ́ w ) schreiben können. x i {\displaystyle \nabla w}Q_{i}(w)=-q(x_{i}'w)x_{i , wo q ( ) {\ R TONstyle q)\in \bb {R} möglicherweise von x i , y i {\displaystyle x_{i},y_{i} sowie nicht auf w {\displaystyle w} außer durch x i ́ w displaystyle x_{i}'w .Least Quadrate folgen dieser Regel, so dass logistische Regression und allgemeinisierte lineare Modelle. beispielsweise in mindestens Quadratmetern, q ( x i ́ w ) = y i − x i ́ w {\displaystyle q(x_{i}'w)=y_{i}-x_{i}'w  und in logistischer Regression q ( x i ′ w ) = y i − S ( x i ́ w ) {\displaystyle q(x_{i})=y_{i}-S(x_{i}'w , wo S ( u) = e u / ( 1 + e u ) Memestyle S(u)=e^{u}/(1+euu) ist die logistische Funktion. Poisson Regression, q ( x i ́ w ) = y i − e x i ́ w WELLdisplaystyle q(x_{i}'w)=y_{i}-e^{x_{i}'w und so. In solchen Einstellungen wird ISGD einfach wie folgt umgesetzt. Let f (   ) =  q q ( x i ́ w o l +  | | x i ) Memedisplaystyle f(\xi )\=eta q(x_{i}'w^{old}+\xi x_{i} {i}1200|2) , wo ξ KINGstyle \xi } scalar ist. ISGD entspricht dann: w n e w = w o l d +  i x i, wo .  = = f (ξ   ) . K rm neue}}=w}}rm {old}}+\xi ).ast x_{i},~{\text{wo}}~\xi {^\ast =}f(\xi {^\ast })    R  R  R R {\displaystyle \xi {^\ast \in \ Mathematikbb {R} } kann in den meisten regulären Modellen gefunden werden, wie die oben genannten allgemeinen linearen Modelle, die Funktion q ( ) . .  q } } \xi \xi \xi  [ . \xi  0  [ sind [min 0  f  max  0 ]  0  0  0  0 ( 0 , f) max. ], f) ], {\ 0 (f ], ) Momentum weitere Vorschläge umfassen die in Rumelhart, Hinton und Williams auf dem Rückenpropagation Lernen erschienene Dynamik. Stochastic  Abfahrt mit Dynamik erinnert an die Aktualisierung  ofw bei jeder Iteration und bestimmt die nächste Aktualisierung als lineare Kombination der Differenzen und der vorherigen Aktualisierung:  w w :=  of  w w  Q  i Q i ( w ) {\displaystyle \Delta w:=\alpha \Delta w-\nabla Q_{i}(w) := w +  w w RARstyle w:=w+\ Delta w}, die zu: w := · )  i Q i ( w ) + )  w w {\displaystyle w:=w-\eta \nabla Q_{i}(w)+\alpha \Delta w}, wo der Parameter w {\displaystyle w}, der Q ( w ) displaystyle Q(w)} minimiert, zu schätzungsweise {\ \eta } ist eine Sprunggröße (in manchen Zeiten heißt die Lernrate im Maschinenlernen) und α Memestyle \alpha } ist ein exponentieller Faktor zwischen 0 und 1, der den relativen Beitrag der aktuellen \ und früherer Verläufe zum Gewichtswechsel bestimmt. Die Namensdynamik beruht auf einer analogen Dynamik in der Physik: der Gewichtvektor w {\displaystyle w} , der als ein durch Parameterraum reisendes Partikel betrachtet wird, beschleunigt sich vom Verlust (Stärkung). Anders als in der klassischen Stämmen-Rückgang tendenziell dazu, in derselben Richtung zu reisen, wodurch Oszillationen verhindert werden. Momentum wurde seit Jahrzehnten erfolgreich von Computerwissenschaftlern in der Ausbildung künstlicher Neuralnetze genutzt. Die Dynamik ist eng mit der unterdamped Langevin Dynamik verknüpft und kann mit Simuled Annealing kombiniert werden. Averaging durchschnittlicher blutdruckbedingter Abgang, der in den späten 80er Jahren unabhängig von Ruppert und Polyak entwickelt wurde, ist gewöhnliche blutige Abwanderung, die im Durchschnitt seines Parametervektors über die Zeit verfügt. Das ist die gleiche wie für gewöhnliche Stchastic sprungweisend, aber der Algorithmus hält auch die W  w = 1 t  i i = 0 t − 1 w i {\displaystyle  cubar w== Marafrac 1 1t oft i=0-1t-1}w_{i . Wenn eine Optimierung erfolgt, findet dieser durchschnittliche Parametervektor den Platz des w. AdaGrad Adagrad (für den adaptiven Gefälle-Algorithmus) ist ein modifizierter klächsischer Abstammungsgorithmus mit je-Parameter Lernrate, der erstmals 2011 veröffentlicht wurde. Informiert, erhöht die Lernrate fürs Parameter und verringert die Lernrate für diejenigen, die weniger wenig weniger klein sind. Diese Strategie verbessert häufig die Konvergenzleistung im Vergleich zu Standard-Städten-Rückgang in Situationen, in denen die Daten geringer und geringer sind. Beispiele solcher Anwendungen sind die Verarbeitung natürlicher Sprache und die Imageerkennung. Es verfügt immer noch über einen Basislernsatz  of, aber dies wird multipliziert mit den Elementen eines Vektors {Gj,j}, der die diagonale äußere Produktmatrix G =  = = 1 gτ g τ g  of g  of T KINGstyle G=\sum HANA_tau =1}t} }g_HANAtau {^\}sf {T}, wo g  i =  i Q i ( w ) {\displaystyle g_ggiotau =\}nabla Q_{i}(w) , die ziehung, auf Iteration .. Die diagonale wird von G j , j =   = 1 t g {\ , j 2 Memestyle G_{j,j} =1}^{t}g_livtau ,j}^{2 . Dieservector wird nach jeder Ersetzung aktualisiert. Die Formel für eine Aktualisierung ist jetzt w:= w −  i d i a g (G ) − 1 2 ) g {\displaystyle w:=w-\eta ,\rm {diag} (G) 1-Barfrac 1 12 12odot g} oder schriftlich als Per-Parameter aktualisiert, w : j - η G j , j g j . KINGstyle w_{j}:=w_{j}-Barfrac Memeeta {\}sqrt G_{j,j}}}}g_{j. Jedes {G(i,i)} führt zu einem skalierenden Faktor für die Lernrate, der für einen einzigen Parameterhülse gilt. G i =  in = 1 t g  2 2 displaystyle HANAsqrt G_{i== Finanzsqrt Memesum ggio_tau =1}t} 22 ist die l2 Norm früherer Derivate, extreme Parameter aktualisiert werden gedämpft, während Parameter, die nur wenige oder kleine Aktualisierungen erhalten, höhere Lernraten erhalten. Adagrad wurde zwar für Konvex-Probleme entwickelt, wurde aber erfolgreich auf die nicht konvexische Optimierung angewendet. RMSProp RMSProp (für den Boden Mean Square Propagation) ist ebenfalls eine Methode, in der die Lernrate für die einzelnen Parameter angepasst wird. Die Idee besteht darin, die Lernrate für ein Gewicht durch einen durchschnittlichen Durchschnitt der jüngsten Defizite für dieses Gewicht aufzuteilen. Zum einen wird der laufende Durchschnitt in Form von Quadratmetern, v ( w , t ) :=  w v ( w , t − 1 ) + ( 1 − γ ) (∇ Q i ( w ) ) 2 7.8displaystyle v(w,t):=\gamma v(w,t-1)+(1-\gamma )(1 \gamma )(w) {i}(w)2)2, ) . . . . . . . style . . . . . . . amma amma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  Und die Parameter werden wie folgt aktualisiert: w := w  –  w v ( w , t )  i Q i ( w ) faserstyle w:=w-ggiof Raceta )sqrt {v(w,t)}}}\nabla Q_{i}(w) RMSProp hat eine gute Anpassung der Lernrate in verschiedenen Anwendungen gezeigt.RMSProp kann als Generalisierung von Rprop gesehen werden und ist in der Lage, mit Mini-Beschwerden zusammenzuarbeiten und sich nicht nur mit vollständigen Themen zu befassen. Adam Adam Adam (kurz für eine anpassbare Momentabschätzung) ist ein aktualisiertes Programm für den RMSProp Optimierungr. In diesem Optimierungs-Algorithmus werden die Durchschnittswerte sowohl der Gefälle als auch die zweite Phase der Verläufe verwendet. Parameter w ( t) Memedisplaystyle w^{(t)} und Verlustfunktion L ( t) Memestyle L L(t)} , wo t Memestyle t} die derzeitige Ausbildung (indexiert am 0 Memestyle 0}) Indexiert, wird der Parameter von Adam durch: m w ( t + 1 ) . · β 1 m w ( t ) + ( 1 − β 1 )  L w L ( t ) Glühbirnestyle m_{w((t+1) 1ringe \beta 1} m_{w((t)}+(1-\beta {_1})\nablaw}L((t) vw (t) · 1 ) · β 2 v ( t) + ( 1 − β 2 } } L (T }) 2 · }^{ ) w }^{ }^{ }^{ ( ( ( ( ( L  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 2  2 m)_{w}= Finanzfrac m_{w((t+1)}}{1-\beta {_1} / ^ w = vw ( t + 1 ) 1 − β 2 displaystyle 7.8hat v__{w}= Finanzfrac v_{w((t+1)}}{1-\beta_{2 w ( t + 1 ) · ) m ^ w v ^ w + ε     {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ {\ ) ) ) )  w ) ) ) )  w ) ) ) ) ) ) ) ) ) ) ) ) ) {\ {\ {\ {\ ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )  HANA m__ v__{w++\epsilon }}}, wo ε \epsilon } ein kleiner scalar (z.B. 10 − 8 {\displaystyle 10}-8} ) verwendet wird, um eine Teilung um 0 zu verhindern, und β 1 {\displaystyle \beta {_1} (z.B. 0,9) bzw. β 2 {\displaystyle \beta \beta {_2} (z.B. 0,999) sind die vergessenen Faktoren und die Verluste der zweiten Tage. Squaring und Quadratwurzeln werden in der Tat umgesetzt. Backtracking Line Search Backtracking Line Search ist eine weitere Variante der Bewegungsabfall. Alle der unten aufgeführten werden aus dem genannten Link stammen. Sie basiert auf einer Bedingung, die als „Armijo-Goldstein“- Bedingung bekannt ist. Beide Methoden ermöglichen eine Änderung der Lernraten bei jeder Iteration; allerdings ist die Art des Wandels anders. Backtracking Line-Suche nutzt Funktionsbewertungen, um die Bedingung von Armijo zu prüfen, und im Prinzip kann der Anschluss an den Algorithmus zur Bestimmung der Lernraten lange und unbekannt sein. Anpassungsorientiertes Wachstum braucht keinen Anschluss an die Festlegung von Lernraten. Anpassungsergebnis garantiert jedoch nicht das "dringe Immobilien" – das Backtracking Line Search genießt –, das ist, dass f ( x n + 1 ) ≤ f ( x n ) Memestyle f(x_{n+1})\leq f(x_{n)} für alle n. Liegt die Höhe der Kostenfunktion weltweit bei Lipschitz kontinuierlich, mit Lipschitz konstant L, und die Lernrate wird in der Reihenfolge 1/L ausgewählt, dann ist die Standardversion von FORTSCHRITTE ein Sonderfall der Rückführungs-Such. Grenzübergreifende Methoden Ein katastrophaler Analog der Norm (deterministic) Newton-Raphson (eine zweite Stufe) bietet eine asymmetrische, optimale oder nahezu optimale Form der iterativen Optimierung bei der Festlegung einer steinigen Annäherung. Von Byrd, Hansen, Nocedal und Singer wurde eine Methode entwickelt, die direkte Messungen der Hessian matrices der Zusammenfassungen der empirischen Risikofunktion nutzt. Direkte Bestimmung der erforderlichen Hessian matrices für die Optimierung kann jedoch in der Praxis nicht möglich sein. Konkrete und theoretische solide Methoden für die Zweit-Versionen von NACH, die keine direkten Hessian-Informationen erfordern, werden von Spall und anderen bereitgestellt. (Ein weniger effizientes Verfahren auf der Grundlage von finite Differenzen statt gleichzeitiger Perturbationen) wird von Ruppert gewährt.) Diese Methoden, die keine direkten Hessian-Informationen erfordern, basieren auf den Werten der Zusammenfassungen in der oben genannten empirischen Risikofunktion oder den Werten der Rücklagen der Zusammenfassungen (d.h. der Inputs). Insbesondere ist die Zweitgrenzoptimität asymmetrisch erreichbar ohne direkte Berechnung der Hesssian matrices der Zusammenfassungen in der empirischen Risikofunktion. Anmerkungen Lesen Sie auch auf die Suche nach einer Rückführungslinie – Änderungen, die zu einer Zeit koordiniert werden, statt eines Beispiels für lineares Lernen Stochastic Berg-Ausgangsreferenzen Lesen Bot, Léon (2004), "Stochastic Learning"," Advanced Lectures zum Thema Maschinenbau, LNAI, 3176, Springer, pp.146-168, ISBN [3-540-23122-6 Buduma, Nikhil; Springer; Zusammenkunft, "Bedfall Descents", "Grundkenntnisse von vertieftem Lernen": Design, "Jung" Außenbeziehungen Ublas für lineare Regression Werkzeugmaschinen Learning Algorithms "Gradient Ding, How Neural Networks Learn".3Blue1Bra.Oktober 2017 – via YouTube.Goh (April 4, 2017). "Warum Real Works". Destill. Interaktives Papier, das die Dynamik erläutert.