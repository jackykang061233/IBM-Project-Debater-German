Kovarianz-Matrix-Adaption Evolution Strategie (CMA-ES) ist eine bestimmte Art von Strategie zur numerischen Optimierung. Evolutionsstrategien (ES) sind stochastische, derivatfreie Methoden zur numerischen Optimierung nichtlinearer oder nichtkonvex kontinuierlicher Optimierungsprobleme. Sie gehören zur Klasse evolutionärer Algorithmen und evolutionärer Berechnung. Ein evolutionärer Algorithmus basiert weitgehend auf dem Prinzip der biologischen Evolution, nämlich dem wiederholten Wechselspiel von Variation (über Rekombination und Mutation) und der Selektion: In jeder Generation (Bewegung) werden neue Individuen (Kandidatlösungen, bezeichnet als x {\displaystyle x}) durch Variation, meist stochastisch, der aktuellen Elternindividuen erzeugt. Dann werden einige Personen ausgewählt, um die Eltern in der nächsten Generation zu werden, basierend auf ihrem Fitness- oder Zielfunktionswert f ( x ) {\displaystyle f(x}) .Like this, over the generation Sequenz, Individuen mit besseren und besseren f {\displaystyle f} -Werte werden erzeugt. In einer Evolutionsstrategie werden neue Kandidatlösungen nach einer multivariaten Normalverteilung in R n {\displaystyle \mathbb {R} {^n} abgetastet.Die Rekombination entspricht der Auswahl eines neuen Mittelwerts für die Verteilung. Mutation ist die Addition eines Zufallsvektors, einer Störung mit Nullmittel. Die paarweisen Abhängigkeiten zwischen den Größen in der Verteilung werden durch eine Kovarianzmatrix dargestellt. Die Kovarianz-Matrixanpassung (CMA) ist ein Verfahren zur Aktualisierung der Kovarianz-Matrix dieser Verteilung. Dies ist besonders dann sinnvoll, wenn die Funktion f {\displaystyle f} schlecht konditioniert ist. Die Anpassung der Kovarianz-Matrix ermöglicht das Erlernen eines zweiten Ordnungsmodells der zugrunde liegenden Zielfunktion ähnlich der Annäherung der inversen hessischen Matrix in der quasi-Newton-Methode in der klassischen Optimierung. Im Gegensatz zu den meisten klassischen Methoden werden weniger Annahmen über die Art der zugrunde liegenden Zielfunktion gemacht. Nur das Ranking zwischen Kandidatenlösungen wird für das Lernen der Probenverteilung genutzt, und es werden weder Derivate noch die Funktionswerte selbst nach der Methode benötigt. Grundsätze Im CMA-ES-Algorithmus werden zwei Hauptprinzipien für die Anpassung von Parametern der Suchverteilung ausgenutzt. Zunächst ein Maximum-Lihood-Prinzip, basierend auf der Idee, die Wahrscheinlichkeit von erfolgreichen Kandidatenlösungen und Suchschritten zu erhöhen. Der Durchschnitt der Distribution wird so aktualisiert, dass die Wahrscheinlichkeit von bisher erfolgreichen Kandidatenlösungen maximiert wird. Die Kovarianzmatrix der Verteilung wird (inkrementell) so aktualisiert, dass die Wahrscheinlichkeit früher erfolgreicher Suchschritte erhöht wird. Beide Updates können als natürliche Gradientenabstieg interpretiert werden. Damit führt die CMA auch eine iterierte Hauptkomponentenanalyse erfolgreicher Suchschritte unter Beibehaltung aller Hauptachsen durch. Die Schätzung der Verteilungsalgorithmen und der Cross-Entropy-Methode basiert auf sehr ähnlichen Ideen, aber Schätzung (nicht-incremental) der Kovarianz-Matrix durch Maximierung der Wahrscheinlichkeit erfolgreicher Lösungspunkte statt erfolgreicher Suchschritte. Zweitens werden zwei Pfade der Zeitentwicklung des Verteilungsmittels der Strategie erfasst, genannt Such- oder Evolutionspfade. Diese Wege enthalten signifikante Informationen über die Korrelation zwischen aufeinanderfolgenden Schritten. Insbesondere, wenn aufeinanderfolgende Schritte in einer ähnlichen Richtung durchgeführt werden, werden die Evolutionspfade lang. Die Evolutionspfade werden auf zwei Arten ausgenutzt. Ein Weg wird für das Kovarianz-Matrix-Adaptionsverfahren anstelle von einzelnen erfolgreichen Suchschritten verwendet und ermöglicht eine möglicherweise viel schnellere Varianzerhöhung günstiger Richtungen. Der andere Weg dient dazu, eine zusätzliche Schrittgrößenregelung durchzuführen. Diese Schritt-Größe-Steuerung zielt darauf ab, aufeinanderfolgende Bewegungen der Verteilung orthogonal in der Erwartung bedeuten. Die Schritt-Größe-Kontrolle verhindert effektiv vorzeitige Konvergenz, ermöglicht aber schnelle Konvergenz zu einem Optimum. AlgorithmIm Folgenden wird die am häufigsten verwendeten (μ/μw, λ)-CMA-ES umrissen, wobei in jedem Iterationsschritt eine gewichtete Kombination der μ am besten aus λ neuen Kandidatenlösungen zur Aktualisierung der Verteilungsparameter verwendet wird. Die Hauptschleife besteht aus drei Hauptteilen: 1) Probenahme neuer Lösungen, 2) Nachbestellung der abgetasteten Lösungen auf Basis ihrer Fitness, 3) Aktualisierung der internen Zustandsvariablen basierend auf den neu bestellten Proben. Ein Pseudocode des Algorithmus sieht wie folgt aus. λ {\displaystyle \lambda} // Anzahl der Proben pro Iteration, mindestens zwei, im allgemeinen > 4 initialisieren m {\displaystyle m} σ {\displaystyle \sigma }, C = I {\displaystyle C=I}, p σ = 0 {\displaystyle p_{\sigma =0 , p c = 0 {\displaystyle p_{c}=0 // initialisieren Zustandsvariablen während nicht enden do // iterate for i {\displaystyle i} in { 1 ... λ } {\displaystyle {1\ldots \lambda \} do // Sample λ {\displaystyle \lambda } neue Lösungen und bewerten sie x i = {\displaystyle x_{i=} pattern_multivariate_normal(mean = m {\displaystyle {=m , covariance_matrix = σ 2 C {\displaystyle {=\}sigma {^2}C ) f_{i}=\Operatorname {fitness} (x_{i}) x 1 ... λ {\displaystyle x_{1\ldots \lambda } ← x s ( 1 ) ... s (λ ) {\displaystyle x_{s\ldots s(\lambda )}} mit s (style i ) = argsort wir brauchen später m - m' {\displaystyle m-m'} und x i - m' {\displaystyle x_{i}-m' m {\displaystyle m} ← update_m ( x 1 , ..., x λ ) {\displaystyle (x_{1},\ldots ,x_{\lambda }} // bewegen Mittel zu besseren Lösungen p σ {\displaystyle p_{\sigma }} ← update_ps ( p σ , σ − 1 C − 1 / 2 ( m − m') ) {\displaystyle (p_{\sigma ,\}sigma 1}C^{-1/2}(m-m') // update isotropic evolution path p c {\displaystyle p_{c} σ σ σ σ σ σ σ σ σ σ σ σ φ σ σ σ σ σ σ σ σ σ σ σ σ φ σ σ σ σ σ σ σ σ σ σ σ σ φ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ Die Reihenfolge der fünf Update-Zuweisungen ist relevant: m {\displaystyle m} muss zuerst aktualisiert werden, p σ {\displaystyle p_{\sigma }} und p c {\displaystyle p_{c} müssen aktualisiert werden, bevor C {\displaystyle C} und σ {\displaystyle \sigma } zuletzt aktualisiert werden müssen. Im Folgenden werden die Aktualisierungsgleichungen für die fünf Zustandsvariablen angegeben. Dabei handelt es sich um die Suchraumdimension n {\displaystyle n} und den Iterationsschritt k {\displaystyle k} . Die fünf Zustandsvariablen sind m k ε R n {\displaystyle m_{k} in \mathbb {R} {^n}, die Verteilungsmittel- und aktuelle Lieblingslösung für das Optimierungsproblem, σ k > 0 {\displaystyle \sigma {_k}>0 , the step-size, C k {\displaystyle C_{k}, a symmetric and positiv-definite n × n {\displaystyle n\times n} covariance matrix with C 0 = I {\displaystyle C_{0}= I und p σ ε R n , p c ε R n {\displaystyle p_{\sigma \}in \mathbb {R},p_{c}\in \mathbb {R}, zwei Evolutionspfade, zunächst auf den Nullvektor gesetzt. Die Iteration beginnt mit der Probenahme λ > 1 {\displaystyle \lambda >1* Kandidatenlösungen ε R n {\displaystyle x_{i}\in \mathbb {R} {^n} aus einer multivariate Normalverteilung N (m_{k, σ k 2 C k ) {\displaystyle \textstyle {\mathcal N}(m_{k},\sigma k}{2}C_{k) (m_{k},\sigma k{2}C_{k})\\&\sim \ m_{k}+\sigma_{k}\times {\mathcal N}(0,C_{k})\end{justed Die zweite Zeile schlägt die Interpretation als Störung (Mutation) des aktuellen Lieblingslösungsvektors m k {\displaystyle m_{k} (der Verteilungsmittelvektor) vor. Die Kandidatenlösungen x i {\displaystyle x_{i} werden auf der Zielfunktion f : R n → R {\displaystyle f:\mathbb bewertet. {R} {^n}\to \mathbb {R} zu minimieren. Denotieren der f {\displaystyle f} -sortierten Kandidatenlösungen wie { x i : λ  i i = 1 ... λ } = { x i  i i = 1 ... λ } und f ( x 1 : λ ) ≤ ⋯ ≤ f ( x μ : λ ) ≤ f ( x μ + 1 : λ ) ≤ da, {\displaystyle x_{i:\lambda x_{i}\midi=1\dots\lambda \}text und }f(x_{1:\lambda \})leq \dots \leq f(x_{\mu \:lambda \})leq f(x_{\mu +1:\lambda \})leq \cdots ,} der neue Mittelwert wird als m k + 1 berechnet 1 μ w i x i: λ = m k + Σ i = 1 μ w i ( x i : λ - m k ) * i=1{\mu w_{i}\,x_{i:\lambda = +/m_{k}+\sum * i=1{\mu w_{i}\,(x_{i:\lambda -m_{k})\end{ausgerichtet, wenn die positiven (Rekombination) Gewichte w 1 ≥ w 2 ≥ ⋯ ≥ w μ > 0 {\displaystyle w_{1}\geq w_{2}\geq\dots \geq w_{\mu >0 sum to one. Typischerweise werden μ ≤ λ / 2 {\displaystyle \mu \leq \lambda /2} und die Gewichte so gewählt, daß μ w := 1 = 1 μ wi 2 ≈ λ / 4 {\displaystyle \textstyle \mu {_w}:=1/\sum * i=1{\mu w_{i}^{2}\approx \lambda /4} .Die einzige Rückmeldung aus der Objektivfunktion hier und im folgenden ist eine Ordnung der abgetasteten Kandidatenlösungen aufgrund der Indizes i: λ {\displaystyle i:\lambda } . Die Schritt-Größe σ k {\displaystyle \sigma {_k} wird mit kumulativer Schritt-Größe-Adaption (CSA,) manchmal auch als Weglängensteuerung bezeichnet aktualisiert. Der Evolutionspfad (oder Suchpfad) p σ {\displaystyle p_{\sigma }} wird zuerst aktualisiert. p σ ← ( 1 − c σ ) ⏟ Rabattfaktor p σ + 1 − ( 1 − c σ ) 2 ⏞ ergänzt um reduzierte Varianz μ w C k − 1 / 2 m k + 1 − m k ⏞ Verschiebung von m σ k ⏟ verteilt als N (0, I ) unter neutraler Selektion {\sigma \}gets \underbrace (1 * \ '+overbrace {\sqrt 1-(1-c_{\sigma {^)2 \^!text{Ergänzungen für Rabattvarianz}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! ) m_{k+1}-m_{k \^!text{displacement of m\!\!\!\!}{\sigma {_k} _\!text{distributed as {\}mathcal N}(0,I){\text unter neutraler Auswahl\}! σ k + 1 = σ k × exp ‡ ( c σ d σ ( σ σ ε σ ο ο ο ο ο σ σ σ σ σ ο ο σ σ k σ k σ k × exp ζ ( c σ d σ ( σ σ σ σ ο σ σ σ σ σ σ σ σ σ ο e ο e ο e ο e ο e ο e ο e ο e ο e ο e η η η η N ( 0 ( 0, I, I, I, I ο, I η ο, I, I η ο ο ο ο ο ο ο η η η σ σ η η σ η η η η η η η η η η η σ σ η η η η η σ η σ σ η η η  {_k+1} {_k}Zeiten \exp {\bigg ({\}frac c_{\sigma }d_{\sigma \}underbrace Left({\frac |p_{\sigma {\}Betreibername {E} {E}\\\mathcal {N}(0,I)\}}-1\right _\\\\! Text (unvoreingenommen etwa 0 unter neutraler Auswahl)\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\}{\{\\\\\\\\\}{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}}}}}}}}}}}}}}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ wobei c σ - 1 ≈ n / 3 {\displaystyle c_{\sigma {-^1}\approx n/3} der rückwärtige Zeithorizont für den Evolutionspfad p σ {\displaystyle p_{\sigma} ist c_{\sigma \}ll 1} ist an eine exponentielle Abklingkonstante wie ( 1 - c σ σ σ ) k ≈ exp Die Halbwertszeit, * i=1{\mu w_{i}^{2}\right)^{-1 ist die varianzwirksame Auswahlmasse und 1 ≤ μ w ≤ μ w ≤ μ {\displaystyle 1\leq \mu {_w}\leq \mu } durch Definition von w i {\displaystyle w_{i}, C k - 1 / 2 = C k - 1 = C k - 1 C_{k}{\\\\\'1/2}={\\sqrt ) C_{k}^{\;-1 ist die einzigartige symmetrische Quadratwurzel der Inverse von C k {\displaystyle C_{k} und d σ {\displaystyle d_{\sigma }} ist der Dämpfungsparameter in der Regel in der Nähe eines. Für d σ = ∞ {\displaystyle d_{\sigma =\}infty } oder c σ = 0 {\displaystyle c_{\sigma =0 bleibt die Schrittgröße unverändert. Die Schrittgröße σ k {\displaystyle \sigma {_k} wird erhöht, wenn und nur, wenn der ermittelte Wert P σ zusammengestellt ist {\displaystyle |p_{\sigma }\|} größer ist als der erwartete Wert E festgestellt ≈ N (0, I) = 2 Γ (n + 1\) / 2 Γ (n / 2 ) ≈ n ( 1 -style 1 /) + 1 / (oper 21) (E} {E}\\\mathcal N}(0,I)\&&={\sqrt {2}\,\Gamma (n+1)/2)/\Gamma (n/2)\&\approx {\sqrt n}\,(1-1/(4\,n)+1/(21\,n^{2}))\end{justiert und verringert, wenn es kleiner ist. Aus diesem Grund tendiert das Schritt-Größe-Update dazu, aufeinanderfolgende Schritte C k - 1 {\displaystyle C_{k}^{-1 -conjugate zu machen, indem nach erfolgreicher Anpassung (m k + 2 - m k + 1 k + 1 σ k + 1 ) T C k - 1 m k + 1 - m k σ k ≈ 0 {\displaystyle \textstyle links({\frac ) * {_k}}\approx 0} .Endlich wird die Kovarianzmatrix aktualisiert, wobei wiederum der jeweilige Evolutionspfad zuerst aktualisiert wird. p c ← ( 1 − c c c ) ⏟ Diskontfaktor p c + 1 [0 , α n ] ( ‡ p σ ‡) ⏟ Indikatorfunktion 1 − ( 1 − c c c c ) 2 ⏞ ergänzt um reduzierte Varianz μ m k + 1 − mk σ k ⏟ als N (0, C k ) unter neutraler Auswahl verteilt {\displaystyle p_{c}\gets \underbrace (1-c_{c}) _\!text{discount ! ! * {_k} _\!text{distributed as}\;{\mathcal N}(0,C_{k})\;{\text{unter neutrale Auswahl\}! C k + 1 = ( 1 - c 1 - c μ + c s ) Diskontfaktor C k + c 1 p c p c T ⏟ eine Matrix + c μ Σ i = 1 μ w i x i : λ - m k σ k ( x i : λ - m k σ k σ k ) T ⏟ Ranke min (μ , n ) Matrix {\displaystyle C_{k+1}=\underbrace (1-c_{1}-c_{\mu +c_{) _\!text{discount factor}\!\!\!\!\!\',C_{k}+c_{1}\underbrace * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * ~ Underbrace ~ * i=1{\mu ) x_{i:\lambda - Ja. x_{i:\lambda -m_{k}{\sigma _k}}}}\right)^{T {\_operatorname {rank} min(\mu ,n){\text matrix} wobei T {\displaystyle T} die transpose und c c - 1 ≈ n / 4 bedeutet n/4} ist der rückwärtige Zeithorizont für den Evolutionspfad p c {\displaystyle p_{c} und größer als eins, α ≈ 1,5 {\displaystyle \alpha \approx 1.5} und die Anzeigefunktion 1 [0, α n ] (ε\\\\\\\\displaystyle \mathbf {1} {_0,\\\\sq} |\}leq \alpha {\sqrt {n}, was in der Regel der Fall ist, c s = ( 1 - 1 [0, α n ] (erwähnt p σ ) 2 ) c 1 c ( 2 - c c c ) {\displaystyle c_{s}=(1-\mathbf {1} {_0,\alpha  learning________________ -m_{k})/\sigma {_k} aus N ( 0, C k + 1 ) {\displaystyle {\mathcal N}(0,C_{k+1) abzutasten. Die Anzahl der Kandidatenproben pro Iteration, λ {\displaystyle \lambda }, wird nicht a priori bestimmt und kann in einem weiten Bereich variieren. Kleinere Werte, z.B. λ = 10 {\displaystyle \lambda = 10}, führen zu mehr lokalem Suchverhalten. Größere Werte, beispielsweise λ = 10 n {\displaystyle \lambda =10n} mit Standardwert μ w ≈ λ / 4 {\displaystyle \mu {_w}\approx \lambda /4}, machen die Suche globaler. Manchmal wird der Algorithmus wiederholt mit zunehmendem λ {\displaystyle \lambda } um einen Faktor von zwei für jeden Neustart neu gestartet. Neben der Einstellung λ {\displaystyle \lambda } (oder ggf. μ {\displaystyle \mu } anstelle, wenn z.B. λ {\displaystyle \lambda } durch die Anzahl der verfügbaren Prozessoren vorgegeben ist), sind die oben eingeführten Parameter nicht spezifisch für die gegebene Zielfunktion und daher nicht vom Benutzer modifiziert zu werden. Beispielcode in MATLAB/Octave Theoretische Grundlagen Bei den Verteilungsparametern - also Varianzen und Kovarianzen - ist die normale Wahrscheinlichkeitsverteilung für die Probenahme neuer Kandidatenlösungen die maximale Entropiewahrscheinlichkeitsverteilung über R n {\displaystyle \mathbb {R} {^n}, d.h. die Probenverteilung mit der minimalen Menge an in die Verteilung eingebauten Vorinformationen. Weitere Überlegungen zu den Aktualisierungsgleichungen von CMA-ES werden im Folgenden gemacht. Variable Metrik Die CMA-ES implementiert eine stochastische variable Methode. Im ganz bestimmten Fall einer konvex-quadratischen Objektivfunktion f (x) = 1 2 ( x - x Ψ ) T H ( x - x χ Ψ ) {\displaystyle f(x)={\textstyle {\frac 1}}}(x-x^{*})^{T}H(x-x die Kovarianzmatrix C k {\displaystyle C_{k} Allgemeiner, auch auf der Funktion g П f {\displaystyle g\circ f}, wo g {\displaystyle g} streng ansteigt und daher die Konservierung und f {\displaystyle f} konvexquadratisch ist, die Kovarianzmatrix C k {\displaystyle C_{k} passt sich an H - 1 {\displaystyle H^{-1} an, bis zu einem Skalarfaktor und kleinen zufälligen Schwankungen. Beachten Sie, dass eine verallgemeinerte Fähigkeit von Evolutionsstrategien zur Anpassung einer Kovarianz-Matrix-Reflektivität des inverse-Hessian für ein statisches Modell auf einer quadratischen Annäherung nachgewiesen wurde. Maximale Wahrscheinlichkeitsaktualisierung Die Aktualisierungsgleichungen für mittlere und Kovarianzmatrix maximieren eine Wahrscheinlichkeit, während sie einem Erwartungsmaximierungsalgorithmus ähneln. Das Update des mittleren Vektors m {\displaystyle m} maximiert eine log-likelihood, so dass m k + 1 = arg ✅ max m Σ i = 1 μ w i log ζ N ( x i : λ ∣ m ) {\displaystyle m_{k+1}=\arg \max * i=1{\mu w_{i}\logp_{\mathcal N}(x_{i:\lambda \}mid m}) wobei log ‡ p N ( x ) = - 1 2 log det ( 2 π C ) - 1 2 ( x - m ) T C - 1 ( x - m ) C_{\displaystyle \log p_{\mathcal N}(x)=-{\frac 1}{2}\log det(2\pi C)-{\frac 1}(x-m)^{T}C^{-1}(x-m bezeichnet die log-likelihood of x{displaystyle xstyle} aus einer multivariate Normalverteilung mit mittlerem {display Dann sind die Rotation der Datenpunkte oder die Wahl von C {\displaystyle C} nicht-diagonal gleichwertig. Das Rank-μ {\displaystyle \mu }-Update der Kovarianzmatrix, d.h. der rechte größte Summand in der Update-Gleichung von C k {\displaystyle C_{k}, maximiert eine Log-Lihood in dieser EPMATHMARKEREP T = arg{\displaystyle \sum _i=1} ) x_{i:\lambda - Ja. x_{i:\lambda -m_{k}{\sigma _k}}}}\right)^{T}=\arg \max {_C}\sum _i=1}{\mu ***________________________________________________________________ Nein. x_{i:\lambda - Ja. {_k}\right|C\right) für μ ≥ n {\displaystyle {mu \geq n} (andereweise C {\displaystyle C} ist einzigartig, aber im Wesentlichen das gleiche Ergebnis hält für μ < n\displaystyle \mu <n}\hier, p N ( x | C) {\displaystyle p{\\\mathcal {N}}(x| = 1 , C k + 1 {\displaystyle C_{k+1} ist der oben genannte Maximum-Lihood-Schätzer. Siehe Schätzung der Kovarianzmatrizen für Details zur Ableitung. Natürlicher Gradientenabstieg im Raum der Probenverteilungen Akimoto et al.and Glasmachers et al. entdeckte unabhängig davon, dass die Aktualisierung der Verteilungsparameter dem Abstieg in Richtung eines abgetasteten natürlichen Gradienten des erwarteten objektiven Funktionswertes E f ( x ) {\displaystyle Ef(x}) entspricht (zu minimieren), wo die Erwartung unter der Probenverteilung genommen wird. Mit der Parametereinstellung von c σ = 0 {\displaystyle c_{\sigma =0 und c 1 = 0 {\displaystyle c_{1}=0, d.h. ohne Schritt-Größe-Steuerung und Rank-One-Update, kann CMA-ES somit als Instantiation of Natural Evolution Strategies (NES) angesehen werden. Der natürliche Gradient ist unabhängig von der Parametrierung der Verteilung. (x) Die sogenannte Score-Funktion, MENT θ ln ‡ p ( x θ θ ) = MENT θ p ( x ) p ( x ) p ( x ) {\displaystyle \nabla {_\!theta \}ln p(x\mid \theta {=\)frac\nabla {_\!theta p(x)}{p(x, zeigt die relative Empfindlichkeit. Der natürliche Gradient von E f ( x ) {\displaystyle Ef(x}) , entspricht der Fisher-Informationsmetrie (ein informationelles Entfernungsmaß zwischen Wahrscheinlichkeitsverteilungen und der Krümmung der relativen Entropie), liest jetzt ‡ E ≠ ⁡ ⁡ ∣ θ θ θ θ = F θ - 1 😉 = +)F_{\theta {-^1\nabla {_\!theta \}Operatorname {E} f(x)\mid \theta \)end{aligned} wobei die Fisher-Informationsmatrix F θ {\displaystyle F_{\theta } die Erwartung des Hessian von -lnp ist und den Ausdruck unabhängig von der gewählten Parametrierung macht. Kombinieren Sie die bisherigen Gleichheiten, die wir erhalten ‡ E ‡ ( f ( x ) ∣ θ ) = F θ - 1 E ‡ ( f ( x ) ♦ ‡ ♦ ‡ p ( x ∣ θ ) ) = E ≠ f\ ( x ) F θ - 1 κ θ n δ n δ n δ n = +)F_{\theta {-^1}\Operatorname {E} f(x)\nabla {_\!theta \}ln p(x\mid \theta =\&)Operatorname {E} f(x)F_{\theta {-^1\nabla {_\!theta \}ln p(x\mid \theta \)end{align} Eine Monte Carlo-Annäherung der letzteren Erwartung nimmt den Durchschnitt über λ-Proben von p MENT ~ E ^ θ (f ) := - Σ i = 1 λ w i ⏞ Vorzugsgewicht F θ - 1 κ κ θ ln ρ ( x i : λ ∣ θ ) ⏟ Vorzugsrichtung von x i : λ mit w i = - f ( x i : λ ) / λ {\displaystyle {\tilde ! ! E}_{\theta (}f):=-\sum _i=1}^{\lambda ! F_{\thet {-^1\nabla {_\!theta \}ln p(x_{i:\lambda \}mid \theta } _\!text{kandidaten von }x_{i:\lambda \ ') w_{i}=-f(x_{i:\lambda \}/)lambda } wobei die Notation i: λ {\displaystyle i:\lambda } von oben verwendet wird und daher w i {\displaystyle w_{i} monoton in i {\displaystyle i} abnimmt. Ollivier et al.finally fand eine rigorose Ableitung für die robusteren Gewichte, w i {\displaystyle w_{i}, wie sie in den CMA-ES definiert sind (Gewichte sind oft Null für i > μ). Sie werden als konsistenter Estimator für die CDF von f (X) , X fra p ( . | θ ) {\displaystyle f(X),X\sim p(.|\theta )} am Punkt f ( x i : λ \)\displaystyle f(x_{i:\lambda })} formuliert, der sich mit einer festen monotonen verminderten Transformation zusammensetzt -)1/2}{\lambda \right) Dies macht den Algorithmus unempfindlich gegen die spezifischen f {\displaystyle f} -Werte. Genauer gesagt, mit dem CDF-Schätzer von f {\displaystyle f} statt f {\displaystyle f} selbst lassen den Algorithmus nur von der Ranking von f {\displaystyle f} -Werte, aber nicht von ihrer zugrunde liegenden Verteilung abhängig. Es macht den Algorithmus invariant zu monotonen f {\displaystyle f} -Transformationen. θ = [ m k T vec ‡ ( C k σ k ] T ε R n + n 2 + 1 {\displaystyle \theta = [m_{k}{T}\operatorname {vec} (C_{k})^{T}\sigma _k}{T}\in \mathbb n+n^{2}+1 so, daß p ( ⋅ θ θ ) {\displaystyle p(\cdot \mid \theta } die Dichte der multivariate Normalverteilung N (m k , σ k 2 C k ) {\displaystyle n}(m_{k},\sigma k{2}C_{k{\displaystyle F_{\theta \mid \sigma *^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ k{2}C_{k}&0\0&2C_{k}Zeiten C_{k}\end{array}\right] und für ln ċ p ( x θ θ θ ) = ln ‡ p ( x ∣ m k, σ k 2 C k ) = - 1 2 ( x - m k ) T σ k - 2 C k - 1 ( x - m k) - 1 2 ln merk det ( 2 π σ k 2 k ) k}^{-2}C_{k}^{-1}(x-m_{k})-{\frac 1}{2}}\ln det(2\pi \sigma k}^{2}C_{k) und nach einigen Berechnungen ergeben sich die Aktualisierungen im CMA-ES, als ob Matte die richtige Matrix aus dem jeweiligen natürlichen Gradientensubvektor bildet. Das bedeutet, c 1 = c σ = 0 {\displaystyle c_{1} =0, die CMA-ES-Updates sinken in Richtung der Näherung MENT ~ E ^ θ (f ) {\displaystyle {\tilde {\nabla {\}widehat E}_{theta (f) des natürlichen Gradienten unter Verwendung verschiedener Schrittgrößen (Lernraten 1 und c μdisplaystyle c_{\mu } ) für die orthogonalen Parameter m Die neueste Version von CMA-ES verwendet auch eine andere Funktion w {\displaystyle w} für m {\displaystyle m} und C {\displaystyle C} mit negativen Werten nur für letztere (sogenannte aktive CMA). Stationarität oder Unvoreingenommenheit Es ist vergleichsweise einfach zu erkennen, dass die Aktualisierungsgleichungen von CMA-ES einige Stationaritätsbedingungen erfüllen, indem sie im Wesentlichen unvoreingenommen sind. Unter neutraler Auswahl, wobei x i : λ ν N ( m k, σ k 2 C k ) {\displaystyle x_{i:\lambda \}sim {\mathcal N}(m_{k},\sigma k}{2}C_{k) , finden wir, daß E ∂ator ( m k + 1 k name ) = m k {displaystyle \ {E} (m_{k+1}\mid m_{k})=m_{k und unter einigen milden zusätzlichen Annahmen unter den anfänglichen Bedingungen E ‡ (log ‡ σ k + 1 σ σ k ) = log ⁡ ⁡ σ k {\displaystyle \operatorname {E} \(log \sigma {k+1\mid \sigma {_k})= {E} (C_{k+1}\mid C_{k})=C_{k Invariance Eigenschaften bedeuten eine gleichmäßige Leistung auf einer Klasse von objektiven Funktionen. Sie wurden als Vorteil argumentiert, weil sie das Verhalten des Algorithmus verallgemeinern und vorhersagen und damit die Bedeutung empirischer Ergebnisse auf einzelnen Funktionen stärken. Für CMA-ES wurden folgende Invarianzeigenschaften ermittelt. Invarianz unter ordnungserhaltenden Transformationen des objektiven Funktionswertes f {\displaystyle f}, in dem für alle h : R n → R {\displaystyle h:\mathbb {R} {^n}\to \mathbb {R} Das Verhalten ist identisch mit f : x ↦ g (h ( x ) ) {\displaystyle f:x\mapsto g(h(x}) für alle streng steigenden g : R → R {\displaystyle g:\mathbb{R} \to \mathbb {R} .Diese Invarianz ist einfach zu überprüfen, weil nur die f {\displaystyle f} -ranking im Algorithmus verwendet wird, die invariant ist unter der Wahl von g {\displaystyle g} .Scale-invariance, in that for any h: R n → R {math\displaystyle h:\ {R} {^n}\to \mathbb {R} Das Verhalten ist unabhängig von α > 0 {\displaystyle \alpha >0} für die objektive Funktion f : x ↦ h ( α x ) {\displaystyle f:x\mapsto h(\alpha x} bei σ 0 a 1 / α {\displaystyle \ n {_0}\propto 1/\alpha} und m 0 a 1 / α m_{0}\propto 1/\alpha } .Invariance unter Rotation des Suchraums in diesem für alle h : R n → R {\displaystyle h:\mathbb {R} {^n}\to \mathbb {R}} und alle z ε R n {\displaystyle z\in \mathbb {R} {^n} das Verhalten auf f : x ↦ h (R x ) {\displaystyle f:x\mapsto h(Rx}) ist unabhängig von der orthogonalen Matrix R {\displaystyle R}, gegeben m 0 = R - 1 z {\displaystyle ) .Mehr allgemein ist der Algorithmus auch invariant unter allgemeinen linearen Transformationen R {\displaystyle R}, wenn zusätzlich die initiale Kovarianzmatrix als R - 1 R - 1 T gewählt wird {\displaystyle ) .Anyserious Parameter-Optimierungsverfahren sollte invariant sein, aber die meisten Methoden zeigen nicht alle oben beschriebenen Invarianzeigenschaften. Ein prominentes Beispiel mit den gleichen Invarianzeigenschaften ist die Nelder-Mead-Methode, bei der der Initial-Soxx jeweils gewählt werden muss. Konvergence Konzeptionelle Überlegungen wie die Skalen-Invarianz-Eigenschaft des Algorithmus, die Analyse von einfacheren Evolutionsstrategien und überwältigende empirische Beweise legen nahe, dass der Algorithmus auf einer großen Klasse von Funktionen schnell zum globalen Optimum konvergiert, bezeichnet als x ++ {\displaystyle x^{}* . Bei einigen Funktionen erfolgt die Konvergenz unabhängig von den Anfangsbedingungen mit der Wahrscheinlichkeit eins. Auf einigen Funktionen ist die Wahrscheinlichkeit kleiner als eins und hängt typischerweise von der Anfangszahl m 0 {\displaystyle m_{0} und σ 0 {\displaystyle \sigma {_0} ab.Empirisch kann oft die schnellste mögliche Konvergenzrate in k {\displaystyle k} für rangbasierte direkte Suchverfahren beobachtet werden (abhängig von dem als lineare oder log-lineare oder exponentielle Konvergenz bezeichneten Kontext). Informell können wir m k - x χ ≈ ≈ m 0 - x χ χ e - c k {\displaystyle m_{k}-x^{*}\\\\\\\\\cca. ;m_{0}-x^{*\\\\\\times e^{-ck} für einige c > 0 {\displaystyle c>0}, und strenger 1 k Σ i = 1 k log m i - x χ χ χ 1 k log kennzeichnete m k - x χ χ χ χ χ χ χ → c < 0 für k → ∞, {\displaystyle {\frac 1 * i=1{k{k}\log m_{i}-x^^\\\\\\\\\\\\\\\\\\\\\{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ 1 m_{k}-x{*}\\\\\\\\\\\\m_{0}-x\\\\\\}\\\to -;c<0\quad \text{für }k\to \infty \;,} oder ähnliches, E ‡ log ‡ m k - x χ χ ≠ zusammengestellt m k - 1 - x χ χ ≠ → gefunden - c < 0 für k → ∞ . {\displaystyle \operatorname {E} \log {\frac m_{k}-x{*}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\c -;c<0\quad \text{für }k\to \infty \;.} Das bedeutet, dass im Durchschnitt die Entfernung zum Optimum in jeder Iteration um einen konstanten Faktor abnimmt, nämlich durch exp ∂ ( - c ) {\displaystyle \exp(-c}) .Die Konvergenzrate c {\displaystyle c} beträgt etwa 0,1 λ / n {\displaystyle 0,1\lambda /n} bei λ {\displaystyle \lambda } ist nicht viel größer als die Dimension n {\displaystyle . Auch bei optimalen σ {\displaystyle \sigma } und C {\displaystyle C} kann die Konvergenzrate c {\displaystyle c} bei den oben genannten Rekombinationsgewichten w i {\displaystyle w_{i} nicht wesentlich über 0,25 λ / n {\displaystyle 0.25\lambda /n} liegen. Die tatsächlichen linearen Abhängigkeiten in λ {\displaystyle \lambda } und n {\displaystyle n} sind bemerkenswert und sie sind in beiden Fällen die beste, die man in dieser Art von Algorithmus hoffen kann. Dennoch fehlt ein strenger Konvergenznachweis. Interpretation als Koordinatensystemtransformation Die Verwendung einer Nichtidentitätskovarianzmatrix für die multivariate Normalverteilung in Evolutionsstrategien entspricht einer Koordinatensystemtransformation der Lösungsvektoren, vor allem deshalb, weil die Abtastgleichung x i ∼ m k + σ k × N ( 0 , C k ) m k + σ k × C k 1 / 2 N ( 0 , I ) {\displaystyle begin{aligned}x_{i}&\ * m_{k}+\sigma {_k}Zeiten {\mathcal N}(0,C_{k})\&\sim \ m_{k}+\sigma {_k}Zeiten C_{k}{1/2}{\mathcal N}(0,I)\end{aligned kann in einem "codierten Raum" gleich ausgedrückt werden, wie C k - 1 / 2 x i ⏟ im Coderaum ∼ C k - 1 / 2 m k ⏟ + σ k × N (0, I) {\displaystyle \underbrace ! ) {\}+sigma {_k}\times {\mathcal {N}(0,I)Die Kovarianzmatrix definiert eine bijektive Transformation (Codierung) für alle Lösungsvektoren in einen Raum, wo die Probenahme mit Identitätskovarianzmatrix erfolgt. Da die Aktualisierungsgleichungen in den CMA-ES unter linearen Koordinatensystemtransformationen invariant sind, kann das CMA-ES als adaptives Codierverfahren neu geschrieben werden, das auf eine einfache Evolutionsstrategie mit Identitätskovarianzmatrix angewendet wird. Dieses adaptive Codierungsverfahren ist nicht auf Algorithmen beschränkt, die aus einer multivariaten Normalverteilung (wie Evolutionsstrategien), sondern prinzipiell auf jede iterative Suchmethode angewendet werden können. Leistung in der Praxis Im Gegensatz zu den meisten anderen evolutionären Algorithmen ist der CMA-ES aus der Sicht des Benutzers quasi-parameterfrei. Der Benutzer muss einen anfänglichen Lösungspunkt wählen, m 0 ε R n {\displaystyle m_{0}\in \mathbb {R} {^n} und die anfängliche Schrittgröße, σ 0 > 0 {\displaystyle \sigma {_0}>0 . Optional kann die Anzahl der Kandidatenproben λ (Bevölkerungsgröße) durch den Benutzer geändert werden, um die charakteristischen Suchbedingungen zu ändern (siehe oben). Die CMA-ES ist in Hunderten von Anwendungen empirisch erfolgreich und gilt insbesondere für nicht-konvexe, nicht-separable, krank-konditionierte, multimodale oder laute Zielfunktionen als nützlich. Eine Umfrage bei Black-Box-Optimierungen fand heraus, dass es 31 andere Optimierungsalgorithmen herausnahm, die besonders stark auf "schwierigen Funktionen" oder größeren Dimensions-Suchplätzen. Die Suchraumdimension reicht typischerweise zwischen zwei und einigen hundert. Unter Berücksichtigung eines Black-Box-Optimierungsszenarios, bei dem Gradienten nicht verfügbar sind (oder nicht nützlich) und Funktionsauswertungen die einzigen betrachteten Kosten für die Suche sind, wird das CMA-ES-Verfahren wahrscheinlich durch andere zehn Methoden in den folgenden Bedingungen überproportioniert: auf Low-dimensionale Funktionen, d.h. n < 5 {\displaystyle n<5}, z.B. durch das Downhill simplex-Verfahren oder surrogate-basierte Methoden (wie z. Bei trennbaren Funktionen dürfte der Leistungsnachteil am wichtigsten sein, da CMA-ES bei allen vergleichbaren Lösungen möglicherweise nicht finden kann. Auf der anderen Seite zeigt die CMA-ES bei nicht trennbaren Funktionen, die krank oder robust sind oder nur mit mehr als 100 n {\displaystyle 100n} Funktionsauswertungen gelöst werden können, am häufigsten überlegene Leistung. Variationen und ErweiterungenDie (1+1)-CMA-ES erzeugt nur eine Kandidatenlösung pro Iterationsschritt, die die neue Distribution bedeutet, wenn es besser ist als der aktuelle Mittelwert. Für c c = 1 {\displaystyle c_{c}=1 ist die (1+1)-CMA-ES eine enge Variante der Gaussian-Adaption. Einige natürliche Evolution Strategien sind enge Varianten des CMA-ES mit bestimmten Parametereinstellungen. Natürliche Evolution Strategien nutzen keine Evolutionspfade (also in CMA-ES-Einstellung c c = c σ = 1 {\displaystyle c_{c}=c_{\sigma = 1 ) und formalisieren das Update von Varianzen und Kovarianzen auf einem Cholesky-Faktor anstelle einer Kovarianzmatrix. Die CMA-ES wurde auch als MO-CMA-ES auf multiobjective Optimierung erweitert. Eine weitere bemerkenswerte Erweiterung war die Addition einer negativen Aktualisierung der Kovarianzmatrix mit dem sogenannten aktiven CMA. Die Verwendung des zusätzlichen aktiven CMA-Updates wird heute als Standardvariante betrachtet. Siehe auch Globale Optimierung Stochastic Optimierung Derivative-free Optimierung Schätzung des Distributionsalgorithmus Referenzen Bibliographie Hansen N, Ostermeier A (2001). Vollständig derandomisierte Selbstanpassung in Evolutionsstrategien. Evolutionary Computation, 9(2) S.159–195.[1] Hansen N, Müller SD, Koumoutsakos P (2003). Reduzierung der Zeitkomplexität der derandomisierten Evolutionsstrategie mit Kovarianz-Matrixanpassung (CMA-ES). Evolutionary Computation, 11(1) S.1–18 [2] Hansen N, Kern S (2004). Bewertung der CMA-Entwicklungsstrategie für multimodale Testfunktionen. In Xin Yao et al,. Editoren, Parallel Problemlösung aus der Natur – PPSN VIII, S.282–291, Springer. [3] Igel C, Hansen N, Roth S (2007). Covariance Matrix Anpassung für Multi-Objektive Optimierung. Evolutionary Computation, 15(1) pp.1–28.[4] Externe Links Eine kurze Einführung in CMA-ES von N. Hansen Die CMA Evolution Strategy: A Tutorial CMA-ES Quellcode Seite