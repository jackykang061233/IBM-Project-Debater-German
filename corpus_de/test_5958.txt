Kovarianz-Matrix-Adaption Evolution Strategie (CMA-ES) ist eine bestimmte Art von Strategie zur numerischen Optimierung. Evolutionsstrategien (ES) sind stochastische, derivatfreie Methoden zur numerischen Optimierung nichtlinearer oder nichtkonvex kontinuierlicher Optimierungsprobleme. Sie gehÃ¶ren zur Klasse evolutionÃ¤rer Algorithmen und evolutionÃ¤rer Berechnung. Ein evolutionÃ¤rer Algorithmus basiert weitgehend auf dem Prinzip der biologischen Evolution, nÃ¤mlich dem wiederholten Wechselspiel von Variation (Ã¼ber Rekombination und Mutation) und der Selektion: In jeder Generation (Bewegung) werden neue Individuen (KandidatlÃ¶sungen, bezeichnet als x {\displaystyle x}) durch Variation, meist stochastisch, der aktuellen Elternindividuen erzeugt. Dann werden einige Personen ausgewÃ¤hlt, um die Eltern in der nÃ¤chsten Generation zu werden, basierend auf ihrem Fitness- oder Zielfunktionswert f ( x ) {\displaystyle f(x}) .Like this, over the generation Sequenz, Individuen mit besseren und besseren f {\displaystyle f} -Werte werden erzeugt. In einer Evolutionsstrategie werden neue KandidatlÃ¶sungen nach einer multivariaten Normalverteilung in R n {\displaystyle \mathbb {R} {^n} abgetastet.Die Rekombination entspricht der Auswahl eines neuen Mittelwerts fÃ¼r die Verteilung. Mutation ist die Addition eines Zufallsvektors, einer StÃ¶rung mit Nullmittel. Die paarweisen AbhÃ¤ngigkeiten zwischen den GrÃ¶ÃŸen in der Verteilung werden durch eine Kovarianzmatrix dargestellt. Die Kovarianz-Matrixanpassung (CMA) ist ein Verfahren zur Aktualisierung der Kovarianz-Matrix dieser Verteilung. Dies ist besonders dann sinnvoll, wenn die Funktion f {\displaystyle f} schlecht konditioniert ist. Die Anpassung der Kovarianz-Matrix ermÃ¶glicht das Erlernen eines zweiten Ordnungsmodells der zugrunde liegenden Zielfunktion Ã¤hnlich der AnnÃ¤herung der inversen hessischen Matrix in der quasi-Newton-Methode in der klassischen Optimierung. Im Gegensatz zu den meisten klassischen Methoden werden weniger Annahmen Ã¼ber die Art der zugrunde liegenden Zielfunktion gemacht. Nur das Ranking zwischen KandidatenlÃ¶sungen wird fÃ¼r das Lernen der Probenverteilung genutzt, und es werden weder Derivate noch die Funktionswerte selbst nach der Methode benÃ¶tigt. GrundsÃ¤tze Im CMA-ES-Algorithmus werden zwei Hauptprinzipien fÃ¼r die Anpassung von Parametern der Suchverteilung ausgenutzt. ZunÃ¤chst ein Maximum-Lihood-Prinzip, basierend auf der Idee, die Wahrscheinlichkeit von erfolgreichen KandidatenlÃ¶sungen und Suchschritten zu erhÃ¶hen. Der Durchschnitt der Distribution wird so aktualisiert, dass die Wahrscheinlichkeit von bisher erfolgreichen KandidatenlÃ¶sungen maximiert wird. Die Kovarianzmatrix der Verteilung wird (inkrementell) so aktualisiert, dass die Wahrscheinlichkeit frÃ¼her erfolgreicher Suchschritte erhÃ¶ht wird. Beide Updates kÃ¶nnen als natÃ¼rliche Gradientenabstieg interpretiert werden. Damit fÃ¼hrt die CMA auch eine iterierte Hauptkomponentenanalyse erfolgreicher Suchschritte unter Beibehaltung aller Hauptachsen durch. Die SchÃ¤tzung der Verteilungsalgorithmen und der Cross-Entropy-Methode basiert auf sehr Ã¤hnlichen Ideen, aber SchÃ¤tzung (nicht-incremental) der Kovarianz-Matrix durch Maximierung der Wahrscheinlichkeit erfolgreicher LÃ¶sungspunkte statt erfolgreicher Suchschritte. Zweitens werden zwei Pfade der Zeitentwicklung des Verteilungsmittels der Strategie erfasst, genannt Such- oder Evolutionspfade. Diese Wege enthalten signifikante Informationen Ã¼ber die Korrelation zwischen aufeinanderfolgenden Schritten. Insbesondere, wenn aufeinanderfolgende Schritte in einer Ã¤hnlichen Richtung durchgefÃ¼hrt werden, werden die Evolutionspfade lang. Die Evolutionspfade werden auf zwei Arten ausgenutzt. Ein Weg wird fÃ¼r das Kovarianz-Matrix-Adaptionsverfahren anstelle von einzelnen erfolgreichen Suchschritten verwendet und ermÃ¶glicht eine mÃ¶glicherweise viel schnellere VarianzerhÃ¶hung gÃ¼nstiger Richtungen. Der andere Weg dient dazu, eine zusÃ¤tzliche SchrittgrÃ¶ÃŸenregelung durchzufÃ¼hren. Diese Schritt-GrÃ¶ÃŸe-Steuerung zielt darauf ab, aufeinanderfolgende Bewegungen der Verteilung orthogonal in der Erwartung bedeuten. Die Schritt-GrÃ¶ÃŸe-Kontrolle verhindert effektiv vorzeitige Konvergenz, ermÃ¶glicht aber schnelle Konvergenz zu einem Optimum. AlgorithmIm Folgenden wird die am hÃ¤ufigsten verwendeten (Î¼/Î¼w, Î»)-CMA-ES umrissen, wobei in jedem Iterationsschritt eine gewichtete Kombination der Î¼ am besten aus Î» neuen KandidatenlÃ¶sungen zur Aktualisierung der Verteilungsparameter verwendet wird. Die Hauptschleife besteht aus drei Hauptteilen: 1) Probenahme neuer LÃ¶sungen, 2) Nachbestellung der abgetasteten LÃ¶sungen auf Basis ihrer Fitness, 3) Aktualisierung der internen Zustandsvariablen basierend auf den neu bestellten Proben. Ein Pseudocode des Algorithmus sieht wie folgt aus. Î» {\displaystyle \lambda} // Anzahl der Proben pro Iteration, mindestens zwei, im allgemeinen > 4 initialisieren m {\displaystyle m} Ïƒ {\displaystyle \sigma }, C = I {\displaystyle C=I}, p Ïƒ = 0 {\displaystyle p_{\sigma =0 , p c = 0 {\displaystyle p_{c}=0 // initialisieren Zustandsvariablen wÃ¤hrend nicht enden do // iterate for i {\displaystyle i} in { 1 ... Î» } {\displaystyle {1\ldots \lambda \} do // Sample Î» {\displaystyle \lambda } neue LÃ¶sungen und bewerten sie x i = {\displaystyle x_{i=} pattern_multivariate_normal(mean = m {\displaystyle {=m , covariance_matrix = Ïƒ 2 C {\displaystyle {=\}sigma {^2}C ) f_{i}=\Operatorname {fitness} (x_{i}) x 1 ... Î» {\displaystyle x_{1\ldots \lambda } â† x s ( 1 ) ... s (Î» ) {\displaystyle x_{s\ldots s(\lambda )}} mit s (style i ) = argsort wir brauchen spÃ¤ter m - m' {\displaystyle m-m'} und x i - m' {\displaystyle x_{i}-m' m {\displaystyle m} â† update_m ( x 1 , ..., x Î» ) {\displaystyle (x_{1},\ldots ,x_{\lambda }} // bewegen Mittel zu besseren LÃ¶sungen p Ïƒ {\displaystyle p_{\sigma }} â† update_ps ( p Ïƒ , Ïƒ âˆ’ 1 C âˆ’ 1 / 2 ( m âˆ’ m') ) {\displaystyle (p_{\sigma ,\}sigma 1}C^{-1/2}(m-m') // update isotropic evolution path p c {\displaystyle p_{c} Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ï† Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ï† Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ï† Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Die Reihenfolge der fÃ¼nf Update-Zuweisungen ist relevant: m {\displaystyle m} muss zuerst aktualisiert werden, p Ïƒ {\displaystyle p_{\sigma }} und p c {\displaystyle p_{c} mÃ¼ssen aktualisiert werden, bevor C {\displaystyle C} und Ïƒ {\displaystyle \sigma } zuletzt aktualisiert werden mÃ¼ssen. Im Folgenden werden die Aktualisierungsgleichungen fÃ¼r die fÃ¼nf Zustandsvariablen angegeben. Dabei handelt es sich um die Suchraumdimension n {\displaystyle n} und den Iterationsschritt k {\displaystyle k} . Die fÃ¼nf Zustandsvariablen sind m k Îµ R n {\displaystyle m_{k} in \mathbb {R} {^n}, die Verteilungsmittel- und aktuelle LieblingslÃ¶sung fÃ¼r das Optimierungsproblem, Ïƒ k > 0 {\displaystyle \sigma {_k}>0 , the step-size, C k {\displaystyle C_{k}, a symmetric and positiv-definite n Ã— n {\displaystyle n\times n} covariance matrix with C 0 = I {\displaystyle C_{0}= I und p Ïƒ Îµ R n , p c Îµ R n {\displaystyle p_{\sigma \}in \mathbb {R},p_{c}\in \mathbb {R}, zwei Evolutionspfade, zunÃ¤chst auf den Nullvektor gesetzt. Die Iteration beginnt mit der Probenahme Î» > 1 {\displaystyle \lambda >1* KandidatenlÃ¶sungen Îµ R n {\displaystyle x_{i}\in \mathbb {R} {^n} aus einer multivariate Normalverteilung N (m_{k, Ïƒ k 2 C k ) {\displaystyle \textstyle {\mathcal N}(m_{k},\sigma k}{2}C_{k) (m_{k},\sigma k{2}C_{k})\\&\sim \ m_{k}+\sigma_{k}\times {\mathcal N}(0,C_{k})\end{justed Die zweite Zeile schlÃ¤gt die Interpretation als StÃ¶rung (Mutation) des aktuellen LieblingslÃ¶sungsvektors m k {\displaystyle m_{k} (der Verteilungsmittelvektor) vor. Die KandidatenlÃ¶sungen x i {\displaystyle x_{i} werden auf der Zielfunktion f : R n â†’ R {\displaystyle f:\mathbb bewertet. {R} {^n}\to \mathbb {R} zu minimieren. Denotieren der f {\displaystyle f} -sortierten KandidatenlÃ¶sungen wie { x i : Î»  i i = 1 ... Î» } = { x i  i i = 1 ... Î» } und f ( x 1 : Î» ) â‰¤ â‹¯ â‰¤ f ( x Î¼ : Î» ) â‰¤ f ( x Î¼ + 1 : Î» ) â‰¤ da, {\displaystyle x_{i:\lambda x_{i}\midi=1\dots\lambda \}text und }f(x_{1:\lambda \})leq \dots \leq f(x_{\mu \:lambda \})leq f(x_{\mu +1:\lambda \})leq \cdots ,} der neue Mittelwert wird als m k + 1 berechnet 1 Î¼ w i x i: Î» = m k + Î£ i = 1 Î¼ w i ( x i : Î» - m k ) * i=1{\mu w_{i}\,x_{i:\lambda = +/m_{k}+\sum * i=1{\mu w_{i}\,(x_{i:\lambda -m_{k})\end{ausgerichtet, wenn die positiven (Rekombination) Gewichte w 1 â‰¥ w 2 â‰¥ â‹¯ â‰¥ w Î¼ > 0 {\displaystyle w_{1}\geq w_{2}\geq\dots \geq w_{\mu >0 sum to one. Typischerweise werden Î¼ â‰¤ Î» / 2 {\displaystyle \mu \leq \lambda /2} und die Gewichte so gewÃ¤hlt, daÃŸ Î¼ w := 1 = 1 Î¼ wi 2 â‰ˆ Î» / 4 {\displaystyle \textstyle \mu {_w}:=1/\sum * i=1{\mu w_{i}^{2}\approx \lambda /4} .Die einzige RÃ¼ckmeldung aus der Objektivfunktion hier und im folgenden ist eine Ordnung der abgetasteten KandidatenlÃ¶sungen aufgrund der Indizes i: Î» {\displaystyle i:\lambda } . Die Schritt-GrÃ¶ÃŸe Ïƒ k {\displaystyle \sigma {_k} wird mit kumulativer Schritt-GrÃ¶ÃŸe-Adaption (CSA,) manchmal auch als WeglÃ¤ngensteuerung bezeichnet aktualisiert. Der Evolutionspfad (oder Suchpfad) p Ïƒ {\displaystyle p_{\sigma }} wird zuerst aktualisiert. p Ïƒ â† ( 1 âˆ’ c Ïƒ ) âŸ Rabattfaktor p Ïƒ + 1 âˆ’ ( 1 âˆ’ c Ïƒ ) 2 â ergÃ¤nzt um reduzierte Varianz Î¼ w C k âˆ’ 1 / 2 m k + 1 âˆ’ m k â Verschiebung von m Ïƒ k âŸ verteilt als N (0, I ) unter neutraler Selektion {\sigma \}gets \underbrace (1 * \ '+overbrace {\sqrt 1-(1-c_{\sigma {^)2 \^!text{ErgÃ¤nzungen fÃ¼r Rabattvarianz}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! ) m_{k+1}-m_{k \^!text{displacement of m\!\!\!\!}{\sigma {_k} _\!text{distributed as {\}mathcal N}(0,I){\text unter neutraler Auswahl\}! Ïƒ k + 1 = Ïƒ k Ã— exp â€¡ ( c Ïƒ d Ïƒ ( Ïƒ Ïƒ Îµ Ïƒ Î¿ Î¿ Î¿ Î¿ Î¿ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Î¿ Î¿ Ïƒ Ïƒ k Ïƒ k Ïƒ k Ã— exp Î¶ ( c Ïƒ d Ïƒ ( Ïƒ Ïƒ Ïƒ Ïƒ Î¿ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Î¿ e Î¿ e Î¿ e Î¿ e Î¿ e Î¿ e Î¿ e Î¿ e Î¿ e Î¿ e Î· Î· Î· Î· N ( 0 ( 0, I, I, I, I Î¿, I Î· Î¿, I, I Î· Î¿ Î¿ Î¿ Î¿ Î¿ Î¿ Î¿ Î· Î· Î· Ïƒ Ïƒ Î· Î· Ïƒ Î· Î· Î· Î· Î· Î· Î· Î· Î· Î· Î· Ïƒ Ïƒ Î· Î· Î· Î· Î· Ïƒ Î· Ïƒ Ïƒ Î· Î· Î·  {_k+1} {_k}Zeiten \exp {\bigg ({\}frac c_{\sigma }d_{\sigma \}underbrace Left({\frac |p_{\sigma {\}Betreibername {E} {E}\\\mathcal {N}(0,I)\}}-1\right _\\\\! Text (unvoreingenommen etwa 0 unter neutraler Auswahl)\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\}{\{\\\\\\\\\}{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}}}}}}}}}}}}}}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ wobei c Ïƒ - 1 â‰ˆ n / 3 {\displaystyle c_{\sigma {-^1}\approx n/3} der rÃ¼ckwÃ¤rtige Zeithorizont fÃ¼r den Evolutionspfad p Ïƒ {\displaystyle p_{\sigma} ist c_{\sigma \}ll 1} ist an eine exponentielle Abklingkonstante wie ( 1 - c Ïƒ Ïƒ Ïƒ ) k â‰ˆ exp Die Halbwertszeit, * i=1{\mu w_{i}^{2}\right)^{-1 ist die varianzwirksame Auswahlmasse und 1 â‰¤ Î¼ w â‰¤ Î¼ w â‰¤ Î¼ {\displaystyle 1\leq \mu {_w}\leq \mu } durch Definition von w i {\displaystyle w_{i}, C k - 1 / 2 = C k - 1 = C k - 1 C_{k}{\\\\\'1/2}={\\sqrt ) C_{k}^{\;-1 ist die einzigartige symmetrische Quadratwurzel der Inverse von C k {\displaystyle C_{k} und d Ïƒ {\displaystyle d_{\sigma }} ist der DÃ¤mpfungsparameter in der Regel in der NÃ¤he eines. FÃ¼r d Ïƒ = âˆ {\displaystyle d_{\sigma =\}infty } oder c Ïƒ = 0 {\displaystyle c_{\sigma =0 bleibt die SchrittgrÃ¶ÃŸe unverÃ¤ndert. Die SchrittgrÃ¶ÃŸe Ïƒ k {\displaystyle \sigma {_k} wird erhÃ¶ht, wenn und nur, wenn der ermittelte Wert P Ïƒ zusammengestellt ist {\displaystyle |p_{\sigma }\|} grÃ¶ÃŸer ist als der erwartete Wert E festgestellt â‰ˆ N (0, I) = 2 Î“ (n + 1\) / 2 Î“ (n / 2 ) â‰ˆ n ( 1 -style 1 /) + 1 / (oper 21) (E} {E}\\\mathcal N}(0,I)\&&={\sqrt {2}\,\Gamma (n+1)/2)/\Gamma (n/2)\&\approx {\sqrt n}\,(1-1/(4\,n)+1/(21\,n^{2}))\end{justiert und verringert, wenn es kleiner ist. Aus diesem Grund tendiert das Schritt-GrÃ¶ÃŸe-Update dazu, aufeinanderfolgende Schritte C k - 1 {\displaystyle C_{k}^{-1 -conjugate zu machen, indem nach erfolgreicher Anpassung (m k + 2 - m k + 1 k + 1 Ïƒ k + 1 ) T C k - 1 m k + 1 - m k Ïƒ k â‰ˆ 0 {\displaystyle \textstyle links({\frac ) * {_k}}\approx 0} .Endlich wird die Kovarianzmatrix aktualisiert, wobei wiederum der jeweilige Evolutionspfad zuerst aktualisiert wird. p c â† ( 1 âˆ’ c c c ) âŸ Diskontfaktor p c + 1 [0 , Î± n ] ( â€¡ p Ïƒ â€¡) âŸ Indikatorfunktion 1 âˆ’ ( 1 âˆ’ c c c c ) 2 â ergÃ¤nzt um reduzierte Varianz Î¼ m k + 1 âˆ’ mk Ïƒ k âŸ als N (0, C k ) unter neutraler Auswahl verteilt {\displaystyle p_{c}\gets \underbrace (1-c_{c}) _\!text{discount ! ! * {_k} _\!text{distributed as}\;{\mathcal N}(0,C_{k})\;{\text{unter neutrale Auswahl\}! C k + 1 = ( 1 - c 1 - c Î¼ + c s ) Diskontfaktor C k + c 1 p c p c T âŸ eine Matrix + c Î¼ Î£ i = 1 Î¼ w i x i : Î» - m k Ïƒ k ( x i : Î» - m k Ïƒ k Ïƒ k ) T âŸ Ranke min (Î¼ , n ) Matrix {\displaystyle C_{k+1}=\underbrace (1-c_{1}-c_{\mu +c_{) _\!text{discount factor}\!\!\!\!\!\',C_{k}+c_{1}\underbrace * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * ~ Underbrace ~ * i=1{\mu ) x_{i:\lambda - Ja. x_{i:\lambda -m_{k}{\sigma _k}}}}\right)^{T {\_operatorname {rank} min(\mu ,n){\text matrix} wobei T {\displaystyle T} die transpose und c c - 1 â‰ˆ n / 4 bedeutet n/4} ist der rÃ¼ckwÃ¤rtige Zeithorizont fÃ¼r den Evolutionspfad p c {\displaystyle p_{c} und grÃ¶ÃŸer als eins, Î± â‰ˆ 1,5 {\displaystyle \alpha \approx 1.5} und die Anzeigefunktion 1 [0, Î± n ] (Îµ\\\\\\\\displaystyle \mathbf {1} {_0,\\\\sq} |\}leq \alpha {\sqrt {n}, was in der Regel der Fall ist, c s = ( 1 - 1 [0, Î± n ] (erwÃ¤hnt p Ïƒ ) 2 ) c 1 c ( 2 - c c c ) {\displaystyle c_{s}=(1-\mathbf {1} {_0,\alpha  learning________________ -m_{k})/\sigma {_k} aus N ( 0, C k + 1 ) {\displaystyle {\mathcal N}(0,C_{k+1) abzutasten. Die Anzahl der Kandidatenproben pro Iteration, Î» {\displaystyle \lambda }, wird nicht a priori bestimmt und kann in einem weiten Bereich variieren. Kleinere Werte, z.B. Î» = 10 {\displaystyle \lambda = 10}, fÃ¼hren zu mehr lokalem Suchverhalten. GrÃ¶ÃŸere Werte, beispielsweise Î» = 10 n {\displaystyle \lambda =10n} mit Standardwert Î¼ w â‰ˆ Î» / 4 {\displaystyle \mu {_w}\approx \lambda /4}, machen die Suche globaler. Manchmal wird der Algorithmus wiederholt mit zunehmendem Î» {\displaystyle \lambda } um einen Faktor von zwei fÃ¼r jeden Neustart neu gestartet. Neben der Einstellung Î» {\displaystyle \lambda } (oder ggf. Î¼ {\displaystyle \mu } anstelle, wenn z.B. Î» {\displaystyle \lambda } durch die Anzahl der verfÃ¼gbaren Prozessoren vorgegeben ist), sind die oben eingefÃ¼hrten Parameter nicht spezifisch fÃ¼r die gegebene Zielfunktion und daher nicht vom Benutzer modifiziert zu werden. Beispielcode in MATLAB/Octave Theoretische Grundlagen Bei den Verteilungsparametern - also Varianzen und Kovarianzen - ist die normale Wahrscheinlichkeitsverteilung fÃ¼r die Probenahme neuer KandidatenlÃ¶sungen die maximale Entropiewahrscheinlichkeitsverteilung Ã¼ber R n {\displaystyle \mathbb {R} {^n}, d.h. die Probenverteilung mit der minimalen Menge an in die Verteilung eingebauten Vorinformationen. Weitere Ãœberlegungen zu den Aktualisierungsgleichungen von CMA-ES werden im Folgenden gemacht. Variable Metrik Die CMA-ES implementiert eine stochastische variable Methode. Im ganz bestimmten Fall einer konvex-quadratischen Objektivfunktion f (x) = 1 2 ( x - x Î¨ ) T H ( x - x Ï‡ Î¨ ) {\displaystyle f(x)={\textstyle {\frac 1}}}(x-x^{*})^{T}H(x-x die Kovarianzmatrix C k {\displaystyle C_{k} Allgemeiner, auch auf der Funktion g ĞŸ f {\displaystyle g\circ f}, wo g {\displaystyle g} streng ansteigt und daher die Konservierung und f {\displaystyle f} konvexquadratisch ist, die Kovarianzmatrix C k {\displaystyle C_{k} passt sich an H - 1 {\displaystyle H^{-1} an, bis zu einem Skalarfaktor und kleinen zufÃ¤lligen Schwankungen. Beachten Sie, dass eine verallgemeinerte FÃ¤higkeit von Evolutionsstrategien zur Anpassung einer Kovarianz-Matrix-ReflektivitÃ¤t des inverse-Hessian fÃ¼r ein statisches Modell auf einer quadratischen AnnÃ¤herung nachgewiesen wurde. Maximale Wahrscheinlichkeitsaktualisierung Die Aktualisierungsgleichungen fÃ¼r mittlere und Kovarianzmatrix maximieren eine Wahrscheinlichkeit, wÃ¤hrend sie einem Erwartungsmaximierungsalgorithmus Ã¤hneln. Das Update des mittleren Vektors m {\displaystyle m} maximiert eine log-likelihood, so dass m k + 1 = arg âœ… max m Î£ i = 1 Î¼ w i log Î¶ N ( x i : Î» âˆ£ m ) {\displaystyle m_{k+1}=\arg \max * i=1{\mu w_{i}\logp_{\mathcal N}(x_{i:\lambda \}mid m}) wobei log â€¡ p N ( x ) = - 1 2 log det ( 2 Ï€ C ) - 1 2 ( x - m ) T C - 1 ( x - m ) C_{\displaystyle \log p_{\mathcal N}(x)=-{\frac 1}{2}\log det(2\pi C)-{\frac 1}(x-m)^{T}C^{-1}(x-m bezeichnet die log-likelihood of x{displaystyle xstyle} aus einer multivariate Normalverteilung mit mittlerem {display Dann sind die Rotation der Datenpunkte oder die Wahl von C {\displaystyle C} nicht-diagonal gleichwertig. Das Rank-Î¼ {\displaystyle \mu }-Update der Kovarianzmatrix, d.h. der rechte grÃ¶ÃŸte Summand in der Update-Gleichung von C k {\displaystyle C_{k}, maximiert eine Log-Lihood in dieser EPMATHMARKEREP T = arg{\displaystyle \sum _i=1} ) x_{i:\lambda - Ja. x_{i:\lambda -m_{k}{\sigma _k}}}}\right)^{T}=\arg \max {_C}\sum _i=1}{\mu ***________________________________________________________________ Nein. x_{i:\lambda - Ja. {_k}\right|C\right) fÃ¼r Î¼ â‰¥ n {\displaystyle {mu \geq n} (andereweise C {\displaystyle C} ist einzigartig, aber im Wesentlichen das gleiche Ergebnis hÃ¤lt fÃ¼r Î¼ < n\displaystyle \mu <n}\hier, p N ( x | C) {\displaystyle p{\\\mathcal {N}}(x| = 1 , C k + 1 {\displaystyle C_{k+1} ist der oben genannte Maximum-Lihood-SchÃ¤tzer. Siehe SchÃ¤tzung der Kovarianzmatrizen fÃ¼r Details zur Ableitung. NatÃ¼rlicher Gradientenabstieg im Raum der Probenverteilungen Akimoto et al.and Glasmachers et al. entdeckte unabhÃ¤ngig davon, dass die Aktualisierung der Verteilungsparameter dem Abstieg in Richtung eines abgetasteten natÃ¼rlichen Gradienten des erwarteten objektiven Funktionswertes E f ( x ) {\displaystyle Ef(x}) entspricht (zu minimieren), wo die Erwartung unter der Probenverteilung genommen wird. Mit der Parametereinstellung von c Ïƒ = 0 {\displaystyle c_{\sigma =0 und c 1 = 0 {\displaystyle c_{1}=0, d.h. ohne Schritt-GrÃ¶ÃŸe-Steuerung und Rank-One-Update, kann CMA-ES somit als Instantiation of Natural Evolution Strategies (NES) angesehen werden. Der natÃ¼rliche Gradient ist unabhÃ¤ngig von der Parametrierung der Verteilung. (x) Die sogenannte Score-Funktion, MENT Î¸ ln â€¡ p ( x Î¸ Î¸ ) = MENT Î¸ p ( x ) p ( x ) p ( x ) {\displaystyle \nabla {_\!theta \}ln p(x\mid \theta {=\)frac\nabla {_\!theta p(x)}{p(x, zeigt die relative Empfindlichkeit. Der natÃ¼rliche Gradient von E f ( x ) {\displaystyle Ef(x}) , entspricht der Fisher-Informationsmetrie (ein informationelles EntfernungsmaÃŸ zwischen Wahrscheinlichkeitsverteilungen und der KrÃ¼mmung der relativen Entropie), liest jetzt â€¡ E â‰  â¡ â¡ âˆ£ Î¸ Î¸ Î¸ Î¸ = F Î¸ - 1 ğŸ˜‰ = +)F_{\theta {-^1\nabla {_\!theta \}Operatorname {E} f(x)\mid \theta \)end{aligned} wobei die Fisher-Informationsmatrix F Î¸ {\displaystyle F_{\theta } die Erwartung des Hessian von -lnp ist und den Ausdruck unabhÃ¤ngig von der gewÃ¤hlten Parametrierung macht. Kombinieren Sie die bisherigen Gleichheiten, die wir erhalten â€¡ E â€¡ ( f ( x ) âˆ£ Î¸ ) = F Î¸ - 1 E â€¡ ( f ( x ) â™¦ â€¡ â™¦ â€¡ p ( x âˆ£ Î¸ ) ) = E â‰  f\ ( x ) F Î¸ - 1 Îº Î¸ n Î´ n Î´ n Î´ n = +)F_{\theta {-^1}\Operatorname {E} f(x)\nabla {_\!theta \}ln p(x\mid \theta =\&)Operatorname {E} f(x)F_{\theta {-^1\nabla {_\!theta \}ln p(x\mid \theta \)end{align} Eine Monte Carlo-AnnÃ¤herung der letzteren Erwartung nimmt den Durchschnitt Ã¼ber Î»-Proben von p MENT ~ E ^ Î¸ (f ) := - Î£ i = 1 Î» w i â Vorzugsgewicht F Î¸ - 1 Îº Îº Î¸ ln Ï ( x i : Î» âˆ£ Î¸ ) âŸ Vorzugsrichtung von x i : Î» mit w i = - f ( x i : Î» ) / Î» {\displaystyle {\tilde ! ! E}_{\theta (}f):=-\sum _i=1}^{\lambda ! F_{\thet {-^1\nabla {_\!theta \}ln p(x_{i:\lambda \}mid \theta } _\!text{kandidaten von }x_{i:\lambda \ ') w_{i}=-f(x_{i:\lambda \}/)lambda } wobei die Notation i: Î» {\displaystyle i:\lambda } von oben verwendet wird und daher w i {\displaystyle w_{i} monoton in i {\displaystyle i} abnimmt. Ollivier et al.finally fand eine rigorose Ableitung fÃ¼r die robusteren Gewichte, w i {\displaystyle w_{i}, wie sie in den CMA-ES definiert sind (Gewichte sind oft Null fÃ¼r i > Î¼). Sie werden als konsistenter Estimator fÃ¼r die CDF von f (X) , X fra p ( . | Î¸ ) {\displaystyle f(X),X\sim p(.|\theta )} am Punkt f ( x i : Î» \)\displaystyle f(x_{i:\lambda })} formuliert, der sich mit einer festen monotonen verminderten Transformation zusammensetzt -)1/2}{\lambda \right) Dies macht den Algorithmus unempfindlich gegen die spezifischen f {\displaystyle f} -Werte. Genauer gesagt, mit dem CDF-SchÃ¤tzer von f {\displaystyle f} statt f {\displaystyle f} selbst lassen den Algorithmus nur von der Ranking von f {\displaystyle f} -Werte, aber nicht von ihrer zugrunde liegenden Verteilung abhÃ¤ngig. Es macht den Algorithmus invariant zu monotonen f {\displaystyle f} -Transformationen. Î¸ = [ m k T vec â€¡ ( C k Ïƒ k ] T Îµ R n + n 2 + 1 {\displaystyle \theta = [m_{k}{T}\operatorname {vec} (C_{k})^{T}\sigma _k}{T}\in \mathbb n+n^{2}+1 so, daÃŸ p ( â‹… Î¸ Î¸ ) {\displaystyle p(\cdot \mid \theta } die Dichte der multivariate Normalverteilung N (m k , Ïƒ k 2 C k ) {\displaystyle n}(m_{k},\sigma k{2}C_{k{\displaystyle F_{\theta \mid \sigma *^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ k{2}C_{k}&0\0&2C_{k}Zeiten C_{k}\end{array}\right] und fÃ¼r ln Ä‹ p ( x Î¸ Î¸ Î¸ ) = ln â€¡ p ( x âˆ£ m k, Ïƒ k 2 C k ) = - 1 2 ( x - m k ) T Ïƒ k - 2 C k - 1 ( x - m k) - 1 2 ln merk det ( 2 Ï€ Ïƒ k 2 k ) k}^{-2}C_{k}^{-1}(x-m_{k})-{\frac 1}{2}}\ln det(2\pi \sigma k}^{2}C_{k) und nach einigen Berechnungen ergeben sich die Aktualisierungen im CMA-ES, als ob Matte die richtige Matrix aus dem jeweiligen natÃ¼rlichen Gradientensubvektor bildet. Das bedeutet, c 1 = c Ïƒ = 0 {\displaystyle c_{1} =0, die CMA-ES-Updates sinken in Richtung der NÃ¤herung MENT ~ E ^ Î¸ (f ) {\displaystyle {\tilde {\nabla {\}widehat E}_{theta (f) des natÃ¼rlichen Gradienten unter Verwendung verschiedener SchrittgrÃ¶ÃŸen (Lernraten 1 und c Î¼displaystyle c_{\mu } ) fÃ¼r die orthogonalen Parameter m Die neueste Version von CMA-ES verwendet auch eine andere Funktion w {\displaystyle w} fÃ¼r m {\displaystyle m} und C {\displaystyle C} mit negativen Werten nur fÃ¼r letztere (sogenannte aktive CMA). StationaritÃ¤t oder Unvoreingenommenheit Es ist vergleichsweise einfach zu erkennen, dass die Aktualisierungsgleichungen von CMA-ES einige StationaritÃ¤tsbedingungen erfÃ¼llen, indem sie im Wesentlichen unvoreingenommen sind. Unter neutraler Auswahl, wobei x i : Î» Î½ N ( m k, Ïƒ k 2 C k ) {\displaystyle x_{i:\lambda \}sim {\mathcal N}(m_{k},\sigma k}{2}C_{k) , finden wir, daÃŸ E âˆ‚ator ( m k + 1 k name ) = m k {displaystyle \ {E} (m_{k+1}\mid m_{k})=m_{k und unter einigen milden zusÃ¤tzlichen Annahmen unter den anfÃ¤nglichen Bedingungen E â€¡ (log â€¡ Ïƒ k + 1 Ïƒ Ïƒ k ) = log â¡ â¡ Ïƒ k {\displaystyle \operatorname {E} \(log \sigma {k+1\mid \sigma {_k})= {E} (C_{k+1}\mid C_{k})=C_{k Invariance Eigenschaften bedeuten eine gleichmÃ¤ÃŸige Leistung auf einer Klasse von objektiven Funktionen. Sie wurden als Vorteil argumentiert, weil sie das Verhalten des Algorithmus verallgemeinern und vorhersagen und damit die Bedeutung empirischer Ergebnisse auf einzelnen Funktionen stÃ¤rken. FÃ¼r CMA-ES wurden folgende Invarianzeigenschaften ermittelt. Invarianz unter ordnungserhaltenden Transformationen des objektiven Funktionswertes f {\displaystyle f}, in dem fÃ¼r alle h : R n â†’ R {\displaystyle h:\mathbb {R} {^n}\to \mathbb {R} Das Verhalten ist identisch mit f : x â†¦ g (h ( x ) ) {\displaystyle f:x\mapsto g(h(x}) fÃ¼r alle streng steigenden g : R â†’ R {\displaystyle g:\mathbb{R} \to \mathbb {R} .Diese Invarianz ist einfach zu Ã¼berprÃ¼fen, weil nur die f {\displaystyle f} -ranking im Algorithmus verwendet wird, die invariant ist unter der Wahl von g {\displaystyle g} .Scale-invariance, in that for any h: R n â†’ R {math\displaystyle h:\ {R} {^n}\to \mathbb {R} Das Verhalten ist unabhÃ¤ngig von Î± > 0 {\displaystyle \alpha >0} fÃ¼r die objektive Funktion f : x â†¦ h ( Î± x ) {\displaystyle f:x\mapsto h(\alpha x} bei Ïƒ 0 a 1 / Î± {\displaystyle \ n {_0}\propto 1/\alpha} und m 0 a 1 / Î± m_{0}\propto 1/\alpha } .Invariance unter Rotation des Suchraums in diesem fÃ¼r alle h : R n â†’ R {\displaystyle h:\mathbb {R} {^n}\to \mathbb {R}} und alle z Îµ R n {\displaystyle z\in \mathbb {R} {^n} das Verhalten auf f : x â†¦ h (R x ) {\displaystyle f:x\mapsto h(Rx}) ist unabhÃ¤ngig von der orthogonalen Matrix R {\displaystyle R}, gegeben m 0 = R - 1 z {\displaystyle ) .Mehr allgemein ist der Algorithmus auch invariant unter allgemeinen linearen Transformationen R {\displaystyle R}, wenn zusÃ¤tzlich die initiale Kovarianzmatrix als R - 1 R - 1 T gewÃ¤hlt wird {\displaystyle ) .Anyserious Parameter-Optimierungsverfahren sollte invariant sein, aber die meisten Methoden zeigen nicht alle oben beschriebenen Invarianzeigenschaften. Ein prominentes Beispiel mit den gleichen Invarianzeigenschaften ist die Nelder-Mead-Methode, bei der der Initial-Soxx jeweils gewÃ¤hlt werden muss. Konvergence Konzeptionelle Ãœberlegungen wie die Skalen-Invarianz-Eigenschaft des Algorithmus, die Analyse von einfacheren Evolutionsstrategien und Ã¼berwÃ¤ltigende empirische Beweise legen nahe, dass der Algorithmus auf einer groÃŸen Klasse von Funktionen schnell zum globalen Optimum konvergiert, bezeichnet als x ++ {\displaystyle x^{}* . Bei einigen Funktionen erfolgt die Konvergenz unabhÃ¤ngig von den Anfangsbedingungen mit der Wahrscheinlichkeit eins. Auf einigen Funktionen ist die Wahrscheinlichkeit kleiner als eins und hÃ¤ngt typischerweise von der Anfangszahl m 0 {\displaystyle m_{0} und Ïƒ 0 {\displaystyle \sigma {_0} ab.Empirisch kann oft die schnellste mÃ¶gliche Konvergenzrate in k {\displaystyle k} fÃ¼r rangbasierte direkte Suchverfahren beobachtet werden (abhÃ¤ngig von dem als lineare oder log-lineare oder exponentielle Konvergenz bezeichneten Kontext). Informell kÃ¶nnen wir m k - x Ï‡ â‰ˆ â‰ˆ m 0 - x Ï‡ Ï‡ e - c k {\displaystyle m_{k}-x^{*}\\\\\\\\\cca. ;m_{0}-x^{*\\\\\\times e^{-ck} fÃ¼r einige c > 0 {\displaystyle c>0}, und strenger 1 k Î£ i = 1 k log m i - x Ï‡ Ï‡ Ï‡ 1 k log kennzeichnete m k - x Ï‡ Ï‡ Ï‡ Ï‡ Ï‡ Ï‡ Ï‡ â†’ c < 0 fÃ¼r k â†’ âˆ, {\displaystyle {\frac 1 * i=1{k{k}\log m_{i}-x^^\\\\\\\\\\\\\\\\\\\\\{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ 1 m_{k}-x{*}\\\\\\\\\\\\m_{0}-x\\\\\\}\\\to -;c<0\quad \text{fÃ¼r }k\to \infty \;,} oder Ã¤hnliches, E â€¡ log â€¡ m k - x Ï‡ Ï‡ â‰  zusammengestellt m k - 1 - x Ï‡ Ï‡ â‰  â†’ gefunden - c < 0 fÃ¼r k â†’ âˆ . {\displaystyle \operatorname {E} \log {\frac m_{k}-x{*}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\c -;c<0\quad \text{fÃ¼r }k\to \infty \;.} Das bedeutet, dass im Durchschnitt die Entfernung zum Optimum in jeder Iteration um einen konstanten Faktor abnimmt, nÃ¤mlich durch exp âˆ‚ ( - c ) {\displaystyle \exp(-c}) .Die Konvergenzrate c {\displaystyle c} betrÃ¤gt etwa 0,1 Î» / n {\displaystyle 0,1\lambda /n} bei Î» {\displaystyle \lambda } ist nicht viel grÃ¶ÃŸer als die Dimension n {\displaystyle . Auch bei optimalen Ïƒ {\displaystyle \sigma } und C {\displaystyle C} kann die Konvergenzrate c {\displaystyle c} bei den oben genannten Rekombinationsgewichten w i {\displaystyle w_{i} nicht wesentlich Ã¼ber 0,25 Î» / n {\displaystyle 0.25\lambda /n} liegen. Die tatsÃ¤chlichen linearen AbhÃ¤ngigkeiten in Î» {\displaystyle \lambda } und n {\displaystyle n} sind bemerkenswert und sie sind in beiden FÃ¤llen die beste, die man in dieser Art von Algorithmus hoffen kann. Dennoch fehlt ein strenger Konvergenznachweis. Interpretation als Koordinatensystemtransformation Die Verwendung einer NichtidentitÃ¤tskovarianzmatrix fÃ¼r die multivariate Normalverteilung in Evolutionsstrategien entspricht einer Koordinatensystemtransformation der LÃ¶sungsvektoren, vor allem deshalb, weil die Abtastgleichung x i âˆ¼ m k + Ïƒ k Ã— N ( 0 , C k ) m k + Ïƒ k Ã— C k 1 / 2 N ( 0 , I ) {\displaystyle begin{aligned}x_{i}&\ * m_{k}+\sigma {_k}Zeiten {\mathcal N}(0,C_{k})\&\sim \ m_{k}+\sigma {_k}Zeiten C_{k}{1/2}{\mathcal N}(0,I)\end{aligned kann in einem "codierten Raum" gleich ausgedrÃ¼ckt werden, wie C k - 1 / 2 x i âŸ im Coderaum âˆ¼ C k - 1 / 2 m k âŸ + Ïƒ k Ã— N (0, I) {\displaystyle \underbrace ! ) {\}+sigma {_k}\times {\mathcal {N}(0,I)Die Kovarianzmatrix definiert eine bijektive Transformation (Codierung) fÃ¼r alle LÃ¶sungsvektoren in einen Raum, wo die Probenahme mit IdentitÃ¤tskovarianzmatrix erfolgt. Da die Aktualisierungsgleichungen in den CMA-ES unter linearen Koordinatensystemtransformationen invariant sind, kann das CMA-ES als adaptives Codierverfahren neu geschrieben werden, das auf eine einfache Evolutionsstrategie mit IdentitÃ¤tskovarianzmatrix angewendet wird. Dieses adaptive Codierungsverfahren ist nicht auf Algorithmen beschrÃ¤nkt, die aus einer multivariaten Normalverteilung (wie Evolutionsstrategien), sondern prinzipiell auf jede iterative Suchmethode angewendet werden kÃ¶nnen. Leistung in der Praxis Im Gegensatz zu den meisten anderen evolutionÃ¤ren Algorithmen ist der CMA-ES aus der Sicht des Benutzers quasi-parameterfrei. Der Benutzer muss einen anfÃ¤nglichen LÃ¶sungspunkt wÃ¤hlen, m 0 Îµ R n {\displaystyle m_{0}\in \mathbb {R} {^n} und die anfÃ¤ngliche SchrittgrÃ¶ÃŸe, Ïƒ 0 > 0 {\displaystyle \sigma {_0}>0 . Optional kann die Anzahl der Kandidatenproben Î» (BevÃ¶lkerungsgrÃ¶ÃŸe) durch den Benutzer geÃ¤ndert werden, um die charakteristischen Suchbedingungen zu Ã¤ndern (siehe oben). Die CMA-ES ist in Hunderten von Anwendungen empirisch erfolgreich und gilt insbesondere fÃ¼r nicht-konvexe, nicht-separable, krank-konditionierte, multimodale oder laute Zielfunktionen als nÃ¼tzlich. Eine Umfrage bei Black-Box-Optimierungen fand heraus, dass es 31 andere Optimierungsalgorithmen herausnahm, die besonders stark auf "schwierigen Funktionen" oder grÃ¶ÃŸeren Dimensions-SuchplÃ¤tzen. Die Suchraumdimension reicht typischerweise zwischen zwei und einigen hundert. Unter BerÃ¼cksichtigung eines Black-Box-Optimierungsszenarios, bei dem Gradienten nicht verfÃ¼gbar sind (oder nicht nÃ¼tzlich) und Funktionsauswertungen die einzigen betrachteten Kosten fÃ¼r die Suche sind, wird das CMA-ES-Verfahren wahrscheinlich durch andere zehn Methoden in den folgenden Bedingungen Ã¼berproportioniert: auf Low-dimensionale Funktionen, d.h. n < 5 {\displaystyle n<5}, z.B. durch das Downhill simplex-Verfahren oder surrogate-basierte Methoden (wie z. Bei trennbaren Funktionen dÃ¼rfte der Leistungsnachteil am wichtigsten sein, da CMA-ES bei allen vergleichbaren LÃ¶sungen mÃ¶glicherweise nicht finden kann. Auf der anderen Seite zeigt die CMA-ES bei nicht trennbaren Funktionen, die krank oder robust sind oder nur mit mehr als 100 n {\displaystyle 100n} Funktionsauswertungen gelÃ¶st werden kÃ¶nnen, am hÃ¤ufigsten Ã¼berlegene Leistung. Variationen und ErweiterungenDie (1+1)-CMA-ES erzeugt nur eine KandidatenlÃ¶sung pro Iterationsschritt, die die neue Distribution bedeutet, wenn es besser ist als der aktuelle Mittelwert. FÃ¼r c c = 1 {\displaystyle c_{c}=1 ist die (1+1)-CMA-ES eine enge Variante der Gaussian-Adaption. Einige natÃ¼rliche Evolution Strategien sind enge Varianten des CMA-ES mit bestimmten Parametereinstellungen. NatÃ¼rliche Evolution Strategien nutzen keine Evolutionspfade (also in CMA-ES-Einstellung c c = c Ïƒ = 1 {\displaystyle c_{c}=c_{\sigma = 1 ) und formalisieren das Update von Varianzen und Kovarianzen auf einem Cholesky-Faktor anstelle einer Kovarianzmatrix. Die CMA-ES wurde auch als MO-CMA-ES auf multiobjective Optimierung erweitert. Eine weitere bemerkenswerte Erweiterung war die Addition einer negativen Aktualisierung der Kovarianzmatrix mit dem sogenannten aktiven CMA. Die Verwendung des zusÃ¤tzlichen aktiven CMA-Updates wird heute als Standardvariante betrachtet. Siehe auch Globale Optimierung Stochastic Optimierung Derivative-free Optimierung SchÃ¤tzung des Distributionsalgorithmus Referenzen Bibliographie Hansen N, Ostermeier A (2001). VollstÃ¤ndig derandomisierte Selbstanpassung in Evolutionsstrategien. Evolutionary Computation, 9(2) S.159â€“195.[1] Hansen N, MÃ¼ller SD, Koumoutsakos P (2003). Reduzierung der ZeitkomplexitÃ¤t der derandomisierten Evolutionsstrategie mit Kovarianz-Matrixanpassung (CMA-ES). Evolutionary Computation, 11(1) S.1â€“18 [2] Hansen N, Kern S (2004). Bewertung der CMA-Entwicklungsstrategie fÃ¼r multimodale Testfunktionen. In Xin Yao et al,. Editoren, Parallel ProblemlÃ¶sung aus der Natur â€“ PPSN VIII, S.282â€“291, Springer. [3] Igel C, Hansen N, Roth S (2007). Covariance Matrix Anpassung fÃ¼r Multi-Objektive Optimierung. Evolutionary Computation, 15(1) pp.1â€“28.[4] Externe Links Eine kurze EinfÃ¼hrung in CMA-ES von N. Hansen Die CMA Evolution Strategy: A Tutorial CMA-ES Quellcode Seite