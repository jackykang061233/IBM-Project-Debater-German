Mediated Computing ist ein Bereich der Computerwissenschaft, in dem die Systeme verteilt werden. Ein verteiltes System ist ein System, dessen Komponenten auf verschiedenen vernetzten Computern liegen, die ihre Maßnahmen mitteilen und koordinieren, indem sie Nachrichten an ein anderes System weitergeben. Miteinander interagieren die Komponenten, um ein gemeinsames Ziel zu erreichen. Drei wesentliche Merkmale der verteilten Systeme sind: KonWährung von Bauteilen, fehlende globale Uhr und unabhängiges Versagen von Bauteilen. Beispiele für verteilte Systeme variieren von SOA-basierten Systemen bis hin zu massiven Online-Spiele bis hin zu Peer-to-Peer-Anwendungen. Ein Computerprogramm, das innerhalb eines verteilten Systems läuft, ist ein verteiltes Programm (und verteilte Programmierung ist der Prozess der Schreibweise). Es gibt viele verschiedene Arten von Umsetzungen für den Übertragungsmechanismus, einschließlich reiner IL, RPC-ähnlicher Verbindungen und Nachrichtenschlangen. Distributed Computing verweist auch auf die Nutzung der verteilten Systeme zur Lösung von Rechenproblemen. In verteiltem Rechner ist ein Problem in viele Aufgaben unterteilt, von denen jeder von einem oder mehreren Computern gelöst wird, die mit jedem anderen über die Weitergabe von Nachrichten kommunizieren. Einführung Das Wort, das in Bezug auf "verteiltes System", "verteilte Programmierung" und "verteilte Algorithmen" verteilt wurde, die ursprünglich auf Computernetze verwiesen werden, in denen einzelne Computer physisch innerhalb eines bestimmten geografischen Gebiets verteilt wurden. Die Begriffe werden heute in einem viel breiteren Sinne verwendet, auch in Bezug auf autonome Prozesse, die auf demselben physischen Computer laufen und mit einander interagieren. Obwohl es keine einheitliche Definition eines verteilten Systems gibt, werden die folgenden Definitionsmerkmale häufig als: Es gibt mehrere autonome Recheneinheiten (Computer oder Knoten), von denen jeder seine eigene lokale Erinnerung hat. Die beteiligten Unternehmen kommunizieren einander durch Nachrichtenübermittlung. Ein verteiltes System kann ein gemeinsames Ziel haben, wie die Lösung eines großen Rechenproblems; der Nutzer sieht dann die Sammlung autonomer Prozessoren als Einheit. Alternativ kann jeder Computer seinen eigenen Nutzer mit individuellen Bedürfnissen haben, und der Zweck des verteilten Systems ist es, die Nutzung gemeinsamer Ressourcen zu koordinieren oder den Nutzern Kommunikationsdienste anzubieten. Andere typische Eigenschaften der verteilten Systeme umfassen: Das System muss Fehler in einzelnen Computern tolerieren. Die Struktur des Systems (Netztopologie, Netzverfall, Anzahl der Computer) ist im Voraus nicht bekannt, das System kann aus verschiedenen Arten von Computern und Netzverbindungen bestehen und das System kann während der Ausführung eines verteilten Programms ändern. Jeder Computer hat nur einen begrenzten, unvollständigen Überblick über das System. Jeder Computer kann nur einen Teil des Inputs kennen. Parallele und verteilte Rechnersysteme sind Gruppen vernetzter Computer, die ein gemeinsames Ziel für ihre Arbeit verfolgen. Die Begriffe "Koncurrent Computing", "parallel Computing," und "verteilte Rechen" haben viel Überschneidungen und keine klare Unterscheidung zwischen ihnen. Das gleiche System kann sowohl parallel als auch verteilt sein; die Prozessoren in einem typischen verteilten System laufen gleichzeitig. Parallel-. kann als eine besonders eng gekoppelte Form des verteilten Rechners angesehen werden, und der verteilte Computer kann als eine lose gekoppelte Form von Parallelprozess angesehen werden. Gleichwohl ist es möglich, parallele oder verteilte Systeme mit folgenden Kriterien zu kategorisieren: Parallelprozess können alle Verarbeiter Zugang zu einem gemeinsamen Speicher haben, um Informationen zwischen den Verarbeitern auszutauschen. Jeder Prozessor verfügt über sein eigenes privates Gedächtnis (verteiltes Gedächtnis). Informationen werden ausgetauscht, indem Nachrichten zwischen den Verarbeitern übermittelt werden. Die Zahl am richtigen Beispiel zeigt den Unterschied zwischen verteilten und parallelen Systemen. Abbildung (a) ist ein Schematisches Bild eines typischen verteilten Systems; das System ist als Netztopologie vertreten, in der jeder Node ein Computer ist und jede Linie, die die Knoten miteinander verbindet, ist eine Kommunikationsverbindung. Abbildung (b) zeigt das gleiche verteilte System im Detail: Jeder Computer hat sein eigenes lokales Gedächtnis, und Informationen können nur ausgetauscht werden, indem er Nachrichten von einem Node an einen anderen weitergeben, indem er die verfügbaren Kommunikationsverbindungen nutzt. Abbildung (c) zeigt ein Parallelsystem, in dem jeder Verarbeiter einen direkten Zugang zu einem gemeinsamen Speicher hat. Die Situation ist noch komplizierter durch die traditionelle Verwendung der Begriffe parallel und verteilter Algorithmus, die nicht ganz den oben genannten Definitionen paralleler und verteilter Systeme entsprechen (siehe unten für ausführlichere Diskussionen). In der Regel des Daumens verwendet die Hochleistungs- parallele Berechnung in einem gemeinsamen Multiprozessor jedoch parallele Algorithmen, während die Koordinierung eines groß angelegten verteilten Systems verwendet Algorithmen. Geschichte Mit der Nutzung von parallelen Prozessen, die durch die Kommunikation über die Nachrichtenübermittlung kommunizieren, ist die Grundlage der in den 60er Jahren untersuchten Systemarchitekturen. Die ersten weit verbreiteten Systeme waren lokale Netze wie Ethernet, die in den siebziger Jahren entwickelt wurden. ARPANET, einer der Vorgänger des Internets, wurde in den späten 1960er Jahren eingeführt und ARPANET E-Mail wurde Anfang der siebziger Jahre entwickelt. E-Mail wurde die erfolgreichste Anwendung von ARPANET, und es ist wahrscheinlich das früheste Beispiel für eine groß angelegte Anwendung. Neben dem ARPANET (und seinem Nachfolger, dem globalen Internet) gehören neben anderen frühen weltweiten Computernetzen die Nutzungnet und FidoNet aus den 80er Jahren, die beide zur Unterstützung der verteilten Diskussionssysteme verwendet wurden. In den späten siebziger und frühen 80er Jahren wurde die Studie des verteilten Rechners zu einem eigenen Zweig der Informatik. Die erste Konferenz auf dem Gebiet, das Symposium "Grundsätze des verteilten Computers" (PODC), stammt aus dem Jahr 1982 und das internationale Symposium "Vertriebsrechner" (DISC) wurde 1985 in Ottawa erstmals als Internationaler Workshop über verteilte Algorithmen auf Graphen abgehalten. Architekturen Verschiedene Hardware- und Softwarearchitekturen werden für verteiltes Rechen verwendet. In einem niedrigeren Niveau ist es notwendig, mehrere CPUs mit einer bestimmten Netzart zu verbinden, unabhängig davon, ob dieses Netz auf einem Schaltkreis gedruckt wird oder aus locker gekoppelten Geräten und Kabeln bestehen. In einem höheren Maße ist es notwendig, die Prozesse, die auf diesen CPUs laufen, mit einer Art Kommunikationssystem zu verbinden. Verteilte Programmierung fällt in der Regel zu einer Reihe grundlegender Architekturen: Kunden-Server, drei-tier-, n-tier- oder Peer-to-Peer; oder Kategorien: lose Kupplung oder enge Kupplung. Kunden-Server: Architekturen, in denen intelligente Kunden den Server für Daten kontaktieren, dann Format und Anzeige an die Nutzer. Inputs auf dem Kunden sind auf dem Server zurückgefordert, wenn es einen dauerhaften Wandel darstellt. Three-tier: Architekturen, die die Kundeninformation auf mittlere Ebene verschieben, damit staatslose Kunden genutzt werden können. Dies vereinfacht den Einsatz. Die meisten Webanwendungen sind dreigeteilt: Architekturen, die in der Regel auf Webanwendungen verweisen, die ihre Anfragen an andere Unternehmensdienstleistungen weiterleiten. Diese Art der Anwendung ist die größte Verantwortung für den Erfolg von Anwendungsservern. Peer-to-Peer: Architekturen, in denen es keine speziellen Maschinen gibt, die eine Dienstleistung erbringen oder die Netzressourcen verwalten. Stattdessen sind alle Verantwortlichkeiten einheitlich zwischen allen Maschinen aufgeteilt, die als Peers bekannt sind. Peers können sowohl als Kunden als auch als Server dienen. Beispiele dieser Architektur sind BitTorrent und das slowenische Netzwerk. Ein weiterer grundlegender Aspekt der verteilten Rechenarchitektur ist die Methode der Kommunikation und Koordinierung der Arbeiten zwischen den laufenden Prozessen. Durch verschiedene Nachrichtenübermittlungsprotokolle können die Prozesse direkt mit einem anderen kommunizieren, in der Regel in einem Master-/Slowenienverhältnis. Alternativ kann eine datenbankorientierte Architektur das verteilte Rechen ohne jede Form der direkten interprozessalen Kommunikation ermöglichen, indem sie eine gemeinsame Datenbank nutzt. datenbankgestützte Architektur bietet insbesondere die Analyse der Verhältnisverarbeitung in einer Schematischen Architektur, die eine Live-Umwelt-Verbindung ermöglicht. Dies ermöglicht die Verbreitung von Rechenfunktionen sowohl innerhalb als auch außerhalb der Parameter einer vernetzten Datenbank. Anwendungen Gründe für die Nutzung von verteilten Systemen und verteiltem Rechner können Folgendes beinhalten: Die Art eines Antrags kann die Nutzung eines Kommunikationsnetzes erfordern, das mehrere Computer miteinander verbindet: beispielsweise Daten, die in einem physischen Standort hergestellt und in einem anderen Ort benötigt werden. Viele Fälle, in denen die Verwendung eines einzigen Computers grundsätzlich möglich wäre, aber die Nutzung eines verteilten Systems ist aus praktischen Gründen sinnvoll. Zum Beispiel kann es kostengünstiger sein, das gewünschte Leistungsniveau durch eine Reihe von Niedrigendcomputern im Vergleich zu einem einzigen hochEndcomputer zu erhalten. Ein verteiltes System kann mehr Zuverlässigkeit bieten als ein nicht verteilbares System, da es keinen einzigen Fehler gibt. Darüber hinaus kann ein verteiltes System leichter expandieren und verwalten als ein monolithisches uniprozessor-System. Beispiele für verteilte Systeme und Anwendungen des verteilten Rechners sind: Telekommunikationsnetze: Telefonnetze und zellulare Netze, Computernetze wie das Internet, drahtlose Sensornetze, Linealgorithmen; Netzanwendungen: World Wide Web und Peer-to-Peer-Netze, massives Online-Spiele und virtuelle Realitätsgemeinschaften, verteilte Datenbanken und verteilte Datenbankverwaltungssysteme, Netzdateisysteme, verteilte Caches, verteilte Informationsverarbeitungssysteme wie Bankensysteme und Flugbuchungssysteme; Echtzeit-Verfahrenskontrolle: Flugzeugkontrollsysteme, Industriekontrollsysteme; parallele Berechnung: wissenschaftliches Informatik, einschließlich Cluster-, Netz-, Cloud-.-.- und verschiedene freiwillige Rechenprojekte (siehe Liste der verteilten Rechnerprojekte), verteilt in Computer-Tabellen. theoretische Stiftungsmodelle Viele Aufgaben, die wir durch den Einsatz eines Computers automatisieren möchten, sind von Frage – wer möchte eine Frage stellen und der Computer sollte eine Antwort erstellen. In der theoretischen Computerwissenschaft werden solche Aufgaben als Rechenprobleme bezeichnet. Formell besteht ein Rechenproblem aus Instanzen zusammen mit einer Lösung für jede Instanz. Gerichtsverfahren sind Fragen, die wir bitten können, und Lösungen sind auf diese Fragen gefragt. Theoretische Computerwissenschaft versucht zu verstehen, welche rechnerischen Probleme durch den Einsatz eines Computers (Komputieritätstheorie) gelöst werden können und wie effizient (Krektivitätstheorie). Traditionell wird gesagt, dass ein Problem durch den Einsatz eines Computers gelöst werden kann, wenn wir einen Algorithmus entwickeln können, der eine korrekte Lösung für jedes einzelne Beispiel herstellt. Ein solcher Algorithmus kann als Computerprogramm umgesetzt werden, das auf einem allgemeinverbindlichen Computer läuft: Das Programm ist ein Problembeispiel aus Input, führt einige Berechnungen durch und stellt die Lösung als Output her. Formalismen wie zufällige Zugangsmaschinen oder universelle Turing-Maschinen können als abstrakte Modelle eines sequentiellen allgemeinen Computers verwendet werden, der einen solchen Algorithmus auslöst. Bereich der laufenden und verteilten Rechenstudien ähnliche Fragen im Falle mehrerer Computer oder eines Computers, der ein Netz von Interaktionsprozessen durchführt: welche rechnerischen Probleme in einem solchen Netzwerk gelöst werden können und wie effizient? Man ist jedoch nicht ganz offensichtlich, was durch "Lösung eines Problems" im Falle eines ständigen oder verteilten Systems gemeint ist: was ist die Aufgabe des Algorithmen-Designers, und was ist der gleichzeitige oder verteilte Wert eines sequenziellen allgemeinen Computers? Im Mittelpunkt der nachstehenden Diskussion stehen mehrere Computer, obwohl viele der Themen für parallele Prozesse mit einem einzigen Computer identisch sind. Drei Begriffe werden häufig verwendet: Parallele Algorithmen im gemeinsamen Modell Alle Verarbeiter haben Zugang zu einem gemeinsamen Speicher. Der Algorithmusentwickler wählt das Programm aus, das von jedem Prozessor durchgeführt wird. Ein theoretisches Modell ist das parallele Zufalls-Zugangssystem (PRAM). Das klassische PRAM-Modell übernimmt jedoch einen synchronen Zugang zum gemeinsamen Gedächtnis. Kooperative Programme können auf verteilte Systeme ausgedehnt werden, wenn das zugrunde liegende Betriebssystem die Kommunikation zwischen Nodes abdeckt und praktisch das Gedächtnis über alle einzelnen Systeme ungerechtfertigt. Ein Modell, das dem Verhalten von Echtzeit-Multiprozessor-Maschinen nähert und der Verwendung von Maschinenanleitungen, wie etwa Vergleiche-and-swap (CAS), Rechnung trägt, ist das als synchrones gemeinsames Gedächtnis. Es gibt eine Vielzahl von Arbeiten an diesem Modell, eine Zusammenfassung, die in der Literatur gefunden werden kann. Parallele Algorithmen im Modell der Anzeige Der Algorithmusentwickler wählt die Struktur des Netzes sowie das von jedem Computer durchgeführte Programm aus. Modelle wie die Schaltkreise und Sortiernetze werden verwendet. Flexible Schaltkreise können als Computernetz angesehen werden: jeder Weg ist ein Computer, der ein sehr einfaches Computerprogramm betreibt. Gleichermaßen kann ein Sortiernetz als Computernetz angesehen werden: jeder Vergleichator ist ein Computer. Verteilte Algorithmen in der Anzeige Der Algorithmusentwickler wählt nur das Computerprogramm aus. Alle Computer laufen dasselbe Programm. Das System muss unabhängig von der Struktur des Netzes ordnungsgemäß funktionieren. Ein allgemein benutztes Modell ist ein Diagramm mit einer einzigen finite-state Maschine pro node. Bei verteilten Algorithmen sind die Rechenprobleme in der Regel mit Graphen verknüpft. Häufig ist das Diagramm, das die Struktur des Computernetzes beschreibt, das Problem. Dies wird im folgenden Beispiel dargestellt. Beispiel: Das rechnerische Problem, eine Farbe eines bestimmten Graph-G. Verschiedene Felder zu finden, könnte die folgenden Ansätze verfolgen: Zentralisiertegorithmen Die Graph-G wird als eine Reihe definiert, und die Spanne wird als Beitrag zu einem Computer verwendet. Das Computerprogramm stellt eine Farbe des Diagramms fest, verschlüsselt die Farbe als eine Spanne und führt das Ergebnis aus. Parallele Algorithmen Wieder einmal wird die Graph G als eine Reihe definiert. Mehr Computer können jedoch parallel zur gleichen Spanne gelangen. Jeder Computer könnte sich auf einen Teil des Diagramms konzentrieren und eine Farbe für diesen Teil herstellen. Hauptschwerpunkt ist die Hochleistungsberechnung, die die Verarbeitungsleistung von mehreren Computern parallel nutzt. Verteilte Algorithmen Graph G ist die Struktur des Computernetzes. Es gibt einen Computer für jeden Node von G und eine Kommunikationsverbindung für jeden Rand der G. Zunächst weiß jeder Computer nur über seine unmittelbaren Nachbarn in der Grafik G; die Computer müssen Nachrichten austauschen, um mehr über die Struktur der G. Jeder Computer muss seine eigene Farbe als Output produzieren. Hauptschwerpunkt ist die Koordinierung des Betriebs eines willkürlichen verteilten Systems. Obwohl der Bereich paralleler Algorithmen einen anderen Schwerpunkt hat als der Bereich der verteilten Algorithmen, besteht viel Wechselwirkung zwischen den beiden Bereichen. Zum Beispiel wurde der Cole-Vishkin-Algorithmus für Graphikfarben ursprünglich als Parallelgorithmus dargestellt, aber die gleiche Technik kann auch direkt als verteilter Algorithmus verwendet werden. Darüber hinaus kann ein Parallelgorithmus entweder in einem Parallelsystem (mit gemeinsamem Gedächtnis) oder in einem verteilten System (Nutzung der Nachrichtenübermittlung) angewendet werden. Die traditionelle Grenze zwischen parallelen und verteilten Algorithmen (ein geeignetes Netzwerk gegenüber dem Betrieb in einem bestimmten Netz) liegt nicht im selben Ort wie die Grenze zwischen parallelen und verteilten Systemen (gemeinsames Gedächtnis vs. Nachrichtenübermittlung). Komplexe Maßnahmen Parallele Algorithmen, aber eine weitere Ressource neben Zeit und Raum ist die Zahl der Computer. Häufig gibt es zwischen der laufenden Zeit und der Anzahl der Computer einen Abstieg: Das Problem kann schneller gelöst werden, wenn es parallel mehr Computer gibt (siehe Geschwindigkeit). Wenn ein Entscheidungsproblem in der Polylogarithmie gelöst werden kann, indem eine polynomische Anzahl von Verarbeitern verwendet wird, wird das Problem in der Klasse NC angesprochen. Die Klasse NC lässt sich ebenso gut definieren, indem sie den PRAM- Formalismus oder die Schaltkreise von Boolean nutzt – PRAM-Maschinen können die Schaltkreise effizient und umgekehrt simulieren. In der Analyse der verteilten Algorithmen wird in der Regel mehr Aufmerksamkeit auf Kommunikationsoperationen als rechnerische Schritte gelegt. vielleicht ist das einfachere Modell des verteilten Rechners ein synchrones System, bei dem alle Knoten in einer Schleppfunktion arbeiten. Dieses Modell ist allgemein als LOCAL-Modell bekannt. In jeder Kommunikationsrunde erhalten alle Knoten parallel (1) die neuesten Botschaften ihrer Nachbarn, (2) willkürliche lokale Berechnungen durchführen und (3) neue Botschaften an ihre Nachbarn senden. In solchen Systemen ist eine zentrale Komplexitätsmaßnahme die Anzahl der Synchron-Kommunikationsrunden, die erforderlich sind, um die Aufgabe zu erfüllen. Diese Komplexitätsmaßnahme ist eng mit dem Durchmesser des Netzes verbunden. Lassen Sie D den Durchmesser des Netzes. Einerseits kann ein vernachlässigbares Problem in etwa 2D-Kommunikationsrunden uneinheitlich gelöst werden: Sie sammeln alle Informationen in einem Ort (D-Runde), lösen das Problem und informieren Sie alle Node über die Lösung (D-Runde). Andererseits müssen die Knoten des Netzes, wenn die Dauer des Algorithmus viel kleiner als die D-Kommunikationsrunden ist, ihre Produktion produzieren, ohne dass die Möglichkeit besteht, Informationen über weite Teile des Netzes zu erhalten. Mit anderen Worten müssen die Nodes global einheitliche Entscheidungen treffen, die auf Informationen basieren, die in ihrer lokalen D-Nachbarschaft verfügbar sind. Viele verteilte Algorithmen sind mit der laufenden Zeit viel kleiner als D-Runde, und das Verständnis, was Probleme durch solche Algorithmen gelöst werden können, ist einer der zentralen Forschungsfragen des Feldes. In der Regel wird ein Algorithmus, der ein Problem in der Polylogarithmiezeit in der Netzgröße gelöst, als effizient in diesem Modell angesehen. Eine weitere häufig verwendete Maßnahme ist die Gesamtzahl der im Netz übermittelten Bits (vgl. Kommunikationskomplex). Die Merkmale dieses Konzepts werden in der Regel mit dem CONGEST(B)-Modell erfasst, das ähnlich wie das LOCAL-Modell definiert ist, aber wenn einzelne Botschaften nur B Bits enthalten können. Andere Probleme traditionelle rechnerische Probleme nehmen die Ansicht an, dass der Nutzer eine Frage, einen Computer (oder ein verteiltes System) die Frage, stellt dann eine Antwort und einen Stopp her. Jedoch gibt es auch Probleme, wenn das System nicht gestoppt werden muss, einschließlich des Problems der Speiseröhren und anderer ähnlicher Probleme der gegenseitigen Ausgrenzung. In diesen Problemen soll das verteilte System die Verwendung gemeinsamer Ressourcen kontinuierlich koordinieren, damit keine Konflikte oder Sackgassen auftreten. Es gibt auch grundlegende Herausforderungen, die einzigartig sind, um zu verteilen, z.B. solche, die mit der Fehlertoleranz zusammenhängen. Beispiele für damit verbundene Probleme sind Konsensprobleme, Fremdschuldtoleranz und Selbststabilisierung. Mehr Forschung konzentriert sich auch auf das Verständnis der asynchronischen Natur der verteilten Systeme: Kontrastmittel können verwendet werden, um synchrone Algorithmen in asynchronen Systemen durchzuführen. Logische Uhren bieten einen Kausalum vor der Bestellung von Veranstaltungen. Messalgorithmen bieten weltweit einheitliche physische Zeitstempel an. Wahlkoordinatorwahlen (oder Führungswahlen) ist der Prozess der Ausweisung eines einzigen Prozesses als Organisator einiger Aufgaben, die unter mehreren Computern verteilt sind. Bevor die Aufgabe begonnen wird, sind alle Netzknoten entweder nicht bewusst, welche Node als Koordinator der Aufgabe dienen oder nicht mit dem aktuellen Koordinator kommunizieren kann. Nach Ablauf eines Koordinator-Wahlgorithmus erkennt jeder Knoten im gesamten Netz eine besondere, einzigartige Node als Task-Koordinator an. Das Netzknoten kommunizieren untereinander, um zu entscheiden, welchen von ihnen in den Koordinatorstaat gelangen.Hierzu brauchen sie eine gewisse Methode, um die Symmetrie zwischen ihnen zu überwinden. Kann jeder Node beispielsweise einzigartige und vergleichbare Identitäten haben, können die Knoten ihre Identität vergleichen und entscheiden, dass die Node mit höchster Identität der Koordinator ist. Die Definition dieses Problems wird oft auf LeLann übertragen, die es als Methode zur Schaffung eines neuen Tokens in einem Schleppnetz, in dem das Token verloren hat, formalisiert. Koordinatoren für Wahlalgorithmen sind so konzipiert, dass sie in Bezug auf die übertragenen Gesamtmenge und die Zeit wirtschaftlich sind. Der von Gallager, Humblet und Spira für allgemeine undirektierte Graphen vorgeschlagene Algorithmus hat einen starken Einfluss auf die Gestaltung verteilter Algorithmen im Allgemeinen und gewann den Dijkstra-Preis für ein einflussreiches Papier im verteilten Rechen. Viele andere Algorithmen wurden für verschiedene Arten von Netzdiagrammen vorgeschlagen, wie undirektierte Ringen, unidirektionale Ringen, vollständige Graphen, Netze, zielgerichtete Euler-Schätzungen und andere. Korach, Kutten und Moran wurden eine allgemeine Methode vorgeschlagen, die die Frage der Graph-Familie vom Entwurf des Koordinator-Wahlgorithmus entkoppelt. Um die Koordinierung durchzuführen, beschäftigen die verteilten Systeme das Konzept der Koordinatoren. Das Koordinierungsproblem besteht darin, einen Prozess von einer Gruppe von Prozessen zu verschiedenen Verarbeitern in einem verteilten System zu wählen, um als zentraler Koordinator tätig zu werden. Mehrere zentrale Koordinator-Auswahlgorithmen bestehen. Eigenschaften der verteilten Systeme Bisher liegt der Schwerpunkt auf der Konzeption eines verteilten Systems, das ein bestimmtes Problem gelöst. Ein ergänzendes Forschungsproblem untersucht die Eigenschaften eines bestimmten verteilten Systems. Das Problem ist ein ähnliches Beispiel aus dem Bereich der zentralisierten Berechnung: Wir erhalten ein Computerprogramm und die Aufgabe ist, zu entscheiden, ob es aufhält oder läuft. Das Problem ist im allgemeinen unbestreitbar, und natürlich ist das Verhalten eines Computernetzes mindestens so schwer wie das Verhalten eines Computers zu verstehen. Es gibt jedoch viele interessante Sonderfälle, die entscheiden können. Insbesondere ist es möglich, Grund für das Verhalten eines Netzes von finite-state Maschinen zu sein. Ein Beispiel ist, ob ein bestimmtes Netz von Interaktionen (alsynchronisch und nicht-deterministisch) Finnite-state-Maschinen eine Sackgasse erreichen kann. Dieses Problem ist der ZahlungsdienstleisterACE-vollständige, d.h. es ist freilich, aber nicht wahrscheinlich, dass ein effizienter (zentraler, paralleler oder verteilter) Algorithmus vorhanden ist, der das Problem im Falle großer Netze gelöst. Lesen Sie auch BücherAndrews, Gregory R. (2000), Stiftungen von Multithreaded, Parallel- und Distributed-Programmierung, Roc-Wesley, [0-201-35752-3.Arora, Sanjeev; Barak, Boaz (2009), Clektive Komplexity – ein modernes Konzept, Cambridge, ISBN [0-521-42426-42426-4.Cormen, Thomas H; Leiserson, Charles E; Rivest, Ronald (1990), Alithms (Anthithmen) . MIT Presse, ISBN @0-262-03141-7.Dolev, Shlomi (2000), Selbststabilisierung, MIT Presse, [0-262-04178-2.Elmasri, Ramez; Navathe, Shamkant B. (2000), Grundzüge der Datenbanken (3. ed), J.-Wesley, [0-201-54263-9.Ghaza, Sukumar (2007), Distributed Systems – Ein Algorithmic-Ansatz, Chapman & Hall/KRK, ISBN _1-58488-564-1.Lynch, A. (1996,) Verteilte Algorithms, Morgan Kaufmann, [2055860-348-6.Herlihy, Maurice P.vit, Nir N. (2008), Art of Multiprozessor, New Morgan, New York, S. .: A Locality-Sensitives Konzept, SIAM, [0-89871-464-7], Archiviert aus dem Original im Zeitraum 2009-2006, erholt 2009-07-16. ArtikelCole, Richard; Vishkin, Uzi (1986,) "Deterministische Münze mit Anwendungen für eine optimale Parallelliste", Information und Kontrolle, 70 (1): 32-53, doi:106/0019-9958(86)80023-7.Kei, Idit (2008), "Ditributed" 32 – Das Jahr der Überprüfung," ACM SIGACT News, 39 (4): 53–54, CiteSeerX 10,1285, doi:10.1145/1466390.1466402.Linial, Nathan (1992), "Locality in verteilten Graphen," SIAM Journal on Computing, 21 (1): 193–201, CiteSeerX 10.1.471.63, doi:10.1137/0221015.Naor, Larry Stock, 1995, "Wasch. Web-Seiten Godfrey, Bill (2002)." Peter, Ian (2004).“Ian Peter's History of the Internet. Retrieved 2009-08-04. Mehr lesen Bücher Atiya, Hagit und Jennifer Welch (2004), Disstributed Computing: Fundamentals, Simulationen und Advanced Issues, Haas-Interscience ISBN 0-471-45324-2.Christ Cachin; Rachidraoui; Luís Rodrigues (2011), Einführung einer zuverlässigen und sicheren Distributed Programmierung (2. ed). Springer, Bibcode:2011itra.book....C, ISBN @3-642-15259-7 Coulouris, George; et al.(2011), Distributed Systems: Concept and Design (5. Edition), Addison-Wesley ISBN 0-132-14301-1.Faber, Jim (1998), Java Distributed Systems Computer, O'Reilly: Java Distributed Computing von Jim Faber, 1998 Garg, Vijay K. (2002), Elemente des verteilten Rechners, Julius-IEEE Presse-Seminar Nr. Tel, Gerard (1994), Einführung zu Distributed Algorithms, Cambridge University Press Chandy, Mani und al. Paralleles Programm Design ArtsKeidar, Idit; Rajsbaum, Sergio, eds.(2000-2002), "Distributed Rechensäule"," ACM SIGACT News. Birrell, A. D; Levin, R; Schroeder, M. D; Needham, R. M. (April 1982). " Wein: Übung im verteilten Rechner" (PDF). Mitteilungen der ACM.25 (4): 260–274.doi:10.1145/358468.358487.Conference PapiereC. Rodríguez, M. Villagra und B. Barán, Bionetics2007, S.66–69, 2007. Externe Links Distributed Computing bei Curlie Distributed Rechenmagazine in Curlie