Human Kompatibel: Künstliche Intelligenz und das Problem der Kontrolle ist ein 2019 Nicht-Fiction-Buch von Informatiker Stuart J. Russell. Sie behauptet, dass das Risiko für die Menschheit von fortgeschrittener künstlicher Intelligenz (KI) trotz der Unsicherheit um zukünftige Fortschritte in der KI ein ernstes Anliegen ist. Sie schlägt auch einen Ansatz für das KI-Kontrollproblem vor. Zusammenfassung Russell beginnt mit der Behauptung, dass das Standardmodell der KI-Forschung, in dem die primäre Definition des Erfolgs besser und besser bei der Erreichung starrer menschlich spezifizierter Ziele wird, gefährlich falsch geführt wird. Solche Ziele können nicht wirklich das widerspiegeln, was die menschlichen Designer beabsichtigen, z.B. indem sie keine menschlichen Werte berücksichtigen, die nicht in den Zielen enthalten sind. Wenn eine nach dem Standardmodell entwickelte KI superintelligent werden sollte, würde sie wahrscheinlich die menschlichen Werte nicht vollständig reflektieren und für die Menschheit katastrophal sein. Russell behauptet, dass gerade weil die Zeitlinie für die Entwicklung von human- oder superintelligenter KI höchst unsicher ist, die Sicherheitsforschung so bald wie möglich begonnen werden sollte, da es auch sehr unsicher ist, wie lange es dauern würde, um diese Forschung abzuschließen. Russell argumentiert, dass anhaltende Fortschritte bei der KI-Fähigkeit aufgrund des wirtschaftlichen Drucks unvermeidlich sind. Solche Drücke sind bereits bei der Entwicklung bestehender KI-Technologien wie selbstfahrenden Autos und Personalassistenten zu erkennen. Darüber hinaus könnte AI auf menschlicher Ebene viele Billionen von Dollar wert sein. Russell untersucht dann die aktuelle Debatte über KI-Risiko. Er bietet Widersprüche für eine Reihe gemeinsamer Argumente, die KI-Risiko ablehnen und einen Großteil ihrer Beharrlichkeit auf den Tribalismus zurückweisen – Forscher können KI-Risikobedenken als Angriff auf ihr Feld sehen. Russell bekräftigt jedoch, dass es legitime Gründe dafür gibt, KI-Risikoprobleme ernst zu nehmen, und dass der wirtschaftliche Druck eine weitere Innovation in KI unvermeidlich macht. Russell schlägt dann einen Ansatz zur Entwicklung von nachweislich nützlichen Maschinen vor, die sich auf den Unterschied zum Menschen konzentrieren. Anders als in dem Standardmodell der KI, wo das Ziel starr und sicher ist, würde dieser Ansatz das eigentliche Ziel der KI weiterhin ungewiss haben, wobei die KI sich nur der Gewissheit nähert, da sie mehr Informationen über den Menschen und die Welt erhält. Diese Unsicherheit würde im Idealfall katastrophale Missverständnisse menschlicher Präferenzen verhindern und die Zusammenarbeit und Kommunikation mit Menschen fördern. Russell schließt mit der Forderung nach engerer Governance von KI-Forschung und -Entwicklung sowie kultureller Introspektion über die angemessene Autonomie, um in einer AI-dominierten Welt zu bleiben. Russells drei Prinzipien Russell listet drei Prinzipien auf, um die Entwicklung von nützlichen Maschinen zu leiten. Er betont, dass diese Prinzipien nicht ausdrücklich in die Maschinen kodiert werden sollen, sondern sie sind für die menschlichen Entwickler bestimmt. Die Grundsätze sind wie folgt: 1.Das einzige Ziel der Maschine ist es, die Verwirklichung der menschlichen Präferenzen zu maximieren. 2. Die Maschine ist zunächst unsicher, was diese Vorlieben sind. 3.Die ultimative Quelle von Informationen über menschliche Präferenzen ist menschliches Verhalten. Die Vorlieben Russell bezieht sich auf "alles eintreffen; sie decken alles, was Sie kümmern könnten, willkürlich weit in die Zukunft". Ebenso umfasst das Verhalten jede Wahl zwischen Optionen, und die Unsicherheit ist so, dass eine gewisse Wahrscheinlichkeit, die recht klein sein kann, jeder logisch möglichen menschlichen Präferenz zugeordnet werden muss. Russell erforscht inverses Verstärkungslernen, bei dem eine Maschine eine Belohnungsfunktion aus beobachtetem Verhalten als mögliche Grundlage für einen Mechanismus zum Erlernen menschlicher Präferenzen unterzieht. Empfang Mehrere Bewerter stimmten den Argumenten des Buches zu. Ian Sample in The Guardian nannte es überzeugend und "das wichtigste Buch über KI in diesem Jahr". Richard Waters der Financial Times lobte das Buch "Zwingen intellektueller Rigour". Kirkus befürwortete es als "ein starker Fall für die Planung für den Tag, an dem Maschinen über uns hinausgehen können". Die gleichen Kritiker charakterisierten das Buch als "wry and witty", oder aufgrund seines "laconic style and dry humour" zugänglich. Matthew Hutson vom Wall Street Journal sagte: "Mr. Russells spannendes Buch geht tief und funkelt mit trockenen Witzen." Ein Bibliotheks-Journal-Reviewer nannte es "Der richtige Führer zur richtigen Zeit". James McConnachie of The Times schrieb: "Dies ist nicht ganz das populäre Buch, das KI dringend benötigt. Seine technischen Teile sind zu schwierig, ihre philosophischen zu einfach. Aber es ist faszinierend und bedeutsam. " Demgegenüber wurde Human Kompatibel in seiner Nature Review von David Leslie, einem Ethics Fellow am Alan Turing Institute, kritisiert; und ähnlich wie in einem New York Times Opinion Essay von Melanie Mitchell. Ein Punkt der Zufriedenheit war, ob Superintelligenz möglich ist. Leslie Staaten Russell "verfehlt zu überzeugen, dass wir jemals die Ankunft einer "zweiten intelligenten Spezies" sehen werden", und Mitchell bezweifelt, dass eine Maschine jemals "die Allgemeinheit und Flexibilität der menschlichen Intelligenz" übertreffen könnte, ohne "die Geschwindigkeit, Präzision und Programmierbarkeit eines Computers" zu verlieren. Eine zweite Meinungsverschiedenheit war, ob intelligente Maschinen natürlich dazu neigen würden, so genannte "gemeinsame Sinne" moralische Werte anzunehmen. Auf Russells Gedankenexperiment über einen Geo-Engineering-Roboter, der "die Menschheit zum Entsäuern der Ozeane antreibt", versucht Leslie, jede Intelligenz zu identifizieren. In ähnlicher Weise glaubt Mitchell, dass ein intelligenter Roboter natürlich dazu neigt, "durch den gemeinsamen Sinn, die Werte und das gesellschaftliche Urteil, ohne das allgemeine Intelligenz nicht existieren kann, versucht zu werden". Das Buch ist seit langem für den Preis von Financial Times/McKinsey 2019 erhältlich. Siehe auch Künstliche Intelligenz: Ein modernes Approach Center for Human-Compatible Künstliche Intelligenz The Precipice: Existential Risk and the Future of Humanity Slaughterbots Superintelligence: Paths, Dangers, Strategies References Externe Interviews mit Stuart J. Russell