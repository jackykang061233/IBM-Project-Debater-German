In der evolutionären Berechnung ist die differentielle Evolution (DE) eine Methode, die ein Problem optimiert, indem es iterativ versucht, eine Kandidatenlösung in Bezug auf ein bestimmtes Maß an Qualität zu verbessern. Solche Methoden sind allgemein als Metaheuristik bekannt, da sie wenige oder keine Annahmen über das zu optimierende Problem machen und sehr große Räume von Kandidatenlösungen suchen können. Metaheuristiken wie DE garantieren jedoch nie eine optimale Lösung. DE wird für mehrdimensionale reale Funktionen verwendet, verwendet aber nicht den Gradienten des zu optimierenden Problems, d.h. DE erfordert nicht, dass das Optimierungsproblem differenzierbar ist, wie es durch klassische Optimierungsverfahren wie Gradientenabstieg und Quasi-Newton-Verfahren erforderlich ist. Die DE kann daher auch bei Optimierungsproblemen verwendet werden, die nicht einmal kontinuierlich sind, laut sind, sich zeitlich ändern, etc. DE optimiert ein Problem durch die Aufrechterhaltung einer Bevölkerung von Kandidatenlösungen und die Schaffung neuer Kandidatlösungen durch die Kombination bestehender nach seinen einfachen Formeln, und dann zu halten, welche Kandidat-Lösung die beste Punktzahl oder Fitness auf dem Optimierungsproblem zur Hand hat. Auf diese Weise wird das Optimierungsproblem als schwarze Box behandelt, die bei einer Kandidatenlösung lediglich ein Maß an Qualität liefert und daher der Gradient nicht benötigt wird. DE wurde in den 1990er Jahren von Storn und Price eingeführt. Bücher wurden über theoretische und praktische Aspekte der Verwendung von DE in Parallel-Computing, multiobjective Optimierung, eingeschränkte Optimierung, und die Bücher enthalten auch Umfragen von Anwendungsbereichen. Umfragen zu den vielfältigen Forschungsaspekten der DE finden sich in Zeitschriftenartikeln . Algorithmen Eine grundlegende Variante des DE-Algorithmus funktioniert durch eine Bevölkerung von Kandidatenlösungen (genannte Agenten). Diese Agenten werden im Suchraum durch einfache mathematische Formeln bewegt, um die Positionen der vorhandenen Agenten aus der Bevölkerung zu kombinieren. Ist die neue Position eines Agenten eine Verbesserung, so wird sie akzeptiert und ist Teil der Bevölkerung, sonst wird die neue Position einfach verworfen. Der Prozess wird wiederholt und dadurch wird erhofft, aber nicht garantiert, dass schließlich eine befriedigende Lösung gefunden wird. F : R n → R {\displaystyle f:\mathbb {R} {^n}\to \mathbb {R} ist die Fitnessfunktion, die minimiert werden muss (Anmerkung, dass die Maximierung durchgeführt werden kann, indem man die Funktion h := - f {\displaystyle h:=-f} betrachtet. Die Funktion nimmt eine Kandidatenlösung als Argument in Form eines Vektors von realen Zahlen und erzeugt eine reale Zahl als Ausgabe, die die Fitness der gegebenen Kandidatenlösung anzeigt. Der Gradient f {\displaystyle f} ist nicht bekannt. Das Ziel ist es, eine Lösung m {\displaystyle \mathbf {m} zu finden, für die f ( m ) ≤ f ( p ) {\displaystyle f(\mathbf {m} )\leq f(\mathbf {p} } für alle p {\displaystyle \mathbf {p} global im Suchraum ist, was bedeutet, dass m {\displaystyle} ε R n {\displaystyle \mathbf {x} \in \mathbb {R} Der grundlegende DE-Algorithmus kann dann wie folgt beschrieben werden: Wählen Sie die Parameter CR ε [0, 1 ] {\displaystyle text{CR}\in [0,1}], F ∈ [0, 2 ] {\displaystyle F\in [0,2}] und NP ≥ 4 {\displaystyle text{NP}}\geq 4} . NP {\displaystyle \text{NP} ist die Bevölkerungsgröße, d.h. die Anzahl der Kandidaten oder Eltern; eine klassische Einstellung ist 10 n {\displaystyle n} .Der Parameter CR ε [0, 1] {\displaystyle text{CR}}\in [0,1}] wird die Crossover-Wahrscheinlichkeit und der Parameter F ε [0, 2] {\displaystyle F\in [0,2}] das Differenzgewicht genannt. Klassische Einstellungen sind F = 0.8 {\displaystyle F=0,8} und C R = 0.9 {\displaystyle CR=0,9} .Die Optimierungsleistung kann durch diese Wahlen stark beeinflusst werden; siehe unten. Initialisieren Sie alle Agenten x {\displaystyle \mathbf {x} mit zufälligen Positionen im Suchbereich. Bis ein Kündigungskriterium erfüllt ist (z.B. Anzahl der durchgeführten Iterationen oder ausreichender Fitness erreicht ist), wiederholen Sie Folgendes: Für jeden Agenten x {\displaystyle \mathbf {x} in der Population tun: Pick drei Agenten a , b {\displaystyle \mathbf {a},\mathbf {b} } und c {\displaystyle \math\bf {c} aus der Population zufällig, sie müssen sowohl voneinander als auch von Agent xth\displaystyle Wählen Sie einen zufälligen Index R ε { 1 , ... , n } {\displaystyle R\in {1,\ldots ,n}\ wo n {\displaystyle n} die Dimensionalität des Problems optimiert ist. Die potenziell neue Position des Agenten y = [ y 1 , ..., y n ] {\displaystyle \mathbf {y} =[y_{1},\ldots ,y_{n}] wie folgt berechnen: Für jede i ε { 1 , ... , n } {\displaystyle i\in {1,\ldots ,n}\, wählen Sie eine gleichmäßig verteilte Zufallszahl r i ∼ U (0, 1 ) {\displaystyle r_{i}\sim U(0,1}) Wenn r i < C R {\displaystyle r_{i}<CR oder i = R {\displaystyle i=R} dann y i = i + F × (b i - c i ) y_{i}=a_{i}+F\times (b_{i}-c_{i) andernfalls y i = x i {\displaystyle y_{i}=x_{i .(Index Position R {\displaystyle R} wird sicher ersetzt.) Wenn f ( y ) ≤ f ( x ) {\displaystyle f(\mathbf {y} )\leq f(\mathbf {x} )} dann den Agenten x {\displaystyle \mathbf {x} in der Bevölkerung mit der verbesserten oder gleichen Kandidatenlösung y\displaystyle \mathbf {y} } ersetzt. Auswahl der Parameter Die Wahl der DE-Parameter F, CR {\displaystyle F,{\text{CR} und NP {\displaystyle \text{NP} kann einen großen Einfluss auf die Optimierungsleistung haben.Die Auswahl der DE-Parameter, die eine gute Leistung liefern, war daher Gegenstand viel Forschung. Daumenregeln für die Parameterauswahl wurden von Storn et al.and Liu und Lampinen entwickelt. Die mathematische Konvergenzanalyse zur Parameterauswahl wurde von Zaharie durchgeführt. Varianten Varianten des DE-Algorithmus werden kontinuierlich in einem Bemühen zur Verbesserung der Optimierungsleistung entwickelt. Viele verschiedene Systeme zur Durchführung von Crossover und Mutation von Agenten sind im oben angegebenen Basisalgorithmus möglich, siehe z. Siehe auch eine Mayfly Optimierung Algorithm Künstliche Bienen-Kolonie-Algorithmus CMA-ES Evolution Strategie Genereller Algorithmus == Referenzen ==