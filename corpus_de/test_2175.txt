Word-Sense-Diambiguation (WSD) ist ein offenes Problem bei rechnerischen Linguistiken, die darauf bedacht sind, welchen Sinn eines Wortes in einem Satz verwendet wird. Die Lösung dieses Problems wirkt sich auf andere computerbezogene Schriften wie Diskurs, Verbesserung der Relevanz von Suchmaschinen, Anaphora-Auflösung, Kohärenz und Inferenz aus. Aufgrund der Tatsache, dass natürliche Sprache Reflexion der neurologischen Realität erfordert, wie durch die Fähigkeiten der neuronalen Netzwerke des Gehirns, hat die Informatik eine langfristige Herausforderung bei der Entwicklung der Fähigkeit in Computern, natürliche Sprachverarbeitung und maschinelles Lernen zu tun. Viele Techniken wurden erforscht, darunter wörterbuchbasierte Methoden, die das in lexischen Ressourcen kodierte Wissen verwenden, beaufsichtigte maschinelle Lernmethoden, bei denen ein Klassifikator für jedes einzelne Wort an einem Korpus von manuell sinnbehafteten Beispielen geschult wird, und völlig unsupervised Methoden, die Erscheinungen von Wörtern bündeln wodurch Wortsinne induziert werden. Unter diesen, beaufsichtigte Lernansätze waren die bisher erfolgreichsten Algorithmen. Die Genauigkeit der aktuellen Algorithmen ist schwierig zu erklären, ohne eine Vielzahl von Höhlen. In englischer Sprache liegt die Genauigkeit auf der grobkörnigen (homographisch) Ebene routinemäßig über 90,% mit einigen Methoden auf bestimmten Homographen erreicht über 96 %. Bei feineren Sinnesdifferenzen wurden in Auswertungsübungen (SemEval-2007, Senseval-2,) Top-Akzentualitäten von 59,1 % bis 69,0 % gemeldet, wobei die Grundgenauigkeit des einfachsten möglichen Algorithmus, immer den häufigsten Sinn zu wählen, 51,4 % bzw. 57, % betrug. Über die Wort-Sense-Diambiguation Disambiguation erfordert zwei strenge Eingaben: ein Wörterbuch, um die zu disambiguierenden Sinne und ein Korpus von Sprachdaten zu disambiguieren (in einigen Methoden ist auch ein Trainingskorpus von Sprachbeispielen erforderlich). WSD-Aufgabe hat zwei Varianten: "lexische Probe" (Disambiguierung der Vorkommnisse einer kleinen Probe von Zielworten, die zuvor ausgewählt wurden) und "alle Wörter"-Aufgabe (Disambiguation aller Wörter in einem laufenden Text). "Alle Wörter" Aufgabe ist in der Regel eine realistischere Form der Auswertung, aber die Korpus ist teurer zu produzieren, weil menschliche Annotatoren die Definitionen für jedes Wort in der Reihenfolge jedes Mal lesen müssen, wenn sie ein tagging Urteil, anstatt einmal für einen Block von Instanzen für das gleiche Zielwort. Die Geschichte WSD wurde zunächst in den frühen Tagen der maschinellen Übersetzung in den 1940er Jahren als eine eindeutige Rechenaufgabe formuliert, was sie zu einem der ältesten Probleme in der Rechensprache macht. Warren Weaver stellte zunächst das Problem in einem rechnerischen Kontext in seinem 1949 Memorandum über die Übersetzung vor. Später argumentierte Bar-Hillel (1960) dass WSD nicht durch "elektronischen Computer" gelöst werden konnte, weil im Allgemeinen alle Weltkenntnisse modelliert werden müssen. In den 1970er Jahren war WSD ein Teil der semantischen Interpretationssysteme, die im Bereich der künstlichen Intelligenz entwickelt wurden, beginnend mit Wilks Präferenzsemantik. Da die WSD-Systeme zur Zeit weitgehend regel- und handcodiert waren, waren sie jedoch anfällig für einen Wissenserfassungsengpass. Durch die 1980er Jahre wurden umfangreiche lexische Ressourcen, wie das Oxford Advanced Learner's Dictionary of Current English (OALD,) zur Verfügung gestellt: Handcodierung wurde durch Wissen ersetzt, das automatisch aus diesen Ressourcen extrahiert wurde, aber Disambiguation war noch wissensbasierte oder wörterbuchbasierte. In den 1990er Jahren wurde die statistische Revolution eine fortgeschrittene rechnerische Linguistik, und WSD wurde ein Paradigmenproblem, auf dem überwachte maschinelle Lerntechniken angewendet werden. Die 2000er sahen überwachten Techniken erreichen ein Plateau in der Genauigkeit, und so hat sich die Aufmerksamkeit auf grobkörnige Sinne, Domain-Adaption, semi-supervised und unupervised corpus-basierten Systemen, Kombinationen verschiedener Methoden und die Rückkehr von wissensbasierten Systemen über graphische Methoden verschoben. Dennoch, beaufsichtigte Systeme weiterhin am besten. Unterschiede zwischen Wörterbüchern Ein Problem mit Wortsinn-Diambiguation entscheidet, was die Sinne sind, da unterschiedliche Wörterbücher und Thesauruse unterschiedliche Wortteilungen in Sinne liefern. Einige Forscher haben vorgeschlagen, ein bestimmtes Wörterbuch zu wählen, und mit seinem Satz von Sinnen, um mit dieser Frage Verwendung zu behandeln. In der Regel waren die Forschungsergebnisse mit weiten Unterschieden in den Sinnen jedoch viel besser als die mit engen. Die meisten Forscher arbeiten weiterhin an feinkörnigen WSD. Die meisten Forschungen auf dem Gebiet der WSD werden durchgeführt, indem WordNet als Referenz-Sense-Inventar für Englisch verwendet wird.WordNet ist ein rechnerisches Lexikon, das Konzepte als Synonym-Sets kodiert (z.B. das Konzept des Autos wird als { Auto, Auto, Auto, Maschine, Motorauto } kodiert.) Weitere Ressourcen, die für Disambiguationszwecke verwendet werden, umfassen Roget's Thesaurus und Wikipedia. In letzter Zeit wurde BabelNet, ein mehrsprachiges Lexikon, für mehrsprachige WSD verwendet. Teil-of-speech tagging In jedem realen Test haben sich Teile-of-speech-Taggings und Sinnes-Taggings als sehr eng mit jedem möglichen Zwängen der anderen verbunden erwiesen. Die Frage, ob diese Aufgaben zusammengehalten oder entkoppelt werden sollen, ist nach wie vor nicht einstimmig gelöst, aber vor kurzem neigen Wissenschaftler dazu, diese Dinge getrennt zu testen (z.B. in den Senseval/SemEval-Wettbewerben werden Teile der Rede als Input für den Text zur Disambiguation bereitgestellt). Die beiden WSM-Teil-of-Speech-Taggings beinhalten die Deambiguierung oder das Tagging mit Wörtern. Jedoch neigen Algorithmen, die für einen verwendet werden, nicht dazu, für den anderen gut zu arbeiten, vor allem weil der Teil der Rede eines Wortes in erster Linie von dem unmittelbar benachbarten zu drei Wörtern bestimmt wird, während der Sinn eines Wortes durch weitere Wörter bestimmt werden kann. Die Erfolgsquote für Teil-of-speech-Tagging-Algorithmen ist derzeit viel höher als die für WSD, der Stand der Technik rund 96 % Genauigkeit oder besser, im Vergleich zu weniger als 75 % Genauigkeit in Wortsinn-Diambiguation mit überwachtem Lernen. Diese Zahlen sind typisch für Englisch und können sehr verschieden von denen für andere Sprachen sein. Interjudge Varianz Ein weiteres Problem ist die interjudge Varianz. WSD-Systeme werden normalerweise getestet, indem sie ihre Ergebnisse auf eine Aufgabe verglichen mit denen eines Menschen haben. Während es jedoch relativ einfach ist, Textteile zuzuordnen, hat sich die Ausbildung von Menschen, die Sinne zu bekennen, als wesentlich schwieriger erwiesen. Während die Benutzer alle möglichen Teile der Rede ein Wort nehmen können, ist es oft unmöglich, alle Sinne zu merken, die ein Wort nehmen kann. Darüber hinaus stimmen die Menschen nicht der Aufgabe zu – geben Sie eine Liste von Sinnen und Sätzen, und die Menschen werden nicht immer zustimmen, auf welchem Wort in welchem Sinne gehört. Da die menschliche Leistung als Standard dient, ist sie eine obere Grenze für die Computerleistung. Die menschliche Leistung ist jedoch bei grobkörnigen als feinkörnigen Unterschieden viel besser, weshalb die Forschung über grobkörnige Unterscheidungen in den letzten WSD-Bewertungsübungen getestet wurde. Pragmatics Einige KI-Forscher wie Douglas Lenat argumentieren, dass man ohne irgendeine Form von gesunder Sensibilität keine Bedeutungen von Wörtern parsen kann. Diese sprachliche Frage wird Pragmatik genannt. Wie von den Forschern vereinbart, die Sinne von Wörtern richtig zu identifizieren, muss man die Fakten des gesunden Menschenverstands kennen. Darüber hinaus wird manchmal der gemeinsame Sinn benötigt, um solche Wörter wie Pronomen zu disambiguieren, wenn Anaphoras oder Cataphoras im Text haben. Aufgabenabhängigkeit von Sense-Inventar und Algorithmen Ein aufgabenunabhängiger Sinnbestand ist kein kohärentes Konzept: Jede Aufgabe erfordert eine eigene Wortbedeutungsteilung in für die Aufgabe relevante Sinne. Zusätzlich könnten durch verschiedene Anwendungen völlig unterschiedliche Algorithmen benötigt werden. Bei der maschinellen Übersetzung erfolgt das Problem in Form einer Zielwortauswahl. Die Sinne sind Wörter in der Zielsprache, die oft signifikanten Bedeutungsunterschieden in der Quellsprache entsprechen (die Bank könnte in den französischen Banque übersetzen), d.h. "Finanzbank" oder Rive", d.h. "Fluss"). Bei der Informationsabrufung ist ein Sinnesinventar nicht unbedingt erforderlich, da es ausreichend ist, zu wissen, dass in der Abfrage und einem abgerufenen Dokument ein Wort im gleichen Sinne verwendet wird; was ist, ist unwichtig. Unstimmigkeit der Sinne Schließlich ist der Begriff des "Wortssinns" rutschig und kontrovers. Die meisten Menschen können in Unterscheidungen auf der grobkörnigen Homographenebene (z.B. Stift als Schreibinstrument oder Gehäuse) zustimmen, aber gehen eine Ebene auf feinkörnige Polysemie hinunter, und Unstimmigkeiten entstehen. So stimmten beispielsweise in Senseval-2, die feinkörnige Sinnesdifferenzen verwendet, menschliche Annotatoren in nur 85 % der Worterscheinungen zu. Wortbedeutung ist im Prinzip unendlich variabel und kontextempfindlich. Sie teilt sich nicht leicht in verschiedene oder diskrete Untermittel auf. Lexikographen entdecken häufig lose und überlappende Wort-Bedeutungen, und Standard- oder konventionelle Bedeutungen erweitert, moduliert und in einer verwirrenden Vielfalt ausgenutzt. Die Kunst der Lexikographie ist es, von dem Korpus zu Definitionen zu verallgemeinern, die das gesamte Bedeutungsspektrum eines Wortes evozieren und erklären, so dass es scheint, als seien Wörter semantisch wohlverhalten.Es ist jedoch keineswegs klar, ob diese Bedeutungsunterschiede in rechnerischen Anwendungen gelten, da die Entscheidungen von Lexikographen in der Regel von anderen Erwägungen getrieben werden. Im Jahr 2009 wurde eine Aufgabe – genannt lexische Substitution – als mögliche Lösung für das Sinnesdiskretheitsproblem vorgeschlagen. Die Aufgabe besteht darin, einen Ersatz für ein Wort im Kontext zu schaffen, das die Bedeutung des ursprünglichen Wortes bewahrt (potenziell können Ersatzstoffe aus dem vollen Lexikon der Zielsprache gewählt werden, wodurch Unstimmigkeit überwunden wird). Ansätze und Methoden Es gibt zwei Hauptansätze für WSD – tiefe Ansätze und flache Ansätze. Tiefe Ansätze vermuten den Zugang zu einem umfassenden Körper des Weltwissens. Diese Ansätze werden in der Regel nicht als sehr erfolgreich in der Praxis angesehen, vor allem weil ein solcher Wissenskörper nicht in einem computerlesbaren Format existiert, außerhalb sehr begrenzter Domänen. Darüber hinaus kann es aufgrund der langen Tradition in der rechnerischen Linguistik schwierig sein, solche Ansätze in Bezug auf codiertes Wissen zu versuchen und in einigen Fällen zwischen dem Wissen, das an sprachlichen oder weltlichen Kenntnissen beteiligt ist, zu unterscheiden. Der erste Versuch war, dass Margaret Masterman und ihre Kollegen, in der Cambridge Language Research Unit in England, in den 1950er Jahren. Dieser Versuch diente als Daten eine gestanzte Kartenversion von Rogets Thesaurus und seinen nummerierten Köpfen, als Anzeige von Themen und suchte nach Wiederholungen im Text, mit einem festgelegten Schnittpunktalgorithmus. Es war nicht sehr erfolgreich, aber hatte starke Beziehungen zu späteren Arbeiten, vor allem Yarowskys maschinelle Lernoptimierung einer Thesaurusmethode in den 1990er Jahren. Langsame Ansätze versuchen nicht, den Text zu verstehen, sondern betrachten die umliegenden Worte. Diese Regeln können automatisch vom Computer abgeleitet werden, indem ein Trainingskorpus von Wörtern verwendet wird, die mit ihren Wortsinnen verschlagwortet sind. Dieser Ansatz, während theoretisch nicht so mächtig wie tiefe Ansätze, gibt in der Praxis überlegene Ergebnisse, aufgrund des begrenzten Weltwissens des Computers. Es gibt vier konventionelle Ansätze für WSD: Wörterbuch- und Wissensbasierte Methoden: Diese verlassen sich vor allem auf Wörterbücher, Thesauri und lexische Wissensgrundlagen, ohne irgendwelche Korpus-Beweise zu verwenden. Halb- oder minimal beaufsichtigte Methoden: Diese nutzen eine sekundäre Wissensquelle, wie ein kleiner annotierter Korpus als Samendaten in einem Bootstrapping-Prozess oder ein wortausgerichtetes zweisprachiges Korpus. Überarbeitete Methoden: Diese nutzen sinnlich benannte Körper zu trainieren. Unbeaufsichtigte Methoden: Diese eschew (fast) vollständig externe Informationen und arbeiten direkt von roher unannotierter Korporation. Diese Methoden sind auch unter dem Namen Wortsinndiskriminierung bekannt. Fast alle diese Ansätze arbeiten, indem man ein Fenster mit n Inhaltsworten um jedes Wort definiert, das im Korpus deambiguiert wird und diese n umgebenden Wörter statistisch analysiert. Zwei flache Ansätze, die zum Trainieren verwendet werden und dann disambiguate sind Naïve Bayes Klassifikatoren und Entscheidungsbäume. In der jüngsten Forschung haben kernelbasierte Methoden wie Support-Vektor-Maschinen eine überlegene Leistung im überwachten Lernen gezeigt. Graph-basierte Ansätze haben auch viel Aufmerksamkeit von der Forschungsgemeinschaft gewonnen und derzeit Leistung in der Nähe des Standes der Technik zu erreichen. Wörterbuch- und Wissensbasierte Methoden Der Lesk-Algorithmus ist die seminale wörterbuchbasierte Methode. Es basiert auf der Hypothese, dass Wörter, die zusammen in Text verwendet werden, miteinander verwandt sind und dass die Beziehung in den Definitionen der Wörter und ihrer Sinne beobachtet werden kann. Zwei (oder mehr) Wörter werden durch das Finden des Paares von Wörterbuch-Senses mit dem größten Wortüberlappung in ihren Wörterbuch-Definitionen disambiguiert. Zum Beispiel, wenn die Wörter in "pine cone" diambiguiert, umfassen die Definitionen der entsprechenden Sinne sowohl die Wörter immergrün und Baum (zumindest in einem Wörterbuch). Ein ähnlicher Ansatz sucht den kürzesten Weg zwischen zwei Wörtern: Das zweite Wort wird iterativ unter den Definitionen jeder semantischen Variante des ersten Wortes gesucht, dann unter den Definitionen jeder semantischen Variante jedes Wortes in den vorherigen Definitionen und so weiter. Schließlich wird das erste Wort durch die semantische Variante diambiguiert, die den Abstand vom ersten zum zweiten Wort minimiert. Eine Alternative zur Verwendung der Definitionen besteht darin, die allgemeine Wortsinnverwandtheit zu berücksichtigen und die semantische Ähnlichkeit jedes Paares von Wortsinnen basierend auf einer bestimmten lexischen Wissensbasis wie WordNet zu berechnen. Graphische Methoden, die an die Verbreitung der Aktivierungsforschung der frühen Tage der KI-Forschung erinnern, wurden erfolgreich angewandt.Es wurden komplexere graphische Ansätze gezeigt, die sowohl fast als auch beaufsichtigte Methoden durchführen oder sogar auf bestimmten Domänen übertreffen. Vor kurzem wurde berichtet, dass einfache Graphen-Konnektivitätsmaßnahmen, wie Grad, hochmoderne WSD in Gegenwart einer ausreichend reichen lexischen Wissensbasis durchführen. Auch die automatische Übertragung von Wissen in Form von semantischen Beziehungen von Wikipedia zu WordNet wurde gezeigt, um einfache wissensbasierte Methoden zu verbessern, so dass sie die besten überwachten Systeme rivalisieren und sogar in einer Domain-spezifischen Einstellung. Die Verwendung von Selektionspräferenzen (oder Selektionseinschränkungen) ist z.B. auch nützlich, wenn man weiß, dass man in der Regel Essen kocht, kann man das Wort Bass in "I am Cook Basses" (d.h. es ist kein Musikinstrument) disambiguieren. Überarbeitete Methoden Beaufsichtigte Methoden basieren auf der Annahme, dass der Kontext genügend Beweise für die Deambiguierung von Wörtern liefern kann (hence, common sense and Reasoning werden als unnötig erachtet). Wahrscheinlich wurde jeder maschinelle Lernalgorithmus auf WSD angewendet, einschließlich zugehöriger Techniken wie Feature-Auswahl, Parameteroptimierung und Ensemble-Learning. Support Vector Maschinen und speicherbasiertes Lernen haben sich bisher als erfolgreichste Ansätze erwiesen, wahrscheinlich weil sie mit der hohen Dimensionalität des Funktionsraums fertig werden können. Diese beaufsichtigten Methoden unterliegen jedoch einem neuen Wissenserwerbsengpass, da sie sich auf erhebliche Mengen von manuell fühlbaren Korporationen zur Ausbildung verlassen, die mühsam und teuer zu schaffen sind. Halbsupervised Methoden Aufgrund der fehlenden Trainingsdaten verwenden viele Wortsinn-Diambiguationsalgorithmen semi-supervised learning, was sowohl markierte als auch unmarkierte Daten erlaubt. Der Yarowsky-Algorithmus war ein frühes Beispiel für einen solchen Algorithmus. Es verwendet den „Ein Sinn pro Kollokation“ und die „Ein Sinn pro Diskurs“-Eigenschaften menschlicher Sprachen zur Wortsinndisambiguation. Aus der Beobachtung neigen Wörter dazu, in den meisten gegebenen Diskursen und in einer gegebenen Kollokation nur einen Sinn zu zeigen. Der Bootstrapping-Ansatz beginnt von einer kleinen Menge von Samendaten für jedes Wort: entweder manuell markierte Trainingsbeispiele oder eine kleine Anzahl von Surefire Entscheidungsregeln (z.B. spielen im Kontext des Basss fast immer zeigt das Musikinstrument). Die Samen werden verwendet, um einen anfänglichen Klassifikator mit jeder überwachten Methode zu trainieren. Dieser Klassifikator wird dann auf dem unbefestigten Teil des Korpus verwendet, um ein größeres Trainingsset zu extrahieren, in dem nur die zuversichtlichsten Klassifikationen enthalten sind. Der Vorgang wiederholt sich, wobei jeder neue Klassifikator auf einem sukzessive größeren Trainingskorpus trainiert wird, bis der gesamte Korpus verbraucht wird, oder bis eine bestimmte maximale Anzahl von Iterationen erreicht ist. Andere semi-supervised-Techniken verwenden große Mengen von untagged corpora, um co-occurrence Informationen zu liefern, die die verschlagwortete corpora ergänzt. Diese Techniken haben das Potenzial, bei der Anpassung der überwachten Modelle an verschiedene Domänen zu helfen. Auch ein mehrdeutiges Wort in einer Sprache wird in einer zweiten Sprache in Abhängigkeit vom Wortsinn oft in verschiedene Wörter übersetzt. Word-ausgeglichene zweisprachige Korporation wurde verwendet, um Cross-lingual Sinnesdifferenzen, eine Art semi-supervised System zu unterziehen. Unsupervised Methoden Unsupervised Lernen ist die größte Herausforderung für WSD-Forscher. Die zugrunde liegende Annahme besteht darin, dass ähnliche Sinne in ähnlichen Zusammenhängen auftreten und somit aus Text durch Clustern von Wortereignissen mit einem gewissen Maß an Ähnlichkeit des Kontexts, einer als Wortsinninduktion oder Diskriminierung bezeichneten Aufgabe, abgeleitet werden können. Dann können neue Erscheinungen des Wortes in die nächsten induzierten Cluster/Senses klassifiziert werden. Die Leistung ist geringer als bei den anderen oben beschriebenen Verfahren, aber Vergleiche sind schwierig, da induzierte Sinne auf ein bekanntes Wörterbuch von Wortsinnen abgebildet werden müssen. Ist eine Zuordnung zu einem Satz von Wörterbuchsenses nicht erwünscht, können Cluster-basierte Auswertungen (einschließlich Entropie- und Reinheitsmaßnahmen) durchgeführt werden. Alternativ können Wortsinninduktionsverfahren getestet und innerhalb einer Anwendung verglichen werden. Zum Beispiel wurde gezeigt, dass Wortsinn Induktion verbessert Web-Suchergebnis-Clustering durch Erhöhung der Qualität der Ergebnis-Cluster und der Grad Diversifizierung der Ergebnislisten. Es wird gehofft, dass unübertroffenes Lernen den Wissenserwerb Engpass überwinden wird, weil sie nicht von Handanstrengung abhängig sind. Die Darstellung von Wörtern, die ihren Kontext durch feste Größe dichte Vektoren (Worteinbettungen) betrachten, ist zu einem der grundlegendsten Blöcke in mehreren NLP-Systemen geworden.Obwohl die meisten traditionellen Worteinbettungstechniken Wörter mit mehreren Bedeutungen in eine einzelne Vektordarstellung einbinden, können sie noch verwendet werden, um WSD zu verbessern. Neben Worteinbettungstechniken können lexische Datenbanken (z.B. WordNet, ConceptNet, BabelNet) auch ununterbrochene Systeme bei der Abbildung von Wörtern und deren Sinnen als Wörterbücher unterstützen. Einige Techniken, die lexische Datenbanken und Worteinbettungen kombinieren, werden in AutoExtend und am besten geeignet Sense Annotation (MSSA) vorgestellt. In AutoExtend zeigen sie ein Verfahren, das eine Objekteingangsdarstellung in ihre Eigenschaften, wie Wörter und deren Wortsinne, entkoppelt. AutoExtend verwendet eine Graphenstruktur, um Wörter (z.B. Text) und Nicht-Wort (z.B. Synsets in WordNet) Objekte als Knoten und die Beziehung zwischen Knoten als Kanten abzubilden. Die Beziehungen (Beziehungen) in AutoExtend können entweder die Addition oder Ähnlichkeit zwischen seinen Knoten ausdrücken. Der erste erfasst die Intuition hinter dem Offset-Kalk, während dieser die Ähnlichkeit zwischen zwei Knoten definiert. In MSSA verwendet ein ununterbrochenes Disambiguationssystem die Ähnlichkeit zwischen Wortsinnen in einem festen Kontextfenster, um den am besten geeigneten Wortsinn mit einem vortrainierten Worteinbettungsmodell und WordNet auszuwählen. Für jedes Kontextfenster berechnet MSSA den Schwerpunkt jeder Wortsinndefinition durch Mittelung der Wortvektoren seiner Wörter in WordNet's Glanz (d.h. kurz definierender Glanz und ein oder mehrere Verwendungsbeispiel) unter Verwendung eines vortrainierten Worteinbettungsmodells. Diese Schwerpunkte werden später verwendet, um den Wortsinn mit der höchsten Ähnlichkeit eines Zielwortes zu seinen unmittelbar benachbarten Nachbarn (d.h. Vorgänger- und Nachfolgeworten) auszuwählen. Nachdem alle Wörter annotiert und disambiguiert werden, können sie als Trainingskorpus in jeder Standardworteinbettungstechnik verwendet werden. In seiner verbesserten Version kann MSSA Gebrauch von Wortsinn-Einbettungen machen, um seinen Disambiguationsprozess iterativ zu wiederholen. Sonstige Ansätze Andere Ansätze können unterschiedlich in ihren Methoden variieren: Domain-getriebene Disambiguation; Identifikation von dominanten Wortsinnen; WSD mit Cross-Lingual Evidence. WSD-Lösung in John Balls sprachunabhängiger NLU kombiniert Patom-Theorie [1] und RRG (Role and Reference Grammar) Art Inferenz in konstratbasierten Grammatiken Sonstige Sprachen Hindi: Mangel an lexischen Ressourcen in Hindi haben die Leistung von überwachten Modellen von WSD gehindert, während die unbeaufsichtigten Modelle durch umfangreiche Morphologie leiden. Eine mögliche Lösung dieses Problems ist die Konstruktion eines WSD-Modells mittels Parallel-Corporate. Die Schaffung des Hindi WordNet hat für mehrere Supervised-Methoden einen Weg geebnet, die erwiesenermaßen eine höhere Genauigkeit in der disambiguating nouns zu erzeugen. Lokale Hindernisse und Zusammenfassung Der Wissenserwerb Engpass ist vielleicht die große Behinderung, das WSD-Problem zu lösen. Unsupervised Methoden verlassen sich auf Wissen über Wortsinne, die nur spärlich in Wörterbüchern und lexischen Datenbanken formuliert ist. Beaufsichtigte Methoden hängen entscheidend von der Existenz von manuell annotierten Beispielen für jeden Wortsinn ab, einer erforderlichen, die bisher nur für eine Handvoll von Wörtern für Testzwecke erfüllt werden kann, wie es in den Senseval Übungen geschieht. Eines der vielversprechendsten Trends in der WSD-Forschung ist die Verwendung des größten Korpus, das World Wide Web, um lexische Informationen automatisch zu erwerben. WSD wurde traditionell als Zwischen-Sprachtechnik-Technologie verstanden, die Anwendungen wie Informationsabruf (IR) verbessern könnte. In diesem Fall ist aber auch umgekehrt: Web-Suchmaschinen implementieren einfache und robuste IR-Techniken, die das Web erfolgreich für Informationen in WSD verwenden können. Der historische Mangel an Trainingsdaten hat das Erscheinungsbild einiger neuer Algorithmen und Techniken hervorgebracht, wie es in der automatischen Akquisition von Sinnesmarkenkörper beschrieben ist. Das Wissen ist ein wesentlicher Bestandteil der WSD. Wissensquellen liefern Daten, die wesentlich sind, um Sinne mit Worten zu verbinden. Sie können von der Korporation von Texten variieren, entweder unmarkiert oder mit Wortsinnen versehen, zu maschinell lesbaren Wörterbüchern, Thesauri, Glossare, Onlogien, etc. Sie können wie folgt klassifiziert werden: Strukturierte maschinell lesbare Wörterbücher (MRDs) Ontologies Thesauri Unstrukturiert: Collocation-Ressourcen Andere Ressourcen (wie Wortfrequenzlisten, Stopplisten, Domain-Etiketten, etc.) Corpora: rohes Korporat und sinnannotiertes Korporat Die Vergleich und Auswertung unterschiedlicher WSD-Systeme ist aufgrund der unterschiedlichen Testsätze, Sinnesvorräte und Wissensressourcen äußerst schwierig.Vor der Organisation spezifischer Evaluierungskampagnen wurden die meisten Systeme auf hauseigenen, oft kleinen Datensätzen bewertet. Um den Algorithmus zu testen, sollten Entwickler ihre Zeit verbringen, um alle Wortvorkommnisse anzuzeigen. Und der Vergleich von Methoden auch auf demselben Korpus ist nicht förderfähig, wenn es verschiedene Sinnesvorräte gibt. Um gemeinsame Bewertungsdatensätze und -verfahren zu definieren, wurden öffentliche Evaluierungskampagnen organisiert. Senseval (jetzt umbenannt SemEval) ist ein internationales Wort-Sense-Diambiguation-Wettbewerb, das alle drei Jahre seit 1998 abgehalten wird: Senseval-1 (1998,) Senseval-2 (2001,) Senseval-3 (2004,) und sein Nachfolger SemEval (2007). Ziel des Wettbewerbs ist es, verschiedene Vorlesungen zu organisieren, Corpus für Testsysteme vorzubereiten und handannotieren, eine vergleichende Bewertung von WSD-Systemen in verschiedenen Arten von Aufgaben durchzuführen, einschließlich All-Worts und lexical Sample WSD für verschiedene Sprachen, und vor kurzem neue Aufgaben wie semantische Rollenlabeling, Glanz WSD, lexical Substitution, etc. Die für die Bewertung dieser Wettbewerbe eingereichten Systeme integrieren in der Regel verschiedene Techniken und kombinieren oft beaufsichtigte und wissensbasierte Methoden (insbesondere zur Vermeidung von schlechter Leistung in fehlenden Ausbildungsbeispielen). In den letzten Jahren 2007-2012 waren die WSD-Auswertungsaufgabenwahlen gewachsen und das Kriterium für die Bewertung von WSD hat sich je nach Variante der WSD-Auswertungsaufgabe drastisch geändert. Im Folgenden wird die Vielfalt der WSD-Aufgaben aufgezählt: Auswahl der Aufgaben Wie sich die Technologie entwickelt, wächst die Word Sense Disambiguation (WSD) Aufgaben in verschiedenen Geschmacksrichtungen zu verschiedenen Forschungsrichtungen und für mehr Sprachen: Klassische monolinguale WSD-Bewertungsaufgaben verwenden WordNet als Sinnesinventar und basieren weitgehend auf einer überwachten/semi-supervisierten Klassifikation mit dem manuell annotierten Körper: Classic English WSD verwendet das Princeton WordNet, da es Inventar erfasst und die primäre Klassifikationseingabe normalerweise auf dem SemCor corpus basiert. Klassische WSD für andere Sprachen verwendet ihr jeweiliges WordNet als Sinnesvorräte und Sinne annotierte Korporation, die in ihren jeweiligen Sprachen gekennzeichnet ist. Oft werden Forscher auch auf den SemCor corpus tippen und Bitexte mit Englisch als seine Quellsprache orientieren Cross-lingual WSD Bewertungsaufgabe konzentriert sich auch auf WSD in zwei oder mehr Sprachen gleichzeitig. Im Gegensatz zu den mehrsprachigen WSD-Aufgaben, anstatt manuell sinngemäße Beispiele für jeden Sinn eines polysemous noun zu liefern, wird das Sinnesinventar auf Basis paralleler Korporationen, z.B. Europarl corpus, aufgebaut. Mehrsprachige WSD-Auswertungsaufgaben konzentrierten sich gleichzeitig auf WSD in 2 oder mehr Sprachen, wobei sie ihre jeweiligen WordNets als Sinnesvorräte oder BabelNet als mehrsprachiger Sinnbestand nutzen. Es entwickelte sich aus den Translation WSD-Bewertungsaufgaben, die in Senseval-2 stattgefunden haben.Ein beliebter Ansatz ist die Durchführung von einsprachigen WSD und dann die Quellsprachensinne in die entsprechenden Zielwort-Übersetzungen. Word Sense Induction and Disambiguation Task ist eine kombinierte Task-Auswertung, bei der der Sinnbestand zunächst aus einem festen Trainingssatz-Daten, bestehend aus polysemösen Wörtern und dem Satz, in dem sie aufgetreten sind, induziert wird, dann wird WSD auf einem anderen Testdatensatz durchgeführt. Software Babelfy, ein einheitliches State-of-the-Art-System für mehrsprachige Word Sense Disambiguation und Entity Linking BabelNet API, eine Java-API für wissensbasierte mehrsprachige Word Sense Disambiguation in 6 verschiedenen Sprachen mit dem BabelNet semantic network WordNet::SenseRelate, ein Projekt-Sense, das freie, offene Quellsysteme für Wortdisambiguation umfasst Siehe auch Ambiguity Controlled natürliche Sprache Entity Linking Lesk algorithm Lexical SubstitutionPart-of-speech tagging Polysemy Semeval Semantic Unification Judicial Interpretation Sentence Limit Disambiguation Syntactic Ambiguity Wortsinn Wortsinn Induktion Notizen Werke zitiert Agirre, E;. Lopez de Lacalle, A;. Soroa, A. (2009). " Wissensbasierte WSD auf bestimmten Domains: Besser als Generic Supervised WSD durchführen" (PDF). Proc.of IJCAI. Agirre, E;. M. Stevenson. 2006. Wissensquellen für WSD. In Word Sense Disambiguation: Algorithmen und Anwendungen, E. Agirre und P. Edmonds, Eds.Springer, New York, NY.Bar-Hillel, Y. (1964). Sprache und Information. Lesung, MA: Addison-Wesley. Buitelaar, P;. B. Magnini, C. Strapparava und P. Vossen. 2006.Domain-spezifische WSD. In Word Sense Disambiguation: Algorithmen und Anwendungen, E. Agirre und P. Edmonds, Eds.Springer, New York, NY. Chan, Y. S;. H. T. Ng. 2005. Skalieren von Wortsinn-Diambiguation über parallele Texte. In Proceedings der 20. Nationalkonferenz über Künstliche Intelligenz (AAAI, Pittsburgh, PA). Edmonds, P. 2000. Entwerfen einer Aufgabe für SENSEVAL-2.Tech-Note. University of Brighton, Brighton. U.K Fellbaum, Christiane (1997)." Analyse einer Handschriftaufgabe". Proc.of ANLP-97Workshop zum Tagging Text mit Lexical Semantics: Warum, Was, und wie? Washington D.C., USA. Gliozzo, A;. B. Magnini und C. Strapparava.2004. Unsupervised Domain Relevanz Schätzung für Wortsinn Disambiguation. In den Proceedings der 2004 Konferenz über empirische Methoden in der Natural Language Processing (EMNLP, Barcelona, Spanien). Ide, N;. T. Erjavec, D. Tufis.2002. Sense Diskriminierung mit parallelem Körper. In Proceedings of ACL Workshop on Word Sense Disambiguation: Aktuelle Erfolge und zukünftige Richtungen (Philadelphia, PA). Kilgarriff, A. 1997. Ich glaube nicht an Wortsinne. Comput.Human.31(2,) S.91–113.Kilgarriff, A;. G. Grefenstette. 2003. Einführung in die Sonderausgabe im Web als corpus. Computational Linguistics 29(3,) pp.333–347 Kilgarriff, Adam; Joseph Rosenzweig, English Senseval: Report and Results May–June, 2000, University of Brighton Lapata, M;. and F. Keller. 2007. Ein Informations-Retrieval-Ansatz zum Ranking. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL, Rochester, NY). Lenat, D. "Computer versus Common Sense".Retrieved 2008-12-10.(GoogleTachTalks auf YouTube) Lenat, D;. R. V. Guha. 1989.Building Large Knowledge-Based Systems, Addison-Wesley Lesk; M. 1986.Automatische Sinnesdisambiguation mit maschinell lesbaren Wörterbüchern: Wie man einen Kiefer Kegel aus einem Eiskegel sagt. In Proc.of SIGDOC-86: 5. Internationale Konferenz zur Systemdokumentation, Toronto, Kanada. Litkowski, K. C. 2005.Wettbewerbliche Lexikone und Wörterbücher. In Encyclopaedia of Language and Linguistics (2. ed.,) K. R. Brown, Ed.Elsevier Publishers, Oxford, U.K Magnini, B; G. Cavaglià. 2000. Integrieren von Themenfeldcodes in WordNet. Bei den Verfahren der 2. Konferenz über Sprachressourcen und -bewertung (LREC, Athen, Griechenland). McCarthy, D;. R. Koeling, J. Weeds, J. Carroll. 2007. Unsupervised Akquisition von vorherrschenden Wortsinnen. Computational Linguistics 33(4:) 553–590.McCarthy, D;. R. Navigli. 2009. The English Lexical Substitution Task, Language Resources and Evaluation, 43(2,) Springer. Mihalcea, R. 2007. Verwendung von Wikipedia für automatische Word-Sense-Disambiguation. In Proc.of of the North American Chapter of the Association for Computational Linguistics (NAACL 2007,) Rochester, April 2007. Mohammad, S; G. Hirst. 2006. Bestimmen von Wortsinn Dominanz mit einem Thesaurus. In Proceedings der 11. Konferenz zum Europäischen Kapitel des Vereins für computergestützte Linguistik (EACL, Trento, Italien). Navigli, R. 2006.Meaningful Clustering of Senses hilft Word SenseDisambiguation zu erhöhen Leistung. Proc.of der 44. Jahrestagung des Vereins für rechnerische Linguistik gemeinsam mit der 21. Internationalen Konferenz über rechnerische Linguistik (COLING-ACL 2006,) Sydney, Australien. Navigli, R;. A. Di Marco. Clustering und Diversifizierung von Web-Suchergebnissen mit Graph-basierten Word-Sense-Induktion.Computational Linguistik, 39(3,) MIT Presse, 2013, S.709–754. Navigli, R;. G. Crisafulli. Erzeugung Word senses to Improve Web Search Result Clustering. Proc. of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP 2010,) MIT Stata Center, Massachusetts, USA. Navigli, R;. M. Lapata. Eine experimentelle Studie über Graph-Konnektivität für Unsupervised Word Sense Disambiguation.IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI,) 32(4,) IEEE Press, 2010. Navigli, R;. K. Litkowski, O. Hargraves.2007.SemEval-2007 Aufgabe 07: Coarse-Grained English All-Words Task. Proc.of Semeval-2007 Workshop (SemEval) in der 45. Jahrestagung des Vereins für rechnerische Linguistik (ACL 2007,) Prag, Tschechische Republik. Navigli, R.;P Velardi.2005. Strukturelle Semantische Verbindungen: eine wissensbasierte Annäherung an Word Sense Disambiguation.IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI,) 27(7). Palmer, M;. O. Babko-Malaya und H. T. Dang.2004. Verschiedene Sinneskörnigkeiten für verschiedene Anwendungen. In den Proceedings des 2. Workshops zum skalierbaren natürlichen Sprachverstehen von Systemen in HLT/NAACL (Boston, MA). Ponzetto, S. P;. R. Navigli.Knowledge-rich Word Sense Disambiguation rivaling überwachte Systeme. In Proc.of der 48. Jahrestagung des Vereins für Computational Linguistics (ACL,) 2010. Pradhan, S;. E. Loper, D. Dligach, M. Palmer. 2007.SemEval-2007 Aufgabe 17: Englische lexische Probe, SRL und alle Wörter. Proc.of Semeval-2007 Workshop (SEMEVAL) in der 45. Jahrestagung des Vereins für computergestützte Linguistik (ACL 2007,) Prag, Tschechische Republik. Schütze, H. 1998.Automatisches Wort zur Diskriminierung. Computational Linguistics, 24(1:) 97–123.Snow, R;. S. Prakash, D. Jurafsky, A. Y. Ng. 2007.Learning to Merge Word Senses, Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL). Snyder, B;. M. Palmer. 2004. Die englische All-Worts-Task. In Proc.of des 3. Internationalen Workshops zur Evaluation von Systemen für die Semantische Analyse von Text (Senseval-3,) Barcelona, Spanien. Weaver, Warren (1949)."Übersetzung (PDF.) In Locke, W.N; Booth, A.D. (Hrsg.). Übersetzung von Sprachen: Vierzehn Essays. Cambridge, MA: MIT Drücken. Wilks, Y;. B. Slator, L. Guthrie.1996. Elektrizität Wörter: Wörterbücher, Computer und Bedeutungen. Cambridge, MA: MIT Drücken. Yarowsky, D. Word-Sense-Diambiguation mit statistischen Modellen der Roget-Kategorien, die auf großen Körper ausgebildet sind. In Proc.of der 14. Konferenz über Computational Lingus (COLING) 1992. Yarowsky, D. 1995. Unsupervised Wort sin disambiguation rivaling überwachte Methoden. In Proc.of der 33. Jahrestagung des Vereins für Computational Linguistics. Externe Links und vorgeschlagenes Lesen Computational Linguistics Special Issue on Word Sense Disambiguation (1998) Evaluation Übungen für Word SenseDisambiguation Die de facto Standard-Benchmarks für WSD-Systeme. Roberto Navigli. Word Sense Disambiguation: A Survey, ACM Computing Surveys, 41(2,) 2009, S.1–69. Ein aktueller Stand der Technik des Feldes. Word Sense Disambiguation wie in Scholarpedia Word Sense Disambiguation definiert: Der Stand der Kunst (PDF)Ein umfassender Überblick Von Prof. Nancy Ide & Jean Véronis (1998). Word Sense Disambiguation Tutorial, von Rada Mihalcea und Ted Pedersen (2005). Nun, gut. Word Sense Disambiguation mit Google n-Grams, von Craig Trim (2013). Word Sense Disambiguation: Algorithmen und Anwendungen, herausgegeben von Eneko Agirre und Philip Edmonds (2006,) Springer. Bezieht das gesamte Feld mit Kapiteln, die von führenden Forschern beigetragen.www.wsdbook.org Website des Buches Bar-Hillel, Yehoshua. 1964. Sprache und Information. New York: Addison-Wesley. Edmonds, Philip & Adam Kilgarriff. 2002.Einführung in die Sonderausgabe zur Bewertung von Wortsinn-Diambiguationssystemen. Journal of Natural Language Engineering, 8(4):279-291.Edmonds, Philip. 2005.Lexical disambiguation. The Elsevier Encyclopedia of Language and Linguistics, 2. Ed., ed.by Keith Brown, 607–23. Oxford: Elsevier. Ide, Nancy & Jean Véronis.1998. Wortsinn Disambiguation: Der Stand der Technik.Computational Linguistics, 24(1):1-40. Jurafsky, Daniel & James H. Martin. 2000. Sprach- und Sprachverarbeitung. New Jersey, USA: Prentice Hall. Litkowski, K. C. 2005. Computational Lexikon und Wörterbücher. In Encyclopaedia of Language and Linguistics (2. ed.,) K. R. Brown, Ed.Elsevier Publishers, Oxford, U.K, 753–761.Manning, Christopher D. & Hinrich Schütze. 1999.Stiftungen der statistischen Natural Language Processing. Cambridge, MA: MIT Drücken. Grundlagen der Statistischen natürlichen Sprachverarbeitung Mihalcea, Rada. 2007. Wortsinn Verdeutlichung. Encyclopedia of Machine Learning.Springer-Verlag.Resnik, Philip und David Yarowsky. 2000. Distinguishing-Systeme und Unterscheidungssinne: Neue Bewertungsmethoden für Wortsinndisambiguation, Natural Language Engineering, 5(2):113-133.[2] Yarowsky, David. 2001. Wortsinn Verdeutlichung. Handbuch der Natural Language Processing, ed.by Dale et al., 629–654. New York: Marcel Dekker. Das lineare Modell der Innovation war ein frühes Modell, um die Beziehung von Wissenschaft und Technologie zu verstehen, die mit Grundlagenforschung beginnt, die in angewandte Forschung, Entwicklung und Diffusion fließt Sie stellt die wissenschaftliche Forschung als Grundlage für Innovation dar, die schließlich zum Wirtschaftswachstum führt. Das Modell wurde seit Jahrzehnten von vielen Wissenschaftlern kritisiert. Die Mehrheit der Kritiken wies darauf hin, dass ihre Rohheit und Einschränkungen bei der Erfassung der Quellen, des Prozesses und der Auswirkungen von Innovation bestehen.Es wurde jedoch auch argumentiert, dass das lineare Modell einfach eine Kreation von Akademikern war, die in der Wissenschaft stark diskutiert wurde, aber nie in der Praxis geglaubt wurde. Das Modell wird passender als Grundlage verwendet, um mehr nuancierte alternative Modelle zu verstehen. Aktuelle Innovationsmodelle ergeben sich aus Ansätzen wie Actor-Network Theory, Social Forming von Technologie und sozialem Lernen, bieten ein viel reicheres Bild von der Art, wie Innovation funktioniert. Aktuelle Ideen in Open Innovation und User Innovation ergeben sich aus diesen späteren Ideen. Im "Phase Gate Model" wird das Produkt- oder Dienstleistungskonzept frühzeitig eingefroren, um das Risiko zu minimieren. Durch das Unternehmen beinhaltet der Innovationsprozess eine Reihe von sequentiellen Phasen, die so angeordnet sind, dass die vorangegangene Phasenmuse vor dem Film in die nächste Phase gelöscht werden. Daher muss ein Projekt ein Tor mit der Erlaubnis des Torhüters passieren, bevor es in die nächste Folgephase geht. Die Kriterien für das Durchfahren jedes Tores werden vorher definiert. Der Gatekeeper prüft, ob die genannten Ziele für die vorangegangene Phase ordnungsgemäß erfüllt sind oder nicht und ob eine gewünschte Entwicklung in der vorhergehenden Phase stattgefunden hat oder nicht. Zwei Versionen des linearen Innovationsmodells werden oft vorgestellt: "Technologie Push" Modell "Marktzug" Modell Von den 1950er bis Mitte der 1960er Jahre wurde der industrielle Innovationsprozess im Allgemeinen als linearer Fortschritt von der wissenschaftlichen Entdeckung, durch technologische Entwicklung in Unternehmen bis zum Markt wahrgenommen. Die Stadien des Modells "Technologie Push" sind: Grundlagenwissenschaft→Design und Engineering→ Verarbeitendes Gewerbe→ Marketing→Aus den Mitte der 1960er- bis Anfang der 1970er-Jahre geht das Innovationsmodell der zweiten Generation hervor, das als "Marktzug" bezeichnet wird. Nach diesem einfachen sequentiellen Modell war der Markt die Quelle neuer Ideen für die Direktion von FuE, die eine reaktive Rolle in diesem Prozess hatte. Die Stadien des Modells "Marktzug " sind: Marktbedarf— Entwicklung — Herstellung— VertriebDie linearen Modelle der Innovation unterstützten zahlreiche Kritiken über die Linearität der Modelle. Diese Modelle ignorieren die vielen Feedbacks und Schleifen, die zwischen den verschiedenen Phasen des Prozesses auftreten. Mängel und Störungen, die auf verschiedenen Stufen auftreten, können zu einer Überarbeitung früherer Schritte führen, was zu einer Innovation führen kann. Eine Geschichte des linearen Modells der Innovation findet sich in Benoît Godin's The Linear Model of Innovation: Die historische Konstruktion eines analytischen Rahmens. Ein kritischer Blick auf den Ursprung der Terminologie und wie es eine zweifelhafte Geschichte haben kann, findet sich in David Edgertons „Das lineare Modell“ nicht: Reflexionen über die Geschichte und Historiographie von Wissenschaft und Forschung in der Industrie im 20. Jahrhundert. Siehe auch Innovation Technologischer Wandel Wissenschafts- und Technologiestudien Referenzen Rogers, Everett (2003). Diffusion von Innovationen, 5. Auflage, Kostenlose Presse.ISBN 0-7432-2209-1