In der Informatik ist die Partikelschwarm-Optimierung (PSO) eine rechnerische Methode, die ein Problem durch iterativ versuchen, eine Kandidatenlösung in Bezug auf ein bestimmtes Maß an Qualität zu verbessern. Es löst ein Problem, indem eine Population von Kandidatenlösungen, hier gegrabene Partikel, und diese Partikel im Suchraum nach einfacher mathematischer Formel über die Position und Geschwindigkeit des Partikels herum bewegt. Jede Partikelbewegung wird durch ihre lokale bekannteste Position beeinflusst, wird aber auch zu den bekanntesten Positionen im Suchraum geführt, die als bessere Positionen von anderen Partikeln aktualisiert werden. Dies wird erwartet, dass der Schwarm zu den besten Lösungen zu bewegen. PSO ist ursprünglich Kennedy, Eberhart und Shi zugeordnet und diente als stilisierte Darstellung der Bewegung von Organismen in einer Vogelschleuse oder Fischschule als erstes zur Simulation des sozialen Verhaltens. Der Algorithmus wurde vereinfacht und es wurde beobachtet, eine Optimierung durchzuführen. Das Buch von Kennedy und Eberhart beschreibt viele philosophische Aspekte der PSO und der swarm Intelligence. Eine umfangreiche Erhebung über PSO-Anwendungen wird von Poli erstellt. Kürzlich wurde eine umfassende Übersicht über theoretische und experimentelle Arbeiten am PSO von Bonyadi und Michalewicz veröffentlicht. PSO ist eine metaheuristische, da es wenige oder keine Annahmen über das zu optimierende Problem macht und sehr große Räume von Kandidatenlösungen suchen kann. Auch verwendet PSO nicht den Gradienten des zu optimierenden Problems, was bedeutet, dass PSO nicht erfordert, dass das Optimierungsproblem differenzierbar ist, wie es durch klassische Optimierungsverfahren wie Gradientenabstieg und Quasi-Newton-Verfahren erforderlich ist. Metaheuristiken wie PSO garantieren jedoch keine optimale Lösung. Algorithm Eine grundlegende Variante des PSO-Algorithmus funktioniert durch eine Population (sog. Swarm) von Kandidatenlösungen (sog. Partikel). Diese Partikel werden im Suchraum nach wenigen einfachen Formeln herumbewegt. Die Bewegungen der Partikel werden durch ihre eigene bekannteste Position im Suchraum sowie die bekannteste Position des gesamten Schwarms geführt. Wenn verbesserte Positionen entdeckt werden, werden diese dann kommen, um die Bewegungen des Schwarms zu führen. Der Prozess wird wiederholt und dadurch wird erhofft, aber nicht garantiert, dass schließlich eine befriedigende Lösung gefunden wird. formal lassen f: Rn → R die Kostenfunktion sein, die minimiert werden muss. Die Funktion übernimmt eine Kandidatenlösung als Argument in Form eines Vektors von realen Zahlen und erzeugt als Ausgabe eine reale Zahl, die den objektiven Funktionswert der gegebenen Kandidatenlösung angibt. Der Gradient von f ist nicht bekannt. Ziel ist es, eine Lösung a zu finden, für die f(a) ≤ f(b) für alle b im Suchraum, was bedeutet, dass a das globale Minimum ist. Lassen Sie S die Anzahl der Partikel im Schwarm sein, die jeweils eine Position xi ε Rn im Suchraum und eine Geschwindigkeit vi ε Rn.Let pi die bekannteste Position des Partikels i aufweisen und g die bekannteste Position des gesamten Schwarms sein lassen. Ein grundlegender PSO-Algorithmus ist dann: für jeden Partikeli = 1, ..., S do Initialize the Partikel's position with a uniform distribution random vector: xi ~ U(blo, bup) Initialize the Partikel's best bekannter position to its initialize: pi xi if f(pi) < f(g) then update the swarm's best met position: g ← piω Initialize the Partikel's speed: vip Aktualisieren Sie die Position des Partikels: xi ← xi + lr vi wenn f(xi) < f(pi)then Aktualisieren Sie die bekannteste Position des Partikels: pi ← xi wenn f(pi) < f(g) dann Aktualisieren Sie die bekannteste Position des Schwarms: g ← pi Die Werte blo und bup stellen die unteren und oberen Grenzen des Suchraums dar. Das Kündigungskriterium kann die Anzahl der durchgeführten Iterationen oder eine Lösung sein, bei der der ausreichende objektive Funktionswert gefunden wird. Die Parameter ω, φp und φg werden vom Praktizierenden ausgewählt und steuern das Verhalten und die Wirksamkeit der PSO-Methode (unten). lr stellt die Lernrate (0 ≤ lr ≤ 1,0 dar, das ist der Anteil, an dem die Geschwindigkeit die Bewegung des Partikels beeinflusst (wo lr = 0 bedeutet, dass die Geschwindigkeit das Partikel überhaupt nicht beeinflusst und lr = 1 bedeutet, dass die Geschwindigkeit das Partikel vollständig beeinflusst.) Auswahl der Parameter Die Wahl der PSO-Parameter kann einen großen Einfluss auf die Optimierungsleistung haben. Die Auswahl von PSO-Parametern, die eine gute Leistung liefern, war daher Gegenstand vieler Forschung. Die PSO-Parameter können auch mit einem anderen Overlaying Optimierer, einem als Meta-Optimierung bekannten Konzept oder sogar fein abgestimmt bei der Optimierung, z.B. mittels Fuzzy-Logik, abgestimmt werden. Auch für verschiedene Optimierungssszenarien wurden Parameter abgestimmt. Nachbarschaften und Topologien Die Topologie des Schwarms definiert die Teilmenge von Partikeln, mit denen jedes Partikel Informationen austauschen kann. Die Grundversion des Algorithmus verwendet die globale Topologie als swarm-Kommunikationsstruktur. Diese Topologie ermöglicht es allen Partikeln, mit allen anderen Partikeln zu kommunizieren, so dass der gesamte Schwarm die gleiche beste Position g von einem einzigen Partikel teilt. Dieser Ansatz könnte jedoch dazu führen, dass der Schwarm in ein lokales Minimum eingesperrt wird, so dass verschiedene Topologien verwendet wurden, um den Informationsfluss zwischen Partikeln zu steuern. So teilen beispielsweise in lokalen Topologien Partikel nur Informationen mit einer Teilmenge von Partikeln. Diese Teilmenge kann ein geometrisches sein – zum Beispiel "die m nächstgelegenen Partikel" – oder, häufiger, ein soziales, d.h. ein Satz von Partikeln, die nicht von jeder Distanz abhängig sind. In solchen Fällen soll die PSO-Variante am besten lokal sein (vs global best for the basic PSO). Eine häufig verwendete Schwarmtopologie ist der Ring, in dem jedes Teilchen nur zwei Nachbarn hat, aber es gibt viele andere. Die Topologie ist nicht unbedingt statisch. Da die Topologie mit der Vielfalt der Kommunikation der Teilchen verbunden ist, wurden einige Anstrengungen unternommen, um adaptive Topologien zu schaffen (SPSO, APSO, stochastischen Stern, TRIBES, Cyber Swarm und C-PSO.) Innere Arbeiten Es gibt mehrere Denkschulen, warum und wie der PSO-Algorithmus Optimierung durchführen kann. Ein gemeinsamer Gedanke unter den Forschern ist, dass das Schwarmverhalten zwischen explorativem Verhalten, d.h. der Suche nach einer breiteren Region des Suchraums und ausbeuterischem Verhalten, d.h. einem lokal orientierten Such, variiert, um einem (möglicherweise lokalen) Optimum näher zu kommen. Diese Schule des Denkens ist seit Beginn der PSO vorherrschend. Diese Denkschule sieht vor, dass der PSO-Algorithmus und seine Parameter so gewählt werden müssen, dass die Erkundung und Ausbeutung angemessen ausgewogen werden, um eine vorzeitige Konvergenz zu einem lokalen Optimum zu vermeiden, aber dennoch eine gute Konvergenz zum Optimum sicherzustellen. Dieser Glaube ist der Vorläufer vieler PSO-Varianten, siehe unten. Eine andere Denkschule ist, dass das Verhalten eines PSO-Schwarms in Bezug auf die tatsächliche Optimierungsleistung, insbesondere für höherdimensionale Such- und Optimierungsprobleme, die diskontinuierlich, laut und zeitveränderlich sein können, nicht gut verstanden wird. Diese Denkschule versucht lediglich, PSO-Algorithmen und Parameter zu finden, die eine gute Leistung verursachen, unabhängig davon, wie das Schwarmverhalten in Bezug auf z.B. Exploration und Ausbeutung interpretiert werden kann. Solche Studien haben zur Vereinfachung des PSO-Algorithmus geführt, siehe unten. Konvergence In Bezug auf PSO bezieht sich das Wort Konvergenz typischerweise auf zwei verschiedene Definitionen: Konvergenz der Abfolge von Lösungen (aka, Stabilitätsanalyse, Konvergierung), in denen alle Partikel zu einem Punkt im Suchraum konvergiert haben, der möglicherweise das Optimum sein kann oder nicht, Konvergenz zu einem lokalen Optimum, wo alle persönlichen Besten p oder alternativ die bekannteste Position g des Schwarms ein lokales Optimum des Problems nähert, unabhängig davon, wie sich der Schwarm verhält. Konvergenz der Sequenz von Lösungen wurde auf PSO untersucht. Diese Analysen haben zu Leitlinien für die Auswahl von PSO-Parametern geführt, die angenommen werden, um Konvergenz zu einem Punkt zu verursachen und Divergenz der Schwarmpartikel zu verhindern (die Partikel bewegen sich nicht ungebunden und konvergieren sich irgendwo). Allerdings wurden die Analysen von Pedersen kritisiert, da sie annehmen, dass der Schwarm nur ein Teilchen hat, dass er keine stochastischen Größen verwendet und dass die Anziehungspunkte, d.h. die bekannteste Position p des Partikels und die bekannteste Position g des Schwarms während des Optimierungsprozesses konstant bleiben. Es wurde jedoch gezeigt, dass diese Vereinfachungen die durch diese Untersuchungen festgestellten Grenzen für Parameter, in denen der Schwarm konvergent ist, nicht beeinflussen. In den letzten Jahren wurden erhebliche Anstrengungen unternommen, um die bei der Stabilitätsanalyse von PSO genutzte Modellierungsannahme zu schwächen, wobei das jüngste verallgemeinerte Ergebnis auf zahlreiche PSO-Varianten Anwendung findet und genutzt wurde, was gezeigt wurde, dass es sich um die minimal notwendigen Modellierungsannahmen handelt. Die Konvergenz zu einem lokalen Optimum wurde für PSO in und analysiert. Es hat sich gezeigt, dass PSO eine gewisse Änderung braucht, um ein lokales Optimum zu finden. Dies bedeutet, dass die Ermittlung der Konvergenzfähigkeiten verschiedener PSO-Algorithmen und Parameter immer noch von empirischen Ergebnissen abhängt. Ein Versuch, dieses Problem anzugehen, ist die Entwicklung einer "orthogonalen Lernstrategie" für eine verbesserte Nutzung der bereits in der Beziehung zwischen p und g vorhandenen Informationen, um eine führende konvergierende Exemplar zu bilden und mit jeder PSO-Topologie wirksam zu sein. Ziel ist es, die Leistung von PSO insgesamt zu verbessern, einschließlich schnellerer globaler Konvergenz, höherer Lösungsqualität und stärkerer Robustheit. Solche Studien liefern jedoch keine theoretischen Beweise, um ihre Behauptungen tatsächlich zu beweisen. Anpassungsmechanismen Ohne die Notwendigkeit eines Kompromisses zwischen Konvergenz (Exploitation) und Divergenz (Exploration) kann ein adaptiver Mechanismus eingeführt werden. Adaptive Partikel-Swarm-Optimierung (APSO) bietet bessere Sucheffizienz als Standard-PSO. APSO kann globale Suche über den gesamten Suchraum mit einer höheren Konvergenzgeschwindigkeit durchführen. Es ermöglicht eine automatische Steuerung des Trägheitsgewichts, Beschleunigungskoeffizienten und anderer algorithmischer Parameter zur Laufzeit, wodurch gleichzeitig die Suchwirkung und Effizienz verbessert wird. Auch kann APSO auf das weltweit beste Teilchen wirken, um aus der wahrscheinlichen lokalen Opima zu springen. APSO wird jedoch neue Algorithmus-Parameter einführen, es führt dennoch keine zusätzliche Design- oder Implementierungskomplexität ein. Varianten Es sind zahlreiche Varianten sogar eines Basis-PSO-Algorithmus möglich. Beispielsweise gibt es verschiedene Möglichkeiten, die Partikel und Geschwindigkeiten zu initialisieren (z.B. mit Null Geschwindigkeiten statt zu starten), wie man die Geschwindigkeit dämpft, nur aktualisieren Pi und g nach dem gesamten Schwarm aktualisiert, etc. Einige dieser Entscheidungen und deren mögliche Leistungswirkung wurden in der Literatur diskutiert. Eine Reihe von Standard-Implementierungen wurden von führenden Forschern erstellt, "für den Einsatz sowohl als Basis für die Leistungsprüfung von Verbesserungen in der Technik, sowie PSO für die breitere Optimierungs-Community. Ein bekannter, streng definierter Standardalgorithmus bietet einen wertvollen Vergleich, der im gesamten Forschungsbereich genutzt werden kann, um neue Fortschritte besser zu testen." Die neueste ist Standard PSO 2011 (SPSO-2011.) Hybridisierung Auch neue und anspruchsvollere PSO-Varianten werden kontinuierlich eingeführt, um die Optimierungsleistung zu verbessern. Es gibt bestimmte Trends in dieser Forschung; man soll eine Hybrid-Optimierungsmethode unter Verwendung von PSO in Verbindung mit anderen Optimatoren, z.B. kombiniertem PSO mit biogeografischer Optimierung, und die Einarbeitung einer effektiven Lernmethode machen. Eine weitere Forschungstendenz besteht darin, die vorzeitige Konvergenz (d.h. Optimierungsstagnation) zu lindern, z.B. durch Umkehrung oder Störung der Bewegung der PSO-Partikel, ein weiterer Ansatz zur Bewältigung der vorzeitigen Konvergenz ist der Einsatz mehrerer Swarms (Multi-Swarm-Optimierung). Der mehrstufige Ansatz kann auch zur Realisierung einer multiobjektiven Optimierung eingesetzt werden. Schließlich gibt es Entwicklungen bei der Anpassung der Verhaltensparameter von PSO bei der Optimierung. Vereinfachungen Eine andere Schule des Denkens ist, dass PSO so viel wie möglich vereinfacht werden sollte, ohne seine Leistung zu beeinträchtigen; ein allgemeines Konzept oft als Occam Rasierer bezeichnet. Die Vereinfachung von PSO wurde ursprünglich von Kennedy vorgeschlagen und wurde umfangreicher untersucht, wo es erschien, dass die Optimierungsleistung verbessert wurde, und die Parameter waren einfacher abzustimmen und sie führten konsequenter über verschiedene Optimierungsprobleme. Ein weiteres Argument für die Vereinfachung von PSO ist, dass Metaheuristiken ihre Wirksamkeit nur durch rechnerische Experimente auf einer endlichen Anzahl von Optimierungsproblemen empirisch demonstrieren können. Dies bedeutet, dass eine Metaheuristik wie PSO nicht korrekt nachgewiesen werden kann und dies das Risiko erhöht, Fehler bei der Beschreibung und Umsetzung zu machen. Ein gutes Beispiel hierfür war eine vielversprechende Variante eines genetischen Algorithmus (eine andere populäre Metaheuristik), aber es wurde später als defekt empfunden, da es in seiner Optimierungssuche auf ähnliche Werte für verschiedene Dimensionen im Suchraum stark belastet war, was das Optimum der betrachteten Benchmark-Probleme war. Diese Vorspannung war aufgrund eines Programmierfehlers und wurde nun behoben. Die Initialisierung von Geschwindigkeiten kann zusätzliche Eingänge erfordern. Die Bare Bones PSO-Variante wurde 2003 von James Kennedy vorgeschlagen und braucht überhaupt keine Geschwindigkeit zu verwenden. Eine weitere einfachere Variante ist die beschleunigte Partikelschwarm-Optimierung (APSO), die auch keine Geschwindigkeit verwenden muss und die Konvergenz in vielen Anwendungen beschleunigen kann. Ein einfacher Democode von APSO ist verfügbar. Mehrobjektive Optimierung PSO wurde auch auf multiobjektive Probleme angewendet, bei denen der objektive Funktionsvergleich pareto Dominanz bei der Bewegung der PSO-Partikel und nicht dominierte Lösungen berücksichtigt, um die Paretofront anzunähern. Binär, diskret und kombinatorisch Da die oben angegebenen PSO-Gleichungen auf realen Zahlen arbeiten, ist eine allgemein verwendete Methode zur Lösung diskreter Probleme, den diskreten Suchraum auf eine kontinuierliche Domäne abzubilden, einen klassischen PSO anzuwenden und dann das Ergebnis abzuleiten. Eine solche Kartierung kann sehr einfach sein (z.B. nur mit abgerundeten Werten) oder anspruchsvoller. Es kann jedoch darauf hingewiesen werden, dass die Bewegungsgleichungen von Bedienern Gebrauch machen, die vier Aktionen ausführen: die Differenz zweier Positionen berechnen. Es ergibt sich eine Geschwindigkeit (genauer eine Verschiebung), die eine Geschwindigkeit durch einen Zahlenkoeffizienten multipliziert, indem zwei Geschwindigkeiten addiert werden, die eine Geschwindigkeit auf eine Position anwenden, und eine Geschwindigkeit wird durch n reale Zahlen dargestellt, und diese Operatoren sind einfach -, *, + und wieder .+ Aber alle diese mathematischen Objekte können ganz anders definiert werden, um binäre Probleme (oder allgemein diskrete) oder sogar kombinatorische zu bewältigen. Ein Ansatz besteht darin, die auf Sets basierenden Operatoren neu zu definieren. Siehe auch Künstliche Bienen-Kolonie-Algorithmus Bienen algorithm Derivative-free-Optimierung Mehrkriegsoptimierung Partikelfilter Swarm Intelligence Fish School Search Dispersive Fliegen Optimierung Referenzen Externe Links Particle Swarm Central ist ein Projektarchiv für Informationen über PSO. Mehrere Quellcodes sind frei verfügbar. Ein kurzes Video von Partikelschwarmen, das drei Benchmark-Funktionen optimiert. Simulation der PSO-Konvergenz in einem zweidimensionalen Raum (Matlab). Anwendungen von PSO.Liu, Yang (2009). "Automatische Kalibrierung eines Regenfall-Auslauf-Modells mit einem schnellen und elitären multi-objektiven Partikel-Schwarm-Algorithmus". Expert Systems with Applications.36 (5): 9533–9538. doi:10.1016/j.eswa.2008.10.086.Links zu PSO-Quellcode