Cloud Computing ist die On-Demand-Verfügbarkeit von Computersystemressourcen, insbesondere Datenspeicher (Cloud Storage) und Rechenleistung, ohne direktes aktives Management durch den Benutzer. Große Wolken haben häufig Funktionen über mehrere Standorte verteilt, wobei jeder Standort ein Rechenzentrum ist. Cloud Computing basiert auf dem Teilen von Ressourcen, um Kohärenz und Wirtschaften von Skalen zu erreichen. Cloud-Anbieter verwenden in der Regel ein Pay-as-you-go-Modell, das bei der Reduzierung der Investitionskosten helfen kann, aber auch zu unerwarteten Betriebskosten für unbewusste Nutzer führen kann. Wertvorstellung Befürwortet von öffentlichen und hybriden Clouds stellen fest, dass Cloud Computing Unternehmen ermöglicht, die Kosten für IT-Infrastruktur zu vermeiden oder zu minimieren. Die Befürworter behaupten auch, dass Cloud Computing es Unternehmen ermöglicht, ihre Anwendungen schneller und schneller zu laufen, mit verbesserter Verwaltbarkeit und weniger Wartung, und dass es IT-Teams ermöglicht, schneller Ressourcen einzustellen, um schwankende und unvorhersehbare Nachfrage zu erfüllen, bietet die Burst Computing-Fähigkeit: hohe Rechenleistung bei bestimmten Zeiten der Spitzennachfrage. Geschichte Referenzen zum Ausdruck "Cloud Computing" erschienen bereits 1996, mit der ersten bekannten Erwähnung in einem Compaq internen Dokument. Das Cloud-Symbol diente dazu, bereits 1977 Netzwerke von Rechengeräten im ursprünglichen ARPANET und das CSNET bis 1981 – ebenso wie Vorgänger im Internet – darzustellen. Die Wortwolke wurde als Metapher für das Internet verwendet und eine standardisierte cloudähnliche Form wurde verwendet, um ein Netzwerk auf Telefonie-Schema zu bezeichnen. Mit dieser Vereinfachung ist die Implikation, dass die Besonderheiten, wie die Endpunkte eines Netzwerks miteinander verbunden sind, für das Verständnis des Diagramms nicht relevant sind. Der Begriff Cloud wurde verwendet, um Plattformen für verteiltes Computing bereits 1993 zu verweisen, als Apple Spin-off General Magic und AT&T es bei der Beschreibung ihrer (gepaarten) Telescript- und PersonaLink-Technologien verwendet. In Wireds April 1994 Feature "Bill and Andy's Excellent Adventure II" kommentierte Andy Hertzfeld auf Telescript, General Magics verteilte Programmiersprache: "Die Schönheit von Telescript ... ist, dass wir jetzt, anstatt nur ein Gerät zu programmieren, die gesamte Cloud da draußen haben, wo ein einzelnes Programm kann gehen und zu vielen verschiedenen Informationsquellen reisen und eine Art virtueller Service erstellen. Das hatte noch niemand gedacht. Das Beispiel, das Jim White [der Designer von Telescript, X.400 und ASN.1] jetzt verwendet, ist ein datenübergreifender Dienst, in dem ein Software-Agent in den Blumenladen geht und Blumen bestellt und dann in den Ticketshop geht und die Tickets für die Show erhält, und alles wird beiden Parteien mitgeteilt." Frühgeschichte Während der 1960er Jahre wurden die ersten Begriffe der Zeitverteilung über RJE (Remote Job Entry) populär; diese Terminologie war meist mit großen Anbietern wie IBM und DEC verbunden. Vollzeit-Sharing-Lösungen wurden in den frühen 1970er Jahren auf solchen Plattformen wie Multics (auf GE Hardware,) Cambridge CTSS und den frühesten UNIX-Ports (auf DEC-Hardware) angeboten. Dennoch war das "Data Center"-Modell, in dem die Nutzer den Betreibern Jobs zur Ausführung auf IBMs Mainframes vorgelegt haben, überwältigend. In den 1990er-Jahren begannen Telekommunikationsunternehmen, die zuvor vor allem dedizierte Punkt-zu-Punkt-Datenkreise angeboten hatten, virtuelle private Netzwerkdienste (VPN) mit vergleichbarer Servicequalität anzubieten, aber zu geringeren Kosten. Durch den Austausch von Traffic, wie sie sah fit für die Balance-Server-Nutzung, könnten sie insgesamt Netzwerkbandbreite effektiver verwenden. Sie begannen, das Cloud-Symbol zu verwenden, um den Abgrenzungspunkt zwischen dem, was der Anbieter verantwortlich war, und dem zu bezeichnen, für das die Nutzer verantwortlich waren. Cloud Computing erweiterte diese Grenze, um alle Server sowie die Netzwerkinfrastruktur abzudecken. Als Computer diffuser wurden, erforschten Wissenschaftler und Technologen Wege, um durch die Zeitteilung mehr Nutzern große Rechenleistung zur Verfügung zu stellen. Sie experimentierten mit Algorithmen, um die Infrastruktur, Plattform und Anwendungen zu optimieren, um CPUs zu priorisieren und die Effizienz für Endbenutzer zu erhöhen. Die Verwendung der Cloud-Metaphore für virtualisierte Dienste stammt mindestens von General Magic im Jahr 1994, wo es verwendet wurde, um das Universum von Orten zu beschreiben, die mobile Agenten in der Telescript-Umgebung gehen könnten. Wie von Andy Hertzfeld beschrieben: "Die Schönheit von Telescript", sagt Andy, "ist, dass jetzt, anstatt nur ein Gerät zu programmieren, wir haben jetzt die gesamte Cloud da draußen, wo ein einzelnes Programm kann gehen und zu vielen verschiedenen Informationsquellen reisen und eine Art virtueller Service erstellen." Die Verwendung der Cloud-Metaphore wird an General Magic-Kommunikationsmitarbeiter David Hoffman, basierend auf langjähriger Nutzung in Netzwerken und Telekommunikation, gutgeschrieben. Neben der Nutzung durch General Magic selbst wurde sie auch bei der Förderung der assoziierten PersonaLink Services von AT&T verwendet. 2000sIm Juli 2002 hat Amazon Tochtergesellschaft Amazon Web Services gegründet, mit dem Ziel, "Entwickler zu erschließen, innovative und unternehmerische Anwendungen auf eigene Faust aufzubauen. "Im März 2006 stellte Amazon seinen Simple Storage Service (S3,) vor, gefolgt von Elastic Compute Cloud (EC2) im August desselben Jahres. Diese Produkte haben die Nutzung der Server-Virtualisierung für die Bereitstellung von IaaS auf einer kostengünstigeren und On-Demand-Preisbasis vorangetrieben. Im April 2008 veröffentlichte Google die Beta-Version von Google App Engine. Die App Engine war ein PaaS (eines der ersten seiner Art), der vollständig gepflegte Infrastruktur und eine Bereitstellungsplattform für Nutzer zur Erstellung von Webanwendungen mit gemeinsamen Sprachen/Technologien wie Python, Node.js und PHP zur Verfügung stellte. Ziel war es, die Notwendigkeit einiger administrativer Aufgaben zu beseitigen, die für ein IaaS-Modell typisch sind, und gleichzeitig eine Plattform zu schaffen, in der Anwender solche Anwendungen problemlos einsetzen und sie auffordern können. Anfang 2008 wurde die NASA's Nebula, die im RESERVOIR-Projekt der Europäischen Kommission erweitert wurde, die erste Open-Source-Software für den Einsatz von privaten und hybriden Wolken und für den Verband von Wolken. Bis Mitte 2008 sah Gartner eine Gelegenheit für Cloud Computing "die Beziehung zwischen den Verbrauchern von IT-Diensten zu gestalten, diejenigen, die IT-Dienste nutzen und die sie verkaufen" und beobachtete, dass "Organisationen von unternehmenseigenen Hardware- und Software-Assets zu per-use service-basierten Modellen wechseln", so dass die "projizierte Verschiebung zu Computing ... zu einem dramatischen Wachstum in IT-Produkten in einigen Bereichen und signifikante Reduktionen in anderen Bereichen führen wird. "Im Jahr 2008 begann die US National Science Foundation mit dem Cluster Exploratory Programm, um akademische Forschung mit Google-IBM Cluster-Technologie zu finanzieren, um massive Datenmengen zu analysieren. Im Jahr 2009 kündigte die Regierung von Frankreich Projekt Andromède an, eine "sovereign cloud" oder nationale Cloud Computing zu schaffen, mit der Regierung 285 Millionen Euro auszugeben. Die Initiative scheiterte schlecht und Cloudwatt wurde am 1. Februar 2020 geschlossen. 2010sIm Februar 2010 veröffentlichte Microsoft Microsoft Microsoft Azure, die im Oktober 2008 bekannt gegeben wurde. Im Juli 2010 haben Rackspace Hosting und die NASA gemeinsam eine Open-Source-Cloud-Software-Initiative namens OpenStack gestartet. Das OpenStack-Projekt soll Organisationen helfen, die Cloud-Computing-Dienste auf Standard-Hardware anbieten. Der frühe Code kam von der NASA Nebula-Plattform sowie von der Rackspace Cloud Files-Plattform. Als Open-Source-Angebot und zusammen mit anderen Open-Source-Lösungen wie CloudStack, Ganeti und OpenNebula hat sie die Aufmerksamkeit mehrerer Schlüsselgemeinden auf sich gezogen. Mehrere Studien zielen darauf ab, diese Open Source-Angebote basierend auf einer Reihe von Kriterien zu vergleichen. Am 1. März 2011 kündigte IBM den IBM SmartCloud-Framework an, um Smarter Planet zu unterstützen. Unter den verschiedenen Komponenten der Smarter Computing-Stiftung ist Cloud Computing ein wichtiger Bestandteil. Am 7. Juni 2012 kündigte Oracle die Oracle Cloud an. Dieses Cloud-Angebot ist das erste, das Benutzern Zugang zu einem integrierten Set von IT-Lösungen bietet, einschließlich der Applications (SaaS), Platform (PaaS) und Infrastructure (IaaS) Schichten. Im Mai 2012, Google Compute Engine wurde in der Vorschau veröffentlicht, bevor in General Availability im Dezember 2013 ausgerollt. Im Jahr 2019 war Linux das am häufigsten verwendete Betriebssystem auf Microsoft Azure. Im Dezember 2019 kündigte Amazon AWS Outposts an, der ein voll verwalteter Service ist, der die AWS-Infrastruktur, AWS-Dienste, APIs und Tools auf nahezu alle Kundendatenzentren, Co-Location-Raum oder On-Premises-Einrichtungen für ein wirklich konsequentes Hybriderlebnis erweitert. Das Ziel der Cloud Computing ist es, den Nutzern von all diesen Technologien profitieren zu können, ohne dass mit jedem dieser Technologien tiefes Wissen oder Fachwissen benötigt wird. Die Cloud zielt darauf ab, Kosten zu senken und hilft den Nutzern, sich auf ihr Kerngeschäft zu konzentrieren, anstatt durch IT-Hürden behindert zu werden. Die Haupttechnologie für Cloud Computing ist die Virtualisierung. Die Virtualisierungssoftware trennt ein physikalisches Rechengerät in ein oder mehrere virtuelle Geräte, von denen jeder einfach verwendet und verwaltet werden kann, um Rechenaufgaben auszuführen. Mit der Virtualisierung auf Betriebssystemebene, die im Wesentlichen ein skalierbares System von mehreren unabhängigen Rechengeräten erstellt, können idle-Computing-Ressourcen zugewiesen und effizienter eingesetzt werden. Die Virtualisierung bietet die nötige Flexibilität, um den IT-Betrieb zu beschleunigen und die Kosten durch die Erhöhung der Infrastrukturauslastung zu senken. Autonomic Computing automatisiert den Prozess, durch den der Benutzer Ressourcen auf Anfrage bereitstellen kann. Durch die Minimierung der Nutzerbeteiligung beschleunigt die Automatisierung den Prozess, reduziert die Arbeitskosten und reduziert die Möglichkeit menschlicher Fehler. Cloud Computing verwendet Konzepte aus dem Dienstprogramm Computing, um Metriken für die verwendeten Dienste bereitzustellen. Cloud Computing versucht, QoS (Servicequalität) und Zuverlässigkeitsprobleme anderer Grid Computing-Modelle anzusprechen. Cloud Computing teilt Eigenschaften mit: Client-Server-Modell— Client-Server-Computing bezieht sich auf jede verteilte Anwendung, die zwischen Dienstleistern (Server) und Service-Anfragenden (Clients) unterscheidet. Computerbüro— Ein Servicebüro, das Computerdienste anbietet, insbesondere von den 1960er bis 1980er Jahren. Grid Computing — Eine Form des verteilten und parallelen Computings, wobei ein "Super- und virtueller Computer" aus einem Cluster von vernetzten, lose gekoppelten Computern besteht, die zusammenwirken, um sehr große Aufgaben zu erfüllen. Fog Computing— Distributed Computing Paradigm, das Daten, Rechen-, Speicher- und Anwendungsdienste näher an den Client- oder Nahbenutzer-Kantengeräten, wie z.B. Netzwerkroutern, zur Verfügung stellt. Darüber hinaus behandelt Nebel Computing Daten auf Netzwerkebene, auf intelligenten Geräten und auf der Endbenutzer-Clientseite (z.B. mobile Geräte) anstatt Daten an einen Remote-Standort zur Verarbeitung zu senden. Mainframe-Computer-Powerful-Computer, die hauptsächlich von großen Organisationen für kritische Anwendungen verwendet werden, typischerweise Massendatenverarbeitung wie zensus; Industrie- und Verbraucherstatistik; Polizei- und Geheimdienst; Unternehmensressourcenplanung; und Finanztransaktionsverarbeitung. Utility Computing— Die "Verpackung von Rechenressourcen, wie Berechnung und Speicherung, als ein dosierter Dienst ähnlich einem traditionellen öffentlichen Dienst wie Strom. "Peer-to-peer- Eine verteilte Architektur ohne zentrale Koordination. Teilnehmer sind sowohl Lieferanten als auch Verbraucher von Ressourcen (im Gegensatz zum herkömmlichen Client-Server-Modell). Green Computing — Studie und Praxis der umweltverträglichen Berechnung oder IT. Cloud-Sandbox— Eine lebendige, isolierte Computerumgebung, in der ein Programm, Code oder Datei laufen kann, ohne die Anwendung zu beeinflussen, in der es läuft. Eigenschaften Cloud Computing zeigt die folgenden Schlüsselmerkmale: Agilität für Organisationen kann verbessert werden, da Cloud Computing die Flexibilität der Nutzer mit der Neuvorbereitung, dem Hinzufügen oder dem Ausbau von technologischen Infrastrukturressourcen erhöhen kann. Kostensenkungen werden von Cloud-Anbietern beansprucht. Ein Public-Cloud-Liefermodell wandelt Kapitalausgaben (z.B. Kaufserver) auf Betriebsausgaben um. Dies senkt die Zugangshindernisse, da die Infrastruktur typischerweise von einem Dritten bereitgestellt wird und nicht für einmalige oder selten intensive Rechenaufgaben erworben werden muss. Die Pricing auf der Basis von Dienstrechnern ist feinkörnig, mit nutzungsbasierten Abrechnungsoptionen. Außerdem sind weniger interne IT-Fähigkeiten für die Umsetzung von Projekten erforderlich, die Cloud Computing nutzen. Das hochmoderne Repository des e-FISCAL-Projekts enthält mehrere Artikel, die Kostenaspekte genauer untersuchen, wobei die meisten davon schließen, dass Kosteneinsparungen von der Art der unterstützten Aktivitäten und der Art der im eigenen Haus verfügbaren Infrastruktur abhängen. Geräte- und Ortsunabhängigkeit ermöglichen es Benutzern, Systeme mit einem Webbrowser unabhängig von ihrem Standort oder dem von ihnen verwendeten Gerät (z.B. PC, Mobiltelefon) zuzugreifen. Da die Infrastruktur außer Betrieb ist (typischerweise von einem Drittanbieter bereitgestellt) und über das Internet aufgerufen wird, können die Nutzer von überall her mit ihr verbinden. Die Wartung der Cloud-Umgebung ist einfacher, da die Daten auf einem externen Server gehostet werden, der von einem Anbieter gewartet wird, ohne dass in die Rechenzentrumshardware investiert werden muss. Die IT-Wartung von Cloud Computing wird durch das IT-Wartungsteam des Cloud-Providers verwaltet und aktualisiert, das die Cloud-Computing-Kosten im Vergleich zu den On-Premises-Datenzentren reduziert. Multitenancy ermöglicht den Austausch von Ressourcen und Kosten über einen großen Pool von Nutzern und ermöglicht so: Zentralisierung der Infrastruktur an Orten mit geringeren Kosten (wie Immobilien, Strom usw.) Spitzenlast-Kapazitätserhöhungen (Benutzer brauchen nicht Ingenieur und zahlen für die Ressourcen und Ausrüstung, um ihre höchstmöglichen Lastniveaus zu erfüllen) Nutzung und Effizienzverbesserungen für Systeme, die oft nur 10–20% genutzt werden. Die Leistung wird von IT-Experten des Diensteanbieters überwacht und mit Webdiensten als Systemschnittstelle konsistente und lose gekoppelte Architekturen aufgebaut. Die Produktivität kann erhöht werden, wenn mehrere Benutzer gleichzeitig an den gleichen Daten arbeiten können, anstatt darauf zu warten, dass sie gespeichert und eMail. Die Zeit kann gespeichert werden, da die Informationen nicht neu eingespeichert werden müssen, wenn Felder übereinstimmen, noch müssen Benutzer Software-Upgrades auf ihren Computer installieren. Die Verfügbarkeit verbessert sich durch die Nutzung mehrerer redundanter Standorte, die ein gut gestaltetes Cloud Computing für die Unternehmenskontinuität und Katastrophenrückgewinnung geeignet macht. Skalierbarkeit und Elastizität durch dynamische (on-demand) Bereitstellung von Ressourcen auf einer feinkörnigen, Self-Service-Basis in naher Echtzeit (Anmerkung, die VM Startzeit variiert nach VM-Typ, Standort, OS und Cloud-Anbieter), ohne dass Benutzer für Spitzenlasten zu entwickeln. Dies gibt die Möglichkeit, nach oben zu skaliert werden, wenn der Nutzungsbedarf steigt oder nach unten, wenn Ressourcen nicht verwendet werden. Der zeiteffiziente Nutzen der Cloud-Skalierbarkeit bedeutet auch schnellere Zeit zum Markt, mehr Geschäftsflexibilität und Anpassungsfähigkeit, da das Hinzufügen neuer Ressourcen nicht so viel Zeit braucht wie früher. Zu den aufstrebenden Ansätzen für die Verwaltung von Elastizität gehören der Einsatz von maschinellen Lerntechniken, um effiziente Elastizitätsmodelle vorzuschlagen. Sicherheit kann durch Zentralisierung von Daten, erhöhte sicherheitsgerichtete Ressourcen usw. verbessern, aber Bedenken können über den Verlust der Kontrolle über bestimmte sensible Daten und die fehlende Sicherheit für gespeicherte Kernel bestehen. Sicherheit ist oft so gut oder besser als andere traditionelle Systeme, zum Teil, weil Dienstleister in der Lage sind, Ressourcen zur Lösung von Sicherheitsproblemen zu widmen, die viele Kunden nicht leisten können, anzugehen oder die sie nicht an die technischen Fähigkeiten zu wenden. Die Komplexität der Sicherheit wird jedoch deutlich erhöht, wenn Daten über einen größeren Bereich oder über eine größere Anzahl von Geräten verteilt werden, sowie in Multi-Tenant-Systemen, die von unabhängigen Nutzern geteilt werden. Darüber hinaus kann der Zugriff auf Sicherheitsauditprotokolle schwierig oder unmöglich sein. Private Cloud-Installationen werden zum Teil durch den Wunsch der Nutzer motiviert, die Kontrolle über die Infrastruktur zu behalten und die Kontrolle der Informationssicherheit zu vermeiden. Das National Institute of Standards and Technology's Definition von Cloud Computing identifiziert "fünf wesentliche Eigenschaften": Selbstbedienung. Ein Verbraucher kann einseitig Rechenfunktionen wie Serverzeit und Netzwerkspeicher bereitstellen, wenn dies automatisch erforderlich ist, ohne dass eine menschliche Interaktion mit jedem Dienstleister erforderlich ist. Fernnetzzugang. Fähigkeiten sind über das Netzwerk verfügbar und über Standardmechanismen zugänglich, die die Nutzung durch heterogene dünne oder dicke Client-Plattformen fördern (z.B. Mobiltelefone, Tablets, Laptops und Workstations). Ressourcenpooling. Die Computing-Ressourcen des Anbieters werden gepoolt, um mehrere Verbraucher mit einem Multi-Tenant-Modell zu bedienen, wobei unterschiedliche physikalische und virtuelle Ressourcen dynamisch zugewiesen und entsprechend der Verbrauchernachfrage neu zugewiesen werden. Schnelle Elastizität. Fähigkeiten können elastisch vorgesehen und freigegeben werden, in einigen Fällen automatisch, schnell nach außen und nach innen mit der Nachfrage kompensieren. Für den Verbraucher erscheinen die zur Bereitstellung verfügbaren Fähigkeiten oft unbegrenzt und können jederzeit in beliebiger Menge verwendet werden. Gemessener Dienst. Cloud-Systeme steuern und optimieren die Ressourcennutzung automatisch, indem sie eine Dosierfähigkeit auf einer für die Art des Dienstes geeigneten Abstraktion (z.B. Speicherung, Verarbeitung, Bandbreite und aktive Benutzerkonten) nutzen. Ressourcennutzung kann überwacht, kontrolliert und gemeldet werden und bietet Transparenz für den Anbieter und den Verbraucher des genutzten Dienstes. Servicemodelle Obwohl serviceorientierte Architektur für "Everything as a service" (mit den Akronymen EaaS oder XaaS oder einfach aas) Cloud-Computing-Anbieter bieten ihre Dienste nach verschiedenen Modellen, von denen die drei Standardmodelle pro NIST Infrastruktur als Service (IaaS,) Plattform als Service (PaaS) und Software als Service (SaaS). Diese Modelle bieten zunehmende Abstraktion; sie werden daher oft als Schichten in einem Stack dargestellt: Infrastruktur,- Plattform- und Software-as-a-Service, aber diese müssen nicht verwandt sein. Zum Beispiel kann man SaaS auf physikalischen Maschinen (Alte Metall,) implementieren, ohne zugrunde liegende PaaS- oder IaaS-Schichten zu verwenden, und umgekehrt kann man ein Programm auf IaaS laufen und direkt darauf zugreifen, ohne es als SaaS umzuwickeln. Infrastruktur als Dienst (IaaS) "Infrastruktur als Dienst" (IaaS) bezieht sich auf Online-Dienste, die hochrangige APIs zur Verfügung stellen, die verwendet werden, um verschiedene Low-Level-Details der zugrunde liegenden Netzwerkinfrastruktur wie physische Rechenressourcen, Standort, Datenpartitionierung, Skalierung, Sicherheit, Backup, etc. zu abstrakt. Ein Hypervisor führt die virtuellen Maschinen als Gäste. Pools von Hypervisoren innerhalb des Cloud-Betriebssystems können große Anzahl von virtuellen Maschinen und die Möglichkeit, Dienstleistungen nach den unterschiedlichen Anforderungen der Kunden nach oben und unten zu skalieren unterstützen. Linux-Container laufen in isolierten Partitionen eines einzelnen Linux-Kernels, der direkt auf der physischen Hardware läuft. Linux-Cgroups und Namespaces sind die zugrunde liegenden Linux-Kernel-Technologien, die verwendet werden, um die Behälter zu isolieren, zu sichern und zu verwalten. Die Containerisierung bietet eine höhere Leistung als die Virtualisierung, da es keinen Hypervisor-Überkopf gibt. IaaS-Wolken bieten oft zusätzliche Ressourcen wie eine Virtual-Maschine-Festplatten-Bildbibliothek, Rohblockspeicherung, Datei- oder Objektspeicherung, Firewalls, Load Balancer, IP-Adressen, virtuelle lokale Netzwerke (VLANs) und Softwarepakete. Die Definition von Cloud Computing von NIST beschreibt IaaS als "wo der Verbraucher willkürliche Software bereitstellen und ausführen kann, die Betriebssysteme und Anwendungen umfassen kann. Der Verbraucher verwaltet oder steuert die zugrunde liegende Cloud-Infrastruktur nicht, sondern hat die Kontrolle über Betriebssysteme, Speicher und eingesetzte Anwendungen; und möglicherweise begrenzte Kontrolle über ausgewählte Netzwerkkomponenten (z.B. Host Firewalls). "IaaaS-Cloud-Anbieter liefern diese Ressourcen auf Anfrage von ihren großen Anlagenpools in Rechenzentren installiert. Für eine breit angelegte Vernetzung können Kunden entweder die Internet- oder Carrier Clouds (dedizierte virtuelle private Netzwerke) nutzen. Um ihre Anwendungen zu implementieren, installieren Cloud-Benutzer Betriebssystem-Bilder und ihre Anwendungssoftware auf der Cloud-Infrastruktur. In diesem Modell pflegt der Cloud-Benutzer die Betriebssysteme und die Anwendungssoftware aufrecht.Cloud-Anbieter berechnen in der Regel IaaaS-Dienste auf einer Dienstprogramm-Computing-Basis: Kosten spiegelt die Menge der Ressourcen zugewiesen und verbraucht. Plattform als Service (PaaS)Die Definition von Cloud Computing von NIST definiert Plattform als Service als: Die Fähigkeit, die dem Verbraucher zur Verfügung gestellt wird, ist es, auf die Cloud-Infrastruktur verbrauchergeschaffene oder erworbene Anwendungen zu implementieren, die mithilfe von Programmiersprachen, Bibliotheken, Diensten und Tools erstellt werden, die vom Anbieter unterstützt werden. Der Verbraucher verwaltet oder steuert die zugrunde liegende Cloud-Infrastruktur einschließlich Netzwerk, Server, Betriebssysteme oder Speicher, hat aber die Kontrolle über die bereitgestellten Anwendungen und eventuell Konfigurationseinstellungen für die Anwendungs-Hosting-Umgebung. PaaS-Anbieter bieten eine Entwicklungsumgebung für Anwendungsentwickler. Der Anbieter entwickelt typischerweise Toolkit und Standards für Entwicklung und Kanäle für Verteilung und Zahlung. In den PaaS-Modellen liefern Cloud-Anbieter eine Rechenplattform, beispielsweise Betriebssystem, programmiersprachige Ausführungsumgebung, Datenbank und Webserver. Anwendungsentwickler entwickeln und betreiben ihre Software auf einer Cloud-Plattform, anstatt die zugrunde liegenden Hardware- und Softwareschichten direkt zu kaufen und zu verwalten. Mit einigen PaaS skaliert der zugrunde liegende Computer- und Speicherressourcen-Skala automatisch an die Anforderung der Applikation, so dass der Cloud-Benutzer keine Ressourcen manuell zuweisen muss. Einige Integrations- und Datenmanagementanbieter nutzen auch spezialisierte Anwendungen von PaaS als Liefermodelle für Daten. Beispiele sind iPaaS (Integration Platform as a Service) und dPaaS (Data Platform as a Service). I PaaS ermöglicht es Kunden, Integrationsströme zu entwickeln, auszuführen und zu steuern. Unter dem iPaaS-Integrationsmodell steuern Kunden die Entwicklung und den Einsatz von Integrationen, ohne Hardware oder Middleware zu installieren oder zu verwalten. dgl. PaaS liefert Integration – und Datenmanagement – Produkte als voll verwalteter Service. Unter dem dPaaS-Modell verwaltet der PaaS-Anbieter, nicht der Kunde, die Entwicklung und Durchführung von Programmen durch den Aufbau von Datenanwendungen für den Kunden. dgl. PaaS-Nutzer Zugriff auf Daten über Daten-Visualisierungstools. Software als Dienst (SaaS) Die Definition von Cloud Computing von NIST definiert Software als Dienst als: Die Fähigkeit, die dem Verbraucher zur Verfügung gestellt wird, ist die Verwendung der Anwendungen des Anbieters, die auf einer Cloud-Infrastruktur laufen. Die Anwendungen sind von verschiedenen Client-Geräten entweder über eine dünne Client-Schnittstelle, wie einen Webbrowser (z.B. webbasierte E-Mail) oder eine Programm-Schnittstelle zugänglich. Der Verbraucher verwaltet oder steuert die zugrunde liegende Cloud-Infrastruktur, einschließlich Netzwerk, Server, Betriebssysteme, Storage oder sogar individuelle Anwendungsmöglichkeiten, mit Ausnahme begrenzter benutzerspezifischer Anwendungskonfigurationseinstellungen nicht. Im Software-Modell (SaaS) erhalten Anwender Zugriff auf Anwendungssoftware und Datenbanken. Cloud-Anbieter verwalten die Infrastruktur und Plattformen, die die Anwendungen ausführen. SaaS wird manchmal als "on-Demand-Software" bezeichnet und wird in der Regel auf einer Pay-per-Use-Basis oder mit einer Abonnement-Gebühren. Im SaaS-Modell installieren und betreiben Cloud-Provider Applikationssoftware in der Cloud und Cloud-Benutzer auf die Software von Cloud-Clients. Cloud-Benutzer verwalten nicht die Cloud-Infrastruktur und -Plattform, auf der die Anwendung läuft. Dies eliminiert die Notwendigkeit, die Anwendung auf den eigenen Computern des Cloud-Benutzers zu installieren und auszuführen, was die Wartung und Unterstützung vereinfacht. Cloud-Anwendungen unterscheiden sich von anderen Anwendungen in ihrer Skalierbarkeit – was durch das Klonen von Aufgaben auf mehrere virtuelle Maschinen zur Laufzeit erreicht werden kann, um den wechselnden Arbeitsbedarf zu decken. Load Balancer verteilen die Arbeit über das Set von virtuellen Maschinen. Dieser Prozess ist für den Cloud-Benutzer transparent, der nur einen einzigen Access-Point sieht. Um eine Vielzahl von Cloud-Nutzern zu unterbringen, können Cloud-Anwendungen vielfältig sein, so dass jede Maschine mehr als eine Cloud-User-Organisation bedienen kann. Das Preismodell für SaaS-Anwendungen ist in der Regel eine monatliche oder jährliche Pauschalgebühr pro Nutzer, so dass die Preise skalierbar und einstellbar werden, wenn die Nutzer zu einem beliebigen Zeitpunkt hinzugefügt oder entfernt werden. Es kann auch kostenlos sein. Die Vertreter behaupten, dass SaaS einem Unternehmen das Potenzial bietet, die IT-Betriebskosten durch Outsourcing von Hardware und Softwarewartung und Unterstützung für den Cloud-Anbieter zu reduzieren. Dies ermöglicht es dem Unternehmen, IT-Betriebskosten von Hardware/Software-Ausgaben und von Personalaufwendungen weg zu lokalisieren, um andere Ziele zu erreichen. Darüber hinaus können mit zentral gehosteten Anwendungen Updates veröffentlicht werden, ohne dass Benutzer neue Software installieren müssen. Ein Nachteil von SaaS ist die Speicherung der Daten der Nutzer auf dem Server des Cloud Providers. Dadurch konnte ein unbefugter Zugriff auf die Daten erfolgen. Beispiele für Anwendungen, die als SaaS angeboten werden, sind Spiele und Produktivitätssoftware wie Google Docs und Word Online. SaaS-Anwendungen können mit Cloud-Speicher oder File-Hosting-Diensten integriert werden, was der Fall ist, dass Google Docs mit Google Drive und Word Online mit Onedrive integriert werden. Mobile Backend als Service (MBaaS) Im mobilen Backend als Service (m)-Modell, auch als Backend als Service (BaaaS,) Web-App und mobile App-Entwickler bekannt, können ihre Anwendungen mit Cloud-Speicher- und Cloud-Computing-Diensten mit Applikations-Programmierschnittstellen (APIs) verbinden, die ihren Anwendungen und benutzerdefinierten Software-Entwicklungskits (SDKs) ausgesetzt sind. Zu den Diensten gehören Benutzerverwaltung, Push-Benachrichtigungen, Integration mit Social Networking-Diensten und mehr. Dies ist ein relativ jüngstes Modell in der Cloud Computing, mit den meisten BaaS Startups aus dem Jahr 2011 oder später, aber Trends zeigen, dass diese Dienstleistungen erhebliche Mainstream Traktion mit Unternehmenskunden gewinnen. Serverloses Computing oder Function-as-a-Service(FaaS) Serverless Computing ist ein Cloud Computing Code Ausführungsmodell, bei dem der Cloud-Provider die Start- und Stopp-Virtual-Maschinen als notwendig verwaltet, um Anfragen zu bedienen, und Anfragen werden durch ein abstraktes Maß der Ressourcen, die benötigt werden, um die Anfrage zu befriedigen, anstatt per virtuellem Rechner pro Stunde abgeglichen. Trotz des Namens, es beinhaltet nicht tatsächlich laufenden Code ohne Server. Serverless Computing ist so benannt, weil das Unternehmen oder die Person, die das System besitzt, keine Server oder virtuelle Maschinen für den Backend-Code kaufen, mieten oder bereitstellen muss, um weiterzulaufen. Funktion als Dienst (FaaS) ist ein Service-gehostetes Remote-Prozeß, der serverloses Computing nutzt, um die Bereitstellung einzelner Funktionen in der Cloud zu ermöglichen, die auf Ereignisse reagieren. FaaS wird von einigen betrachtet, um unter dem Dach des serverlosen Computing zu kommen, während einige andere die Bedingungen austauschbar verwenden. Private Cloud Private Cloud Private Cloud ist Cloud-Infrastruktur, die ausschließlich für eine einzelne Organisation betrieben wird, ob intern oder von einem Dritten verwaltet und intern oder extern gehostet wird. Ein privates Cloud-Projekt zu betreiben erfordert ein erhebliches Engagement für die Virtualisierung der Geschäftsumgebung und erfordert die Organisation, Entscheidungen über bestehende Ressourcen neu zu bewerten. Es kann das Geschäft verbessern, aber jeder Schritt im Projekt erhöht Sicherheitsfragen, die behandelt werden müssen, um ernsthafte Schwachstellen zu verhindern. Selbst laufende Rechenzentren sind in der Regel kapitalintensiv. Sie haben einen erheblichen physischen Fußabdruck, der Raum-, Hardware- und Umweltkontrollen erfordert. Diese Vermögenswerte müssen periodisch erneuert werden, was zu zusätzlichen Kapitalaufwendungen führt. Sie haben Kritik an sich gezogen, weil die Nutzer "noch müssen sie kaufen, bauen und verwalten" und damit nicht von weniger Hand-on-Management profitieren, im Wesentlichen ["lacking] das ökonomische Modell, das Cloud Computing so ein faszinierendes Konzept macht." Public Cloud Cloud Services gelten als öffentlich, wenn sie über das öffentliche Internet bereitgestellt werden, und sie können als kostenpflichtiges Abonnement oder kostenlos angeboten werden. Architektonisch gibt es nur wenige Unterschiede zwischen öffentlichen und privaten Dienstleistungen, aber Sicherheitsbedenken erhöhen sich erheblich, wenn Dienstleistungen (Anwendungen, Lagerung und andere Ressourcen) von mehreren Kunden geteilt werden. Die meisten Public-Cloud-Anbieter bieten Direktverbindungsdienste, die es Kunden ermöglichen, ihre Altdatenzentren sicher an ihre Cloud-Resident-Anwendungen zu binden. Mehrere Faktoren wie die Funktionalität der Lösungen, Kosten, Integration und organisatorische Aspekte sowie Sicherheit und Sicherheit beeinflussen die Entscheidung der Unternehmen und Organisationen, eine Public Cloud oder On-Premises-Lösung zu wählen. Hybrid Cloud Hybrid Cloud Hybrid Cloud ist eine Zusammensetzung einer Public Cloud und einer privaten Umgebung, wie eine Private Cloud oder On-Premises-Ressourcen, die unterschiedliche Einheiten bleiben, aber zusammengebunden sind, bietet die Vorteile mehrerer Bereitstellungsmodelle. Hybrid Cloud kann auch die Möglichkeit bedeuten, Collokation, Managed und/oder dedizierte Services mit Cloud-Ressourcen zu verbinden. Gartner definiert einen hybriden Cloud-Service als Cloud-Computing-Service, der aus einer Kombination von privaten, öffentlichen und gemeinschaftlichen Cloud-Services besteht, von verschiedenen Dienstleistern. Ein hybrider Cloud-Service überschneidet die Isolations- und Providergrenzen, so dass er nicht einfach in eine Kategorie des privaten, öffentlichen oder gemeinschaftlichen Cloud-Services eingesetzt werden kann. Es ermöglicht es, entweder die Kapazität oder die Fähigkeit eines Cloud-Services, durch Aggregation, Integration oder Anpassung mit einem anderen Cloud-Service zu erweitern. Es gibt verschiedene Anwendungsfälle für die Hybrid-Cloud-Zusammensetzung. Beispielsweise kann eine Organisation sensible Client-Daten im Haus auf einer privaten Cloud-Anwendung speichern, aber diese Anwendung auf eine Business Intelligence-Anwendung, die auf einer Public Cloud als Software-Service zur Verfügung gestellt. Dieses Beispiel der Hybrid Cloud erweitert die Fähigkeiten des Unternehmens, einen bestimmten Business-Service durch die Hinzufügung extern verfügbarer Public Cloud-Dienste zu liefern. Die Hybrid-Cloud-Adoption hängt von einer Reihe von Faktoren wie Datensicherheit und Compliance-Anforderungen, der erforderlichen Kontrolle über Daten und den Anwendungen, die eine Organisation nutzt, ab. Ein weiteres Beispiel für die Hybrid Cloud ist, dass IT-Organisationen öffentliche Cloud-Computing-Ressourcen nutzen, um temporäre Kapazitätsanforderungen zu erfüllen, die von der privaten Cloud nicht erfüllt werden können. Diese Fähigkeit ermöglicht es Hybrid-Wolken, Cloud Bursting für Skalierung über Wolken einzusetzen. Cloud Bursting ist ein Anwendungs-Bereitstellungsmodell, bei dem eine Anwendung in einer privaten Cloud oder einem Rechenzentrum läuft und bei steigender Nachfrage nach Rechenkapazität in eine Public Cloud platzt. Ein Hauptvorteil des Cloud Bursting und eines Hybrid Cloud-Modells ist, dass eine Organisation nur dann für zusätzliche Rechenressourcen zahlt, wenn sie benötigt werden. Cloud Bursting ermöglicht es Rechenzentren, eine hauseigene IT-Infrastruktur zu schaffen, die durchschnittliche Workloads unterstützt und Cloud-Ressourcen aus öffentlichen oder privaten Clouds während Spikes in den Prozessanforderungen nutzt. Das spezialisierte Modell der Hybrid Cloud, die auf heterogener Hardware aufgebaut ist, heißt "Cross-platform Hybrid Cloud". Eine plattformübergreifende Hybrid-Cloud wird in der Regel von verschiedenen CPU-Architekturen betrieben, beispielsweise x86-64 und ARM, darunter. Benutzer können Anwendungen ohne Kenntnisse der Hardware-Diversity der Cloud transparent einsetzen und skalieren. Diese Art von Cloud entsteht aus dem Anstieg von ARM-basierten System-on-Chip für Server-Class-Computing. Hybride Cloud-Infrastruktur dient im Wesentlichen dazu, Einschränkungen zu beseitigen, die den Multi-Access-Relais-Eigenschaften der privaten Cloud-Netzwerkierung inhärent sind. Die Vorteile umfassen eine verbesserte Laufzeitflexibilität und eine adaptive Speicherverarbeitung, die einzigartig an virtualisierte Schnittstellenmodelle ist. Andere Cloud-Infrastruktur der Gemeinschaft teilt die Infrastruktur zwischen mehreren Organisationen aus einer bestimmten Gemeinschaft mit gemeinsamen Anliegen (Sicherheit, Compliance, Gerichtsstand usw.), ob intern oder von einem Dritten verwaltet und intern oder extern gehostet. Die Kosten werden über weniger Benutzer verteilt als eine Public Cloud (aber mehr als eine Private Cloud), so dass nur einige der Kosteneinsparungspotenziale von Cloud Computing realisiert werden. Eine Cloud-Computing-Plattform kann aus einem verteilten Maschinensatz an unterschiedlichen Standorten zusammengesetzt werden, der mit einem einzigen Netzwerk- oder Hubdienst verbunden ist. Es ist möglich, zwischen zwei Arten verteilter Wolken zu unterscheiden: Public-Ressource Computing und Freiwillige Cloud. Public-Resource Computing— Diese Art der verteilten Cloud ergibt sich aus einer expansiven Definition von Cloud Computing, da sie eher an verteiltes Computing als Cloud Computing interessiert sind. Dennoch wird es als eine Unterklasse von Cloud Computing betrachtet. Volunteer Cloud— Volunteer Cloud Computing ist als Schnittstelle von Public-Ressource Computing und Cloud Computing gekennzeichnet, wo eine Cloud Computing-Infrastruktur mit ehrenamtlichen Ressourcen aufgebaut wird. Aus dieser Art von Infrastruktur ergeben sich viele Herausforderungen, weil die Flüchtigkeit der Ressourcen, die für den Bau genutzt werden, und die dynamische Umgebung, in der sie arbeitet, ausmacht. Es kann auch Peer-to-Peer-Wolken oder Ad-hoc-Wolken genannt werden. Ein interessanter Aufwand in dieser Richtung ist Cloud@Home, es zielt darauf ab, eine Cloud-Computing-Infrastruktur mit ehrenamtlichen Ressourcen zu implementieren, die ein Business-Modell zur Anreizung von Beiträgen durch finanzielle Restitution bieten. Multi Cloud Multi Cloud Multi Cloud ist die Verwendung mehrerer Cloud Computing-Dienste in einer einzigen heterogenen Architektur, um die Abhängigkeit von einzelnen Anbietern zu reduzieren, Flexibilität durch Wahl zu erhöhen, gegen Katastrophen zu mildern, etc. Es unterscheidet sich von der Hybrid Cloud, indem es sich auf mehrere Cloud-Dienste bezieht, anstatt mehrere Bereitstellungsmodi (öffentlich, privat, vermächtnis.) Poly Cloud Poly Cloud bezieht sich auf die Verwendung mehrerer öffentlicher Clouds, um bestimmte Dienstleistungen zu nutzen, die jeder Anbieter anbietet. Es unterscheidet sich von Multi Cloud, indem es nicht entwickelt ist, um Flexibilität zu erhöhen oder gegen Fehler zu mildern, sondern verwendet wird, um eine Organisation mehr zu ermöglichen, die mit einem einzigen Anbieter getan werden könnte. Big Data Cloud Die Probleme der Übertragung großer Datenmengen in die Cloud sowie der Datensicherheit, wenn die Daten in der Cloud zunächst die Cloud für große Daten behinderten, aber jetzt, da viele Daten in der Cloud stammen und mit dem Aufkommen von Bare-Metall-Servern die Cloud zu einer Lösung für Anwendungsfälle wie Business Analytics und Geospatialanalyse geworden ist. Die HPC-Cloud HPC-Cloud bezieht sich auf den Einsatz von Cloud Computing-Services und Infrastrukturen zur Ausführung von High-Performance Computing-Anwendungen (HPC). Diese Anwendungen verbrauchen erhebliche Mengen an Rechenleistung und Speicher und werden traditionell auf Clustern von Computern ausgeführt. 2016 bot eine Handvoll Unternehmen, darunter R-HPC, Amazon Web Services, Univa, Silicon Graphics International, Sabalcore, Gomput und Penguin Computing eine leistungsstarke Computing-Cloud. Die Penguin On Demand (POD) Cloud war eine der ersten nicht-virtualisierten Remote HPC-Dienste, die auf einer Pay-as-you-go-Basis angeboten werden. Penguin Computing startete 2016 seine HPC-Cloud als Alternative zu Amazons EC2 Elastic Compute Cloud, die virtualisierte Computing-Knoten verwendet. Die Architektur Cloud-Architektur, die Systemarchitektur der Softwaresysteme, die an der Lieferung von Cloud Computing beteiligt sind, beinhaltet typischerweise mehrere Cloud-Komponenten, die über einen losen Koppelmechanismus wie eine Messaging-Warte miteinander kommunizieren. Elastische Bestimmung impliziert die Intelligenz bei der Verwendung einer engen oder lockeren Kopplung, wie sie auf Mechanismen wie diese und andere angewendet wird. Cloud Engineering Cloud Engineering ist die Anwendung von Engineering-Disziplinen von Cloud Computing. Es bringt einen systematischen Ansatz zu den hochrangigen Anliegen der Kommerzialisierung, Normung und Governance bei der Konzeption, Entwicklung, Betrieb und Aufrechterhaltung von Cloud Computing-Systemen. Es ist eine multidisziplinäre Methode, die Beiträge aus verschiedenen Bereichen wie Systeme, Software, Web, Performance, Informationstechnologie Engineering, Sicherheit, Plattform, Risiko und Qualitätstechnik umfasst. Sicherheit und Datenschutz Cloud Computing stellt Datenschutzbedenken dar, weil der Dienstleister jederzeit auf die Daten zugreifen kann, die sich in der Cloud befinden. Es könnte versehentlich oder bewusst Informationen ändern oder löschen. Viele Cloud-Anbieter können Informationen mit Dritten teilen, wenn dies für Zwecke des Rechts und der Bestellung erforderlich ist. Das ist in ihren Datenschutzrichtlinien erlaubt, denen die Nutzer zustimmen müssen, bevor sie Cloud-Dienste nutzen. Zu den Lösungen für die Privatsphäre gehören die Richtlinien und Rechtsvorschriften sowie die Entscheidungen der Endbenutzer, wie Daten gespeichert werden. Benutzer können Daten verschlüsseln, die in der Cloud verarbeitet oder gespeichert werden, um unberechtigten Zugriff zu verhindern. Identitätsmanagementsysteme können auch praktische Lösungen für Datenschutzbelange im Cloud Computing bereitstellen. Diese Systeme unterscheiden zwischen autorisierten und nicht autorisierten Benutzern und bestimmen die Datenmenge, die jedem Unternehmen zugänglich ist. Die Systeme arbeiten, indem sie Identitäten erstellen und beschreiben, Aktivitäten aufzeichnen und ungenutzte Identitäten loswerden. Laut der Cloud Security Alliance sind die drei Top-Bedrohungen in der Cloud Insecure Interfaces und APIs, Data Loss & Leakage und Hardware Failure – die 29,% 25% bzw. 10% aller Cloud Security Outages ausmachten. Gemeinsam bilden diese Form gemeinsamer Technologieverwundbarkeiten. In einer Cloud-Provider-Plattform, die von verschiedenen Nutzern geteilt wird, besteht die Möglichkeit, dass Informationen, die zu verschiedenen Kunden gehören, auf demselben Datenserver liegen. Darüber hinaus, Eugene Schultz, Chief Technology Officer bei Emagined Security, sagte, Hacker verbringen erhebliche Zeit und Mühe auf der Suche nach Wegen, um die Wolke zu durchdringen. " Es gibt einige echte Achilles Fersen in der Cloud-Infrastruktur, die große Löcher für die bösen Jungs zu machen, in". Da Daten von Hunderten oder Tausenden von Unternehmen auf großen Cloud-Servern gespeichert werden können, können Hacker theoretisch die Kontrolle von riesigen Speichern von Informationen durch einen einzigen Angriff gewinnen – ein Prozess, den er Hyperjacking nennt". Einige Beispiele hierfür sind die Sicherheitslücke Dropbox und die Leckage von iCloud 2014. Dropbox war im Oktober 2014 verletzt worden, mit mehr als 7 Millionen seiner Benutzer-Passwörter von Hackern gestohlen wurden, um Geldwert von ihm von Bitcoins (BTC). Durch diese Passwörter sind sie in der Lage, private Daten zu lesen sowie diese Daten durch Suchmaschinen (die Information öffentlich zu machen) indexiert werden. Es besteht das Problem des rechtlichen Eigentums an den Daten (Wenn ein Benutzer einige Daten in der Cloud speichert, kann der Cloud-Anbieter davon profitieren?) Viele Nutzungsbedingungen stehen in der Frage des Eigentums still. Die physische Kontrolle der Computerausrüstung (Privatwolke) ist sicherer als die Ausrüstung vor Ort und unter der Kontrolle einer anderen Person (öffentliche Cloud). Dies bietet großen Anreiz für öffentliche Cloud-Computing-Dienstleister, Gebäude zu priorisieren und ein starkes Management sicherer Dienste zu erhalten. Einige kleine Unternehmen, die kein Know-how in der IT-Sicherheit haben, könnten feststellen, dass es sicherer für sie ist, eine Public Cloud zu verwenden. Es besteht das Risiko, dass Endbenutzer die Probleme nicht verstehen, die bei der Anmeldung zu einem Cloud-Service (Personen lesen manchmal nicht die vielen Seiten der Nutzungsbedingungen Vereinbarung, und klicken Sie einfach auf Akzeptieren ohne Lesen). Dies ist jetzt wichtig, dass Cloud Computing populär wird und für einige Dienste benötigt wird, um zu arbeiten, zum Beispiel für einen intelligenten persönlichen Assistenten (Apples Siri oder Google Now). Grundsätzlich wird Private Cloud mit höherer Kontrolle für den Eigentümer als sicherer angesehen, die Public Cloud wird jedoch als flexibler betrachtet und benötigt weniger Zeit- und Geldinvestitionen vom Nutzer. Einschränkungen und Nachteile Laut Bruce Schneier, "Der Nachteil ist, dass Sie begrenzte Anpassungsmöglichkeiten haben. Cloud Computing ist wegen der Wirtschaftlichkeit der Skala billiger und – wie jede ausgelagerte Aufgabe – neigen Sie dazu, zu bekommen, was Sie wollen. Ein Restaurant mit einem begrenzten Menü ist billiger als ein persönlicher Koch, der alles kochen kann, was Sie wollen. Weniger Optionen zu einem viel günstigeren Preis: es ist eine Funktion, kein Fehler. " Er schlägt auch vor, dass "der Cloud-Anbieter möglicherweise nicht Ihren rechtlichen Bedürfnissen entspricht" und dass Unternehmen die Vorteile von Cloud Computing gegen die Risiken wägen müssen.Im Cloud Computing ist die Steuerung der Back-End-Infrastruktur nur auf den Cloud-Anbieter beschränkt. Cloud-Anbieter entscheiden oft über die Management-Richtlinien, die das, was die Cloud-Anwender mit ihrer Bereitstellung tun können, moderiert. Cloud-Benutzer sind auch auf die Steuerung und Verwaltung ihrer Anwendungen, Daten und Dienste beschränkt. Dazu gehören Datenkappen, die von dem Cloud-Anbieter auf Cloud-Nutzer gestellt werden, der für jeden Kunden eine gewisse Bandbreite zugewiesen und häufig unter anderen Cloud-Nutzern geteilt wird. Datenschutz und Vertraulichkeit sind große Bedenken in einigen Aktivitäten. So könnten beispielsweise schworene Übersetzer, die unter den Vorgaben eines NDA arbeiten, Probleme in Bezug auf sensible Daten haben, die nicht verschlüsselt sind. Durch die Nutzung des Internets können vertrauliche Informationen wie Mitarbeiterdaten und Nutzerdaten leicht an Drittanbieterorganisationen und Personen in Cloud Computing zur Verfügung stehen. Cloud Computing ist für viele Unternehmen von Vorteil; es senkt Kosten und erlaubt ihnen, sich auf Kompetenz anstatt auf Fragen der IT und der Infrastruktur zu konzentrieren. Dennoch hat sich Cloud Computing als einige Einschränkungen und Nachteile erwiesen, insbesondere für kleinere Geschäftsvorgänge, insbesondere in Bezug auf Sicherheit und Ausfallzeiten. Technische Ausfälle sind unvermeidlich und treten manchmal auf, wenn Cloud-Service-Anbieter (CSPs) überwältigt im Prozess des Servierens ihrer Kunden werden. Dies kann zu einer vorübergehenden Geschäftsunterbrechung führen. Da die Systeme dieser Technologie auf das Internet angewiesen sind, kann eine Person während eines Ausfalls nicht auf ihre Anwendungen, Server oder Daten aus der Cloud zugreifen. Entwicklung Cloud Computing ist immer noch Gegenstand der Forschung. Ein treibender Faktor bei der Entwicklung von Cloud Computing war die Haupttechnologieoffizier, die das Risiko von internen Ausfällen minimieren und die Komplexität von Gehäusenetzwerken und Computer-Hardware im eigenen Haus verringern möchten. Sie wollen auch Informationen an Arbeitnehmer, die sich in unterschiedlichen Bereichen in der Nähe und in Echtzeit befinden, weitergeben, um Teams nahtlos arbeiten zu können, egal wo sie sich befinden. Wichtige Cloud-Technologie-Unternehmen investieren Milliarden von Dollar pro Jahr in Cloud Research and Development. Zum Beispiel hat Microsoft 2011 90 Prozent seines R&D-Budgets von 9,6 Milliarden US-Dollar an seine Cloud gebunden. Die Forschung der Investmentbank Centaur Partners Ende 2015 prognostizierte, dass der Umsatz von SaaS von $13,5 Milliarden im Jahr 2011 auf $32,8 Milliarden im Jahr 2016 wachsen würde. Seit der globalen Pandemie von 2020 wird gesagt, dass die Cloud-Technologie aufgrund der Datensicherheit und der Flexibilität der Arbeitsoptionen für alle Mitarbeiter, insbesondere Fernarbeiter, in der Popularität voranschritt. So wuchs Zoom allein 2020 über 160%. Im Jahr 2021 wird die Software als Service (SaaS) nach wie vor das größte Marktsegment für IT-Ausgaben im Endverbraucher-Cloud-Bereich sein – es wird erwartet, dass etwa 16 Prozent auf $117,8 Milliarden wachsen – Application Infrastructure Services (PaaS) wird mit einer höheren 26,6 Prozent Rate auf etwa $55,5 Milliarden wachsen, so Gartner. Digitale Forensik in der Cloud Die Frage der Durchführung von Untersuchungen, bei denen die Cloud-Speichergeräte nicht physisch zugegriffen werden können, hat eine Reihe von Änderungen an der Art und Weise erzeugt, wie sich digitale Beweise befinden und gesammelt werden. Neue Prozessmodelle wurden entwickelt, um die Sammlung zu formalisieren. In einigen Szenarien können bestehende digitale Forensik-Tools verwendet werden, um Cloud-Speicher als vernetzte Laufwerke zugreifen (obwohl dies ein langsamer Prozess ist, der eine große Menge Internet-Verkehr erzeugt). Ein alternativer Ansatz ist die Bereitstellung eines Tools, das in der Cloud selbst verarbeitet. Für Organisationen, die Office 365 mit einem E5-Abonnement verwenden, gibt es die Möglichkeit, Microsofts integrierte E-Decovery-Ressourcen zu verwenden, obwohl diese nicht alle Funktionalitäten bieten, die typischerweise für einen forensischen Prozess erforderlich sind. Siehe auch Referenzen Weiter lesen Millard, Christopher (2013). Cloud Computing Law.Oxford University Press.ISBN 978-0-19-967168-7.Singh, Jatinder; Powles, Julia; Pasquier, Thomas; Bacon, Jean (Juli 2015). " Datenfluss-Management und Compliance in Cloud Computing".IEEE Cloud Computing.2 (4): 24–32.doi:10.1109/MCC.2015.69.S2CID 9812531.Armbrust, Michael; Stoica, Ion; Zaharia, Matei; Fox, Armando; Griffith, Rean; Joseph, Anthony D.; Katz, Randy; Konwinski, Andy; Lee, Gunhi; "Ein Blick auf Cloud Computing". Kommunikation der ACM.53 (4): 50.doi:10.1145/1721654.1721672.S2CID 1673644.Hu, Tung-Hui (2015). Eine Vorgeschichte der Cloud. MIT Press. ISBN 978-0-262-02951-3.Mell, P. (2011, September 31). Die NIST Definition von Cloud Computing. Retrieved November 1, 2015, von National Institute of Standards and Technology Website Externe Links Medien im Zusammenhang mit Cloud Computing bei Wikimedia Commons