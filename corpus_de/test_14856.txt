Übergeordnetes Lernen (SL) ist die maschinelle Lernaufgabe, eine Funktion zu lernen, die einen Eingang zu einem Ausgang auf Basis von Beispiel-Eingangspaaren abbildet. Sie verweist auf eine Funktion aus markierten Trainingsdaten, die aus einer Reihe von Trainingsbeispielen bestehen. Bei überwachtem Lernen handelt es sich jeweils um ein Paar, bestehend aus einem Eingabeobjekt (typischerweise einem Vektor) und einem gewünschten Ausgabewert (auch als Aufsichtssignal bezeichnet). Ein überwachter Lernalgorithmus analysiert die Trainingsdaten und erzeugt eine abgeleitete Funktion, die zur Abbildung neuer Beispiele verwendet werden kann. Ein optimales Szenario ermöglicht es dem Algorithmus, die Klassenetiketten für ungesehene Fälle korrekt zu bestimmen. Dies erfordert, dass der Lernalgorithmus aus den Trainingsdaten auf vernünftige Weise zu uneigenen Situationen verallgemeinert wird (siehe induktive Vorspannung). Diese statistische Qualität eines Algorithmus wird durch den sogenannten Verallgemeinerungsfehler gemessen. Die parallele Aufgabe in der Human- und Tierpsychologie wird oft als Konzeptlernen bezeichnet. Schritte Um ein bestimmtes Problem des überwachten Lernens zu lösen, muss man die folgenden Schritte ausführen: Bestimmen Sie die Art der Ausbildungsbeispiele. Bevor der Benutzer etwas anderes tut, sollte er entscheiden, welche Art von Daten als Trainingsset verwendet werden sollen. Bei der handschriftlichen Analyse kann es sich beispielsweise um einen einzigen handschriftlichen Charakter, um ein ganzes handschriftliches Wort, um einen ganzen Satz von Handschrift oder vielleicht um einen vollen Absatz von Handschrift handeln. - Ein Trainingsset. Das Trainingsset muss repräsentativ für die reale Nutzung der Funktion sein. So wird ein Satz von Eingabeobjekten gesammelt und entsprechende Ausgänge werden auch entweder von menschlichen Experten oder von Messungen erfasst. Bestimmen Sie die Eingabemerkmaldarstellung der gelernten Funktion. Die Genauigkeit der gelernten Funktion hängt stark davon ab, wie das Eingabeobjekt dargestellt ist. Typischerweise wird das Eingabeobjekt in einen Merkmalsvektor transformiert, der eine Anzahl von Merkmalen enthält, die beschreibend sind. Die Anzahl der Merkmale sollte nicht zu groß sein, wegen des Fluches der Dimensionalität, sondern sollte genügend Informationen enthalten, um die Leistung genau vorherzusagen. Bestimmen Sie die Struktur der Lernfunktion und den entsprechenden Lernalgorithmus. Beispielsweise kann der Ingenieur wählen, um Unterstützungs-Vektor-Maschinen oder Entscheidungsbäume zu verwenden. Komplettieren Sie das Design. Führen Sie den Lernalgorithmus auf dem gesammelten Trainingsset aus. Einige beaufsichtigte Lernalgorithmen erfordern, dass der Benutzer bestimmte Steuerparameter ermittelt. Diese Parameter können durch Optimierung der Leistung an einer Teilmenge (genannte Validierungsset) des Trainingssatzes oder durch Quervalidierung eingestellt werden. Bewerten Sie die Genauigkeit der gelernten Funktion. Nach der Parameteranpassung und dem Lernen sollte die Leistung der resultierenden Funktion auf einem vom Trainingssatz getrennten Testsatz gemessen werden. Algorithm-Auswahl Eine breite Palette von beaufsichtigten Lernalgorithmen sind verfügbar, jeweils mit seinen Stärken und Schwächen. Es gibt keinen einzigen Lernalgorithmus, der am besten auf allen beaufsichtigten Lernproblemen funktioniert (siehe das Gratis-Lunch Theorem). Es gibt vier wichtige Themen, die im beaufsichtigten Lernen zu berücksichtigen sind: Bias-Variante Ein erstes Problem ist der Kompromiss zwischen Vorurteil und Varianz. Stellen Sie sich vor, dass wir verschiedene, aber ebenso gute Trainingsdatensätze zur Verfügung haben. Ein Lernalgorithmus wird für einen bestimmten Eingang x \{displaystyle x} vorgespannt, wenn, wenn, wenn auf jedem dieser Datensätze trainiert, es bei der Vorhersage der richtigen Ausgabe für x \{displaystyle x} systematisch falsch ist.Ein Lernalgorithmus hat eine hohe Varianz für einen bestimmten Eingang x \{displaystyle x}, wenn er verschiedene Ausgabewerte bei der Ausbildung auf verschiedenen Trainingseinheiten vorhersagt. Der Vorhersagefehler eines gelernten Klassifikators ist mit der Summe der Vorspannung und der Varianz des Lernalgorithmus verbunden. In der Regel gibt es einen Abschlag zwischen Vorspannung und Varianz. Ein Lernalgorithmus mit geringer Vorspannung muss flexibel sein, damit er die Daten gut anpassen kann. Wenn der Lernalgorithmus jedoch zu flexibel ist, passt er jedem Trainingsdatensatz unterschiedlich an und hat somit eine hohe Varianz. Ein wesentlicher Aspekt vieler beaufsichtigter Lernmethoden ist, dass sie diesen Kompromiss zwischen Vorspannung und Varianz einstellen können (entweder automatisch oder durch Bereitstellung eines Voreinstell-/Variantenparameters, den der Benutzer einstellen kann). Funktionskomplexität und Anzahl der Trainingsdaten Die zweite Ausgabe ist die Anzahl der Trainingsdaten, die bezüglich der Komplexität der wahren Funktion (Klassifikator oder Regressionsfunktion) zur Verfügung stehen. Ist die wahre Funktion einfach, so kann ein unflexibler Lernalgorithmus mit hoher Vorspannung und geringer Varianz aus einer kleinen Menge von Daten lernen. Ist die wahre Funktion jedoch sehr komplex (z.B. weil sie komplexe Interaktionen zwischen vielen verschiedenen Eingabemerkmalen beinhaltet und sich in unterschiedlichen Teilen des Eingaberaums unterschiedlich verhält), so kann die Funktion nur aus einer sehr großen Anzahl von Trainingsdaten und einem flexiblen Lernalgorithmus mit geringer Vorspannung und hoher Varianz lernen. Zwischen dem Eingang und dem gewünschten Ausgang ist eine klare Abgrenzung gegeben. Die Dimensionalität des EingangsraumsEin drittes Problem ist die Dimensionalität des Eingangsraums. Wenn die Eingabe-Feature-Vektoren sehr hohe Dimension haben, kann das Lernproblem auch dann schwierig sein, wenn die wahre Funktion nur von einer kleinen Anzahl dieser Funktionen abhängt. Dies liegt daran, dass die vielen zusätzlichen Dimensionen den Lernalgorithmus verwirren können und ihn zu einer hohen Varianz führen. Daher erfordert eine hohe Eingangsgröße typischerweise eine Abstimmung des Klassifikators mit geringer Varianz und hoher Vorspannung. In der Praxis, wenn der Ingenieur irrelevante Merkmale manuell aus den Eingabedaten entfernen kann, wird dies wahrscheinlich die Genauigkeit der gelernten Funktion verbessern. Darüber hinaus gibt es viele Algorithmen für die Feature-Auswahl, die versuchen, die relevanten Funktionen zu identifizieren und die irrelevanten zu verwerfen. Dies ist ein Beispiel für die allgemeinere Strategie der Dimensionsreduktion, die die Eingabedaten vor dem Ausführen des überwachten Lernalgorithmus in einen tieferen Raum abbilden will. Geräusche in den Ausgangswerten Eine vierte Ausgabe ist der Rauschgrad in den gewünschten Ausgangswerten (die aufsichtlichen Zielvariablen). Sind die gewünschten Ausgangswerte oft falsch (wegen menschlicher Fehler oder Sensorfehler), sollte der Lernalgorithmus nicht versuchen, eine Funktion zu finden, die genau den Trainingsbeispielen entspricht. Die zu sorgfältige Anpassung der Daten führt zu einer Überarbeitung. Sie können auch überfit, wenn es keine Messfehler (Stochastic Rauschen) gibt, wenn die Funktion, die Sie lernen wollen, zu kompliziert für Ihr Lernmodell ist. In einer solchen Situation korrumpiert der Teil der Zielfunktion, der nicht modelliert werden kann, Ihre Trainingsdaten - dieses Phänomen wurde als deterministisches Geräusch bezeichnet. Wenn entweder eine Art von Lärm vorhanden ist, ist es besser, mit einer höheren Vorspannung zu gehen, niedrigere Varianzschätzer. In der Praxis gibt es mehrere Ansätze, um Geräusche in den Ausgabewerten zu verringern, wie beispielsweise ein vorzeitiges Stoppen, um eine Überrüstung zu verhindern, sowie das Erkennen und Entfernen der lauten Trainingsbeispiele vor dem Training des überwachten Lernalgorithmus. Es gibt mehrere Algorithmen, die laute Trainingsbeispiele identifizieren und die verdächtigten lauten Trainingsbeispiele entfernen, bevor Training den Verallgemeinerungsfehler mit statistischer Bedeutung verringert hat. Andere Faktoren Weitere Faktoren, die bei der Auswahl und Anwendung eines Lernalgorithmus zu berücksichtigen sind, sind die folgenden: Heterogenität der Daten. Wenn die Merkmalsvektoren Merkmale von vielen verschiedenen Arten (diskret, diskret bestellt, zählt, kontinuierliche Werte,) einige Algorithmen sind einfacher anzuwenden als andere. Viele Algorithmen, einschließlich Stützvektormaschinen, lineare Regression, logistische Regression, neuronale Netzwerke und nächste Nachbarmethoden, erfordern, dass die Eingabefunktionen numerisch und in ähnliche Bereiche (z.B. im -[1,1]-Intervall) skaliert werden. Hierfür sind Verfahren, die eine Distanzfunktion verwenden, wie nächstgelegene Nachbarmethoden und Support-Vektor-Maschinen mit Gaussian-Kernen. Ein Vorteil von Entscheidungsbäumen ist, dass sie leicht heterogene Daten verarbeiten. Redundanz in den Daten. Wenn die Eingabefunktionen redundante Informationen enthalten (z.B. hochkorrelierte Funktionen), werden einige Lernalgorithmen (z.B. lineare Regression, logistische Regression und distanzbasierte Methoden) aufgrund numerischer Instabilitäten schlecht durchgeführt. Diese Probleme lassen sich oft lösen, indem man eine gewisse Form der Regulierung einführt. Präsenz von Interaktionen und Nichtlinearitäten. Wenn jede der Merkmale einen unabhängigen Beitrag zum Ausgang leistet, dann führen Algorithmen auf Basis linearer Funktionen (z.B. lineare Regression, logistische Regression, Stützvektor-Maschinen, naive Bayes) und Distanzfunktionen (z.B. nächstgelegene Nachbarmethoden, Stützvektor-Maschinen mit Gaussian Kernels) in der Regel gut durch. Wenn es jedoch komplexe Interaktionen unter Merkmalen gibt, dann arbeiten Algorithmen wie Entscheidungsbäume und neuronale Netzwerke besser, weil sie speziell darauf ausgelegt sind, diese Interaktionen zu entdecken. Es können auch lineare Methoden angewendet werden, aber der Ingenieur muss manuell die Interaktionen bei der Verwendung festlegen. Bei der Betrachtung einer neuen Anwendung kann der Ingenieur mehrere Lernalgorithmen vergleichen und experimentell ermitteln, welche am besten auf dem Problem zur Hand funktioniert (siehe Kreuzvalidierung). Das Tun der Leistung eines Lernalgorithmus kann sehr zeitaufwendig sein. Bei festen Ressourcen ist es oft besser, mehr Zeit zu verbringen, zusätzliche Trainingsdaten und informativere Funktionen zu sammeln, als es ist, zusätzliche Zeit zu verbringen, die Lernalgorithmen zu tun. Algorithmen Die am weitesten verbreiteten Lernalgorithmen sind: Support-Vektor-Maschinen Linear regressionLogistische Regression Naive Bayes Lineare Diskriminante Analyse Entscheidung Bäume K-nächste Nachbaralgorithmus Neural Netzwerke (Multilayer perceptron) Ähnliches Lernen Wie beaufsichtigte Lernalgorithmen funktionieren Bei einem Satz von N \{displaystyle N} Trainingsbeispielen des Formulars { ( x 1 , y 1 ) , . . ., ( x N, y N )} \{displaystyle x_{1},y_{1}),...,(x_{N},\;y_{N so, dass x i \{displaystyle x_{i} der Merkmalsvektor des i \{displaystyle i} -th Beispiels ist und y i \{displaystyle y_{i} sein Label (d.h. Klasse) ein Lernalgorithmus eine Funktion sucht g : X → Y \{displaystyle g:X\to Y}, wobei X \{displaystyle X} der Eingangsraum ist und Y \{displaystyle Y} der Ausgangsraum ist. Die Funktion g \{displaystyle g} ist ein Element von einigen Raum der möglichen Funktionen G \{displaystyle G}, meist als Hypothesenraum bezeichnet. Es ist manchmal bequem, g \{displaystyle g} mit einer Scoring-Funktion f : X × Y → R \{displaystyle f:X\times Y\to \mathbb {R} so, dass g \{displaystyle g} als Rückgabe des y \{displaystyle y}-Werts definiert ist, der die höchste Punktzahl gibt: g ( x) = arg ≠ max y f ( x , y ) \{displaystyle g(x)={\underset y}{\arg \max ;\f(x,yote) . Obwohl G \{displaystyle G} und F \{displaystyle F} alle Funktionen sein können, sind viele Lernalgorithmen probabilistische Modelle, bei denen g \{displaystyle g} die Form eines bedingten Wahrscheinlichkeitsmodells g ( x ) = P ( y | x ) \{displaystyle g(x)=P(y|x}, oder f \{displaystyle f} die Form einer gemeinsamen So sind z.B. naive Bayes und lineare diskriminante Analyse gemeinsame Wahrscheinlichkeitsmodelle, während logistische Regression ein bedingtes Wahrscheinlichkeitsmodell ist. Es gibt zwei grundlegende Ansätze zur Wahl f \{displaystyle f} oder g \{displaystyle g}: empirische Risikominimierung und strukturelle Risikominimierung. Empirische Risikominimierung sucht die Funktion, die am besten zu den Trainingsdaten passt. Die strukturelle Risikominimierung umfasst eine Straffunktion, die den Bias-/Variantenabtausch kontrolliert. In beiden Fällen wird davon ausgegangen, dass der Trainingssatz aus einer Probe unabhängiger und gleich verteilter Paare besteht (x i, y i ) \{displaystyle (x_{i},\;y_{i) . Um zu messen, wie gut eine Funktion den Trainingsdaten passt, wird eine Verlustfunktion L : Y × Y → R ≥ 0{displaystyle L:Y\times Y\to \mathbb {R}2 definiert Bei Ausbildungsbeispielen ( x i, y i ) \{displaystyle (x_{i},\;y_{i) ist der Verlust der Voraussage des Wertes y ^ \{displaystyle \{hat {y} L ( y i, y ^ ) \{displaystyle L(y_{i},{\hat {y}style) \" Dies kann aus den Trainingsdaten als R e m p (g ) = 1 N Σ i L ( y i, g ( x i) ) geschätzt werden. \{displaystyle R_{emp}(g)={\frac (y_{i},g(x_{i)) Empirische Risikominimierung In der empirischen Risikominimierung sucht der beaufsichtigte Lernalgorithmus die Funktion g \{displaystyle g}, die R (g ) \{displaystyle R(g}) minimiert.Hence, ein beaufsichtigter Lernalgorithmus kann durch Anwendung eines Optimierungsalgorithmus erstellt werden, um g \{displaystyle g} zu finden. Wenn g \{displaystyle g} eine bedingte Wahrscheinlichkeitsverteilung P ( y | x ) \{displaystyle P(y|x}) ist und die Verlustfunktion die negative log Wahrscheinlichkeit ist: L ( y , y ^ ) = - log ‡ P ( y | x ) \{displaystyle L(y,{\hat {y} like)=-\log P(y|x} äquivalent) Wenn G \{displaystyle G} viele Kandidatenfunktionen enthält oder das Trainingsset nicht ausreichend groß ist, führt empirische Risikominimierung zu hoher Varianz und schlechter Verallgemeinerung. Der Lernalgorithmus ist in der Lage, die Trainingsbeispiele zu merken, ohne sich gut zu verallgemeinern. Das nennt man Überholung. Strukturelle RisikominimierungStrukturelle Risikominimierung versucht, zu verhindern, dass Überbelegung durch die Einbindung einer Regularisierungsstrafe in die Optimierung. Die Regelungsstrafe kann als Umsetzung einer Form von Occams Rasierer angesehen werden, die einfachere Funktionen gegenüber komplexeren bevorzugt. Es wurden eine Vielzahl von Strafen eingesetzt, die unterschiedlichen Definitionen der Komplexität entsprechen. Betrachten Sie beispielsweise den Fall, dass die Funktion g \{displaystyle g} eine lineare Funktion der Form g ( x ) = Σ j = 1 d β j x j \{displaystyle g(x)=\sum _j=1^{d}\beta ist. j}x_{j .Apopular Regularization Strafe ist Σ j j j 2 \{displaystyle \sum _{j}\beta _j}^{2 , die die quadrierte Euclidean Norm der Gewichte, auch bekannt als die L 2 \{displaystyle L_{2} Norm. Andere Normen sind die L 1 \{displaystyle L_{1} Norm, Σ j | β j | \{displaystyle \sum _{j}\\beta _{j}| und die L 0 \{displaystyle L_{0} Norm, die die Anzahl der nicht-Null β j \{displaystyle \beta _{j} s.Die Strafe wird durche m p (g ) + λ C (g ) . \{displaystyle J(g)=R_{emp}(g)+\lambda C(g}) Der Parameter λ \{displaystyle \lambda } steuert die Voreinstellungsvarianz-Trade. Wenn λ = 0 \{displaystyle \lambda =0} , gibt es empirische Risikominimierung mit geringer Vorspannung und hoher Varianz. Wenn λ \{displaystyle \lambda } groß ist, wird der Lernalgorithmus hohe Vorspannung und geringe Varianz haben. Der Wert von λ \{displaystyle \lambda } kann empirisch über Kreuzvalidierung gewählt werden. Die Komplexitätsstrafe hat eine Bayesische Interpretation als negative log-Vorhersagewahrscheinlichkeit g \{displaystyle g}, − log ‡ P (g ) \{displaystyle -\log P(g}) , in welchem Fall J (g ) \{displaystyle J(g}) die posterior Wahrscheinlichkeit von g \{displaystyle g} ist. Generelles Training Die oben beschriebenen Trainingsmethoden sind diskriminierende Trainingsmethoden, da sie eine Funktion g \{displaystyle g} finden, die gut zwischen den verschiedenen Ausgangswerten diskriminiert (siehe diskriminatives Modell). Für den Sonderfall, bei dem f ( x , y ) = P ( x , y ) \{displaystyle f(x,y)=P(x,y} eine gemeinsame Wahrscheinlichkeitsverteilung ist und die Verlustfunktion die negative log Wahrscheinlichkeit ist - Σ i log ‡ P (x i, y i ) , \{displaystyle -\sum _{i}\log P(x_{i},y_{i) ein Risikominimierungsalgorithmus soll generatives Training durchführen, da f \{displaystyle f} als generatives Modell angesehen werden kann, das erklärt, wie die Daten generiert wurden. Generative Trainingsalgorithmen sind oft einfacher und rechnerisch effizienter als diskriminierende Trainingsalgorithmen. In einigen Fällen kann die Lösung wie in naiven Buchten und linearen diskriminierenden Analysen in geschlossener Form berechnet werden. Verallgemeinerungen Es gibt verschiedene Möglichkeiten, wie das standardbeaufsichtigte Lernproblem verallgemeinert werden kann: Semi-supervised learning: Bei dieser Einstellung werden die gewünschten Ausgangswerte nur für eine Teilmenge der Trainingsdaten bereitgestellt. Die übrigen Daten sind unmarkiert. Schwache Überwachung: Bei dieser Einstellung werden laute, begrenzte oder ungenaue Quellen verwendet, um das Überwachungssignal für die Kennzeichnung von Trainingsdaten bereitzustellen. Aktives Lernen: Anstatt davon auszugehen, dass alle Trainingsbeispiele zu Beginn gegeben werden, sammeln aktive Lernalgorithmen interaktive neue Beispiele, typischerweise indem sie Abfragen an einen menschlichen Benutzer machen. Oft basieren die Abfragen auf unmarkierten Daten, was ein Szenario ist, das semi-supervised learning mit aktivem Lernen kombiniert. Strukturierte Vorhersage: Ist der gewünschte Ausgangswert ein komplexes Objekt, wie ein Parsebaum oder ein markiertes Diagramm, so müssen Standardverfahren erweitert werden. Lernen zu ordnen: Wenn die Eingabe ein Satz von Objekten ist und die gewünschte Ausgabe ein Ranking dieser Objekte ist, müssen wieder die Standardverfahren erweitert werden. Ansätze und AlgorithmenAnalytisches Lernen Künstliches neuronales Netzwerk Backpropagation Boosting (meta-algorithm)Bayesische Statistiken Fallbasiertes Denken Entscheidung Baumlernen Induktive Logik-Programmierung Gausssian Prozessregression Gentische Programmierung Gruppenmethode der Datenhandling Kernel-Schätzer Lernautomata Lern-Klassifikatorsysteme Mindeste Nachrichtenlänge (Entscheidung Bäume, Entscheidungsdiagramme, etc.) Multilineares Subraum-Erlernen Naive Bayes Klassifikator Maximale Entropie Klassifikator Conditional random field Nächster Nachbaralgorithmus Wahrscheinlich ungefähr korrektes Lernen (PAC) Lernen Ripple down Regeln, eine Wissenserfassung MethodikSymbolische maschinelle Lernalgorithmen Subsymbolische maschinelle Lernalgorithmen Support-Vektor-Maschinen Minimale Komplexitätsmaschinen (MCM)Randomwälder Ensembles der Klassifikatoren Ordinalklassifikation Datenvorverarbeitung Handhabung unsymmetrischer Datensätze Statistisches relationales Lernen Proaftn, ein Multikriterienklassifikationsalgorithmus Anwendungen Bioinformatik Cheminformatik Quantitative Struktur-Aktivitätsbeziehung Datenbankmarketing Handwriting Erkennung Information retrie Landform-Klassifikation mit Satellitenbild Allgemeine Themen Computer-Learning-Theorie Induktive Bias Overfitting (Maschinenlernen) (Unkalibriert) Klassenmitgliedschaft Fähigkeiten Unsupervised learning Version Leerzeichen Siehe auch Liste der Datensätze für maschinelles Lernen Referenzen Externe Links Machine Learning Open Source Software (MLOSS)