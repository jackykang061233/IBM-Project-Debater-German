Augmented Reality (AR) ist eine interaktive Erfahrung einer realen Umgebung, in der die Objekte, die in der realen Welt leben, durch computergenerierte Wahrnehmungsinformationen, manchmal über mehrere sensorische Modalitäten, einschließlich visuelle, auditive, haptische, somatosensorische und olfaktorische, erweitert werden. AR kann als ein System definiert werden, das drei Grundmerkmale umfasst: eine Kombination aus realen und virtuellen Welten, Echtzeit-Interaktion und genaue 3D-Registrierung von virtuellen und realen Objekten. Die überlagerten sensorischen Informationen können konstruktiv (d.h. additiv zur natürlichen Umgebung) oder destruktiv (d.h. Maskierung der natürlichen Umgebung) sein. Diese Erfahrung ist nahtlos mit der physischen Welt verbunden, so dass sie als ein immersiver Aspekt der realen Umgebung wahrgenommen wird. Auf diese Weise verändert die erweiterte Realität die laufende Wahrnehmung einer realen Weltumgebung, während die virtuelle Realität die reale Weltumgebung des Nutzers durch eine simulierte ersetzt. Augmented Reality ist mit zwei weitgehend synonymen Begriffen verbunden: gemischte Realität und computervermittelte Realität. Der primäre Wert der erweiterten Realität ist die Art und Weise, wie sich Komponenten der digitalen Welt in die Wahrnehmung der realen Welt einmischen, nicht als einfache Darstellung von Daten, sondern durch die Integration von immersiven Empfindungen, die als natürliche Teile einer Umgebung wahrgenommen werden. Die frühesten funktionellen AR-Systeme, die immersive Mixed-Reality-Erfahrungen für Anwender lieferten, wurden Anfang der 1990er Jahre erfunden, angefangen mit dem Virtual Fixtures-System, das 1992 im Armstrong Laboratory der US Air Force entwickelt wurde. Kommerzielle augmented Reality-Erfahrungen wurden zuerst in Entertainment- und Gaming-Unternehmen vorgestellt. Anschließend haben sich augmented Reality-Anwendungen auf kommerzielle Branchen wie Bildung, Kommunikation, Medizin und Unterhaltung ausgeweitet. In der Ausbildung können Inhalte durch Scannen oder Betrachten eines Bildes mit einem mobilen Gerät oder durch Verwendung von markerlosen AR-Techniken aufgerufen werden. Augmented Reality wird verwendet, um natürliche Umgebungen oder Situationen zu verbessern und wahrnehmbar bereicherte Erfahrungen anzubieten. Mit Hilfe fortschrittlicher AR-Technologien (z.B. das Hinzufügen von Computer-Vision, die Einbindung von AR-Kameras in Smartphone-Anwendungen und die Objekterkennung) wird die Information über die umliegende reale Welt des Nutzers interaktiv und digital manipuliert. Die Informationen über die Umwelt und ihre Objekte sind auf der realen Welt überlagert. Diese Informationen können virtuell sein. Augmented Reality ist jede Erfahrung, die künstlich ist und die bereits bestehende Realität ergänzt. oder real, z.B. andere real erfasste oder gemessene Informationen wie elektromagnetische Radiowellen in exakter Ausrichtung mit dem, wo sie tatsächlich im Raum sind, überlagert zu sehen. Augmented Reality hat auch viel Potenzial bei der Sammlung und Weitergabe von zaghaften Kenntnissen. Augmentationstechniken werden typischerweise in Echtzeit und in semantischen Kontexten mit Umweltelementen durchgeführt. Immersive perzeptuelle Informationen werden manchmal mit ergänzenden Informationen wie Scores über einen Live-Video-Feed eines Sportereignisses kombiniert. Dies kombiniert die Vorteile der Augmented Reality-Technologie und der Heads-up-Display-Technologie (HUD). Vergleich mit virtueller Realität In der virtuellen Realität (VR) basiert die Realitätswahrnehmung der Nutzer vollständig auf virtuellen Informationen. In der augmented Reality (AR) wird der Benutzer mit zusätzlichen computergenerierten Informationen innerhalb der Daten aus dem realen Leben, die ihre Wahrnehmung der Realität verbessert, zur Verfügung gestellt. In der Architektur kann beispielsweise VR dazu verwendet werden, eine durchgängige Simulation des Inneren eines neuen Gebäudes zu erstellen, und AR kann dazu verwendet werden, die Strukturen und Systeme eines Gebäudes zu zeigen, die einer realen Sicht überlagert sind. Ein weiteres Beispiel ist die Verwendung von Dienstprogrammen. Einige AR-Anwendungen, wie Augment, ermöglichen es Benutzern, digitale Objekte in reale Umgebungen anzuwenden, so dass Unternehmen augmented Reality-Geräte als Möglichkeit nutzen, um ihre Produkte in der realen Welt zu sehen. Ebenso kann es auch verwendet werden, um zu demo, wie die Produkte in einer Umgebung für Kunden aussehen können, wie von Unternehmen wie Mountain Equipment Co-op oder Lowe's, die Augmented Reality verwenden, gezeigt, um Kunden zu ermöglichen, um zu sehen, wie ihre Produkte zu Hause durch die Verwendung von 3D-Modellen aussehen. Augmented Reality (AR) unterscheidet sich von der virtuellen Realität (VR) in dem Sinne, dass in AR-Teil der Umgebung tatsächlich real ist und nur Schichten von virtuellen Objekten in die reale Umgebung addiert. Andererseits ist in VR die Umgebung vollständig virtuell. Eine Demonstration, wie AR-Schichten auf die reale Welt stoßen, ist mit erweiterten Realitätsspielen zu sehen. WallaMe ist eine augmented Reality-Spiel-Anwendung, die es Benutzern ermöglicht, Nachrichten in realen Umgebungen zu verstecken, mit Geolokationstechnologie, um Benutzer zu ermöglichen, Nachrichten zu verstecken, wo immer sie in der Welt wünschen. Solche Anwendungen haben viele Anwendungen in der Welt, einschließlich im Aktivismus und künstlerischem Ausdruck. Technology Hardware Hardware Komponenten für erweiterte Realität sind: ein Prozessor, Display, Sensoren und Eingabegeräte. Moderne mobile Computergeräte wie Smartphones und Tablet-Computer enthalten diese Elemente, die oft eine Kamera und mikroelektromechanische Systeme (MEMS) Sensoren wie ein Beschleunigungsmesser, GPS und Festkörperkompass enthalten, so dass sie geeignete AR-Plattformen. Es gibt zwei Technologien, die in der augmentierten Realität verwendet werden: diffraktive Wellenleiter und reflektierende Wellenleiter. Display Verschiedene Technologien werden bei der Augmented Reality Rendering verwendet, einschließlich optischer Projektionssysteme, Monitore, Handgeräte und Displaysysteme, die am menschlichen Körper getragen werden. Ein Head-mounted Display (HMD) ist ein Displaygerät, das an der Stirn getragen wird, wie z.B. ein Harness oder ein Helm montiert. HMDs stellen Bilder sowohl der physischen Welt als auch der virtuellen Objekte über das Sichtfeld des Benutzers. Moderne HMDs verwenden oft Sensoren für sechs Freiheitsüberwachungsgrade, die es dem System ermöglichen, virtuelle Informationen an die physische Welt auszurichten und entsprechend den Kopfbewegungen des Benutzers anzupassen. HMDs können VR-Nutzern mobile und kollaborative Erfahrungen anbieten. Spezifische Anbieter, wie uSens und Gestigon, umfassen Gestensteuerungen für die vollständige virtuelle Immersion. Brillen AR-Displays können auf Geräten wie Brillen gemacht werden. Zu den Versionen gehören Brillen, die Kameras zum Abfangen der realen Weltansicht verwenden und ihre erweiterte Sicht durch die Okulare und Geräte, in denen die AR-Bilder durch die Oberflächen der Brillenglasstücke projiziert oder reflektiert werden, wieder darstellen. HUD Ein Head-up-Display (HUD) ist ein transparentes Display, das Daten vorstellt, ohne dass Benutzer von ihren üblichen Blickwinkeln wegschauen müssen. Eine Vorläufertechnologie zur Augmented Reality, Heads-up-Displays wurden zunächst für Piloten in den 1950er Jahren entwickelt, die einfache Flugdaten in ihre Sichtweise projizierten, so dass sie ihre "Kopf hoch" halten und nicht auf die Instrumente schauen. Nah-Augmented Reality-Geräte können als tragbare Head-up-Displays verwendet werden, da sie Daten, Informationen und Bilder anzeigen können, während der Benutzer die reale Welt ansieht. Viele Definitionen der erweiterten Realität definieren sie nur als Überlagerung der Informationen. Dies ist im Grunde, was ein Head-up-Display tut; aber praktisch wird erwartet, dass erweiterte Realität die Registrierung und das Tracking zwischen den überlagerten Wahrnehmungen, Empfindungen, Informationen, Daten und Bildern und einem Teil der realen Welt umfassen. Kontaktlinsen Kontaktlinsen, die AR-Bildgebung anzeigen, sind in der Entwicklung. Diese bionischen Kontaktlinsen können die in das Objektiv eingebetteten Elemente enthalten, einschließlich integrierter Schaltungen, LEDs und einer Antenne für drahtlose Kommunikation. Das erste Kontaktlinsendisplay wurde 1999 von Steve Mann patentiert und soll in Kombination mit AR-Spektakel arbeiten, aber das Projekt wurde verlassen, dann 11 Jahre später in 2010–2011. Eine weitere Version von Kontaktlinsen, in der Entwicklung für das US-Militär, ist entworfen, um mit AR-Spektakel zu funktionieren, so dass Soldaten sich gleichzeitig auf Nah-to-the-eye AR-Bilder auf die Brille und entfernte reale Weltobjekte konzentrieren können. Auf der CES 2013 enthüllte ein Unternehmen namens Innovega auch ähnliche Kontaktlinsen, die benötigt wurden, um mit AR-Brille zu arbeiten. Der futuristische Kurzfilm Sight verfügt über kontaktlinsenartige Augmented Reality-Geräte. Viele Wissenschaftler haben an Kontaktlinsen gearbeitet, die unterschiedliche technologische Ergebnisse erzielen können. Ein von Samsung eingereichtes Patent beschreibt eine AR-Kontaktlinse, die, wenn es fertig ist, eine eingebaute Kamera auf dem Objektiv selbst enthalten wird. Das Design soll seine Schnittstelle durch Blinken eines Auges steuern. Es soll auch mit dem Smartphone des Benutzers verknüpft werden, um Aufnahmen zu überprüfen und separat zu steuern. Wenn es erfolgreich ist, würde das Objektiv eine Kamera oder einen Sensor darin haben. Es wird gesagt, dass es alles von einem Lichtsensor, zu einem Temperatursensor sein könnte. Der erste öffentlich vorgestellte Arbeitsprototypen eines AR-Kontaktobjektivs, das die Verwendung von Brillen in Verbindung nicht erfordert, wurde von Mojo Vision entwickelt und auf der CES 2020 bekannt gegeben. Virtuelles Netzteil-Display Ein virtuelles Netzteil (VRD) ist ein persönliches Displaygerät, das am Labor für Human Interface Technology der Universität Washington unter Dr. Thomas A. Furness III entwickelt wurde. Mit dieser Technologie wird ein Display direkt auf die Netzhaut eines Betrachters gescannt. Dies führt zu hellen Bildern mit hoher Auflösung und hohem Kontrast. Der Betrachter sieht, was scheinbar ein herkömmliches Display im Raum ist. Mehrere Tests wurden durchgeführt, um die Sicherheit der VRD zu analysieren. In einem Test wurden Patienten mit teilweisem Sehverlust – entweder mit einer Makuladegeneration (eine Krankheit, die die Netzhaut degeneriert) oder mit einem Keratokonus – ausgewählt, um Bilder mit der Technologie zu sehen. In der Makuladegenerationsgruppe bevorzugen fünf von acht Subjekten die VRD-Bilder zur Kathodenstrahlröhre (CRT) oder Papierbilder und dachten, sie seien besser und heller und konnten gleiche oder bessere Auflösungsniveaus sehen. Die Keratoconus-Patienten konnten in mehreren Zeilentests mit der VRD im Gegensatz zu ihrer eigenen Korrektur kleinere Zeilen auflösen. Sie fanden auch die VRD-Bilder, um leichter zu sehen und schärfer zu sein. Durch diese mehreren Tests wird das virtuelle Netzhautdisplay als sichere Technologie angesehen. Virtuelles Netzteilbild erzeugt Bilder, die bei Tageslicht und Umgebungsraumlicht sichtbar sind. Die VRD gilt als bevorzugte Kandidat für die Verwendung in einem chirurgischen Display aufgrund seiner Kombination aus hoher Auflösung und hohem Kontrast und Helligkeit. Zusätzliche Tests zeigen ein hohes Potenzial für VRD als Display-Technologie für Patienten mit geringer Sicht. Augen Tippen Sie auf das EyeTap (auch bekannt als Generation-2 Glas) erfasst Lichtstrahlen, die sonst durch die Mitte der Linse des Trägers Auge passieren würden, und ersetzt synthetisches computergesteuertes Licht für jeden Strahl des realen Lichts. Das Generation-4 Glas (Laser EyeTap) ist ähnlich wie die VRD (d.h. es verwendet eine computergesteuerte Laserlichtquelle), mit der Ausnahme, dass es auch unendliche Tiefenschärfe hat und das Auge selbst dazu führt, in der Tat als Kamera und Display durch genaue Ausrichtung mit dem Auge und Resynthese (im Laserlicht) von Lichtstrahlen des in das Auge eintretenden Lichts zu fungieren. Handheld Ein Handheld-Display verwendet ein kleines Display, das in die Hand eines Benutzers passt. Alle handgeführten AR-Lösungen entscheiden sich bisher für Video-Durchschauungen. Ursprünglich handgehaltene AR verwendet fiducial Marker, und später GPS-Einheiten und MEMS-Sensoren wie digitale Kompasse und sechs Grad der Freiheitsbeschleuniger-Gyroskop. Heutzutage werden gleichzeitige Lokalisierung und Kartierung (SLAM) Markerlose Tracker wie PTAM (Parallel Tracking und Mapping) eingesetzt. Handheld Display AR verspricht als erster kommerzieller Erfolg für AR-Technologien. Die beiden Hauptvorteile von Hand AR sind die tragbare Natur von Handgeräten und die allgegenwärtige Natur von Kamera-Handys. Die Nachteile sind die körperlichen Zwänge des Benutzers, die das Handgerät jederzeit vor sich halten müssen, sowie die verzerrende Wirkung von klassisch breitgefächerten Handykameras im Vergleich zur realen Welt, die durch das Auge betrachtet wird. Spiele wie Pokémon Go und Ingress nutzen eine Image Linked Map(ILM)-Schnittstelle, wo anerkannte geotagged Standorte auf einer stilisierten Karte für den Benutzer zu interagieren erscheinen. Projektions-Mapping Projektions-Mapping-Augments reale Weltobjekte und Szenen, ohne die Verwendung von speziellen Displays wie Monitoren, Head-Mounted-Displays oder Handheld-Geräten. Die Projektionsmapping nutzt digitale Projektoren, um grafische Informationen auf physische Objekte anzuzeigen. Der wesentliche Unterschied bei der Projektionskartierung besteht darin, dass das Display von den Benutzern des Systems getrennt ist. Da die Displays nicht jedem Benutzer zugeordnet sind, können Projektions-Mapping-Skalen natürlich bis zu Gruppen von Benutzern, die eine kollokierte Zusammenarbeit zwischen Benutzern ermöglichen. Beispiele sind Leuchtenlampen, mobile Projektoren, virtuelle Tabellen und intelligente Projektoren. Shader Lampen imitieren und Augment-Reality, indem sie Bilder auf neutrale Objekte projizieren. Dies bietet die Möglichkeit, das Erscheinungsbild des Objekts mit Materialien einer einfachen Einheit – einem Projektor, Kamera und Sensor – zu verbessern. Weitere Anwendungen sind Tisch- und Wandvorsprünge. Eine Innovation, die erweiterte virtuelle Tabelle, trennt das virtuelle von der realen, indem Strahlteiler Spiegel an der Decke in einem einstellbaren Winkel befestigt. Virtuelle Vitrinen, die Strahlteilerspiegel zusammen mit mehreren Grafikdisplays verwenden, bieten ein interaktives Mittel, gleichzeitig mit dem virtuellen und dem realen zu interagieren. Viele weitere Implementierungen und Konfigurationen machen die räumlich erweiterte Realität zu einer zunehmend attraktiven interaktiven Alternative. Ein Projektions-Mapping-System kann auf einer beliebigen Anzahl von Oberflächen in einer Inneneinstellung gleichzeitig anzeigen. Die Projektionsmapping unterstützt sowohl eine grafische Visualisierung als auch eine passive haptische Empfindung für die Endbenutzer. Benutzer können physische Objekte in einem Prozess berühren, der passive haptische Empfindung bietet. Tracking Moderner mobiler Augmented-Reality-Systeme nutzen eine oder mehrere der folgenden Bewegungsverfolgungstechnologien: Digitalkameras und/oder andere optische Sensoren, Beschleunigungsmesser, GPS, Gyroskope, Festkörper-Kompasse, Hochfrequenz-Identifizierung (RFID). Diese Technologien bieten unterschiedliche Genauigkeit und Präzision. Am wichtigsten ist die Position und Orientierung des Kopfes des Benutzers. Das Tracking der Hand(en) des Benutzers oder eines Handgeräts kann eine 6DOF Interaktionstechnik bieten. Networking Mobile Augmented Reality-Anwendungen gewinnen aufgrund der breiten Einführung mobiler und besonders tragbarer Geräte Popularität. Sie verlassen sich jedoch oft auf rechnerisch intensive Computer-Visionsalgorithmen mit extremen Latenzanforderungen. Um den Mangel an Rechenleistung zu kompensieren, wird oft ein Abladen der Datenverarbeitung an eine entfernte Maschine gewünscht. Computation offloading stellt neue Einschränkungen in Anwendungen vor, insbesondere in Bezug auf Latenz und Bandbreite. Obwohl es eine Vielzahl von Echtzeit-Multimedia-Transport-Protokollen gibt, gibt es eine Notwendigkeit für die Unterstützung von Netzwerkinfrastruktur sowie. Input-Geräte Techniken umfassen Spracherkennungssysteme, die die gesprochenen Wörter eines Benutzers in Computeranweisungen übersetzen, und Gestenerkennungssysteme, die die Körperbewegungen eines Benutzers durch visuelle Erfassung oder von Sensoren interpretieren, die in einem peripheren Gerät wie einem Zauberstab, einem Taststift, einem Zeiger, einem Handschuh oder einem anderen Körperverschleiß eingebettet sind. Produkte, die als Controller von AR Headsets dienen wollen, sind Wave von Seebright Inc. und Nimble von Intugine Technologies. Computer Der Computer analysiert die erfassten visuellen und anderen Daten, um Augmentationen zu synthetisieren und zu positionieren. Computer sind verantwortlich für die Grafiken, die mit einer erweiterten Realität gehen. Augmented Reality verwendet ein computergeneriertes Bild, das auf die Art und Weise, wie die reale Welt gezeigt wird, einen markanten Effekt hat. Mit der Verbesserung von Technologie und Computern wird die erweiterte Realität zu einer drastischen Veränderung in der Perspektive der realen Welt führen. Laut Zeit, in etwa 15–20 Jahren wird prognostiziert, dass erweiterte Realität und virtuelle Realität werden die primäre Verwendung für Computer-Interaktionen. Computer verbessern sich sehr schnell, was zu neuen Möglichkeiten führt, um andere Technologien zu verbessern. Je mehr Computer Fortschritte machen, wird die erweiterte Realität in der Gesellschaft flexibler und häufiger. Computer sind der Kern der erweiterten Realität. Der Rechner erhält von den Sensoren Daten, die die relative Position einer Objektoberfläche bestimmen. Dies übersetzt eine Eingabe auf den Computer, die dann an die Benutzer ausgibt, indem etwas hinzugefügt wird, das sonst nicht da wäre. Der Computer umfasst Speicher und einen Prozessor. Der Computer nimmt die gescannte Umgebung dann erzeugt Bilder oder ein Video und legt es auf den Empfänger für den Beobachter zu sehen. Die festen Markierungen auf der Oberfläche eines Objekts werden im Speicher eines Computers gespeichert. Der Computer entzieht sich auch aus seinem Speicher, um Bilder realistisch auf den Zuschauer zu präsentieren. Das beste Beispiel dafür ist der Pepsi Max AR Bus Shelter. Projektor Projektoren können auch verwendet werden, um AR-Inhalte anzuzeigen. Der Projektor kann ein virtuelles Objekt auf einen Projektionsschirm werfen und der Betrachter kann mit diesem virtuellen Objekt interagieren. Projektionsflächen können viele Objekte wie Wände oder Glasscheiben sein. Software und Algorithmen Ein zentrales Maß für AR-Systeme ist, wie realistisch sie Augmentationen mit der realen Welt integrieren. Die Software muss reale Weltkoordinaten ableiten, unabhängig von Kamera und Kamerabildern. Dieser Prozess wird als Bildregistrierung bezeichnet und verwendet verschiedene Methoden der Computer-Vision, meist im Zusammenhang mit Video-Tracking. Viele Computer-Visionsmethoden der erweiterten Realität werden von der visuellen Odometrie geerbt. Ein Augogramm ist ein Computer-Bild, das verwendet wird, um AR zu erstellen. Augographie ist die Wissenschafts- und Softwarepraxis der Herstellung von Augogrammen für AR. Üblicherweise bestehen diese Verfahren aus zwei Teilen. Die erste Stufe besteht darin, in den Kamerabildern Zinspunkte, fiducial Marker oder optische Strömung zu erkennen. Dieser Schritt kann Feature-Detektionsverfahren wie Eckerkennung, Blob-Detektion, Kantendetektion oder Schwellung und andere Bildverarbeitungsverfahren verwenden. Die zweite Stufe stellt aus den in der ersten Stufe erhaltenen Daten ein reales Weltkoordinatensystem wieder her. Einige Verfahren nehmen an, dass Objekte mit bekannter Geometrie (oder fiducial Marker) in der Szene vorhanden sind. In einigen dieser Fälle sollte die Szene 3D-Struktur vorher berechnet werden. Wenn ein Teil der Szene unbekannt ist, können gleichzeitige Lokalisierung und Kartierung (SLAM) relative Positionen abbilden. Wenn keine Informationen über Szenengeometrie vorhanden sind, werden Struktur aus Bewegungsmethoden wie Bündeleinstellung verwendet. Die in der zweiten Stufe verwendeten mathematischen Methoden umfassen: projektive (epipolare) Geometrie, geometrische Algebra, Rotationsdarstellung mit exponentieller Karte, Kalman und Partikelfilter, nichtlineare Optimierung, robuste Statistiken. In einer erweiterten Realität wird zwischen zwei verschiedenen Arten von Tracking, genannt Marker und Markerless, unterschieden. Marker sind visuelle Cues, die die Anzeige der virtuellen Informationen auslösen. Ein Stück Papier mit einigen unterschiedlichen Geometrien kann verwendet werden. Die Kamera erkennt die Geometrien, indem sie bestimmte Punkte in der Zeichnung identifiziert. Markerless Tracking, auch Instant Tracking genannt, verwendet keine Marker. Vielmehr positioniert der Benutzer das Objekt in der Kameraansicht vorzugsweise in einer horizontalen Ebene. Es verwendet Sensoren in mobilen Geräten, um die reale Umgebung genau zu erkennen, wie die Orte der Wände und Schnittpunkte. Augmented Reality Markup Language (ARML) ist ein Datenstandard, der im Open Geospatial Consortium (OGC) entwickelt wurde, der aus der Grammatik Extensible Markup Language (XML) besteht, um die Lage und das Aussehen von virtuellen Objekten in der Szene zu beschreiben, sowie ECMAScript-Bindungen, um einen dynamischen Zugriff auf Eigenschaften virtueller Objekte zu ermöglichen. Um eine schnelle Entwicklung von Augmented Reality-Anwendungen zu ermöglichen, sind einige Software-Entwicklungskits (SDKs) entstanden. Entwicklung Die Umsetzung von augmented Reality in Consumer-Produkten erfordert die Prüfung der Gestaltung der Anwendungen und der damit verbundenen Einschränkungen der Technologieplattform.Da AR-Systeme sich stark auf das Eintauchen des Benutzers und die Interaktion zwischen dem Benutzer und dem System verlassen, kann Design die Annahme von Virtualität erleichtern. Für die meisten erweiterten Realitätssysteme kann eine ähnliche Design-Richtlinie verfolgt werden. Die folgenden Listen einige Überlegungen zur Gestaltung von Augmented-Reality-Anwendungen: Umwelt/Kontext-Design Context Design konzentriert sich auf den physischen Umgebungs-, Raum- und Zugänglichkeitsraum des Endbenutzers, der bei der Nutzung des AR-Systems eine Rolle spielen kann. Designer sollten sich der möglichen physikalischen Szenarien bewusst sein, die der Endbenutzer in der Art sein kann: Public, in der die Benutzer ihren ganzen Körper benutzen, um mit der Software Personal zu interagieren, in der der Benutzer ein Smartphone in einem öffentlichen Raum verwendet Intimate, in dem der Benutzer mit einem Desktop sitzt und nicht wirklich Private bewegt, in dem der Benutzer auf einem tragbaren. Durch die Auswertung jedes physikalischen Szenarios können mögliche Sicherheitsrisiken vermieden und Veränderungen vorgenommen werden, um die Eintauchung des Endverbrauchers zu verbessern. UX-Designer müssen Nutzerfahrten für die relevanten physikalischen Szenarien definieren und definieren, wie die Schnittstelle auf jedes reagiert. Insbesondere bei AR-Systemen ist es von entscheidender Bedeutung, auch die räumlichen und umgebenden Elemente zu berücksichtigen, die die Wirksamkeit der AR-Technologie verändern. Umweltelemente wie Beleuchtung und Schall können verhindern, dass der AR-Gerätesensor notwendige Daten erfasst und das Eintauchen des Endverbrauchers ruiniert. Ein weiterer Aspekt der Kontextgestaltung ist die Gestaltung der Funktionalität des Systems und die Fähigkeit, Benutzereinstellungen zu berücksichtigen. Während die Zugänglichkeitstools in der Grundanwendungsgestaltung üblich sind, sollte bei der Gestaltung von zeitbegrenzten Aufforderungen (um unbeabsichtigte Operationen zu verhindern) Audio-Claus und Gesamteingriffszeit einiges berücksichtigt werden. Es ist wichtig zu beachten, dass die Funktionalität der Anwendung in einigen Situationen die Fähigkeit des Benutzers behindern kann. Zum Beispiel sollten Anwendungen, die für das Fahren verwendet werden, die Menge der Benutzerinteraktion reduzieren und stattdessen Audio-Cuts verwenden. Interaction Design Interaction Design in augmented-Reality-Technologiezentren auf das Engagement des Benutzers mit dem Endprodukt, um die Gesamterfahrung und Freude des Benutzers zu verbessern. Ziel der Interaktionsgestaltung ist es, den Benutzer durch die Organisation der dargestellten Informationen zu entfremden oder zu verwirren. Da die Benutzerinteraktion auf die Eingabe des Benutzers beruht, müssen die Designer die Systemsteuerungen leichter verstehen und zugänglich machen. Eine gemeinsame Technik zur Verbesserung der Usability für Augmented-Reality-Anwendungen ist die Entdeckung der häufig zugänglichen Bereiche im Touch-Display des Geräts und die Gestaltung der Anwendung, um diese Bereiche der Kontrolle anzupassen. Es ist auch wichtig, die Nutzerfahrkarten und den Informationsfluss zu strukturieren, der die Gesamtkognitivlast des Systems reduziert und die Lernkurve der Anwendung erheblich verbessert. Im Interaktionsdesign ist es für Entwickler wichtig, Augmented Reality-Technologie zu nutzen, die die Funktion oder den Zweck des Systems ergänzt. So ermöglicht die Nutzung von spannenden AR-Filtern und das Design der einzigartigen Sharing-Plattform in Snapchat den Nutzern, ihre in-app sozialen Interaktionen zu verbessern. In anderen Anwendungen, die Benutzer benötigen, um den Fokus und die Absicht zu verstehen, können Designer ein Retikel oder Raycast aus dem Gerät verwenden. Darüber hinaus können augmented Reality-Entwickler es sinnvoll finden, digitale Elemente skaliert oder auf die Richtung der Kamera und den Kontext von Objekten zu reagieren, die detektiert werden können. Augmented Reality-Technologie ermöglicht die Einführung von 3D-Raum. Dies bedeutet, dass ein Benutzer innerhalb einer einzigen AR-Anwendung auf mehrere Kopien von 2D-Schnittstellen zugreifen kann. Visuelles Design Im Allgemeinen ist die visuelle Gestaltung das Aussehen der sich entwickelnden Anwendung, die den Benutzer angreift. Zur Verbesserung der grafischen Schnittstellenelemente und Benutzerinteraktion können Entwickler visuelle Hinweise verwenden, um dem Benutzer mitzuteilen, welche Elemente von UI für die Interaktion mit ihnen und wie mit ihnen interagieren konzipiert sind. Da navigating in einer AR-Anwendung kann schwierig erscheinen und scheinen frustrierend, visuelle Cue-Design kann Interaktionen scheinen natürlicher. In einigen augmented Reality-Anwendungen, die ein 2D-Gerät als interaktive Oberfläche verwenden, übersetzt die 2D-Steuerumgebung nicht gut in 3D-Raum, wodurch Benutzer zögern, ihre Umgebung zu erkunden. Um dieses Problem zu lösen, sollten Designer visuelle Cues anwenden, um Benutzer zu unterstützen und zu ermutigen, ihre Umgebung zu erkunden. Es ist wichtig, die beiden Hauptobjekte in AR bei der Entwicklung von VR-Anwendungen zu beachten: 3D-Volumenobjekte, die manipuliert und realistisch mit Licht und Schatten interagieren; und animierte Medienbilder wie Bilder und Videos, die meist traditionelle 2D-Medien sind, die in einem neuen Kontext für eine erweiterte Realität dargestellt werden. Wenn virtuelle Objekte auf eine reale Umgebung projiziert werden, ist es für augmented-Reality-Anwendungsdesigner schwierig, eine perfekt nahtlose Integration in Bezug auf die reale Umgebung, insbesondere mit 2D-Objekten, zu gewährleisten. Als solche können Designer Objekte Gewicht hinzufügen, Tiefenkarten verwenden und verschiedene Materialeigenschaften auswählen, die die Präsenz des Objekts in der realen Welt hervorheben. Ein weiteres visuelles Design, das angewendet werden kann, ist die Verwendung verschiedener Beleuchtungstechniken oder Gießschatten, um das allgemeine Tiefenurteil zu verbessern. So wird beispielsweise eine gemeinsame Beleuchtungstechnik einfach eine Lichtquelle über Kopf an der 12 Uhr Position platziert, um Schatten auf virtuellen Objekten zu erstellen. Mögliche Anwendungen Augmented Reality wurde für viele Anwendungen erforscht, von Gaming und Unterhaltung bis Medizin, Bildung und Business. Beispiel Anwendungsgebiete sind Archäologie, Architektur, Handel und Bildung. Einige der frühesten zitierten Beispiele umfassen die erweiterte Realität, die zur Unterstützung der Operation verwendet wird, indem virtuelle Überlagerungen zur Führung von medizinischen Praktizierenden, AR-Inhalte für Astronomie und Schweißen bereitgestellt werden. Archäologie AR wurde verwendet, um archäologische Forschung zu unterstützen. Durch die Erweiterung der archäologischen Merkmale auf die moderne Landschaft ermöglicht AR Archäologen, mögliche Standortkonfigurationen von extanten Strukturen zu formulieren. Computer erzeugte Modelle von Ruinen, Gebäuden, Landschaften oder sogar alten Menschen wurden in frühe archäologische AR-Anwendungen wiederverwertet. Zum Beispiel, VITA (Visual Interaction Tool for Archaeology) wird es den Benutzern erlauben, sich sofort Ausgrabungsergebnisse vorzustellen und zu untersuchen, ohne ihr Zuhause zu verlassen. Jeder Benutzer kann mit "navigieren, suchen und Anzeigen von Daten" zusammenarbeiten. Hrvoje Benko, ein Forscher in der Informatik-Abteilung an der Columbia University, weist darauf hin, dass diese speziellen Systeme und andere wie sie "3D-Panoramabilder und 3D-Modelle der Website selbst an verschiedenen Ausgrabungsstufen" bieten können, während viele der Daten in einer kollaborativen Weise, die einfach zu bedienen ist. Verbundene AR-Systeme liefern multimodale Interaktionen, die die reale Welt mit virtuellen Bildern beider Umgebungen kombinieren. Architektur AR kann bei der Visualisierung von Bauprojekten helfen. Computergenerierte Bilder einer Struktur können vor dem Bau des physischen Gebäudes auf eine reale lokale Sicht eines Grundstücks überlagert werden; dies wurde 2004 von Trimble Navigation öffentlich nachgewiesen. AR kann auch innerhalb eines Architektenarbeitsraums eingesetzt werden, was animierte 3D-Visualisierungen ihrer 2D-Zeichnungen macht. Die Architektur-Sichtsicht kann mit AR-Anwendungen verbessert werden, so dass Benutzer, die ein Gebäude im Außenbereich betrachten, praktisch durch seine Wände sehen, seine Innenobjekte und Layout zu sehen. Mit ständigen Verbesserungen der GPS-Genauigkeit können Unternehmen die erweiterte Realität nutzen, um georeferenzierte Modelle von Baustellen, unterirdischen Strukturen, Kabeln und Rohren mit mobilen Geräten zu visualisieren. Augmented Reality wird angewandt, um neue Projekte zu präsentieren, Herausforderungen vor Ort zu lösen und Werbematerialien zu verbessern. Beispiele sind der Daqri Smart Helm, ein Android-powered Hard Hat verwendet, um Augmented Reality für den Industriearbeiter zu schaffen, einschließlich visuelle Anweisungen, Echtzeit-Benachrichtigungen und 3D-Mapping. Nach dem Erdbeben von Christchurch hat die Universität von Canterbury CityViewAR freigelassen, die es Stadtplanern und Ingenieuren ermöglichte, Gebäude zu visualisieren, die zerstört wurden. Dies lieferte nicht nur Planer mit Werkzeugen, um das vorherige Stadtbild zu verweisen, sondern diente auch als Erinnerung an die Größe der daraus resultierenden Verwüstung, da ganze Gebäude abgerissen wurden. Als kollaborative Werkzeuge für Design und Planung in der Bauumgebung werden städtebauliche AR-Systeme eingesetzt. Zum Beispiel kann AR verwendet werden, um Augmented-Reality-Karten, Gebäude und Daten-Feeds auf Tischplatten projiziert für die kollaborative Betrachtung von gebauten Umweltexperten zu erstellen. Outdoor AR verspricht, dass Designs und Pläne der realen Welt überlagert werden können, die Aufgabe dieser Berufe neu definieren, in-situ-Design in ihren Prozess zu bringen. Design-Optionen können vor Ort artikuliert werden und erscheinen näher an der Realität als traditionelle Desktop-Mechanismen wie 2D-Karten und 3d-Modelle. STEM-Bildung In Bildungseinstellungen wurde AR zur Ergänzung eines Standardlehrplans verwendet. Text, Grafik, Video und Audio können in die Echtzeit-Umgebung eines Schülers überlagert werden. Textbücher, Flashcards und andere pädagogische Lesematerialien können eingebettete Marker oder Trigger enthalten, die beim Scannen durch ein AR-Gerät zusätzliche Informationen an den Schüler in einem Multimedia-Format erzeugt haben. Die 2015 Virtual, Augmented and Mixed Reality: 7. Internationale Konferenz erwähnte Google Glass als ein Beispiel für eine erweiterte Realität, die den physischen Klassenraum ersetzen kann. Zuerst helfen AR-Technologien Lernenden, authentische Explorationen in der realen Welt zu betreiben, und virtuelle Objekte wie Texte, Videos und Bilder sind zusätzliche Elemente für Lernende, um Untersuchungen der realen Umgebung durchzuführen. Wie sich AR entwickelt, können die Studierenden interaktiv teilnehmen und mit Wissen authentischer interagieren. Anstelle der verbleibenden passiven Empfänger können die Studierenden aktive Lernende werden, die mit ihrer Lernumgebung interagieren können. Computergenerierte Simulationen historischer Ereignisse ermöglichen es den Studierenden, Details über jeden bedeutenden Bereich der Veranstaltungsseite zu erkunden und zu lernen. In der Hochschulausbildung ermöglicht Construct3D, ein Studienröhrchen-System, den Studierenden Maschinenbaukonzepte, Mathematik oder Geometrie zu lernen. Die AR-Apps von Chemistry ermöglichen es den Studierenden, mit einem in der Hand gehaltenen Markerobjekt die räumliche Struktur eines Moleküls zu visualisieren und zu interagieren. Andere haben HP Reveal, eine kostenlose App, verwendet, um AR-Notizkarten für die Untersuchung von organischen Chemiemechanismen zu erstellen oder virtuelle Demonstrationen zu erstellen, wie man Laborinstrumentierung verwendet. Anatomie Studenten können verschiedene Systeme des menschlichen Körpers in drei Dimensionen visualisieren. Mit AR als Werkzeug zum Erlernen anatomischer Strukturen wurde gezeigt, dass das Lernende Wissen erhöht und intrinsische Vorteile wie verstärktes Engagement und Lernende Immersion bietet. Die industrielle Fertigung AR wird verwendet, um Papierhandbücher mit digitalen Anweisungen zu ersetzen, die auf dem Sichtfeld des Herstellers überlagert sind und den mentalen Aufwand reduziert werden müssen. AR macht die Maschinenwartung effizient, weil es den Betreibern direkten Zugriff auf die Wartungsgeschichte einer Maschine gibt. Virtuelle Handbücher helfen Herstellern, sich schnell ändernden Produktdesigns anzupassen, da digitale Anweisungen im Vergleich zu physikalischen Handbüchern einfacher bearbeitet und verteilt werden. Digitale Anweisungen erhöhen die Sicherheit des Bedieners, indem die Notwendigkeit der Bediener, einen Bildschirm oder ein Handbuch weg vom Arbeitsbereich zu betrachten, die gefährlich sein kann. Stattdessen werden die Anweisungen auf dem Arbeitsbereich überlagert. Die Verwendung von AR kann das Sicherheitsgefühl der Bediener bei der Arbeit in der Nähe von hochladenden Industriemaschinen erhöhen, indem den Bedienern zusätzliche Informationen über die Status- und Sicherheitsfunktionen einer Maschine sowie gefährliche Bereiche des Arbeitsraums gegeben werden. Commerce AR wird verwendet, um Print- und Videomarketing zu integrieren. Bedrucktes Marketingmaterial kann mit bestimmten Trigger-Bildern gestaltet werden, die bei der Abtastung durch ein AR-fähiges Gerät mittels Bilderkennung eine Videoversion des Werbematerials aktivieren. Ein wesentlicher Unterschied zwischen augmented Reality und unkomplizierter Bilderkennung ist, dass man mehrere Medien gleichzeitig im Ansichtsbildschirm überlagern kann, wie Social Media Share Buttons, das in-page Video sogar Audio- und 3D-Objekte. Traditionelle Print-Only-Publikationen verwenden eine erweiterte Realität, um verschiedene Medientypen zu verbinden. AR kann Produktvorschauen verbessern, wie es einem Kunden ermöglicht, das zu sehen, was innerhalb einer Produktverpackung ist, ohne es zu öffnen. AR kann auch als Hilfe bei der Auswahl von Produkten aus einem Katalog oder durch einen Kiosk verwendet werden. Gescannte Bilder von Produkten können Ansichten von zusätzlichen Inhalten wie Anpassungsoptionen und zusätzliche Bilder des Produkts in seiner Verwendung aktivieren. Bis 2010 wurden virtuelle Umkleideräume für E-Commerce entwickelt. 2012 nutzte eine Münzstätte AR-Techniken, um eine Gedenkmünze für Aruba zu vermarkten. Die Münze selbst wurde als AR-Trigger verwendet, und als sie vor einem AR-fähigen Gerät gehalten wurde, ergab sie zusätzliche Objekte und Informationsschichten, die ohne das Gerät nicht sichtbar waren. Im Jahr 2018 kündigte Apple die USDZ AR-Dateiunterstützung für iPhones und iPads mit iOS12 an. Apple hat eine AR QuickLook Gallery erstellt, die es Massen ermöglicht, eine erweiterte Realität auf ihrem eigenen Apple-Gerät zu erleben. Im Jahr 2018 kündigte Shopify, das kanadische E-Commerce-Unternehmen, die Integration von ARkit2 an. Ihre Händler sind in der Lage, die Werkzeuge zu verwenden, um 3D-Modelle ihrer Produkte hochzuladen. Benutzer können auf die Waren in Safari tippen, um in ihren realen Umgebungen zu sehen. 2018 veröffentlichte Twinkl eine kostenlose AR-Klassenanwendung. Die Schüler können sehen, wie York vor über 1.900 Jahren aussah. Twinkl startete das erste Multiplayer-AR-Spiel, Little Red und hat über 100 kostenlose AR-Bildermodelle. Augmented Reality wird häufiger für Online-Werbung verwendet. Händler bieten die Möglichkeit, ein Bild auf ihrer Website hochzuladen und "probieren" verschiedene Kleidung, die auf dem Bild überlagert sind. Noch weiter installieren Unternehmen wie Bodymetrics Dressing-Stands in Kaufhäusern, die Vollkörper-Scanning anbieten. Diese Stände machen ein 3-D-Modell des Benutzers, so dass die Verbraucher unterschiedliche Outfits an sich selbst sehen, ohne dass physisch wechselnde Kleidung erforderlich ist. Zum Beispiel verwenden JC Penney und Bloomingdale "virtueller Ankleideraum", die es Kunden ermöglichen, sich in Kleidung zu sehen, ohne sie zu versuchen. Ein weiterer Laden, der AR verwendet, um Kleidung für seine Kunden zu vermarkten, ist Neiman Marcus. Neiman Marcus bietet Verbrauchern die Möglichkeit, ihre Outfits in einer 360-Grad-Ansicht mit ihrem "Memory Spiegel" zu sehen. Make-up-Stores wie L'Oreal, Sephora, Charlotte Tilbury und Rimmel haben auch Apps, die AR nutzen. Diese Apps ermöglichen es den Verbrauchern zu sehen, wie das Make-up auf sie aussehen wird. Laut Greg Jones, Direktor von AR und VR bei Google, wird augmented Reality zu "reconnect physische und digitale Einzelhandel". AR-Technologie wird auch von Möbelhändlern wie IKEA, Houzz und Wayfair verwendet. Diese Händler bieten Apps, die es den Verbrauchern ermöglichen, ihre Produkte in ihrem Haus vor dem Kauf von etwas zu sehen. Im Jahr 2017 kündigte Ikea die Ikea Place App an. Es enthält einen Katalog von über 2.000 Produkten – in der Regel die komplette Kollektion von Sofas, Sesseln, Kaffeetischen und Aufbewahrungseinheiten, die man überall in einem Raum mit ihrem Telefon platzieren kann. Die App ermöglichte es, 3D- und maßstäbliche Möbelmodelle im Wohnraum des Kunden zu haben. IKEA erkannte, dass ihre Kunden nicht in den Läden einkaufen oder direkte Einkäufe mehr tätigen. Die Übernahme von Primer von Shopify, eine AR-App zielt darauf ab, kleine und mittlere Verkäufer in Richtung interaktiven AR-Shopping zu drängen, wobei sowohl Händler als auch Verbraucher leicht AR-Integration und Benutzererfahrung nutzen können. Literatur Die erste Beschreibung von AR, wie es heute bekannt ist, war in Virtual Light, dem Roman von William Gibson von 1994. Im Jahr 2011 wurde AR mit Poesie von ni ka von Sekai Camera in Tokio, Japan, gemischt. Die Prosa dieser AR-Gedichte stammen von Paul Celan, Die Keinesrose, die das Jenseits des Erdbebens von 2011 Tōhoku und Tsunami ausdrückt. Die in der bildenden Kunst angewandte visuelle Kunst AR ermöglicht Objekte oder Orte, künstlerische multidimensionale Erfahrungen und Interpretationen der Realität auszulösen. Augmented Reality kann bei der Entwicklung der bildenden Kunst in Museen helfen, indem Museumsbesucher Kunst in Galerien auf vielfältige Weise durch ihre Telefon-Bildschirme sehen können. Das Museum of Modern Art in New York hat in ihrem Kunstmuseum eine Ausstellung erstellt, die AR-Funktionen zeigt, die Zuschauer mit einer App auf ihrem Smartphone sehen können. Das Museum hat ihre persönliche App, MoMAR Gallery, entwickelt, dass Museumsgäste in der augmented Reality Fachgalerie herunterladen und nutzen können, um die Gemälde des Museums auf eine andere Weise zu sehen. Dies ermöglicht es Einzelpersonen, versteckte Aspekte und Informationen über die Bilder zu sehen und in der Lage, eine interaktive technologische Erfahrung mit Kunstwerken zu haben. AR-Technologie wurde auch in Nancy Baker Cahills "Margin of Error" und Revolutionen eingesetzt, den beiden öffentlichen Kunststücken, die sie für die Desert X Ausstellung 2019 geschaffen hat. Die AR-Technologie unterstützte die Entwicklung der Eye-Tracking-Technologie, um die Augenbewegungen einer Behinderten in Zeichnungen auf einem Bildschirm zu übersetzen. AR-Technologie kann auch verwendet werden, um Objekte in der Umgebung des Benutzers zu platzieren. Ein dänischer Künstler, Olafur Eliasson, stellt Objekte wie brennende Sonnen, außerirdische Felsen und seltene Tiere in die Umgebung des Nutzers. Fitness-AR-Hardware und -Software für den Einsatz in der Fitness umfasst Smart-Brillen für das Radfahren und Laufen, mit Performance-Analysen und Kartennavigation auf das Sichtfeld des Benutzers projiziert, und Boxen, Kampfsport und Tennis, wo die Nutzer weiterhin ihre physische Umgebung für die Sicherheit kennen. Fitness-bezogene Spiele und Software umfassen Pokemon Go und Jurassic World Alive. Human Computer Interaction Interaction ist ein interdisziplinärer Bereich des Computing, der sich mit der Gestaltung und Umsetzung von Systemen befasst, die mit Menschen interagieren. Forscher in HCI kommen aus einer Reihe von Disziplinen, darunter Informatik, Ingenieurwesen, Design, menschlicher Faktor und Sozialwissenschaften, mit einem gemeinsamen Ziel, Probleme im Design und der Nutzung von Technologie zu lösen, so dass es leichter, effektiv, effizient, sicher und mit Zufriedenheit eingesetzt werden kann. Fernkollaboration Primarschulkinder lernen leicht von interaktiven Erfahrungen. Als Beispiel wurden astronomische Konstellationen und die Bewegungen von Objekten im Sonnensystem in 3D orientiert und in Richtung des Gerätes überlagert und mit ergänzenden Videoinformationen erweitert. Papierbasierte Wissenschaftsbuchabbildungen könnten als Video lebendig erscheinen, ohne dass das Kind zu webbasierten Materialien navigieren muss. Im Jahr 2013 wurde ein Projekt auf Kickstarter gestartet, um über Elektronik mit einem Bildungsspielzeug zu lehren, das Kindern erlaubte, ihre Schaltung mit einem iPad zu scannen und den elektrischen Strom zu sehen, der umfließt. Während einige Bildungs-Apps bis 2016 für AR zur Verfügung standen, war es nicht weit verbreitet. Apps, die die erweiterte Realität nutzen, um das Lernen zu helfen, enthalten SkyView für das Studium der Astronomie, AR Circuits für den Aufbau einfacher elektrischer Schaltungen und SketchAr für das Zeichnen. AR wäre auch ein Weg für Eltern und Lehrer, ihre Ziele für die moderne Bildung zu erreichen, die die Bereitstellung individueller und flexibler Lernen, die engere Verbindung zwischen dem, was in der Schule und in der realen Welt gelehrt wird, und den Schülern helfen, sich stärker an ihrem eigenen Lernen zu beteiligen. Notfall-Management/Suche und RettungAugmented Reality-Systeme werden in öffentlichen Sicherheitssituationen verwendet, von Superstürmen bis zu Verdächtigen im großen. Bereits 2009 diskutierten zwei Artikel von Emergency Management die AR-Technologie für das Notfallmanagement. Der erste war "Augmented Reality – Emerging Technology for Emergency Management", von Gerald Baron. Laut Adam Crow: "Technologien wie Augmented Reality (z.B. Google Glass) und die wachsende Erwartung der Öffentlichkeit werden weiterhin professionelle Notfallmanager dazu zwingen, radikal zu verschieben, wenn, wo und wie Technologie vor, während und nach Katastrophen eingesetzt wird."Ein weiteres frühes Beispiel war ein Suchflugzeug, das nach einem verlorenen Wanderer im rauen Berggebiet suchte. Augmented Reality-Systeme lieferten Luftkamera-Betreiber mit einem geographischen Bewusstsein für Waldstraßennamen und Orte, die mit dem Kamera-Video vermischt wurden. Der Kamerabetreiber konnte besser nach dem Wanderer suchen, der den geographischen Kontext des Kamerabildes kennt. Sobald sich der Betreiber befindet, konnte er die Rettungskräfte effizienter an den Standort des Wanderers leiten, da die geographische Lage und die Bezugslandmarken eindeutig gekennzeichnet waren. Die soziale Interaktion AR kann genutzt werden, um die soziale Interaktion zu erleichtern. Ein augmented Reality Social Network Framework namens Talk2Me ermöglicht es den Menschen, Informationen zu verbreiten und andere beworbene Informationen in einer augmented-Reality- Weise zu sehen. Der zeitnahe und dynamische Informationsaustausch und die Sichtbarkeit von Talk2Me helfen, Gespräche zu initiieren und Freunde für Nutzer mit Menschen in körperlicher Nähe zu machen. Die Verwendung eines AR-Headsets kann jedoch die Qualität einer Interaktion zwischen zwei Personen hemmen, wenn man nicht einen trägt, wenn das Headset eine Ablenkung wird. Augmented Reality gibt den Nutzern auch die Möglichkeit, unterschiedliche Formen sozialer Interaktionen mit anderen Menschen in einem sicheren, risikofreien Umfeld zu praktizieren. Hannes Kauffman, Associate Professor für Virtuelle Realität an der TU Wien, sagt: "In der kollaborativen augmented Reality können mehrere Benutzer auf einen gemeinsamen Raum zugreifen, der von virtuellen Objekten besiedelt wird, während sie in der realen Welt geerdet bleiben. Diese Technik ist besonders leistungsstark für pädagogische Zwecke, wenn die Nutzer kollokiert werden und natürliche Kommunikationsmittel (Sprache, Gesten, etc.) verwenden können, aber auch erfolgreich mit immersiver VR oder Remote Collaboration gemischt werden können. " Hannes zitiert Bildung als potenzielle Nutzung dieser Technologie. Videospiele Die Gaming-Branche umfasste AR-Technologie. Für vorbereitete Innenumgebungen wurden eine Reihe von Spielen entwickelt, wie z.B. AR Air Hockey, Titans of Space, kollaborativer Kampf gegen virtuelle Feinde und AR-enhanced Pool Tischspiele. Augmented Reality erlaubt Videospiel-Spieler zu erleben, digitale Spiel spielen in einer realen Weltumgebung. Niantic veröffentlichte das augmented Reality Mobile-Spiel Pokémon Go.Disney hat mit Lenovo zusammengearbeitet, um das augmented Reality-Spiel Star Wars: Jedi Challenges zu schaffen, das mit einem Lenovo Mirage AR Headset, einem Tracking-Sensor und einem Lightsaber-Controller arbeitet, der im Dezember 2017 starten soll. Augmented Reality Gaming (ARG) wird auch verwendet, um Film- und Fernsehunterhaltungseigenschaften zu vermarkten. Am 16. März 2011 förderte BitTorrent eine offene lizenzierte Version des Spielfilms Zenith in den USA. Nutzer, die die BitTorrent Client-Software heruntergeladen haben, wurden ebenfalls dazu ermutigt, Part One von drei Teilen des Films herunterzuladen und zu teilen. Am 4. Mai 2011, Teil Zwei der Filme wurden auf VODO zur Verfügung gestellt. Die episodische Veröffentlichung des Films, ergänzt durch eine ARG Transmedia Marketing Kampagne, hat einen viralen Effekt und über eine Million Benutzer heruntergeladen den Film. Das industrielle Design AR ermöglicht es Industriedesignern, vor der Fertigstellung das Design und den Betrieb eines Produkts zu erleben. Volkswagen hat AR für den Vergleich der berechneten und tatsächlichen Crash-Test-Bilder verwendet. AR wurde verwendet, um Karosseriestruktur und Motorlayout zu visualisieren und zu modifizieren. Es wurde auch verwendet, um digitale Mock-ups mit physischen Mock-ups zu vergleichen, um Diskrepanzen zwischen ihnen zu finden. Gesundheitsplanung, Praxis und Bildung Eines der ersten Anwendungen der erweiterten Realität war im Gesundheitswesen, insbesondere die Planung, Praxis und Ausbildung von chirurgischen Eingriffen zu unterstützen. Bereits 1992 war die Verbesserung der menschlichen Leistung während der Operation ein formell erklärtes Ziel beim Aufbau der ersten erweiterten Realitätssysteme in den U.S. Air Force Labors. Seit 2005 wird ein Gerät namens eines Nah-Infrarot-Adernfinders verwendet, das subkutane Venen, Prozesse und Projekte das Bild der Venen auf die Haut verwendet wurde, um Venen zu lokalisieren. AR bietet Chirurgen mit Patientenüberwachungsdaten im Stil des Head-up-Displays eines Kämpfers Piloten und ermöglicht den Zugriff auf Patientenbildaufnahmen, einschließlich funktionaler Videos, und überlagert werden. Beispiele sind eine virtuelle Röntgenaufnahme basierend auf der Vor-Tomographie oder auf Echtzeit-Bildern von Ultraschall- und konfokalen Mikroskopiesonden, die Visualisierung der Position eines Tumors im Video eines Endoskops oder Strahlenexpositionsrisiken von Röntgenbildgebungsgeräten. AR kann das Betrachten eines Fetus in der Mutterleibsel verbessern. Siemens, Karl Storz und IRCAD haben ein System für laparoskopische Leberchirurgie entwickelt, das AR verwendet, um sub-Oberflächentumoren und Gefäße zu sehen. AR wurde für die Kakerlakenphobie-Behandlung verwendet. Patienten mit augmented Reality-Brillen können an Medikamente erinnert werden. Augmented Reality kann sehr hilfreich im medizinischen Bereich sein. Es könnte verwendet werden, um wichtige Informationen an einen Arzt oder Chirurg zu liefern, ohne dass sie ihre Augen vom Patienten nehmen. Am 30. April 2015 kündigte Microsoft die Microsoft HoloLens, ihren ersten Versuch, die Realität zu verbessern. Die HoloLens hat sich durch die Jahre entwickelt und ist in der Lage, Hologramme für nahe Infrarot-Fluoreszenz-basierte bildgeführte Chirurgie zu projizieren. Als Augmented Reality Fortschritte, findet es immer mehr Anwendungen im Gesundheitswesen. Augmented Reality und ähnliche Computer-basierte Dienstprogramme werden verwendet, um medizinische Fachkräfte zu trainieren. In der Gesundheitsversorgung kann AR dazu verwendet werden, während diagnostische und therapeutische Eingriffe, z.B. während der Operation, zu beraten. Magee et al. beschreiben beispielsweise die Verwendung von erweiterter Realität für medizinisches Training bei der Simulation von Ultraschall geführter Nadelplatzierung. Eine kürzliche Studie von Akçayır, Akçayır, Pektaş und Ocak (2016) ergab, dass AR-Technologie sowohl die Laborfähigkeiten der Universitätsstudenten verbessert und ihnen dabei hilft, positive Einstellungen in Bezug auf Physik-Laborarbeit aufzubauen. Vor kurzem begann die erweiterte Realität, die Annahme in der Neurochirurgie zu sehen, ein Feld, das schwere Mengen der Abbildung vor Verfahren erfordert. Spatial Immersion und Interaktion Augmented Reality-Anwendungen, die auf Handheld-Geräten, die als virtuelle Realität Headsets verwendet werden, können auch die menschliche Präsenz im Raum digitalisieren und ein computergenerierte Modell von ihnen, in einem virtuellen Raum, wo sie verschiedene Aktionen interagieren und durchführen können. Solche Fähigkeiten werden von Project Anywhere, entwickelt von einem Postgraduierten an der ETH Zürich, die als "out-of-body-Erfahrung" bezeichnet wurde, gezeigt. Flugausbildung An der jahrzehntelangen perzeptual-motorischen Forschung in der experimentellen Psychologie nutzten Forscher des Aviation Research Laboratory der Universität Illinois an Urbana-Champaign eine erweiterte Realität in Form eines Flugwegs am Himmel, um Flugstudenten beizubringen, wie man ein Flugzeug mit einem Flugsimulator landet. Ein adaptiver augmentierter Zeitplan, in dem die Schüler die Augmentation nur dann gezeigt haben, wenn sie vom Flugweg abgingen, erwies sich als effektivere Schulungsintervention als ein konstanter Zeitplan. Flugschüler lehrten, im Simulator mit der adaptiven Augmentation zu landen lernte, ein leichtes Flugzeug schneller als Studenten mit der gleichen Menge Landing-Training im Simulator, aber mit konstanter Augmentation oder ohne Augmentation. Militär Eine interessante frühe Anwendung von AR geschah, als Rockwell International Videokarten-Überlagerungen von Satelliten- und Orbital-Debris-Tracks erstellte, um bei Raumbeobachtungen am Air Force Maui Optical System zu helfen. In ihrem 1993 erschienenen Papier "Debris Correlation Using the Rockwell WorldView System" beschreiben die Autoren die Verwendung von Kartenauflagen, die auf Video von Raumüberwachungsteleskopen angewendet werden. Die Kartenauflagen zeigten die Trajektorien verschiedener Objekte in geographischen Koordinaten. Dies erlaubte den Fernrohrbetreibern, Satelliten zu identifizieren und auch potenziell gefährliche Raumverluste zu identifizieren und zu katalogisieren. Die US-Armee hat ab 2003 das SmartCam3D-Augmented-Reality-System in das Shadow Unmanned-Aerial-System integriert, um Sensorbetreibern mit teleskopischen Kameras zu helfen, Menschen oder Sehenswürdigkeiten zu lokalisieren. Das System kombinierte feste geographische Informationen einschließlich Straßennamen, Sehenswürdigkeiten, Flughäfen und Eisenbahnen mit Live-Video aus dem Kamerasystem. Das System bot einen "Bild im Bild"-Modus, der es ermöglicht, eine synthetische Sicht auf die Umgebung des Gesichtsfelds der Kamera anzuzeigen. Dies hilft, ein Problem zu lösen, in dem der Blickfeld so eng ist, dass es wichtige Kontexte ausschließt, als ob "durch einen Soda-Stroh zu schauen". Das System zeigt Echtzeit-Freund/foe/neutrale Ortsmarker, die mit Live-Video gemischt sind und dem Bediener ein verbessertes Situationsbewusstsein bieten. Seit 2010 wollen koreanische Forscher Minenentdeckungsroboter ins Militär umsetzen. Das vorgeschlagene Design für einen solchen Roboter umfasst eine mobile Plattform, die wie eine Spur ist, die in der Lage wäre, unebene Entfernungen einschließlich Treppen abzudecken. Der Minenerkennungssensor des Roboters würde eine Kombination aus Metalldetektoren und bodendurchdringenden Radaren umfassen, um Minen oder IEDs zu lokalisieren. Dieses einzigartige Design wäre unermesslich hilfreich bei der Rettung von Leben koreanischer Soldaten. Forscher am USAF Research Lab (Calhoun, Draper et al.) fanden eine etwa zweifache Erhöhung der Geschwindigkeit, mit der UAV-Sensorbetreiber mit dieser Technologie interessante Punkte gefunden haben. Diese Fähigkeit, das geographische Bewusstsein zu erhalten, erhöht die Missionseffizienz quantitativ. Das System ist auf der US Army RQ-7 Shadow und dem MQ-1C Gray Eagle Unmanned Aerial Systems im Einsatz. Im Kampf kann AR als vernetztes Kommunikationssystem dienen, das in Echtzeit nützliche Schlachtfelddaten auf die Brille eines Soldaten macht. Aus Sicht des Soldaten können Menschen und verschiedene Objekte mit speziellen Indikatoren gekennzeichnet werden, um potenzielle Gefahren zu warnen. Virtuelle Karten und 360°-View-Kamera-Bildgebung können auch zur Unterstützung der Navigations- und Schlachtfeldperspektive eines Soldaten gemacht werden, und dies kann an Militärführer in einem Remote-Befehlszentrum übertragen werden. Die Kombination von 360°-Kameras Visualisierung und AR kann an Bord von Kampffahrzeugen und Tanks als Rundum-Review-System verwendet werden. AR kann sehr effektiv sein, die 3D-Topologien von Munitionslagern im Gelände mit der Wahl der Munitionskombination in Stapeln und Abständen zwischen ihnen mit einer Visualisierung von Risikobereichen praktisch auszugestalten. Der Umfang der AR-Anwendungen umfasst auch die Visualisierung von Daten von eingebetteten Munitionsüberwachungssensoren. Navigation Die NASA X-38 wurde mit einem Hybrid-Synthetik-Visionssystem geflogen, das die Kartendaten auf Video überlagert, um eine verbesserte Navigation für das Raumfahrzeug bei Flugtests von 1998 bis 2002 zu ermöglichen. Es nutzte die LandForm-Software, die für Zeiten begrenzter Sicht nützlich war, einschließlich einer Instanz, wenn das Videokamerafenster über verlassen Astronauten auf die Kartenüberlagerungen gefroren wurde. Die LandForm-Software wurde 1999 auch auf dem Army Yuma Proving Ground getestet. Auf dem Foto auf der rechten Seite kann man die Kartenmarker sehen, die Fahrbahnen, Flugverkehrskontrollturm, Taxis und Hangars auf dem Video überlagert. AR kann die Wirksamkeit von Navigationsgeräten verbessern. Informationen können auf der Windschutzscheibe des Automobils angezeigt werden, die Zielrichtungen und Zähler, Wetter, Gelände, Straßenbedingungen und Verkehrsinformationen angibt, sowie Hinweise auf mögliche Gefahren in ihrem Weg. Seit 2012 entwickelt ein Schweizer Unternehmen WayRay holographische AR-Navigationssysteme, die holographische optische Elemente zur Projektion aller streckenbezogenen Informationen einschließlich Richtungen, wichtigen Benachrichtigungen und interessanten Punkten direkt in die Sichtlinie der Fahrer und weit vor dem Fahrzeug verwenden. An Bord von Seeschiffen kann AR Brückenwächtern ermöglichen, wichtige Informationen wie die Überschrift und Geschwindigkeit eines Schiffes während der gesamten Brücke zu überwachen oder andere Aufgaben auszuführen. Workplace Augmented Reality kann positive Auswirkungen auf die Zusammenarbeit mit der Arbeit haben, da die Menschen dazu neigen, aktiver mit ihrem Lernumfeld zu interagieren. Sie kann auch eine stillschweigende Wissenserneuerung fördern, die Unternehmen wettbewerbsfähiger macht. AR wurde verwendet, um die Zusammenarbeit zwischen verteilten Teammitgliedern über Konferenzen mit lokalen und virtuellen Teilnehmern zu erleichtern. AR-Aufgaben beinhalteten Brainstorming- und Diskussionssitzungen, die eine gemeinsame Visualisierung über Touchscreen-Tabellen, interaktive digitale Whiteboards, gemeinsame Designräume und verteilte Kontrollräume nutzen. In industriellen Umgebungen erweist sich die augmented Reality als substanziell, wenn immer mehr Anwendungsfälle über alle Aspekte des Produktlebenszyklus hinausgehen, angefangen bei der Produktgestaltung und der neuen Produkteinführung (NPI) bis hin zur Herstellung von Service und Wartung, der Materialhandhabung und -verteilung. So wurden beispielsweise Etiketten auf Teilen eines Systems angezeigt, um Betriebsanleitungen für eine mechanische Wartung auf einem System zu klären. Montagelinien profitierten von der Nutzung von AR. Neben Boeing waren BMW und Volkswagen bekannt, diese Technologie in Montagelinien zur Überwachung von Prozessverbesserungen einzubinden. Große Maschinen sind wegen ihrer mehreren Schichten oder Strukturen schwierig zu pflegen. AR ermöglicht es den Menschen, die Maschine zu durchschauen, als ob mit einem Röntgen, sie auf das Problem sofort zeigen. Da sich AR-Technologie entwickelt hat und AR-Geräte der zweiten und dritten Generation auf den Markt kommen, blüht die Wirkung von AR im Unternehmen weiter. In der Harvard Business Review diskutieren Magid Abraham und Marco Annunziata, wie AR-Geräte jetzt verwendet werden, um "die Produktivität der Arbeiter auf einer Reihe von Aufgaben zu erhöhen, die sie zum ersten Mal verwendet werden, auch ohne vorherige Ausbildung". "Diese Technologien erhöhen die Produktivität, indem sie die Arbeitnehmer besser und effizienter machen und so das Potenzial haben, sowohl wirtschaftliches Wachstum als auch bessere Arbeitsplätze zu schaffen." Rundfunk und Live-Events Die Wettervisualisierungen waren die erste Anwendung der erweiterten Realität im Fernsehen. Es ist nun beim Wetter Casting üblich, um Video von Bildern, die in Echtzeit von mehreren Kameras und anderen Bildgebungsgeräten erfasst werden, in voller Bewegung anzuzeigen. Zusammen mit 3D-Grafiken-Symbolen und einem gemeinsamen virtuellen Geospatialmodell sind diese animierten Visualisierungen die erste wahre Anwendung von AR auf TV. AR ist im Sport-Telecasting häufig geworden. Sport- und Unterhaltungseinrichtungen werden mit Durchblick- und Overlay-Augmentation durch Tracked-Kamera-Feeds für eine verstärkte Sichtung durch das Publikum ausgestattet. Beispiele sind die gelbe "erste Down" Linie in Fernsehsendungen von amerikanischen Fußballspielen gesehen, die die Linie zeigen, die das Offensive-Team zu überqueren muss, um einen ersten Down zu erhalten. AR wird auch in Verbindung mit Fußball und anderen sportlichen Veranstaltungen verwendet, um Werbeanzeigen zu zeigen, die auf den Blick auf den Spielbereich überlagert sind. Sektionen von Rugby-Feldern und Kricket-Pitches zeigen auch gesponserte Bilder. Schwimmtelecasts fügen oft eine Linie über die Bahnen, um die Position des aktuellen Plattenhalters als Rennen zu zeigen, damit die Zuschauer das aktuelle Rennen auf die beste Leistung vergleichen können. Weitere Beispiele sind Hockey-Puck-Tracking und Annotationen der Rennwagen-Performance und Snooker-Ball-Trajektorien. AR wurde verwendet, um Konzert- und Theateraufführungen zu verbessern. So erlauben Künstler beispielsweise Hörern, ihre Hörerfahrung zu verbessern, indem sie der anderen Bands/Gruppen von Nutzern ihre Performance hinzufügen. Tourismus und Sightseeing Reisende können AR nutzen, um Echtzeit-Informationsanzeigen über einen Standort, seine Funktionen und Kommentare oder Inhalte von früheren Besuchern zur Verfügung zu stellen. Zu den fortschrittlichen AR-Anwendungen gehören Simulationen historischer Ereignisse, Orte und Objekte, die in die Landschaft gebracht werden. AR-Anwendungen, die mit geographischen Standorten verbunden sind, präsentieren Standortinformationen durch Audio, Ankündigung von Besonderheiten von Interesse an einer bestimmten Website, wie sie für den Benutzer sichtbar werden. Übersetzung AR-Systeme wie Word Lens können den Fremdtext auf Zeichen und Menüs interpretieren und in einer erweiterten Ansicht des Benutzers den Text in der Sprache des Benutzers wiedergeben. Gesprochene Wörter einer Fremdsprache können als gedruckte Untertitel in der Ansicht des Benutzers übersetzt und angezeigt werden. Musik Es wurde vorgeschlagen, dass erweiterte Realität in neuen Methoden der Musikproduktion, Mischen, Steuerung und Visualisierung verwendet werden kann. Ein Werkzeug für die 3D-Musik-Kreation in Clubs, das neben regelmäßigen Sound-Mixing-Funktionen, den DJ Dutzende von Sound-Samples spielen lässt, überall in 3D-Raum platziert, wurde konzipiert. Leeds College of Music Teams haben eine AR-App entwickelt, die mit Audient-Desks verwendet werden kann und es den Studierenden ermöglicht, ihr Smartphone oder Tablet zu benutzen, um Informationen oder Interaktivität auf einem Audient-Mischpult zu platzieren. ARmony ist ein Software-Paket, das die erweiterte Realität nutzt, um Menschen zu helfen, ein Instrument zu lernen. In einem Proof-of-concept-Projekt Ian Sterling, einem Interaktionsdesign-Student am California College of the Arts, und Software-Ingenieur Swaroop Pal demonstrierte eine HoloLens-App, deren Hauptzweck darin besteht, eine 3D-Raum-UI für Cross-Platform-Geräte bereitzustellen – die Android Music Player-App und Arduino-gesteuertes Fan und Licht – und ermöglichen auch Interaktion mit Blick- und Gestensteuerung. AR Mixer ist eine App, die es erlaubt, zwischen Songs durch Manipulation von Objekten auszuwählen und zu mischen – etwa die Orientierung einer Flasche oder Dose zu ändern. In einem Video zeigt Uriel Yehezkel mit dem Leap Motion Controller und GECO MIDI, um Ableton Live mit Handgesten zu steuern und zu sagen, dass er durch diese Methode in der Lage war, mehr als 10 Parameter gleichzeitig mit beiden Händen zu steuern und volle Kontrolle über den Aufbau des Liedes, Emotion und Energie zu übernehmen. Es wurde ein neuartiges Musikinstrument vorgeschlagen, das es den Novizen ermöglicht, elektronische Musikkompositionen zu spielen, ihre Elemente interaktiv zu remixen und zu modulieren, indem einfache physische Objekte manipuliert werden. Ein System mit expliziten Gesten und impliziten Tanzbewegungen, um die visuellen Augmentationen einer Live-Musik-Performance zu kontrollieren, die dynamischere und spontanere Performances und – in Kombination mit indirekter augmentierter Realität – zu einer intensiveren Interaktion zwischen Künstler und Publikum führt. Die Forschung der CRIStAL-Mitglieder an der Universität Lille nutzt die erweiterte Realität, um die musikalische Leistung zu bereichern. Das ControllAR-Projekt ermöglicht es Musikern, ihre MIDI-Steuerflächen mit den remixten grafischen Benutzeroberflächen der Musiksoftware zu erweitern. Das Rouages-Projekt schlägt vor, digitale Musikinstrumente zu erweitern, um ihre Mechanismen für das Publikum zu offenbaren und so die wahrgenommene Lebenheit zu verbessern. Reflets ist eine neuartige augmented-Reality-Anzeige, die musikalischen Performances gewidmet ist, in denen das Publikum als 3D-Display fungiert, indem es virtuelle Inhalte auf der Bühne offenbart, die auch für 3D-Musikinteraktion und Zusammenarbeit verwendet werden können. Snapchat Snapchat-Benutzer haben Zugriff auf erweiterte Realität in der Instant Messaging-App des Unternehmens durch Verwendung von Kamerafiltern. Im September 2017, Snapchat aktualisiert seine App, um einen Kamera-Filter, die Benutzer erlaubt, eine animierte, Cartoon-Version von sich als Bitmoji". Diese animierten Avatare würden in der realen Welt durch die Kamera projiziert und fotografiert oder aufgezeichnet werden. Im selben Monat kündigte Snapchat auch eine neue Funktion namens "Sky Filters" an, die auf seiner App verfügbar sein wird. Diese neue Funktion nutzt die erweiterte Realität, um das Aussehen eines Bildes des Himmels zu ändern, ähnlich wie die Benutzer die Filter der App auf andere Bilder anwenden können. Die Nutzer können aus den Himmelsfiltern wie der Sternennacht, den stürmischen Wolken, den schönen Sonnenuntergängen und dem Regenbogen wählen. Die Gefahren von AR Reality Modifikationen In einem Papier mit dem Titel "Death by Pokémon GO" behaupten Forscher an der Krannert School of Management der Purdue University, dass das Spiel "eine unverhältnismäßige Zunahme der vehicularen Abstürzen und damit verbundene vehiculare Schäden, persönliche Verletzungen und Todesfälle in der Nähe von Orten, genannt PokéStops, wo Benutzer das Spiel während des Fahrens spielen können." Mit Daten aus einer Gemeinde wird das Papier das, was dies bedeuten könnte, bundesweit und abgeschlossen "die Zunahme der Crashs, die auf die Einführung von Pokémon GO zurückzuführen ist 145,632 mit einer damit verbundenen Zunahme der Anzahl der Verletzungen von 29,370 und eine damit verbundene Zunahme der Zahl der Todesfälle von 256 über den Zeitraum vom 6. Juli 2016 bis zum 30. November 2016." Die Autoren extrapolierten die Kosten dieser Abstürzen und Todesfälle zwischen $2bn und $7,3 Milliarden für den gleichen Zeitraum. Darüber hinaus wurden mehr als eins in drei untersuchten fortgeschrittenen Internet-Nutzer möchten störende Elemente um sie herum bearbeiten, wie Müll oder Graffiti. Sie möchten sogar ihre Umgebung ändern, indem sie Straßenschilder, Billboard-Anzeigen und uninteressante Einkaufsfenster löschen. So scheint es, dass AR genauso eine Bedrohung für Unternehmen ist, wie es eine Chance ist. Obwohl dies ein Alptraum für zahlreiche Marken sein könnte, die es nicht schaffen, Verbraucher-Imaginationen zu erfassen, schafft es auch das Risiko, dass die Träger von Augmented Reality Brille kann sich nicht bewusst werden umliegende Gefahren. Verbraucher wollen Augmented Reality-Brille verwenden, um ihre Umgebung in etwas zu ändern, das ihre eigenen persönlichen Meinungen widerspiegelt. Rund zwei in fünf wollen die Art und Weise verändern, wie ihre Umgebung aussehen und sogar wie die Menschen zu ihnen erscheinen. Neben den möglichen Datenschutzproblemen, die unten beschrieben werden, sind Überlast- und Überlastungsprobleme die größte Gefahr von AR. Für die Entwicklung neuer AR-relevanter Produkte bedeutet dies, dass die Benutzeroberfläche bestimmten Richtlinien folgen sollte, um den Benutzer nicht mit Informationen zu überlasten, während der Anwender auch daran gehindert wird, das AR-System zu übertreffen, so dass wichtige Umweltaussichten verpasst werden. Das nennt man den virtuell erweiterten Schlüssel. Sobald der Schlüssel ignoriert wird, können die Menschen die reale Welt nicht mehr wünschen. Datenschutz Das Konzept der modernen Augmented Reality hängt von der Fähigkeit des Gerätes ab, die Umgebung in Echtzeit zu erfassen und zu analysieren. Hierdurch gibt es potenzielle rechtliche Bedenken gegenüber der Privatsphäre. Während der erste Änderungsantrag zur Verfassung der Vereinigten Staaten eine solche Aufnahme im Namen des öffentlichen Interesses ermöglicht, macht die ständige Aufnahme eines AR-Geräts es schwierig, dies zu tun, ohne auch außerhalb des öffentlichen Bereichs zu erfassen. Rechtliche Komplikationen würden in Bereichen gefunden werden, in denen ein Recht auf eine bestimmte Menge an Privatsphäre erwartet wird oder wo urheberrechtlich geschützte Medien angezeigt werden. In Bezug auf die Privatsphäre gibt es die einfache Zugang zu Informationen, die man nicht leicht über eine bestimmte Person besitzen sollte. Dies geschieht durch die Gesichtserkennungstechnologie. Angenommen, dass AR automatisch Informationen über Personen, die der Nutzer sieht, gibt es alles, was aus sozialen Medien, kriminellen Daten und Familienstand gesehen werden könnte. Der Code of Ethics on Human Augmentation, der 2004 von Steve Mann eingeführt und 2013 mit Ray Kurzweil und Marvin Minsky weiter verfeinert wurde, wurde schließlich auf der Virtual Reality Toronto Konferenz am 25. Juni 2017 ratifiziert. Bemerkenswerte Forscher Ivan Sutherland erfand das erste VR-Head-mounted-Display an der Harvard University. Steve Mann formulierte ein früheres Konzept der vermittelten Realität in den 1970er und 1980er Jahren, mit Kameras, Prozessoren und Display-Systemen, um die visuelle Realität zu verändern, um den Menschen zu helfen, bessere (dynamische Range-Management,) zu sehen, computerisierte Schweißhelme zu bauen, sowie "augmediated Reality" Vision-Systeme für den Alltag. Er ist auch Berater für Meta. Louis Rosenberg entwickelte eines der ersten bekannten AR-Systeme, genannt Virtual Fixtures, während er 1991 an den US Air Force Armstrong Labs arbeitete und die erste Studie darüber veröffentlichte, wie ein AR-System die menschliche Leistung verbessern kann. Rosenbergs spätere Arbeit an der Stanford University in den frühen 90er Jahren war der erste Beweis, dass virtuelle Overlays, wenn sie registriert und über die direkte Sicht eines Benutzers auf die reale physische Welt präsentiert werden, die menschliche Leistung deutlich steigern könnten. Mike Abernathy war eine der ersten erfolgreichen augmentierten Video-Overlays (auch Hybrid-Synthetik-Vision genannt) mit Kartendaten für Raumverluste im Jahr 1993, während bei Rockwell International. Er gründete Rapid Imaging Software, Inc. und war 1995 Hauptautor des LandForm-Systems und des SmartCam3D-Systems. LandForm augmented Reality wurde 1999 erfolgreich Flug getestet an Bord eines Hubschraubers und SmartCam3D wurde verwendet, um die NASA X-38 von 1999 bis 2002 zu fliegen. Er und die NASA-Kommissar Francisco Delgado erhielten 2004 die Auszeichnungen der National Defense Industries Association Top5. Steven Feiner, Professor an der Columbia Universität, ist Autor eines 1993 erschienenen Papiers über einen AR-System-Prototypen, KARMA (der wissensbasierte Augmented Reality Maintenance Assistant), zusammen mit Blair MacIntyre und Doree Seligmann. Er ist auch Berater für Meta.S Ravela, B. Draper, J. Lim und A. Hanson entwickelten ein Marker/Fixture-less-Augmented-Reality-System mit Computer Vision im Jahr 1994. Sie erweiterten einen Motorblock, der von einer einzigen Videokamera mit Anmerkungen zur Reparatur beobachtet wurde. Sie verwenden modellbasierte Posenschätzungen, Aspektdiagramme und visuelle Merkmalsverfolgung, um das Modell mit dem beobachteten Video dynamisch zu registrieren. Ronald Azuma ist Wissenschaftler und Autor von bedeutenden AR-Werken, einschließlich einer Umfrage von augmented Reality - der am meisten zitierte Artikel im AR-Bereich und einer der einflussreichsten MIT-Pressepapiere aller Zeiten. Francisco Delgado ist ein NASA-Ingenieur und Projektmanager, der sich auf die menschliche Schnittstellenforschung und -entwicklung spezialisiert hat. Seit 1998 forschte er in Displays, die Video mit synthetischen Visionsystemen (derzeit Hybrid-Synthetik) kombinieren, die wir heute als erweiterte Realitätssysteme zur Kontrolle von Flugzeugen und Raumfahrzeugen erkennen. 1999 testete er und Kollege Mike Abernathy das LandForm-System an Bord eines Hubschraubers der US Army. Delgado übernimmt die Integration der LandForm- und SmartCam3D-Systeme in das X-38 Crew Return Vehicle. Im Jahr 2001 berichtete die Aviation Week, dass die NASA-Astronauten den erfolgreichen Einsatz von hybrider synthetischer Vision (Augmented Reality) bei einem Flugtest im Dryden Flight Research Center auf den X-38 fliegen konnten. Die Technologie wurde bei allen nachfolgenden Flügen des X-38 eingesetzt. Delgado war Mitbewerber der National Defense Industries Association 2004 Top 5 Software des Jahrespreises für SmartCam3D. Bruce H. Thomas und Wayne Piekarski entwickelten 1998 das Tinmith-System. Sie zusammen mit Steve Feiner mit seinem MARS-System Pionier im Freien erweiterte Realität. Mark Billinghurst ist Professor für Human Computer Interaction an der University of South Australia und ein bemerkenswerter AR-Forscher. Er hat über 250 Fachpublikationen produziert und Demonstrationen und Kurse auf einer Vielzahl von Konferenzen präsentiert. Reinhold Behringer führte wichtige frühe Arbeiten (1998) in der Bildregistrierung für augmented Reality und Prototypen verschleißbare Testbetten für augmented Reality durch. Er organisierte auch das erste IEEE International Symposium über Augmented Reality 1998 (IWAR'98) und war mit einem der ersten Bücher über Augmented Reality verbunden. Felix G. Hamza-Lup, Larry Davis und Jannick Rolland entwickelten 2002 das 3D ARC Display mit optischer Durchsicht-Kopf-Bewarnung für die AR-Visualisierung. Dieter Schmalstieg und Daniel Wagner entwickelten 2009 ein Marker-Tracking-System für Mobiltelefone und PDAs. Tracy McSheery, von Phasespace, Entwickler im Jahr 2009 von weitem Blickfeld AR-Objektive wie in Meta 2 und anderen verwendet. Jeri Ellsworth leitete eine Forschungsarbeit für das Valve über augmented Reality (AR) später diese Forschung zu ihrem eigenen Start-up CastAR. Das 2013 gegründete Unternehmen wurde schließlich geschlossen. Später schuf sie einen weiteren Start-up auf der Basis der gleichen Technologie namens Tilt Five; ein weiterer AR-Start-up, der von ihr gebildet wurde, um ein Gerät für digitale Brettspiele zu schaffen. John Tinnell, assoziierter Professor an der Universität Denver, ist Autor von Aktionsmedien:Digitale Kommunikation jenseits des Desktops (2018) und des Co-Editors (mit Sean Morey, Associate Professor an der Universität von Tennessee-Knoxville) von Augmented Reality: Innovative Perspektiven über Kunst, Industrie und Academia (2017). Beide Arbeiten erforschen die Anwendungen der AR-Technologie auf humanitätsbasierte Disziplinen wie visuelle Kunst, Geschichte und öffentliche/professionelle Schrift. Geschichte 1901:L. Frank Baum, Autor, erwähnt zunächst die Idee einer elektronischen Anzeige/Spektakel, die Daten auf das reale Leben überträgt (in diesem Fall Menschen). Es ist ein 'Kennzeichen' genannt.1957–62:Morton Heilig, ein Kameramann, erstellt und patentiert einen Simulator namens Sensorama mit Visualisierungen, Sound, Vibration und Geruch.1968:Ivan Sutherland erfindet das Head-mounted Display und positioniert es als Fenster in eine virtuelle Welt. 1975:Myron Krueger erstellt Videoplace, um Benutzern die Interaktion mit virtuellen Objekten zu ermöglichen. 1980:Die Forschung von Gavan Lintern der Universität Illinois ist die erste veröffentlichte Arbeit, um den Wert eines Heads-up-Displays für die Lehre von real-world Flugfähigkeiten zu zeigen.1980:Steve Mann erstellt den ersten tragbaren Computer, ein Computer Vision-System mit Text und grafischen Overlays auf einer fotografisch vermittelten Szene. 1981:Dan Reitan geospatial kartiert mehrere Wetter-Radar-Bilder und Raum-basierte und Studio-Kameras auf Erdkarten und abstrakte Symbole für Fernseh-Wetterübertragungen, die ein Vorläufer-Konzept der erweiterten Realität (gemischte real/graphische Bilder) zu TV.1986: In IBM beschreibt Ron Feigenblatt heute die erfahrenste Form von AR (viz. "magic windows", z.B. Smartphone-basierte Pokémon Go), die Verwendung eines kleinen, intelligenten Flat Panel-Displays, das von Hand positioniert und ausgerichtet ist.1987: Douglas George und Robert Morris schaffen einen funktionierenden Prototyp eines astronomischen teleskopbasierten "Heads-up-Display"-Systems (ein Vorläufer-Konzept zur erweiterten Realität), das im Teleskop-Okular überlagert ist, über die tatsächlichen Himmelbilder, Multi-Intensity-Star und Himmelskörperbilder und andere relevante Informationen. 1990:Der Begriff der erweiterten Realität wird Thomas P. Caudell, ein ehemaliger Boeing-Forscher, zugeschrieben. 1992:Louis Rosenberg entwickelte eines der ersten funktionierenden AR-Systeme, genannt Virtual Fixtures, am United States Air Force Research Laboratory – Armstrong, die den Nutzen für die menschliche Wahrnehmung gezeigt haben. 1992:Steven Feiner, Blair MacIntyre und Doree Seligmann präsentieren auf der Graphics Interface Konferenz einen frühen Beitrag zu einem AR-System-Prototypen KARMA. 1993:CMOS-Aktivpixel-Sensor, ein Typ von Metall-Oxid-Halbleiter (MOS)-Bildsensor, entwickelt am Jet Propulsion Laboratory der NASA. CMOS-Sensoren werden später in AR-Technik weit verbreitet für optisches Tracking eingesetzt.1993:Mike Abernathy, et al.,. berichten die erste Verwendung von augmented Reality bei der Identifizierung von Raumverlusten mit Rockwell WorldView durch Überlagerung von Satelliten geographischen Trajektorien auf Live-Teleskop-Video.1993: Eine allgemein zitierte Version des oben genannten Papiers wird in Kommunikation der ACM veröffentlicht – Sonderausgabe über Computer erweiterte Umgebungen, herausgegeben von Pierre Wellner, Wendy Mackay und Rich Gold. 1993:Loral WDL, mit Sponsoring von STRICOM, führte die erste Demonstration durch, die live AR-equippte Fahrzeuge und bemannte Simulatoren kombinierte. Unveröffentlichtes Papier, J. Barrilleaux, "Erfahrungen und Beobachtungen in der Anwendung Augmented Reality to Live Training", 1999. 1994:Julie Martin schafft erste "Augmented Reality Theater Produktion", Tanzen im Cyberspace, gefördert vom Australien Council for the Arts, bietet Tänzer und Acrobats, die in Echtzeit physische Raum- und Leistungsebenen manipulieren. Die Akrobaten tauchten in das virtuelle Objekt und Umgebungen ein. Die Installation verwendete Silicon Graphics Computer und Polhemus Sensorsystem. 1995: S. Ravela et al.at University of Massachusetts führt ein visionsbasiertes System ein, das monokulare Kameras verwendet, um Objekte (Motorblöcke) über Ansichten für eine erweiterte Realität zu verfolgen.1998: Terrasse erweiterte Realität, die an der University of North Carolina in Chapel Hill von Ramesh Raskar, Welch, Henry Fuchs vorgestellt wird. 1999: Frank Delgado, Mike Abernathy et al. 1999: Das US Naval Research Laboratory beteiligt sich an einem zehnjährigen Forschungsprogramm, das Battlefield Augmented Reality System (BARS) genannt wird, um einige der frühen Wearable-Systeme für dismounted Soldat, die im städtischen Umfeld für Situationsbewusstsein und Schulungen tätig sind, zu Prototypen. 1999: NASA X-38 geflogen mit LandForm-Software-Videokarte Overlays im Dryden Flight Research Center. 2000: Rockwell International Science Center zeigt etherlose tragbare Augmented-Reality-Systeme, die analoges Video und 3-D-Audio über Hochfrequenz-WLAN-Kanäle empfangen. Die Systeme enthalten Navigationsfunktionen im Freien, mit digitalen Horizont Silhouetten aus einer Geländedatenbank, die in Echtzeit auf der Live-Außenszene überlaint wird, wodurch die Visualisierung von Gelände durch Wolken und Nebel unsichtbar gemacht wird.2004: Außenhelm-montiertes AR-System, das von Trimble Navigation und dem Human Interface Technology Laboratory (HIT Lab) demonstriert wurde.2006: Outland Research entwickelt AR-Media-Player, der virtuelle Inhalte auf eine Benutzeransicht der realen Welt synchron mit Spielmusik überlagert und so ein immersives AR-Entertainment-Erlebnis bietet. 2008:Wikitude AR Travel Guide startet am 20. Okt 2008 mit dem G1 Android-Handy.2009:ARToolkit wurde an Adobe Flash (FLARToolkit) von Saqoosha portiert und bringt erweiterte Realität in den Webbrowser. 2010:Design von Minenerkennungsroboter für koreanisches Minenfeld.2012:Launch of Lyteshot, eine interaktive AR-Gaming-Plattform, die Smart-Brillen für Spieldaten nutzt 2013: Mina Luna Erstellte den ersten Modefilm mit erweiterter Realität. 2015:Microsoft kündigt an Windows Holographic und die HoloLens erweitert Realität Headset. Das Headset verwendet verschiedene Sensoren und eine Verarbeitungseinheit, um hochauflösende Hologramme mit der realen Welt zu vermischen. 2016:Niantic veröffentlicht Pokémon Go für iOS und Android im Juli 2016. Das Spiel wurde schnell zu einer der beliebtesten Smartphone-Anwendungen und wiederum spikes die Popularität der erweiterten Realität Spiele. 2017:Magic Leap kündigt die Verwendung von Digital Lightfield-Technologie an, die in das Magic Leap One Headset eingebettet ist. Das Urheber-Edition-Headset beinhaltet die Brille und ein auf Ihrem Gürtel getragenes Computing-Pack. 2019:Microsoft kündigt an HoloLens 2 mit deutlichen Verbesserungen im Bereich der Sicht und Ergonomie. Siehe auch Referenzen Externe Links Medien im Zusammenhang mit Augmented Reality bei Wikimedia Commons