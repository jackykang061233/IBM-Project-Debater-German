Informatik ist die Untersuchung algorithmischer Prozesse, Rechenmaschinen und Berechnungen selbst. Als Disziplin umfasst die Informatik eine Reihe von Themen von theoretischen Studien von Algorithmen, Berechnungen und Informationen zu den praktischen Fragen der Implementierung von Rechensystemen in Hardware und Software. Seine Felder können in theoretische und praktische Disziplinen unterteilt werden. Zum Beispiel betrifft die Berechnungstheorie abstrakte Modelle der Berechnung und allgemeine Klassen von Problemen, die mit ihnen gelöst werden können, während Computergrafiken oder Rechengeometrie spezifischere Anwendungen betonen. Algorithmen und Datenstrukturen wurden als Herz der Informatik bezeichnet. Die Programmiersprachetheorie betrachtet Ansätze zur Beschreibung von Rechenprozessen, während die Computer-Programmierung die Verwendung von ihnen zur Erstellung komplexer Systeme beinhaltet. Computerarchitektur beschreibt den Aufbau von Computerkomponenten und computerbetriebenen Geräten. Künstliche Intelligenz zielt darauf ab, zielorientierte Prozesse wie Problemlösung, Entscheidungsfindung, Umweltanpassung, Planung und Lernen von Menschen und Tieren zu synthetisieren. Ein digitaler Computer kann verschiedene Informationsprozesse simulieren. Die grundlegende Sorge der Informatik ist die Bestimmung, was automatisiert werden kann und kann. Informatiker konzentrieren sich in der Regel auf akademische Forschung. Der Turing Award wird in der Regel als höchste Auszeichnung in Informatik anerkannt. Geschichte Die frühesten Grundlagen dessen, was zur Informatik werden würde, prägen die Erfindung des modernen digitalen Computers. Maschinen zur Berechnung fester numerischer Aufgaben, wie z.B. des Abacus, sind seit der Antike vorhanden, die bei Berechnungen wie Multiplikation und Division helfen. Algorithmen für die Durchführung von Berechnungen existieren seit der Antike, auch vor der Entwicklung von anspruchsvollen Rechenmaschinen. Wilhelm Schickard entwarf 1623 den ersten mechanischen Rechenrechner. Im Jahre 1673 zeigte Gottfried Leibniz einen digitalen mechanischen Rechner, genannt Stepped Reckoner. Leibniz kann als erster Informatiker und Informationstheoretiker betrachtet werden, aus anderen Gründen das binäre Zahlensystem dokumentieren. Im Jahr 1820 startete Thomas de Colmar die mechanische Rechnerindustrie, als er sein vereinfachtes Rechenwerk erfand, die erste Rechenmaschine stark genug und zuverlässig genug, um täglich in einer Büroumgebung eingesetzt zu werden. Charles Babbage begann im Jahre 1822 das Design des ersten automatischen mechanischen Rechners, seiner Difference Engine, der ihm schließlich die Idee des ersten programmierbaren mechanischen Rechners, seiner Analytical Engine gab. Er begann diese Maschine 1834 zu entwickeln, und "in weniger als zwei Jahren hatte er viele der entfremdeten Merkmale des modernen Computers skizziert". " Ein entscheidender Schritt war die Annahme eines von der Jacquardwebmaschine abgeleiteten Lochkartensystems", das es unendlich programmierbar macht. Im Jahre 1843 schrieb Ada Lovelace während der Übersetzung eines französischen Artikels über die Analytische Maschine in einer der vielen Notizen, die sie beinhaltete, einen Algorithmus, um die Bernoulli Zahlen zu berechnen, die als der erste veröffentlichte Algorithmus angesehen wird, der je speziell auf die Implementierung auf einem Computer zugeschnitten ist. Um 1885 erfand Herman Hollerith den Tabulator, der gestanzte Karten verwendet, um statistische Informationen zu verarbeiten; schließlich wurde sein Unternehmen Teil von IBM. Nach Babbage, obwohl er sich seiner früheren Arbeit nicht bewusst war, veröffentlichte Percy Ludgate 1909 den 2. der beiden Entwürfe für mechanische analytische Motoren in der Geschichte. 1937, hundert Jahre nach Babbages unmöglichem Traum, überzeugte Howard Aiken IBM, die alle Arten von gestanzten Kartenausrüstungen machte und auch im Taschenrechner-Geschäft war, seinen riesigen programmierbaren Taschenrechner zu entwickeln, den ASCC/Harvard Mark I, basierend auf Babbages Analytical Engine, der selbst Karten und eine zentrale Recheneinheit verwendet. Als die Maschine fertig war, riefen einige sie als "Babbages Traum wahr werden". Während der 1940er Jahre, mit der Entwicklung neuer und leistungsfähiger Rechenmaschinen wie dem Atanasoff-Berry-Computer und ENIAC, wurde der Begriff Computer auf die Maschinen und nicht auf ihre menschlichen Vorgänger bezogen. Wie deutlich wurde, dass Computer für mehr als nur mathematische Berechnungen verwendet werden konnten, erweiterte sich der Bereich der Informatik, um die Berechnung im Allgemeinen zu studieren. 1945 gründete IBM das Watson Scientific Computing Laboratory an der Columbia University in New York City. Das renovierte Bruderschaftshaus auf Manhattans West Side war IBMs erstes Labor, das der reinen Wissenschaft gewidmet ist.Das Labor ist der Vorläufer der IBM Research Division, die heute weltweit Forschungseinrichtungen betreibt. Letztendlich war die enge Beziehung zwischen IBM und der Universität maßgeblich an der Entstehung einer neuen wissenschaftlichen Disziplin, wobei Columbia 1946 eine der ersten akademischen Akkreditierungen in der Informatik anbietet. Die Informatik begann in den 1950er und frühen 1960er Jahren als eigenständige akademische Disziplin zu etablieren. Das weltweit erste Informatikstudium, das Cambridge Diploma in Informatik, begann 1953 an der Universität Cambridge Computer Laboratory. Die erste Informatikabteilung in den Vereinigten Staaten wurde 1962 an der Purdue University gegründet. Da praktische Computer verfügbar wurden, sind viele Anwendungen des Computing in ihren eigenen Rechten zu unterschiedlichen Studienbereichen geworden. Etymologie Obwohl zunächst 1956 vorgeschlagen, erscheint der Begriff "Computerwissenschaft" in einem 1959 Artikel in Kommunikation der ACM, in dem Louis Fein für die Schaffung einer Graduate School in Informatik analog zur Gründung der Harvard Business School im Jahr 1921 argumentiert, indem er argumentiert, dass, wie Management-Wissenschaft, das Thema angewandt wird und interdisziplinäre in der Natur, während die charakteristischen Merkmale einer akademischen Disziplin. Seine Bemühungen, und die von anderen wie numerischen Analysten George Forsythe, wurden belohnt: Universitäten gingen an, solche Abteilungen zu schaffen, beginnend mit Purdue im Jahr 1962. Trotz seines Namens beinhaltet eine erhebliche Menge an Informatik nicht die Studie der Computer selbst. Dadurch wurden mehrere alternative Namen vorgeschlagen. Bestimmte Abteilungen von großen Universitäten bevorzugen den Begriff Informatik, um genau diesen Unterschied zu betonen. Dänischer Wissenschaftler Peter Naur schlug den Begriff Datalogy vor, um zu reflektieren, dass die wissenschaftliche Disziplin um Daten und Datenbehandlung dreht, während nicht notwendigerweise Computer eingebunden. Die erste wissenschaftliche Einrichtung, die den Begriff nutzte, war die Abteilung für Datalogie an der Universität Kopenhagen, gegründet 1969, und Peter Naur ist der erste Professor in der Datalogie. Der Begriff wird hauptsächlich in den skandinavischen Ländern verwendet. Ein alternativer Begriff, der auch von Naur vorgeschlagen wird, ist die Datenwissenschaft, die jetzt für ein multidisziplinäres Gebiet der Datenanalyse, einschließlich Statistiken und Datenbanken verwendet wird. In den frühen Tagen des Computings wurden eine Reihe von Begriffen für die Praktizierenden des Bereichs Computing in den Mitteilungen des ACM -Turingineer, Turologe, Flussdiagramme-Mann, angewandte Meta-Mathematiker und angewandte Epistemologin vorgeschlagen. Drei Monate später in der gleichen Zeitschrift wurde Comptologist vorgeschlagen, gefolgt von Hypologist im nächsten Jahr. Der Begriff Computics wurde ebenfalls vorgeschlagen. In Europa werden oft Begriffe verwendet, die sich aus vertraglichen Übersetzungen des Ausdrucks "automatische Information" (z.B. "informazione automatica" in Italienisch) oder "Information und Mathematik" ergeben, z.B. informatique (Französisch), Informatik (Deutsch,) informatica (Italienisch, Niederländisch), informática (Spanisch, Portugiesisch,) informatika (Slavic languages und Ungarisch) oder plr. Ähnliche Wörter wurden auch in Großbritannien (wie in der School of Informatics, University of Edinburgh) angenommen. " In den USA ist die Informatik jedoch im Kontext einer anderen Domäne mit dem angewandten Computing verknüpft. " Ein volkstümliches Zitat, das oft auf – aber fast sicher nicht zuerst formuliert von – Edsger Dijkstra zurückzuführen ist, besagt, dass "Computerwissenschaft ist nicht mehr über Computer als Astronomie über Teleskope." Der Aufbau und der Einsatz von Computern und Computersystemen gilt in der Regel als die Provinz der Disziplinen außer der Informatik. Zum Beispiel wird die Studie der Computerhardware in der Regel als Teil der Computertechnik betrachtet, während die Studie von kommerziellen Computersystemen und deren Bereitstellung oft als Informationstechnologie oder Informationssysteme bezeichnet wird. Zwischen den verschiedenen rechnerbezogenen Disziplinen gab es jedoch viel Überdüngung von Ideen. Informatik Forschung schneidet auch oft andere Disziplinen, wie Philosophie, kognitive Wissenschaft, Linguistik, Mathematik, Physik, Biologie, Erdwissenschaft, Statistik und Logik. Informatik wird von einigen betrachtet, um eine viel engere Beziehung mit Mathematik als viele wissenschaftliche Disziplinen zu haben, mit einigen Beobachtern sagen, dass Computing eine mathematische Wissenschaft ist. Die frühe Informatik wurde stark beeinflusst von der Arbeit von Mathematikern wie Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter und Alonzo Kirche und es gibt weiterhin einen nützlichen Austausch von Ideen zwischen den beiden Bereichen wie mathematische Logik, Kategorie Theorie, Domänentheorie und Algebra.Die Beziehung zwischen Informatik und Software Engineering ist ein beständiges Problem, das durch Streitigkeiten darüber, was der Begriff "Software Engineering" bedeutet, weiter verschleiert wird und wie Informatik definiert wird. David Parnas, der sich aus der Beziehung zwischen anderen Ingenieur- und Wissenschaftsdisziplinen zusammensetzt, hat behauptet, dass der Hauptfokus der Informatik die Eigenschaften der Berechnung im Allgemeinen untersucht, während der Hauptfokus der Software-Engineering die Gestaltung spezifischer Berechnungen ist, um praktische Ziele zu erreichen, die die beiden separaten, aber komplementären Disziplinen. Die akademischen, politischen und finanziellen Aspekte der Informatik hängen davon ab, ob eine Abteilung mit einem mathematischen Schwerpunkt oder mit einem technischen Schwerpunkt gebildet wird. Informatik-Abteilungen mit einer Mathematik Betonung und mit einer numerischen Ausrichtung betrachten die Ausrichtung mit der rechnerischen Wissenschaft. Beide Arten von Abteilungen neigen dazu, Anstrengungen zu unternehmen, um das Feld pädagogisch zu überbrücken, wenn nicht über alle Forschungen. Philosophie Eine Reihe von Informatikern haben für die Unterscheidung von drei getrennten Paradigmen in der Informatik argumentiert. Peter Wegner argumentierte, dass diese Paradigmen sind Wissenschaft, Technologie und Mathematik. Peter Dennings Arbeitsgruppe argumentierte, dass sie Theorie, Abstraktion (Modellierung) und Design seien. Amnon H. Eden beschrieb sie als "rationalistisches Paradigma" (das Informatik als Zweig der Mathematik behandelt, die in der theoretischen Informatik vorherrscht und vor allem deduktive Argumentation verwendet), das "technokratische Paradigma" (die in Ingenieursansätzen, vor allem in der Software-Engineering, gefunden werden könnte) und das "wissenschaftliche Paradigma" (die sich auf computerbezogene Artefakte aus den naturwissenschaftlichen nähert. Die Informatik konzentriert sich auf Methoden, die in Design, Spezifikation, Programmierung, Verifikation, Implementierung und Test von human-made-Computing-Systemen beteiligt sind. Felder Informatik ist nicht mehr über Computer als Astronomie geht es um Teleskope. Als Disziplin umfasst die Informatik eine Reihe von Themen von theoretischen Studien von Algorithmen und den Grenzen der Berechnung bis zu den praktischen Fragen der Implementierung von Rechensystemen in Hardware und Software. CSAB, ehemaliger Computing Sciences Accreditation Board – bestehend aus Vertretern der Association for Computing Machinery (ACM) und der IEEE Computer Society (IEEE CS) – identifiziert vier Bereiche, die für die Disziplin der Informatik entscheidend sind: Theorie der Berechnung, Algorithmen und Datenstrukturen, Programmiermethodik und Sprachen, Computerelemente und Architektur. Zusätzlich zu diesen vier Bereichen identifiziert CSAB auch Bereiche wie Software-Engineering, Künstliche Intelligenz, Computer-Netzwerk und Kommunikation, Datenbanksysteme, Parallelrechnung, verteilte Berechnung, Mensch-Computer-Interaktion, Computer-Grafiken, Betriebssysteme, numerische und symbolische Berechnung als wichtige Bereiche der Informatik. Theoretische Informatik Theoretische Informatik ist mathematisch und abstrakt im Geist, aber es leitet seine Motivation aus der praktischen und alltäglichen Berechnung. Ihr Ziel ist es, die Art der Berechnung zu verstehen und als Folge dieses Verständnisses effizientere Methoden bereitzustellen. Berechnungstheorie Nach Peter Denning ist die grundlegende Frage der Informatik: "Was kann automatisiert werden?" Die Berechnungstheorie konzentriert sich auf die Beantwortung grundlegender Fragen über das, was berechnet werden kann und welche Ressourcen benötigt werden, um diese Berechnungen durchzuführen. Um die erste Frage zu beantworten, untersucht die Berechnungstheorie, welche Rechenprobleme auf verschiedenen theoretischen Berechnungsmodellen auflösbar sind. Die zweite Frage wird von der rechnerischen Komplexitätstheorie behandelt, die die Zeit- und Raumkosten untersucht, die mit unterschiedlichen Ansätzen verbunden sind, um eine Vielzahl von rechnerischen Problemen zu lösen. Das berühmte P = NP?Problem, eines der Millennium Prize Probleme, ist ein offenes Problem in der Berechnungstheorie. Information und Codierung Theorie Informationstheorie, eng mit Wahrscheinlichkeit und Statistik verbunden, ist mit der Quantifizierung von Informationen. Dies wurde von Claude Shannon entwickelt, um grundlegende Grenzen für Signalverarbeitungsvorgänge zu finden, wie z.B. Komprimierung von Daten und zuverlässige Speicherung und Übermittlung von Daten. Coding-Theorie ist die Untersuchung der Eigenschaften von Codes (Systeme zur Umwandlung von Informationen von einer Form in eine andere) und ihre Eignung für eine bestimmte Anwendung.Codes werden für die Datenkompression, Kryptographie, Fehlererkennung und Korrektur verwendet, und vor kurzem auch für die Netzwerkcodierung. Kodizes werden untersucht, um effiziente und zuverlässige Datenübertragungsmethoden zu entwickeln. Datenstrukturen und Algorithmen Datenstrukturen und Algorithmen sind die Studien von allgemein verwendeten Rechenmethoden und deren Recheneffizienz. Programmiersprache Theorie und formale Methoden Die Programmiersprachetheorie ist ein Zweig der Informatik, der sich mit dem Design, der Implementierung, der Analyse, der Charakterisierung und der Klassifizierung von Programmiersprachen und deren individuellen Merkmalen befasst. Es fällt in die Disziplin der Informatik, sowohl abhängig von und beeinflussen Mathematik, Software-Engineering und Linguistik. Es ist ein aktives Forschungsgebiet, mit zahlreichen engagierten akademischen Zeitschriften. Formale Methoden sind eine besondere Art mathematisch basierter Technik zur Spezifikation, Entwicklung und Überprüfung von Software- und Hardwaresystemen. Der Einsatz formaler Methoden für Software- und Hardware-Design wird durch die Erwartung motiviert, dass, wie in anderen Ingenieursdisziplinen, eine entsprechende mathematische Analyse zur Zuverlässigkeit und Robustheit eines Designs beitragen kann. Sie bilden eine wichtige theoretische Untermauerung für Software-Engineering, vor allem bei der Sicherheit oder Sicherheit. Formale Methoden sind eine nützliche Ergänzung zu Software-Tests, da sie helfen, Fehler zu vermeiden und können auch einen Rahmen für Tests geben. Für den industriellen Einsatz ist eine Werkzeugunterstützung erforderlich. Die hohen Kosten für die Verwendung formaler Methoden bedeuten jedoch, dass sie in der Regel nur bei der Entwicklung hochintegritäts- und lebenskritischer Systeme eingesetzt werden, wo Sicherheit oder Sicherheit von größter Bedeutung ist. Formale Methoden werden am besten als Anwendung einer ziemlich breiten Vielfalt von theoretischen Informatik-Grundlagen, insbesondere Logik-Kalkuli, formale Sprachen, Automata-Theorie und Programm-Semantik beschrieben, aber auch Typ-Systeme und algebraische Datentypen zu Problemen in der Software und Hardware-Spezifikation und Verifikation. Computersysteme und Rechenprozesse Künstliche Intelligenz Künstliche Intelligenz (KI) zielt darauf ab, zielgerichtete Prozesse wie Problemlösung, Entscheidungsfindung, Umweltanpassung, Lernen und Kommunikation, die in Menschen und Tieren gefunden werden, zu synthetisieren. Von seinen Ursprüngen in der Kybernetik und in der Dartmouth-Konferenz (1956) war künstliche Intelligenz Forschung notwendigerweise disziplinär, auf Gebieten der Fachkompetenz wie angewandte Mathematik, symbolische Logik, Semiotik, Elektrotechnik, Philosophie des Geistes, Neurophysiologie und soziale Intelligenz. KI ist im populären Geist mit der robotischen Entwicklung verbunden, aber das Hauptfeld der praktischen Anwendung war als eingebettete Komponente in Bereichen der Softwareentwicklung, die ein rechnerisches Verständnis erfordern. Der Ausgangspunkt in den späten 1940er Jahren war Alan Turings Frage "Kann Computer denken?," und die Frage bleibt effektiv unbeantwortet, obwohl der Turing-Test noch verwendet wird, um die Computerausgabe auf der Ebene der menschlichen Intelligenz zu bewerten. Aber die Automatisierung von evaluativen und prädiktiven Aufgaben wurde zunehmend erfolgreich als Ersatz für die menschliche Überwachung und Intervention in Computeranwendungen mit komplexen realen Daten. Computer-Architektur und Organisation Computer-Architektur oder digitale Computer-Organisation, ist das konzeptionelle Design und grundlegende operative Struktur eines Computersystems. Es konzentriert sich weitgehend auf die Art und Weise, wie die zentrale Verarbeitungseinheit intern ausführt und auf Adressen im Speicher zugreift. Computer-Ingenieure studieren Rechenlogik und Design von Computer-Hardware, von einzelnen Prozessorkomponenten, Mikrocontrollern, Personalcomputern bis hin zu Supercomputern und Embedded Systemen. Der Begriff "Architektur" in der Computerliteratur kann auf die Arbeit von Lyle R. Johnson und Frederick P. Brooks, Jr., Mitglieder der Abteilung Machine Organization in IBM Hauptforschungszentrum im Jahr 1959 zurückgeführt werden. Gleichzeitige, parallele und verteilte Berechnung Konkurrenz ist eine Eigenschaft von Systemen, in denen mehrere Berechnungen gleichzeitig durchgeführt werden und potenziell miteinander interagieren. Eine Reihe von mathematischen Modellen wurden für die allgemeine gleichzeitige Berechnung entwickelt, einschließlich Petri Netze, Prozessrechnung und das Parallel Random Access Machine Modell. Wenn mehrere Computer in einem Netzwerk unter Verwendung von Konkurs verbunden sind, wird dies als verteiltes System bekannt. Computer innerhalb dieses verteilten Systems haben einen eigenen privaten Speicher, und Informationen können ausgetauscht werden, um gemeinsame Ziele zu erreichen.Computernetze Dieser Zweig der Informatik zielt darauf ab, Netzwerke zwischen Computern weltweit zu verwalten. Computer-Sicherheit und Kryptographie Computer-Sicherheit ist ein Zweig der Computer-Technologie mit dem Ziel, Informationen vor unbefugtem Zugriff, Störung oder Änderung zu schützen, während die Zugänglichkeit und Verwendbarkeit des Systems für seine beabsichtigten Benutzer. Kryptographie ist die Praxis und Studie des Verstecks (Verschlüsselung) und damit Entschlüsselung (Entschlüsselung) Informationen. Moderne Kryptographie ist weitgehend mit der Informatik verbunden, denn viele Verschlüsselungs- und Entschlüsselungsalgorithmen basieren auf ihrer rechnerischen Komplexität. Datenbanken und Data Mining Eine Datenbank soll große Datenmengen leicht organisieren, speichern und abrufen. Digitale Datenbanken werden mit Datenbankverwaltungssystemen verwaltet, um Daten über Datenbankmodelle und Abfragesprachen zu speichern, zu erstellen, zu pflegen und zu suchen. Data Mining ist ein Prozess der Entdeckung von Mustern in großen Datensätzen. Computergrafiken und Visualisierung Computergrafiken sind die Studie von digitalen visuellen Inhalten und beinhaltet die Synthese und Manipulation von Bilddaten. Die Studie ist mit vielen anderen Bereichen in der Informatik verbunden, einschließlich Computer Vision, Bildverarbeitung und Rechengeometrie, und wird stark in den Bereichen Spezialeffekte und Videospiele angewendet. Bild- und Tonverarbeitung Informationen können in Form von Bildern, Ton, Video oder anderen Multimedia. Über Signale können Informationen gestreamt werden. Seine Verarbeitung ist der zentrale Begriff der Informatik, die europäische Sicht auf das Computing, die Informationsverarbeitung Algorithmen unabhängig von der Art des Informationsträgers untersucht - sei es elektrisch, mechanisch oder biologisch. Dieses Feld spielt eine wichtige Rolle in der Informationstheorie, in der Telekommunikation, in der Informationstechnik und hat Anwendungen in der medizinischen Bild- und Sprachsynthese, unter anderem. Was ist die untere Begrenzung der Komplexität von schnellen Fourier-Transformationsalgorithmen? ist eines der ungelösten Probleme in der theoretischen Informatik. Angewandte Informatik Informatik Informatik Informatik, Finanzen und Ingenieurwissenschaften Wissenschaftliches Rechnen (oder Rechenwissenschaft) ist der Bereich der Studie, um mathematische Modelle und quantitative Analysetechniken zu konstruieren und Computer zur Analyse und Lösung wissenschaftlicher Probleme zu verwenden. Eine große Nutzung der wissenschaftlichen Berechnung ist die Simulation von verschiedenen Prozessen, darunter rechnerische Fluiddynamik, physikalische, elektrische und elektronische Systeme und Schaltungen, sowie Gesellschaften und soziale Situationen (insbesondere Kriegsspiele) zusammen mit ihren Lebensräumen, unter vielen anderen. Moderne Computer ermöglichen die Optimierung von Designs wie komplette Flugzeuge. Bemerkenswert in der elektrischen und elektronischen Schaltung sind SPICE, sowie Software zur physikalischen Realisierung neuer (oder modifizierter) Designs. Letztere enthält eine wesentliche Designsoftware für integrierte Schaltungen. Social Computing und Mensch-Computer-InteraktionSocial Computing ist ein Bereich, der sich mit der Schnittstelle von Sozialverhalten und Rechensystemen beschäftigt. Human-Computer-Interaktionsforschung entwickelt Theorien, Prinzipien und Richtlinien für Benutzeroberflächendesigner. Software Engineering Software Engineering ist die Studie der Entwicklung, Implementierung und Änderung der Software, um sicherzustellen, dass es von hoher Qualität, erschwinglich, pflegefähig und schnell zu bauen. Es ist ein systematischer Ansatz für Softwaredesign, der die Anwendung von Engineering-Praktiken auf Software beinhaltet. Software-Engineering beschäftigt sich mit der Organisation und Analyse von Software – es geht nicht nur um die Erstellung oder Herstellung neuer Software, sondern um ihre interne Anordnung und Wartung. Zum Beispiel Softwaretests, Systemtechnik, technische Schulden und Softwareentwicklungsprozesse. Entdeckungen Der Philosoph des Computers Bill Rapaport bemerkte drei große Einblicke in die Informatik: Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's und Samuel Morse's Einsicht: Es gibt nur zwei Objekte, mit denen ein Computer zu tun hat, um alles zu vertreten." Alle Informationen über jedes rechnerische Problem können mit nur 0 und 1 dargestellt werden (oder jedes andere bistabile Paar, das zwischen zwei leicht unterscheidbaren Zuständen, wie z.B. on/off, magnetisiert/de-magnetisiert, Hoch-Spannung/Niederspannung etc., Flip-Flop kann). Alan Turings Einsicht: Es gibt nur fünf Aktionen, die ein Computer durchführen muss, um alles zu tun." Jeder Algorithmus kann in einer Sprache für einen Computer aus nur fünf Grundanweisungen ausgedrückt werden:Bewegen Sie einen Ort; bewegen Sie einen Ort rechts; Lesesymbol am aktuellen Ort; Drucken 0 am aktuellen Ort; Drucken 1 am aktuellen Ort.Corrado Böhm und Giuseppe Jacopinis Einsicht: Es gibt nur drei Möglichkeiten, diese Aktionen (in komplexere) zu kombinieren, die benötigt werden, um für einen Computer alles zu tun". Es sind nur drei Regeln erforderlich, um jede Reihe von Grundanweisungen in komplexere zu kombinieren: Sequenz: zuerst tun Sie dies, dann tun Sie dies; Auswahl: IF so-und-dies ist der Fall, THEN tun dies, ELSE tun; Wiederholung: WHILE so-and-dies ist der Fall, DO this. Beachten Sie, dass die drei Regeln von Boehms und Jacopinis Einsicht mit der Verwendung von goto (was bedeutet, dass es mehr elementar als strukturierte Programmierung.) Programmierung von Paradigmen Programmiersprachen können verwendet werden, um verschiedene Aufgaben auf verschiedene Weise zu erfüllen. Gemeinsame Programmierparadigmen umfassen: Funktionelle Programmierung, ein Stil des Aufbaus der Struktur und Elemente von Computerprogrammen, die Berechnung als Auswertung von mathematischen Funktionen behandelt und vermeidet Zustand und mutierbare Daten. Es ist ein deklaratives Programmierparadigma, das bedeutet, dass die Programmierung mit Ausdrücken oder Erklärungen statt Aussagen erfolgt. Imperative Programmierung, ein Programmierparadigma, das Aussagen verwendet, die den Zustand eines Programms ändern. In ähnlicher Weise, dass die zwingende Stimmung in natürlichen Sprachen Befehle ausdrückt, besteht ein zwingendes Programm aus Befehlen für den Computer zu erfüllen. Imperative Programmierung konzentriert sich auf die Beschreibung, wie ein Programm funktioniert. Objektorientierte Programmierung, ein Programmierparadigma basierend auf dem Konzept von Objekten, die Daten in Form von Feldern enthalten können, oft als Attribute bekannt; und Code in Form von Verfahren, oft als Methoden bekannt. Ein Merkmal von Objekten ist, dass die Prozeduren eines Objekts auf die Datenfelder des Objekts zugreifen und oft ändern können, mit denen sie verbunden sind. Somit werden objektorientierte Computerprogramme aus Objekten gebildet, die miteinander interagieren. Serviceorientierte Programmierung, ein Programmierparadigma, das Dienste als Einheit der Computerarbeit verwendet, um integrierte Business-Anwendungen und missionskritische Softwareprogramme zu entwerfen und umzusetzen Viele Sprachen bieten Unterstützung für mehrere Paradigmen, so dass die Unterscheidung mehr eine Frage des Stils als der technischen Fähigkeiten. Academia Konferenzen sind wichtige Veranstaltungen für die Informatikforschung. Während dieser Konferenzen präsentieren Forscher aus dem öffentlichen und privaten Sektor ihre jüngste Arbeit und treffen sich. Anders als in den meisten anderen akademischen Bereichen, in der Informatik, ist das Prestige von Konferenzpapieren größer als das von Zeitschriftenveröffentlichungen. Eine vorgeschlagene Erklärung dafür ist die schnelle Entwicklung dieses relativ neuen Feldes erfordert eine schnelle Überprüfung und Verteilung der Ergebnisse, eine Aufgabe besser von Konferenzen behandelt als von Zeitschriften. Bildung Informatik, bekannt durch seine nahe Synonyme, Computing, Computer Studies, wurde in Großbritannien Schulen seit den Tagen der Batch-Verarbeitung, mark sensible Karten und Papierband, aber in der Regel für einige wenige Studenten unterrichtet. Im Jahr 1981 produzierte die BBC ein Mikro-Computer- und Klassenzimmer-Netzwerk und Informatikstudien wurden für GCE O-Studenten (11–16 Jahre alt) und Informatik an eine Ebene Studenten. Seine Bedeutung wurde anerkannt, und es wurde ein obligatorischer Teil des Nationalen Curriculums, für die Key Stage 3 & 4. Im September 2014 wurde sie für alle Schüler im Alter von 4 Jahren Anspruch. In den USA, mit 14.000 Schulbezirken, die den Lehrplan bestimmen, wurde die Bestimmung gebrochen. Laut einem Bericht 2010 des Verbandes für Computing Machinery (ACM) und Computer Science Teachers Association (CSTA) haben nur 14 von 50 Staaten erhebliche Bildungsstandards für die Informatik der High School angenommen. Israel, Neuseeland und Südkorea haben die Informatik in ihre nationalen Sekundarschullehrpläne aufgenommen, und mehrere andere folgen. Siehe auch Hinweise ReferenzenWeiter lesen Externe Links Informatik bei Curlie Scholarly Gesellschaften in InformatikWas ist Informatik? Best Papers Awards in Informatik seit 1996 Fotografien von Informatikern von Bertrand Meyer EECS.berkeley.edu Bibliographie und akademische Suchmaschinen CiteSeerx (Artikel:) Suchmaschine, digitale Bibliothek und Repository für wissenschaftliche und akademische Papiere mit Fokus auf Informatik und Informatik. DBLP Informatik Bibliographie (Article:) Computer-Wissenschaft Bibliographie Website an der Universität Trier, in Deutschland. The Collection of Computer Science Bibliographies (Collection of Computer Science Bibliographies) Professional Organisationen Association for Computing Machinery IEEE Computer Society Informatics Europe AAAI AAAS Computer Science Misc Computer Science –Stack Exchange: a community-run Question-and-answer site for computer science Was ist Informatik ist Informatik Informatik?Informatik (Software) Muss als unabhängige Disziplin betrachtet werden.