Ein globales katastrophales Risiko ist ein hypothetisches zukünftiges Ereignis, das das menschliche Wohlbefinden weltweit beschädigen könnte, sogar die moderne Zivilisation gefährden oder zerstören könnte. Ein Ereignis, das menschliches Aussterben hervorrufen oder das Potenzial der Menschheit dauerhaft und drastisch verkleinern könnte, ist als existentielles Risiko bekannt. Mögliche globale Katastrophenrisiken sind anthropogene Risiken, die durch Menschen (Technologie, Governance, Klimawandel) und nicht anthropogene oder natürliche Risiken verursacht werden. Technologische Risiken umfassen die Schaffung destruktiver künstlicher Intelligenz, Biotechnologie oder Nanotechnologie. Unzureichende oder maligne globale Governance schafft Risiken in der sozialen und politischen Domäne, wie ein globaler Krieg, einschließlich nuklearer Holocaust, Bioterrorismus mit genetisch veränderten Organismen, Cyberterrorismus zerstören kritische Infrastruktur wie das elektrische Netz; oder das Versagen, eine natürliche Pandemie zu verwalten. Probleme und Risiken im Bereich der Erdsystem-Governance umfassen globale Erwärmung, Umweltzerstörung, einschließlich Aussterben von Arten, Hunger infolge nicht-equitable Ressourcenverteilung, menschliche Überbevölkerung, Ernteausfälle und nicht nachhaltige Landwirtschaft. Beispiele für nicht anthropogene Risiken sind ein Asteroidenschlagereignis, eine supervulkanische Eruption, ein tödlicher Gammastrahl, ein geomagnetischer Sturm, der elektronische Geräte zerstört, ein natürlicher langfristiger Klimawandel, ein feindliches außerirdisches Leben, oder die vorhersehbare Sonne, die sich in einen roten Riesenstern verwandelt, der die Erde vertieft. In den letzten zwei Jahrzehnten wurden eine Reihe von akademischen und gemeinnützigen Organisationen gegründet, um globale katastrophale und existenzielle Risiken zu erforschen und potenzielle Klimaschutzmaßnahmen zu formulieren. Definition und Klassifizierung Definieren globaler katastrophaler Risiken Der Begriff globales katastrophales Risiko "fehlt eine scharfe Definition", und bezieht sich im Allgemeinen auf ein Risiko, das "schwere Schädigung des menschlichen Wohlbefindens auf globaler Ebene" auslösen könnte. Die Menschheit hat schon früher große Katastrophen erlitten. Einige von ihnen haben schwere Schäden verursacht, waren aber nur lokal im Rahmen – z.B. der Schwarze Tod hat zu dem Tod eines Drittels der europäischen Bevölkerung geführt, zu der Zeit 10% der globalen Bevölkerung. Einige waren global, aber nicht so schwer – z.B. die Influenza Pandemie von 1918 tötete geschätzte 36% der Weltbevölkerung. Die meisten globalen katastrophalen Risiken würden nicht so intensiv sein, um die Mehrheit des Lebens auf der Erde zu töten, aber selbst wenn man es tat, würden sich das Ökosystem und die Menschheit schließlich erholen (im Gegensatz zu existentiellen Risiken). Auch in der Katastrophe: Risiko und Reaktion, Richard Posner Singles und Gruppen zusammen Veranstaltungen, die "sehr überstürzen oder ruinieren" auf einer globalen, anstatt einer "lokalen oder regionalen" Skala. Posner zeigt Ereignisse wie die besondere Aufmerksamkeit auf Kosten-Nutzen-Gelände würdig, weil sie direkt oder indirekt das Überleben der menschlichen Rasse als Ganzes gefährden könnten. Vorhandene Risiken sind definiert als "Risiken, die die Zerstörung des langfristigen Potenzials der Menschheit bedrohen." Die Veranlassung eines existentiellen Risikos (eine existentielle Katastrophe) würde entweder zu einem unrechtmäßigen menschlichen Aussterben führen oder irreversibel in einem drastisch schlechteren Zustand verschließen. Vorhandene Risiken sind eine Unterklasse globaler katastrophaler Risiken, bei denen der Schaden nicht nur global, sondern auch endständig und dauerhaft ist (vorbeugende Erholung und damit Auswirkungen auf die aktuelle und alle nachfolgenden Generationen). Nichtauslöschungsrisiken Während die Extinktion die offensichtlichste Weise ist, in der das langfristige Potenzial der Menschheit zerstört werden könnte, gibt es andere, einschließlich des unauffindbaren Zusammenbruchs und der auffindbaren Dystopie. Eine Katastrophe, die schwer genug ist, um den ständigen, irreversiblen Zusammenbruch der menschlichen Zivilisation zu verursachen, würde eine existentielle Katastrophe darstellen, auch wenn sie unter der Auslöschung fiel. Ebenso, wenn die Menschheit unter ein totalitäres Regime fiel, und es gab keine Chance auf Erholung – wie von George Orwell in seinem 1949 Roman Nineteen Achtzig-Four vorgestellt – eine solche dystopische Zukunft wäre auch eine existentielle Katastrophe. Bryan Caplan schreibt, dass "eine Ewigkeit des Totalitarismus wäre schlimmer als das Aussterben". Ein dystopisches Szenario teilt die Hauptmerkmale der Auslöschung und des auffindbaren Zusammenbruchs der Zivilisation – vor der Katastrophe konfrontierte die Menschheit eine große Auswahl an hellen Zukunften, aus denen sie wählen konnte; nach der Katastrophe ist die Menschheit ewig in einem schrecklichen Zustand gesperrt. Natürliche vs. anthropogene Experten sind sich allgemein einig, dass anthropogene existenzielle Risiken (much) wahrscheinlicher sind als natürliche Risiken. Ein wesentlicher Unterschied zwischen diesen Risikotypen besteht darin, dass empirische Beweise eine Obergrenze auf der Ebene des natürlichen Risikos festsetzen können. Die Menschheit existiert seit mindestens 200.000 Jahren, über die sie einem annähernd konstanten natürlichen Risiko ausgesetzt ist. Wenn das natürliche Risiko hoch wäre, dann wäre es höchst unwahrscheinlich, dass die Menschheit so lange überlebt hätte, wie sie es hat. Ausgehend von einer Formalisierung dieses Arguments haben die Forscher festgestellt, dass wir zuversichtlich sein können, dass das natürliche Risiko unter 1 in 14.000 (und wahrscheinlich "weniger als eins in 87.000") pro Jahr liegt. Eine weitere empirische Methode, die Wahrscheinlichkeit bestimmter natürlicher Risiken zu untersuchen, ist die Untersuchung der geologischen Daten. So ist beispielsweise ein im Maßstab ausreichendes Comet- oder Asteroiden-Wirkungsereignis, um einen Aufprall-Winter zu verursachen, der vor dem Jahr 2100 zu einem menschlichen Aussterben führen würde, auf eine Million geschätzt worden. Darüber hinaus können große Supervulkanausbrüche einen vulkanischen Winter verursachen, der das Überleben der Menschheit gefährden könnte. Die geologische Aufzeichnung deutet darauf hin, dass supervulkanische Ausbrüche im Durchschnitt etwa alle 50.000 Jahre zu erwarten sind, obwohl die meisten solcher Ausbrüche nicht die für die menschliche Auslöschung erforderliche Skala erreichen würden. Berühmterweise hat der Supervulkan Mt. Toba zum Zeitpunkt seiner letzten Eruption fast die Menschheit ausgelöscht (obwohl dies befriedigt ist). Da das anthropogene Risiko ein relativ neueres Phänomen ist, kann die Erfahrung des Überlebens der Menschheit keine ähnlichen Zusicherungen bieten. Die Menschheit hat nur 75 Jahre seit der Schaffung von Atomwaffen überlebt, und für künftige Technologien gibt es überhaupt keinen Erfolg. Dies hat Denker wie Carl Sagan dazu geführt, dass die Menschheit derzeit in einer „Zeit der Gefahren“ steht – eine einzigartige gefährliche Periode in der Menschheitsgeschichte, in der sie beispiellose Risiken ausgesetzt ist, angefangen von der ersten, als wir uns durch unsere Handlungen mit Risiken für uns selbst konfrontiert haben. Risikovorausschätzungen Angesichts der Einschränkungen der gewöhnlichen Beobachtung und Modellierung wird häufig eine Experten-Elicitation verwendet, anstatt Wahrscheinlichkeitsschätzungen zu erhalten. Im Jahr 2008 schätzte eine informelle Umfrage von Experten auf einer vom Future of Humanity Institute veranstalteten Konferenz ein Risiko von 19% des menschlichen Aussterbens bis zum Jahr 2100, obwohl angesichts der Einschränkungen der Umfrage diese Ergebnisse "mit einem Korn des Salzes" genommen werden sollten. Tabelle Quelle: Zukunft des Humanity Institute, 2008. Es gab eine Reihe weiterer Schätzungen des existenziellen Risikos, des Aussterbensrisikos oder eines globalen Zusammenbruchs der Zivilisation: Im Jahr 1996 schätzte John Leslie in den nächsten fünf Jahrhunderten ein Risiko von 30% (im Durchschnitt etwa 9% pro Jahrhundert). Im Jahr 2002 gab Nick Bostrom langfristig folgende Schätzung des Existenzrisikos: „Meine subjektive Meinung ist, dass die Einstellung dieser Wahrscheinlichkeit kleiner als 25% falsch geführt werden würde und die beste Schätzung erheblich höher sein könnte.“ 2003, Martin Rees schätzte im 21. Jahrhundert eine 50%ige Chance auf einen Zusammenbruch der Zivilisation. Der Jahresbericht 2016 der Global Challenges Foundation schätzt eine jährliche Wahrscheinlichkeit des Aussterbens von mindestens 0,05 % pro Jahr. Eine 2016 Umfrage von KI-Experten fand eine mediane Schätzung von 5%, dass KI auf menschlicher Ebene ein Ergebnis verursachen würde, das "extrem schlecht (z.B. menschliches Aussterben)" war. Im Jahr 2020, Toby Ord Schätzungen existentielles Risiko im nächsten Jahrhundert bei „1 in 6“ in seinem Buch Das Rezept: Existential Risk and the Future of Humanity. Metaculus Nutzer schätzen derzeit eine 3% Wahrscheinlichkeit der Menschheit vor 2100 aussterben. Methodische Herausforderungen Die Erforschung der Natur und der Abschwächung globaler katastrophaler Risiken und existenzieller Risiken unterliegt einer einzigartigen Reihe von Herausforderungen und damit nicht leicht den üblichen Standards der wissenschaftlichen Rigour. So ist es weder möglich noch ethisch, diese Risiken experimentell zu untersuchen. Carl Sagan hat dies in Bezug auf den Atomkrieg zum Ausdruck gebracht: „Das Verständnis der langfristigen Folgen des Atomkriegs ist kein Problem, das für die experimentelle Überprüfung geeignet ist“. Darüber hinaus verändern sich viele katastrophale Risiken schnell, da sich die technologischen Fortschritte und Hintergrundbedingungen (wie internationale Beziehungen) ändern. Eine weitere Herausforderung ist die allgemeine Schwierigkeit, die Zukunft über lange Zeiträume genau vorherzusagen, insbesondere für athropogene Risiken, die von komplexen politischen, wirtschaftlichen und sozialen Systemen abhängig sind. Neben bekannten und greifbaren Risiken können unvorhersehbare schwarze Schwan-Extinktionsereignisse auftreten, die ein zusätzliches methodisches Problem darstellen. Der Mangel an historischer Präzedenzmenschlichkeit hat nie eine existentielle Katastrophe erlitten, und wenn man auftreten sollte, wäre es notwendigerweise beispiellos. Daher stellen existenzielle Risiken einzigartige Herausforderungen für die Vorhersage, noch mehr als andere langfristige Ereignisse, aufgrund von Beobachtungsauswahleffekten. Anders als bei den meisten Ereignissen ist das Scheitern eines kompletten Aussterbens in der Vergangenheit kein Beweis gegen ihre Wahrscheinlichkeit in der Zukunft, denn jede Welt, die ein solches Aussterben erlebt hat, hat keine Beobachter, so unabhängig von ihrer Häufigkeit, keine Zivilisation beobachtet existentielle Risiken in ihrer Geschichte. Diese anthropischen Probleme können teilweise vermieden werden, indem man Beweise betrachtet, die solche Selektionseffekte nicht haben, wie Asteroidenschlagkrater auf den Mond, oder direkt die wahrscheinlichen Auswirkungen neuer Technologien bewerten. Um die Dynamik eines beispiellosen, unauffindbaren globalen Zivilisationszusammenbruchs (eine Art existentielles Risiko) zu verstehen, kann es lehrreich sein, die verschiedenen lokalen Zivilisationszusammenbrüche zu untersuchen, die in der gesamten Menschheitsgeschichte stattgefunden haben. Zum Beispiel haben Zivilisationen wie das Römische Reich in einem Verlust zentralisierter Governance und einem großen zivilisationsweiten Verlust von Infrastruktur und fortschrittlicher Technologie beendet. Diese Beispiele zeigen jedoch, dass die Gesellschaften für die Katastrophe ziemlich widerstandsfähig erscheinen; zum Beispiel überlebte das mittelalterliche Europa den Schwarzen Tod, ohne etwas zu leiden, das einem Zivilisationszusammenbruch ähnelt, obwohl es 25 bis 50 Prozent seiner Bevölkerung verlor. Incentives und Koordination Es gibt wirtschaftliche Gründe, die erklären können, warum so wenig Anstrengung in existentielle Risikominderung geht. Es ist ein globales öffentliches Gut, also sollten wir erwarten, dass es von Märkten unterliefert wird. Auch wenn eine große Nation in Risikominderungsmaßnahmen investiert, wird diese Nation nur einen kleinen Teil des Nutzens dafür genießen. Darüber hinaus ist die existentielle Risikoreduktion ein weltweites Gemeinwohl, da die meisten Vorteile einer existenziellen Risikoreduktion von zukünftigen Generationen genossen würden, und obwohl diese zukünftigen Menschen theoretisch vielleicht bereit wären, erhebliche Summen für eine existentielle Risikoreduktion zu zahlen, besteht kein Mechanismus für eine solche Transaktion. Kognitive Bias Zahlreiche kognitive Bias können das Urteil der Menschen über die Bedeutung existentieller Risiken beeinflussen, einschließlich Umfang Unempfindlichkeit, hyperbolische Rabatte, Verfügbarkeit heuristisch, die Konjunktionsschwäche, die Wirkung heuristisch und die Überlastungswirkung. Scope Insensitivity beeinflusst, wie schlechte Menschen das Aussterben der menschlichen Rasse betrachten. Zum Beispiel, wenn Menschen motiviert sind, Geld an altruistische Ursachen zu spenden, erhöht sich die Menge, die sie geben will, nicht linear mit der Größe des Problems: Menschen sind etwa so bereit, den Tod von 200.000 oder 2.000 Vögeln zu verhindern. In ähnlicher Weise sind die Menschen oft mehr besorgt über Bedrohungen für Einzelpersonen als für größere Gruppen. Morale Bedeutung des existenziellen Risikos In einer der frühesten Erörterungen der Ethik des menschlichen Aussterbens bietet Derek Parfit das folgende Gedankenexperiment an: Ich glaube, wenn wir die Menschheit zerstören, wie wir jetzt können, wird dieses Ergebnis viel schlimmer sein, als die meisten Menschen denken. Vergleiche drei Ergebnisse:(1) Frieden.(2) Ein Atomkrieg, der 99% der weltweit vorhandenen Bevölkerung tötet.(3)Ein Atomkrieg, der 100% tötet.(2) Schlimmer als (1,) und (3) wäre schlimmer als (2). Welches sind die beiden Unterschiede? Die meisten Menschen glauben, dass der größere Unterschied zwischen (1) und (2) ist. Ich glaube, der Unterschied zwischen (2) und (3) ist sehr viel größer. Die Skala dessen, was in einer existentiellen Katastrophe verloren geht, wird durch das langfristige Potenzial der Menschheit bestimmt – was die Menschheit erreichen könnte, wenn sie überlebt. Aus einer utilitaristischen Perspektive ist der Wert des Schutzes der Menschheit das Produkt ihrer Dauer (wie lange die Menschheit überlebt), ihre Größe (wie viele Menschen es im Laufe der Zeit gibt), und ihre Qualität (im Durchschnitt, wie gut ist das Leben für zukünftige Menschen). Im Durchschnitt überleben Arten etwa eine Million Jahre vor dem Aussterben. Parfit weist darauf hin, dass die Erde für etwa eine Milliarde Jahre bewohnbar bleiben wird. Und dies könnte niedrigere Grenzen auf unserem Potenzial sein: Wenn die Menschheit über die Erde hinaus expandieren kann, könnte sie die menschliche Bevölkerung stark erhöhen und für Trillionen von Jahren überleben. Die Größe des foregone Potenzials, das verloren gehen würde, war die Menschheit aussterben zu gehen, ist sehr groß. Daher würde die Reduzierung des existenziellen Risikos um einen kleinen Betrag einen sehr signifikanten moralischen Wert haben. Einige Ökonomen und Philosophen haben Ansichten verteidigt, darunter exponentielle Rabatte und personenbeeinflussende Ansichten der Bevölkerungsethik, auf denen zukünftige Menschen nicht (oder viel weniger) moralisch sprechen. Während diese Ansichten kontrovers sind, würden sie sogar zustimmen, dass eine existentielle Katastrophe zu den schlimmsten Dingen gehören würde, die man sich vorstellen kann. Es würde das Leben von acht Milliarden gegenwärtig existierenden Menschen verkürzen und alles zerstören, was ihr Leben wertvoll macht, und höchstwahrscheinlich viele von ihnen einem tiefen Leiden unterwerfen. Sogar wenn man den Wert zukünftiger Generationen außer Acht lässt, kann es starke Gründe geben, das existenzielle Risiko zu reduzieren, das in Sorge für gegenwärtig bestehende Menschen begründet ist. Jenseits des Utilitarismus unterstützen andere moralische Perspektiven die Bedeutung der Verringerung des existenziellen Risikos. Eine existentielle Katastrophe würde mehr als nur die Menschheit zerstören – sie würde alle kulturellen Artefakte, Sprachen und Traditionen zerstören und viele der Dinge, die wir schätzen. Die moralischen Gesichtspunkte, auf denen wir Pflichten zum Schutz und zur Wertschätzung haben, würden dies als einen großen Verlust sehen, der vermieden werden sollte. Man kann auch Gründe berücksichtigen, die in Pflichten der vergangenen Generationen begründet sind. So schreibt Edmund Burke von einer "Partnerschaft ... zwischen denen, die leben, denen, die tot sind, und denen, die geboren werden sollen". Wenn man die Schulden ernst nimmt, die die Menschheit den vergangenen Generationen schuldet, argumentiert Ord die beste Möglichkeit, sie zurückzuzahlen, könnte sein, um sie vorwärts zu zahlen und sicherzustellen, dass die Erbschaft der Menschheit in zukünftige Generationen weitergegeben wird. Es gibt mehrere Ökonomen, die die Bedeutung globaler katastrophaler Risiken diskutiert haben. Zum Beispiel argumentiert Martin Weitzman, dass die meisten der erwarteten wirtschaftlichen Schäden durch den Klimawandel aus der kleinen Chance kommen, dass die Erwärmung die mittleren Erwartungen deutlich übertrifft, was zu Katastrophenschäden führt. Richard Posner hat argumentiert, dass die Menschheit viel zu wenig, im Allgemeinen, über kleine, schwer zu schätzende Risiken von Großkatastrophen tut. Mögliche Risikoquellen Einige Quellen des katastrophalen Risikos sind antropogene (man-made), wie globale Erwärmung, Umweltdegradation, entwickelte Pandemie und Kernkrieg. Auf der anderen Seite sind einige Risiken nicht-anthropogen oder natürlich, wie Meteoriteneinschläge oder Supervolkane. Anthropogen Viele Experten – auch die am Future of Humanity Institute an der University of Oxford und am Centre for the Study of Existential Risk an der University of Cambridge – berechtigen anthropogene über natürliche Risiken aufgrund ihrer viel geschätzten Wahrscheinlichkeit. Sie sind vor allem von Risiken betroffen, die durch fortschrittliche Technologien wie künstliche Intelligenz und Biotechnologie entstehen. Künstliche Intelligenz Es wurde vorgeschlagen, dass, wenn KI-Systeme schnell superintelligent werden, sie unvorhergesehene Handlungen oder außerkompetente Menschlichkeit ergreifen können. Nach Ansicht des Philosophen Nick Bostrom ist es möglich, dass die erste Super-Intelligenz auftauchen in der Lage sein würde, fast jedes mögliche Ergebnis zu bringen, das sie geschätzt hat, und fast jeden Versuch, es zu verhindern, seine Ziele zu erreichen. So könnte sogar eine Superintelligenz, die der Menschheit gleichgültig ist, gefährlich sein, wenn sie die Menschen als ein Hindernis für unverwandte Ziele wahrnahm. In Bostroms Buch Superintelligence definiert er das als Kontrollproblem. Physiker Stephen Hawking, Microsoft Gründer Bill Gates, und SpaceX Gründer Elon Musk haben diese Bedenken Echo gemacht, mit Hawking-Theorie, dass eine solche KI "Spell das Ende der menschlichen Rasse". Im Jahr 2009 veranstaltete der Verband für die Förderung der Künstlichen Intelligenz (AAAI) eine Konferenz, um zu diskutieren, ob Computer und Roboter in der Lage sein könnten, jede Art von Autonomie zu erwerben, und wie sehr diese Fähigkeiten eine Bedrohung oder Gefahr darstellen könnten. Sie stellten fest, dass einige Roboter verschiedene Formen der Halbautonomie erworben haben, einschließlich in der Lage, Energiequellen auf eigene Faust zu finden und in der Lage zu sein, Ziele zu wählen, die mit Waffen angreifen. Sie stellten auch fest, dass einige Computerviren der Beseitigung entgehen können und "Cockroach Intelligence" erreicht haben. Sie stellten fest, dass Selbstbewusstsein, wie in Science-Fiction dargestellt, wahrscheinlich unwahrscheinlich ist, aber es gibt andere mögliche Gefahren und Fallstricke. Verschiedene Medienquellen und wissenschaftliche Gruppen haben getrennte Tendenzen in unterschiedlichen Bereichen festgestellt, die zusammen zu größeren Robotik-Funktionalitäten und Autonomie führen könnten und einige inhärente Anliegen darstellen. Eine Umfrage von KI-Experten schätzte, dass die Chance des maschinellen Lernens auf menschlicher Ebene mit einem "extrem schlechten (z.B. menschlichen Aussterben) langfristigen Effekt auf die Menschheit 5% beträgt. Eine Umfrage 2008 des Future of Humanity Institute schätzte eine Wahrscheinlichkeit von 5% durch Superintelligenz bis 2100. Eliezer Yudkowsky glaubt, dass Risiken durch künstliche Intelligenz schwerer vorherzusagen sind als alle anderen bekannten Risiken aufgrund von Voreingenommenheit aus Anthropomorphismus. Da die Menschen ihre Urteile der künstlichen Intelligenz auf ihre eigene Erfahrung stützen, behauptet er, sie unterschätzen die potentielle Macht der KI. Die Biotechnologie Biotechnologie kann ein globales katastrophales Risiko in Form von biotechnologischen Organismen (Viren, Bakterien, Pilze, Pflanzen oder Tiere) darstellen. In vielen Fällen wird der Organismus ein Erreger von Menschen, Tieren, Kulturen oder anderen Organismen sein, von denen wir abhängen (z.B. Bestäuber oder Darmbakterien). Jeder Organismus, der in der Lage ist, die Ökosystemfunktionen katastrophal zu stören, z.B. hoch wettbewerbsfähige Unkräuter, überwundene essentielle Kulturen, stellt jedoch ein biotechnologisches Risiko dar. Eine Biotechnologie-Katastrophe kann durch versehentliche Freisetzung eines genetisch veränderten Organismus aus kontrollierten Umgebungen, durch die geplante Freisetzung eines solchen Organismus verursacht werden, der sich dann als unvorhergesehene und katastrophale Wechselwirkungen mit essentiellen natürlichen oder agroökosystemen oder durch gezielte Verwendung von biologischen Wirkstoffen in biologischen Kriegsführungen oder Bioterrorismusanschlägen herausstellt. Pathogene können bewusst oder unbeabsichtigt genetisch verändert werden, um Virulenz und andere Eigenschaften zu verändern. Zum Beispiel, eine Gruppe von australischen Forscher unbeabsichtigt veränderte Eigenschaften des Maus-Virus, während versuchen, ein Virus zu entwickeln, um Nagetiere zu sterilisieren. Das modifizierte Virus wurde auch bei geimpften und natürlich widerstandsfähigen Mäusen sehr tödlich. Die technologischen Mittel zur genetischen Veränderung der Viruseigenschaften sind wahrscheinlich in der Zukunft weit verbreitet, wenn nicht richtig reguliert. Die terroristischen Anwendungen der Biotechnologie waren historisch selten. Inwieweit dies auf mangelnde Fähigkeiten oder Motivation zurückzuführen ist, wird nicht gelöst. Angesichts der aktuellen Entwicklung ist jedoch zukünftig ein höheres Risiko von neuartigen, entwickelten Erregern zu erwarten. Im Bereich der Biotechnologie wurde ein beträchtliches Wachstum beobachtet, und Noun und Chyba deuten darauf hin, dass dies in den kommenden Jahrzehnten zu großen Steigerungen der biotechnologischen Fähigkeiten führen wird.Sie argumentieren, dass Risiken durch biologische Kriegsführung und Bioterrorismus von nuklearen und chemischen Bedrohungen abweichen, da biologische Erreger einfacher zu Massenproduzieren sind und ihre Produktion schwer zu kontrollieren ist (insbesondere da die technologischen Fähigkeiten auch für einzelne Anwender verfügbar sind). Im Jahr 2008 schätzte eine Umfrage des Future of Humanity Institute bis 2100 eine Wahrscheinlichkeit von 2 % des Aussterbens aus der entwickelten Pandemie. Noun und Chyba schlagen drei Kategorien von Maßnahmen vor, um Risiken durch Biotechnologie und natürliche Pandemie zu reduzieren: Verordnung oder Vorbeugung potenziell gefährlicher Forschungen, verbesserte Anerkennung von Ausbrüchen und Entwicklungseinrichtungen zur Minderung von Krankheitsausbrüchen (z.B. besser und/oder weit verbreitete Impfstoffe). Cyberattack Cyberattacks haben das Potenzial, alles von persönlichen Daten zu elektrischen Netzen zu zerstören. Christine Peterson, Mitbegründer und ehemaliger Präsident des Foresight Institute, glaubt, dass ein Cyberangriff auf Elektrogitter das Potenzial hat, ein katastrophales Risiko zu sein. Sie stellt fest, dass wenig getan worden ist, um solche Risiken zu mildern, und dass die Minderung mehrere Jahrzehnte der Nachjustierung dauern könnte. Umweltkatastrophe Eine Umwelt- oder Umweltkatastrophe, wie der Weltkulturversagen und der Zusammenbruch von Ökosystemdienstleistungen, könnte durch die gegenwärtigen Trends der Überbevölkerung, der wirtschaftlichen Entwicklung und der nicht nachhaltigen Landwirtschaft induziert werden. Die meisten Umweltszenarien beinhalten ein oder mehrere der folgenden: Holozän-Extinktionsereignis, Wasserknappheit, die dazu führen könnte, dass etwa die Hälfte der Erdbevölkerung ohne sicheres Trinkwasser, Verursacherrückgang, Überfischung, massive Entwaldung, Wüstenbildung, Klimawandel oder massive Wasserverschmutzung Episoden. Im Anfang des 21. Jahrhunderts wurde eine Bedrohung in dieser Richtung als Kolonie-Konzernstörung erkannt, ein Phänomen, das die bevorstehende Auslöschung der westlichen Honigbiene voraussetzt. Da die Biene eine wichtige Rolle bei der Bestäubung spielt, würde ihr Aussterben die Nahrungskette stark stören. In einem Bericht vom Oktober 2017, der in The Lancet veröffentlicht wurde, hieß es, dass die Toxizität, das Wasser, die Böden und die Arbeitsplätze im Jahr 2015 gemeinsam für neun Millionen Todesfälle weltweit verantwortlich seien, insbesondere wegen der Luftverschmutzung, die mit dem Tod verbunden war, indem die Anfälligkeit für nicht-infektiöse Krankheiten wie Herzerkrankungen, Schlaganfall und Lungenkrebs erhöht wurde. Der Bericht warnte, dass die Verschmutzungskrise "die Hülle über die Menge der Verschmutzung, die die Erde tragen kann" übertraf und "das Fortleben der menschlichen Gesellschaften". Eine in wissenschaftlichen Berichten veröffentlichte May-2020-Analyse ergab, dass, wenn die Entwaldung und der Ressourcenverbrauch mit aktuellen Raten weitergehen, sie in einem "katastrophischen Zusammenbruch der menschlichen Bevölkerung" und möglicherweise "ein irreversibler Zusammenbruch unserer Zivilisation" innerhalb der nächsten Jahrzehnte gipfeln könnten. Die Studie besagt, dass die Menschheit von einer von der Wirtschaft dominierten Zivilisation zu einer "kulturellen Gesellschaft" übergehen sollte, die "das Interesse des Ökosystems über das individuelle Interesse seiner Komponenten, aber schließlich im Einklang mit dem allgemeinen gemeinschaftlichen Interesse" beraubt. Die Autoren weisen auch darauf hin, dass "wenn gewalttätige Ereignisse wie den globalen Krieg oder natürliche katastrophale Ereignisse für jeden von unmittelbarer Besorgnis sind, ein relativ langsamer Verbrauch der planetarischen Ressourcen nicht als eine sterbliche Gefahr für die menschliche Zivilisation empfunden werden kann." Experimenteller Technologieunfall Nick Bostrom schlug vor, dass die Menschheit bei der Verfolgung von Wissen versehentlich ein Gerät schaffen könnte, das Erde und das Sonnensystem zerstören könnte. Untersuchungen in der Kern- und Hochenergiephysik könnten ungewöhnliche Bedingungen mit katastrophalen Folgen schaffen. Zum Beispiel befürchten Wissenschaftler, dass der erste Atomtest die Atmosphäre entzünden könnte. Andere befürchten, dass der RHIC oder der Große Hadron Collider eine weltweite Katastrophe mit schwarzen Löchern, Fremden oder falschen Vakuumzuständen starten könnte. Diese besonderen Bedenken wurden herausgefordert, aber die allgemeine Besorgnis bleibt bestehen. Die Biotechnologie könnte zur Schaffung einer Pandemie führen, chemische Kriege könnten zu einem extremen, Nanotechnologie könnte zu einem grauen Goo führen, in dem selbstreplikierende Roboter alle lebenden Materie auf der Erde konsumieren, während sie mehr von sich selbst bauen – in beiden Fällen entweder bewusst oder zufällig. Globale Erwärmung Globale Erwärmung bezieht sich auf die Erwärmung durch die menschliche Technologie seit dem 19. Jahrhundert oder früher. Projekte des zukünftigen Klimawandels schlagen eine weitere globale Erwärmung, ein Anstieg des Meeresspiegels und eine Erhöhung der Häufigkeit und Schwere einiger extremer Wetterereignisse und wetterbedingter Katastrophen vor. Die Auswirkungen der globalen Erwärmung sind der Verlust der biologischen Vielfalt, die Belastungen der bestehenden Lebensmittel produzierenden Systeme, die vermehrte Verbreitung bekannter Infektionskrankheiten wie Malaria und die schnelle Mutation von Mikroorganismen. Im November 2017 zeigte eine Erklärung von 15,364 Wissenschaftlern aus 184 Ländern, dass zunehmende Treibhausgase aus der Nutzung fossiler Brennstoffe, Wachstum der menschlichen Bevölkerung, Entwaldung und Übernutzung von Land für die landwirtschaftliche Produktion, vor allem durch die Landwirtschaft Wiederkäuer für den Fleischverbrauch, auf eine Art und Weise ablaufen, die in den kommenden Jahrzehnten eine Zunahme des Menschenmords prognostiziert. Der rumänische amerikanische Wirtschaftswissenschaftler Nicholas Georgescu-Roegen, ein Vorläufer der Ökonomie und der Paradigmengründer der Ökonomie, hat argumentiert, dass die Tragfähigkeit der Erde, d.h. die Fähigkeit der Erde, menschliche Populationen und Konsumniveaus zu erhalten, irgendwann in der Zukunft abnehmen muss, da die Erde gegenwärtig einen endlichen Bestand an Mineralressourcen hervorruft und zur Nutzung gebracht wird. Ökonom und stationärer Theoretiker Herman Daly, ein Student von Georgescu-Roegen, hat das gleiche Argument durch die Behauptung, dass "... alles, was wir tun können, ist zu vermeiden, dass die begrenzte Fähigkeit der Schöpfung, um das gegenwärtige und zukünftige Leben zu unterstützen [auf der Erde]. " Seit Georgescu-Roegen und Daly diese Ansichten veröffentlichten, diskutierten verschiedene Wissenschaftler auf diesem Gebiet die existentielle Unmöglichkeit, den endlichen Bestand an Mineralressourcen der Erde gleichmäßig unter einer unbekannten Anzahl von heutigen und zukünftigen Generationen zuzuordnen. Diese Anzahl von Generationen wird uns wahrscheinlich unbekannt bleiben, denn es gibt keinen Weg – oder nur wenig Weg –, im Voraus zu wissen, ob oder wann die Menschheit letztendlich dem Aussterben begegnen wird. In der Tat wird jede denkbare intertemporale Zuteilung des Bestands zwangsläufig zu einem späteren Zeitpunkt mit einem allgemeinen wirtschaftlichen Rückgang enden. Nanotechnologie Viele nanoskalige Technologien sind in der Entwicklung oder derzeit im Einsatz. Das einzige, das ein signifikantes globales katastrophales Risiko darstellt, ist die molekulare Fertigung, eine Technik, die es ermöglicht, komplexe Strukturen auf atomarer Präzision aufzubauen. Molekulare Fertigung erfordert signifikante Fortschritte in der Nanotechnologie, aber einmal erreicht konnte hochmoderne Produkte zu niedrigen Kosten und in großen Mengen in Nanofaktoren von Desktop-Anteilen produzieren. Wenn Nanofaktoren die Fähigkeit gewinnen, andere Nanofaktoren zu produzieren, kann die Produktion nur durch relativ viele Faktoren wie Eingabematerialien, Energie und Software begrenzt werden. Molekulare Herstellung könnte verwendet werden, um billig produzieren, unter vielen anderen Produkten, hochentwickelte, langlebige Waffen. Mit kompakten Computern und Motoren ausgestattet zu sein, könnte diese zunehmend autonom sein und eine große Auswahl an Fähigkeiten haben. Chris Phoenix und Treder klassifizieren katastrophale Risiken der Nanotechnologie in drei Kategorien: Von der Weiterentwicklung anderer Technologien wie KI und Biotechnologie. Durch die Möglichkeit einer Massenproduktion von potenziell gefährlichen Produkten, die eine Risikodynamik (z.B. Waffenrennen) verursachen, je nachdem, wie sie verwendet werden. Von unkontrollierten selbsterhaltenden Prozessen mit destruktiven Effekten. Mehrere Forscher sagen, dass der Großteil des Risikos aus der Nanotechnologie von dem Potenzial stammt, zu Krieg, Waffenrennen und zerstörerischen globalen Regierung führen. Mehrere Gründe wurden vorgeschlagen, warum die Verfügbarkeit von Nanotechnologie-Waffen mit großer Wahrscheinlichkeit zu instabilen Waffenrennen führen kann (im Vergleich zu z.B. Atomwaffenrennen): Eine große Anzahl von Spielern kann versucht werden, das Rennen zu betreten, da die Schwelle dafür gering ist; Die Fähigkeit, Waffen mit der molekularen Fertigung zu machen, wird billig und leicht zu verstecken; daher kann man die mangelnde Einsicht in die Fähigkeiten der anderen Parteien versuchen, die Spieler aus Vorsicht zu rüsten oder preemptive Streiks zu starten; Molecular Manufacturing kann die Abhängigkeit vom internationalen Handel verringern, ein potenzieller Friedensförderfaktor; Kriege; Da die Selbstregulierung durch alle staatlichen und nichtstaatlichen Akteure schwer zu erreichen ist, wurden vor allem Maßnahmen zur Minderung kriegsbedingter Risiken im Bereich der internationalen Zusammenarbeit vorgeschlagen. Die internationale Infrastruktur kann erweitert werden, um der internationalen Ebene mehr Souveränität zu verleihen. Dies könnte dazu beitragen, die Bemühungen um die Waffenkontrolle zu koordinieren. Auch internationale Einrichtungen, die speziell der Nanotechnologie (in Analogie zur Internationalen Atomenergieagentur IAEA) oder der allgemeinen Rüstungskontrolle gewidmet sind, können konzipiert werden. Man kann auch gemeinsam unterschiedliche technologische Fortschritte bei den Verteidigungstechnologien erzielen, eine Politik, die die Akteure in der Regel bevorzugen sollten. Das Center for Responsible Nanotechnology schlägt auch einige technische Einschränkungen vor. Eine verbesserte Transparenz hinsichtlich technologischer Fähigkeiten kann ein weiterer wichtiger Moderator für die Rüstungskontrolle sein. Grey goo ist ein weiteres katastrophales Szenario, das von Eric Drexler in seinem 1986 erschienenen Buch Engines of Creation vorgeschlagen wurde und ein Thema in Mainstream-Medien und Fiktion war. Dieses Szenario beinhaltet winzige selbstreplizierende Roboter, die die gesamte Biosphäre verbrauchen, indem sie sie als Energiequelle und Bausteine verwendet. Nanotech-Experten – auch Drexler – diskreditieren heute das Szenario. Laut Phoenix könnte ein "sog. graues Goo nur das Produkt eines bewussten und schwierigen Engineering-Prozesses sein, kein Unfall." Kriegsführung und Massenvernichtung Die am häufigsten erforschten Szenarien sind nukleare Kriegsführung und doomsday-Geräte. Die Einführung eines nuklearen Angriffs als Reaktion auf einen falschen Alarm ist ein mögliches Szenario; dies geschah fast während des sowjetischen nuklearen Fehlalarmvorfalls 1983. Obwohl die Wahrscheinlichkeit eines Atomkrieges pro Jahr schlank ist, hat Professor Martin Hellman es auf lange Sicht als unvermeidlich beschrieben; es sei denn, die Wahrscheinlichkeit nähert sich Null, wird zwangsläufig ein Tag kommen, an dem Zivilisationsglück ausläuft. Während der kubanischen Raketenkrise, US-Präsident John F. Kennedy schätzte die Chancen des Atomkriegs auf "etwas zwischen einem von drei und sogar". Die Vereinigten Staaten und Russland haben einen kombinierten Arsenal von 14.700 Atomwaffen, und es gibt geschätzt insgesamt 15.700 Atomwaffen weltweit. Jenseits der Nuklear-, anderer militärischer Bedrohungen für die Menschheit gehören die biologische Kriegsführung (BW). Demgegenüber ist die chemische Kriegsführung in der Lage, mehrere lokale Katastrophen zu schaffen, unwahrscheinlich, eine globale zu schaffen. Nuklearkrieg könnte beispiellose Menschentodmaut und Lebensraumvernichtung liefern. Eine große Anzahl von Atomwaffen zu detonieren würde unmittelbare, kurzfristige und langfristige Auswirkungen auf das Klima haben, was zu kaltem Wetter und reduziertem Sonnenlicht und Photosynthese führt, die in fortgeschrittenen Zivilisationen signifikante Umwälzungen verursachen können. Während die Volkswahrnehmung manchmal den Kernkrieg als "das Ende der Welt" nimmt, weisen Experten dem menschlichen Aussterben aus dem Atomkrieg eine geringe Wahrscheinlichkeit zu. Im Jahr 1982 schätzte Brian Martin, dass ein US-sowjetischer Atomaustausch 400–450 Millionen direkt, vor allem in den Vereinigten Staaten, Europa und Russland, und vielleicht mehrere hundert Millionen mehr durch Folgefolgen in den gleichen Bereichen töten könnte. Im Jahr 2008 schätzte eine Umfrage des Future of Humanity Institute bis 2100 eine Wahrscheinlichkeit von 4 % des Aussterbens aus der Kriegsführung mit 1 % Aussterben aus der Atomkriegsführung. Weltbevölkerung und Agrarkrise Im 20. Jahrhundert wurde eine rasche Zunahme der Menschen durch medizinische Entwicklungen und massive Steigerungen der landwirtschaftlichen Produktivität wie der Grünen Revolution beobachtet. Zwischen 1950 und 1984, als die Grüne Revolution die Landwirtschaft um den Globus verwandelte, stieg die Weltkornproduktion um 250%. Die Grüne Revolution in der Landwirtschaft half der Lebensmittelproduktion, mit dem weltweiten Bevölkerungswachstum Schritt zu halten oder tatsächlich das Bevölkerungswachstum zu ermöglichen. Die Energie für die Grüne Revolution wurde von fossilen Brennstoffen in Form von Düngemitteln (Naturgas,) Pestiziden (Öl,) und Kohlenwasserstoff-bewässerung bereitgestellt. David Pimentel, Professor für Ökologie und Landwirtschaft an der Cornell University, und Mario Giampietro, Senior Researcher am National Research Institute on Food and Nutrition (INRAN) in ihrer 1994 Studie Food, Land, Population and the US Economy die maximale US-Bevölkerung für eine nachhaltige Wirtschaft auf 200 Millionen. Um eine nachhaltige Wirtschaft und eine Abwehrkatastrophe zu erreichen, müssen die Vereinigten Staaten ihre Bevölkerung um mindestens ein Drittel reduzieren, und die Weltbevölkerung muss um zwei Drittel reduziert werden, sagt die Studie. Die Autoren dieser Studie glauben, dass die erwähnte Agrarkrise nach 2020 eine Auswirkung auf die Welt haben wird und nach 2050 kritisch wird. Der Geologe Dale Allen Pfeiffer behauptet, dass in den kommenden Jahrzehnten die Spirale der Lebensmittelpreise ohne Erleichterung und massive Hunger auf globaler Ebene wie nie zuvor erlebt sehen konnte. Da die Lieferungen von Erdöl und Erdgas für die moderne Landwirtschaft wesentlich sind, könnte ein Rückgang der globalen Ölversorgung (siehe Spitzenöl für globale Anliegen) in den kommenden Jahrzehnten zu Spikulations- und beispiellosen Hungersnot führen. Weizen ist das dritt produzierte Getreide der Menschheit. Übermäßige Pilzinfektionen wie Ug99 (eine Art Stammrost) können zu 100% Ernteverlust in den meisten modernen Sorten führen. Eine kleine oder keine Behandlung ist möglich und Infektion breitet sich auf dem Wind aus. Sollten die großen Getreide erzeugenden Gebiete der Welt infiziert werden, würde die anschließende Krise der Weizenverfügbarkeit zu Preisspitzen und -knappungen in anderen Lebensmitteln führen. Nicht anthropogen Von allen Arten, die je gelebt haben, sind 99 % ausgestorben. Die Erde hat zahlreiche Massenauslöschungsereignisse erlebt, bei denen bis zu 96 % aller zur Zeit vorhandenen Arten beseitigt wurden. Ein bemerkenswertes Beispiel ist das K-T-Extinktionsereignis, das die Dinosaurier getötet hat. Die Art der von der Natur ausgehenden Bedrohungen ist relativ konstant, obwohl dies bestritten wurde. Asteroidenschlag Mehrere Asteroiden haben in der jüngsten geologischen Geschichte mit der Erde kollidiert. Der Chicxulub Asteroid war beispielsweise etwa sechs Meilen im Durchmesser und wird theorisiert, um die Auslöschung von nicht-avianen Dinosauriern am Ende des Cretaceous verursacht haben. In einer Erdumlaufbahn existiert derzeit kein ausreichend großer Asteroid; ein Komet ausreichender Größe, um menschliches Aussterben zu verursachen, könnte die Erde beeinflussen, obwohl die jährliche Wahrscheinlichkeit kleiner als 10 - 8 sein kann. Geowissenschaftler Brian Toon schätzt, dass, während ein paar Leute, wie "einige Fischer in Costa Rica", plausibel einen 6-Meilen-Meteoriten überleben könnten, ein sechzig-Meilen-Meterit groß genug wäre, um "alle zu verbrennen". Asteroiden mit rund 1 km Durchmesser haben die Erde im Durchschnitt einmal alle 500.000 Jahre beeinflusst; diese sind wahrscheinlich zu klein, um ein Aussterbenrisiko zu stellen, könnten aber Milliarden von Menschen töten. Größere Asteroiden sind weniger häufig. Kleine Nah-Earth-Asteroide werden regelmäßig beobachtet und können überall auf der Erde auftreten, um lokale Populationen zu verletzen. Ab 2013 schätzt Spaceguard 95 % aller NEOs über 1 km. Im April 2018 berichtete die B612-Stiftung "Es ist ein 100 Prozent sicher, dass wir getroffen werden [durch einen verheerenden Asteroiden], aber wir sind nicht 100 Prozent sicher wann. "Seit 2018 betrachtete der Physiker Stephen Hawking in seinem letzten Buch kurze Antworten auf die großen Fragen als Asteroidenkollision die größte Bedrohung für den Planeten. Im Juni 2018 warnte der US National Science and Technology Council, dass Amerika für ein Asteroiden-Wirkungsereignis unvorbereitet ist und den "National Near-Earth Object Preparationdness Strategy Action Plan" entwickelt und freigegeben hat, um besser vorzubereiten. Laut Gutachten des US-Kongresses im Jahr 2013 würde die NASA mindestens fünf Jahre Vorbereitung benötigen, bevor eine Mission zum Abfangen eines Asteroiden gestartet werden könnte. Kosmische Bedrohungen Es wurden mehrere astronomische Bedrohungen identifiziert. Massive Objekte, z.B. ein Stern, ein großer Planet oder ein schwarzes Loch, könnten katastrophal sein, wenn eine enge Begegnung im Sonnensystem stattgefunden hat. Im April 2008 wurde angekündigt, dass zwei Simulationen der langfristigen planetarischen Bewegung, eines am Pariser Observatorium und das andere an der University of California, Santa Cruz, eine 1% Chance zeigen, dass Mercurys Orbit durch Jupiters Schwerkraft irgendwann während der Lebensdauer der Sonne instabil gemacht werden könnte. Sollte dies geschehen, schlagen die Simulationen vor, dass eine Kollision mit der Erde eines von vier möglichen Ergebnissen sein könnte (die anderen sind Mercury kollidiert mit der Sonne, kollidiert mit Venus, oder aus dem Sonnensystem insgesamt ausgestoßen). Wenn Merkur mit der Erde kollidieren sollte, könnte das ganze Leben auf der Erde völlig vernichtet werden: ein Asteroid, der 15 km breit ist, wird angenommen, dass er die Auslöschung der nicht-avian Dinosaurier verursacht hat, während Mercury 4,879 km im Durchmesser ist. Wenn unser Universum in einem falschen Vakuum liegt, könnte eine Blase des niederen Energie-Vakuums zufällig oder sonst in unserem Universum existieren und die Umwandlung unseres Universums in einen niedrigeren Energiezustand in einem Volumen katalysieren, das sich mit fast der Geschwindigkeit des Lichts ausdehnt und alles zerstört, was wir ohne Vorwarnung kennen. Ein solches Auftreten wird Vakuumdekay genannt. Eine weitere kosmische Bedrohung ist ein Gamma-Strahlbruch, der typischerweise von einem Supernova erzeugt wird, wenn ein Stern an sich einbricht und dann in einer massiven Explosion nach außen springt. Unter Umständen werden diese Ereignisse gedacht, um massive Ausbrüche von Gammastrahlung zu erzeugen, die von der Rotationsachse des Sterns nach außen ausgehen. Wenn ein solches Ereignis auf die Erde ausgerichtet sein sollte, könnten die massiven Mengen an Gammastrahlung die Erdatmosphäre erheblich beeinflussen und eine existentielle Bedrohung für das ganze Leben darstellen. Ein solcher Gamma-Strahlbruch kann die Ursache der Ordovician-Silurian-Extinktionsereignisse gewesen sein. Weder dieses Szenario noch die Destabilisierung des Mercury-Orbits sind in absehbarer Zukunft wahrscheinlich. Ein leistungsfähiges Solar- oder Solar-Superstorm, das eine drastische und ungewöhnliche Abnahme oder Erhöhung der Sonnenleistung ist, könnte schwere Folgen für das Leben auf der Erde haben. Astrophysiker berechnen derzeit, dass die Erde in einigen Milliarden Jahren wahrscheinlich durch die Expansion der Sonne in einen roten Riesenstern verschluckt wird. Extraterrestrische Invasion Intelligentes außerirdisches Leben, wenn es vorhanden ist, könnte die Erde entweder in die Luft eindringen, um das menschliche Leben zu vernichten und zu supplantieren, es unter einem Kolonialsystem zu versklaven, die Ressourcen des Planeten zu stehlen oder den Planeten insgesamt zu zerstören. Obwohl Beweise für fremdes Leben noch nie bewiesen wurden, haben Wissenschaftler wie Carl Sagan postuliert, dass die Existenz des außerirdischen Lebens sehr wahrscheinlich ist. 1969 wurde das "Extra-Terrestrial Exposure Law" dem United States Code of Federal Regulations (Titel 14, Abschnitt 1211) als Reaktion auf die Möglichkeit einer biologischen Kontamination durch das US Apollo Space Program hinzugefügt. Es wurde 1991 entfernt. Wissenschaftler halten ein solches Szenario technisch möglich, aber unwahrscheinlich. Ein Artikel in The New York Times diskutierte die möglichen Bedrohungen für die Menschlichkeit, absichtlich Botschaften zu senden, die auf das außerirdische Leben in den Kosmos im Kontext der SETI-Bemühungen gerichtet sind. Mehrere bekannte Persönlichkeiten wie Stephen Hawking und Elon Musk haben gegen das Senden solcher Botschaften argumentiert, weil außerirdische Zivilisationen mit Technologie wahrscheinlich weit fortgeschrittener sind als die Menschheit und eine existentielle Bedrohung für die Menschheit darstellen könnten. Natürliche Pandemie Es gibt zahlreiche historische Beispiele von Pandemien, die eine verheerende Wirkung auf eine Vielzahl von Menschen gehabt haben.Die gegenwärtige, beispiellose Skala und Geschwindigkeit der menschlichen Bewegung machen es schwieriger als je zuvor, eine Epidemie durch lokale Quarantäne, und andere Quellen der Unsicherheit und die sich entwickelnde Natur des Risikos zu enthalten, können natürliche Pandemie eine realistische Bedrohung für die menschliche Zivilisation darstellen. Es gibt mehrere Klassen von Argumenten über die Wahrscheinlichkeit von Pandemien. Man stammt aus der Geschichte, wo die begrenzte Größe der historischen Pandemie Beweis dafür ist, dass größere Pandemie unwahrscheinlich ist. Dieses Argument wurde aus Gründen bestritten, einschließlich des sich ändernden Risikos durch veränderte Bevölkerungs- und Verhaltensmuster unter den Menschen, der begrenzten historischen Aufzeichnung und der Existenz einer anthropischen Vorspannung. Ein weiteres Argument basiert auf einem evolutionären Modell, das voraussagt, dass sich natürlich entwickelnde Erreger letztlich eine Obergrenze für ihre Virulenz entwickeln werden. Dies liegt daran, dass Krankheitserreger mit hoher Virulenz schnell ihre Wirte töten und ihre Chancen reduzieren, die Infektion auf neue Wirte oder Träger zu verbreiten. Dieses Modell hat jedoch Grenzen, da der Fitness-Vorteil der begrenzten Virulenz in erster Linie eine Funktion einer begrenzten Anzahl von Hosts ist. Jeder Erreger mit hoher Virulenz, hoher Übertragungsrate und langer Inkubationszeit kann bereits eine katastrophale Pandemie verursacht haben, bevor schließlich die Virulenz durch natürliche Selektion begrenzt ist. Zusätzlich hat ein Krankheitserreger, der Menschen als sekundärer Wirt infiziert und vor allem eine andere Spezies (Zoonose) infiziert, keine Einschränkungen auf seine Virulenz bei Menschen, da die zufälligen sekundären Infektionen ihre Evolution nicht beeinflussen. Schließlich können sich in Modellen, in denen Virulenzniveau und Übertragungsrate verwandt sind, hohe Virulenzwerte entwickeln. Die Virulenz wird vielmehr durch die Existenz komplexer Populationen von Wirten mit unterschiedlichen Infektionsanfälligkeiten begrenzt, oder indem einige Wirte geographisch isoliert werden. Die Größe der Wirtsbevölkerung und der Wettbewerb zwischen verschiedenen Stämmen von Erregern können auch die Virulenz verändern. Weder diese Argumente gelten für bioengineerierte Krankheitserreger, und das stellt ganz unterschiedliche Risiken der Pandemien dar. Experten haben zu dem Schluss geführt, dass "Entwicklungen in Wissenschaft und Technologie die Entwicklung und den Einsatz hochkonsequenzierter biologischer Waffen erheblich erleichtern könnten", und diese "hochvirulenten und hochtransmissiblen [bio-engineered pathogens] stellen neue potenzielle pandemische Bedrohungen dar." Der Klimawandel bezieht sich auf eine dauerhafte Veränderung des Klimas der Erde. Das Klima reichte von Eiszeiten bis hin zu wärmeren Zeiten, als Palmen in der Antarktis wuchsen. Es ist hypothetisiert worden, dass es auch eine Periode namens "Snowball Erde" gab, als alle Ozeane in einer Eisschicht bedeckt waren. Diese globalen Klimaänderungen traten langsam auf, nahe dem Ende der letzten großen Eiszeit, als das Klima stabiler wurde. Allerdings ist der abrupte Klimawandel im Jahrzehnt Zeitskala regional aufgetreten. Eine natürliche Variation in einem neuen Klimaregime (Kälte oder heißere) könnte eine Bedrohung für die Zivilisation darstellen. In der Geschichte der Erde sind viele Eiszeiten bekannt geworden. Ein Eisalter würde sich ernsthaft auf die Zivilisation auswirken, weil große Flächen (vor allem in Nordamerika, Europa und Asien) unbewohnbar werden könnten. Derzeit befindet sich die Welt in einer Zwischenzeit innerhalb einer viel älteren Gletscherveranstaltung. Die letzte Gletscherexpansion endete vor etwa 10.000 Jahren und alle Zivilisationen entwickelten sich später. Wissenschaftler prognostizieren nicht, dass ein natürliches Eisalter bald auftreten wird. Die Menge der in die Ozeane und Atmosphäre der Erde emittierten Wärmeeintrittsgase wird das nächste Eisalter verhindern, das sonst in etwa 50.000 Jahren und wahrscheinlich mehr Gletscherzyklen beginnen würde. Vulkanismus Ein geologisches Ereignis wie massiver Flutbasalt, Vulkanismus oder die Eruption eines Supervulkans könnte zu einem sogenannten Vulkanwinter führen, ähnlich einem Atomwinter. Eine solche Veranstaltung, die Toba Eruption, trat vor etwa 71.500 Jahren in Indonesien auf. Laut der Toba-Katastrophentheorie kann das Ereignis die Menschenpopulationen auf nur wenige Zehntausende von Individuen reduziert haben. Yellowstone Caldera ist ein weiterer solcher Supervulkan, der in den letzten 17 Millionen Jahren 142 oder mehr kalderabildende Ausbrüche erlitten hat. Ein massiver Vulkanausbruch würde außergewöhnliche Volumen von vulkanischen Staub, giftigen und Treibhausgasen in die Atmosphäre mit schwerwiegenden Auswirkungen auf das globale Klima (auf die extreme globale Abkühlung: Vulkanwinter, wenn kurzfristig, und Eiszeit, wenn langfristige) oder globale Erwärmung (wenn Treibhausgase vorherrschen sollten) ausstoßen. Als der Supervolcano bei Yellowstone vor 640.000 Jahren erupted, die dünnsten Schichten der Asche aus der Caldera ausgestoßen über die meisten der Vereinigten Staaten westlich des Mississippi-Flusses und Teil des nordöstlichen Mexikos. Die Magma bedeckte viel von dem, was jetzt ist Yellowstone Nationalpark und erweitert darüber hinaus, Abdeckung viel von dem Boden von Yellowstone River im Osten zu der Idaho fällt im Westen, mit einigen der Ströme nach Norden über Mammoth Springs. Nach einer aktuellen Studie, wenn die Yellowstone Caldera wieder als Supervolcano erupted, könnte eine Ascheschicht ein bis drei Millimeter dick bis nach New York abgelagert werden, genug, um "Traktion auf Straßen und Pisten zu reduzieren, kurze elektrische Transformatoren und verursachen Atemprobleme". Es gäbe Zentimeter der Dicke über einen Großteil des US-Mittleren Westens, genug, um Pflanzen und Vieh zu stören, vor allem, wenn es zu einer kritischen Zeit in der wachsenden Saison passiert. Die am schlimmsten getroffene Stadt wäre wahrscheinlich Billing, Montana, Bevölkerung 109.000, die das Modell vorhergesagt würde mit Asche geschätzt 1,03 bis 1,8 Meter dick. Der wichtigste Langzeiteffekt ist durch den globalen Klimawandel, der die Temperatur weltweit um etwa 5–15 Grad C für ein Jahrzehnt reduziert, zusammen mit den direkten Auswirkungen der Ablagerungen von Asche auf ihre Kulturen. Ein großer Supervolcano wie Toba würde eine oder zwei Meter dicke Asche über eine Fläche von mehreren Millionen Quadratkilometern ablegen.(1000 Kubikkilometer entspricht einer ein Meter dicken Asche über eine Million Quadratkilometer). Wenn dies in einigen dicht besiedelten landwirtschaftlichen Flächen wie Indien geschah, könnte es eine oder zwei Jahreszeiten von Kulturen für zwei Milliarden Menschen zerstören. Yellowstone zeigt jedoch derzeit keine Anzeichen für eine Supereruption, und es ist nicht sicher, dass dort eine zukünftige Supereruption auftreten wird. Die 2011 veröffentlichte Forschung zeigt, dass massive Vulkanausbrüche eine massive Kohleverbrennung verursachten und Modelle für die bedeutende Erzeugung von Treibhausgasen unterstützen. Die Forscher haben vorgeschlagen, dass massive Vulkanausbrüche durch Kohlebetten in Sibirien signifikante Treibhausgase erzeugen und einen abfließenden Treibhauseffekt verursachen würden. Massive Ausbrüche können auch genug pyroklastische Trümmer und anderes Material in die Atmosphäre werfen, um die Sonne teilweise zu blockieren und einen vulkanischen Winter zu verursachen, wie es im Jahr 1816 nach dem Ausbruch des Mount Tambora, dem sogenannten Jahr ohne Sommer geschah. Eine solche Eruption könnte die unmittelbaren Todesfälle von Millionen von Menschen mehrere hundert Meilen von der Eruption, und vielleicht Milliarden von dem Tod weltweit, aufgrund des Scheiterns der Monsunen verursachen, was zu erheblichen Ernteversagen führt, die Hungersnöte in einem tiefen Ausmaß verursachen. Ein viel spekulativeres Konzept ist die Verneshot: eine hypothetische vulkanische Eruption verursacht durch den Aufbau von Gas tief unter einem Craton. Ein solches Ereignis kann kraftvoll genug sein, um eine extreme Menge an Material aus der Kruste und dem Mantel in eine suborbitale Trajektorie zu bringen. Verteidigung in der Tiefe ist ein nützlicher Rahmen für die Kategorisierung von Risikominderungsmaßnahmen in drei Schichten der Verteidigung: Prävention: Verringerung der Wahrscheinlichkeit einer an erster Stelle auftretenden Katastrophe. Beispiel: Maßnahmen zur Vermeidung von Ausbrüchen neuer hochinfektiöser Krankheiten. Antwort: Verhindern der Skalierung einer Katastrophe auf die globale Ebene. Beispiel: Maßnahmen zur Verhinderung einer Eskalation eines kleinen Kernaustauschs in einen ausgewachsenen Atomkrieg. Widerstand: Erhöhung der Widerstandsfähigkeit der Menschheit (gegen Aussterben), wenn sie mit globalen Katastrophen konfrontiert wird. Beispiel: Maßnahmen zur Erhöhung der Lebensmittelsicherheit während eines nuklearen Winters. Die menschliche Auslöschung ist am wahrscheinlichsten, wenn alle drei Abwehrkräfte schwach sind, d.h., "durch Risiken sind wir unwahrscheinlich, um zu verhindern, unwahrscheinlich, dass sie erfolgreich reagieren und unwahrscheinlich gegen sie widerstandsfähig sind". Die beispiellose Natur existenzieller Risiken stellt eine besondere Herausforderung bei der Gestaltung von Risikominderungsmaßnahmen dar, da die Menschheit nicht aus einer Vorgeschichte früherer Ereignisse lernen kann. Planetenmanagement und die Einhaltung von planetarischen Grenzen wurden als Ansätze zur Verhinderung ökologischer Katastrophen vorgeschlagen. Im Rahmen dieser Ansätze umfasst das Gebiet der Geotechnik die bewusste großtechnische und Manipulation des planetarischen Umfelds, um anthropogene Veränderungen der atmosphärischen Chemie zu bekämpfen oder zu bekämpfen. Raumkolonialisierung ist eine vorgeschlagene Alternative, um die Chancen zu verbessern, ein Auslöschungsszenario überleben. Lösungen dieses Anwendungsbereichs können Mega-Engineering erfordern. Die Lebensmittelspeicherung wurde weltweit vorgeschlagen, die Geldkosten wären jedoch hoch. Darüber hinaus würde es wahrscheinlich zu den aktuellen Millionen von Todesfällen pro Jahr aufgrund von Unterernährung beitragen. Einige Überlebensexperten lagern Überlebensretreats mit mehrjähriger Nahrungsversorgung. Der Svalbard Global Seed Vault ist 400 Fuß (120 m) in einem Berg auf einer Insel in der Arktis begraben. Es soll 2,5 Milliarden Samen aus mehr als 100 Ländern als Vorsorge für die Erhaltung der Weltkulturen halten. Der umliegende Felsen ist -6 °C (21 °F) (Stand 2015) aber der Gewölbe wird auf -18 °C (0 °F) durch Kühlschränke gehalten, die von lokal erzeugter Kohle betrieben werden. Mehr spekulativ, wenn die Gesellschaft weiter funktioniert und wenn die Biosphäre weiterhin bewohnbar bleibt, können Kalorienbedarf für die gegenwärtige menschliche Bevölkerung in der Theorie während einer ausgedehnten Abwesenheit von Sonnenlicht, angesichts ausreichender Vorausplanung erfüllt werden. Konjizierte Lösungen umfassen den Anbau von Pilzen auf der im Zuge der Katastrophe verbliebenen toten Pflanzenbiomasse, die Umwandlung von Zellulose in Zucker oder die Zuführung von Erdgas zu methandigestierenden Bakterien. Globale katastrophale Risiken und globale GovernanceEinige globale Governance schafft Risiken im sozialen und politischen Bereich, aber die Governance-Mechanismen entwickeln sich langsamer als technologischer und sozialer Wandel. Es gibt Bedenken der Regierungen, des Privatsektors sowie der Öffentlichkeit über die fehlenden Regierungsmechanismen, um Risiken effizient zu bewältigen, zu verhandeln und zwischen verschiedenen und widersprüchlichen Interessen zu verurteilen. Dies wird durch ein Verständnis der Vernetzung globaler systemischer Risiken weiter unterstrichen. In Abwesenheit oder Antizipation der globalen Governance können die nationalen Regierungen individuell handeln, um die globalen Katastrophen besser zu verstehen, zu mildern und vorzubereiten. Im Jahr 2018 forderte der Club of Rome mehr Klimaschutz und veröffentlichte seinen Klimaschutzplan, der zehn Aktionspunkte zur Begrenzung der globalen durchschnittlichen Temperaturerhöhung auf 1,5 Grad Celsius vorschlägt. Darüber hinaus veröffentlichte der Club 2019 den umfassenderen Planetary Emergency Plan. Organisationen Das Bulletin der Atomwissenschaftler (est. 1945) ist eine der ältesten globalen Risikoorganisationen, die nach der Aufklärung der Öffentlichkeit durch das Potenzial der Atomkriegsführung im Jenseits des Zweiten Weltkriegs gegründet wurde. Es untersucht Risiken im Zusammenhang mit Atomkrieg und Energie und hält die 1947 gegründete Doomsday-Uhr berühmt. Das Foresight Institute (est. 1986) untersucht die Risiken der Nanotechnologie und deren Vorteile. Es war eine der frühesten Organisationen, die unbeabsichtigten Folgen einer ansonsten harmlosen Technologie zu untersuchen, die in globaler Hinsicht Heuwire verschwand. Es wurde von K. Eric Drexler gegründet, der "grey goo" postulierte. Ab dem Jahr 2000 hat eine wachsende Zahl von Wissenschaftlern, Philosophen und Technologie-Milliardären Organisationen geschaffen, die sich der Untersuchung globaler Risiken sowohl innerhalb als auch außerhalb der Wissenschaft widmen. Unabhängige Nichtregierungsorganisationen (NGOs) umfassen das Machine Intelligence Research Institute (est. 2000), das das Risiko einer durch künstliche Intelligenz verursachten Katastrophe mit Spendern wie Peter Thiel und Jed McCaleb reduzieren soll. Die Nukleare Bedrohungsinitiative (est. 2001) versucht, globale Bedrohungen aus nuklearen, biologischen und chemischen Bedrohungen zu reduzieren und Schäden nach einer Veranstaltung einzudämmen. Er hält einen nuklearen Sicherheitsindex aufrecht. Die Lifeboat Foundation (est. 2009) fördert die Forschung zur Verhinderung einer technologischen Katastrophe. Die meisten Forschungsgeldfondsprojekte an Universitäten. Das Global Catastrophic Risk Institute (est. 2011) ist ein Think Tank für katastrophale Risiken. Es wird von der NGO Social and Environmental Entrepreneurs finanziert. Die Global Challenges Foundation (est. 2012) mit Sitz in Stockholm, die von Laszlo Szombatfalvy gegründet wurde, veröffentlicht einen jährlichen Bericht über den Stand der globalen Risiken. Das Future of Life Institute (est. 2014) zielt darauf ab, Forschung und Initiativen zum Schutz des Lebens bei der Erarbeitung neuer Technologien und Herausforderungen der Menschheit zu unterstützen. Elon Musk ist einer der größten Spender. Das Center on Long-Term Risk (est. 2016), das früher als Foundational Research Institute bekannt ist, ist eine britische Organisation, die darauf abzielt, Risiken des astronomischen Leidens (s-Risikos) aus aufstrebenden Technologien zu reduzieren. Zu den universitären Organisationen zählen die Future of Humanity Institute (est. 2005), die die Fragen der langfristigen Zukunft der Menschheit erforscht, insbesondere das existentielle Risiko. Es wurde von Nick Bostrom gegründet und ist an der Oxford University. Das Centre for the Study of Existential Risk (est. 2012) ist eine Cambridge University-basierte Organisation, die vier große technologische Risiken untersucht: künstliche Intelligenz, Biotechnologie, globale Erwärmung und Kriegsführung. Alle sind menschgemachte Risiken, wie Huw Price der AFP-Nachrichtenagentur erklärt, "Es scheint eine vernünftige Vorhersage, dass einige Zeit in diesem oder dem nächsten Jahrhundert Intelligenz aus den Zwängen der Biologie entkommen wird". Er fügte hinzu, dass, wenn dies geschieht "wir sind nicht mehr die klügsten Dinge um," und wird riskieren, in der Gnade von "Maschinen, die nicht bösartig sind, aber Maschinen, deren Interessen uns nicht enthalten."Stephen Hawking war ein handelnder Berater. Die Millennium Alliance for Humanity and the Biosphere ist eine Stanford University-basierte Organisation, die sich auf viele Fragen im Zusammenhang mit der globalen Katastrophe konzentriert, indem sie Mitglieder der Wissenschaft in den Geisteswissenschaften zusammenbringt. Sie wurde unter anderem von Paul Ehrlich gegründet. Die Stanford University verfügt außerdem über das Zentrum für internationale Sicherheit und Zusammenarbeit, das sich auf politische Zusammenarbeit konzentriert, um das globale Katastrophenrisiko zu reduzieren. Das Center for Security and Emerging Technology wurde im Januar 2019 an der Walsh School of Foreign Service von Georgetown gegründet und wird sich auf die Politikforschung der aufstrebenden Technologien mit einem ersten Schwerpunkt auf künstlicher Intelligenz konzentrieren. Sie erhielten einen Zuschuss von 55M USD von Good Ventures, wie es vom Open Philanthropy Project vorgeschlagen wurde. Andere Risikobewertungsgruppen sind in oder sind Teil staatlicher Organisationen. Die Weltgesundheitsorganisation (WHO) umfasst eine Abteilung namens Global Alert and Response (GAR), die die globale Epidemiekrise überwacht und reagiert. GAR unterstützt die Mitgliedsstaaten bei der Ausbildung und Koordination der Reaktion auf Epidemien. Die United States Agency for International Development (USAID) hat ihr Emerging Pandemic Threats Programm, das darauf abzielt, natürlich erzeugte Pandemien an ihrer Quelle zu verhindern und zu enthalten. Das Lawrence Livermore National Laboratory hat eine Abteilung namens Global Security Principal Direktion, die im Auftrag der Regierung Themen wie Bio-Sicherheit und Gegenterrorismus untersucht. Geschichte Frühe Geschichte des Denkens an menschliche Auslöschung Vor dem 18. und 19. Jahrhundert wurde die Möglichkeit, dass Menschen oder andere Organismen aussterben könnten, mit Skepsis betrachtet. Es widersprach dem Grundsatz der Würde, einer Lehre, dass alle möglichen Dinge existieren. Das Prinzip geht auf Aristoteles zurück und war ein wichtiger Tenet der christlichen Theologie. Die Lehre wurde allmählich durch Beweise aus den Naturwissenschaften untergraben, insbesondere die Entdeckung fossiler Beweise von Arten, die schien nicht mehr existieren, und die Entwicklung von Theorien der Evolution. In On the Origin of Species diskutiert Darwin das Aussterben von Arten als natürlichen Prozess und Kernbestandteil der natürlichen Selektion. Bemerkenswerterweise war Darwin skeptisch über die Möglichkeit plötzlicher Auslöschungen und betrachtete es als ein allmählicher Prozess. Er stellte fest, dass das abrupte Verschwinden von Arten aus dem Fossilienrekord keine Anzeichen für katastrophale Auslöschungen waren, sondern eine Funktion von unrekognisierten Lücken in der Aufzeichnung waren. Da die Möglichkeit des Aussterbens in den Wissenschaften weit verbreitet wurde, so die Aussicht auf die menschliche Auslöschung. Jenseits der Wissenschaft wurde das menschliche Aussterben in der Literatur untersucht. Die romanischen Autoren und Dichter waren besonders an dem Thema interessiert. Lord Byron schrieb über das Aussterben des Lebens auf der Erde in seinem 1816 Gedicht „Darkness“ und in 1824 sah die Menschheit von einem Kometenschlag bedroht und ein Raketensystem zur Verteidigung gegen ihn an. Mary Shelleys 1826 Roman Der Letzte Mann ist in einer Welt aufgestellt, in der die Menschheit durch eine geheimnisvolle Pest fast zerstört wurde. Atomzeit Die Erfindung der Atombombe führte zu einer Diskussionswelle über das Risiko menschlicher Auslöschung unter Wissenschaftlern, Intellektuellen und der Öffentlichkeit. In einem Aufsatz von 1945 schrieb Bertrand Russell, dass ["T] die Aussicht auf die menschliche Rasse über alle Präzedenzfälle hinweg verblüfft ist. Die Menschheit ist mit einer klaren Alternative konfrontiert: entweder werden wir alle umkommen, oder wir müssen ein wenig gesunden Menschenverstand erwerben. "Eine Gallup-Umfrage von 1950 fand, dass 19% der Amerikaner glaubten, dass ein weiterer Weltkrieg "ein Ende der Menschheit" bedeuten würde. Die Entdeckung des 'nuklearen Winters' in den frühen 1980er Jahren, ein spezifischer Mechanismus, durch den der Atomkrieg zu menschlichem Aussterben führen könnte, hob das Problem wieder auf. Über diese Befunde im Jahre 1983 zu schreiben, argumentierte Carl Sagan, dass die Messung der Auslöschung nur in Bezug auf diejenigen, die sterben "betont seine volle Wirkung", und dass der Atomkrieg "wirft alle unsere Nachkommen, solange es Menschen sein wird". Moderne Ära John Leslie's 1996 Buch Das Ende der Welt war eine akademische Behandlung der Wissenschaft und Ethik des menschlichen Aussterbens. In ihm betrachtete Leslie eine Reihe von Bedrohungen für die Menschheit und was sie gemeinsam haben. Im Jahr 2003, British Astronom Royal Sir Martin Rees veröffentlichte unsere letzte Stunde, in der er argumentiert, dass Fortschritte in bestimmten Technologien neue Bedrohungen für das Überleben der Menschheit verursachen, und dass das 21. Jahrhundert ein kritischer Moment in der Geschichte sein kann, wenn das Schicksal der Menschheit beschlossen wird. Herausgegeben von Nick Bostrom und Milan M. Ćirković, Global Catastrophic Risks wurde 2008 veröffentlicht, eine Sammlung von Essays aus 26 Akademikern zu verschiedenen globalen katastrophalen und existenziellen Risiken. Toby Ord's 2020 Buch The Precipice: Existential Risk and the Future of Humanity argumentiert, dass die Prävention existentieller Risiken eines der wichtigsten moralischen Probleme unserer Zeit ist. Das Buch diskutiert, quantifiziert und vergleicht unterschiedliche existentielle Risiken und schließt damit ab, dass die größten Risiken durch unausgeglichene künstliche Intelligenz und Biotechnologie dargestellt werden. Siehe auch Hinweise Weiter lesen Toby Ord (2020). The Precipice - Existential Risk and the Future of Humanity. Bloomsbury Publishing.ISBN 9781526600219 Holt, Jim. "The Power of Catastrophic Thinking" (Review von Toby Ord, The Precipice: Existential Risk and the Future of Humanity, Hachette, 2020, 468 pp.) The New York Review of Books, vol.LXVIII, no. 3 (25. Februar 2021,) pp. 26–29.Jim Holt schreibt (S. 28:) "Ob Sie nach einer Heilung für Krebs suchen oder eine wissenschaftliche oder künstlerische Laufbahn verfolgen oder sich mit der Schaffung von mehr gerechten Institutionen beschäftigen, ist eine Bedrohung für die Zukunft der Menschheit auch eine Bedrohung für die Bedeutung dessen, was Sie tun. "Avin, Shahar; Wintle, Bonnie C.; Weitzdörfer, Julius; ó Héigeartaigh, Seán S.; Sutherland, William J.; Rees, Martin J. (2018). "Klassifizierung globaler katastrophaler Risiken". Futures.102: 20–26.doi:10.1016/j.futures.2018.02.001. Corey S. Powell (2000). " Zwanzig Wege, wie die Welt plötzlich enden konnte", Discover Magazine Martin Rees (2004.)Unsere letzte Stunde: A Scientists Warnung: Wie Terror, Fehler und Umweltunfälle die Zukunft der Menschheit in diesem Jahrhundert gefährden – auf der Erde und darüber hinaus. ISBN 0-465-06863-4 Jean-Francois Rischard (2003). High Noon 20 Global Probleme, 20 Jahre zu Solve Them.ISBN 0-465-07010-8 Edward O. Wilson (2003). Die Zukunft des Lebens.ISBN 0-679-76811-4 Roger-Maurice Bonnet und Lodewijk Woltjer, überleben 1000 Centuries können wir es tun?(2008,) Springer-Praxis Bücher. Derrick Jensen (2006) Endgame (ISBN 1-58322-730-X). Jared Diamond, Kollaps: Wie Gesellschaften entscheiden sich für Fail oder Succeed, Pinguin Books, 2005 und 2011 (ISBN 9780241958681). Huesemann, Michael H. und Joyce A. Huesemann (2011). Technofix: Warum Technologie uns oder die Umwelt nicht retten kann, Kapitel 6, "Nachhaltigkeit oder Zusammenbruch", New Society Publishers, Gabriola Island, British Columbia, Kanada, 464 Seiten (ISBN 0865717044). Joel Garreau, Radical Evolution, 2005 (ISBN 978-0385509657).John A. Leslie (1996). Das Ende der Welt (ISBN 0-415-14043-9). Donella Meadows (1972). Die Grenzen des Wachstums (ISBN 0-87663-165-0). Joseph Tainter, (1990).The Collapse of Complex Societies, Cambridge University Press, Cambridge, UK (ISBN 9780521386739.) Externe Links Geschäftsberichte zum globalen Risiko durch das Global Challenges Foundation Center on Long-Term Risk "What a way to go" von The Guardian. Zehn Wissenschaftler nennen die größten Gefahren für die Erde und bewerten die Chancen, die sie passieren werden. 14. April 2005. Stephen Petranek: 10 Wege, wie die Welt enden könnte, ein TED-Gespräch "Top 10 Wege zur Zerstörung der Erde".livescience.com.LiveScience.Archiviert vom Original am 2011-01. Sind wir auf dem Weg zum Zivilisationszusammenbruch?" BBC.19. Februar 2019. Globale Katastrophe Risk Policy Humanity unter Bedrohung durch perfekten Krisensturm – Studie. Der Guardian. 6. Februar 2020. Ein Workaholic ist eine Person, die zwangsweise arbeitet. Der Begriff stammt aus dem Alkoholismus. Die Person arbeitet auf Kosten ihres Schlafes und soziale Funktionen wie Treffen Freunde oder Familie. Während der Begriff nicht unbedingt bedeutet, dass die Person ihre Arbeit genießt, kann es bedeuten, dass sie einfach fühlen sich gezwungen, es zu tun. Es gibt keine allgemein anerkannte medizinische Definition eines solchen Zustands, obwohl einige Formen von Stress, Impulskontrolle Störung, obsessive-kompulsive Persönlichkeitsstörung, und obsessive-kompulsive Störung kann arbeitsbedingt sein; Ergomanie ist definiert als "übermäßige Hingabe, besonders als Symptom der psychischen Krankheit zu arbeiten". Die heikle Kultur ist ein Neologismus für den Workaholismus, der sich mit einer übermäßigen Hingabe an die Arbeit des einen zum Ausschluss jedes anderen Lebensaspektes zusammensetzt und ein ungesundes Work-Life-Balance schafft. Etymologie Das Wort selbst ist ein Portmanteau-Wort aus Arbeit und Alkoholiker. Sein erstes bekanntes Aussehen, nach dem Oxford Englischen Wörterbuch, kam in Kanada in der Toronto Daily Star vom 5. April 1947, Seite 6, mit einer Pünnning Allusion zu Alkoholics Anonymous: Wenn Sie mit einem unüberwindlichen Verlangen nach Arbeit verflucht werden, rufen Sie Workaholics Synonymous an und ein reformierter Arbeiter hilft Ihnen zurück zu glücklicher Leere. Details Der Begriff workaholic bezieht sich auf verschiedene Arten von Verhaltensmustern, wobei jeder seine eigene Bewertung hat. Zum Beispiel wird der Workaholismus manchmal von Menschen verwendet, die ihre Hingabe an die eigene Karriere positiv ausdrücken möchten. Die Arbeit ist in der Regel mit einem zahlenden Job verbunden, aber es kann auch auf unabhängige Aktivitäten wie Sport, Musik, Kunst und Wissenschaft. Der Begriff wird jedoch häufiger verwendet, um auf ein negatives Verhaltensmuster zu verweisen, das populärerweise dadurch gekennzeichnet ist, dass eine übermäßige Zeit am Arbeiten verbracht wird, ein innerer Zwang, hart zu arbeiten und eine Vernachlässigung der Familie und anderer sozialer Beziehungen. Forscher haben festgestellt, dass in vielen Fällen auch nach dem Einfluss auf die Beziehungen und die körperliche Gesundheit des Subjekts unaufhörliche arbeitsbezogene Aktivitäten fortgesetzt werden. Ursachen davon werden als Angst, niedriges Selbstwertgefühl und Intimitätsprobleme gedacht. Darüber hinaus neigen Workaholics zu einer Unfähigkeit, Arbeitsaufgaben anderen zu übertragen und neigen dazu, hohe Punkte auf Persönlichkeitsmerkmale wie Neurotik, Perfektionismus und Gewissenhaftigkeit zu erhalten. Klinische Psychologe Bryan E. Robinson identifiziert zwei Achsen für Workaholics: Arbeitsinitiierung und Arbeitsvollende. Er assoziiert das Verhalten der Procrastination sowohl mit "Savoring Workaholics" (diese mit geringer Arbeitsinitiation/niedriger Arbeitsvervollständigung) als auch mit "Attention-Deficit Workaholics" (diese mit hoher Arbeitsinitiation und geringer Arbeitsvervollständigung) im Gegensatz zu Bulimic und Relentless Workaholics – beide haben einen hohen Arbeitsabschluss. Der Workaholismus in Japan gilt als ein ernstes soziales Problem, das zu einem frühen Tod führt, oft auf dem Job, ein Phänomen, das karōshi gegraben wurde. Überarbeit wurde für den tödlichen Schlag des japanischen Premierministers Keizō Obuchi im Jahr 2000 populär verantwortlich gemacht. Der Tod von Überarbeit ist kein einzigartiges japanisches Phänomen; 2013 starb eine Bank of America intern in London nach 72 Stunden direkt. Die Arbeitsämter sind in der Regel weniger wirksam als andere Arbeitnehmer, weil sie Schwierigkeiten haben, als Teil eines Teams zu arbeiten, Probleme zu delegieren oder zu verantworten Mitarbeiter oder organisatorische Probleme, weil zu viel Arbeit auf einmal. Darüber hinaus leiden die Workaholics oft unter Schlafentzug, was zu beeinträchtigtem Gehirn und kognitiver Funktion führt. Das Geschäftsrisiko, das Workaholism präsentiert, ist ein unterschätztes Risiko in Unternehmen und Personalmanagement, das zu einer existenziellen Bedrohung für ein Unternehmen entwickeln kann. Siehe auch Burnout Karoshi Downshifting (lifestyle) Money-rich, time-poor Presenteeism Workplace stress Power Belassment Work aversion Workaholics Anonymous Work ethic Protestant work ethic References Externe Links Die Ökonomie des Workaholismus