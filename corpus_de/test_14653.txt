Die rechnerische Fotografie bezieht sich auf digitale Bildaufnahme- und Verarbeitungstechniken, die anstelle optischer Prozesse digitale Berechnungen verwenden. Die rechnerische Fotografie kann die Fähigkeiten einer Kamera verbessern oder Funktionen einführen, die überhaupt nicht mit filmbasierter Fotografie möglich waren, oder die Kosten oder Größe von Kameraelementen reduzieren. Beispiele für die rechnerische Fotografie sind die In-Kamera-Rechnung von digitalen Panoramas, hochdynamischen Bildern und Lichtfeldkameras. Lichtfeldkameras verwenden neue optische Elemente, um dreidimensionale Szeneninformationen zu erfassen, die dann zur Erstellung von 3D-Bildern, einer verbesserten Tiefenfeldtiefe und einer selektiven Defokussion (oder "Postfokus") verwendet werden können. Verbesserte Tiefenfeldtiefe reduziert den Bedarf an mechanischen Fokussiersystemen. Alle diese Funktionen verwenden rechnerische Bildgebungstechniken. Die Definition der rechnerischen Fotografie hat sich entwickelt, um eine Reihe von Themenbereichen in Computergrafiken, Computervision und angewandter Optik zu decken. Diese Bereiche werden im Folgenden nach einer von Shree K. Nayar vorgeschlagenen Taxonomie organisiert. In jedem Bereich ist eine Liste von Techniken, und für jede Technik werden ein oder zwei repräsentative Papiere oder Bücher zitiert. Von der Taxonomie ausgelassen werden Bildverarbeitungstechniken (siehe auch digitale Bildverarbeitung) auf traditionell erfasste Bilder angewendet, um bessere Bilder zu erzeugen. Beispiele für solche Techniken sind Bildskalierung, dynamische Bereichskompression (d.h. Ton Mapping), Farbmanagement, Bildvervollständigung (a.k.a.Inpainting oder Lochfüllung), Bildkompression, digitale Wassermarkierung und künstlerische Bildeffekte. Es werden auch Techniken weggelassen, die Entfernungsdaten, Volumendaten, 3D-Modelle, 4D-Lichtfelder, 4D, 6D oder 8D-Breitbänder oder andere hochdimensionale bildbasierte Darstellungen erzeugen. Epsilon Photography ist ein Unterfeld der rechnerischen Fotografie. Auswirkungen auf die Fotografie Fotos, die mit der rechnerischen Fotografie gemacht werden, können Amateure erlauben, Fotos zu produzieren, die die Qualität der professionellen Fotografen rivalisieren, aber derzeit nicht übertreffen die Verwendung von professionellen Geräten auf der Ebene. Berechnung der Ausleuchtung Dies steuert die fotografische Beleuchtung strukturiert und verarbeitet dann die erfassten Bilder, um neue Bilder zu erstellen. Zu den Anwendungen gehören bildbasiertes Relighting, Bildverbesserung, bilddeblurring, Geometrie/Materialwiederherstellung und so weiter. Die hochdynamische Bildgebung nutzt unterschiedlich belichtete Bilder derselben Szene, um den Dynamikbereich zu erweitern. Weitere Beispiele sind die Verarbeitung und Verschmelzung von unterschiedlich beleuchteten Bildern desselben Gegenstands (Lichtraum). Rechentechnik Dies ist die Erfassung optisch kodierter Bilder, gefolgt von der rechnerischen Decodierung, um neue Bilder zu erzeugen. Die kodierte Apertur-Bildgebung wurde hauptsächlich in der Astronomie oder Röntgen-Bildgebung angewendet, um die Bildqualität zu steigern. Anstelle eines einzelnen Loches wird ein Lochmuster in der Abbildung aufgetragen, und die Dekonvolution wird durchgeführt, um das Bild wiederherzustellen. In der codierten Belichtungsbildgebung wird der Ein-/Aus-Zustand des Shutters kodiert, um den Bewegungskern zu verändern. Auf diese Weise wird Bewegung Entblurring zu einem gut konditionierten Problem. Ebenso kann in einer linsenbasierten codierten Öffnung die Blende durch Einfügen einer Breitbandmaske verändert werden. Aus dem Fokus entblurringt sich somit ein gut konditioniertes Problem. Die kodierte Blende kann auch die Qualität bei der Lichtfelderfassung mit Hadamard-Transformationsoptik verbessern. Kodierte Blendenmuster können auch mit Farbfiltern gestaltet werden, um unterschiedliche Codes bei unterschiedlichen Wellenlängen anzuwenden. Dadurch kann die Lichtmenge, die den Kamerasensor erreicht, im Vergleich zu binären Masken erhöht werden. Computational Abbildung Computational Abbildung ist eine Reihe von Abbildungstechniken, die Datenerfassung und Datenverarbeitung kombinieren, um das Bild eines Objekts durch indirekte Mittel zu erzeugen, um erhöhte Auflösung, zusätzliche Informationen wie optische Phase oder 3D-Rekonstruktion zu liefern. Die Information wird oft ohne Verwendung einer herkömmlichen optischen Mikroskopkonfiguration oder mit begrenzten Datensätzen aufgezeichnet. Die rechnerische Bildgebung erlaubt es, über physische Grenzen von optischen Systemen, wie numerische Apertur hinauszugehen oder sogar die Notwendigkeit optischer Elemente zu vernichten. Für Teile des optischen Spektrums, bei denen bildgebende Elemente wie Objektive schwierig herstellbar sind oder Bildsensoren nicht miniaturisiert werden können, bietet die rechnerische Abbildung nützliche Alternativen, z.B. in Bereichen wie Röntgen- und THz-Strahlung. Gemeinsame Techniken Zu den gängigen rechnerischen Bildgebungstechniken gehören linsenlose Bildgebung, rechnerische Spekkle-Bildgebung, Ptychographie und Fourier-Ptychographie. Die rechnerische Bildgebungsverfahren zeichnen sich oft auf Druck- oder Phasenabruftechniken ab, wo das Winkelspektrum des Objekts rekonstruiert wird. Andere Techniken beziehen sich auf das Gebiet der rechnerischen Bildgebung, wie digitale Holographie, Computervision und inverse Probleme wie Tomographie. Berechnungsmethode Dies ist die Verarbeitung von nicht-optisch kodierten Bildern, um neue Bilder zu erstellen. Rechensensoren Dies sind Detektoren, die die Erfassung und Verarbeitung, typischerweise in Hardware, wie der übersampled binäre Bildsensor kombinieren. Frühe Arbeit in der Computervision Obwohl die rechnerische Fotografie ein derzeit beliebtes Schlagwort in Computergrafiken ist, erschienen viele seiner Techniken zunächst in der Computer-Visionsliteratur, entweder unter anderen Namen oder in Papieren, die auf 3D-Formanalysen abzielen. Die kunsthistorische Computational Fotografie wurde als Kunstform durch die Aufnahme von unterschiedlich exponierten Bildern desselben Themas und die Zusammenführung derselben geübt. Dies war die Inspiration für die Entwicklung des tragbaren Computers in den 1970er und Anfang der 1980er Jahre. Die rechnerische Fotografie wurde von der Arbeit von Charles Wyckoff inspiriert, und so werden rechnerische Fotografiedatensätze (z.B. unterschiedlich belichtete Bilder desselben Subjekts, die zur Herstellung eines einzigen Verbundbildes genommen werden) manchmal als Wyckoff Sets bezeichnet. Frühe Arbeiten in diesem Bereich (gemeinsame Schätzung der Bildprojektion und des Belichtungswerts) wurden von Mann und Candoccia durchgeführt. Charles Wyckoff widmete sich viel seines Lebens, um spezielle Arten von 3-Schicht-Fotofilmen zu schaffen, die verschiedene Belichtungen desselben Themas erfassten. Ein Bild einer Atomexplosion, aufgenommen auf Wyckoffs Film, erschien auf dem Cover des Life Magazine und zeigte den dynamischen Bereich von dunklen Außenbereichen bis zum inneren Kern. Siehe auch Adaptive Optik Multispektral-Bildgebung Gleichzeitige Lokalisierung und Kartierung Super-Resolution MikroskopieTime-of-flight Kamera Referenzen Externe Links Nayar, Shree K. (2007). "Computational Cameras", Konferenz über Machine Vision Anwendungen. Berechnung Fotografie (Raskar, R,. Tumblin, J),. A.K Peters. In der Presse. Sonderausgabe zur Computational Photography, IEEE Computer, August 2006. Camera Culture and Computational Journalism: Erfassung und Weitergabe von visuellen Erfahrungen, IEEE CG&A Special Issue, Feb 2011. Rick Szeliski (2010,) Computer Vision: Algorithmen und Anwendungen, Springer.Computational Fotografie: Methoden und Anwendungen (Ed.Rastislav Lukac,) CRC Presse, 2010. Intelligente Bildbearbeitung (John Wiley und Sons Buchinformationen). Die rechnerischen Gleichungen. GJB-1: Erhöhung des dynamischen Bereichs einer Digitalkamera durch Anwendung des Wyckoff-Prinzips Beispiele für verschleißfähige Rechenfotografie als Kunstform Siggraph Course in Computational Photography