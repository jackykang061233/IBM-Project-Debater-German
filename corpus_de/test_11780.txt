versteckten Markov-Modell (HMM) ist ein statistisches Markov-Modell, bei dem das System als Markov-Prozess gewertet wird – rufen Sie X SSOdisplaystyle X} – mit unobservierbaren (versteckten) Staaten. HMM geht davon aus, dass es ein weiterer Prozess Y WELLdisplaystyle Y} ist, dessen Verhalten von X {\displaystyle X} abhängt. Das Ziel ist es, über X {\displaystyle X} zu erfahren, indem Y Memestyle Y} .HMM sieht vor, dass jedes Mal n 0 n 0 faserstyle n_{0} , die Bedingung, dass der Vertrieb von Y n 0 Memestyle Y_{n_{n_{0} in der Geschichte { Xn = Xn = n = n= n= n n= n X_{n}=x_{n}\}_{n\leq n_{0} darf nicht davon abhängen, ob { x n } n  0 n 0 displaystyle x_{n__{n_{0 .Hidden Markov Modelle sind bekannt für ihre Anwendungen in Thermodynamik, statistische Mechanismen, Physik, Chemie, Wirtschaft, Finanzen, Signalverarbeitung, Informationstheorie, Mustererkennung - wie Rede, Handschrift, Gestenerkennung, Teil-of-speech-Tagung, musikalische Bewertung nach, Teilableitungen und Bioinformatik. Definition Let X n {\displaystyle X_{n} und Y n {\displaystyle Y_{n} sind diskretionäre Prozesse und n ≥ 1 KINGstyle n\geq 1} .Das Paar ( X n , Y n ) Memestyle (X_{n},Y_{n) ist ein verstecktes Markov-Modell, wenn X n RARstyle X_{n} ein Markov-Prozess ist, dessen Verhalten nicht unmittelbar konservierbar ist (versteckt); P  A ( Y n  A A: X 1 = x 1 , ... n = x n = x n) = P   (J n  A A; X n = x n ) , Memedisplaystyle \operator 7.8 Mathematik {P} } WELLbigl (Y_{n Ain A\ WELLl: {1}=x_{1},\ldots ,X_{n}=x_{n}{\bigr )=\}operator {P} {P} } } {n.in A\ \ 574bigl (Y_{n} X_{n}=x_bigr } }, für jede Art, ≥ 1, \l}, Die Bundesstaaten des Prozesses X n WELLdisplaystyle X_{n} sind versteckte Staaten, und P  of ( Y n  A A | X n = x n ) {\displaystyle \operatorname liv {P} } WELLbigl (Y_{n Ain A\ ggiobigl | | X_{n}=x_{n}{\bigr )) wird als Emissionswahrscheinlichkeit oder Produktionswahrscheinlichkeit bezeichnet. Beispiele aus versteckten Urnen In seiner diskreten Form kann ein verstecktes Markov-Verfahren als allgemeines Auftreten des dringlichen Problems mit Ersatz ausgelegt werden (wo jeder Gegenstand aus dem Urn vor dem nächsten Schritt wieder in den ursprünglichen Urn zurückgekehrt ist). Betrachten Sie dieses Beispiel: In einem Raum, der nicht für einen Beobachter sichtbar ist, gibt es eine Genie. Das Zimmer enthält Dr. X1, X2, X3, ... jede von ihnen enthält eine bekannte Mischung von Kugeln, die jeweils auf dem Spiel sind. In diesem Raum wählt die Genie einen Drang aus und zieht Zufallsspiel aus. Er stellt dann den Ball auf einen Förderband, wo der Beobachter die Sequenz der Kugeln beobachten kann, aber nicht die Sequenz der Urnen, aus denen sie gezogen wurden. Die Genie hat ein gewisses Verfahren zur Wahl von Urnen; die Wahl des Urnen für den n-thischen Ball hängt nur von einer Zufallsnummer und der Wahl des Urnen für den (n-1)-th-Skandal ab. Die Wahl von Urn hängt nicht direkt von den vor diesem einzigen früheren Dr. gewählten Urnen ab; dies ist daher ein Markov-Prozess. Sie kann vom oberen Teil der Abbildung 1 beschrieben werden. Der Markov-Prozess selbst kann nicht beobachtet werden, nur die Sequenz der geetikettten Kugeln, so dass diese Regelung ein „verstecktes Markov-Verfahren“ genannt wird. Dies wird durch den geringeren Teil der in Abbildung 1 gezeigten Grafik veranschaulicht, wo man sehen kann, dass auf jeden Staat Hautfälscher y1, y2, y3, y4 gezogen werden können. Selbst wenn der Beobachter die Zusammensetzung der Urnen kennt und gerade eine Reihe von drei Kugeln beobachtet hat, z.B. y1, y2 und y3 auf dem Förderband, kann der Beobachter noch nicht sicher sein, was die Genie (d. h., auf welchem Staat) den dritten Ball ausgemacht hat. Jedoch kann der Beobachter andere Informationen wie die Wahrscheinlichkeit, dass der dritte Ball aus jedem der Urnen stammt, ausweisen. Wettervermutungsspiel betrachten zwei Freunde, Alice und Bob, die weit voneinander getrennt sind und die täglich über das Telefon sprechen, was sie am Tag haben. Bob ist nur an drei Aktivitäten interessiert: Gehen im Park, Einkaufen und Reinigung seiner Wohnung. Ihre Wahl hängt ausschließlich vom Wetter an einem bestimmten Tag ab. Alice hat keine klaren Informationen über das Wetter, aber sie kennt allgemeine Trends. Je nachdem, was Bob sagt, dass er jeden Tag begangen hat, versucht Alice, das Wetter zu schätzen. Alice glaubt, dass das Wetter als gesonderte Markov-Kette funktioniert. Es gibt zwei Staaten, Rainy und Sunny, aber sie können sie nicht direkt beobachten, was ist, sind sie von ihnen verborgen. Jeden Tag gibt es eine gewisse Chance, dass Bob eine der folgenden Aktivitäten ausführen wird, je nach Wetter: Fuß, Einkaufen oder sauber. Seit Bob Alice über seine Tätigkeit, dies sind die Beobachtungen. Das gesamte System ist das eines versteckten Markov-Modells (HMM). Alice kennt die allgemeinen Wettertrends in diesem Gebiet und was Bob durchschnittlich tun möchte. In anderen Worten sind die Parameter des HMM bekannt. Sie können wie folgt in der Graphik vertreten sein: In diesem Code stellt die Start_probability die Überzeugung von Alice dar, welchen Zustand der HMM bei den ersten Anrufen von Bob ist (allerdings weiß sie, dass es sich im Durchschnitt um Regen handelt). Die hier verwendete besondere Wahrscheinlichkeitsverteilung ist nicht das Gleichgewicht eines, das (angemessen an der Übergangszeit) etwa {Rainy: 0,57, Sunny: 0,43} ist. Die Überschreitenbarkeit ist die Änderung des Wetters in der zugrunde liegenden Markov-Kette. In diesem Beispiel gibt es nur eine Chance von 30 %, dass morgen die Sonne sein wird, wenn heute Regen ist. Die Emissions_probability stellt dar, wie wahrscheinlich Bob an jedem Tag eine bestimmte Tätigkeit ausüben kann. Wenn es sich um Regen handelt, gibt es eine 50 % Chance, dass er seine Wohnung saniert; wenn es sich um ein Sofa von 60 % handelt, dass er nicht für einen Spaziergang ist. Ein ähnliches Beispiel wird in der Viterbi-Algorithmusseite weiter ausgearbeitet. Strukturstruktur In der nachstehenden Abbildung wird die allgemeine Architektur eines unmittelbaren HMM dargestellt. Jede ovale Form stellt eine zufällige Variablen dar, die eine Reihe von Werten annehmen können. Die Zufallsvariable x(t) ist der versteckte Zustand der Zeit t (mit dem Modell der vorstehenden Abbildung, x(t) { x1, x2, x3 )}. Die zufällige variable y(t) ist die Beobachtung zum Zeitpunkt t (mit y(t) . { y1, y2,3, y4 )}. Die Pfeile im Diagramm (often bezeichnet ein Bild von Forellen) verdichteten Konditionen. Aus dem Diagramm ist klar, dass die bedingte Wahrscheinlichkeitsverteilung der versteckten variablen x(t) zum Zeitpunkt t, da die Werte der versteckten variablen x jederzeit nur vom Wert der versteckten variablen x(t − 1); die Werte zu Zeit t - 2 und vor keinem Einfluss. Dies ist der Markov-Besitzstand. Ebenso hängt der Wert der beobachteten variablen y(t) nur vom Wert der versteckten variablen x(t) (beide t) ab. In der Standardart des versteckten Markov-Modells, die hier in Betracht gezogen wird, ist der Zustand der versteckten Variablen frei, während die Beobachtungen selbst entweder einzeln (in der Regel aus einer kategorischen Verteilung) oder kontinuierlich (in der Regel aus einer Gausischen Verteilung) sein können. Kennzeichnend für ein verstecktes Markov-Modell sind zwei Arten, Übergangsprobabilities und Emissionsprobabilities (auch als Output-Probabilities bekannt). Die Übergangsprobativität kontrolliert die Art und Weise, wie der versteckte Staat zum Zeitpunkt der T-Zeit den versteckten Zustand erhält, ‐ 1 Memestyle t-1}. Der versteckte Staatsraum wird davon ausgegangen, dass eine von N möglichen Werten besteht, die als kategorischer Vertrieb konzipiert wurden. (Siehe den Abschnitt über Erweiterungen für andere Möglichkeiten).) Dies bedeutet, dass für jeden der N möglich ist, dass eine versteckte variabel sein kann, dass es eine Übergangswahrscheinlichkeit von diesem Staat zu jedem der N möglichen Staaten der verborgenen variablen Zeit t + 1 {\displaystyle t+1} für eine Gesamtzahl von N 2 Memestyle N N2} Übergangsprobabilities gibt. Hinweis darauf, dass die Übergangsvoraussetzungen für Übergänge aus jedem bestimmten Staat auf 1. So ist die N × N WELLdisplaystyle N\times N} Matrix von Übergangsprobabilities eine Markov-Matrix. Kann eine Übergangswahrscheinlichkeit festgelegt werden, sobald die anderen bekannt sind, gibt es eine Gesamtzahl von N (N - 1 ) HANAstyle N(N-1)} Übergangsparameter. Zusätzlich gibt es für jeden der N möglichen Staaten eine Reihe von Emissionsprobabilities, die die Verteilung der beobachteten variablen Variablen zu einem bestimmten Zeitpunkt vorsehen, da der Zustand der versteckten Variablen zu diesem Zeitpunkt stattfindet. Die Größe dieser Anlage hängt von der Art der beobachteten Variablen ab. Wenn beispielsweise die beobachtete Variablen mit M-Werten, die durch eine kategorische Verteilung bestimmt sind, sind M ‐ 1 {\displaystyle M-1} getrennte Parameter für eine Gesamtmenge von N ( M ‐ 1 ) Memestyle N(M-1)} Emissionsparameter für alle versteckten Staaten. Wenn die beobachtete Variablen hingegen ein M-dimensionaler Vektor sind, der nach einer willkürlichen multivariate Gausian-Vertrieb verteilt ist, gibt es M-Parameter, die die Mittel und M (M + 1 ) 2 KINGstyle SSOfrac M(M+1)}{2 Parameter, die die Kovarianzmatrix kontrollieren, für eine Gesamtzahl von N ( M + M ( M + 1 ) 2 ) = N M (M + 3 ) 2 = O (N M 2 ) Memedisplaystyle N\left(M+ggiofrac M(M+1)}{2)right)=ñrac NM(M+3)=2==O(NM22 Emissionsparameter). (In einem solchen Fall, es sei denn, der Wert von M ist klein, kann es praktischer sein, die Art der Kovarien zwischen einzelnen Elementen des Beobachtungsvektors zu beschränken, z.B. wenn man bedenkt, dass die Elemente voneinander unabhängig sind oder weniger restriktiv sind, unabhängig von allen, aber einer festen Anzahl an benachbarten Elementen. Gleichgültige Probleme sind mit versteckten Markov-Modellen verbunden, wie unten beschrieben. Wahrscheinlichkeit einer beobachteten Sequenz Die Aufgabe ist es, in Anbetracht der Parameter des Modells die Wahrscheinlichkeit einer bestimmten Outputsequenz am besten zu berechnen. Dies erfordert eine Zusammenfassung aller möglichen staatlichen Sequenzen: Wahrscheinlichkeit, eine Sequenz Y = y ( 0 ) , y ( 1 ) , ... , y (L − 1 ) Memedisplaystyle Y=y(0),y(1),\dots y(L-1) L der Länge L wird von P ( Y ) =  X X ( Y  X X ) P ( X) , KINGstyle P(Y)=\sum {X} (Y\PX\mid X)P(X)X, P (X) x 1 x) x 2, S. In Anwendung des Prinzips der dynamischen Programmierung kann dieses Problem auch effizient mithilfe des zukunftsgerichteten Algorithmus behandelt werden. Wahrscheinlichkeit der latenten Variablen Eine Reihe von damit zusammenhängenden Aufgaben verlangt die Wahrscheinlichkeit eines oder mehrerer der latenten Variablen, da die Parameter des Modells und eine Reihe von Beobachtungen y ( 1 ) , ... , y ( t) . . . . KINGstyle y(1),\dots ,y(t)}. Filterung In Anbetracht der Parameter des Modells und einer Reihe von Beobachtungen soll die Verteilung über versteckte Staaten der letzten latenten Variablen am Ende der Sequenz berechnet werden, d. h. an die P ( x ( t ) , ... , y ( t) ) ) . . . . . . ) . . ) .  |  | (1) (1)(t) \[\ y(1),\dots ,y(t)}. In der Regel wird diese Aufgabe verwendet, wenn die Sequenz der latenten Variablen als die zugrunde liegenden Staaten betrachtet wird, dass ein Prozess in einer Zeitreihenfolge mit entsprechenden Beobachtungen zu jedem Zeitpunkt eingeleitet wird. Dann ist es natürlich, am Ende über den Stand des Prozesses zu bitten. Dieses Problem kann effizient mithilfe des zukunftsweisenden Algorithmus behandelt werden. Kraft Dies ist ähnlich wie Filterung, bittet aber um die Verteilung einer latenten Variablen in der Mitte einer Sequenz, d. h. zu berechnen P ( x ( k ) , ... , y ( t ) . ) faserstil P(x(k)\ (\dots ,y(t)} für einige k · KINGstyle k <t} . Aus der oben beschriebenen Perspektive kann man davon ausgehen, dass die Wahrscheinlichkeitsverteilung über versteckte Staaten für einen Punkt in der Vergangenheit, im Vergleich zu Zeit t, als wahrscheinlich gilt. Der vorwärts gerichtete Algorithmus ist eine gute Methode für die Berechnung der glatten Werte für alle versteckten staatlichen Variablen. Wahrscheinliche Erklärung Im Gegensatz zu den vorherigen beiden geht es um die gemeinsame Wahrscheinlichkeit der gesamten Sequenz versteckter Staaten, die eine bestimmte Reihe von Beobachtungen erstellt haben (siehe Abbildung auf dem richtigen). Diese Aufgabe ist in der Regel anwendbar, wenn HMM auf verschiedene Arten von Problemen angewendet wird, für die die Aufgaben der Filterung und der Einfachheit gelten. Ein Beispiel ist ein Teil der Ausspechtung, wo die versteckten Staaten die zugrunde liegenden Teile der Rede repräsentieren, die einer beobachteten Reihenfolge der Worte entsprechen. In diesem Fall ist das, was von Interesse ist, die ganze Reihe von Teilen der Rede, nicht nur der Teil der Rede für ein einzelnes Wort, da Filterung oder ein reibungsloser Ablauf berechnet würden. Diese Aufgabe erfordert die Feststellung einer maximalen Anzahl möglicher Staatssequenzen und kann durch den Viterbi-Algorithmus effizient gelöst werden. Statistische Bedeutung Für einige der oben genannten Probleme kann es auch interessant sein, über statistische Bedeutung zu bitten. Was ist die Wahrscheinlichkeit, dass eine Sequenz, die aus irgendeiner Nullverteilung gezogen wird, eine HMM-H Wahrscheinlichkeit (im Falle des Forward-Algorithmus) oder eine höchstzulässige Staatssequenz (im Falle des Viterbi-Algorithmus) mindestens so groß wie eine bestimmte Outputsequenz haben wird? Wenn ein HMM verwendet wird, um die Relevanz einer Hypothesis für eine bestimmte Outputsequenz zu bewerten, zeigt die statistische Bedeutung die falsche positive Rate, die mit der Verweigerung der Hypothese für die Outputsequenz verbunden ist. Lernen In HMMs besteht die Aufgabe, aufgrund einer Produktionssequenz oder einer Reihe solcher Sequenzen die beste Reihe staatlicher Übergangs- und Emissionsprobabilities zu finden. Die Aufgabe besteht in der Regel darin, die höchstwahrscheinliche Schätzung der Parameter des HMM aufgrund der Serie von Outputsequenzen abzuleiten. Kein traktiver Algorithmus ist bekannt, um dieses Problem genau zu lösen, aber eine lokale Höchstwahrscheinlichkeit kann effizient mit dem Baum-Welch-Algorithmus oder dem Baldi-Chammn-Algorithmus abgeleitet werden. Der Baum-Welch-Algorithmus ist ein Sonderfall des erhoffnden maximalen Algorithmus. Wenn die HMMs für die Zeitvorhersage verwendet werden, werden anspruchsvollere Methoden zur Eingrenzung von Bayesian wie Markov Kette Monte Carlo (MCMC) als günstig für die Feststellung eines einzigen höchstmöglichen Wahrscheinlichkeitsmodells sowohl hinsichtlich Genauigkeit als auch Stabilität bezeichnet.Da MCMC erhebliche rechnerische Belastungen auferlegt, in Fällen, in denen die Rechenlast auch von Interesse ist, kann eine alternative Möglichkeit zur unterschiedlichen Annäherung an die Bewegungsfreiheit von Bayesian sein, z.B. eine ungefähre Differenzierung bietet eine Recheneffizienz, die mit der Erwartungs-maximisierung vergleichbar ist, während ein Genauigkeitsprofil nur geringfügig unter der genauen MCMC-Typ-Scheinhaltung liegt. Anwendungen HMMs können in vielen Bereichen angewendet werden, in denen das Ziel darin besteht, eine Datensequenz, die nicht unmittelbar zu überwachen ist (aber andere Daten, die von der Sequenz abhängig sind). Anwendungen umfassen: COUT-Finanzierung Single-Molekülkinetic Analysis Pressemitteilung Anerkennung der Rede, einschließlich Siri Redesynthese Teil-of-speechs-Tagung bei der Erfassung von maschinellen Übersetzung Teilial Gene-Entfernungs-Selbsterkennung der biosequences Time-Serienanalyse Aktivierung des Protein-Sequence-Sequence-Erkennung Metamorphic-Virus DNA-Hybridisierung kinetische Entdeckung der Verkehrsprognose Solarradiance variability History versteckte Markov Modelle wurden in einer Reihe statistischer Papiere von Leonard E und anderen Autoren beschrieben. Einer der ersten Anwendungen von HMMs war die Redeerkennung, beginnend Mitte der siebziger Jahre. In der zweiten Hälfte der 80er Jahre wurden HMMs auf die Analyse biologischer Sequenzen, insbesondere DNA, angewendet. Inzwischen sind sie im Bereich Bioinformatik allgegenwärtig geworden. Verlängerungen In den oben genannten versteckten Markov-Modellen ist der Zustand der versteckten Variablen diskret, während die Beobachtungen selbst entweder getrennt (normalerweise aus einem kategorischen Vertrieb) oder kontinuierlich (typischerweise aus einer Gausischen Verteilung) sein können. versteckte Markov-Modelle können auch allgemeinisiert werden, um kontinuierliche Staatsräume zu ermöglichen. Beispiele solcher Modelle sind diejenigen, bei denen der Markov-Prozess über versteckte Variablen ein lineares dynamisches System ist, das eine lineare Beziehung zwischen den jeweiligen Variablen und wo alle versteckten und beobachteten Variablen einer Gausischen Verteilung folgt. In einfachen Fällen, wie dem linearen dynamischen System, ist eine genaue Gleichgültigkeit (im vorliegenden Fall unter Verwendung des Kalman-Filters); im Allgemeinen ist jedoch eine genaue Gleichgültigkeit in HMMs mit kontinuierlichen latenten Variablen unwiderruflich, und es müssen ungefähre Methoden verwendet werden, wie das erweiterte Kalman-Filter oder das Partikelfilter. versteckte Markov-Modelle sind generative Modelle, bei denen die gemeinsame Verbreitung von Beobachtungen und versteckten Staaten oder gleichwertig sowohl die vorherige Verteilung versteckter Staaten (Übergangsprobabilitäten) als auch die bedingte Verbreitung von Beobachtungen in Staaten (die Emissionsprobativität) modelliert werden. Die oben genannten Algorithmen übernehmen implizit eine einheitliche Vorverteilung über die Übergangszeit. Jedoch ist es auch möglich, versteckte Markov-Modelle mit anderen Arten von Vorvertrieben zu erstellen. Ein offensichtlicher Kandidat, der angesichts der kategorischen Verteilung der Übergangsprobabilities die Dirichlet-Vertrieb ist, die vor der Verteilung der Kategorisierung erfolgt. In der Regel wird eine symmetrische Dirichlet-Vertrieb gewählt, die die Unwissenheit darüber widerspiegelt, welche Staaten in der Regel eher wahrscheinlicher sind als andere. Der einheitliche Parameter dieser Verteilung (unter dem Konzentrationsparameter) kontrolliert die relative Dichte oder Verminderung der entstehenden Übergangsmatrix. Eine Auswahl von 1 ergibt eine einheitliche Verteilung. Werte von mehr als 1 produzieren eine dichte Matrix, in der die Übergangsprobabilities zwischen Paaren von Staaten wahrscheinlich nahezu gleich sein werden. Werte weniger als 1 führen zu einer geringeren Matrix, in der für jeden Herkunftsstaat nur eine kleine Zahl von Zielstaaten nicht zuschussfähiger Übergangsprobabilities haben. Es ist auch möglich, einen zweistufigen Vorteil der Dirichlet-Vertrieb zu verwenden, in dem eine Dirichlet-Vertrieb (der obere Vertrieb) die Parameter eines anderen Dirichlet-Vertriebs (der niedrigeren Verteilung) regelt, der wiederum die Überkapazitäten regelt. Die obere Verteilung regelt die Gesamtverteilung der Staaten, wobei bestimmt wird, wie wahrscheinlich jeder Staat auftritt; der Konzentrationsparameter bestimmt die Besatzdichte oder Verminderung der Staaten. Eine solche zweistufige Vorverteilung, bei der sowohl Konzentrationsparameter als auch Konzentrationsparameter zur Herstellung von geringeren Verteilungen festgelegt werden, könnte zum Beispiel in unkontrollierter Teil-of-speech-Tagung nützlich sein, in denen einige Teilstücke der Rede viel häufiger auftreten als andere; Lernalgorithmen, die eine einheitliche Vorverteilung im Allgemeinen schlecht auf diese Aufgabe ausüben. Parameter dieser Art, mit nichtuniformen Vorvertriebenen, können unter Verwendung von Gibbs Probenahmen oder erweiterte Versionen des erwarteten Abbau-maximisierungsgorithmus genutzt werden. Eine Erweiterung der zuvor beschriebenen versteckten Markov-Modelle mit Dirichlet-Vorläufern nutzt einen Dirichlet-Prozess im Rahmen einer Dirichlet-Vertrieb. Diese Art des Modells ermöglicht eine unbekannte und möglicherweise unendliche Anzahl von Staaten. Es ist üblich, einen zweistufigen Dirichlet-Prozess zu verwenden, ähnlich dem zuvor beschriebenen Modell mit zwei Ebenen der Dirichlet-Vertrieb. Ein solches Modell ist ein hierarchisches Dirichlet-Verfahren verstecktes Markov-Modell oder HDP-HMM für kurze Zeit. Es wurde ursprünglich unter dem Namen "Infinite versteckte Markov Modell"[3] beschrieben und wurde in[4] weiter formalisiert. Eine andere Art der Verlängerung verwendet ein diskriminierendes Modell im Rahmen des generativen Modells von Standard-HMMs. Eine solche Art von Modellmodellen entwickelt direkt die bedingungslose Verteilung der versteckten Staaten angesichts der Beobachtungen, anstatt die gemeinsame Verteilung zu modellieren. Beispiel dieses Modells ist das so genannte höchsttropy Markov-Modell (MEMM), das den bedingten Vertrieb der Staaten mit logistischer Regression (auch bekannt als „maximales Eutropy-Modell“) ausschließt. Vorteil dieser Art von Modell ist, dass willkürliche Merkmale (d. h. Funktionen) der Beobachtungen modelliert werden können, so dass bereichsspezifische Kenntnisse des Problems Hand in das Modell eingespritzt werden können. Modelle dieser Art sind nicht auf die Modellierung direkter Abhängigkeiten zwischen einem versteckten Staat und seiner zugehörigen Beobachtung beschränkt; vielmehr sind die Merkmale naheliegender Beobachtungen, die Kombinationen der zugehörigen Beobachtung und die in der Nähe befindlichen Beobachtungen oder willkürliche Beobachtungen auf jeder Entfernung von einem bestimmten versteckten Staat in den Prozess einbezogen, der zur Bestimmung des Wertes eines versteckten Staates verwendet wird. Darüber hinaus besteht keine Notwendigkeit, diese Merkmale statistisch unabhängig voneinander zu sein, wie wäre der Fall, wenn diese Merkmale in einem generativen Modell verwendet wurden. Letztlich können willkürliche Merkmale über Paaren von benachbarten versteckten Staaten anstelle einfacher Übergänge genutzt werden. Nachteile solcher Modelle sind: (1) Die Arten von Vorvertrieben, die in versteckten Staaten platziert werden können, sind stark eingeschränkt; (2) Es ist nicht möglich, die Wahrscheinlichkeit einer willkürlichen Beobachtung vorherzusagen. Diese zweite Beschränkung ist in der Praxis oft nicht ein Problem, da viele gemeinsame Nutzungen von HMM nicht solche prädiktiven Probabilities erfordern. Eine Variante des zuvor beschriebenen diskriminierenden Modells ist das lineare zufällige Zufallsfeld. Es handelt sich um ein undirektiertes grafisches Modell (aka Markov Randomfeld) anstelle der gezielten grafischen Modelle von MEMM und ähnlichen Modellen. Vorteil dieser Art von Modell ist, dass es nicht unter das sogenannte Kennzeichnungsproblem von MEMM leidet und somit genauere Vorhersagen machen kann. Nachteil ist, dass die Ausbildung langsamer sein kann als für MEMM. Eine andere Variante ist jedoch das faktorielle versteckte Markov-Modell, das eine einheitliche Beobachtung ermöglicht, die auf die entsprechenden versteckten Variablen einer Reihe von K varistyle K} unabhängigen Markov-Ketten statt einer einzigen Markov-Kette zu binden. Es entspricht einem einzigen HMM, wobei N K Memedisplaystyle N NK} Staaten (wenn es N Memestyle N} für jede Kette gibt) und daher das Lernen in einem solchen Modell schwierig ist: für eine Sequenz der Länge T HANAdisplaystyle T}, ein einfacher Viterbi-Algorithmus hat Komplexität O (N 2 K T ) Memestyle O(N^{2KT,T) . Um eine genaue Lösung zu finden, könnte ein Kreisbaumgorithmus verwendet werden, aber es führt zu einer O (N K + 1 K T ) Memedisplaystyle O(N+1K+1}\,K\,T) Komplexität. In der Praxis könnten ungefähre Techniken wie unterschiedliche Ansätze verwendet werden. Alle oben genannten Modelle können erweitert werden, um weitere Abhängigkeiten zwischen versteckten Staaten zu ermöglichen, z.B. die Möglichkeit, dass ein bestimmter Staat von den vorherigen zwei oder drei Staaten und nicht einem einzigen vorherigen Staat abhängig sein kann; d. h. die Übergangsprobabilities werden auf drei oder vier benachbarten Staaten ausgedehnt (oder im Allgemeinen K Memestyle K} benachbarte Staaten). Nachteile solcher Modelle sind, dass dynamische Programmier-Algorithmen für die Ausbildung ein O (N K T ) Memestyle O(NKK}\,T)-Betriebszeit, für K Memestyle K} benachbarte Staaten und T HANAdisplaystyle T} Gesamtbemerkungen (d. h. eine Länge T Memestyle T} Markov Kette). Eine weitere jüngste Erweiterung ist das Triplet Markov-Modell, bei dem ein Hilfsprozess zur Modellierung einiger Datenspezifischer Merkmale hinzugefügt wird. Viele Varianten dieses Modells wurden vorgeschlagen. Man sollte auch auf die interessante Verbindung hinweisen, die zwischen der Theorie der Beweismittel und den dreit Markov-Modellen hergestellt wurde und die Daten im Zusammenhang mit Markovian und dem Modell von nichtstationären Daten verwechseln kann. Hinweis darauf, dass auch in der jüngsten Literatur alternative Multi-stream-Daten Fusionsstrategien vorgeschlagen wurden, z.B.Finly, eine andere Logik zur Lösung des Problems von nichtstationären Daten durch versteckte Markov-Modelle im Jahr 2012. Es besteht darin, ein kleines, wiederkehrendes Neuralnetz (RNN), speziell ein Speichernetz, einzusetzen, um die Entwicklung der zeitlichen Dynamik in den beobachteten Daten zu erfassen. Diese Informationen, die in Form eines hochdimensionalen Vektors kodiert werden, werden als Konstellationsvariable der HMM-Staatsübertretungen verwendet. Nach einer solchen Einrichtung erhalten wir schließlich ein nichtstationäres HMM, dessen Überkapazitäten sich im Laufe der Zeit in einer Weise entwickeln, die sich aus den Daten selbst ergeben, gegenüber einem unrealistischen Ad-hoc-Modell der zeitlichen Entwicklung. Das Modell, das im Zusammenhang mit den Längsschnittdaten geeignet ist, ist ein latentes Markov-Modell. Die grundlegende Version dieses Modells wurde erweitert, um individuelle Kovariate, Zufallseffekte und komplexere Datenstrukturen wie Daten auf mehreren Ebenen zu erfassen. Einen vollständigen Überblick über die latenten Markov-Modelle mit besonderer Aufmerksamkeit auf die Modellannahmen und deren praktische Anwendung finden Sie auch in Bezug auf externe Links Concepts Teif, V. B. Rippe, K. (2010). " Statistik-mechanische Lattice-Modelle für Protein-DNA verbindlich in Chromatin. J Pflanzen.:Condens.Matter.22 (41): 414105.arXiv:1004.5514.Bibcode:2010JPCM...22O4105T doi:10.1088/0953-8984/22/41/414105.PMID 21386588.S2CID 103345.A erwägen Einführung zu versteckten Markov Modellen durch Mark Stempel, San Jose State University. Fitting HMMs mit Erwartungs-maximisierung – vollständige Entivation A Schritt-by-Schritt-Werkzeuge zu HMMs (Universität Leeds)Hidden Markov Modelle (eine Vorablagerung auf Basis der Mathematik)Hidden Markov Modelle (von Narada Warakagoda)Hidden Markov Modelle: Grunds und Anwendungen Teil 1, Teil 2 (von V. Nikolaushin) Vorlesung über ein Spread von Jason Eisner, Video und interaktives