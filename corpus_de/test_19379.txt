Aktionsauswahl ist ein Weg, um das grundlegende Problem intelligenter Systeme aufzuzeigen: was nächstes tun soll. In der künstlichen Intelligenz und der rechnerischen kognitiven Wissenschaft ist das "Aktionsauswahlproblem" in der Regel mit intelligenten Agenten und Aimats – umfangreichen Systemen, die komplexes Verhalten in einem Agentenumfeld zeigen. Der Begriff wird manchmal auch in ethologie oder Tierhaltung verwendet. Ein Problem für das Verständnis der Aktionsauswahl ist die Menge der für die Angabe eines Akts verwendeten Exzellenz. Ein Atomakt könnte auf der Basis des abstrakten Niveaus alles von der Beschaffung einer Muskelzelle sein, um einen Krieg zu provozieren. In der Regel für einen Mechanismus zur Auswahl von Maßnahmen ist das Paket möglicher Maßnahmen vorab festgelegt und festgelegt. Die meisten Forscher in diesem Bereich stellen hohe Anforderungen an ihre Agenten: In der Regel muss der Wirkstoff seine Tätigkeit in dynamischen und unvorhersehbaren Umgebungen auswählen. Die Agenten handeln in der Regel in Echtzeit; daher müssen sie Entscheidungen rechtzeitig treffen. Die Agenten werden normalerweise geschaffen, um verschiedene Aufgaben zu erfüllen. Diese Aufgaben können bei der Ressourcenallokation (z.B. kann der Erreger ein Feuer stellen und gleichzeitig einen Kaffeebecher liefern?) Die Umwelt, die die Agenten in Betrieb nehmen, kann Menschen umfassen, die die Dinge für den Agenten schwieriger machen können (vorsätzlich oder durch Versuch, Hilfe zu leisten). Die Agenten selbst sind oft als Modelltiere oder Menschen gedacht, und das Tier- und Menschenverhalten ist sehr kompliziert. Aus diesen Gründen ist die Aktionsauswahl nicht unharmonisiert und zieht ein gutes Forschungsangebot an. Merkmale der Aktionsauswahl Das Hauptproblem der Aktionsauswahl ist komplex. Da alle Berechnungen sowohl Zeit als auch Raum (in Gedächtnis) erfordern, können die Erreger nicht in jedem Moment jede Option für sie in Betracht ziehen. Infolgedessen müssen sie unvoreingenommen sein und ihre Suche in gewisser Weise einschränken. Für AI ist die Frage der Aktionsauswahl der beste Weg, um diese Suche zu unterbinden? Zur Biologie undethologie ist die Frage, wie viele Arten von Tieren ihre Suche einschränken? Verwenden alle Tiere dieselben Ansätze? Warum verwenden sie die? Eine grundlegende Frage zur Aktionsauswahl ist, ob es wirklich ein Problem für einen Agenten ist oder ob es nur eine Beschreibung eines entstehenden Eigentums eines Verhaltens eines intelligenten Agenten ist. Wenn wir jedoch überlegen, wie wir einen intelligenten Agenten aufbauen wollen, dann muss es einen Mechanismus für die Auswahl der Maßnahmen geben. Dieser Mechanismus kann hoch verteilt werden (wie bei verteilten Organismen wie sozialen Insekten oder dünne Form), oder es kann ein spezielles Modul sein. Der Mechanismus für die Auswahl von Maßnahmen (ASM) bestimmt nicht nur die Maßnahmen des Agenten in Bezug auf die Auswirkungen auf die Welt, sondern legt auch ihre skeptische Aufmerksamkeit vor und aktualisiert sein Gedächtnis. Diese egozentrierten Arten von Maßnahmen können wiederum zu einer Änderung der grundlegenden Verhaltensweisen des Agenten führen, insbesondere wenn die Aktualisierung des Gedächtnisses eine gewisse Form des Maschinenlernens bedeutet. Idealerweise sollte die Aktionsauswahl selbst auch in der Lage sein, zu lernen und anzupassen, aber es gibt viele Probleme, Komplexität und Rechenfähigkeit miteinander zu kombinieren, die den Suchraum einschränken können. In der AI wird ein ASM manchmal auch als Substitutionsarchitektur oder als wesentlicher Bestandteil eines bezeichnet. AI-Mechanismen können im Allgemeinen in mehrere Kategorien unterteilt werden: symbolbasierte Systeme manchmal als klassische Planung, verteilte Lösungen und reaktive oder dynamische Planung. Manche Ansätze fallen nicht in eine dieser Kategorien. Andere sind wirklich mehr über die Bereitstellung wissenschaftlicher Modelle als die praktische AI-Kontrolle; die letzten werden im nächsten Abschnitt weiter beschrieben. Symbolische Ansätze früh in der Geschichte der künstlichen Intelligenz, wurde davon ausgegangen, dass der beste Weg für einen Agenten darin besteht, das zu wählen, was nächste tun soll, um einen wahrscheinlich optimalen Plan zu berechnen und diesen Plan anschließend auszuführen. Dies führte zu einer physikalischen Symbolsystemhypothese, dass ein physikalischer Wirkstoff, der Symbole ergreift, notwendig und ausreichend für Intelligenz ist. Viele Software-Beauftragte verwenden diesen Ansatz immer noch für die Auswahl. In der Regel müssen alle sensorischen Lesen, die Welt, alle Maßnahmen und alle Ziele eines einzelnen in gewisser Weise prädiktieren. Kritiker dieses Ansatzes beklagen, dass es für die Echtzeitplanung zu langsam ist und dass trotz der Nachweise immer noch keine optimalen Pläne erstellt werden können, weil die Beschreibungen der Realität auf Logik ein Prozess ist, der Fehler verursacht. Zufriedenheit ist eine Entscheidungsstrategie, die versucht, Kriterien für die Angemessenheit zu erfüllen, anstatt eine optimale Lösung zu finden. In der Tat kann es vorkommen, dass die Kosten des Entscheidungsprozesses selbst, wie die Kosten für die Erlangung vollständiger Informationen, im Ergebnis kalkuliert werden. zielorientierte Architekturen – In diesen symbolischen Architekturen wird das Verhalten des Agenten in der Regel durch eine Reihe von Zielen beschrieben. Jedes Ziel kann durch einen Prozess oder eine Tätigkeit erreicht werden, die durch einen beschreibenden Plan beschrieben wird. Der Agenten muss nur entscheiden, welche Schritte zur Erreichung eines bestimmten Ziels unternommen werden. Der Plan kann auf Subgos ausgedehnt werden, was den Prozess leicht recuriv macht. Technischer, mehr oder weniger werden die Voraussetzungen genutzt. Diese Architekturen sind reaktiv oder hybrid. Klassische Beispiele für zielgerichtete Architekturen werden durchführbare Verfeinerungen der Weltanschauungsarchitektur wie JAM oder IVE realisiert. Verteilte Ansätze Kontrast zum symbolischen Ansatz haben verteilte Systeme der Aktionsauswahl tatsächlich keine Box im Agenten, der die nächste Aktion beschließt. Mindestens in ihrer idealisierten Form verfügen verteilte Systeme über viele parallele Module und bestimmen die besten Maßnahmen auf der Grundlage lokaler Fachkenntnisse. In diesen idealisierten Systemen wird die Gesamtkohärenz erwartet, möglicherweise durch sorgfältige Gestaltung der Wechselwirkungen. Dieser Ansatz wird oft von der künstlichen Neuralnetzforschung inspiriert. In der Praxis gibt es fast immer ein zentralisiertes System, das bestimmt, welches Modul "die aktivste" ist oder die meisten Salze hat. Reale biologische Gehirne verfügen auch über solche Exekutiv-Entscheidungssysteme, die beurteilen, welche der konkurrierenden Systeme die größte Aufmerksamkeit verdienen oder noch besser sind. ASMO ist eine von Rony Novianto entwickelte Architektur auf der Website. Es zeichnet eine Vielfalt modularer verteilter Prozesse ab, die ihre eigenen Vertretungen und Techniken nutzen können, um die Umwelt zu betrachten, die Prozessinformationen zu verarbeiten, Maßnahmen zu planen und Maßnahmen vorzuschlagen. Verschiedene Arten von Gewinner-take-all-Architekturen, in denen die einzige ausgewählte Maßnahme die volle Kontrolle über die Aktivierung des Kraftfahrzeugsystems einschließlich der Übernahme von Maes Nets (ANA) übernimmt Erweiterte Rosenblatt & Payton ist eine von Toby Tyrrell 1993 entwickelte Aktivierungsarchitektur. Das Verhalten des Agenten wird in Form eines hierarchischen Verbindungsnetzes gespeichert, das Tyrrell als kostenlose Flusshierarchie bezeichnet. Kürzlich zum Beispiel von de Sevin & Thalmann (2005) oder Kadleček (2001) genutzt. Verhaltensbasierte AI war eine Reaktion auf die langsame Geschwindigkeit von Robotern mit symbolischen Handlungsauswahlverfahren. In dieser Form reagieren gesonderte Module auf unterschiedliche Impulse und stellen eigene Antworten her. In Originalform bestand die Subsumrationsarchitektur aus verschiedenen Ebenen, die die Inputs und Outputs der anderen überwachen und unterdrücken könnten. Kreativitäten sind virtuelle Haustiere aus einem Computerspiel, das von dreischichtigen Neuralnetz angetrieben wird, das anpassbar ist. Ihr Mechanismus ist reaktiv, da das Netz zu jedem Zeitpunkt die Aufgabe bestimmt, die vom Haustier durchzuführen ist. Das Netz wird im Papier von Grand et al.(1997) und in The Creatures Entwickler Resources gut beschrieben. Siehe auch die Kreativität. Dynamische Planungskonzepte Da rein verteilte Systeme schwer zu bauen sind, haben sich viele Forscher mit expliziten Plänen für die Festlegung der Prioritäten ihres Systems beschäftigt. Dynamische oder reaktive Planungsmethoden berechnen nur eine nächste Aktion in jedem unmittelbar auf der Grundlage des aktuellen Kontexts und der präskriptierten Pläne. Im Gegensatz zu klassischen Planungsmethoden leiden reaktive oder dynamische Ansätze nicht an einer kombinierten Explosion. Hingegen werden sie manchmal als zu starr angesehen, da die Pläne im Voraus als starke AI eingestuft werden. Gleichzeitig können natürliche Erkenntnisse in einigen Kontexten starr sein, auch wenn es sich um Flüssigkeit handelt und in der Lage ist, sich in anderen anzupassen. Beispiel dynamische Planungsmechanismen umfassen: Finite-state-Maschinen Diese sind reaktive Architekturen, die vor allem für Computerspielgeräte verwendet werden, insbesondere für First-Person-Boden, oder für virtuelle Filmakteure. In der Regel sind die staatlichen Maschinen hierarchisch. Konkrete Spielbeispiele: siehe Halo 2 Bots Papier von Damian Isla (2005) oder Thesis über Quake III Bots von Jan Paul van Wellenren (2001). Ein Filmbeispiel, siehe Softimage. Andere strukturierte Reaktivierungspläne werden eher wie herkömmliche Pläne aussehen, oft mit Möglichkeiten, hierarchische und sequentielle Struktur zu vertreten. Manche, wie PRS, unterstützen teilweise Pläne. Viele Agentenarchitekturen der Mitte der 90er Jahre umfassen solche Pläne als "Gelegene Schicht", die die Organisation für Niedrigverhaltensmodule vorsehen und von einem höheren Echtzeit-Plan geleitet werden. Trotz dieser angeblichen Interoperabilität mit automatischen Planern sind die meisten strukturierten reaktiven Pläne Handcoded (Bryson 2001, Ch. 3). Beispiele für strukturierte reaktive Pläne sind das RAP System von James Firby und die Teleo-reaktiven Pläne von Nils.. PRS, RAPs & TRP werden nicht mehr entwickelt oder unterstützt. Ein nach wie vor aktiver (Stand 2006) ist der Parallel-entwurzelte Nahost-Reaktionsauswahlsystem (oder POSH), das Teil des Behaviour Oriented Design von Joanna Bryson ist. Manchmal soll versucht werden, die wahrgenommene Unflexibilität der dynamischen Planung zu beheben, werden Hybridtechniken verwendet. In diesem Zusammenhang prüft ein herkömmlicher AI-Planungssystem für neue Pläne, wenn der Agenten Zeit hat, und aktualisiert die dynamische Planbibliothek, wenn er gute Lösungen findet. Wichtiger Aspekt eines solchen Systems ist, dass, wenn der Agenten eine Maßnahme auswählen muss, eine Lösung vorhanden ist, die sofort verwendet werden kann (siehe auch immer noch Algorithmen). Andere CogniTAO ist eine Entscheidungsmaschine, die sich auf BDI (Belief-desire-intention) stützt. Soar ist eine symbolische kognitive Architektur. Sie basiert auf den als Produktionen bekannten Bedingungen. Programmierer können das Soar-Entwicklungstoolkit verwenden, um sowohl reaktive als auch Planungsbedienstete als auch Kompromisse zwischen diesen beiden Extremen zu bauen. Excalibur war ein Forschungsprojekt unter Leitung von Alexander Nareyek, das für Computerspiele zuständige Planungsbeamte für Computerspiele bereitstellte. Die Architektur basiert auf struktureller Druckzufriedenheit, die eine fortschrittliche künstliche Intelligenztechnik ist. ACT-R ist ähnlich wie Soar. Es umfasst ein Bayesisches Lernsystem, das zur Priorisierung der Produktionen beiträgt. ABL/Hap Fuzzy Architekturen Der Fuzzy-Ansatz in der Aktionsauswahl stellt ein reibungsloses Verhalten her, als durch Architekturen, die die Bedingungen für die booleanischen Bedingungen (wie Soar oder POSH) nutzen können. Diese Architekturen sind meist reaktiv und symbolisiert. Theorien der Aktionsauswahl in der Natur Viele dynamische Modelle der künstlichen Aktionsauswahl wurden ursprünglich von der Forschung in der Ethologie inspiriert. Konrad Lorenz und Nikolaas Tinbergen boten insbesondere die Idee eines unzulänglichen Leasingmechanismus an, um instinktive Verhaltensmuster zu erklären. Lorenz, die von den Ideen von William McDougall beeinflusst wurde, entwickelte dies zu einem psychohydrauischen Modell der Motivation des Verhaltens. In der ethologie waren diese Ideen in den 1960er Jahren einflussreich, aber sie werden nun wegen ihrer Nutzung einer Energieflussmatrix als überholt angesehen; das Nervensystem und die Kontrolle des Verhaltens werden mittlerweile als Informationsübertragung und nicht als Energiefluss behandelt. Dynamische Pläne und Neuralnetze ähneln der Informationsübertragung, während die Verbreitung der Aktivierung der diffusen Kontrolle emotionaler / hormoneller Systeme ähnelt. Stan Franklin hat vorgeschlagen, dass die Aktionsauswahl die richtige Perspektive ist, um die Rolle und die Entwicklung des Geistes zu verstehen. Siehe seine Seite auf der Aktionsauswahl. Archivd 2006-10-09 auf dem Wegback-Maschine-Modell der Neuralaktionsauswahl Manche Forscher schaffen Modelle der Neuralaktionsauswahl. Siehe zum Beispiel: The Computational Neuroscience Lab (CU Boulder). Anpassung der Behaviour Research Group (Sheffield). Siehe auch die Beschreibung der Sprache Künstliche Intelligenz in Videospielen Roboter-Expertensystem Inference Motor Intelligenter OPS5 Produktionssystem Verstärkung des Lernsystems Rete-Algorithmus-Rete-Appens weiter Lesen Bratman, M: Intention, Pläne und praktische Gründe. Cambridge, Mass: Harvard University Press (1987)Brom, C, Lukavský, J, Šerý, O, Poch, T, Šafrata, P: Affordances and level-of-detail AI for virtuellen Menschen. In: Proceedings of Game Set and Match 2, Delft (2006)Bryson, J: Intelligence by Design: Grundsätze der modularen Funktion und der Koordinierung für ingenieurfähige Geräte. Doktor, Massachusetts Institute of Technology (2001)Champandard, A. J: AI Game Development: Synthetische Kreativitäten mit Lern- und Reaktivem Verhaltens. New Wheels, USA (2003)Grand, S. Cliff, D, Malhotra, A: Kreativität: Künstliches Leben autonome Software-Akteure für Heimunterhaltung. In: Johnson, W. L. (eds.): Leiter der ersten Internationalen Konferenz über autonome Agenten.ACM-Presse (1997) 22-29 Huber, M. JAM: A BDI-theoretic Mobile. In: Proceedings der Dritten Internationalen Konferenz über autonome Agenten (SAPs) (1999) 236-243 Isla, D: Handhabung der Komplexität in Halo 2.In: Gamastura online, 03/11 (2005) Archivd 2006-01-08 auf dem Wegback Werkzeugmaschinen, P: Systemarchitektur (ANA). In: SIGART Bulletin, 2 (4,) Seiten 115-120 (1991) Nareyek, A. Excalibur Project Reynolds, C. W. Flocks, Herden und Schulen: Ein Distributed Verhaltensmodell. Informatik: 21 (4) (SIGGRAPH '87 Conference Proceedings) (1987) 25-34.de Sevin, E. Thalmann, D.: Ein Motivationsmodell der Aktionsauswahl für virtuelle Menschen. Informatik International (CGI), HP Computer SocietyPress, New York (2005)Tyrrell, T: Computational Mechanisms for Action Selection. Ph.D. Zentrum für kognitive Wissenschaft, Universität Edinburgh (1993) van Welleren, J. M. P: The Quake III Arena Bot. Master thesis. Fakultät ITS, University of Technology Delft (2001)Wooldridge, M. Eine Einführung in Multiizer Systems. John Kuhn & Sons (2002) Externe Links The University of Memphis: Agents by Action Selection Archivd 2006-04-18 at the Wayback Maschinen Michael Wooldridge: Einführung in Agenten und ihre Aktionsauswahlmechanismen Cyril Brom: Drehen Sie sich auf einen Kurs zur Aktionsauswahl von künstlichem Soar-Projekt. University of Canada. Modellierung der natürlichen Aktionsauswahl, ein besonderes Thema, das von der Royal Society - Philosophische Transaktionen der Royal Society veröffentlicht wird