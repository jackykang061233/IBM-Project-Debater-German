Die Gaussian Adaption (GA,) auch als normale oder natürliche Adaption (NA) bezeichnet, ist ein evolutionärer Algorithmus, der zur Maximierung der Fertigungsausbeute durch statistische Abweichung von Bauteilwerten von Signalverarbeitungssystemen ausgelegt ist. Kurz gesagt, GA ist ein stochastisches adaptives Verfahren, bei dem eine Anzahl von Proben eines n-dimensionalen Vektors x[xT = (x1, x2, ..., xn]) aus einer multivariaten Gaussschen Verteilung entnommen werden, wobei N(m, M) mittlere m- und Moment-Matrix M aufweist.Die Proben werden auf Ausfall oder Pass getestet. Die auf die Passproben beschränkten ersten und zweiten Ordnungsmomente des Gaussian sind m* und M*.Das Ergebnis von x als Passprobe wird durch eine Funktion s(x,) 0 < s(x) <q ≤ 1 bestimmt, so dass s(x) die Wahrscheinlichkeit ist, dass x als Passprobe gewählt wird. Die durchschnittliche Wahrscheinlichkeit, Passproben zu finden (Ausbeute) ist P (m ) = δ s ( x ) N ( x - m ) d x {\displaystyle P(m)=\int s(x)N(x-m)\,dx} Dann gibt das Theorem von GA: Für jede s(x) und für jeden Wert von P < q gibt es immer eine Gaussian p. d. f.[ Wahrscheinlichkeitsdichtefunktion ], die für maximale Dispersion angepasst ist. Die notwendigen Bedingungen für ein lokales Optimum sind m = m* und M proportional zu M*. Das duale Problem wird auch gelöst: P wird unter Beibehaltung der Dispersionskonstante maximiert (Kjellström, 1991.) Nachweise des Theorems finden sich in den Beiträgen von Kjellström, 1970 und Kjellström & Taxén, 1981. Da die Dispersion als exponentielle Entropie/Disorder/Mittelwertinformation definiert ist, folgt sofort, dass das Theorem auch für diese Konzepte gilt. Insgesamt bedeutet dies, dass die Gaussian-Adaption eine gleichzeitige Maximierung von Ertrag und durchschnittlicher Information durchführen kann (ohne dass die Ausbeute oder die durchschnittliche Information als Kriteriumfunktionen definiert werden muss). Das Theorem ist gültig für alle Regionen der Akzeptanz und alle Gaussian Distributionen. Es kann durch zyklische Wiederholung von zufälliger Variation und Auswahl (wie die natürliche Evolution) verwendet werden. In jedem Zyklus werden eine ausreichend große Anzahl von Gaussian verteilten Punkten abgetastet und auf die Mitgliedschaft im Bereich der Akzeptanz getestet. Der Schwerpunkt des Gaussian, m, wird dann in den Schwerpunkt der zugelassenen (ausgewählten) Punkte m* bewegt. So konvergiert der Prozess zu einem Gleichgewichtszustand, der das Theorem erfüllt. Eine Lösung ist immer angenähert, da der Schwerpunkt immer für eine begrenzte Anzahl von Punkten bestimmt wird. Es wurde zum ersten Mal 1969 als reiner Optimierungsalgorithmus verwendet, der die Regionen der Akzeptanz kleiner und kleiner macht (in Analogie zur simulierten Glühung, Kirkpatrick 1983). Seit 1970 wird sie sowohl für die normale Optimierung als auch für die Ertragsmaximierung eingesetzt. Natürliche Evolution und Gaussische Anpassung Es wurde auch mit der natürlichen Entwicklung von Populationen von lebenden Organismen verglichen. In diesem Fall ist s(x) die Wahrscheinlichkeit, dass die Person mit einem Array x von Phenotypen überleben wird, indem sie der nächsten Generation Nachkommen gibt; eine Definition der individuellen Fitness von Hartl 1981. Die Rendite, P, wird durch die mittlere Fitness ersetzt, die als Mittel über die Menge der Individuen in einer großen Bevölkerung bestimmt wird. Phenotypen sind oft Gaussian verteilt in einer großen Bevölkerung und eine notwendige Bedingung für die natürliche Evolution in der Lage, das Theorem von Gaussian Anpassung, in Bezug auf alle Gaussian quantitative Charaktere zu erfüllen, ist, dass es den Schwerpunkt der Gravitation des Gaussian in den Schwerpunkt der ausgewählten Individuen drücken kann. Dies kann durch das Hardy-Weinberg-Gesetz geschehen. Dies ist möglich, weil das Theorem der Gaussian-Adaption für jede von der Struktur unabhängige Region der Akzeptabilität gilt (Kjellström, 1996). In diesem Fall können die Regeln der genetischen Variation wie Crossover, Inversion, Transposition etcetera als Zufallszahlengeneratoren für die Phenotypen angesehen werden. So kann in diesem Sinne die Gaussian-Adaption als genetischer Algorithmus betrachtet werden. Wie man einen Berg klettert Mittele Fitness kann berechnet werden, sofern die Verteilung der Parameter und die Struktur der Landschaft bekannt ist. Die reale Landschaft ist nicht bekannt, aber Abbildung unten zeigt ein fiktives Profil (blau) einer Landschaft entlang einer Linie (x) in einem Raum, der sich durch solche Parameter erstreckt. Die rote Kurve ist der Mittelwert aus der roten Glockenkurve am unteren Teil der Figur. Man erhält sie, indem man die Glockenkurve entlang der x-Achse gleiten lässt und das Mittel an jeder Stelle berechnet.Wie man sieht, werden kleine Gipfel und Gruben geglättet. Wenn also die Evolution bei A mit einer relativ kleinen Varianz (die rote Glockenkurve) gestartet wird, dann erfolgt das Klettern auf der roten Kurve. Der Prozess kann für Millionen von Jahren bei B oder C stecken, solange die Hohlräume rechts von diesen Punkten verbleiben und die Mutationsrate zu klein ist. Ist die Mutationsrate ausreichend hoch, kann die Störung oder Varianz zunehmen und die Parameter können wie die grüne Glockenkurve verteilt werden. Dann findet das Klettern auf der grünen Kurve statt, die noch geglättet wird. Da die Hohlräume rechts von B und C nun verschwunden sind, kann der Prozess bis zu den Gipfeln bei D.Aber natürlich legt die Landschaft eine Grenze auf die Störung oder Variabilität. Außerdem — abhängig von der Landschaft — kann der Prozess sehr ruckig werden, und wenn das Verhältnis zwischen der Zeit, die der Prozess an einem lokalen Gipfel und der Zeit des Übergangs zum nächsten Gipfel verbracht hat, sehr hoch ist, kann es auch wie ein punktiertes Gleichgewicht aussehen, wie es von Gould vorgeschlagen wird (siehe Ridley). Computersimulation der Gaussian Adaptation Bislang betrachtet die Theorie nur Mittelwerte von kontinuierlichen Verteilungen entsprechend einer unendlichen Anzahl von Individuen. In Wirklichkeit ist die Anzahl der Individuen jedoch immer begrenzt, was zu einer Unsicherheit bei der Schätzung von m und M (der Momentenmatrix des Gaussian) führt. Und dies kann auch die Effizienz des Prozesses beeinflussen. Davon ist leider zumindest theoretisch sehr wenig bekannt. Die Implementierung einer normalen Anpassung auf einem Computer ist eine ziemlich einfache Aufgabe. Die Anpassung von m kann durch eine Probe (individuell) zu einem Zeitpunkt erfolgen, z.B. m(i + 1) (=1 – a) m(i)+ axwhere x eine Passprobe ist, und a < 1 eine geeignete Konstante, so dass die Inverse von a die Zahl der Inversen in der Bevölkerung darstellt. M kann grundsätzlich nach jedem Schritt y aktualisiert werden, der zu einem möglichen Punkt x = m + y gemäß:M(i + 1) (=1 – 2b) M(i) + 2byyT führt, wobei yT die Transpose von y und b << 1 eine andere geeignete Konstante ist. Um eine geeignete Erhöhung der durchschnittlichen Informationen zu gewährleisten, sollte y normalerweise mit der Momentmatrix μ2M verteilt werden, wobei der Skalar μ > 1 zur Erhöhung der durchschnittlichen Information (Information Entropie, Störung, Diversität) mit einer geeigneten Rate verwendet wird. Aber M wird nie in den Berechnungen verwendet werden. Stattdessen verwenden wir die von WWT definierte Matrix W = M.Thus, wir haben y = Wg, wobei g normalerweise mit der Momentmatrix μU verteilt wird und U die Einheitsmatrix ist. W und WT können durch die Formeln W = (1 – b)W + bygT und WT = (1 – b)WT + bgyT aktualisiert werden, weil Multiplikation M = (1 – 2b)M + 2byyT gibt, wo Begriffe einschließlich b2 vernachlässigt wurden. So wird M indirekt mit guter Näherung angepasst. In der Praxis genügt es, W nur W(i + 1) = (1 – b)W(i +bygT) zu aktualisieren. Dies ist die Formel, die in einem einfachen 2-dimensionalen Modell eines Gehirns verwendet wird, das die hebische Regel des assoziativen Lernens erfüllt; siehe den nächsten Abschnitt (Kjellström, 1996 und 1999). Die Abbildung unten zeigt die Wirkung von erhöhten durchschnittlichen Informationen in einem Gaussian p.d.f. verwendet, um eine Berg Crest zu klettern (die beiden Linien stellen die Konturlinie dar). Sowohl der rote und grüne Cluster haben gleiche mittlere Fitness, etwa 65,%, aber der grüne Cluster hat eine viel höhere durchschnittliche Information, die den grünen Prozess viel effizienter macht. Die Wirkung dieser Anpassung ist in einem 2-dimensionalen Fall nicht sehr verfremdend, aber in einem hochdimensionalen Fall kann die Effizienz des Suchvorgangs um viele Größenordnungen erhöht werden. Die Entwicklung im Gehirn Im Gehirn soll die Evolution von DNA-Botschaften durch eine Evolution von Signalmustern ersetzt werden und die phenotypische Landschaft wird durch eine mentale Landschaft ersetzt, deren Komplexität kaum zweiter sein wird. Die Metapher mit der geistigen Landschaft basiert auf der Annahme, dass bestimmte Signalmuster zu einem besseren Wohlbefinden oder Leistung führen. Zum Beispiel führt die Steuerung einer Gruppe von Muskeln zu einer besseren Aussprache eines Wortes oder einer Leistung eines Stückes von Musik. Bei diesem einfachen Modell wird angenommen, dass das Gehirn aus miteinander verbundenen Komponenten besteht, die Signalwerte addieren, multiplizieren und verzögern können. Ein Nervenzellenkernel kann Signalwerte hinzufügen, eine Synapse kann mit einer Konstanten multiplizieren und An axon kann Werte verzögern. Dies ist eine Grundlage der Theorie von digitalen Filtern und neuronalen Netzwerken, bestehend aus Komponenten, die hinzufügen, multiplizieren und Verzögerung Signalwerte sowie von vielen Gehirnmodellen, Levine 1991. In der Figur unterhalb des Gehirnstamms soll Gaussian verteilte Signalmuster liefern.Dies kann möglich sein, da bestimmte Neuronen zufällig feuern (Kandel et al.). Der Stamm stellt auch eine gestörte Struktur dar, die von mehr bestellten Schalen umgeben ist (Bergström, 1969), und nach der zentralen Grenze Theorem kann die Summe der Signale von vielen Neuronen Gausssian verteilt sein. Die dreieckigen Boxen stellen Synapsen dar und die Boxen mit dem + Zeichen sind Zellkerne. In den Cortex-Signalen sollen auf Machbarkeit getestet werden. Wenn ein Signal angenommen wird, werden die Kontaktbereiche in den Synapsen gemäß den nachstehenden Formeln im Einvernehmen mit der hebbianischen Theorie aktualisiert. Die Figur zeigt eine 2-dimensionale Computersimulation der Gaussschen Anpassung gemäß der letzten Formel im vorhergehenden Abschnitt. m und W werden gemäß: m1 = 0.9 m1 + 0.1 x1; m2 = 0.9 m2 + 0.1 x2;w11 = 0.9 w11 + 0.1 y1g1; w12 = 0.9 w12 + 0.1 y1g2;w21 = 0.9 w21 + 0.1 y2g1; w22 = 0.9w22 + 0.1 y2g2; Wie man sieht, ist dies wie ein kleines Gehirn, das von der Theorie beherrscht wird. Gausssche Anpassung und freier Wille Gaussische Anpassung als evolutionäres Modell des Gehirns, das der hebbbianischen Theorie des assoziativen Lernens gehorcht, bietet eine alternative Sicht des freien Willens aufgrund der Fähigkeit des Prozesses, die mittlere Fitness von Signalmustern im Gehirn zu maximieren, indem eine geistige Landschaft in Analogie mit phenotypischer Evolution klettert. Ein solcher zufälliger Prozess gibt uns viel Wahlfreiheit, aber kaum Wille. Eine Illusion des Willens kann jedoch von der Fähigkeit des Prozesses ausgehen, die mittlere Fitness zu maximieren und das Prozessziel zu suchen. I e., es bevorzugt höhere Gipfel in der Landschaft, bevor niedriger, oder bessere Alternativen vor schlechter. Auf diese Weise kann eine illusive Erscheinung auftreten. Eine ähnliche Ansicht hat Zohar 1990. Siehe auch Kjellström 1999. Ein Theorem der Effizienz für die zufällige Suche Die Effizienz der Gaussian-Adaption beruht auf der Theorie der Information durch Claude E. Shannon (siehe Informationsinhalt). Wenn ein Ereignis mit der Wahrscheinlichkeit P auftritt, kann die Information -log(P) erreicht werden. Wenn beispielsweise die mittlere Fitness P ist, werden die gewonnenen Informationen für jedes für das Überleben ausgewählte Individuum -log(P) - im Durchschnitt - und die zur Gewinnung der Informationen benötigte Arbeit/Zeit ist proportional zu 1/P. Wenn also Effizienz, E, als Information definiert ist, die durch die Arbeit/Zeit, die benötigt wird, um es zu erhalten, wir haben: E =-Plog(P). Diese Funktion erreicht ihr Maximum, wenn P = 1/e = 0,37. Das gleiche Ergebnis wurde von Gaines mit einer anderen Methode erhalten. E = 0if P = 0, für ein Verfahren mit unendlicher Mutationsrate, und wenn P = 1, für ein Verfahren mit Mutationsrate = 0 (vorgesehen, dass der Prozess lebendig ist). Diese Maßnahme der Effizienz gilt für eine große Klasse von zufälligen Suchvorgängen, sofern bestimmte Bedingungen vorliegen.1 Die Suche sollte in unterschiedlichen Parameterrichtungen statistisch unabhängig und gleich effizient sein. Diese Bedingung kann in etwa erfüllt werden, wenn die Momentmatrix des Gaussian für maximale durchschnittliche Informationen an einen bestimmten Bereich der Annehmbarkeit angepasst wurde, da lineare Transformationen des gesamten Prozesses die Effizienz nicht beeinflussen. 2 Alle Individuen haben gleiche Kosten und das Derivat bei P = 1 ist < 0.Dann kann folgendes Theorem nachgewiesen werden: Alle Maßnahmen der Effizienz, die die oben genannten Bedingungen erfüllen, sind asymmetrisch proportional zu –P log(P/q), wenn die Anzahl der Abmessungen steigt, und werden durch P = q exp(-1)(Kjellström, 1996 und 1999) maximiert. Die obige Figur zeigt eine mögliche Effizienzfunktion für einen zufälligen Suchvorgang wie Gaussian Adaption. Links ist der Prozess am meisten chaotisch, wenn P = 0, während es eine perfekte Ordnung nach rechts gibt, wo P = ANHANG In einem Beispiel von Rechenberg, 1971, 1973, wird ein zufälliger Spaziergang durch einen Korridor verschoben, der den Parameter x1 maximiert. In diesem Fall wird der Bereich der Akzeptanz als (n - 1)-dimensionales Intervall in den Parametern x2, x3,..., xn definiert, jedoch wird niemals ein x1-Wert unterhalb des zuletzt angenommenen angenommen. Seit P kann in diesem Fall die maximale Geschwindigkeit zu höheren x1-Werten für P = 0,5/e = 0,18 in Übereinstimmung mit den Ergebnissen von Rechenberg nicht überschreiten. Ein Aspekt, der auch in diesem Zusammenhang von Interesse sein kann, ist, dass für den Nachweis des Theorems keine Definition von Informationen erforderlich ist (andere als jene abgetasteten Punkte innerhalb eines Bereichs der Annehmbarkeit gibt Auskunft über die Ausdehnung der Region). Da dann die Formel als durch die für die Informationsaufnahme erforderliche Arbeit geteilte Information interpretiert werden kann, ist dies auch ein Hinweis, dass -log(P) ein guter Kandidat für ein Maß an Information ist.Der Stauffer- und Grimson-Algorithmus Gaussian-Adaption wurde auch für andere Zwecke verwendet, wie zum Beispiel Schattenentfernung durch "The Stauffer-Grimson-Algorithmus", der der Gausssian-Adaption entspricht, wie sie oben im Abschnitt "Computersimulation der Gaussian-Adaption" verwendet wird. In beiden Fällen wird die maximale Wahrscheinlichkeitsmethode zur Schätzung von Mittelwerten durch Anpassung an einer Probe zu einem Zeitpunkt verwendet. Aber es gibt Unterschiede. Im Stauffer-Grimson-Fall wird die Information nicht zur Steuerung eines Zufallszahlengenerators zur Zentrierung, Maximierung von mittlerer Fitness, mittlerer Information oder Fertigungsausbeute verwendet. Die Anpassung der Momentenmatrix unterscheidet sich auch sehr viel im Vergleich zu "die Evolution im Gehirn" oben. Siehe auch Entropie in der Thermodynamik und Informationstheorie Fishers grundlegendes Theorem der natürlichen Selektion Free will Genetic algorithm Hebbian learning Information content Simulated annealing Stochastic Optimierung Covariance Matrix Adaption Evolution Strategie (CMA-ES) Auswahleinheit Referenzen Bergström, R. M. Ein Entropiemodell des Entwickelnden Gehirns. Entwicklungspsychologie, 2(3:) 139–152, 1969.Brooks, D. R. & Wiley, E. O. Evolution als Entropie, Gegen eine einheitliche Theorie der Biologie. Die University of Chicago Press, 1986. Brooks, D. R. Evolution im Informationszeitalter: Wiederentdeckung der Natur des Organismus.Semiosis, Evolution, Energie, Entwicklung, Band 1, Nummer 1, März 2001 Gaines, Brian R. Knowledge Management in Societies of Intelligent Adaptive Agents. Zeitschrift für intelligente Informationssysteme 9, 277–298 (1997). Hartl, D. L. A Primer of Population Genetics. Sinauer, Sunderland, Massachusetts, 1981.Hamilton, WD 1963.Die Evolution des altruistischen Verhaltens. American Naturalist 97:354–356 Kandel, E. R., Schwartz, J. H., Jessel, T. M. Essentials of Neural Science and Behavior. Prentice Hall International, London, 1995.S Kirkpatrick und C. D. Gelatt und M. P. Vecchi, Optimierung durch Simulated Annealing, Science, Vol 220, Number 4598, S. 671–680, 1983. Kjellström, G. Network Optimization by Random Variation der Komponentenwerte. Ericsson Technics, vol. 25, no. 3, pp.133–151, 1969.Kjellström, G. Optimierung von elektrischen Netzwerken in Bezug auf Toleranzkosten. Ericsson Technics, Nr. 3, pp.157–175, 1970.Kjellström, G. & Taxén, L. Stochastic Optimization in System Design. IEEE Trans.on Circ.and Syst., vol.CAS-28, Nr. 7, Juli 1981.Kjellström, G., Taxén, L. und Lindberg, P. O. Diskrete Optimierung von digitalen Filtern mit Gaussian Adaptation und Quadratic Function Minimization. IEEE Trans.on Circ.and Syst., vol. CAS-34, no 10, Oktober 1987. Kjellström, G.On the Efficiency of Gaussian Adaptation. Journal of Optimization Theory and Applications, Vol. 71, No. 3, Dezember 1991. Kjellström, G. & Taxén, L. Gaussian Adaptation, ein evolutionsbasierter effizienter globaler Optimierer; Computational and Applied Mathematics,In C. Brezinski & U. Kulish (Editors,) Elsevier Science Publishers B. V., pp 267-276, 1992. Kjellström, G. Evolution als statistischer Optimierungsalgorithmus. Evolutionstheorie 11:105–117 (Januar 1996). Kjellström, G. Die Evolution im Gehirn. Angewandte Mathematik und Computation, 98(2–3):293–300, Februar 1999.Kjellström, G. Evolution in einer Muschel und einige Folgen für Bewertungen. EVOLVE, ISBN 91-972936-1-X, Stockholm, 2002.Levine, D. S. Einführung in Neural & Cognitive Modeling. Laurence Erlbaum Associates, Inc., Publishers, 1991. MacLean, P. D.A Triune Konzept des Gehirns und Verhaltens. Toronto, Univ.Toronto Presse, 1973.Maynard Smith, J. 1964.Gruppenauswahl und Kin Selection, Nature 201:1145–1147. Maynard Smith, J. Evolutionary Genetics. Oxford University Press, 1998.Mayr, E. What Evolution is. Basic Books, New York, 2001.Müller, Christian L. und Sbalzarini Ivo F. Gaussian Adaptation revisited - ein entroper Blick auf Covariance Matrix Adaptation. Institut für Theoretische Informatik und Schweizer Institut für Bioinformatik, ETH Zürich, CH-8092 Zürich, Schweiz. Pinel, J. F. und Singhal, K. Statistisches Design Centering and Tolerancing using Parametric Sampling.IEEE Transaktionen auf Schaltungen und Systemen, Vol.Das-28, Nr. 7, Juli 1981. Rechenberg, I. (1971:) Evolutionsstrategie — Optimierung technischer Systeme nach Prinzipien der biologischen Evolution (PhD-Thesis). Aufgedruckt von Fromman-Holzboog (1973). Ridley, M. Evolution. Blackwell Science, 1996.Stauffer, C. & Grimson, W.E.L Learning Patterns of Activity using Real-Time Tracking, IEEE Trans.on PAMI, 22(8,) 2000. Stehr, G.On the Performance Space Exploration von analog integrierten Schaltungen.Technische Universität München, Dissertation 2005. Taxén, L. A Framework for the Coordination of Complex Systems’ Development. Institut für Technologie, Linköping Universität, Dissertation, 2003.Zohar,D. Das Quantenselbst: eine revolutionäre Sicht der menschlichen Natur und des Bewusstseins, das in der neuen Physik verwurzelt ist. London, Bloomsbury, 1990.