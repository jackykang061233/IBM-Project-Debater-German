Moore's Gesetz ist die Beobachtung, dass die Anzahl der Transistoren in einer dichten integrierten Schaltung (IC) etwa alle zwei Jahre verdoppelt. Moore's Gesetz ist eine Beobachtung und Projektion eines historischen Trends. Anstatt ein Gesetz der Physik ist es eine empirische Beziehung, die mit Gewinnen aus Erfahrung in der Produktion verbunden ist. Die Beobachtung wird nach Gordon Moore, dem Mitbegründer von Fairchild Semiconductor und Intel (und dem ehemaligen CEO von letzterem), benannt, der 1965 jedes Jahr eine Verdoppelung in der Anzahl der Komponenten pro integriertem Schaltkreis aufwies und projizierte, dass diese Wachstumsrate mindestens ein weiteres Jahrzehnt dauern würde. 1975 hat er sich auf das nächste Jahrzehnt gefreut, die Prognose, alle zwei Jahre zu verdoppeln, eine jährliche Wachstumsrate (CAGR) von 41 % überarbeitet. Während Moore nicht empirische Beweise in der Vorausschätzung, dass der historische Trend würde fortgesetzt, seine Vorhersage seit 1975 und seitdem bekannt als Gesetz". Moore's Vorhersage wurde in der Halbleiterindustrie verwendet, um langfristige Planungen zu führen und Ziele für Forschung und Entwicklung festzulegen, so dass einiges als selbstvollende Prophezeiung funktioniert. Fortschritte in der digitalen Elektronik, wie die Verringerung der qualitätsbereinigten Mikroprozessorpreise, die Erhöhung der Speicherkapazität (RAM und Flash), die Verbesserung der Sensoren und sogar die Anzahl und Größe von Pixeln in digitalen Kameras, sind stark mit Moore's Gesetz verknüpft. Diese Schrittänderungen in der digitalen Elektronik waren eine treibende Kraft des technologischen und sozialen Wandels, der Produktivität und des Wirtschaftswachstums. Branchenexperten haben sich nicht genau darüber einig, wann Moores Gesetz nicht mehr anzuwenden ist. Mikroprozessorarchitekten berichten, dass der Halbleiterfortschritt seit etwa 2010 industrieweit gebremst ist, unter dem von Moore's Gesetz vorhergesagten Tempo. Seit 2018 haben führende Halbleiterhersteller jedoch IC-Fertigungsprozesse in der Massenproduktion entwickelt, die behauptet werden, mit Moore's Gesetz Schritt zu halten. Geschichte Im Jahr 1959 diskutierte Douglas Engelbart die projizierte Downscaling der integrierten Schaltung (IC) Größe im Artikel "Microelectronics, and the Art of Similitude". Engelbart präsentierte seine Ideen auf der Internationalen Solid-State Circuits Konferenz von 1960, wo Moore im Publikum anwesend war. Im selben Jahr erfand Mohamed Atalla und Dawon Kahng den MOSFET (Metall-Oxid-Halbleiter-Feldeffekttransistor), auch als MOS-Transistor bekannt, bei Bell Labs. Der MOSFET war der erste wirklich kompakte Transistor, der für ein breites Anwendungsspektrum miniaturisiert und massenproduziert werden konnte, mit seiner hohen Skalierbarkeit und geringen Leistungsaufnahme, die zu einer höheren Transistordichte führt und den Aufbau von hochdichten IC-Chips ermöglicht. In den frühen 1960er Jahren erkannte Gordon E. Moore, dass die idealen elektrischen und skalierenden Eigenschaften von MOSFET-Geräten zu einem rasch steigenden Integrationsgrad und einem unvergleichlichen Wachstum in elektronischen Anwendungen führen würden. Im Jahr 1965 wurde Gordon Moore, der damals als Leiter der Forschung und Entwicklung bei Fairchild Semiconductor tätig war, aufgefordert, in den nächsten zehn Jahren zur fünfunddreißigjährigen Jubiläumsausgabe des Magazins Electronics beizutragen. Seine Antwort war ein kurzer Artikel mit dem Titel "Cramming mehr Komponenten auf integrierte Schaltungen". In seinem Editorial spekulierte er, dass bis 1975 auf einem ein Viertelquare-inch-Halbleiter bis zu 65.000 Komponenten enthalten sein könnten. Die Komplexität der Mindestkomponentenkosten hat sich mit einer Rate von etwa einem Faktor von zwei pro Jahr erhöht. Natürlich kann kurzfristig erwartet werden, dass diese Rate weitergeht, wenn nicht zu erhöhen. Langfristig ist die Steigerungsrate etwas unsicherer, obwohl es keinen Grund gibt zu glauben, dass sie für mindestens 10 Jahre nicht annähernd konstant bleibt. Moore gab einen log-linearen Zusammenhang zwischen Gerätekomplexität (höhere Schaltungsdichte zu reduzierten Kosten) und Zeit. In einem 2015 Interview, Moore bemerkte den Artikel von 1965: "Ich habe nur eine wilde Extrapolation sagte, es wird jedes Jahr für die nächsten 10 Jahre zu verdoppeln. " 1974 erkannte Robert H. Dennard bei IBM die schnelle MOSFET-Skaliertechnologie und formulierte, was als Dennard-Skalierung bekannt wurde, was beschreibt, dass als MOS-Transistoren kleiner werden, ihre Leistungsdichte konstant bleibt, so dass der Stromverbrauch im Verhältnis zur Fläche bleibt. MOSFET-Skalierung und Miniaturisierung waren die wichtigsten Antriebskräfte hinter Moore's Gesetz. Der Nachweis der Halbleiterindustrie zeigt, dass diese inverse Beziehung zwischen Leistungsdichte und Flächendichte Mitte der 2000er Jahre abgebaut wurde.Auf der IEEE International Electron Devices Meeting von 1975 hat Moore seine Prognoserate überarbeitet und die Halbleiterkomplexität prognostiziert, bis etwa 1980 jährlich verdoppelt, woraufhin sie etwa alle zwei Jahre auf eine Verdoppelung zurückgehen würde. Er skizzierte mehrere Faktoren für dieses exponentielle Verhalten: Das Aufkommen der Metall-Oxid-Halbleiter-Technologie (MOS) Die exponentielle Steigerungsrate der Düsengrößen, verbunden mit einer Abnahme der fehlerhaften Dichten, mit der Folge, dass Halbleiterhersteller mit größeren Flächen arbeiten können, ohne Reduktionsausbeuten zu verlieren Finer minimale Abmessungen Was Moore als "Kreislauf und Geräte-Schlauheit"Kurz nach 1975, Caltech Professor Carver Mead populärte den Begriff "Moore's law". Moore's Gesetz schließlich kam weithin als Ziel für die Halbleiterindustrie anerkannt, und es wurde von wettbewerbsfähigen Halbleiterherstellern zitiert, wie sie die Verarbeitungsleistung erhöhen. Moore betrachtete sein gleichnamiges Gesetz als überraschend und optimistisch: "Moore's Gesetz ist eine Verletzung von Murphys Gesetz. Alles wird besser und besser. " Die Beobachtung wurde sogar als selbstfüllende Prophezeiung angesehen. Die Verdoppelungsperiode wird oft als 18 Monate wegen einer Vorhersage von Moores Kollegen, Intel Executive David House, falsch zitiert. Im Jahr 1975 stellte House fest, dass Moores überarbeitetes Gesetz über die Verdoppelung des Transistors alle zwei Jahre implizierte, dass die Computerchip-Performance alle 18 Monate etwa verdoppeln würde (ohne Erhöhung des Stromverbrauchs). Moore's Gesetz ist eng mit MOSFET Skalierung verbunden, da die schnelle Skalierung und Miniaturisierung von MOSFETs die zentrale Antriebskraft hinter Moore's Gesetz ist. Mathematisch prognostizierte Moore's Law, dass die Transistorzahl alle 2 Jahre wegen der Schrumpfung der Transistordimensionen und anderer Verbesserungen verdoppelt würde. Als Folge der Schrumpfdimensionen prognostizierte Dennard Skalierung, dass der Stromverbrauch pro Flächeneinheit konstant bleibt. Die Kombination dieser Effekte, David House entführte, dass Computer-Chip-Leistung würde etwa alle 18 Monate verdoppeln. Auch durch Dennard-Skalierung würde diese gesteigerte Leistung nicht mit einer erhöhten Leistung einhergehen, d.h. die Energieeffizienz von auf Silizium basierenden Computerchips verdoppelt sich alle 18 Monate. Dennard Skalierung endete in den 2000er Jahren. Koomey zeigte später, dass eine ähnliche Rate der Effizienzverbesserung predierte Siliziumchips und Moore's Law, für Technologien wie Vakuumröhren. Mikroprozessorarchitekten berichten, dass der Halbleiterfortschritt seit rund 2010 branchenweit unter dem von Moore's Gesetz vorhergesagten Tempo gebremst hat. Brian Krzanich, der ehemalige CEO von Intel, zitierte Moore's 1975 Revision als Präzedenzfall für die aktuelle Verzögerung, die aus technischen Herausforderungen resultiert und ist "ein natürlicher Teil der Geschichte des Moore'schen Gesetzes". Die Verbesserung der physikalischen Dimensionen, die als Dennard-Skalierung bekannt sind, endete auch Mitte der 2000er Jahre. Dadurch hat ein Großteil der Halbleiterindustrie seinen Fokus auf die Bedürfnisse von Großrechneranwendungen und nicht auf die Halbleiterskalierung verschoben. Dennoch haben führende Halbleiterhersteller TSMC und Samsung Electronics behauptet, mit Moore's Gesetz mit 10 nm und 7 nm Knoten in der Massenproduktion und 5 nm Knoten in der Risikoproduktion Schritt zu halten. Moores zweites Gesetz Da die Kosten für die Computerleistung für den Verbraucher sinken, folgen die Kosten für die Hersteller, Moore's Gesetz zu erfüllen, einem entgegengesetzten Trend: FuE, Herstellung und Testkosten haben mit jeder neuen Generation von Chips stetig zugenommen. Die steigenden Herstellungskosten sind eine wichtige Berücksichtigung für die Aufrechterhaltung des Moore-Gesetzes. Dies hatte zur Formulierung von Moores zweitem Gesetz geführt, auch Rock's Gesetz genannt, das heißt, dass die Kapitalkosten einer Halbleiterfab auch im Laufe der Zeit exponentiell zunimmt. Zahlreiche Innovationen von Wissenschaftlern und Ingenieuren haben Moores Gesetz seit Beginn der IC-Ära beibehalten. Einige der wichtigsten Neuerungen sind unten aufgeführt, als Beispiele für Durchbrüche, die fortschrittliche integrierte Schaltung und Halbleiter-Geräte-Produktionstechnologie haben, so dass Transistor zählt in weniger als fünf Jahrzehnten um mehr als sieben Größenordnungen wachsen. Integrierte Schaltung (IC) – Die Raison d'être für Moore's Gesetz. Der Germanium-Hybrid-IC wurde 1958 von Jack Kilby bei Texas Instruments erfunden, gefolgt von der Erfindung des Silizium-monolithischen IC-Chips von Robert Noyce auf Fairchild Semiconductor 1959. Metall-Oxid-Halbleiter-Feldeffekttransistor (MOSFET) – Erfindet von Mohamed M. Atalla und Dawon Kahng bei Bell Labs 1959, war es der erste Transistor, der aufgrund seiner hohen Skalierbarkeit miniaturisiert und massiert werden konnte.Komplementärer Metall-Oxid-Halbleiter (CMOS) – Das CMOS-Verfahren wurde 1963 von Chih-Tang Sah und Frank Wanlass auf Fairchild Semiconductor erfunden. Dynamic random-access Memory (DRAM) – Bipolar DRAM wurde 1965 von Toshiba entwickelt und danach wurde MOS DRAM 1967 von Robert H. Dennard bei IBM entwickelt. MOS DRAM ermöglichte es, einzelne Transistor-Speicherzellen auf IC-Chips herzustellen. Chemisch-verstärkter Photolack – Erfindet von Hiroshi Ito, C. Grant Willson und J. M. J. Fréchet bei IBM um 1980, was 5-10 mal empfindlicher für ultraviolettes Licht war. IBM führte Mitte der 1980er Jahre einen chemisch verstärkten Photoresist für die DRAM-Produktion ein. Deep UV Excimer Laser Photolithographie – Erfunden von Kanti Jain bei IBM um 1980. Vor diesem Hintergrund wurden Excimer-Laser seit ihrer Entwicklung in den 1970er Jahren hauptsächlich als Forschungseinrichtungen eingesetzt. Aus einer breiteren wissenschaftlichen Perspektive wurde die Erfindung der Excimer-Laserlithographie als einer der wichtigsten Meilensteine der 50-jährigen Geschichte des Lasers hervorgehoben. Interconnect-Innovationen – Interconnect-Innovationen der späten 1990er Jahre, einschließlich chemisch-mechanischer Polierung oder chemisch-mechanischer Planarisierung (CMP,) Grabenisolation und Kupfer-Verbindungen – obwohl nicht direkt ein Faktor bei der Schaffung kleinerer Transistoren – ermöglichten verbesserte Wafer-Ausbeute, zusätzliche Schichten von Metalldrähten, engere Abstand von Geräten und niedrigerer elektrischer Widerstand. Computer-Industrie-Technologie Straßenkarten vorhergesagt im Jahr 2001, dass Moore's Gesetz für mehrere Generationen von Halbleiterchips fortsetzen würde. Aktuelle Trends Eine der wichtigsten Herausforderungen des Engineering zukünftige Nanoscale-Transistoren ist die Konstruktion von Gates. Da die Gerätedimension schrumpft, wird die Steuerung des Stromflusses im dünnen Kanal erschwert. Moderne Nano-Skala-Transistoren bilden typischerweise die Form von Multi-Gate-MOSFETs, wobei der FinFET der häufigste Nano-Skala-Transistor ist. Der FinFET hat Gatedielektrikum auf drei Seiten des Kanals. Im Vergleich dazu weist die Gate-All-Around-MOSFET-Struktur noch eine bessere Gate-Steuerung auf. Ein Gate-All-around-MOSFET (GAAFET) wurde 1988 erstmals von einem Toshiba-Forschungsteam unter der Leitung von Fujio Masuoka demonstriert, das einen vertikalen Nanowire-GAAFET, den er als "Umrundungs-Gate-Transistor" (SGT) bezeichnete, demonstrierte. Masuoka, am besten bekannt als Erfinder des Flash-Speichers, später links Toshiba und gründete Unisantis Electronics im Jahr 2004, um die Umgebungs-Gate-Technologie zusammen mit Tohoku Universität zu erforschen. 2006 entwickelte ein Team von koreanischen Forschern des Korea Advanced Institute of Science and Technology (KAIST) und des National Nano Fab Centers einen 3 nm-Transistor, das weltweit kleinste nanoelektronische Gerät auf Basis der FinFET-Technologie. Im Jahr 2010 kündigten Forscher am Tyndall National Institute in Cork, Irland einen knotenfreien Transistor an. Ein um einen Silizium-Nanowire gewickeltes Steuergate kann den Durchgang von Elektronen ohne Verwendung von Kreuzungen oder Dotierungen steuern. Sie behaupten, diese können im 10-Nanometer-Skala mit bestehenden Herstellungsverfahren hergestellt werden. 2011 haben Forscher der Universität Pittsburgh die Entwicklung eines Ein-Elektronen-Transistors mit 1,5 Nanometer Durchmesser aus oxidbasierten Materialien bekannt gegeben. Drei Drähte konvergieren auf einer zentralen Insel, die ein oder zwei Elektronen beherbergt. Elektronen Tunnel von einem Draht zum anderen durch die Insel. Bedingungen auf dem dritten Draht führen zu deutlichen leitenden Eigenschaften, einschließlich der Fähigkeit des Transistors als Festzustandsspeicher zu wirken. Nanowire-Transistoren könnten die Erstellung von mikroskopischen Computern anspornen. 2012 kündigte ein Forscherteam der University of New South Wales die Entwicklung des ersten Arbeitstransistors an, der aus einem einzigen Atom besteht, das genau in einem Siliziumkristall platziert ist (nicht nur aus einer großen Probe von Zufallstransistoren ausgewählt). Moore's Gesetz prognostizierte diesen Meilenstein für die ICs im Labor bis 2020. Im Jahr 2015 zeigte IBM 7 nm Knotenchips mit Silizium-Germanium-Transistoren, die mit EUVL hergestellt wurden. Das Unternehmen glaubt, dass diese Transistordichte viermal so groß wäre wie die der Strom 14 nm Chips. Samsung und TSMC planen, 3 nm GAAFET-Knoten von 2021–2022 herzustellen. Beachten Sie, dass Knotennamen wie 3 nm keinen Bezug zur physikalischen Größe von Geräteelementen (Transistoren) haben. Ein Toshiba-Forschungsteam mit T. Imoto, M. Matsui und C. Takubo entwickelte 2001 ein "System Block Module"-Waferbonding-Verfahren zur Herstellung von dreidimensionalen integrierten Schaltungen (3D IC)-Paketen. Im April 2007 führte Toshiba einen achtschichtigen 3D IC ein, den 16 GB THGAM eingebetteten NAND Flash-Speicherchip, der mit acht gestapelten 2 GB NAND-Flash-Chips hergestellt wurde.Im September 2007 führte Hynix 24-Schicht 3D IC ein, einen 16 GB Flash-Speicherchip, der mit 24 gestapelten NAND-Flash-Chips unter Verwendung eines Waferbonding-Prozesses hergestellt wurde. V-NAND, auch als 3D NAND bekannt, ermöglicht die vertikale Stapelung von Flash-Speicherzellen unter Verwendung von Ladungsfallen-Flash-Technologie, die ursprünglich 1967 von John Szedon vorgestellt wurde, wodurch die Anzahl der Transistoren auf einem Flash-Speicherchip deutlich erhöht wird. 3D NAND wurde 2007 von Toshiba erstmals bekannt gegeben. V-NAND wurde 2013 erstmals im Handel von Samsung Electronics hergestellt. Im Jahr 2008 kündigten Forscher von HP Labs einen arbeitenden Memristor an, ein viertes grundlegendes passives Schaltungselement, dessen Existenz erst zuvor theorisiert worden war. Die einzigartigen Eigenschaften des Memristors ermöglichen die Schaffung kleinerer und besser funktionierender elektronischer Geräte. Im Jahr 2014 entwickelten Bioingenieure der Stanford University einen Kreislauf, der auf dem menschlichen Gehirn modelliert wurde. Sechzehn Neurocore-Chips simulieren eine Million Neuronen und Milliarden synaptischer Verbindungen, behauptet, 9.000 Mal schneller und energieeffizienter als ein typischer PC zu sein. Im Jahr 2015, Intel und Micron kündigte 3D XPoint, ein nicht-flüchtiger Speicher behauptet deutlich schneller mit ähnlicher Dichte im Vergleich zu NAND. Die 2016 geplante Produktion wurde bis zum zweiten Halbjahr 2017 verzögert. Im Jahr 2017 kombinierte Samsung seine V-NAND-Technologie mit eUFS 3D IC Stacking, um einen 512 GB Flash-Speicherchip zu produzieren, mit acht gestapelten 64-Schicht V-NAND-Diäten. Im Jahr 2019 produzierte Samsung einen 1 TB Flash-Chip mit acht gestapelten 96-Schicht V-NAND-Dioden, zusammen mit Quad-Level-Zell (QLC)-Technologie (4-Bit pro Transistor,) äquivalent 2 Trillion-Transistoren, die höchste Transistorzahl jedes IC-Chips. Im Jahr 2020 plant Samsung Electronics, den 5 nm-Knoten mit FinFET und EUV-Technologie herzustellen. Im Mai 2021 kündigt IBM die Erstellung des ersten 2 nm Computerchips an, wobei angeblich Teile kleiner sind als menschliche DNA. Mikroprozessorarchitekten berichten, dass der Halbleiterfortschritt seit etwa 2010 industrieweit gebremst ist, unter dem von Moore's Gesetz vorhergesagten Tempo. Brian Krzanich, der ehemalige CEO von Intel, sagte: "Unsere Kadenz ist heute zweieinhalb Jahre näher als zwei. " Intel erklärte im Jahr 2015, dass Verbesserungen in MOSFET-Geräten gebremst haben, beginnend bei der 22 nm-Funktionsbreite um 2012, und weiter bei 14 nm. Die physikalischen Grenzen der Transistorskalierung sind durch Source-to-Drain-Leckage, begrenzte Gate-Metalle und begrenzte Optionen für Kanalmaterial erreicht worden. Andere Ansätze werden untersucht, die sich nicht auf die physikalische Skalierung verlassen. Dazu gehören der Spin-Zustand von Elektronen-Spintronics, Tunnel-Übergänge und die erweiterte Eingrenzung von Kanalmaterialien über Nano-Draht-Geometrie. Spinbasierte Logik- und Speicheroptionen werden aktiv in Laboren entwickelt. Alternative Materialforschung Die überwiegende Mehrheit der Stromtransistoren auf ICs besteht hauptsächlich aus dotiertem Silizium und seinen Legierungen. Da Silizium in Einzel-Nanometer-Transistoren hergestellt wird, verändern Kurzkanaleffekte die gewünschten Materialeigenschaften von Silizium als Funktionstransistor. Im Folgenden sind mehrere Nicht-Silizium-Substitute bei der Herstellung von kleinen Nanometer-Transistoren. Ein vorgeschlagenes Material ist Indium Galliumarsenid oder InGaAs. Im Vergleich zu ihren Silizium- und Germanium-Gegenständen sind InGaAs-Transistoren für zukünftige High-Speed-, Low-Power-Logik-Anwendungen vielversprechender. Aufgrund der Eigeneigenschaften von III-V-Verbindungshalbleitern wurden als Alternativen zu herkömmlichen MOSFET-Designs Quanten- und Tunneleffekttransistoren auf Basis von InGaAs vorgeschlagen. In den frühen 2000er Jahren wurden die atomaren Schichtabscheidungs-Hochschicht- und Pitch-Doppel-Paterning-Prozesse von Gurtej Singh Sandhu bei Micron Technology erfunden und Moore's Gesetz für planare CMOS-Technologie auf 30 nm Klasse und kleiner erweitert. Im Jahr 2009 kündigte Intel die Entwicklung von 80-Nanometer InGaAs-Quanten-Well-Transistoren an. Quantum Well-Geräte enthalten ein Material zwischen zwei Schichten von Material mit einem breiteren Bandspalt. Trotz der doppelten Größe der führenden reinen Silizium-Transistoren zu der Zeit, berichtete das Unternehmen, dass sie genauso gut durchgeführt und weniger Strom verbraucht. Im Jahr 2011 demonstrierten Forscher von Intel 3-D-Tri-Gate InGaAs-Transistoren mit verbesserten Streueigenschaften im Vergleich zu herkömmlichen planaren Designs. Die Firma behauptet, dass ihre Konstruktion die besten Elektrostatiken jedes III-V-Verbindungshalbleitertransistors erreichte. Auf der International Solid-State Circuits Conference 2015 erwähnte Intel die Verwendung von III-V-Verbindungen auf Basis einer solchen Architektur für ihren 7 Nanometer-Knoten.Im Jahr 2011 entwickelten Forscher der University of Texas an Austin einen InGaAs Tunneling-Feldeffekttransistoren, der in der Lage ist, höhere Betriebsströme als bisherige Konstruktionen zu erreichen. Die ersten III-V TFET-Designs wurden 2009 von einem gemeinsamen Team der Cornell University und der Pennsylvania State University gezeigt. Im Jahr 2012 entwickelte ein Team von MIT's Microsystems Technology Laboratories einen 22 nm-Transistor basierend auf InGaAs, der damals der kleinste Non-Silizium-Transistor war, der jemals gebaut wurde. Das Team verwendete Techniken, die derzeit in der Silizium-Geräteherstellung verwendet werden und zielt auf eine bessere elektrische Leistung und eine Reduktion auf 10-Nanometer-Skala. Biologische Berechnungsforschung zeigt, dass biologisches Material eine überlegene Informationsdichte und Energieeffizienz im Vergleich zu Silizium-basiertem Computing aufweist. Für die Graphenelektronik werden verschiedene Formen von Graphen untersucht, z.B. Graphen-Nanoribbon-Transistoren haben seit ihrem Erscheinungsbild in den Publikationen im Jahr 2008 großes Versprechen gezeigt. (Bulk-Graphen hat einen Bandspalt von Null und kann daher wegen seiner konstanten Leitfähigkeit nicht in Transistoren eingesetzt werden, eine Abschaltunfähigkeit. Die Zickzack-Ränder der Nanoribbons stellen lokalisierte Energiezustände in den Leitungs- und Valenzbändern und damit einen Bandgap vor, der ein Schalten bei der Herstellung als Transistor ermöglicht. Als Beispiel weist ein typischer GNR der Breite von 10 nm eine wünschenswerte Bandgapenergie von 0,4eV auf.) Mehr Forschung muss jedoch auf Sub 50 nm-Graphenschichten durchgeführt werden, da sein Widerstandswert zunimmt und damit die Elektronenmobilität abnimmt. Prognosen und Roadmaps Im April 2005 erklärte Gordon Moore in einem Interview, dass die Projektion nicht unbegrenzt erhalten werden kann: "Es kann nicht ewig dauern. Die Natur der Exponentials ist, dass Sie sie ausschieben und schließlich Katastrophe passiert. "Er stellte auch fest, dass Transistoren schließlich die Grenzen der Miniaturisierung auf atomaren Ebenen erreichen würden: In Bezug auf die Größe [von Transistoren] können Sie sehen, dass wir die Größe der Atome nähern, die eine grundlegende Barriere ist, aber es wird zwei oder drei Generationen sein, bevor wir so weit kommen – aber das ist so weit, wie wir jemals sehen konnten. Wir haben weitere 10 bis 20 Jahre, bevor wir eine grundlegende Grenze erreichen. Dann können sie größere Chips machen und Transistorhaushalte in den Milliarden haben. Im Jahr 2016 produzierte die International Technology Roadmap for Semiconductors, nach Moore's Law, die Branche seit 1998 anzutreiben, ihre endgültige Roadmap. Es zentrierte sich nicht mehr auf seinen Forschungs- und Entwicklungsplan für Moore's Gesetz. Stattdessen, es skizziert, was könnte genannt werden, die Mehr als Moore-Strategie, in der die Bedürfnisse der Anwendungen steuern Chip-Entwicklung, anstatt einen Fokus auf Halbleiter-Skalierung. Anwendungstreiber reichen von Smartphones bis AI bis zu Rechenzentren. IEEE begann im Jahr 2016 mit einer Roadmapping-Initiative "Rebooting Computing", benannte die International Roadmap for Devices and Systems (IRDS). Die meisten Prognosen, darunter Gordon Moore, erwarten, dass Moore's Gesetz bis 2025 enden wird. Obwohl Moores Gesetz eine physische Begrenzung erreichen wird, sind viele Prognoser optimistisch über die Fortsetzung des technologischen Fortschritts in einer Vielzahl von anderen Bereichen, einschließlich neuer Chip-Architekturen, Quanten-Computing, und KI und maschinelles Lernen. Konsequenzen Digitale Elektronik hat zum weltweiten Wirtschaftswachstum in den späten zwanzigsten und frühen zwanzigsten Jahrhunderten beigetragen. Die primäre treibende Kraft des Wirtschaftswachstums ist das Wachstum der Produktivität und Moore's Gesetzfaktoren in die Produktivität. Moore (1995) erwartete, dass "die Rate des technologischen Fortschritts von der Finanzwelt kontrolliert werden wird". Die Reverse könnte und konnte in den späten 1990er Jahren auftreten, mit Wirtschaftswissenschaftlern berichtet, dass "Produktivitätswachstum der Schlüsselindikator für Innovation ist. " Moore's Gesetz beschreibt eine treibende Kraft des technologischen und sozialen Wandels, der Produktivität und des Wirtschaftswachstums. Eine Beschleunigung des Halbleiterfortschritts trug zu einem Anstieg des Produktivitätswachstums in den USA bei, der 1997–2004 3,4% pro Jahr erreichte, was die 1,6% pro Jahr sowohl 1972–1996 als auch 2005–2013 übertraf. Wie der Ökonom Richard G. Anderson bemerkt, "Numerische Studien haben die Ursache der Produktivitätsbeschleunigung auf technologische Innovationen bei der Herstellung von Halbleitern, die die Preise solcher Komponenten und der Produkte, die sie enthalten, stark reduziert (und die Fähigkeiten solcher Produkte zu erweitern). " Die primäre negative Implikation von Moore's Gesetz ist, dass Obsoleszenz die Gesellschaft gegen die Grenzen des Wachstums drängt. Da sich die Technologien weiterhin rasch verbessern, werden die Vorgängertechnologien veraltet.In Situationen, in denen Sicherheit und Überlebensfähigkeit von Hardware oder Daten überwiegen, oder in denen die Ressourcen begrenzt sind, stellt eine rasche Überholung oft Hindernisse für den reibungslosen oder fortgesetzten Betrieb dar. Aufgrund der intensiven Ressourcen-Fußabdrücke und toxischen Materialien, die bei der Herstellung von Computern verwendet werden, führt Obsoleszenz zu schwerwiegenden schädlichen Umweltauswirkungen. Die Amerikaner werfen jeden Tag 400.000 Handys aus, aber dieses hohe Niveau der Obsoleszenz scheint Unternehmen als die Möglichkeit, regelmäßige Verkäufe von teuren neuen Geräten zu erzeugen, anstatt ein Gerät für eine längere Zeit zu halten, was zur Industrie mit geplanter Obsoleszenz als Profitcenter führt. Eine alternative Quelle für verbesserte Leistung ist in Mikroarchitekturtechniken, die das Wachstum der verfügbaren Transistorzahl ausnutzen. Out-of-order Ausführung und On-Chip-Caching und Prefetching reduzieren den Speicher-Latenz-Flaschenhals auf Kosten der Verwendung von mehr Transistoren und der Erhöhung der Prozessorkomplexität. Diese Erhöhungen werden empirisch durch Pollack's Regel beschrieben, die besagt, dass Leistungssteigerungen durch Mikroarchitekturtechniken die Quadratwurzel der Komplexität (Anzahl der Transistoren oder der Fläche) eines Prozessors annähern. Seit Jahren, Prozessor-Hersteller lieferten Erhöhungen der Taktraten und Instruktionsebene Parallelismus, so dass eingängiger Code schneller auf neueren Prozessoren ohne Änderung ausgeführt. Um die CPU-Leistungsableitung zu verwalten, bevorzugen Prozessor-Hersteller Multi-Core-Chip-Designs, und Software muss in mehrfacher Weise geschrieben werden, um den vollen Vorteil der Hardware zu nutzen. Viele Multi-Threaded-Entwicklungsparadigmen stellen Overhead ein und werden keine lineare Erhöhung der Geschwindigkeit vs Anzahl der Prozessoren sehen. Dies gilt insbesondere beim Zugriff auf geteilte oder abhängige Ressourcen, aufgrund der Sperrung. Dieser Effekt wird deutlicher, da die Anzahl der Prozessoren zunimmt. Es gibt Fälle, in denen eine etwa 45 %ige Erhöhung der Prozessortransistoren auf etwa 10 - 20 %ige Erhöhung der Verarbeitungsleistung umgesetzt hat. Auf der anderen Seite, Hersteller hinzufügen spezialisierte Verarbeitungseinheiten mit Funktionen wie Grafik, Video und Kryptographie zu behandeln. Zum einen fügt die Parallel-JavaScript-Erweiterung von Intel nicht nur Unterstützung für mehrere Kerne, sondern auch für die anderen nicht-allgemeinen Verarbeitungsfunktionen ihrer Chips als Teil der Migration in der Client-Seiten-Skriptierung nach HTML5 hinzu. Moore's Gesetz hat die Leistung anderer Technologien deutlich beeinflusst: Michael S. Malone schrieb von einem Moore-Krieg nach dem offensichtlichen Erfolg von Schock und Awe in den frühen Tagen des Irak-Kriegs. Fortschritte bei der Entwicklung von geführten Waffen hängen von der elektronischen Technologie ab. Auch Verbesserungen der Leistungsdichte und des leistungsarmen Betriebs im Zusammenhang mit Moore's Gesetz haben zur Entwicklung von Technologien wie Mobiltelefonen und 3-D-Druck beigetragen. Andere Formulierungen und ähnliche Beobachtungen Mehrere Maßnahmen der digitalen Technologie verbessern sich mit exponentiellen Raten im Zusammenhang mit Moore Gesetz, einschließlich der Größe, Kosten, Dichte und Geschwindigkeit der Komponenten. Moore schrieb nur über die Dichte der Komponenten, "eine Komponente ist ein Transistor, Widerstand, Diode oder Kondensator", zu minimalen Kosten. Transistoren pro integrierter Schaltung – Die beliebteste Formulierung ist die Verdoppelung der Anzahl der Transistoren auf ICs alle zwei Jahre. Ende der 1970er Jahre wurde Moore's Gesetz als Grenzwert für die Anzahl der Transistoren auf den komplexesten Chips bekannt. Der Graph oben zeigt, dass dieser Trend heute wahr ist. Ab 2017 ist der kommerziell erhältliche Prozessor mit der höchsten Anzahl von Transistoren der 48 Kern Centriq mit über 18 Milliarden Transistoren. Dichte bei minimalen Kosten pro Transistor – Dies ist die Formulierung in Moore's 1965 Papier. Es geht nicht nur um die Dichte von Transistoren, sondern um die Dichte von Transistoren, bei denen der Aufwand pro Transistor am niedrigsten ist. Da mehr Transistoren auf einen Chip gelegt werden, sinken die Kosten für jeden Transistor, aber die Chance, dass der Chip nicht durch einen Defekt funktioniert, steigt. Im Jahr 1965 untersuchte Moore die Dichte von Transistoren, mit denen die Kosten minimiert werden, und beobachtete, dass, da Transistoren durch Fortschritte bei der Photolithographie kleiner gemacht wurden, diese Zahl mit "eine Rate von etwa einem Faktor von zwei pro Jahr" zunehmen würde. Dennard Skalierung – Dadurch wird erreicht, dass die Stromnutzung im Verhältnis zu Fläche (beide Spannung und Strom proportional zur Länge) von Transistoren abnimmt. In Kombination mit Moore's Gesetz würde die Leistung pro Watt mit etwa der gleichen Rate wie die Transistordichte wachsen und alle 1-2 Jahre verdoppeln.Laut Dennard würden Skalierungstransistordimensionen um 30% (0.7x) jeder Technologiegeneration skaliert und damit ihre Fläche um 50% reduziert. Dies würde die Verzögerung um 30% (0.7x) reduzieren und damit die Betriebsfrequenz um etwa 40% (1.4x) erhöhen. Schließlich würde zur Konstanthaltung des elektrischen Feldes die Spannung um 30,% reduziert Energie um 65 % und Leistung (bei 1,4x Frequenz) um 50 % reduziert. Daher würde sich bei jeder Technologie-Generation die Transistordichte verdoppeln, die Schaltung wird 40% schneller, während der Stromverbrauch (mit doppelter Anzahl von Transistoren) gleich bleibt. Dennard Skalierung kam 2005–2010 aufgrund von Leckströmen zu Ende. Das von Moore vorhergesagte exponentielle Prozessor-Transistor-Wachstum übersetzt sich nicht immer in exponentiell größere praktische CPU-Leistung. Seit 2005–2007 ist Dennard-Skalierung beendet, obwohl Moore's Gesetz mehrere Jahre danach fortsetzte, hat es keine Dividenden in einer verbesserten Leistung abgegeben. Der Hauptgrund für die Störung ist, dass bei kleinen Größen die aktuelle Leckage größere Herausforderungen stellt und auch den Chip aufheizt, was eine Bedrohung für den thermischen Abfluss verursacht und damit die Energiekosten weiter erhöht. Die Aufschlüsselung der Dennard-Skalierung löste einen größeren Fokus auf Multicore-Prozessoren, aber die durch Umschaltung auf mehr Kerne angebotenen Gewinne sind niedriger als die erzielten Gewinne, wenn Dennard-Skalierung fortgesetzt würde. In einem weiteren Abflug von Dennard Skalierung nahm Intel Mikroprozessoren 2012 einen nicht-planaren Tri-Gate FinFET mit 22 nm an, der schneller ist und weniger Strom verbraucht als ein herkömmlicher planarer Transistor. Die Leistungsverbesserung bei Einkern-Mikroprozessoren hat sich deutlich verlangsamt. Die Single-Core-Performance verbesserte sich 1986–2003 um 52 % und 2003–2011 um 23 % pro Jahr, verlangsamte sich aber 2011–2018 auf knapp sieben Prozent pro Jahr. Qualitätsbereinigter Preis für IT-Ausrüstung – Der Preis für Informationstechnologie (IT,) Computer und periphere Geräte, angepasst an Qualität und Inflation, sank im Durchschnitt in den fünf Jahrzehnten von 1959 bis 2009 um 16 % pro Jahr. Das Tempo beschleunigte sich jedoch auf 23 % im Jahr 1995-1999, was durch eine schnellere IT-Innovation ausgelöst wurde, und verlangsamte sich später 2010-2013 auf 2 % im Jahr. Während sich die qualitätsgeregelte Mikroprozessorpreisverbesserung fortsetzt, ändert sich die Verbesserungsrate ebenfalls und ist nicht linear in einer Log-Skala. In den späten 1990er Jahren beschleunigte sich die Preisverbesserung des Mikroprozessors und erreichte 60 % pro Jahr (die Hälfte aller neun Monate) gegenüber der typischen 30 %-Verbesserungsrate (die Hälfte aller zwei Jahre) früher und später. Insbesondere Laptop-Mikroprozessoren verbesserte sich 2004–2010 um 25–35 % pro Jahr und verlangsamte 2010–2013 auf 15–25 % pro Jahr. Die Anzahl der Transistoren pro Chip kann die qualitätsgeregelten Mikroprozessorpreise nicht vollständig erklären. Moore's 1995 Papier beschränkt Moore's Gesetz nicht auf strenge Linearität oder auf Transistor-Gegenstand, "Die Definition von Moore's Law" hat auf fast alles bezogen auf die Halbleiterindustrie, dass auf einem halblog Grundstück nähert sich eine gerade Linie. Ich zögere, seine Herkunft zu überprüfen und dadurch ihre Definition einzuschränken. " Festplattenlaufdichte – Eine ähnliche Vorhersage (manchmal Kryders Gesetz genannt) wurde im Jahr 2005 für Festplattenlaufwerk Flächendichte gemacht. Die Vorhersage wurde später als überoptimistisch angesehen. Mehrere Jahrzehnte des schnellen Fortschritts in der Flächendichte verlangsamt sich um 2010, von 30–100% pro Jahr auf 10–15% pro Jahr, wegen des Lärms im Zusammenhang mit der geringeren Korngröße der Scheibenmedien, der thermischen Stabilität und der Schreibbarkeit mit verfügbaren Magnetfeldern. Faseroptische Kapazität – Die Anzahl der Bits pro Sekunde, die auf eine optische Faser geschickt werden können, erhöht exponentiell, schneller als Moore's Gesetz. Kecks Gesetz, zu Ehren von Donald Keck. Netzwerkkapazität – Laut Gerry/Gerald Butters, dem ehemaligen Chef der Lucent's Optical Networking Group bei Bell Labs, gibt es eine weitere Version, genannt Butters' Law of Photonics, eine Formulierung, die bewusst Moore's Gesetz parallelisiert. Das Buttergesetz sagt, dass die Datenmenge aus einer Glasfaser alle neun Monate verdoppelt. Damit sinken die Kosten für die Übertragung eines Bits über ein optisches Netzwerk alle neun Monate um die Hälfte. Die Verfügbarkeit von Wellenlängen-Division-Multiplexing (manchmal WDM genannt) erhöht die Kapazität, die auf eine einzelne Faser gelegt werden könnte, um so viel als Faktor 100. Optische Vernetzung und dichte Wellenlängen-Division-Multiplexing (DWDM) bringen die Kosten der Vernetzung schnell herunter, und weitere Fortschritte scheinen sicher zu sein. Dadurch kollabierte der Großhandelspreis des Datenverkehrs in der Punkt-Com-Blase.Nielsens Gesetz sagt, dass die Bandbreite, die den Nutzern zur Verfügung steht, um 50% jährlich zunimmt. Pixel pro Dollar – Ähnlicherweise hat Barry Hendy von Kodak Australia Pixel pro Dollar als Basiswert für eine Digitalkamera aufgetragen, die die historische Linearität (auf einer Log-Skala) dieses Marktes und die Möglichkeit zeigt, den zukünftigen Trend der Digitalkamera-Preis, LCD- und LED-Bildschirme und Auflösung vorherzusagen. Der große Moore's Gesetzkompensator (TGMLC) auch als Wirth's Gesetz bekannt - allgemein wird als Software-Blasat bezeichnet und ist das Prinzip, dass aufeinanderfolgende Generationen von Computersoftware Größe und Komplexität erhöhen, wodurch die durch Moore's Gesetz vorhergesagten Leistungsgewinne kompensiert werden. In einem Artikel von 2008 in InfoWorld führt Randall C. Kennedy, ehemals von Intel, diesen Begriff unter Verwendung von aufeinanderfolgenden Versionen von Microsoft Office zwischen dem Jahr 2000 und 2007 als seine Prämisse ein. Trotz der Gewinne in der Rechenleistung in dieser Zeit nach Moore Gesetz, Office 2007 die gleiche Aufgabe mit der Hälfte der Geschwindigkeit auf einem prototypischen Jahr 2007 Computer im Vergleich zu Office 2000 auf einem Jahr 2000 Computer. Bibliothekserweiterung – wurde 1945 von Fremont Rider berechnet, um alle 16 Jahre die Kapazität zu verdoppeln, wenn genügend Platz zur Verfügung gestellt wurde. Er plädierte für die Ersetzung von sperrigen gedruckten Werken mit miniaturisierten mikroformanalogischen Fotografien, die auf Anfrage für Bibliotheks- und andere Institutionen dupliziert werden könnten. Er hat die digitale Technologie, die Jahrzehnte später folgen würde, nicht vorhergesehen, um analoge Mikroform durch digitale Bildgebung, Speicher und Übertragungsmedien zu ersetzen. Automatisierte, potenziell verlustlose digitale Technologien ermöglichten enorme Zunahmen der Schnelligkeit des Informationswachstums in einer Zeit, die jetzt manchmal als Informationszeit bezeichnet wird. Carlson-Kurve – ist ein von The Economist geprägter Begriff, der das biotechnologische Äquivalent des Moore-Gesetzes beschreibt und nach dem Autor Rob Carlson benannt wird. Carlson hat genau vorhergesagt, dass die Verdoppelungszeit von DNA-Sequencing-Technologien (gemessen durch Kosten und Leistung) zumindest so schnell wie Moore's Gesetz wäre. Carlson Curves illustrieren die schnellen (in einigen Fällen hyperexponentiellen) Kostensenkungen und Leistungssteigerungen einer Vielzahl von Technologien, einschließlich DNA-Sequencing, DNA-Synthese und einer Reihe von physikalischen und rechnerischen Werkzeugen, die in der Proteinexpression und bei der Bestimmung von Proteinstrukturen verwendet werden. Erooms Gesetz – ist eine pharmazeutische Drogenentwicklungsbeobachtung, die bewusst als Moore's Gesetz rückwärts geschrieben wurde, um sie mit den exponentiellen Fortschritten anderer Technologien (wie Transistoren) im Laufe der Zeit zu kontrastieren. Es heißt, die Kosten für die Entwicklung eines neuen Medikaments verdoppeln sich alle neun Jahre. Die Erfahrungskurveneffekte weisen darauf hin, dass jede Verdoppelung der kumulativen Produktion von nahezu jedem Produkt oder einer Dienstleistung durch eine annähernd konstante prozentuale Reduzierung der Stückkosten begleitet wird. Die anerkannte erste dokumentierte qualitative Beschreibung dieser Daten aus 1885. Eine Stromkurve wurde verwendet, um dieses Phänomen in einer Diskussion von 1936 über die Kosten von Flugzeugen zu beschreiben. Edholms Gesetz – Phil Edholm beobachtete, dass die Bandbreite der Telekommunikationsnetze (einschließlich Internet) alle 18 Monate verdoppelt. Die Bandbreiten der Online-Kommunikationsnetze sind von Bits pro Sekunde auf Terabits pro Sekunde angestiegen. Der rasche Anstieg der Online-Bandbreite ist weitgehend auf die gleiche MOSFET-Skalierung zurückzuführen, die Moore's Gesetz ermöglicht, da Telekommunikationsnetze aus MOSFETs aufgebaut werden. Haitz's Gesetz prognostiziert, dass die Helligkeit von LEDs mit ihren Herstellungskosten steigt. Swanson's Gesetz ist die Beobachtung, dass der Preis von Solar-Photovoltaik-Modulen tendiert zu fallen 20 Prozent für jede Verdoppelung von kumulativen Versandvolumen. Gegenwärtig sinken die Kosten um alle 10 Jahre um 75%. Siehe auch Anmerkungen ReferenzenWeiterlesen Brock, David C. ed.)(2006). Moore's Law verstehen: Vier Jahrzehnte Innovation. Philadelphia: Chemical Heritage Foundation.ISBN 0-941901-41-6. OCLC 66463488.Mody, Cyrus (2016). Der lange Arm des Moore-Gesetzes: Mikroelektronik und amerikanische Wissenschaft. Cambridge, Mass.: The MIT Press. ISBN 978-0262035491. Thackray, Arnold; David C. Brock und Rachel Jones (2015). Moore's Law: The Life of Gordon Moore, Silicon Valley's Quiet Revolutionary. New York: Basic Books. Externe Links Intel Presse-Kit – veröffentlicht für Moore's Law 40. Jahrestag, mit einer 1965 Skizze von Moore The Lives and Death of Moore's Law – von Ilkka Tuomi; eine detaillierte Studie über Moore's Law und seine historische Evolution und seine Kritik von Kurzweil No Technology war mehr störend.Diashow des Mikrochip-Wachstums Intel (IA-32) CPU-Geschwindigkeiten 1994-2005 – Geschwindigkeitserhöhungen in den letzten Jahren schienen im Hinblick auf prozentuale Zunahme pro Jahr (verfügbar im PDF- oder PNG-Format) International Technology Roadmap for Semiconductors (ITRS) "Gordon Moore, His Law, and Integrated Circuit", Dream 2047, Oktober 2006A C|net FAQ über Moore' Law at Archive.