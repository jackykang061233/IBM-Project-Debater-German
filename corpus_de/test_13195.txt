Multi-Task-Learning (MTL) ist ein Unterfeld des maschinellen Lernens, in dem mehrere Lernaufgaben gleichzeitig gelöst werden, während Gemeinsamkeiten und Unterschiede über Aufgaben hinweg genutzt werden. Dies kann zu einer verbesserten Lerneffizienz und Prädiktionsgenauigkeit für die aufgabenspezifischen Modelle führen, im Vergleich zu einer separaten Schulung der Modelle. Frühe Versionen von MTL wurden als Hinweise bezeichnet". In einem 1997 weit zitierten Papier gab Rich Caruana folgende Charakterisierung: Multitask Learning ist ein Ansatz zur induktiven Übertragung, der die Verallgemeinerung verbessert, indem die in den Trainingssignalen von verwandten Aufgaben enthaltenen Domäneninformationen als induktive Vorspannung verwendet werden. Dies geschieht durch paralleles Erlernen von Aufgaben bei gemeinsamer Darstellung; was für jede Aufgabe gelernt wird, kann dazu beitragen, dass andere Aufgaben besser erlernt werden. Im Klassifikationskontext zielt MTL darauf ab, die Leistung mehrerer Klassifikationsaufgaben durch gemeinsames Lernen zu verbessern. Ein Beispiel ist ein Spamfilter, das als eindeutige, aber verwandte Klassifikationsaufgaben über verschiedene Benutzer behandelt werden kann. Um dies konkreter zu machen, denken Sie, dass verschiedene Menschen unterschiedliche Verteilungen von Funktionen haben, die Spam-E-Mails von legitimen unterscheiden, zum Beispiel ein englischer Sprecher kann feststellen, dass alle E-Mails auf Russisch sind Spam, nicht so für russische Lautsprecher. Dennoch gibt es eine bestimmte Gemeinsamkeit in dieser Klassifikationsaufgabe für Benutzer, zum Beispiel eine gemeinsame Funktion kann Text im Zusammenhang mit Geldtransfer sein. Das Lösen des Spam-Klassifikationsproblems jedes Benutzers gemeinsam über MTL kann die Lösungen untereinander informieren und die Leistung verbessern. Weitere Beispiele für Einstellungen für MTL sind Multiclass-Klassifikation und Multi-Label-Klassifikation. Multi-Task-Lernen funktioniert, weil die durch die Notwendigkeit eines Algorithmus verursachte regelmäßige Durchführung auf einer damit verbundenen Aufgabe kann der Regularisierung überlegen sein, die verhindert, dass die Überbelegung durch Bestrafen aller Komplexität gleichmäßig. Eine Situation, in der MTL besonders hilfreich sein kann, ist, wenn die Aufgaben signifikante Gemeinsamkeiten teilen und in der Regel leicht unter Probe gestellt werden. Wie weiter unten erläutert, hat sich MTL jedoch auch als nützlich erwiesen, um unbezogene Aufgaben zu erlernen. Methoden Task-Gruppierung und Überschneidung Innerhalb des MTL-Paradigmus können Informationen über einige oder alle Aufgaben geteilt werden. Abhängig von der Struktur der Aufgabenverwandtschaft kann es sein, Informationen selektiv über die Aufgaben zu teilen. Beispielsweise können Aufgaben in einer Hierarchie gruppiert oder existieren oder nach einer allgemeinen Metrik verwandt sein. Angenommen, wie weiter unten formell entwickelt, dass die Parametervektormodellierung jeder Aufgabe eine lineare Kombination von einigen zugrunde liegenden Basis ist. Ähnlichkeit mit dieser Basis kann die Zusammenhänge der Aufgaben angeben. So zeigt z.B. bei Sparsity die Überschneidung von Nicht-Nullkoeffizienten über Aufgaben hinweg die Gemeinsamkeit. Eine Task-Gruppierung entspricht dann denjenigen Aufgaben, die in einem Subraum liegen, der von einer Teilmenge von Basiselementen erzeugt wird, wobei Aufgaben in verschiedenen Gruppen beliebig hinsichtlich ihrer Basen disjunkt oder überlappen können. Aufgabenverwandtschaft kann a priori auferlegt oder aus den Daten gelernt werden. Die hierarchische Aufgabenbeziehung kann auch implizit ausgenutzt werden, ohne dass a priori Wissen oder Lernbeziehungen explizit angenommen werden. Beispielsweise kann das explizite Erlernen von Probenrelevanz über Aufgaben hinweg durchgeführt werden, um die Effektivität des gemeinsamen Lernens über mehrere Domänen hinweg zu gewährleisten. Ausnutzen von unbezogenen Aufgaben Man kann versuchen, eine Gruppe von Hauptaufgaben mit einer Gruppe von Hilfsaufgaben zu lernen, die nicht mit den Hauptaufgaben zusammenhängen. In vielen Anwendungen kann das gemeinsame Erlernen von unbezogenen Aufgaben, die dieselben Eingabedaten verwenden, von Vorteil sein. Der Grund ist, dass Vorkenntnisse über die Aufgabenverwandtschaft zu sparsameren und informativen Darstellungen für jede Aufgabengruppierung führen können, im Wesentlichen durch das Screening von Idiosyncrasies der Datenverteilung. Es wurden neue Methoden vorgeschlagen, die auf einer vorherigen Multitask-Methodik aufbauen, indem eine gemeinsame Low-dimensionale Darstellung innerhalb jeder Task-Gruppierung begünstigt wird. Der Programmierer kann Aufgaben verschiedener Gruppen bestrafen, die die beiden Darstellungen orthogonal fördern. Experimente zu synthetischen und realen Daten haben gezeigt, dass die Einbeziehung unbezogener Aufgaben zu signifikanten Verbesserungen gegenüber Standard-Multi-Task-Lernmethoden führen kann. Wissenstransfer In Verbindung mit mehrstufigem Lernen ist das Konzept des Wissenstransfers. Während traditionelles mehrstufiges Lernen impliziert, dass eine gemeinsame Darstellung gleichzeitig über Aufgaben hinweg entwickelt wird, bedeutet Wissenstransfer eine sequentiell geteilte Darstellung. Großformatige maschinelle Lernprojekte wie das tiefe konvolutionale neuronale Netz GoogLeNet, ein bildbasierter Objekt-Klassifikator, können robuste Darstellungen entwickeln, die für weitere Algorithmen, die ähnliche Aufgaben erlernen, nützlich sein können. Beispielsweise kann das vortrainierte Modell als Merkmalsextraktor zur Vorverarbeitung für einen anderen Lernalgorithmus verwendet werden. Oder das vortrainierte Modell kann verwendet werden, um ein Modell mit ähnlicher Architektur zu initialisieren, das dann fein abgestimmt wird, um eine andere Klassifizierungsaufgabe zu lernen. Gruppen-Online-Adaptives Lernen Traditionell Multi-Task-Erlernen und Wissenstransfer werden auf stationäre Lerneinstellungen angewendet. Ihre Erweiterung auf nicht-stationäre Umgebungen wird als Group online adaptive learning (GOAL) bezeichnet. Der Austausch von Informationen könnte besonders nützlich sein, wenn Lernende in sich verändernden Umgebungen arbeiten, weil ein Lernender von früheren Erfahrungen eines anderen Lernenden profitieren könnte, um sich schnell an ihre neue Umgebung anzupassen. Ein solches gruppenadaptives Lernen hat zahlreiche Anwendungen, von der Vorhersage der finanziellen Zeitreihen über Content-Empfehlungssysteme bis hin zum visuellen Verständnis für adaptive autonome Agenten. Mathematics Reproducing Hilbert Raum von vektorwertierten Funktionen (RKHSvv) Das MTL-Problem kann im Kontext von RKHSvv (ein vollständiger innerer Produktraum von vektorwertierten Funktionen mit einem reproduzierenden Kernel ausgestattet) geworfen werden. Insbesondere hat sich der jüngste Fokus auf Fälle konzentriert, in denen die Taskstruktur über einen separierbaren Kernel identifiziert werden kann, wie im folgenden beschrieben. Die Präsentation hier stammt von Ciliberto et al,. 2015. RKHSvv-Konzepte Angenommen, der Trainingsdatensatz ist EPMATHMARKEREP i) 1 n t ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ {R} \times \mathbb {R} \rightarrow \mathbb {R} _{+}} fÃ1⁄4r jede Aufgabe: .This fÃ1⁄4hrt zu dem normalisierten maschinellen Lernproblem: wo H {\displaystyle {\mathcal {H} ein Vektor ist, der reproducing Kernel Hilbert Raum mit Funktionen f : X → Y T {\displaystyle f:{\mathcal (X) - Ja. T mit Komponenten f t : X → Y {\displaystyle f_{t}:{\mathcal (X) {\displaystyle {\mathcal {H} der Funktionen f : X → R T {\displaystyle f:{\mathcal {X}\rightarrow \mathbb {R}\^T} ist eine symmetrische Matrix-ausgewertete Funktion Γ (R) c ε H {\displaystyle \Gamma \(cdot ,x)c\in {\mathcal {H} und die folgende reproduzierende Eigenschaft hält: Der reproduierende Kernel gibt einen Repräsentantentheorem an, der zeigt, dass jede Lösung zu Gleichung 1 die Form hat: Trennbare Kerne Die Form des Kernels Γ induziert sowohl die Darstellung des Funktionsraums als auch die Strukturen, die über Aufgaben ausgegeben werden. Eine natürliche Vereinfachung besteht darin, einen separierbaren Kernel zu wählen, der in separate Kerne auf dem Eingaberaum X und auf den Aufgaben { 1 , ., T } {\displaystyle {1,...,T} einbezieht. A s, t {\textstyle \gamma x_{i},t),(x_{j},s))=k(x_{i},x_{j})k_{T}(s,t)=k(x_{i},x_{j}) A_{s,t . Für vektorwertierte Funktionen f ε H {\displaystyle f\in {\mathcal {H} können wir Γ ( x i, x j) = k ( x i, x j ) schreiben. A {\displaystyle (x_{i},x_{j})=k(x_{i},x_{j}) A, wo k ein skalar reproduzierender Kern ist, und A ist eine symmetrische positive semi-definite T × T {\displaystyle T\times T} Matrix. S + T = { PSD-Matrizen } T {\displaystyle S_{+}^{T}=\text{PSD matrices}\}\subset \mathbb {R} {^T\times T} .Diese Faktorisierungseigenschaft, Trennbarkeit, impliziert, dass die Eingabe-Feature-Raumdarstellung nicht von der Aufgabe variiert. Das heißt, es gibt keine Interaktion zwischen dem Eingabekernel und dem Task-Kernel. Die Struktur auf Aufgaben wird allein durch A dargestellt. Methoden für nicht trennbare Kerne Γ ist ein aktuelles Forschungsfeld. Für den separablen Fall wird die Darstellungstheorem auf f ( x ) = Σ i = 1 N k ( x, x i) A c i {\textstyle f(x)=\sum i=1}^{N}k(x,x_{i})Ac_{i .Die Modellausgabe auf den Trainingsdaten ist dann KCA , wobei K die n × n {\displaystyle n\times n} empirical kernel matrix mit Einträgen K i, j = k ( x i, x j ) {\textstyle K_{i,j}=k(x_{i},x_{j) und C ist die n × T {\displaystyle n\times T} Matrix der Zeilen c i {\displaystyle c_{i} . Mit dem separablen Kernel kann Gleichung 1 neu geschrieben werden, da V ein (gewichtetes) Durchschnitt von L eingeschrieben in Y und KCA ist.( Das Gewicht ist Null, wenn Y i t {\displaystyle Y_{i}^{t eine fehlende Beobachtung ist. Der zweite Begriff in P kann wie folgt abgeleitet werden:= Σ i, j = 1 n k ( x i, x j ) c i ⊤ A c j = t r ( K C A C ⊤ ) ) {\displaystyle start{align}\|f\ed{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ x_{i}Ac_{i},\sum _j=1}^{n}k(\cdot ,x_{j} (\cdot x_{i} ,x_{j}Ac_{j}\rangle {\_mathcal H}&{\text{(bilinearity)}\\&=\sum_i,j=1{n}\langle k(x_{i},x_{j}}Ac_{i},c_{j}\rangle ... {R} Ac_{j}=tr(KCAC^{\top \)end{ausgeglichene bekannte Taskstruktur Darstellungen der Aufgabenstruktur Es gibt drei weitgehend äquivalente Möglichkeiten, die Taskstruktur darzustellen: durch einen Regularizer; durch eine Ausgabemetrik und durch eine Ausgabe-Mapping. Beispiele für die Struktur der Aufgaben Über die Regularizer-Formulierung kann man eine Vielzahl von Aufgabenstrukturen leicht darstellen. A † = γ I T + (γ - λ ) 1 T 1 1 ⊤ {\textstyle A^{\dagger =\}gamma I_{T}+(\gamma \-lambda {\)frac 1}{T}}\mathbf {1} \mathbf} {\^top}} (wo I T {\displaystyle I_{T} die TxT-Identitätsmatrix ist, und 1 1 ⊤ {\textstyle \mathbf {1} \mathbf {1} {\^top } die TxT-Matrix von einem ist gleichwertig, um Γ die Varianz steuern zu lassen ∑ t | f t - f ̄ |  H ||  H || k text k} ) H}_{k der Aufgaben aus ihrem mittleren 1 T Σ t f t {\textstyle {\frac 1}{T}\sum t}f_{t . Beispielsweise können Blutspiegel eines Biomarkers an T-Patienten bei n t {\displaystyle n_{t}-Zeitpunkten während eines Tages eingenommen werden und Interesse kann in der Regelierung der Varianz der Vorhersagen über Patienten liegen. A † = α I T + (α − λ ) M {\displaystyle A^{\dagger =\}alpha I_{T}+(\alpha \-lambda )M}, wobei M t, s = 1 | G r | I ( t, s ε G r eff) {\displaystyle M_{t,s}={\frac - Ja. {I} (t,s\in G_{r}) ist gleichwertig, um α {\displaystyle \alpha } die hinsichtlich eines Gruppenmittels gemessene Varianz steuern zu lassen: Σ r Σ t ∈ G r | | f t - 1 | G r | Σ s ε g r ) ) ) ) | | | | | | | dis   ) ) ) ) ) ) )                       ) ) ∈ ) ∈ ∈ ∈ ∈ ∈ ∈ ∈ ∈ ∈ G_{r}cf_{t}-{\fra ') {_s\in G_{r})}f_{s| .(Hier | G r | {\displaystyle G_{r} die Herzlichkeit der Gruppe r, und ich {\displaystyle \mathbb {I} ist die Anzeigefunktion). So könnten beispielsweise Menschen in verschiedenen politischen Parteien (Gruppen) zusammen mit der Vorhersage der Begünstigungsbewertung eines Politikers reguliert werden. Beachten Sie, dass diese Strafe auf die erste reduziert, wenn alle Aufgaben in der gleichen Gruppe sind. A † = δ I T + ( δ - λ ) L {\displaystyle A^{\dagger =\}delta I_{T}+(\delta \-lambda )L}, wobei L = D − M {\displaystyle L=D-M} der Laplacian für den Graph mit Adjacency Matrix M ist, der paarweise Ähnlichkeiten von Aufgaben gibt. Dies entspricht einer größeren Strafe für die Entfernungstrennaufgaben t und s, wenn sie ähnlicher sind (nach dem Gewicht M t, s {\displaystyle M_{t,s} ,) i.e δ {\displaystyle \delta } normalisiert Σ t, s s  − f t − f s |  H  H H k 2 M t, s {\displaystyle \sum t,s}||f_{t}-f_{s}||_{\mathcal ) .Alle der oben genannten Wahlen von A auch induzieren den zusätzlichen Regularisierungsterm λ Σ t | | f | | H k 2 {\textstyle \lambda \sum t}||f||_{\mathcal H}_{k}^^^2, die die Komplexität in f breiter belastet. Lernaufgaben zusammen mit ihrer Struktur Lernproblem P kann verallgemeinert werden, um Lernaufgabe-Matrix zuzulassen A wie folgt: Wahl von F : S + T → R + {\displaystyle F:S_{+} T}\rightarrow \mathbb {R} _{+}} muss so ausgelegt sein, Matrizen A eines bestimmten Typs zu lernen. Siehe unten "Special Cases". Die Optimierung von Q Einschnürung bei konvexen Verlusten und koerzitiven Strafen Ciliberto et al.have hat gezeigt, dass, obwohl Q nicht gemeinsam in C und A konvex ist, ein damit verbundenes Problem gemeinsam konvex ist. Spezifisch auf dem konvexen Satz C = { (C, A) ε R n × T × S + T | R a n g e (C ⊤ K C ) R a n g e ( A ) } {\displaystyle {\mathcal C}=\{(C,A)\in \mathbb {R} {^n\times T}\timesS_{+}^{T}RRange(C{\top }KC)\subseteq Range(A\}) , das äquivalente Problem ist mit dem gleichen Minimalwert konvexvexemplar. Und wenn (C R, A R ) {\displaystyle (C_{R},A_{R) ein Minimierer für R ist, dann (C R A R †, A R ) {\displaystyle (C_{R}A_{R}^{\dagger ,A_{R) ist ein Minimierer für Q. R kann durch ein Barriereverfahren auf einem geschlossenen Satz gelöst werden, indem folgende Störung eingeführt wird: Die Perturbation über die Barriere δ 2 t r (A † ) {\displaystyle \delta 2}tr(A^{\dagger })} zwingt die Zielfunktionen gleich + ∞ {\displaystyle \+infty } an der Grenze R n × T × S + T {\displaystyle R^^n\Zeiten T\Zeiten S_{+}^{T .S kann mit einem Blockkoordinatenabstiegsverfahren, abwechselnd in C und A gelöst werden. Dies führt zu einer Folge von Minimatoren (C m , A m ) {\displaystyle (C_{m},A_{m) in S, die zu der Lösung in R als δ m → 0 {\displaystyle \delta {_m}\rightarrow 0} konvergiert, und gibt daher die Lösung für Q. Sonderfälle Spektralstrafen - Dinnuzo et al vorgeschlagen Einstellung F als Frobenius Norm t Sie optimierten Q direkt mit Blockkoordinatenabstieg, ohne dass Schwierigkeiten an der Grenze von R n × T × S + T {\displaystyle \mathbb {R} {^n\times T}\times S_{+}^{T .Clustered Tasks learning - Jacob et al schlug vor, A in der Einstellung zu lernen, in der T Aufgaben werden in R disjoint Clustern organisiert. In diesem Fall lassen E ε { 0 , 1 } T × R {\displaystyle E\in 0,1 Zeit R} die Matrix mit E t , r = I ( Task t ε group r ) {\displaystyle E_{t,r}=\mathbb {I} \(text{task }t\in \text{group r) .Einstellungen M = I − E † E T {\displaystyle M=I-E^{\dagger E^{T , und U = 1 T 11 ⊤ {\displaystyle U={\frac 1}{T}\mathbf {11} {\^top }, die Task-Matrix A † {\displaystyle A^{\dagger }}} kann in Abhängigkeit von M {\displaystyle M} parametrisiert werden: A † (M \) = ε M U + ε B (M - U psi) + ε ( Igger - M ψ\display} {\displaystyle A^ {_M}U+\epsilon {_B}(M-U)+\epsilon(I-M , mit Begriffen, die den Durchschnitt penalisieren, zwischen Cluster-Varianz und innerhalb von Cluster-Varianz bzw. der Aufgabenvorhersagungen. M ist nicht konvex, aber es gibt eine konvexe Relaxation S c = { M ε S + T : I - M ε S + T ξ t r ( M ) = r } {\displaystyle {\mathcal SAMMLUNG M S_{+}^{T}:I-M\in S_{+}^{T}\land tr(M)=r\} .In dieser Formulierung, F (A) = I (A (M) ε ε : M ε S C } ) {\displaystyle F(A)=\mathbb {I} A(M)\in {A:M\in {\mathcal S}}}_{C\) . Nicht konvexe Strafen - Strafen können so konstruiert werden, dass A ein Diagramm Laplacian ist, oder dass A niedriger Rang Factorisierung. Diese Sanktionen sind jedoch nicht konvex, und die Analyse der von Ciliberto et al.does vorgeschlagenen Barrieremethode geht in diesen Fällen nicht durch. Nicht trennbare Kerne - Trennbare Kerne sind begrenzt, insbesondere sie berücksichtigen keine Strukturen im Interaktionsraum zwischen Eingangs- und Ausgangsdomänen gemeinsam. Zukunftsarbeit ist erforderlich, um Modelle für diese Kernel zu entwickeln. Anwendungen Spamfilterung Mit den Prinzipien von MTL wurden Techniken zur kollaborativen Spamfilterung vorgeschlagen, die die Personalisierung erleichtert. In großen Formaten offene Mitglieder-E-Mail-Systeme, die meisten Benutzer nicht genug Nachrichten für einen einzelnen lokalen Klassifikator, um effektiv zu sein, während die Daten zu laut für einen globalen Filter über alle Benutzer verwendet werden. Ein hybrider global/individueller Klassifikator kann wirksam sein, den Einfluss von Nutzern, die E-Mails sehr diligent von der Allgemeinheit etikettieren, zu absorbieren. Dies kann erreicht werden, während immer noch ausreichend Qualität für Benutzer mit wenigen markierten Instanzen. Web-Suche Mit verbesserten Entscheidungsbäumen kann man implizite Datenfreigabe und Regularisierung ermöglichen. Diese Lernmethode kann auf Web-Such-Ranking-Datensätzen verwendet werden. Ein Beispiel ist die Verwendung von Ranking-Datensätzen aus mehreren Ländern. Hier ist Multitask-Lernen besonders hilfreich, da Datensätze aus verschiedenen Ländern aufgrund der Kosten für redaktionelle Urteile weitgehend unterschiedlich sind. Es hat sich gezeigt, dass das Lernen verschiedener Aufgaben gemeinsam zu signifikanten Leistungsverbesserungen mit überraschender Zuverlässigkeit führen kann. Softwarepaket Das Multi-Task Learning via StructurAl Regularization (MALSAR)Matlab-Paket implementiert die folgenden Multi-Task Lernalgorithmen: Mean-Regularized Multi-Task Lernen Multi-Task Lernen mit gemeinsamen Feature-AuswahlRobust Multi-Task Feature Lernen Trace-NormRegularisiert Mehrstufiges LernenAlternative strukturelle Optimierung Inkohärentes Low-Rank- und Sparse LearningRobust Low-Rank Multi-Task Learning Clustered Multi-Task Learning Multi-Task Learning mit Graph Structures Siehe auch Referenzen Externe Links Die Biosignals Intelligence Group an der UIUC Washington University an der St. Louis Depart.of Computer Science Software Das Multi-Task Learning über strukturelle Regularisierung PackageOnline Multi-Task Learning Ein universelles Online-Multi-Task-Learning-Toolkit basierend auf bedingten zufälligen Feldmodellen und stochastischen Gradienten-Abstiegstraining (C,# .NET)