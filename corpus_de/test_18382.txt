In der Computerwissenschaft sind anspruchsvolle Algorithmen, manchmal sogenannten „gepansenkenden“ Algorithmen, eine wichtige Klasse von Strengealgorithmen, die versuchen, einen Ort zu finden, an dem ein oder mehrere (auch genannte Muster) innerhalb einer größeren Tiefe oder Text gefunden werden. Ein grundlegendes Beispiel für die Suche ist, wenn das Muster und der gesuchte Text eine Reihe von Elementen eines Alphabets (finite Set). sind.  human kann ein menschliches Alphabet sein, z.B. die Buchstaben A durch Z und andere Anwendungen können ein binäres Alphabet ( = = {0,1) oder ein DNA- Alphabet (. = {A,C,G,T) in Bioinformatik verwenden. In der Praxis kann die Methode des durchführbaren Glättchen-Algorithmus von der festen Kodierung beeinflusst werden. Insbesondere, wenn eine variable Breite-Kodierung verwendet wird, kann es langsamer sein, den Nth-Status zu finden, was vielleicht Zeit proportional zu N. Dies kann einige Suchalgorithmen erheblich verlangsamen. Eine von vielen möglichen Lösungen ist die Suche nach der Sequenz von Code-Einheiten anstelle, aber dies kann falsche Spiele liefern, es sei denn, die Kodierung ist speziell für die Vermeidung bestimmt. Übersicht Der wichtigste Fall der Nadelsuche ist eine (häufig sehr lange) Tiefe, manchmal die Heustack und eine (häufig sehr kurze) Nadel genannt. Ziel ist es, ein oder mehrere Fälle der Nadel innerhalb des Heustacks zu finden. Zum Beispiel könnte man versuchen, Manche Bücher sind zu geschmacklich, andere müssen verschluckt werden, und einige wenige müssen gekaut und verdaut werden. Eines kann das erste Ereignis, das vierte Wort ist, oder alle Ereignisse, von denen es 3 gibt, oder das letzte, das fünfte Wort vom Ende. Häufig werden jedoch verschiedene Zwänge hinzugefügt. Zum Beispiel kann man die Nadel nur dann angleichen, wenn sie aus einem (oder mehr) vollständigen Wörtern besteht -perhaps definiert als nicht unmittelbar aneinander angrenzende Briefe. In diesem Fall sollte eine Suche nach Hew oder Low den oben genannten Satz verfehlen, auch wenn diese lengel auftreten. Ein weiteres gemeinsames Beispiel ist die Normalisierung. Für viele Zwecke sollte eine Suche nach einem Satz wie "zu sein" auch an Orten erfolgreich sein, in denen etwas anderes zwischen dem und dem Ort besteht: Mehr als ein Raum Andere weiße Raumfahrtzeichen, wie z.B. die Befüllung, die nicht-gefährten Räume, die Ausbrüche usw. weniger häufig, eine Hyphen oder weiche Hyphen In strukturierten Texten, Etiketten oder sogar willkürlich große, aber elterhetische Dinge wie Fußnoteen, Listennummern oder andere Marker, eingebettete Bilder und so. Viele Symbolsysteme umfassen Zeichen, die Synonym sind (mindestens für einige Zwecke): Lateinische Alphabete unterscheiden sich von der oberen Sache, aber für viele Zwecke wird eine harte Suche voraussichtlich die Unterscheidung ignorieren. Viele Sprachen umfassen Ligaturen, bei denen ein zusammengesetzter Charakter zwei oder mehr andere Zeichen entspricht. Viele Schreibsysteme umfassen diaktische Zeichen wie Akzente oder Wowelpunkte, die in ihrer Nutzung variieren können oder von unterschiedlicher Bedeutung sind. DNA-Sequenzen können nichtkodierte Segmente umfassen, die für einige Zwecke ignoriert werden können, oder Polymorphismen, die zu keiner Änderung der codierten Proteine führen, die für einige andere Zwecke nicht als echte Differenz zählen können. Manche Sprachen haben Regeln, in denen eine andere Art oder Form von Charakter zu Beginn, Mitte oder Ende der Worte verwendet werden muss. Letztlich werden die Aspekte der Sprache selbst einbezogen. Zum Beispiel möchte man alle Ereignisse eines Wortes finden, obwohl es sich um andere Formulierungen, Vorsätze oder Suffixes usw. handelt. Eine weitere komplexere Art der Suche ist regelmäßige Ausdruckssuche, bei der der Nutzer ein Muster von Zeichen oder anderen Symbolen erstellt, und jedes Spiel mit dem Muster sollte die Suche erfüllen. Zum Beispiel, um sowohl die amerikanische englische Wortfarbe als auch die englische gleiche Farbe zu fangen, anstatt zwei unterschiedliche Liter zu suchen, könnte man einen regelmäßigen Ausdruck verwenden, wie: colou?r, wo der "?", wo der frühere Charakter (u) fakultativ ist. In diesem Artikel werden vor allem Algorithmen für die einfacheren Arten von Nadeln diskutiert. Ein ähnliches Problem, das im Bereich Bioinformatik und Genomik eingeführt wurde, ist die maximale Genauigkeit (MEM). MEMs sind gemeinsame Unterbänder, die nicht verlängert werden können oder ohne ein Missverhältnis verursachen können. Beispiele für Suchalgorithmen Naïve anspruchsvolle Suche nach einem einfachen und ineffizienten Weg, um zu sehen, wo eine Nadel innerhalb eines anderen auftritt, ist es, jeden Ort zu überprüfen, um zu sehen, ob es dort gibt. Erstens sehen wir, ob es eine Kopie der Nadel im ersten Charakter des Heustacks gibt; wenn nicht, sehen wir, ob eine Kopie der Nadel, die auf dem zweiten Charakter des Heustacks beginnt; wenn nicht, beginnen wir den dritten Charakter und so kurz. Im normalen Fall müssen wir nur eine oder zwei Zeichen für jede falsche Position betrachten, um zu sehen, dass es eine falsche Position ist, so im durchschnittlichen Fall, dauert dies O(n + m) Schritte, wenn n die Länge der Heustack und m die Länge der Nadel ist; aber im schlimmsten Fall suchen Sie auf eine Schale wie Aaaaab in einer Schale wie Aaaaab, es dauert O(nm) Finite-state-automaton-on-basierte Suche. In diesem Ansatz vermeiden wir die Rückführung durch den Aufbau einer deterministischen Finnite automaton (DFA), die die gespeicherten Suchplatten erkennt. Diese sind teuer zu bauen – sie werden in der Regel mit dem Stromsetbau geschaffen – aber sind sehr schnell zu verwenden. So hat die DFA zum Beispiel das Wort MOMMY erkannt. Dieser Ansatz wird in der Praxis häufig allgemeinisiert, um willkürliche regelmäßige Ausdrucksformen zu suchen. ss Knuth-Morris-Pratt berechnet eine DFA, die die Inputs mit der Spitze erkennt, um als Suffix zu suchen, beginnt Boyer-Moore am Ende der Nadel, so dass sie in der Regel eine ganze Nadellänge auf jedem Schritt anlegen kann. Baeza–Yate halten fest, ob die vorherigen j-Aufzeichnungen einen Vorsprung der Suchmaschine darstellen, und sind daher an die Suche nach fuzzyen angepasst. Der Bitap-Algorithmus ist eine Anwendung des Baeza-Yate-Ansatzes. Indexmethoden Schneller Suchealgorithmen präprozessieren den Text. Nach dem Aufbau eines Substring-Index, beispielsweise eines suffixbaums oder einer suffix-Sorte, können die Ereignisse eines Musters schnell gefunden werden. Als Beispiel kann ein Suffixbaum in ) (n ) Memedisplaystyle \Theta (n)} gebaut werden, und alle z Memestyle z} Ereignisse eines Musters können in O ( m) Memestyle O(m)} unter der Annahme gefunden werden, dass das Alphabet eine konstante Größe und alle inneren Knoten im suffix Baum kennt, was unter ihnen liegt. Letztere können durch den Einsatz eines DFS-Algorithmus aus der Wurzel des Suffixbaums erreicht werden. Andere Varianten Einige Suchmethoden, z.B. die Suche nach Trigram, zielen darauf ab, eine Zwischenbilanz zwischen der Suchmaschine und dem Text anstelle eines Gleichgewichts/Nichtangebots zu finden. Es handelt sich manchmal um Fuzzy-Suche. Einstufung von Suchalgorithmen durch eine Reihe von Mustern Die verschiedenen Algorithmen können von der Anzahl der Muster jeder Verwendung klassifiziert werden. Single-Patent-Algorithmen In der folgenden Zusammenstellung ist m die Länge des Musters, die Länge des nachprüfbaren Textes, k = . ist die Größe des Alphabets und f ist eine ständige Einführung durch SIMD-Operationen. 1.^Asymptotische Zeiten werden unter Verwendung von O, PFL und .-Zulassung ausgedrückt. Der Boyer-Moore-Fischgorithmus ist der Standard-Benchmark für die praktische Forschung. Algorithms mit einem finitären Satz von Mustern Aho-Corasick-Qualgorithmen (Verlängerung von Knuth-Morris-Pratt)Commentz-Walter-Algorithmen (Verlängerung von Boyer-Moore) Set-BOM (Verlängerung von Backward Oracle)Rabin-Karp-Galgorithmus Algorithms mit einer unbegrenzten Anzahl von Mustern können die Muster in diesem Fall nicht unbegrenzt angegeben werden. Sie sind in der Regel durch eine reguläre oder regelmäßige Ausdrucksform vertreten. Klassifizierung durch Verwendung von Vorverarbeitungsprogrammen Andere Klassifikationsansätze sind möglich. Einer der häufigsten Verwendungen als wichtigste Kriterien. Einstufung durch entsprechende Strategien Eine andere Klasse bezeichnet die Algorithmen nach ihrer jeweiligen Strategie: Wenden Sie den ersten Vorsatz (Knuth-Morris-Pratt, Shift-And, Aho-Corasick) suffix zuerst (Boyer-Moore und Varianten, Kommentarz-Walter) Hier den besten Faktor zuerst (BNDM, BOM, Set-BOM) Andere Strategie (Naïve, Rabin-Karp) Siehe auch die Sequence-Konvergenzmuster, die den Comprim-Muster entsprechen, die die Abfragen von Wildcards Full-text, S. Boyer und J. S. Moore, einen schnellen Suchealgorithmus, Carom.ACM 20, (10), 262–272(1977). Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein. Einführung in Algorithms, dritte Ausgabe. MIT Presse und McGraw-Hill, 2009.ISBN 0-262-03293-7.Chapter 32: Strenge, S. 985–1013. Außenbeziehungen Huge Liste der Muster, die miteinander in Einklang stehen Letzte Aktualisierung: 12/27/2008 20:18:38 Große (vorbehaltene) Liste von Strengen-Algorithmen NIST-Liste von anspruchsvollen Algorithmen Strenge – Leistungsmuster, die Algorithmen in Java entsprechen – Umsetzungen vieler strenger Konformitäts-Algorithmen in Java (BNDM, Boyer-Moore-Horspools, Boyer-Moore-Horspool-Raita, Shift-Or) Strenge – Umsetzungen vieler strenger, strenger und mehrfacher Modelle (für Einzel- und Multiple Muster und Modelle) in Java (nur für die Umsetzung von C2G) – detaillierte Darstellungen und Kombinationen von C2G-Cithen und C.