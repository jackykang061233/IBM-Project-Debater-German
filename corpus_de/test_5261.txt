Symbolische künstliche Intelligenz ist der Begriff für die Sammlung aller Methoden in der künstlichen Intelligenzforschung, die auf hochrangigen symbolischen (menschlesbaren) Darstellungen von Problemen, Logik und Suche basieren. Symbolische KI war das dominante Paradigma der KI-Forschung von Mitte der 1950er bis Ende der 1980er Jahre. John Haugeland gab den Namen GOFAI ("Good Old-Fashioned Artificial Intelligence") zu symbolischen KI in seinem 1985 Buch Artificial Intelligence: The Very Idea, die die philosophischen Auswirkungen der künstlichen Intelligenzforschung erforschte. In der Robotik ist der analoge Begriff GOFR ("Gute altmodische Robotik"). Die Forscher in den 1960er und 1970er Jahren waren davon überzeugt, dass symbolische Ansätze letztendlich in der Schaffung einer Maschine mit künstlicher allgemeiner Intelligenz gelingt und dieses Ziel ihres Feldes betrachteten. Der symbolische Ansatz würde jedoch schließlich aufgegeben werden, vor allem wegen der technischen Grenzen dieses Ansatzes. Es wurde durch sehr mathematische statistische KI erfolgreich, die weitgehend auf spezifische Probleme mit spezifischen Zielen gerichtet ist, statt allgemeine Intelligenz. Die Forschung an allgemeine Intelligenz wird nun im exploratorischen Teilgebiet der künstlichen allgemeinen Intelligenz untersucht. Ursprung Das erste symbolische KI-Programm war der von Allen Newell, Herbert Simon und Cliff Shaw 1955-56 verfasste Logiktheoretiker. Die symbolische Herangehensweise wurde in der von Newell und Simon Mitte der 1960er Jahre vorgeschlagenen "physischen Symbolsystemhypothese" deutlich ausgedrückt: "Ein physisches Symbolsystem hat die notwendigen und ausreichenden Mittel für allgemeine intelligente Handlungen." Dominantes Paradigma 1955-1990 In den 1960er Jahren erreichten symbolische Ansätze großen Erfolg bei der Simulation von intelligentem Verhalten in kleinen Demonstrationsprogrammen. KI-Forschung wurde in drei Institutionen in den 1960er Jahren zentriert:Carnegie Mellon University, Stanford und MIT, und wie unten beschrieben, entwickelt jeder seine eigene Art von Forschung. Frühere Ansätze auf Basis von Cybernetik oder künstlichen neuronalen Netzwerken wurden aufgegeben oder in den Hintergrund geschoben. Kognitive Simulation Der Ökonom Herbert Simon und Allen Newell studierten die Fähigkeiten der menschlichen Problemlösung und versuchten, sie zu formalisieren, und ihre Arbeit legte die Grundlagen des Bereichs der künstlichen Intelligenz, sowie kognitive Wissenschaft, Operationen Forschung und Management Wissenschaft. Ihr Forschungsteam nutzte die Ergebnisse psychologischer Experimente, um Programme zu entwickeln, die die Techniken simulierten, die Menschen verwendet, um Probleme zu lösen. Diese Tradition, zentriert an der Carnegie Mellon University, würde schließlich in der Entwicklung der Soar Architektur in den Mitte der 1980er Jahre gipfeln. Im Gegensatz zu Simon und Newell fühlte John McCarthy, dass Maschinen den menschlichen Gedanken nicht simulieren müssten, sondern versuchen sollten, die Essenz der abstrakten Argumentation und Problemlösung zu finden, unabhängig davon, ob die Menschen die gleichen Algorithmen benutzten. Sein Labor in Stanford (SAIL) konzentrierte sich auf die Verwendung formaler Logik, um eine Vielzahl von Problemen zu lösen, einschließlich Wissensdarstellung, Planung und Lernen. Logic war auch der Schwerpunkt der Arbeit an der Universität Edinburgh und anderswo in Europa, die zur Entwicklung der Programmiersprache Prolog und der Wissenschaft der Logik-Programmierung führte. Antiloge oder skruffige Forscher am MIT (wie Marvin Minsky und Seymour Papert) fanden heraus, dass die Lösung schwieriger Probleme in der Vision und der natürlichen Sprachverarbeitung ad hoc Lösungen erforderte – sie argumentierten, dass kein einfaches und allgemeines Prinzip (wie Logik) alle Aspekte des intelligenten Verhaltens erfassen würde. Roger Schank beschrieb ihre antilogischen Ansätze als skruffy (im Gegensatz zu den ordentlichen Paradigmen bei CMU und Stanford). Commonsense Wissensbasen (wie Doug Lenat's Cyc) sind ein Beispiel für skrupellose KI, da sie von Hand gebaut werden müssen, ein kompliziertes Konzept zu einer Zeit. Wissensbasierte Als Computer mit großen Erinnerungen um 1970 verfügbar wurden, begannen Forscher aus allen drei Traditionen, Wissen in KI-Anwendungen aufzubauen. Die Wissensrevolution wurde von der Erkenntnis angetrieben, dass durch viele einfache KI-Anwendungen enorme Wissensmengen erforderlich wären. Techniken Ein symbolisches KI-System kann als Mikrowelt realisiert werden, beispielsweise Blöcke Welt. Die Mikrowelt stellt die reale Welt im Computerspeicher dar. Es wird mit Listen mit Symbolen beschrieben, und der intelligente Agent nutzt die Betreiber, um das System in einen neuen Zustand zu bringen. Das Produktionssystem ist die Software, die im Zustand Raum für die nächste Aktion des intelligenten Agenten sucht. Die Symbole zur Darstellung der Welt sind mit sensorischer Wahrnehmung geerdet. Im Gegensatz zu neuronalen Netzen arbeitet das Gesamtsystem mit Heuristiken zusammen, was bedeutet, dass Domain-spezifisches Wissen zur Verbesserung der Zustandsraumsuche genutzt wird. Erfolg mit Expertensystemen 1975-1990 Diese "Knowledge revolution" führte zur Entwicklung und Bereitstellung von Expertensystemen (von Edward Feigenbaum vorgestellt), der ersten wirklich erfolgreichen Form von AI-Software. Ein wesentlicher Bestandteil der Systemarchitektur für alle Expertensysteme ist die Wissensbasis, die Fakten und Regeln speichert, die KI illustrieren. Diese nutzen ein Netz von Produktionsregeln. Produktionsregeln verbinden Symbole in einer Beziehung ähnlich einer If-Then-Anweisung. Das Expertensystem verarbeitet die Regeln, um Abzüge zu machen und zu bestimmen, welche zusätzlichen Informationen es benötigt, d.h. welche Fragen zu stellen sind, indem es menschliche lesbare Symbole verwendet. Verlassen des symbolischen Ansatzes der 1990er Jahre Frühe Opposition Ein früher Kritiker der symbolischen KI war der Philosoph Hubert Dreyfus. Anfang der 1960er Jahre richtete die KI-Kritik Dreyfus die philosophischen Grundlagen des Feldes in einer Reihe von Papieren und Büchern an. Er prognostizierte, dass es nur für Spielzeugprobleme geeignet wäre, und dachte, dass es nicht möglich wäre, komplexere Systeme aufzubauen oder die Idee auf nützliche Software zu skalieren. Das gleiche Argument wurde im Bericht Lighthill gegeben, der Mitte der 1970er Jahre den KI Winter startete. Roboter Zu den Gegnern des symbolischen Ansatzes in den 1980er Jahren gehörten Robotikisten wie Rodney Brooks, die darauf abzielen, autonome Roboter ohne symbolische Darstellung (oder mit nur minimaler Darstellung) und computergestützte Intelligenz-Forscher zu produzieren, die Techniken wie neuronale Netzwerke anwenden und Optimierungen anwenden, um Probleme im Maschinen- und Steuerungstechnik zu lösen. Unsichere Argumentationssymbole können verwendet werden, wenn die Eingabe eindeutig ist und unter Sicherheit fällt. Aber wenn es Unsicherheiten gibt, beispielsweise bei der Formulierung von Vorhersagen, wird die Darstellung mit künstlichen neuronalen Netzwerken durchgeführt. In jüngster Zeit wurden strukturierte Anstrengungen unternommen, um die symbolischen und vernetzten KI-Ansätze unter dem Dach des neural-symbolischen Computing zu integrieren. Wie von Valiant und vielen anderen argumentiert, erfordert der effektive Aufbau von reichen rechnerischen kognitiven Modellen die Kombination von Klangsymbolik und effizienten (Maschine) Lernmodellen. Siehe auch Künstliche Intelligenz § erhebt Geschichte der künstlichen Intelligenz Physikalische Symbolsysteme Hypothese Homoiconicity Symbolische Berechnung Synthetische Intelligenz Anmerkungen Zitate Crevier, Daniel (1993,) AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0-465-02997-3.Dreyfus, Hubert L (1981). " Von der Mikrowelt bis zur Wissensdarstellung: KI bei einer Sackgasse" (PDF). Mind Design.MIT Presse, Cambridge, MA: 161–204.Artur S. d'Avila Garcez, Tarek R. Besold, Luc De Raedt, Peter Földiák, Pascal Hitzler, Thomas Icard, Kai-Uwe Kühnberger, Luís C. Lamb, Risto Miikkulainen, Daniel L. Silver.Neural-Symbolic Lernen und Denken: Beiträge und Herausforderungen. AAAI Spring Symposia 2015. Stanford: AAAI Press. CS1 maint: verwendet Autorenparameter (link) Haugeland, John (1985,) Künstliche Intelligenz: The Very Idea, Cambridge, Mass: MIT Press, ISBN 0-262-08153-9 Hayes-Roth, Frederick; Murray, William; Adelman, Leonard. "Expertensysteme". AccessScience.doi:10.1036/1097-8542.248550.Honavar, Vasant; Uhr, Leonard (1994). Symbolische Künstliche Intelligenz, Connectionist Networks & Beyond (Technischer Bericht). Iowa State University Digital Repository, Informatik Technische Berichte.76.p 6.Honavar, Vasant (1995). Symbolische künstliche Intelligenz und numerische künstliche neuronale Netzwerke: Gegen eine Auflösung der Dichotomie. Die Springer International Series In Engineering and Computer Science.Springer US.pp.351–388.doi:10.1007/978-0-585-29599-2_11.Howe, J. (November 1994). Archiviert aus dem Original am 15. Mai 2007. Erschienen am 30. August 2007.Kolata, G. (1982). " Wie können Computer gesund werden?".Science.217 (4566): 1237–1238.Bibcode:1982Sci...217.1237K doi:10.1126/science.217.4566.1237.PMID 17837639.Maker, Meg Houston (2006)."AI@50: AI Past, Present, Future". Dartmouth College. Archiviert vom Original am 3. Januar 2007. Retrieved 16. Oktober 2008.McCorduck, Pamela (2004,) Maschinen, die denken (2. ed,.) Natick, MA: A. K. Peters, Ltd., ISBN 1-56881-205-1.Russell, Stuart J.; Norvig, Peter (2003,) Künstliche Intelligenz: Ein moderner Ansatz (2. ed,.) Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2. Xifan Yao und Jiajun Zhou und Jiangming Zhang und Claudio R. Boer (2017). Von der intelligenten Fertigung bis zur intelligenten Fertigung für Industrie 4.0, die von der Künstlichen Intelligenz der nächsten Generation angetrieben wird, und weiter auf der 5. Internationalen Konferenz über Enterprise Systems (ES). IEEE.doi:10.1109/es.2017.58