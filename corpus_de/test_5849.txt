Mixed Reality (MR) ist die Zusammenführung von realen und virtuellen Welten, um neue Umgebungen und Visualisierungen zu erzeugen, in denen physische und digitale Objekte in Echtzeit koexistieren und interagieren. Mixed Reality findet nicht ausschließlich in der physischen Welt oder in der virtuellen Welt statt, sondern ist ein Hybrid aus Realität und virtueller Realität. Augmented Reality, ein verwandter Begriff, findet in der physischen Welt statt, wobei Informationen oder Objekte virtuell hinzugefügt werden. Es gibt viele praktische Anwendungen der gemischten Realität, einschließlich Design, Unterhaltung, militärische Ausbildung und Remote-Arbeit. Es gibt auch verschiedene Display-Technologien, die die Interaktion zwischen Benutzern und Mixed-Reality-Anwendungen erleichtern. Definition Virtualität/Medienkontinuum Die Mixed Reality wurde 1994 von Paul Milgram und Fumio Kishino als "jeweils zwischen dem Extrema des Virtuality-Kontinuums" (VC) definiert, wo sich das Virtuality-Kontinuum von der völlig realen bis in die vollständig virtuelle Umgebung erstreckt, wobei die Augmented Reality und Augmented Virtuality zwischen sich reichten. Das mediality continuum kann in einem Schweißhelm oder einer Brille implementiert werden, die Werbung blockieren oder Anzeigen mit nützlichen Informationen ersetzen kann. Dieses Mediated Reality Continuum steht als Grundlage für die Beschreibung, wie Objekte in den physischen und virtuellen Welten interagieren. Anstatt sich einfach auf Realität und Virtualität als zwei völlig getrennte Wesen zu verlassen, wurde angenommen, dass es ein Kontinuum zwischen diesen beiden Konzepten und Anwendungen der gemischten Realität irgendwo zwischen den beiden wohnen kann. Milgram und Kishino argumentierten in ihrem Papier, dass zuerst den Begriff gemischte Realität eingeführt wurde, dass ein solcher Begriff notwendig ist, um auf "eine bestimmte Unterklasse von VR-bezogenen Technologien zu verweisen, die die Verschmelzung von realen und virtuellen Welten beinhalten", eine Spezifikation, die zuvor kein Wort gegeben hatte. Unterschiede in der Terminologie Mische Realität bezieht sich auf alles in der Realität-Virtualität Kontinuum außer für Anwendungen auf den beiden Extremen. Dazu gehören virtuelle Realität (VR,) erweiterte Realität (AR,) und erweiterte Virtualität (AV). An einem Ende des Spektrums liegt die reale Welt ohne technologische Überlagerungen. Am anderen Ende des Spektrums liegt die virtuelle Realität, die sich auf "eine künstliche Umgebung bezieht, die durch sensorische Reize (wie SehenswÃ1⁄4rdigkeiten und Geräusche) eines Computers erfahren wird und in der seine Handlungen teilweise bestimmen, was in der Umgebung geschieht. " Augmented Reality liegt zwischen diesen beiden Punkten und bezieht sich auf "eine erweiterte Version der Realität, die durch den Einsatz von Technologie geschaffen wurde, um digitale Informationen über ein Bild von etwas zu überlagern, das durch ein Gerät betrachtet wird." Mixed Reality ist einzigartig, indem der Begriff in der Regel bezieht sich auf künstliche Produkte, die mit Benutzern in der realen Welt interagieren. Augmented Virtuality (AV) ist eine Unterkategorie gemischter Realität, die sich auf die Verschmelzung von realen Objekten in virtuelle Welten bezieht. Als Zwischenfall im Virtuality-Kontinuum bezeichnet es überwiegend virtuelle Räume, in denen physische Elemente (wie physische Objekte oder Menschen) in Echtzeit dynamisch in die virtuelle Welt integriert und interagieren können. Diese Integration wird durch die Verwendung verschiedener Techniken, wie das Streamen von Video aus physischen Räumen, wie durch eine Webcam, oder durch die 3D-Digitalisierung von physischen Objekten erreicht. Die Verwendung von realen Sensorinformationen, wie z.B. Gyroskope, zur Steuerung einer virtuellen Umgebung ist eine zusätzliche Form einer erweiterten Virtualität, in der externe Eingaben Kontext für die virtuelle Ansicht bieten. Interrealitätsphysik In einem physikalischen Kontext bezieht sich der Begriff "Interreality System" auf ein virtuelles Realitätssystem, das mit seinem realen Gegenstück gekoppelt ist. In einem Papier von 2007 wird ein Interrealitätssystem beschrieben, das ein echtes physisches Pendel, das mit einem Pendel gekoppelt ist, das nur in der virtuellen Realität existiert, umfasst. Dieses System weist zwei stabile Bewegungszustände auf: einen "Dual Reality"-Zustand, in dem die Bewegung der beiden Pendeln unkorreliert ist, und einen "Mixed Reality"-Zustand, in dem die Anhänger eine stabile phasenverriegelte Bewegung aufweisen, die stark korreliert ist. Die Verwendung der Begriffe "gemischte Realität" und Interrealität ist im Kontext der Physik klar definiert und kann in anderen Bereichen etwas anders sein, aber es wird allgemein als "überbrücken der physischen und virtuellen Welt" gesehen. Anwendungen Mixed Reality wurde in Anwendungen in allen Bereichen wie Design, Bildung, Unterhaltung, militärische Ausbildung und Gesundheitsversorgung verwendet. Design Durch den Einsatz der MR-Technologie kann die Geometrie von 3-dimensionalen Objekten visualisiert werden. Benutzer können auch mit dem virtuellen Modell durch Gesten und Sprachbefehle interagieren. MR kann Studenten oder Designern helfen, nicht nur das Design digitaler Modelle durch Visualisierung der 3-D-Geometrie zu verstehen, sondern auch Produktfunktionen, geometrische Beziehungen zu verstehen und ihre Kreativität zu kultivieren. Es kann vom Primar- bis zum Tertiärbereich angewendet werden. Bildung Simulationsbasiertes Lernen umfasst VR- und AR-basiertes Training und interaktives, experimentelles Lernen. Es gibt viele mögliche Anwendungsfälle für Mixed Reality sowohl in Bildungseinstellungen als auch in professionellen Trainingseinstellungen. Insbesondere in der Bildung wurde AR verwendet, um historische Schlachten zu simulieren, bietet eine unvergleichliche Immersive Erfahrung für Studenten und potenziell verbesserte Lernerfahrungen. Unterhaltung Von Fernsehsendungen bis zu Spielkonsolen, gemischte Realität hat viele Anwendungen im Bereich der Unterhaltung. Die britische Spielshow 2004 Bamzooki forderte Kinderanwärter auf, virtuelle Zooks zu schaffen und sie in einer Vielzahl von Herausforderungen zu konkurrieren. Die Show nutzte gemischte Realität, um die Zooks zum Leben zu bringen. Die Fernsehshow lief für eine Saison, Ende 2010. Die 2003 Spielshow FightBox forderte auch Teilnehmer, um Wettbewerbscharaktere zu schaffen und verwendet gemischte Realität, um sie zu interagieren. Im Gegensatz zu Bamzoomis allgemein gewaltfreien Herausforderungen war das Ziel von FightBox für neue Teilnehmer, den stärksten Kämpfer zu schaffen, um den Wettbewerb zu gewinnen. Im Jahr 2003 veröffentlichte PlayStation das EyeToy als Webcam-Accessoire für die PlayStation 2 Gaming-Konsole. Die EyeToy bot Computer Vision und Gestenerkennung Unterstützung für Spiele. Bis zum 6. November 2008 wurden weltweit 10,5 Millionen EyeToy-Einheiten verkauft. Das EyeToy wurde durch das PlayStation Eye 2007, dann die PlayStation Camera 2013, die in der PlayStation 4 und PlayStation 5 verwendet wird, erfolgreich abgeschlossen. Im Jahr 2009 präsentierten die Forscher dem Internationalen Symposium über gemischte und erweiterte Realität (ISMAR) ihr soziales Produkt namens BlogWall, das aus einem projizierten Bildschirm an einer Wand bestand. Benutzer können kurze Textclips oder Bilder an der Wand posten und einfache Spiele wie Pong spielen. Der BlogWall hat auch einen Lyrik-Modus vorgestellt, in dem er die empfangenen Nachrichten umstellen würde, um ein Gedicht und einen Umfrage-Modus zu bilden, in dem die Nutzer andere bitten könnten, ihre Umfragen zu beantworten. Das mobile Spiel 2016 Pokémon Go gab den Spielern eine Möglichkeit, den Pokémon, den sie in einem generischen 2-D-Hintergrund aufgetreten sind, zu sehen oder die gemischte Realitätsfunktion AR-Modus zu verwenden. Als der AR-Modus aktiviert wurde, wurden die Kamera und das Gyroskop des Mobilgerätes verwendet, um ein Bild des aufgetretenen Pokémons in der realen Welt zu erzeugen. Bis 13. Juli 2016 erreichte das Spiel 15 Millionen globale Downloads. Niantic, die Schöpfer von Mixed Reality Spiele Pokémon Go and Ingress, veröffentlichte ein neues Mixed Reality-Spiel im Juni 2019 namens Harry Potter: Wizards Unite. Das Gameplay war ähnlich wie bei Pokémon Go.Mario Kart Live: Home Circuit ist ein Mixed-Reality-Rennspiel für den Nintendo Switch, der im Oktober 2020 veröffentlicht wurde.[16a-New] Das Spiel ermöglicht es den Spielern, ihr Zuhause als Rennstrecke zu nutzen Innerhalb der ersten Woche der Veröffentlichung wurden 73,918 Exemplare in Japan verkauft, so dass es das meistverkaufte Spiel der Woche. Andere Untersuchungen haben das Potenzial für gemischte Realität untersucht, die auf Theater-, Film- und Themenparks angewendet werden kann. Militärausbildung Das erste voll immersive Mixed Reality System war die Virtual Fixtures Plattform, die 1992 von Louis Rosenberg an den Armstrong Laboratories der United States Air Force entwickelt wurde. Es ermöglichte den Anwendern, Roboter in realen Umgebungen zu steuern, die reale physische Objekte und 3D virtuelle Overlays (Fixtures) enthalten, die die menschliche Leistung von Manipulationsaufgaben verbessern. Die publizierten Studien zeigten, dass durch die Einführung virtueller Objekte in die reale Welt signifikante Leistungssteigerungen durch menschliche Bediener erreicht werden konnten. Combat-Reality kann mit komplexen, geschichteten Daten und visuellen Hilfsmitteln simuliert und dargestellt werden, von denen die meisten Head-mounted-Displays (HMD) sind, die jede Display-Technologie umfassen, die am Kopf des Benutzers getragen werden kann. Militärische Trainingslösungen werden oft auf kommerziellen Off-the-Shelf (COTS) Technologien wie Virtual Battlespace 3 und VirTra aufgebaut, die beide von der United States Army verwendet werden. Ab 2018 wird VirTra sowohl von zivilen als auch militärischen Strafverfolgungsbehörden genutzt, um Personal in einer Vielzahl von Szenarien zu trainieren, darunter aktive Schützen, häusliche Gewalt und militärische Verkehrsstopps. Mixed-Reality-Technologien wurden vom United States Army Research Laboratory verwendet, um zu untersuchen, wie dieser Stress die Entscheidungsfindung beeinflusst. Mit gemischter Realität können Forscher sicher Militärpersonal in Szenarien studieren, in denen Soldaten nicht wahrscheinlich überleben würden. Im Jahr 2017 entwickelte die US-Armee die Synthetic Training Environment (STE,) eine Sammlung von Technologien für Ausbildungszwecke, die eine gemischte Realität beinhalten sollen. Seit 2018 war STE noch in der Entwicklung ohne Projektabschluss. Einige aufgezeichnete Ziele von STE beinhalteten die Verbesserung des Realismus und die Steigerung der Simulations-Training Fähigkeiten und die Verfügbarkeit von STE an andere Systeme. Es wurde behauptet, dass Mischrealitätsumgebungen wie STE die Trainingskosten reduzieren könnten, wie etwa die Verringerung der Menge an Munition, die während des Trainings verbraucht wurde. 2018 wurde berichtet, dass STE die Repräsentation eines Teils des Geländes der Welt für Trainingszwecke beinhalten würde. STE würde eine Vielzahl von Trainingsmöglichkeiten für Teams von Mannschaften und Kämpfen bieten, darunter Stryker-, Rüstungs- und Infanterieteams. Remote Working Mixed Reality ermöglicht es einer globalen Belegschaft von Remote-Teams, gemeinsam zu arbeiten und die geschäftlichen Herausforderungen einer Organisation zu bewältigen. Egal wo sie sich physisch befinden, ein Mitarbeiter kann ein Headset und geräuschgebende Kopfhörer tragen und eine kollaborative, immersive virtuelle Umgebung eingeben. Da diese Anwendungen in Echtzeit genau übersetzen können, werden Sprachbarrieren irrelevant. Auch dieser Prozess erhöht die Flexibilität. Während viele Arbeitgeber noch unflexible Modelle der festen Arbeitszeit und des Standortes verwenden, gibt es Beweise, dass die Mitarbeiter produktiver sind, wenn sie eine größere Autonomie über wo, wann und wie sie arbeiten. Einige Mitarbeiter bevorzugen laute Arbeitsumgebungen, andere brauchen Stille. Einige arbeiten am besten am Morgen; andere arbeiten am besten in der Nacht. Die Mitarbeiter profitieren auch von der Autonomie, wie sie auf unterschiedliche Weise arbeiten. Das klassische Modell für Lernstile unterscheidet zwischen Visual, Auditory und Kinesthetic Lernenden. Die maschinelle Wartung kann auch mit Hilfe der gemischten Realität ausgeführt werden. Größere Unternehmen mit mehreren Fertigungsstandorten und viele Maschinen können gemischte Realität nutzen, um ihre Mitarbeiter zu erziehen und zu belehren. Die Maschinen benötigen regelmäßige Check-ups und müssen jetzt und dann angepasst werden. Diese Anpassungen werden meist vom Menschen vorgenommen, so dass die Mitarbeiter über notwendige Anpassungen informiert werden müssen. Durch den Einsatz von Mixed Reality können Mitarbeiter von mehreren Standorten Headsets tragen und Live-Anweisungen über die Änderungen erhalten. Instruktoren können die Darstellung, die jeder Mitarbeiter sieht, bedienen und durch den Produktionsbereich gleiten, technische Details einzoomen und jede Änderung erklären. Die Mitarbeiter, die eine Fünf-Minuten-Trainingssitzung mit einem solchen Mixed-Reality-Programm absolvieren, wurden gezeigt, um dieselben Lernergebnisse zu erzielen, wie ein 50-seitiges Trainingshandbuch zu lesen. Eine Erweiterung auf diese Umgebung ist die Einarbeitung von Live-Daten von Betriebsmaschinen in den virtuellen kollaborativen Raum und dann verbunden mit dreidimensionalen virtuellen Modellen der Ausrüstung. Dies ermöglicht die Schulung und Durchführung von Wartungs-, Betriebs- und Sicherheitsarbeitsprozessen, die sonst in einer Live-Situation schwierig sein würden, während der Einsatz von Know-how, unabhängig von ihrem physischen Standort. Functional Mockup Mixed Reality kann verwendet werden, um Mockups zu bauen, die physische und digitale Elemente kombinieren. Mit der gleichzeitigen Lokalisierung und Kartierung (SLAM) können Mockups mit der physischen Welt interagieren, um die Kontrolle von realistischeren sensorischen Erfahrungen wie Objektpermanenz zu gewinnen, die in der Regel unfehlbar oder extrem schwierig zu verfolgen und zu analysieren wäre, ohne die Verwendung von digitalen und physischen Hilfsmitteln. Bewußtsein Es ist hypothetisiert worden, dass ein Hybrid aus gemischter und virtueller Realität den Weg ebnen könnte, dass menschliches Bewusstsein vollständig in eine digitale Form überführt wird – ein Konzept, das als Virternität bekannt ist, das Blockchain nutzen würde, um seine Hauptplattform zu schaffen. Healthcare Smartglasses kann in den Operationssaal integriert werden, um in chirurgischen Eingriffen zu helfen; möglicherweise zeigt die Patientendaten bequem und überlagert präzise visuelle Anleitungen für den Operateur. Mixed-Reality-Headsets wie die Microsoft HoloLens ermöglichen einen effizienten Austausch von Informationen zwischen Ärzten, zusätzlich zu einer Plattform für ein verbessertes Training. Dies kann in einigen Situationen (d.h. Patienten, die mit ansteckenden Krankheiten infiziert sind) die Sicherheit des Arztes verbessern und den PPE-Einsatz reduzieren. Während gemischte Realität viel Potenzial zur Verbesserung der Gesundheitsversorgung hat, hat es auch einige Nachteile. Die Technologie wird sich in Szenarien nie vollständig integrieren, wenn ein Patient anwesend ist, da es ethische Bedenken um den Arzt gibt, den Patienten nicht sehen zu können. Produktinhaltsmanagement Produktinhaltsmanagement vor dem Aufkommen von Mixed Reality bestand weitgehend aus Broschüren und wenig Kunden-Produkt-Einbindung außerhalb dieses 2-dimensionalen Bereichs. Mit Mixed Reality-Technologien wurden neue Formen des interaktiven Produktinhaltsmanagements entwickelt. Vor allem die 3-dimensionalen digitalen Renderings von normalerweise 2-dimensionalen Produkten haben eine erhöhte Erreichbarkeit und Wirksamkeit der Verbraucher-Produkt-Interaktion. Display-Technologien Während Mixed Reality sich auf die Verflechtung der virtuellen Welt und der physischen Welt auf hohem Niveau bezieht, gibt es eine Vielzahl von digitalen Medien, die verwendet werden, um eine gemischte Realitätsumgebung zu erreichen. Sie können sich von Handgeräten bis hin zu ganzen Räumen erstrecken, die jeweils in unterschiedlichen Disziplinen praktische Anwendungen haben. Automatische virtuelle Umgebung speichern Die Cave Automatic Virtual Environment (CAVE) ist eine Umgebung, typischerweise ein kleiner Raum in einem größeren Außenraum, in dem ein Benutzer von projizierten Displays um sie herum umgeben ist, über ihnen und darunter.3D-Brillen und Surround-Sound ergänzen die Projektionen, um dem Benutzer eine Perspektive zu bieten, die die physische Welt simulieren soll. Seit der Entwicklung wurden CAVE-Systeme von Ingenieuren übernommen, die Prototypprodukte entwickeln und testen. Sie ermöglichen es den Produktdesignern, ihre Prototypen zu testen, bevor sie Ressourcen ausbreiten, um einen physikalischen Prototyp zu produzieren, während sie auch Türen für die manuelle Prüfung auf nicht immateriellen Objekten wie mikroskopische Umgebungen oder ganze Fabrikböden öffnen. Nach der Entwicklung des CAVE veröffentlichten die gleichen Forscher schließlich das CAVE2, das sich aus den Mängeln des ursprünglichen CAVEs erhebt. Die originellen Projektionen wurden für 37 Megapixel 3D LCD-Panels ersetzt, Netzwerkkabel integrieren das CAVE2 mit dem Internet, und ein genaueres Kamerasystem ermöglicht es der Umgebung zu verschieben, während der Benutzer sich in ihm bewegt. Head-up Display Head-up-Display (HUD), wie der Name schon sagt, ist ein Display, das in das Sichtfeld eines Benutzers projiziert wird, das ihnen zusätzliche Informationen liefert, ohne die Umgebung vor ihnen zu behindern oder sie dazu zu zwingen, wegzuschauen. Ein Standard-HUD besteht aus drei Elementen: einem Projektor, der für die Überlagerung der Grafiken des HUD, des Mähdreschers, der Oberfläche der Grafiken projiziert wird, und dem Computer, der die beiden anderen Komponenten integriert und alle Echtzeit-Berechnungen oder Anpassungen berechnet. Prototype HUDs wurden zuerst in militärischen Anwendungen verwendet, um Kampfpiloten im Kampf zu unterstützen, aber schließlich entwickelt, um in allen Aspekten des Fluges zu helfen - nicht nur Kampf. HUDs wurden dann auch in der gewerblichen Luftfahrt standardisiert und schließlich in die Automobilindustrie eingetaucht. Einer der ersten Anwendungen von HUD im Automobiltransport kam mit Pioneers Heads-up System, das die fahrerseitige Sonnenblende durch ein Display ersetzt, das Navigationsanweisungen auf die Straße vor dem Fahrer projiziert. Große Hersteller wie General Motors, Toyota, Audi und BMW haben seitdem einige Form von Head-up-Display in bestimmten Modellen enthalten. Headmounted Display Ein über den gesamten Kopf getragenes oder vor den Augen getragenes Head-Mount-Display (HMD) ist ein Gerät, das eine oder zwei Optiken verwendet, um ein Bild direkt vor den Augen des Benutzers zu projizieren. Seine Anwendungen reichen über Medizin, Unterhaltung, Luftfahrt und Engineering und bieten eine Schicht visueller Immersion, die traditionelle Displays nicht erreichen können. Head-mounted-Displays sind bei den Verbrauchern auf dem Entertainment-Markt am beliebtesten, mit großen Tech-Unternehmen, die HMDs entwickeln, um ihre bestehenden Produkte zu ergänzen. Diese Head-mounted-Displays sind jedoch virtuelle Realitätsanzeigen und integrieren die physische Welt nicht. Beliebte Augmented Reality HMDs sind jedoch in Unternehmensumgebungen günstiger. Microsofts HoloLens ist eine erweiterte Realität HMD, die Anwendungen in der Medizin hat, geben Ärzten mehr profunde Echtzeit-Einsicht, sowie Engineering, überlagern wichtige Informationen über die physische Welt. Eine weitere bemerkenswerte Augmented Reality HMD wurde von Magic Leap entwickelt, einem Startup, das ein ähnliches Produkt mit Anwendungen sowohl im privaten Sektor als auch im Verbrauchermarkt entwickelt. Mobile Devices Mobile Geräte, die in erster Linie Smartphones und Tablets umfassen, haben die Rechenleistung und Portabilität weiter erhöht. Während ursprünglich eine computergenerierte Schnittstelle auf einem LED-Bildschirm angezeigt wird, sind moderne Mobilgeräte mit einem Toolkit zur Entwicklung von Augmented Reality-Anwendungen ausgestattet. Diese Anwendungen ermöglichen Entwicklern, Computergrafiken über Videos der physischen Welt zu überlagern. Das erste mobile Realitätsspiel mit großem Erfolg war Pokémon GO, das 2016 veröffentlicht wurde und 800 Millionen Downloads akkumulierte. Während sich Unterhaltungsanwendungen mit AR bewährt haben, haben sich auch Produktivitäts- und Dienstprogramme mit der Integration von AR-Funktionen begonnen. Google hat Updates zu ihrer Google Maps-Anwendung veröffentlicht, die AR-Navigationsrichtungen enthalten, die vor dem Benutzer auf die Straßen überlagert werden, sowie ihre übersetzen App zu erweitern, um übersetzten Text auf physisches Schreiben in über 20 Fremdsprachen zu überlagern. Mobile Geräte sind einzigartige Display-Technologien, da sie häufig zu jeder Zeit ausgestattet sind. Siehe auch Referenzen Weiter lesen Signer, Beat & Curtin, Timothy J. (2017). Tangible Hologramme: Auf dem Weg zur mobilen physischen Verbesserung von virtuellen Objekten, Technical Report WISE Lab, WISE-2017-01, März 2017. Fleischmann, Monika; Strauss, Wolfgang (Hg.) (2001). Proceedings of "CAST01/Living in Mixed Realities" Intl.Conf.On Communication of Art, Science and Technology, Fraunhofer IMK 2001, 401.ISSN 1618-1379 (Print,) ISSN 1618-1387 (Internet). Interaktive Multimedia Laboratorien Ein Forschungslabor der National University of Singapore konzentriert sich auf multimodale Mixed Reality-Schnittstellen. Mixed Reality Geographical Information System (MRGIS) Costanza, E,. Kunz, A,. und Fjeld, M. 2009. Mixed Reality: A Survey Costanza, E,. Kunz, A,. und Fjeld, M. 2009. Mixed Reality: Eine Umfrage. In der Mensch-Maschine-Interaktion: Forschungsergebnisse des MMI-Programms, D. Lalanne und J. Kohlas (Hrsg.)LNCS 5440, S. 47–68.H Regenbrecht und C. Ott und M. Wagner und T. Lum und P. Kohler und W. Wilke und E. Mueller, An Augmented Virtuality Approach to 3D Videoconferencing, Proceedings of the 2. IEEE and ACM International Symposium on Mixed and Augmented Reality, S. 290-291, 2003 Kristian Simsarian und Karl-Petter Akesson, WindowsEin Beispiel für Augmented Virtuality, Interface Sixth International Conference Montpellier, Man-machine Interaktion, pp 68-71, 1997 Mixed Reality Project: experimentelle Anwendungen auf Mixed Reality (Augmented Reality, Augmented Virtuality) und Virtual Reality. Mixed Reality Scale – Milgram und Kishinos (1994)Virtualität Kontinuumparaphrase mit Beispielen. IEICE Transaktionen zu Informationssystemen, Vol E77-D, No.12 Dezember 1994 - Eine Taxonomie der visuellen Darstellungen der gemischten Realität - Paul Milgram, Fumio Kishino Externe Links Medien im Zusammenhang mit gemischter Realität bei Wikimedia Commons