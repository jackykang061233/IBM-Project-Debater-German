Das folgende ist ein Glossar der Begriffe, die in den mathematischen Wissenschaften Statistiken und Wahrscheinlichkeit verwendet werden. Eine zulässige Entscheidungsregel Algebra von zufälligen Variablen alternative Hypothese Analyse der Varianz atomares Ereignis Ein weiterer Name für elementares Ereignis B Bar Chart Bayes' Theorem Bayes Schätzelement Bayes Faktor Bayesian Inferenz Bias 1. Ein Merkmal einer Stichprobe, die nicht repräsentativ für die Bevölkerung 2 ist. Die Differenz zwischen dem erwarteten Wert eines Schätzers und den wahren Wert binäre Daten Daten, die nur zwei Werte annehmen können, in der Regel durch 0 und 1 binomiale Verteilung bivariate Analyse blockieren Box-Jenkins-Methodenfeld C Kausalstudie Eine statistische Studie, in der das Ziel ist, die Wirkung einiger Variablen auf das Ergebnis einer anderen Variablen zu messen. Zum Beispiel, wie wird mein Kopfschmerzen fühlen, wenn ich Aspirin nehme, versus wenn ich nicht Aspirin nehme? Causalstudien können entweder experimentell oder beobachtungsorientiert sein. Zentrale Grenze Theorem zentrale Moment charakteristische Funktion Chi-Quadrat-Verteilung Chi-Quadrat-Test-Cluster-Analyse Cluster-Processing-Ereignisse völlig randomisierte Design-Computational-Statistik-Betreiber Bei einer statistischen Studie handelt es sich um alle Variablen, deren Werte durch Behandlungen, wie Alter, Geschlecht und Cholesterinniveau, nicht beeinflusst werden, bevor eine Diät (Behandlung.) bedingte Verteilung Bei zwei gemeinsam verteilten Zufallsvariablen X und Y, ist die bedingte Wahrscheinlichkeitsverteilung von Y gegeben X (schriftlich "Y s X)" die Wahrscheinlichkeitsverteilung von Y, wenn X als eine bestimmte Wertbedingungswahrscheinlichkeitswahrscheinlichkeitswahrscheinlichkeitswahrscheinlichkeitswahrscheinlichkeitswahrscheinlichkeit Die Wahrscheinlichkeit eines Ereignisses A, vorausgesetzt Ereignis B. Die bedingte Wahrscheinlichkeit ist P(A|B) geschrieben und wird "die Wahrscheinlichkeit von A, gegeben B" bedingte Wahrscheinlichkeitsverteilungs-Vertrauensintervall gelesen Bei unfruchtbaren Statistiken ist ein CI eine Reihe von plausiblen Werten für einige Parameter, wie z.B. den Bevölkerungsanteil. Beispielsweise kann ein Forscher anhand einer Studie über Schlafgewohnheiten unter 100 Personen schätzen, dass die Gesamtbevölkerung irgendwo zwischen 5 und 9 Stunden pro Nacht schläft. Dies unterscheidet sich vom Probenmittel, das direkt gemessen werden kann. Vertrauensniveau Auch als Vertrauenskoeffizient bekannt, zeigt die Vertrauensstufe die Wahrscheinlichkeit an, dass das Vertrauensintervall (Bereich) die wahre Bevölkerungszahl erfasst. Zum Beispiel hat ein Vertrauensintervall mit einem 95-prozentigen Vertrauensniveau eine 95-prozentige Chance, die Bevölkerung zu erfassen. Technisch bedeutet dies, dass, wenn das Experiment mehrmals wiederholt wurde, 95 Prozent der CIs den wahren Bevölkerungsdurchschnitt enthalten würden. confounding conjugate vorherige kontinuierliche variable Bequemlichkeit Probenahme Korrelation Auch Korrelationskoeffizient genannt, ein numerisches Maß für die Stärke der linearen Beziehung zwischen zwei zufälligen Variablen (man kann es verwenden, um beispielsweise zu quantifizieren, wie Schuhgröße und -höhe in der Population korreliert sind). Ein Beispiel ist der Pearson Produkt-Moment-Korrelationskoeffizient, der durch Division der Kovarianz der beiden Variablen durch das Produkt ihrer Standardabweichungen gefunden wird. Unabhängige Variablen haben eine Korrelation von 0.A Bevölkerungskorrelation wird oft durch das Symbol ρ {\displaystyle \rho } repräsentiert, während eine Probenkorrelation durch r {\displaystyle r} . Zähldaten aus Zählung, die nur nicht-negative Ganzzahlwerte Kovarianz annehmen können Bei zwei zufälligen Variablen X und Y mit erwarteten Werten E (X) = μ {\displaystyle E(X)=\mu } und E ( Y) = ν {\displaystyle E(Y)=\nu } wird die Kovarianz als erwarteter Wert zufälliger Variable (X - μ ) (Y - ν ) {\displaystyle (X-opernu) definiert Es wird zur Messung der Korrelation verwendet. D Datendaten-Analysedatensatz A Probe und der zugehörige Datenpunkte-Datenpunkt A Typierte Messung - es kann ein Boolean-Wert, eine reale Zahl, ein Vektor (in diesem Fall auch als Datenvektor bezeichnet) etc Entscheidungs-Regel-Entscheidungs-Theorie Grade der Freiheitsdichte-Schätzung abhängige variable beschreibende Statistik-Design von Experimenten Abweichung diskrete Variablen-Dot-Doppelzählung E-ElementarereignisEin Ereignis mit nur einem Element. Zum Beispiel ist beim Ziehen einer Karte aus einem Deck ein elementares Ereignis, während "Gerade eines Königs oder eines Ass" keine Schätztheorie-Schätzvorrichtung ist. Eine Funktion der bekannten Daten, die zur Schätzung eines unbekannten Parameters verwendet wird; eine Schätzung ist das Ergebnis aus der tatsächlichen Anwendung der Funktion auf einen bestimmten Datensatz. Der Mittelwert kann als Schätzwert herangezogen werden Die Summe der Wahrscheinlichkeit jedes möglichen Ergebnisses des Experiments multipliziert mit seiner Auszahlung (Wert"). So stellt er den durchschnittlichen Betrag dar, den man pro Wette gewinnt, wenn Wetten mit identischen Quoten oft wiederholt werden. Beispielsweise beträgt der Erwartungswert einer sechsseitigen Stanzwalze 3,5. Das Konzept ist dem Mittelwert ähnlich. Der erwartete Wert der Zufallsgröße X wird typischerweise E(X) für den Bediener und μ {\displaystyle \mu } (mu) für den Parameter geschrieben. Experiment Jedes Verfahren, das unendlich wiederholt werden kann und eine gut definierte Reihe von Ergebnissen exponentielle Familienereignis Eine Teilmenge des Probenraums (ein mögliches Experiment-Ergebnis), dem eine Wahrscheinlichkeit zugeordnet werden kann. Zum Beispiel beim Walzen einer Matrize ist "Ziegen einer fünf oder einer sechs" ein Ereignis (mit einer Wahrscheinlichkeit von einem Drittel, wenn die Matrize fair ist) F-Faktor-Analyse Faktor-Experiment-Frequenzverteilung Frequenz-Domänen-G allgemeine lineare Modell generalisierte lineare Modell gruppierte Daten H Histogramm I Independence (Probability-Theorie) unabhängige variable interquartile-Bereich J-Verteilung Bei zwei Zufalls-Verteilung Bei zwei zufälligen X und Y-Verteilung Die Wahrscheinlichkeit zweier gemeinsamer Ereignisse. Die gemeinsame Wahrscheinlichkeit von A und B ist geschrieben P (A С B ) {\displaystyle P(A\cap B}) oder P (A, B ) . Ein Maß für die selten extremen Beobachtungen (Ausreißer) der Wahrscheinlichkeitsverteilung einer real bewerteten Zufallsgröße. Höhere Kurtose bedeutet mehr der Varianz ist auf selten extreme Abweichungen zurückzuführen, im Gegensatz zu häufig bescheidenen Abweichungen L L L-Moment Gesetz von großen Zahlen Wahrscheinlichkeit Funktion Eine bedingte Wahrscheinlichkeit Funktion als Funktion seines zweiten Arguments mit seinem ersten Argument fest gehalten. Stellen Sie sich zum Beispiel vor, eine nummerierte Kugel mit der Zahl k aus einem Beutel von n Kugeln, nummeriert 1 bis n zu ziehen. Dann könnte man eine Wahrscheinlichkeitsfunktion für die Zufallsvariable N beschreiben, da die Wahrscheinlichkeit k gegeben wird, dass es n Kugeln gibt: die Wahrscheinlichkeit wird 1/n für n größer oder gleich k sein, und 0 für n kleiner als k. Im Gegensatz zu einer Wahrscheinlichkeitsverteilungsfunktion wird diese Wahrscheinlichkeitsfunktion nicht bis zu 1 auf der Probenraumverlustfunktion Wahrscheinlichkeits-Verhältnis-Test M M-Estimator Randverteilung Bei zwei gemeinsam verteilten Zufallsvariablen X und Y ist die Randverteilung von X einfach die Wahrscheinlichkeitsverteilung von X, die Informationen über Y Randwahrscheinlichkeit marginale Wahrscheinlichkeit ignoriert Die Wahrscheinlichkeit eines Ereignisses, ignorieren alle Informationen über andere Ereignisse. Die Randwahrscheinlichkeit von A ist P(A) geschrieben. Im Gegensatz zu bedingter Wahrscheinlichkeit Markov Kette Monte Carlo mathematische Statistiken maximale Wahrscheinlichkeit Schätzung bedeuten ANHANG Der Erwartungswert einer Zufallsgröße 2. Das arithmetische Mittel ist der Durchschnitt einer Anzahl von Zahlen, oder die Summe der Werte geteilt durch die Anzahl der Werte median median absolute Abweichung Modus bewegt mittlere multimodale Verteilung multivariate Analyse multivariate Kerneldichte Schätzung multivariate zufällige Variable Ein Vektor, dessen Komponenten zufällige Variablen auf dem gleichen Wahrscheinlichkeitsraum sind gegenseitige Exklusivität gegenseitige Unabhängigkeit Eine Sammlung von Ereignissen ist unabhängig, wenn für jede Teilmenge der Sammlung die gemeinsame Wahrscheinlichkeit aller auftretenden Ereignisse gleich dem Produkt der gemeinsamen Wahrscheinlichkeiten der einzelnen Ereignisse ist. Denken Sie an das Ergebnis einer Serie von Münzflips. Dies ist eine stärkere Bedingung als die gegenseitige Unabhängigkeit N nichtparametrische Regression nichtparametrische Statistiken Nicht-Sampling-Fehler normale Verteilung normaler Wahrscheinlichkeitsdiagramm null Hypothese Die Aussage wird in einem Test von statistischer Bedeutung geprüft Üblicherweise ist die Nullhypothese eine Aussage von "kein Effekt" oder "kein Unterschied"." Wenn man beispielsweise testen wollte, ob Licht einen Einfluss auf den Schlaf hat, wäre die Nullhypothese, dass es keinen Effekt gibt. Es wird oft als H0 symbolisiert. O Meinungsumfrage optimale Entscheidung optimales Design Outlier P p p-Wert paarweise Unabhängigkeit Eine paarweise unabhängige Sammlung von Zufallsvariablen ist ein Satz von Zufallsvariablen, von denen zwei unabhängig sind Kann ein Populationsparameter, ein Verteilungsparameter, ein nicht beobachteter Parameter (mit unterschiedlichen Bedeutungstönen) sein. In der Statistik ist dies oft eine zu schätzende Menge Partikelfilter prozentile Pie Chart Punkt Schätzleistung vor Wahrscheinlichkeit In der Bayesischen Inferenz stellt dies vorausgehende Überzeugungen oder andere Informationen dar, die vor neuen Daten oder Beobachtungen verfügbar sind. Siehe Parameter posterior Wahrscheinlichkeit Das Ergebnis einer Bayesischen Analyse, die die Kombination von vorherigen Überzeugungen oder Informationen mit beobachteten Daten Hauptkomponentenanalyse Wahrscheinlichkeitsdichte verkapselt Beschreibt die Wahrscheinlichkeit in einer kontinuierlichen Wahrscheinlichkeitsverteilung. Zum Beispiel, Sie können nicht sagen, dass die Wahrscheinlichkeit eines Mannes, der sechs Fuß groß ist 20,%, aber Sie können sagen, er hat 20% der Chancen, zwischen fünf und sechs Fuß groß zu sein. Die Wahrscheinlichkeitsdichte wird durch eine Wahrscheinlichkeitsdichtefunktion gegeben. Entgegen der Wahrscheinlichkeit Massenwahrscheinlichkeitsdichte Funktion Gibt die Wahrscheinlichkeitsverteilung für eine kontinuierliche Zufallsvariablenwahrscheinlichkeitsverteilung A-Funktion an, die die Wahrscheinlichkeit aller Elemente in einem bestimmten Raum gibt: siehe Liste der Wahrscheinlichkeitsverteilungen Wahrscheinlichkeitsmaß Die Wahrscheinlichkeit von Ereignissen in einem Wahrscheinlichkeitsraum Wahrscheinlichkeitsraum Ein Stichprobenraum, über den eine Wahrscheinlichkeitsmaßnahme definiert wurde Q quantile quartile Quote Probenahme R Zufallsgröße A messbare Funktion auf einem Wahrscheinlichkeitsraum, oft echtwertig. Die Verteilungsfunktion einer Zufallsgröße gibt die Wahrscheinlichkeit unterschiedlicher Ergebnisse. Wir können auch den Mittelwert und die Varianz eines zufällig variablen randomisierten Blockdesign-Bereichs ableiten. Die Länge des kleinsten Intervalls, das alle Daten rekursive Bayesian Schätz-Regressions-Analyse wiederholt Maßnahmen Design-Antworten enthält In einer statistischen Studie können alle Variablen, deren Werte von den Behandlungen betroffen sein können, wie Cholesterinspiegel nach einer bestimmten Ernährung für sechs Monate. eingeschränkte randomization robuste Statistik Rund-off-Fehler S-Probe Der Teil einer Bevölkerung, der tatsächlich beobachtet wird. Das arithmetische Mittel einer aus der Bevölkerung gezogenen Werteprobe. Es wird mit x ̄ {\displaystyle {\overline {x} bezeichnet.Ein Beispiel ist die durchschnittliche Testnote einer Untermenge von 10 Schülern aus einer Klasse. Probenmittel wird als Schätzer der Bevölkerung verwendet, die in diesem Beispiel die durchschnittliche Testnote aller Schüler in der Klasse wäre. Probenraum Die Menge der möglichen Ergebnisse eines Experiments. Beispielsweise wird der Probenraum zum Walzen einer sechsseitigen Matrize die Probenahme {1, 2, 3, 4, 5, 6} betragen. Es gibt viele Methoden zu wählen, auf welchen Probe die Beobachtungen Probenahme Bias Probenahme Verteilung Die Wahrscheinlichkeitsverteilung, unter wiederholter Beprobung der Population, einer bestimmten statistischen Abtastfehler-Streuungs-Streuungs-Streuungs-Skala-Parameter-Bedeutungsebene einfache zufällige Probe Simpsons Paradox-Skewness Ein Maß für die Asymmetrie der Wahrscheinlichkeitsverteilung einer real bewerteten Zufallsgröße. Grob gesprochen, eine Verteilung hat positives skew (rechts-skewed), wenn der höhere Schwanz länger ist und negative skew (links-skewed), wenn der untere Schwanz länger ist (die beiden ist ein gemeinsamer Fehler) Spaghetti-Plot-Spektrum-Bias Standardabweichung Das am häufigsten verwendete Maß für statistische Dispersion. Es ist die quadratische Wurzel der Varianz, und ist in der Regel geschrieben σ {\displaystyle \sigma } (sigma) Standardfehler Standard Score Statistik Das Ergebnis der Anwendung eines statistischen Algorithmus auf einen Datensatz. Es kann auch als eine beobachtbare statistische Variable statistische Dispersion statistische Grafiken statistische Hypothese Prüfung der statistischen Unabhängigkeit Zwei Ereignisse sind unabhängig, wenn das Ergebnis des einen nicht das der anderen beeinflussen (z.B. das Erhalten eines 1 auf einer einzigen Walze beeinträchtigt nicht die Wahrscheinlichkeit, ein 1 auf einer zweiten Walze zu erhalten).In ähnlicher Weise, wenn wir behaupten, dass zwei zufällige Variablen unabhängig sind, bedeuten wir intuitiv, dass das Wissen über den Wert eines von ihnen keine Informationen über den Wert der anderen statistischen Inferenz über eine Population aus einer daraus gezogenen Zufallsstichprobe oder allgemein über einen zufälligen Prozess aus ihrem beobachteten Verhalten während einer endlichen Periode der statistischen Interferenz statistisches Modell statistische Bevölkerung A Satz von Einheiten, über die statistische Inferenzen gezogen werden sollen, ofts. Die statistische Variabilität ist ein Maß dafür, wie vielfältig einige Daten sind. Es kann durch die Varianz oder den Standardabweichung statistischen Parameter A-Parameter ausgedrückt werden, der eine Familie von Wahrscheinlichkeitsverteilungen statistische Signifikanzstatistik Index der t-Test-Stamm-und-Blatt-Display sektifizierte Stichprobenerhebung Methodik Überlebensfunktion Survivorship-Bias symmetrische Wahrscheinlichkeitsverteilung systematische Probenahme T-Test Statistikzeit-Domänen-Zeitreihen-Analysezeitreihen-Analysezeit-Behandlungen Variablen in einer statistischen Studie, die konzeptuell manipulierbar sind. Zum Beispiel ist in einer Gesundheitsstudie nach einer bestimmten Ernährung eine Behandlung, während das Alter nicht ist. Verfahren Kann sich auf jede einzelne Wiederholung beziehen, wenn man über ein Experiment spricht, das aus einer beliebigen festen Anzahl von ihnen besteht. Als Beispiel kann man an ein Experiment denken, das eine beliebige Zahl von einem bis n Münztönen, sagen 17. In diesem Fall kann man einen Toss als Versuch bezeichnen, um Verwirrung zu vermeiden, da das ganze Experiment aus 17 besteht. getrimmte Schätzer Typ I und Typ II Fehler U unimodale Wahrscheinlichkeit Verteilung Einheiten In einer statistischen Studie werden die Objekte, denen Behandlungen zugeordnet werden. In einer Studie, die die Auswirkungen des Rauchens von Zigaretten untersucht, wären die Einheiten zum Beispiel Menschen. V-Variable Ein Maß für seine statistische Streuung einer Zufallsgröße, die angibt, wie weit vom erwarteten Wert seine Werte typischerweise sind. Die Varianz der Zufallsvariablen X wird in der Regel als var ξ (X ) {\displaystyle \operatorname {var} (X}) σ X 2 {\displaystyle \sigma _X}^{2 , oder einfach σ 2 {\displaystyle \s ^2} W gewichtete arithmetische Kontinuität