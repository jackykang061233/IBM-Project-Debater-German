Natürliche Evolutionsstrategien (NES) sind eine Familie von numerischen Optimierungsalgorithmen für schwarze Box Probleme. Ähnlich wie bei Evolutionsstrategien, aktualisieren sie iterativ die (kontinuierlichen) Parameter einer Suchverteilung, indem sie dem natürlichen Gradienten zu einer höheren erwarteten Fitness folgen. Methode Die allgemeine Vorgehensweise ist wie folgt: Die parametrierte Suchverteilung dient zur Erzeugung einer Charge von Suchpunkten und die Fitnessfunktion wird an jeder Stelle ausgewertet. Die Parameter der Verteilung (die Strategieparameter enthalten) ermöglichen es dem Algorithmus, die (lokale) Struktur der Fitness-Funktion adaptiv zu erfassen. Dies umfasst beispielsweise bei einer Gaussschen Verteilung das Mittel und die Kovarianzmatrix. Aus den Proben schätzt NES einen Suchgradienten auf den Parametern hin zu einer höheren erwarteten Fitness. NES führt dann einen Gradienten-Ascent-Schritt entlang des natürlichen Gradienten durch, eine zweite Ordnungsmethode, die im Gegensatz zum einfachen Gradienten das Update w.r.t.uncertainty wieder normalisiert. Dieser Schritt ist entscheidend, da er Schwingungen, vorzeitige Konvergenz und unerwünschte Effekte aus einer gegebenen Parametrierung verhindert. Der gesamte Prozess wiederholt sich, bis ein Stoppkriterium erfüllt ist. Alle Mitglieder der NES-Familie arbeiten nach denselben Grundsätzen. Sie unterscheiden sich in der Art der Wahrscheinlichkeitsverteilung und der verwendeten Gradienten-Annäherungsmethode. Unterschiedliche Suchräume erfordern unterschiedliche Suchverteilungen; z.B. in geringer Dimensionalität kann es sehr vorteilhaft sein, die volle Kovarianzmatrix zu modellieren. Bei hohen Abmessungen hingegen ist eine skalierbare Alternative die Kovarianz nur auf die Diagonale zu beschränken. Darüber hinaus können hoch multimodale Suchplätze von schwereren Distributionen (wie Cauchy, im Gegensatz zum Gaussian) profitieren. Eine letzte Unterscheidung ergibt sich zwischen den Verteilungen, in denen wir den natürlichen Gradienten analytisch berechnen können, und den allgemeinen Verteilungen, in denen wir ihn von den Proben abschätzen müssen. Suchgradienten suchen Lassen Sie θ {\displaystyle \theta } die Parameter der Suchverteilung π ( x | θ ) {\displaystyle \pi (x\,\\,\theta )} und f ( x ) {\displaystyle f(x}) die Fitness-Funktion bei x {\displaystyle x} ausgewertet. NES verfolgt dann das Ziel, die erwartete Fitness unter der Suchverteilung J ( θ ) = E θ ‡ [ f ( x ) ] = δ f ( x ) π ( x | θ θ ) d x {\displaystyle J(\theta =)\operatorname {E} {f(x)]=\int f(x)\)\; Der Gradient kann als MENT Θ J (θ ) = ξ θ δ σ σ δ π ( x ) π ( x ∫ ∫ θ ) d x δ σ σ π σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ σ(x) mal die log-Derivate bei x {\displaystyle x} . In der Praxis ist es möglich, die Monte Carlo Approximation basierend auf einer endlichen Anzahl von λ {\displaystyle \lambda }-Proben ‡ J (θ ) ≈ 1 λ Σ k = 1 λ f ( x k ) }\log \pi (x_{k}\,\\,\theta } .Endlich können die Parameter der Suchverteilung iterativ aktualisiert werden θ ← θ + η MENT θ ( θ ) {\displaystyle \theta \leftarrow \theta \+eta \nabla {\_theta } Natürlicher Gradientenanstieg Anstelle der einfachen stochastischen Gradienten für Updates folgt NES dem natürlichen Gradienten, der gezeigt hat, dass zahlreiche Vorteile gegenüber dem einfachen (Vanille) Gradienten zu haben, z.B.: die Gradientenrichtung ist unabhängig von der Parametrierung der Suchverteilung, die Aktualisierungsgrößen werden automatisch auf Ungewissheit eingestellt, wiederum Geschwindigkeitskonvergenz auf Plateaus und Grat. Das NES-Update ist daher θ + η F - 1 MENT θ J ( θ ) {\displaystyle \theta \leftarrow \theta \+eta \mathbf {F} {-^1}\nabla {\_theta }J(\theta )},wo F {\displaystyle \mathbf {F} } die Fisher ist. Die Fisher-Matrix kann manchmal genau berechnet werden, andernfalls wird sie aus Proben geschätzt, wobei die log-Derivate ‡ log ‡ π ( x θ θ ) wieder verwendet werden {\displaystyle \nabla {\_theta }\log \pi (x|\theta )} . Die Fitness-Formgebung NES nutzt rangbasierte Fitness-Formgebung, um den Algorithmus robuster zu machen, und invariant unter monoton steigenden Transformationen der Fitness-Funktion. Zu diesem Zweck wird die Fitness der Bevölkerung in eine Reihe von Werten u 1 ≥ ⋯ ≥ u λ {\displaystyle u_{1}\geq \dots \geq u_{\lambda } umgewandelt.Lassen Sie x i {\displaystyle x_{i} den besten Individuum bezeichnen. Die Gradientenschätzung wird mit Gebrauchstauglichkeit wieder ‡ J (θ ) = Σ k = 1 λ u k Д θ log ‡ π ( x k | θ θ ) {\displaystyle \nabla {\_theta }J(\theta =)\sum _k=1}^{\lambda u_{k}\;\nabla {\_theta }\log \pi (x_{k}\,\\theta }} .Die Auswahl der Dienstfunktion ist ein freier Parameter des Algorithmus. Pseudocode-Eingang: f, θ i n i t {\displaystyle f,\;\;\theta {_init} 1 Wiederholung 2 für k = 1 ... λ {\displaystyle k=1\ldots \lambda } do // λ ist die Populationsgröße 3 Ziehprobe x k ≠ π ( ∙ θ θ θ ) {\displaystyle x_{k}\sim\pi(\cdot |\theta } 4 Bewertung der Fitness f ( x k ) {\displaystyle f(x_{k}) 5 Berechnung der Log-Derivate 😉 log ‡ π ( x k | θ θ ) {\displaystyle \nabla {\_theta }\log \pi (x_{k}\theta } 6 Ende 7 die Dienstprogramme u k {\displaystyle u_{k} // basierend auf Rang 8 schätzen den Gradienten 😉 1 λ u k Ð Ð log π ( x k | θ ) {\displaystyle \nabla} *J\leftarrow {\frac 1}{\lambda }\sum _k=1{\lambda ) 9 Schätzwert F ← 1 λ Σ k = 1 λ κ κ θ log π ( x k | θ θ θ Θ ) κ κ κ κ π ( x k | ) θ ) ) ) ) ⊤ ⊤ ⊤ ⊤ ⊤ ⊤ ⊤ ⊤ ⊤ ⊤ {\displaystyle \mathbf ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nabla \\_theta }\log \pi (x_{k}the\theta )\nabla {\_theta }\log \pi (x_{k}\theta {\c}}\\c\c\c\c\\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c{\displaystyle \theta \leftarrow \theta \+eta \cdot \mathbf (F) η ist die Lernrate 11 bis zur Beendigung des Kriteriums Siehe auch Evolutionäre Berechnung Kovarianz-Matrix-Adaption Evolutionsstrategie (CMA-ES) Bibliographie D. Wierstra, T. Schaul, J. Peters und J. Schmidhuber (2008). Natürliche Evolutionsstrategien.IEEE Kongress zur Evolutionskommission (CEC). Y Sun, D. Wierstra, T. Schaul und J. Schmidhuber (2009). Stochastic Search mit dem natürlichen Gradienten. Internationale Konferenz zum maschinellen Lernen (ICML). T Glasmachers, T. Schaul, Y. Sun, D. Wierstra und J. Schmidhuber (2010). Offene natürliche Evolutionsstrategien. Genetische und evolutionäre Computation Conference (GECCO). T Schaul, T. Glasmachers und J. Schmidhuber (2011). Hohe Abmessungen und schwere Tails für natürliche Evolutionsstrategien. Genetische und evolutionäre Computation Conference (GECCO).T Schaul (2012). Natürliche Evolution Strategien Konvergieren auf Sphere Funktionen. Genetische und evolutionäre Computation Conference (GECCO.) Externe Links Sammlung von NES-Implementierungen in verschiedenen Sprachen