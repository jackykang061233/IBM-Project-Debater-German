NatÃ¼rliche Evolutionsstrategien (NES) sind eine Familie von numerischen Optimierungsalgorithmen fÃ¼r schwarze Box Probleme. Ã„hnlich wie bei Evolutionsstrategien, aktualisieren sie iterativ die (kontinuierlichen) Parameter einer Suchverteilung, indem sie dem natÃ¼rlichen Gradienten zu einer hÃ¶heren erwarteten Fitness folgen. Methode Die allgemeine Vorgehensweise ist wie folgt: Die parametrierte Suchverteilung dient zur Erzeugung einer Charge von Suchpunkten und die Fitnessfunktion wird an jeder Stelle ausgewertet. Die Parameter der Verteilung (die Strategieparameter enthalten) ermÃ¶glichen es dem Algorithmus, die (lokale) Struktur der Fitness-Funktion adaptiv zu erfassen. Dies umfasst beispielsweise bei einer Gaussschen Verteilung das Mittel und die Kovarianzmatrix. Aus den Proben schÃ¤tzt NES einen Suchgradienten auf den Parametern hin zu einer hÃ¶heren erwarteten Fitness. NES fÃ¼hrt dann einen Gradienten-Ascent-Schritt entlang des natÃ¼rlichen Gradienten durch, eine zweite Ordnungsmethode, die im Gegensatz zum einfachen Gradienten das Update w.r.t.uncertainty wieder normalisiert. Dieser Schritt ist entscheidend, da er Schwingungen, vorzeitige Konvergenz und unerwÃ¼nschte Effekte aus einer gegebenen Parametrierung verhindert. Der gesamte Prozess wiederholt sich, bis ein Stoppkriterium erfÃ¼llt ist. Alle Mitglieder der NES-Familie arbeiten nach denselben GrundsÃ¤tzen. Sie unterscheiden sich in der Art der Wahrscheinlichkeitsverteilung und der verwendeten Gradienten-AnnÃ¤herungsmethode. Unterschiedliche SuchrÃ¤ume erfordern unterschiedliche Suchverteilungen; z.B. in geringer DimensionalitÃ¤t kann es sehr vorteilhaft sein, die volle Kovarianzmatrix zu modellieren. Bei hohen Abmessungen hingegen ist eine skalierbare Alternative die Kovarianz nur auf die Diagonale zu beschrÃ¤nken. DarÃ¼ber hinaus kÃ¶nnen hoch multimodale SuchplÃ¤tze von schwereren Distributionen (wie Cauchy, im Gegensatz zum Gaussian) profitieren. Eine letzte Unterscheidung ergibt sich zwischen den Verteilungen, in denen wir den natÃ¼rlichen Gradienten analytisch berechnen kÃ¶nnen, und den allgemeinen Verteilungen, in denen wir ihn von den Proben abschÃ¤tzen mÃ¼ssen. Suchgradienten suchen Lassen Sie Î¸ {\displaystyle \theta } die Parameter der Suchverteilung Ï€ ( x | Î¸ ) {\displaystyle \pi (x\,\\,\theta )} und f ( x ) {\displaystyle f(x}) die Fitness-Funktion bei x {\displaystyle x} ausgewertet. NES verfolgt dann das Ziel, die erwartete Fitness unter der Suchverteilung J ( Î¸ ) = E Î¸ â€¡ [ f ( x ) ] = Î´ f ( x ) Ï€ ( x | Î¸ Î¸ ) d x {\displaystyle J(\theta =)\operatorname {E} {f(x)]=\int f(x)\)\; Der Gradient kann als MENT Î˜ J (Î¸ ) = Î¾ Î¸ Î´ Ïƒ Ïƒ Î´ Ï€ ( x ) Ï€ ( x âˆ« âˆ« Î¸ ) d x Î´ Ïƒ Ïƒ Ï€ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ Ïƒ(x) mal die log-Derivate bei x {\displaystyle x} . In der Praxis ist es mÃ¶glich, die Monte Carlo Approximation basierend auf einer endlichen Anzahl von Î» {\displaystyle \lambda }-Proben â€¡ J (Î¸ ) â‰ˆ 1 Î» Î£ k = 1 Î» f ( x k ) }\log \pi (x_{k}\,\\,\theta } .Endlich kÃ¶nnen die Parameter der Suchverteilung iterativ aktualisiert werden Î¸ â† Î¸ + Î· MENT Î¸ ( Î¸ ) {\displaystyle \theta \leftarrow \theta \+eta \nabla {\_theta } NatÃ¼rlicher Gradientenanstieg Anstelle der einfachen stochastischen Gradienten fÃ¼r Updates folgt NES dem natÃ¼rlichen Gradienten, der gezeigt hat, dass zahlreiche Vorteile gegenÃ¼ber dem einfachen (Vanille) Gradienten zu haben, z.B.: die Gradientenrichtung ist unabhÃ¤ngig von der Parametrierung der Suchverteilung, die AktualisierungsgrÃ¶ÃŸen werden automatisch auf Ungewissheit eingestellt, wiederum Geschwindigkeitskonvergenz auf Plateaus und Grat. Das NES-Update ist daher Î¸ + Î· F - 1 MENT Î¸ J ( Î¸ ) {\displaystyle \theta \leftarrow \theta \+eta \mathbf {F} {-^1}\nabla {\_theta }J(\theta )},wo F {\displaystyle \mathbf {F} } die Fisher ist. Die Fisher-Matrix kann manchmal genau berechnet werden, andernfalls wird sie aus Proben geschÃ¤tzt, wobei die log-Derivate â€¡ log â€¡ Ï€ ( x Î¸ Î¸ ) wieder verwendet werden {\displaystyle \nabla {\_theta }\log \pi (x|\theta )} . Die Fitness-Formgebung NES nutzt rangbasierte Fitness-Formgebung, um den Algorithmus robuster zu machen, und invariant unter monoton steigenden Transformationen der Fitness-Funktion. Zu diesem Zweck wird die Fitness der BevÃ¶lkerung in eine Reihe von Werten u 1 â‰¥ â‹¯ â‰¥ u Î» {\displaystyle u_{1}\geq \dots \geq u_{\lambda } umgewandelt.Lassen Sie x i {\displaystyle x_{i} den besten Individuum bezeichnen. Die GradientenschÃ¤tzung wird mit Gebrauchstauglichkeit wieder â€¡ J (Î¸ ) = Î£ k = 1 Î» u k Ğ” Î¸ log â€¡ Ï€ ( x k | Î¸ Î¸ ) {\displaystyle \nabla {\_theta }J(\theta =)\sum _k=1}^{\lambda u_{k}\;\nabla {\_theta }\log \pi (x_{k}\,\\theta }} .Die Auswahl der Dienstfunktion ist ein freier Parameter des Algorithmus. Pseudocode-Eingang: f, Î¸ i n i t {\displaystyle f,\;\;\theta {_init} 1 Wiederholung 2 fÃ¼r k = 1 ... Î» {\displaystyle k=1\ldots \lambda } do // Î» ist die PopulationsgrÃ¶ÃŸe 3 Ziehprobe x k â‰  Ï€ ( âˆ™ Î¸ Î¸ Î¸ ) {\displaystyle x_{k}\sim\pi(\cdot |\theta } 4 Bewertung der Fitness f ( x k ) {\displaystyle f(x_{k}) 5 Berechnung der Log-Derivate ğŸ˜‰ log â€¡ Ï€ ( x k | Î¸ Î¸ ) {\displaystyle \nabla {\_theta }\log \pi (x_{k}\theta } 6 Ende 7 die Dienstprogramme u k {\displaystyle u_{k} // basierend auf Rang 8 schÃ¤tzen den Gradienten ğŸ˜‰ 1 Î» u k Ã Ã log Ï€ ( x k | Î¸ ) {\displaystyle \nabla} *J\leftarrow {\frac 1}{\lambda }\sum _k=1{\lambda ) 9 SchÃ¤tzwert F â† 1 Î» Î£ k = 1 Î» Îº Îº Î¸ log Ï€ ( x k | Î¸ Î¸ Î¸ Î˜ ) Îº Îº Îº Îº Ï€ ( x k | ) Î¸ ) ) ) ) âŠ¤ âŠ¤ âŠ¤ âŠ¤ âŠ¤ âŠ¤ âŠ¤ âŠ¤ âŠ¤ âŠ¤ {\displaystyle \mathbf ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nabla \\_theta }\log \pi (x_{k}the\theta )\nabla {\_theta }\log \pi (x_{k}\theta {\c}}\\c\c\c\c\\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c{\displaystyle \theta \leftarrow \theta \+eta \cdot \mathbf (F) Î· ist die Lernrate 11 bis zur Beendigung des Kriteriums Siehe auch EvolutionÃ¤re Berechnung Kovarianz-Matrix-Adaption Evolutionsstrategie (CMA-ES) Bibliographie D. Wierstra, T. Schaul, J. Peters und J. Schmidhuber (2008). NatÃ¼rliche Evolutionsstrategien.IEEE Kongress zur Evolutionskommission (CEC). Y Sun, D. Wierstra, T. Schaul und J. Schmidhuber (2009). Stochastic Search mit dem natÃ¼rlichen Gradienten. Internationale Konferenz zum maschinellen Lernen (ICML). T Glasmachers, T. Schaul, Y. Sun, D. Wierstra und J. Schmidhuber (2010). Offene natÃ¼rliche Evolutionsstrategien. Genetische und evolutionÃ¤re Computation Conference (GECCO). T Schaul, T. Glasmachers und J. Schmidhuber (2011). Hohe Abmessungen und schwere Tails fÃ¼r natÃ¼rliche Evolutionsstrategien. Genetische und evolutionÃ¤re Computation Conference (GECCO).T Schaul (2012). NatÃ¼rliche Evolution Strategien Konvergieren auf Sphere Funktionen. Genetische und evolutionÃ¤re Computation Conference (GECCO.) Externe Links Sammlung von NES-Implementierungen in verschiedenen Sprachen