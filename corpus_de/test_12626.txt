Der folgende Umriss wird als Übersicht und aktuelle Anleitung zur Objekterkennung bereitgestellt: Objekterkennung – Technologie im Bereich der Computervision zum Auffinden und Auffinden von Objekten in einer Bild- oder Videosequenz. Die Menschen erkennen eine Vielzahl von Objekten in Bildern mit wenig Aufwand, trotz der Tatsache, dass das Bild der Objekte in verschiedenen Blickpunkten, in vielen verschiedenen Größen und Skalen oder sogar bei der Übersetzung oder Drehung etwas variieren kann. Objekte können sogar erkannt werden, wenn sie teilweise aus der Sicht behindert werden. Diese Aufgabe ist immer noch eine Herausforderung für Computer-Vision-Systeme. Viele Ansätze zur Aufgabe wurden über mehrere Jahrzehnte umgesetzt. Ansätze auf Basis von CAD-ähnlichen Objektmodellen Kantenerkennung Primal Skizze Marr, Mohan und Nevatia Lowe Olivier Faugeras Erkennung von Teilen Allgemeine Zylinder (Thomas Binford)Geons (Irving Biederman) Dickinson, Forsyth und Ponce Appearance-basierte Methoden Verwenden Sie Beispielbilder (genannte Vorlagen oder Exemplare) der Objekte zur Ausführung von Erkennungsobjekten sehen unter unterschiedlichen Bedingungen unterschiedlich aus: Änderungen in der Beleuchtung oder Farbe Änderungen in der Blickrichtung Änderungen in der Größe/Form Eine einzelne Exemplar ist unwahrscheinlich, um zuverlässig zu Erfolg. Es ist jedoch unmöglich, alle Erscheinungen eines Objekts darzustellen. Randanpassung Benutzt Kantenerkennungstechniken wie die Canny Kantenerkennung, um Kanten zu finden. Veränderungen in der Beleuchtung und Farbe haben in der Regel nicht viel Einfluss auf Bildkanten Strategie: Kanten in Vorlage und Bild erkennen Kantenbilder vergleichen, um die Vorlage zu finden Muss Reichweite möglicher Vorlagepositionen berücksichtigen Messungen: Gut – Zählen Sie die Anzahl der überlappenden Kanten. Nicht robust für Veränderungen in der Form Besser – Zählen Sie die Anzahl der Template-Crand-Pixel mit einem gewissen Abstand einer Kante im Suchbild Best – bestimmen Sie die Wahrscheinlichkeitsverteilung der Entfernung zur nächsten Kante im Suchbild (wenn Vorlage an der richtigen Position). Schätzen Sie die Wahrscheinlichkeit jeder Vorlage Position erzeugen Bild Divide-and-Conquer Suche Strategie: Betrachten Sie alle Positionen als Set (eine Zelle im Raum der Positionen) Bestimmen Sie die untere Grenze auf die Punktzahl am besten Position in der Zelle Wenn gebunden zu groß ist, Wenn gebunden nicht zu groß ist, teilen Sie Zelle in Subzellen und versuchen Sie jede Subzelle rekursiv Prozess stoppt, wenn Zelle "klein genug" ist Im Gegensatz zur Multi-Resolution-Suche ist diese Technik garantiert, alle Spiele zu finden, die das Kriterium erfüllen (damit die untere Grenze genau ist)Finding the Bound: Um die untere Grenze auf der besten Punktzahl zu finden, schauen Sie sich die Punktzahl für die Vorlage Position repräsentiert durch die Mitte der Zelle Subtrahieren maximale Änderung von der "Mitte" Position für jede andere Position in Zelle (besetzt an Zell-Ecken)Komplexe ergeben sich aus der Bestimmung der Grenzen auf Distanz Greyscale Matching Edges sind (meist) robust für Beleuchtungsänderungen, aber sie werfen eine Menge Informationen weg Muss Pixelabstand in Abhängigkeit von Pixelposition und Pixelintensität berechnen Kann auch auf die Farbe angewendet werden Gradient-Anpassung Eine andere Möglichkeit, robust zu sein für Beleuchtungsänderungen, ohne wegzuwerfen, so viel Information ist, Bildgradienten zu vergleichen Matching wird wie passende Graustufenbilder durchgeführt Einfache Alternative: Verwendung (normalisiert) Korrelation Histogramme von empfänglichen Feldantworten Vermeidet explizite Punktkorrespondenz Beziehungen zwischen verschiedenen Bildpunkten implizit kodiert in den empfänglichen Feldantworten Swain und Ballard (1991,) Schiele und Crowley (2000,) Linde und Lindeberg (2004, 2012) Große Modellbasen Ein Ansatz, die Datenbank für ein bestimmtes Bild effizient zu suchen, um Eigenvektoren der Vorlagen (genannte Eigenfaces) zu verwenden.Modelbases sind eine Sammlung von geometrischen Modellen der Objekte, die erkannt werden sollten Feature-basierte Methoden eine Suche verwendet wird um mögliche Übereinstimmungen zwischen Objektmerkmalen und Bildmerkmalen zu finden. die primäre Beschränkung ist, dass eine einzige Position des Objekts alle machbaren Spiele berücksichtigen muss. Methoden, die Merkmale aus den zu erkennenden Objekten und den zu durchsuchenden Bildern extrahieren. Oberfläche Patches Ecken lineare Kanten Interpretation Bäume Eine Methode zur Suche nach möglichen Spielen ist die Suche durch einen Baum. Jeder Knoten im Baum stellt eine Reihe von Treffern dar. Root-Knoten für leeres Set Jeder andere Knoten ist die Verbindung der Spiele im Stammknoten und eine zusätzliche Übereinstimmung. Wildcard wird für Features ohne Match verwendet Nodes werden „gepflückt“, wenn das Set von Spielen undurchführbar ist. Ein gekürzter Knoten hat keine Kinder Historisch bedeutsam und immer noch verwendet, aber weniger häufig Hypothesize und Test General Idea: Hypothesize eine Korrespondenz zwischen einer Sammlung von Bildmerkmalen und einer Sammlung von Objektmerkmalen Verwenden Sie diese dann, um eine Hypothese über die Projektion vom Objektkoordinatenrahmen zum Bildrahmen zu erzeugen Verwenden Sie diese Projektionshypothese, um eine Renderung des Objekts zu erzeugen.Dieser Schritt wird üblicherweise als Rückprojektion bezeichnet Vergleichen Sie das Rendern zum Bild, und wenn die beiden hinreichend ähnlich sind, akzeptieren Sie die Hypothese, die Hypothese zu erhalten. Es gibt eine Vielzahl von verschiedenen Möglichkeiten, Hypothesen zu erzeugen. Wenn Kamera-Intrinsic-Parameter bekannt sind, entspricht die Hypothese einer hypothetischen Position und Orientierung – Pose – für das Objekt. Geometrische Zwänge verwenden Konstruieren Sie eine Korrespondenz für kleine Sätze von Objekt-Features zu jeder richtig großen Teilmenge von Bildpunkten.( Dies sind die Hypothesen) Drei grundlegende Ansätze: Hypothesen von Pose Consistency zu erhalten Hypothesen durch Pose Clustering Hypothesen durch Verwendung von Invariants Kostensuche, die auch redundant ist, aber mit Randomization und/oder Grouping Randomization verbessert werden kann Prüfung kleiner Sätze von Bildmerkmalen, bis die Wahrscheinlichkeit eines fehlenden Objekts klein wird Für jede Menge von Bildmerkmalen müssen alle möglichen Anpassungssätze von Modellmerkmalen berücksichtigt werden. Formel:(1 – Wc)k = ZW = der Anteil der Bildpunkte, die "gut" sind (w ~ m/n) c= die Anzahl der notwendigen Korrespondenzen k = die Anzahl der Versuche Z = die Wahrscheinlichkeit jeder Studie unter Verwendung einer (oder mehrerer) fehlerhaften Korrespondenzen Gruppe Wenn wir Gruppen von Punkten bestimmen können, die wahrscheinlich aus dem gleichen Objekt kommen, können wir die Anzahl der Hypothesen reduzieren, die geprüft werden müssen Pose Konsistenz Auch genannt Ausrichtung, da das Objekt auf das Bild ausgerichtet wird Korrespondenzenzen zwischen Bildmerkmalen und Modellmerkmalen sind nicht unabhängig – geometrisch Eine geringe Anzahl von Korrespondenzen ergibt die Objektposition – die anderen müssen mit dieser Allgemeinen Idee übereinstimmen: Wenn wir eine Übereinstimmung zwischen einer ausreichend großen Gruppe von Bildmerkmalen und einer ausreichend großen Gruppe von Objektmerkmalen hypothetisieren, dann können wir die fehlenden Kameraparameter aus dieser Hypothese (und so den Rest des Objekts machen)Strategy: Hypothesen mit einer geringen Anzahl von Korrespondenzen generieren (z.B. Dreifachpunkte für 3D-Erkennung)Projekt andere Modellmerkmale in Bild (Rückprojekt) und zusätzliche Korrespondenzen überprüfen Verwenden Sie die kleinste Anzahl der Korrespondenzen, die erforderlich sind, um diskrete Objektpositionen zu erreichen Pose Clustering General Idea: Jedes Objekt führt zu vielen korrekten Sätzen von Korrespondenzen, von denen jeder (etwa) die gleiche Pose Vote auf Pose hat. Verwenden Sie ein Akku-Array, das Pose Raum für jedes Objekt darstellt Dies ist im Wesentlichen eine Hough-Transformation Strategie: Für jedes Objekt wird ein Akkumulator-Array eingerichtet, das Posenraum darstellt – jedes Element im Akkumulator-Array entspricht einem "Bucket" im Posenraum. Dann nehmen Sie jede Bildrahmengruppe und hypothetisieren Sie eine Korrespondenz zwischen ihm und jeder Rahmengruppe auf jedem Objekt Für jede dieser Korrespondenzen bestimmen Sie Pose-Parameter und machen Sie einen Eintrag in der Speicheranordnung für das aktuelle Objekt am Pose-Wert. Wenn in jedem Objekt eine große Anzahl von Stimmen vorhanden sind, kann dies als Beweis für das Vorhandensein dieses Objekts in dieser Position interpretiert werden. Die Nachweise können mit einer Verifikationsmethode überprüft werden Beachten Sie, dass diese Methode Korrespondenzen verwendet, anstatt einzelne Korrespondenzen Implementierung einfacher ist, da jeder Satz eine geringe Anzahl von möglichen Objektposen liefert. Verbesserung Der Lärmwiderstand dieser Methode kann verbessert werden, indem man nicht die Stimmen für Objekte in Posen zählt, in denen die Abstimmung offensichtlich unzuverlässig ist. Beispielsweise wäre in Fällen, in denen, wenn das Objekt an dieser Pose war, die Objektrahmengruppe unsichtbar. Diese Verbesserungen reichen aus, um Arbeitssysteme zu erbringen Invariante Es gibt geometrische Eigenschaften, die invariant für Kameratransformationen sind Am einfachsten entwickelt für Bilder von planaren Objekten, kann aber auch auf andere Fälle angewendet werden. Ein Algorithmus, der geometrische Invarianten verwendet, um für Objekthypothesen abzustimmen Ähnlich wie das Posen-Clustering, aber anstatt auf Pose zu wählen, stimmen wir jetzt über Geometrie A Technik, die ursprünglich für die Anpassung von geometrischen Merkmalen entwickelt wurde (unkalibrierte Affine Ansichten von Flugzeugmodellen) gegen eine Datenbank solcher Merkmale Weit verbreitet für Musteranpassung, CAD/CAM und medizinische Bildgebung. Es ist schwierig, die Größe der Eimer zu wählen Es ist schwer, sicher zu sein, was “geil” bedeutet. Daher kann es eine Gefahr geben, dass der Tisch verstopft wird. Skaleninvariante Merkmalstransformation (SIFT)Keypoints von Objekten werden zunächst aus einem Satz von Referenzbildern extrahiert und in einer Datenbank gespeichert Ein Objekt wird in einem neuen Bild erkannt, indem jedes Feature einzeln aus dem neuen Bild mit dieser Datenbank verglichen und Kandidatenanpassungsmerkmale basierend auf Euclidean Entfernung ihrer Merkmalsvektoren gefunden werden.Lowe (2004) Speeded Up Robust Features (SURF) Ein robuster Bilddetektor & Deskriptor Die Standardversion ist mehrmals schneller als SIFT und behauptet, dass ihre Autoren robuster gegen unterschiedliche Bildtransformationen sind als SIFT Basierend auf Summen von ca. 2D Haar Wavelet-Antworten und effiziente Nutzung von integralen Bildern. Bay et al.(2008) Tasche der Wörter Repräsentationen Generischer Algorithmus Genetische Algorithmen können ohne vorherige Kenntnis eines bestimmten Datensatzes arbeiten und Erkennungsprozeduren ohne menschliche Intervention entwickeln. Ein jüngstes Projekt erreichte eine 100-prozentige Genauigkeit auf dem Benchmark-Motorrad-, Gesichts-, Flugzeug- und Autobilddatensätze von Caltech und 99,4 Prozent Genauigkeit auf Fischarten-Bilddatensätzen. Weitere Ansätze 3D-Objekterkennung und -rekonstruktion Biologische inspirierte Objekterkennung Künstliche neuronale Netzwerke und Deep Learning besonders konvolutionale neuronale Netzwerke Kontext Explicit und implizite 3D-Objektmodelle Schnelle IndexierungGlobale Szenendarstellungen Gradiente Histogramme Stochastic grammars Intraclass Transfer Learning Objekt-Kategorisierung aus Bildsuche Reflexion Form-aus-Shading Template-Anpassung Texture Objekterkennungsverfahren haben folgende Anwendungen: Aktivitätserkennung Automatische Bildannotation Automatische Zielerkennung Android Eyes - Objekterkennung Computergestützte Diagnose Bilderpanoramas Bild Wasserzeichen Globale Roboterlokalisierung GesichtserkennungOptische Charaktererkennung Fertigungsqualitätskontrolle Content-basierte Bildwiederholung Objektzählung und Überwachung automatisierter Parksysteme Visuelle Positionierung und Verfolgung Videostabilisierung Pedestrian Erkennung Umfragen Daniilides und Eklundh, Edelman. Roth, Peter M. & Winter, Martin (2008). " SURVEYOFAPPEARANCE-BASED METHODEN FÜR OBJECT RECOGNITION" (PDF). Technischer Bericht.ICG-TR-01/08 Siehe auch Histogramm von orientierten Gradienten Convolutional neuronal network OpenCV Scale-invariant feature transform (SIFT) Objekterkennung Scholarpedia Artikel über Scale-invariant Feature-Transformation und damit verbundene Objekterkennung Methoden SURF Template Matching Integral Channel featureListsListe der Computer Vision Themen Liste der aufstrebenden Technologien Übersicht über künstliche Intelligenz Hinweise Referenzen Elgammal, Ahmed "CS 534: Computer Vision 3D Modellbasierte Erkennung", Dept of Computer Science, Rutgers University; Hartley, Richard und Zisserman, Andrew "Multiple View Geometry in computer vision", Cambridge Press, 2000, ISBN 0-521-62304-9. Roth, Peter M. und Winter, Martin "Survey of Appearance-Based Methods for Object Recognition", Technical Report ICG-TR-01/08, Inst. for Computer Graphics and Vision, TU Graz, Österreich; 15. Januar 2008. Collins, Robert "Lecture 31: Object Recognition: SIFT Keys", CSE486, Penn State IPRG Image Processing - Online Open Research Group Christian Szegedy, Alexander Toshev und Dumitru Erhan. Deep Neural Networks für Objekterkennung. Fortschritte bei Neural Information Processing Systems 26, 2013.page 2553–2561. = Externe Links ==