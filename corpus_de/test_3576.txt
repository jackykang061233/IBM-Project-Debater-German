In der Geschichte der künstlichen Intelligenz ist ein KI-Winter eine Zeit der reduzierten Finanzierung und Interesse an der künstlichen Intelligenz Forschung. Der Begriff wurde analog zur Idee eines nuklearen Winters geprägt. Das Feld hat mehrere Hype-Zyklen erlebt, gefolgt von Enttäuschung und Kritik, gefolgt von Finanzierungskürzungen, gefolgt von erneuerten Interesse Jahre oder Jahrzehnte später. Der Begriff erschien 1984 als Thema einer öffentlichen Debatte auf der jährlichen Sitzung von AAAI (damals "American Association of Artificial Intelligence"). Es ist eine Kettenreaktion, die mit dem Pessimismus in der KI-Gemeinschaft beginnt, gefolgt von dem Pessimismus in der Presse, gefolgt von einer schweren Kürzung der Finanzierung, gefolgt von dem Ende der ernsthaften Forschung. Auf dem Treffen haben Roger Schank und Marvin Minsky – zwei führende KI-Forscher, die den Winter der 1970er Jahre überlebt hatten – die Wirtschaftsgemeinschaft gewarnt, dass die Begeisterung für KI in den 1980er Jahren aus der Kontrolle geflüchtet war und dass die Enttäuschung sicherlich folgen würde. Drei Jahre später begann die Milliarden-Dollar-KI-Branche zu kollabieren. Hype ist häufig in vielen aufstrebenden Technologien, wie der Bahnmanie oder der Punkt-Com-Blase. Der KI-Winter war ein Ergebnis eines solchen Hypes, durch über-aufgeblasene Versprechen von Entwicklern, unnatürlich hohe Erwartungen von Endnutzern und umfangreiche Förderung in den Medien. Trotz des Anstiegs und des Rückgangs des Rufes von KI hat sie weiterhin neue und erfolgreiche Technologien entwickelt. KI-Forscher Rodney Brooks würde sich 2002 beklagen, dass "da draußen dieser dumme Mythos ist, dass KI gescheitert ist, aber KI ist jede Sekunde um dich herum. " Im Jahr 2005 stimmte Ray Kurzweil zu: "Viele Beobachter denken immer noch, dass der KI-Winter das Ende der Geschichte war und dass seitdem nichts aus dem KI-Feld gekommen ist. Doch heute sind viele Tausende von KI-Anwendungen tief in die Infrastruktur jeder Branche eingebettet." Der Enthusiasmus und der Optimismus über KI haben sich seit seinem Tiefpunkt Anfang der 1990er Jahre allgemein erhöht. Anfang 2012 führte das Interesse an künstlicher Intelligenz (und insbesondere dem Teilbereich des maschinellen Lernens) der Forschungs- und Firmengemeinden zu einem dramatischen Anstieg der Finanzierung und Investitionen. Überblick Es gab zwei große Winter in 1974–1980 und 1987–1993 und mehrere kleinere Episoden, darunter: 1966: Versagen der maschinellen Übersetzung 1970: Verlassen des Verbindungsismus Zeit der überlappenden Tendenzen: 1971–75: DARPAs Frustration mit dem Forschungsprogramm Speech Understanding an der Carnegie Mellon University 1973: große Abnahme der AI-Forschung im Vereinigten Königreich in Reaktion auf den Lighthill-Bericht 1973–74:DARPAs Rückschläge auf akademische AI-Forschung im Allgemeinen 1987: Zusammenbruch des LISP-Maschinenmarktes 1988: Aufhebung der neuen Ausgaben für AI durch die Strategische Computing Initiative 1993: Die Regierung unterstützte aggressiv die Bemühungen bei der maschinellen Übersetzung ab 1954. Anfangs waren die Forscher optimistisch. Noam Chomskys neue Arbeit in der Grammatik hat den Übersetzungsprozess gestrafft und es gab "viele Vorhersagen von bevorstehenden Durchbrüchen". Die Forscher hatten jedoch die tiefe Schwierigkeit der Wort-Sense-Diambiguation unterschätzt. Um einen Satz zu übersetzen, brauchte eine Maschine eine Idee zu haben, worum es im Satz ging, sonst machte sie Fehler. Ein apokryphalisches Beispiel ist "der Geist ist bereit, aber das Fleisch ist schwach. " Übersetzt hin und her mit Russisch, es wurde "die Wodka ist gut, aber das Fleisch ist faul. " Später würden die Forscher das Problem des gemeinsamen Wissens nennen. Bis 1964 hatte sich der Nationale Forschungsrat um den Mangel an Fortschritten bemüht und den Beirat für die automatische Sprachverarbeitung (ALPAC) gebildet, um das Problem zu untersuchen. Sie schlossen in einem berühmten Bericht von 1966, dass die maschinelle Übersetzung teurer, weniger genau und langsamer als die menschliche Übersetzung war. Nachdem sie etwa 20 Millionen Dollar ausgegeben hatten, beendete die NRC alle Unterstützung. Die Karrieren wurden zerstört und die Forschung beendet. Maschinenübersetzung ist noch ein offenes Forschungsproblem im 21. Jahrhundert, das mit einigen Erfolgen (Google Translate, Yahoo Babel Fish.) Die Aufgabe des Verbindungsismus im Jahr 1969 Einige der frühesten Arbeiten in KI verwendet Netzwerke oder Schaltungen von angeschlossenen Einheiten, um intelligentes Verhalten zu simulieren. Beispiele für diese Art von Arbeit, genannt Verbindungsismus, sind Walter Pitts und Warren McCulloughs erste Beschreibung eines neuronalen Netzwerks für Logik und Marvin Minskys Arbeit am SNARC-System. In den späten 1950er Jahren wurden die meisten dieser Ansätze aufgegeben, als die Forscher begannen, symbolische Argumentation als die Essenz der Intelligenz zu erforschen, nach dem Erfolg von Programmen wie dem Logiktheoretiker und dem General Problem Solver. Eine Art Verbindungsarbeit setzte sich jedoch fort: die Studie von Perceptrons, erfunden von Frank Rosenblatt, der das Feld mit seiner Verkaufsmannschaft und der schiere Kraft seiner Persönlichkeit am Leben hielt. Er prophezeite optimistisch, dass der Perceptron "sich vielleicht irgendwann in der Lage sein kann, Entscheidungen zu treffen und Sprachen zu übersetzen". Die Mainstream-Forschung an Perceptrons kam 1969 zu einem abrupten Ende, als Marvin Minsky und Seymour Papert das Buch Perceptrons publizierten, das als die Grenzen dessen, was Perceptrons tun konnten, empfunden wurde. Die Verbindungsansätze wurden für das nächste Jahrzehnt aufgegeben. Während wichtige Arbeiten wie die Entdeckung der Rückverbreitung von Paul Werbos in begrenzter Weise fortgesetzt wurden, war die Finanzierung von Verbindungsprojekten in den 1970er und Anfang der 1980er Jahre schwierig zu finden. Der Winter der Verbindungsforschung kam in den Mitten der 1980er Jahre zu Ende, als die Arbeit von John Hopfield, David Rumelhart und anderen wieder großes Interesse an neuronalen Netzwerken. Das Rosenblatt lebte jedoch nicht, da er in einem Bootsunfall kurz nach der Veröffentlichung von Perceptrons starb. Die Rückschläge von 1974 Der Bericht Lighthill 1973, Professor Sir James Lighthill, wurde vom britischen Parlament gebeten, den Stand der KI-Forschung im Vereinigten Königreich zu bewerten. Sein Bericht, der jetzt den Lighthill-Bericht genannt wurde, kritisierte das völlige Versagen von KI, seine "Grandiose-Ziele zu erreichen. " Er kam zu dem Schluss, dass nichts in KI getan werden konnte nicht in anderen Wissenschaften. Er erwähnte speziell das Problem der "kombinatorischen Explosion" oder der Intraktivität, die implizierte, dass viele der erfolgreichsten Algorithmen von KI zu einem Stillstand auf realen Weltproblemen schleifen würden und nur für die Lösung von Spielzeugversionen geeignet waren. Der Bericht wurde 1973 in einer Debatte in der Serie BBC Controversy angefochten. Die Debatte "Der allgemeine Zweck Roboter ist ein Wunder" von der Royal Institution war Lighthill gegen das Team von Donald Michie, John McCarthy und Richard Gregory. McCarthy schrieb später, dass "das kombinatorische Explosionsproblem in KI von Anfang an erkannt wurde". Der Bericht führte zum vollständigen Abbau der AI-Forschung in England. Die AI-Forschung setzte sich in nur wenigen Universitäten fort (Edinburgh, Essex und Sussex). Die Forschung würde bis 1983 nicht in großem Umfang wieder aufleben, als Alvey (ein Forschungsprojekt der britischen Regierung) als Reaktion auf das japanische Fünfte Generationsprojekt (siehe unten) die KI wieder von einer Kriegstruhe von 350 Millionen Pfund finanzierte. Alvey hatte eine Reihe von UK-only Anforderungen, die nicht gut international, vor allem mit US-Partnern, und verloren Phase 2 Finanzierung. Die Anfang der 1970er-Jahre finanzierte Kürzungen In den 1960er-Jahren lieferte die Defense Advanced Research Projects Agency (damals ARPA, heute DARPA genannt) Millionen Dollar für die AI-Forschung mit wenigen Streichern. J C. R. Licklider, der Gründungsdirektor von DARPA's Computing Division, glaubte an "Förderung von Menschen, nicht Projekten" und er und mehrere Nachfolger erlaubten AIs Führer (wie Marvin Minsky, John McCarthy, Herbert A. Simon oder Allen Newell) zu verbringen, fast jede Art, wie sie mochten. Diese Einstellung änderte sich nach der Passage von Mansfield Änderungsantrag im Jahr 1969, die DARPA zur Finanzierung "missionsorientierter Direktforschung, anstatt grundlegender und geschützter Forschung" benötigte. Reine undirected Forschung der Art, die in den 1960er Jahren angelaufen war, würde nicht mehr von DARPA finanziert werden. Forscher mussten jetzt zeigen, dass ihre Arbeit bald eine nützliche militärische Technologie produzieren würde. KI-Forschungsvorschläge wurden auf einen sehr hohen Standard abgehalten. Die Situation wurde nicht geholfen, als der Lighthill-Bericht und die eigene Studie von DARPA (die American Study Group) nahelegten, dass die meisten AI-Forschungen in absehbarer Zeit nichts wirklich nützliches produzieren würden. Das Geld von DARPA richtete sich an spezifische Projekte mit identifizierbaren Zielen, wie autonome Tanks und Schlachtmanagementsysteme. Bis 1974 war die Finanzierung von KI-Projekten schwer zu finden. KI-Forscher Hans Moravec gab der Krise die unrealistischen Vorhersagen seiner Kollegen vor: "Viele Forscher wurden in einem Netz zunehmender Übertreibung gefangen. Ihre anfänglichen Versprechen an DARPA waren viel zu optimistisch. Natürlich blieb das, was sie geliefert haben, deutlich kurz davor. Aber sie glaubten, dass sie nicht in ihrem nächsten Vorschlag versprechen, weniger als im ersten, so dass sie mehr versprochen. " Das Ergebnis, Moravec behauptet, dass einige der Mitarbeiter von DARPA hatte Geduld mit AI-Forschung verloren. " Es wurde bei DARPA buchstäblich formuliert, dass "einige dieser Menschen eine Lektion [von] mit ihren zwei Millionen-Dollar-ein-Jahr-Verträgen zu fast nichts" gelehrt werden würde! Moravec hat Daniel Crevier erzählt. Während das autonome Tankprojekt ein Scheitern war, erwies sich das Schlachtmanagementsystem (das dynamische Analyse- und Replaning-Tool) als enorm erfolgreich, ersparte Milliarden im ersten Golfkrieg, zahlte alle DARPAs Investitionen in KI und rechtfertigte die pragmatische Politik von DARPA. Der SUR-Debacle DARPA war zutiefst enttäuscht von Forschern, die am Forschungsprogramm Speech Understanding an der Carnegie Mellon University arbeiten. DARPA hatte gehofft, dass es versprochen wurde, ein System, das auf Sprachbefehle eines Piloten reagieren konnte. Das SUR-Team hatte ein System entwickelt, das gesprochenes Englisch erkennen konnte, aber nur wenn die Worte in einer bestimmten Reihenfolge gesprochen wurden. DARPA war der Ansicht, dass sie ausgesperrt worden war und sie 1974 einen Vertrag von drei Millionen Dollar pro Jahr annulliert haben. Viele Jahre später würden mehrere erfolgreiche kommerzielle Spracherkennungssysteme die vom Carnegie Mellon-Team (wie versteckte Markov-Modelle) entwickelte Technologie nutzen und der Markt für Spracherkennungssysteme würde bis 2001 4 Milliarden Dollar erreichen. Die Rückschläge der späten 1980er und frühen 1990er Jahre Der Zusammenbruch des LISP-Maschinenmarktes In den 1980er Jahren wurde eine Form von KI-Programm als "Expertensystem" von Unternehmen auf der ganzen Welt angenommen. Das erste kommerzielle Expertensystem wurde bei Carnegie Mellon für Digital Equipment Corporation entwickelt, und es war ein enormer Erfolg: Es wurde geschätzt, dass das Unternehmen 40 Millionen Dollar über nur sechs Jahre Betriebszeit gerettet haben. Unternehmen auf der ganzen Welt begannen, Expertensysteme zu entwickeln und zu implementieren, und bis 1985 hatten sie mehr als eine Milliarde Dollar für KI ausgegeben, die meisten davon für interne KI-Abteilungen. Eine Industrie wuchs auf, um sie zu unterstützen, darunter Software-Unternehmen wie Teknowledge und Intellicorp (KEE), und Hardware-Unternehmen wie Symbolics und LISP Machines Inc., die spezialisierte Computer, genannt LISP-Maschinen, bauten, die optimiert wurden, um die Programmiersprache LISP, die bevorzugte Sprache für AI zu verarbeiten. 1987, drei Jahre nach Minsky und Schanks Vorhersage, brach der Markt für spezialisierte LISP-basierte KI-Hardware zusammen. Workstations von Unternehmen wie Sun Microsystems boten eine leistungsfähige Alternative zu LISP Maschinen und Unternehmen wie Lucid bot eine LISP-Umgebung für diese neue Klasse von Arbeitsplätzen. Die Performance dieser allgemeinen Workstations wurde für LISP Machines zu einer immer schwierigeren Herausforderung. Unternehmen wie Lucid und Franz LISP boten immer mächtigere Versionen von LISP an, die für alle UNIX-Systeme tragbar waren. So wurden beispielsweise Benchmarks veröffentlicht, die Workstations zeigen, die einen Leistungsvorteil gegenüber LISP-Maschinen erhalten. Spätere Desktop-Computer von Apple und IBM gebaut würden auch eine einfachere und beliebtere Architektur bieten, um LISP-Anwendungen zu betreiben. Bis 1987 waren einige von ihnen so mächtig geworden wie die teureren LISP-Maschinen. Die Desktop-Computer hatten regelbasierte Motoren wie CLIPS zur Verfügung. Diese Alternativen haben den Verbrauchern keinen Grund, eine teure Maschine für den Betrieb von LISP zu kaufen. Eine ganze Industrie im Wert von einer halben Milliarde Dollar wurde in einem Jahr ersetzt. Anfang der 1990er Jahre waren die meisten kommerziellen LISP-Unternehmen gescheitert, darunter Symbolics, LISP Machines Inc. Lucid Inc. usw. Andere Unternehmen, wie Texas Instruments und Xerox, verließen das Feld. Eine kleine Anzahl von Kundenunternehmen (d.h. Unternehmen mit Systemen, die in LISP geschrieben und auf LISP-Maschinenplattformen entwickelt wurden) setzte weiterhin Systeme aufrecht. In einigen Fällen hat diese Wartung die Annahme der daraus resultierenden Unterstützungsarbeit mit einbezogen. Slowdown bei der Bereitstellung von Expertensystemen Anfang der 1990er Jahre erwies sich die frühesten erfolgreichen Expertensysteme wie XCON als zu teuer zu halten. Sie waren schwer zu aktualisieren, sie konnten nicht lernen, sie waren spröde (d.h. sie konnten groteske Fehler machen, wenn sie ungewöhnliche Eingaben gegeben,) und sie fielen auf Probleme (wie das Qualifikationsproblem), die früher in der Forschung in nicht monotonen Logik identifiziert worden waren. Expertensysteme erwiesen sich als nützlich, aber nur in einigen speziellen Kontexten. Ein weiteres Problem beschäftigte sich mit der rechnerischen Härte der Wahrheitspflege für allgemeines Wissen. KEE nutzte einen Annahme-basierten Ansatz (siehe NASA, TEXSYS), der mehrere Weltszenarien unterstützte, die schwer zu verstehen und anzuwenden waren. Die wenigen verbleibenden Experten-System Shell-Unternehmen wurden schließlich gezwungen, nach neuen Märkten und Software-Paradigmen zu suchen, wie z.B. auf Basis von Argumenten oder Universal-Datenbank-Zugang. Die Reifung von Common Lisp speicherte viele Systeme wie ICAD, die Anwendung im wissensbasierten Engineering gefunden. Andere Systeme, wie Intellicorp's KEE, zogen von LISP zu einem C+ (variant) auf dem PC und halfen, objektorientierte Technologie zu etablieren (einschließlich der Bereitstellung großer Unterstützung für die Entwicklung von UML (siehe UML-Partner). Das Projekt der Fünften Generation 1981 hat das japanische Ministerium für internationalen Handel und Industrie 850 Millionen Dollar für das Computerprojekt der Fünften Generation bereitgestellt. Ihre Ziele waren es, Programme zu schreiben und Maschinen zu bauen, die Gespräche führen könnten, Sprachen übersetzen, Bilder interpretieren, und Grund wie Menschen. 1991 war die beeindruckende Liste der 1981 gestifteten Ziele nicht erreicht worden. Laut HP Newquist in The Brain Makers "Am 1. Juni 1992 beendete das Fünfte Generation-Projekt nicht mit einem erfolgreichen Roar, sondern mit einem Whimper". Wie bei anderen KI-Projekten waren die Erwartungen viel höher als das, was tatsächlich möglich war. Strategische Computing Initiative Kürzungen 1983 begann DARPA als Reaktion auf das Projekt der fünften Generation erneut mit der Förderung der KI-Forschung durch die Strategische Computing Initiative. Wie ursprünglich vorgeschlagen, würde das Projekt mit praktischen, erzielbaren Zielen beginnen, die sogar künstliche allgemeine Intelligenz als langfristiges Ziel enthalten. Das Programm stand unter der Leitung des Informationsverarbeitungstechnikamtes (IPTO) und war auch auf Supercomputing und Mikroelektronik ausgerichtet. Bis 1985 hatten sie 100 Millionen Dollar ausgegeben und 92 Projekte wurden an 60 Institutionen, der Hälfte in der Industrie, der Hälfte an Universitäten und Regierungslaboren durchgeführt. KI-Forschung wurde von der GGB großzügig gefördert. Jack Schwarz, der 1987 zur Leitung von IPTO aufgestiegen war, entließ Expertensysteme als "saubere Programmierung" und reduzierte die Finanzierung der KI "tief und brutal", um SCI zu informieren. Schwarz fühlte, dass DARPA seine Finanzierung nur auf jene Technologien konzentrieren sollte, die das meiste Versprechen zeigten, d.h. DARPA sollte surfen, anstatt "Hund Paddle" und er fühlte sich stark AI war nicht "die nächste Welle". Insider im Programm zitiert Probleme in Kommunikation, Organisation und Integration. Einige Projekte überlebten die Finanzierungskürzungen, darunter Pilotassistent und ein autonomes Landfahrzeug (die nie geliefert wurden) und das Kampfmanagementsystem DART, das (wie oben erwähnt) erfolgreich war. Entwicklungen post-AI Winter Eine Umfrage von Berichten aus den frühen 2000er Jahren deutet darauf hin, dass KIs Ruf immer noch weniger als stellar war: Alex Castro, zitiert in The Economist, 7. Juni 2007: "[Investoren] wurden durch den Begriff "Voice-Erkennung" ausgeschrieben, der wie "künstliche Intelligenz" mit Systemen verbunden ist, die allzu oft nicht zu ihren Versprechen leben konnten."Patty Tascarella in Pittsburgh Business Times, 2006 "Einige glauben, dass das Wort Robotik tatsächlich ein Stigma trägt, das die Chancen eines Unternehmens bei der Finanzierung verletzt. "John Markoff in der New York Times, 2005: "Einige Informatiker und Software-Ingenieure vermeiden den Begriff künstliche Intelligenz für Angst, als wilde Träumer angesehen zu werden. " Viele Forscher in KI Mitte der 2000er Jahre nannten bewusst ihre Arbeit mit anderen Namen, wie Informatik, maschinelles Lernen, Analytik, wissensbasierte Systeme, Business-Regeln-Management, kognitive Systeme, intelligente Systeme, intelligente Agenten oder computergestützte Intelligenz, um anzuzeigen, dass ihre Arbeit besondere Werkzeuge betont oder auf ein bestimmtes Subproblem gerichtet ist. Obwohl dies zum Teil der Fall sein kann, weil sie ihr Feld als grundlegend verschieden von KI betrachten, ist es auch wahr, dass die neuen Namen helfen, die Finanzierung zu fördern, indem das Stigma der falschen Versprechen, die dem Namen "künstliche Intelligenz" beigefügt sind, vermieden wird. KI-Integration In den späten 1990er und Anfang des 21. Jahrhunderts wurde die KI-Technologie weit verbreitet als Elemente größerer Systeme, aber das Feld wird selten für diese Erfolge gutgeschrieben. Im Jahr 2006 erklärte Nick Bostrom, dass "viele Schneide KI in allgemeine Anwendungen gefiltert hat, oft ohne KI genannt zu werden, weil einmal etwas nützlich genug und gemeinsam genug wird, es ist nicht mehr KI markiert. " Rodney Brooks sagte um die gleiche Zeit, dass "es da draußen ist dieser dumme Mythos, dass KI gescheitert ist, aber KI ist um Sie jede Sekunde des Tages. " Von KI-Forschern entwickelte Technologien haben kommerziellen Erfolg in einer Reihe von Bereichen wie Maschinenübersetzung, Data Mining, Industrierobotik, Logistik, Spracherkennung, Banksoftware, medizinische Diagnose und Googles Suchmaschine erreicht. Fuzzy-Logik-Controller wurden für Automatikgetriebe in Automobilen entwickelt (die Audi TT 2006, VW Touareg und VW Caravelle verfügen über das DSP-Getriebe, das Fuzzy-Logik nutzt, eine Reihe von Škoda-Varianten (Škoda Fabia) umfasst derzeit auch einen fuzzy-Logik-basierten Controller). Kamera-Sensoren verwenden häufig Fuzzy-Logik, um Fokus zu ermöglichen. Heuristische Recherche- und Datenanalytik sind beide Technologien, die sich aus der evolutionären Computing- und Machine Learning-Unterteilung der KI-Forschungsgemeinschaft entwickelt haben. Auch hier wurden diese Techniken auf eine breite Palette von realen Weltproblemen mit erheblichem kommerziellen Erfolg angewendet. Datenanalytik-Technologie, die Algorithmen für die automatisierte Bildung von Klassifikatoren verwendet, die in der beaufsichtigten maschinellen Lerngemeinschaft in den 1990er Jahren entwickelt wurden (z.B. TDIDT, Support Vector Machines, Neural Nets, IBL) werden nun pervasiv von Unternehmen zur Marketing-Umfrage verwendet, die Trends und Features in Datensätzen anvisieren. KI-Förderung Forscher und Ökonomen beurteilten häufig den Status eines KI-Winters, indem sie überprüfen, welche KI-Projekte gefördert wurden, wie viel und von wem. Die Fördertendenzen werden oft von großen Förderorganisationen in der entwickelten Welt festgelegt. Derzeit bieten DARPA und ein ziviles Förderprogramm mit dem Namen EU-FP7 einen Großteil der Mittel für die KI-Forschung in den USA und der Europäischen Union. Seit 2007 hat DARPA KI-Forschungsvorschläge unter einer Reihe von Programmen wie The Grand Challenge Program, Cognitive Technology Threat Warning System (CT2WS,) "Human Assisted Neural Devices (SN07-43,") "Autonomes Echtzeit Ground Ubiquitous Surveillance-Imaging System (ARGUS-IS) und "Urban Reasoning and Geospatial Exploitation Technology (URGENT)"Am bekanntesten ist das Grand Challenge Program von DARPA, das vollautomatische Straßenfahrzeuge entwickelt hat, die das reale Weltgelände in völlig autonomer Weise erfolgreich navigieren können. DARPA hat auch Programme auf dem Semantic Web mit viel Schwerpunkt auf intelligente Verwaltung von Inhalten und automatisiertes Verständnis unterstützt. Doch James Hendler, der damals Manager des DARPA-Programms, äußerte einige Enttäuschung über die Fähigkeit der Regierung, einen schnellen Wandel zu schaffen, und zog mit dem World Wide Web Consortium zusammen, um die Technologien in den Privatsektor zu überführen. Das Förderprogramm EU-FP7 unterstützt Forscherinnen und Forscherinnen und Forscherinnen der Europäischen Union finanziell. 2007–2008 förderte sie die KI-Forschung im Rahmen des Kognitiven Systems: Interaction and Robotics Programme (€193m), des Digital Libraries and Content Programms (€203m) und des FET-Programms (€185m). Aktueller "AI Frühjahr" Eine deutliche Zunahme der KI-Finanzierung, Entwicklung, Bereitstellung und kommerziellen Nutzung hat dazu geführt, dass der KI-Winter lange vorbei ist. Es wird gelegentlich betont, dass ein neuer KI-Winter durch zu ehrgeizige oder unrealistische Versprechungen von prominenten KI-Wissenschaftlern ausgelöst werden könnte oder auf kommerziellen Anbietern überpromiert wird. Die Erfolge des aktuellen "AI Frühlings" sind Fortschritte in der Sprachübersetzung (insbesondere Google Translate), Bilderkennung (ausgezeichnet durch die ImageNet-Trainingsdatenbank), wie von Google Image Search, und in Spielsystemen wie AlphaZero (Chess-Meister) und AlphaGo (Go-Meister,) und Watson (Jeopardy-Meister.) Die meisten dieser Fortschritte sind seit 2010 aufgetreten. Ursachen hinter KI-Winters zu verstehen Mehrere Erklärungen wurden für die Ursache von KI-Winter im Allgemeinen gemacht. Als KI von staatlich finanzierten Anwendungen auf kommerzielle, kam neue Dynamik ins Spiel. Während Hype die am häufigsten zitierte Ursache ist, sind die Erklärungen nicht notwendigerweise gegenseitig ausschließbar. Hype Die KI-Winter können zum Teil als eine Folge von über-aufgeblasenen Erwartungen und anschließenden Absturz in den Aktienmärkten verstanden werden und von der Bahn mania und der Puppenblase exemplifiziert werden. In einem gemeinsamen Muster in der Entwicklung der neuen Technologie (wie Hype-Zyklus bekannt) schafft ein Ereignis, typischerweise ein technologischer Durchbruch, die Öffentlichkeit, die auf sich selbst speist, eine "Sprech der aufgeblasenen Erwartungen" zu schaffen, gefolgt von einem "Wahrheit der Vernichtung". Da der wissenschaftliche und technologische Fortschritt nicht mit der öffentlichkeitsbelasteten Erwartungssteigerung von Investoren und anderen Akteuren Schritt halten kann, muss ein Absturz folgen. KI-Technologie scheint keine Ausnahme zu dieser Regel zu sein. So führte beispielsweise in den 1960er Jahren die Erkenntnis, dass Computer 1-schichtige neuronale Netzwerke simulieren könnten, zu einem neural-network-Hype-Zyklus, der bis zur 1969 Veröffentlichung des Buches Perceptrons dauerte, die die Probleme stark begrenzte, die durch 1-Schicht-Netzwerke optimal gelöst werden konnten. Im Jahr 1985 führte die Erkenntnis, dass neuronale Netzwerke zur Lösung von Optimierungsproblemen genutzt werden könnten, aufgrund berühmter Papiere von Hopfield und Tank zusammen mit der Bedrohung des japanischen Projekts der 5. Generation zu einem erneuten Interesse und Anwendung. Institutionelle Faktoren Ein weiterer Faktor ist KIs Platz in der Organisation von Universitäten. Die KI-Forschung ist oft interdisziplinärer Forschung. KI ist daher anfällig für die gleichen Probleme andere Arten der interdisziplinären Forschung Gesicht. Die Förderung wird durch die etablierten Abteilungen geleitet, und während der Budgetkürzungen wird es eine Tendenz geben, die "Kerninhalte" jeder Abteilung zu Lasten interdisziplinärer und weniger traditioneller Forschungsprojekte abzuschirmen. Wirtschaftliche Faktoren Abschwächungen in der Volkswirtschaft eines Landes verursachen Budgetkürzungen an Universitäten. Die Tendenz "Kerninhalte" verschlechtert die Auswirkungen auf die KI-Forschung und die Investoren auf dem Markt dürften ihr Geld in weniger riskante Unternehmen während einer Krise stecken. Zusammen kann dies einen wirtschaftlichen Abschwung in einen KI-Winter verstärken. Es ist erwähnenswert, dass der Lighthill-Bericht zu einer Zeit der Wirtschaftskrise im Vereinigten Königreich kam, als die Universitäten Kürzungen vornehmen mussten und die Frage war nur, welche Programme gehen sollten. Unzureichende Rechenfähigkeit Früh in der Rechengeschichte wurde das Potential für neuronale Netze verstanden, aber es wurde nie realisiert. Fair einfache Netzwerke erfordern auch nach heutigen Standards eine erhebliche Rechenleistung. Leere Pipeline Es ist üblich, die Beziehung zwischen Grundlagenforschung und Technologie als Pipeline zu sehen. Fortschritte in der Grundlagenforschung ergeben Fortschritte in der angewandten Forschung, was wiederum zu neuen kommerziellen Anwendungen führt. Daraus wird oft argumentiert, dass ein Mangel an Grundlagenforschung zu einem Rückgang der marktfähigen Technologie einige Jahre nach unten führen wird. Diese Ansicht wurde von James Hendler im Jahr 2008 vorangebracht, als er behauptete, dass der Rückgang von Expertensystemen in den späten 80er Jahren nicht auf eine inhärente und unvermeidbare Sprödigkeit von Expertensystemen zurückzuführen sei, sondern auf Kürzungen der Grundlagenforschung in den 1970er Jahren. Diese in den 1980er Jahren durch angewandte Forschung und Produktentwicklung entwickelten Expertensysteme, aber bis Ende des Jahrzehnts hatte die Pipeline Trocken- und Expertensysteme nicht in der Lage, Verbesserungen zu erzielen, die diese Sprödigkeit überwunden und weitere Finanzierungen gesichert hätten. Nicht anpassen Der Rückgang des LISP-Maschinenmarktes und der Ausfall der Computer der fünften Generation waren Fälle von teuren fortschrittlichen Produkten, die durch einfachere und billigere Alternativen überholt wurden. Dies passt zu der Definition einer Low-End-Trenntechnologie, wobei die LISP-Maschinenbauer marginalisiert werden. Expertensysteme wurden von CLIPS auf die neuen Desktop-Computer übertragen, so dass der Fall des LISP-Maschinenmarktes und der Fall von Expertensystemen streng genommen zwei separate Ereignisse sind. Dennoch wird als ein Grund für den KI-Winter der 1980er Jahre die Nichtanpassung an eine solche Veränderung des Außenrechnermilieus genannt. Argumente und Debatten über Vergangenheit und Zukunft von KI Mehrere Philosophen, kognitive Wissenschaftler und Informatiker haben spekuliert, wo KI gescheitert und was in seiner Zukunft liegt. Hubert Dreyfus betonte in der Vergangenheit fehlerhafte Annahmen der KI-Forschung und vorhersagte bereits 1966 richtig, dass die erste Welle der KI-Forschung die sehr öffentlichen Versprechen nicht erfüllen würde, die sie machte. Andere Kritiker wie Noam Chomsky haben argumentiert, dass KI in die falsche Richtung geleitet wird, zum Teil wegen seiner starken Abhängigkeit von statistischen Techniken. Chomskys Kommentare passen in eine größere Debatte mit Peter Norvig, die sich um die Rolle der statistischen Methoden in KI konzentriert. Der Austausch zwischen den beiden begann mit Kommentaren von Chomsky bei einem Symposium am MIT, zu dem Norvig eine Antwort schrieb. Siehe auch KI-Effekt Geschichte der künstlichen Intelligenz Software-Krise Hinweise Crevier, Daniel (1993,) KI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0-465-02997-3 Hendler, James (2007). " Wo sind alle intelligenten Agenten?".IEEE Intelligent Systems.22 (3:) 2–3.doi:10.1109/MIS.2007.62.Howe, J. (November 1994)."Künstliche Intelligenz an der Universität Edinburgh : eine Perspektive". Archiviert aus dem Original am 17. August 2007. Retrieved 30 August 2007.Kaplan, Andreas; Haenlein, Michael (2018). " Siri, Siri in meiner Hand, wer ist der Größte im Land? Auf die Interpretationen, Illustrationen und Implikationen der Künstlichen Intelligenz". Business Horizons. Business Horizons 62(1).62: 15–25.doi:10.1016/j.bushor.2018.08.004.Kurzweil, Ray (2005). "Die Singularität ist in der Nähe." Viking Press. Lighthill, Professor Sir James (1973). " Künstliche Intelligenz: Eine allgemeine Umfrage". Künstliche Intelligenz: ein Papiersymposium. Wissenschaftsforschungsrat.Minsky, Marvin; Papert, Seymour (1969). " Perceptrons: Eine Einführung in die Computational Geometry". Das MIT Drücken. McCorduck, Pamela (2004,) Maschinen, die denken (2. ed,.) Natick, MA: A. K. Peters, Ltd. ISBN 1-56881-205-1 NRC (1999)."Entwicklungen in Künstlicher Intelligenz". Förderung einer Revolution: Regierungsunterstützung für Computing Research. National Academy Press. Archiviert vom Original am 12. Januar 2008. Retrieved 30 August 2007.CS1 maint: bot: original URL Status unbekannt (link) Newquist, HP (1994). The Brain Makers: Genius, Ego und Greed In der Suche nach Maschinen, die denken.Macmillan/SAMS.ISBN 978-0-9885937-1-8.Russell, Stuart J.; Norvig, Peter (2003,) Künstliche Intelligenz: Ein moderner Ansatz (2. ed,.) Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2 Weitere Informationen Marcus, Gary, "I Human:? Forscher benötigen neue Möglichkeiten, künstliche Intelligenz von der natürlichen Art zu unterscheiden", Scientific American, Vol.316, No. 3 (März 2017,) pp.58–63 Mehrfachtests der künstlichen Intelligenz werden benötigt, weil "da es keinen einzigen Test der Leichtathletik gibt, kann es keinen ultimativen Test der Intelligenz geben". Ein solcher Test, eine "Construction Challenge", würde Wahrnehmung und körperliche Wirkung testen –"zwei wichtige Elemente des intelligenten Verhaltens, die vollständig vom ursprünglichen Turing-Test fehlten". Ein weiterer Vorschlag war, Maschinen die gleichen standardisierten Tests der Wissenschaft und anderen Disziplinen zu geben, die Schüler nehmen. Ein bisher ununterbrochener Stolperstein für künstliche Intelligenz ist eine Unfähigkeit für eine zuverlässige Disambiguation. "[V]irtual ist jeder Satz [der die Menschen erzeugen] mehrdeutig, oft auf vielfältige Weise". Ein prominentes Beispiel ist das "pronoun disambiguation Problem" genannt: eine Maschine hat keine Möglichkeit, zu bestimmen, wem oder was ein Pronomon in einem Satz - wie er, sie oder es - Referenten. Luke Muehlhauser (September 2016). " Was sollen wir aus früheren KI-Voraussagen lernen?". Open Philanthropy Project. Externe Links ComputerWorld Artikel (Februar 2005)AI Expert Newsletter (Januar 2005)"Wenn es funktioniert, ist es nicht KI: Ein kommerzieller Blick auf künstliche Intelligenz Startups" Patterns of Software - eine Sammlung von Essays von Richard P. Gabriel, darunter mehrere autobiografische Essays Review of `Künstliche Intelligenz: Eine allgemeine Umfrage von John McCarthy Andere Freddy II Robot Resources beinhaltet einen Link zu der 90-minütigen 1973 Kontroversen Debatte von der Royal Academy of Lighthill vs. Michie, McCarthy und Gregory in Reaktion auf Lighthills Bericht an die britische Regierung.