Ein Empfehlungssystem oder ein Empfehlungssystem (manchmal ersetzt System durch ein Synonym wie Plattform oder Motor), ist eine Unterklasse von Informationsfiltersystem, das versucht, die Bewertung oder Präferenz, die ein Benutzer einem Element geben würde vorherzusagen. Empfehler-Systeme werden in einer Vielzahl von Bereichen verwendet, mit allgemein anerkannten Beispielen, die in Form von Wiedergabelisten-Generatoren für Video- und Musikdienste, Produktempfehlungen für Online-Shops oder Content-Empfehler für Social Media-Plattformen und Open-Web-Inhalte-Empfehler. Diese Systeme können mit einem einzigen Eingang, wie Musik, oder mehreren Eingängen innerhalb und über Plattformen wie Nachrichten, Bücher und Suchanfragen arbeiten. Es gibt auch beliebte Empfehlungssysteme für bestimmte Themen wie Restaurants und Online-Dating. Weiterempfehlersysteme wurden entwickelt, um Forschungsartikel und Experten, Mitarbeiter und Finanzdienstleistungen zu erforschen. Übersicht Empfehler-Systeme verwenden in der Regel entweder oder beide kollaborative Filterung und inhaltliche Filterung (auch bekannt als der Persönlichkeits-basierte Ansatz), sowie andere Systeme wie wissensbasierte Systeme. Collaborative Filtering-Ansätze bauen ein Modell aus dem früheren Verhalten eines Benutzers (Vorhandene oder ausgewählte und/oder numerische Bewertungen dieser Elemente) sowie ähnliche Entscheidungen anderer Benutzer. Dieses Modell wird dann verwendet, um Elemente (oder Bewertungen für Elemente) vorherzusagen, an die der Benutzer ein Interesse haben kann. Inhaltsbasierte Filteransätze verwenden eine Reihe von diskreten, voreingestellten Merkmalen eines Gegenstands, um weitere Gegenstände mit ähnlichen Eigenschaften zu empfehlen. Aktuelle Empfehlungssysteme kombinieren typischerweise ein oder mehrere Ansätze in ein Hybridsystem. Die Unterschiede zwischen kollaborativer und inhaltlicher Filterung lassen sich durch den Vergleich von zwei frühen Musik-Empfehlungssystemen – Last.fm und Pandora Radio – zeigen. Last.fm erstellt eine Station von empfohlenen Songs, indem er beobachtet, auf welche Bands und einzelnen Tracks der Benutzer regelmäßig zugehört hat und diese gegen das Hörverhalten anderer Benutzer vergleicht. Last.fm wird Tracks spielen, die nicht in der Bibliothek des Benutzers erscheinen, sondern oft von anderen Benutzern mit ähnlichen Interessen gespielt werden. Da dieser Ansatz das Verhalten der Benutzer nutzt, ist er ein Beispiel für eine kollaborative Filtertechnik. Pandora verwendet die Eigenschaften eines Songs oder Künstlers (eine Untermenge der 400 Attribute, die vom Music Genome Project bereitgestellt werden) eine Station, die Musik mit ähnlichen Eigenschaften spielt. Benutzer-Feedback wird verwendet, um die Ergebnisse der Station zu verfeinern und bestimmte Attribute zu deemphasieren, wenn ein Benutzer einen bestimmten Song misst und andere Attribute betont, wenn ein Benutzer einen Song mag. Dies ist ein Beispiel für einen inhaltlichen Ansatz. Jede Art von System hat seine Stärken und Schwächen. Im obigen Beispiel erfordert Last.fm eine große Menge von Informationen über einen Benutzer, um genaue Empfehlungen zu treffen. Dies ist ein Beispiel für das Kaltstart-Problem und ist in kollaborativen Filtersystemen üblich. Während Pandora sehr wenig Informationen benötigt, um zu beginnen, ist es viel eingeschränkt im Umfang (zum Beispiel kann es nur Empfehlungen, die dem ursprünglichen Samen ähnlich sind). Empfehler-Systeme sind eine nützliche Alternative zu Suchalgorithmen, da sie Benutzern helfen, Elemente zu entdecken, die sie möglicherweise nicht anders gefunden haben. Zu beachten sind häufig die Implementierung von Empfehlungssystemen mit Suchmaschinen, die nicht-traditionelle Daten indexieren. Die Empfehlungssysteme wurden erstmals 1990 von Jussi Karlgren an der Columbia University in einem technischen Bericht als "digitales Bücherregal" erwähnt und in technischen Berichten und Publikationen ab 1994 von Jussi Karlgren, dann bei SICS, und Forschungsgruppen unter der Leitung von Pattie Maes am MIT, Will Hill bei Bellcore und Paul Resnick, auch am MIT, dessen Arbeit mit GroupLens Systems Award 2010 ausgezeichnet wurde, durchgeführt. Montaner lieferte den ersten Überblick über Empfehlungssysteme aus einer intelligenten Agentenperspektive. Adomavicius lieferte einen neuen, alternativen Überblick über Empfehlungssysteme. Herlocker bietet einen weiteren Überblick über Bewertungstechniken für Empfehlungssysteme und Beel et al. die Probleme der Offline-Auswertungen diskutiert. Beel et al.have lieferte auch Literaturerhebungen über verfügbare Forschungspapierreferatsysteme und bestehende Herausforderungen. Die Fragestellersysteme stehen im Mittelpunkt mehrerer erteilter Patente. Ansätze Kooperationsfilterung Ein Ansatz für das Design von Empfehlungssystemen, die einen breiten Einsatz haben, ist eine kollaborative Filterung. Die kollaborative Filterung basiert auf der Annahme, dass Menschen, die in der Vergangenheit vereinbart haben, in der Zukunft zustimmen werden, und dass sie ähnliche Arten von Gegenständen mögen, wie sie in der Vergangenheit mochten. Das System generiert Empfehlungen, die nur Informationen über Ratingprofile für verschiedene Benutzer oder Elemente verwenden. Durch die Lokalisierung von Peer-Nutzern/Etiketten mit einer Rating-Geschichte ähnlich dem aktuellen Benutzer oder Element, erzeugen sie Empfehlungen mit dieser Nachbarschaft. Kollaborative Filterverfahren werden als Memory-basierte und modellbasierte eingestuft. Ein bekanntes Beispiel für speicherbasierte Ansätze ist der benutzerbasierte Algorithmus, während das von modellbasierten Ansätzen der Kernel-Mapping-Empfehler ist. Ein wesentlicher Vorteil des kollaborativen Filteransatzes besteht darin, dass er sich nicht auf maschinenanalysierbare Inhalte verlässt und daher in der Lage ist, komplexe Gegenstände wie Filme genau zu empfehlen, ohne dass ein Verständnis des Produkts selbst erforderlich ist. Viele Algorithmen wurden bei der Messung der Benutzerähnlichkeit oder Artikelähnlichkeit in Empfehlungssystemen verwendet. Zum Beispiel der k-nearest Nachbar (k-NN) Ansatz und die Pearson Correlation, wie zuerst von Allen umgesetzt. Beim Aufbau eines Modells aus dem Verhalten eines Benutzers wird häufig zwischen expliziten und impliziten Formen der Datenerhebung unterschieden. Beispiele für die explizite Datenerhebung sind: Wenn Sie einen Benutzer bitten, einen Artikel auf einer Schiebewaage zu bewerten. Einen Benutzer zu suchen. Wenn Sie einen Benutzer bitten, eine Sammlung von Artikeln von der Lieblings bis zum wenigsten Lieblings zu ordnen. Geben Sie zwei Artikel an einen Benutzer und bitten ihn / sie, die bessere von ihnen zu wählen. Wenn Sie einen Benutzer bitten, eine Liste von Gegenständen zu erstellen, die er mag (siehe Rocchio Klassifizierung oder andere ähnliche Techniken). Beispiele für die implizite Datenerhebung sind: Beobachtung der Elemente, die ein Benutzer in einem Online-Shop ansieht. Analyse von Artikel/Benutzer-Anzeigezeiten. Halten Sie eine Aufzeichnung der Artikel, die ein Benutzer online kauft. Erhalten einer Liste von Elementen, die ein Benutzer auf seinen Computer gehört oder beobachtet hat. Analyse des sozialen Netzwerks des Nutzers und der Entdeckung ähnlicher Vorlieben und Abneigungen. Kollaborative Filteransätze leiden oft unter drei Problemen: Kaltstart, Skalierbarkeit und Sparsamkeit. Kaltstart: Für einen neuen Benutzer oder Artikel gibt es nicht genug Daten, um genaue Empfehlungen zu treffen. Hinweis: Eine häufig implementierte Lösung für dieses Problem ist der Multi-armed Bandit-Algorithmus. Skalierbarkeit: In vielen Umgebungen, in denen diese Systeme Empfehlungen machen, gibt es Millionen von Benutzern und Produkten. So ist zur Berechnung von Empfehlungen oft eine große Menge Rechenleistung erforderlich. Sparsity: Die Anzahl der auf großen E-Commerce-Seiten verkauften Artikel ist extrem groß. Die aktivsten Benutzer haben nur eine kleine Teilmenge der gesamten Datenbank bewertet. So haben auch die beliebtesten Artikel sehr wenige Bewertungen. Eines der bekanntesten Beispiele für kollaborative Filterung ist item-to-item kollaborative Filterung (Menschen, die x auch kaufen y), ein Algorithmus, der von Amazon.coms Empfehlungssystem populär gemacht wird. Viele soziale Netzwerke nutzten ursprünglich eine kollaborative Filterung, um neue Freunde, Gruppen und andere soziale Verbindungen zu empfehlen, indem sie das Netzwerk von Verbindungen zwischen einem Benutzer und ihren Freunden untersuchen. Die kollaborative Filterung wird noch als Teil von Hybridsystemen eingesetzt. Inhaltsbasierte Filterung Ein weiterer gemeinsamer Ansatz bei der Konzeption von Empfehlungssystemen ist die inhaltliche Filterung. Inhaltsbasierte Filtermethoden basieren auf einer Beschreibung des Artikels und einem Profil der Präferenzen des Nutzers. Diese Methoden sind am besten geeignet für Situationen, in denen bekannte Daten auf einem Objekt (Name, Ort, Beschreibung, etc.) aber nicht auf dem Benutzer. Content-basierte Empfehlungshilfen behandeln Empfehlung als benutzerspezifisches Klassifikationsproblem und lernen einen Klassifikator für die Vorlieben und Abneigungen des Benutzers basierend auf den Merkmalen eines Produkts. In diesem System werden Schlüsselwörter verwendet, um die Elemente zu beschreiben und ein Benutzerprofil wird erstellt, um die Art des Elements anzuzeigen, den dieser Benutzer mag. Mit anderen Worten, diese Algorithmen versuchen, Elemente zu empfehlen, die denen ähnlich sind, die ein Benutzer in der Vergangenheit mochte oder in der Gegenwart untersucht. Es basiert nicht auf einem Benutzer-Anmeldemechanismus, um dieses oft temporäre Profil zu erzeugen. Insbesondere werden verschiedene Kandidaten-Elemente mit Gegenständen verglichen, die zuvor vom Benutzer bewertet wurden, und die Best-matching-Elemente werden empfohlen. Dieser Ansatz hat seine Wurzeln in der Informationswiederaufnahme und Informationsfilterung Forschung. Um ein Benutzerprofil zu erstellen, konzentriert sich das System meist auf zwei Arten von Informationen: 1.Ein Modell der Präferenz des Benutzers. 2.Eine Geschichte der Interaktion des Benutzers mit dem Empfehlungssystem. Grundsätzlich verwenden diese Methoden ein Elementprofil (d.h. eine Reihe von diskreten Attributen und Merkmalen), das den Gegenstand innerhalb des Systems charakterisiert. Um die Merkmale der Elemente im System abzustrahieren, wird ein Objektpräsentationsalgorithmus angewendet. Ein weit verbreiteter Algorithmus ist die tf-idf-Darstellung (auch Vektorraumdarstellung genannt). Das System erstellt ein inhaltliches Profil von Benutzern basierend auf einem gewichteten Vektor von Elementmerkmalen. Die Gewichte bezeichnen die Bedeutung jeder Funktion für den Benutzer und können aus individuell bewerteten Inhaltsvektoren mit einer Vielzahl von Techniken berechnet werden. Einfache Ansätze verwenden die Durchschnittswerte des bewerteten Objektvektors, während andere ausgeklügelte Methoden maschinelle Lerntechniken wie Bayesian Classifiers, Clusteranalyse, Entscheidungsbäume und künstliche neuronale Netzwerke verwenden, um die Wahrscheinlichkeit zu schätzen, dass der Benutzer den Artikel mag. Ein zentrales Problem bei der inhaltlichen Filterung ist, ob das System in der Lage ist, Nutzerpräferenzen von Nutzeraktionen bezüglich einer Inhaltsquelle zu erlernen und über andere Inhaltstypen zu nutzen. Wenn das System darauf beschränkt ist, Inhalte der gleichen Art wie der Benutzer bereits zu empfehlen, ist der Wert aus dem Empfehlungssystem deutlich geringer als wenn andere Inhaltstypen von anderen Dienstleistungen empfohlen werden können. Zum Beispiel ist die Empfehlung von Nachrichtenartikeln auf der Grundlage des Surfens von Nachrichten nützlich, aber wäre viel nützlicher, wenn Musik, Videos, Produkte, Diskussionen usw. aus verschiedenen Dienstleistungen auf der Grundlage von Nachrichten-Browsing empfohlen werden können. Um dies zu überwinden, verwenden die meisten Content-basierten Empfehlungssysteme jetzt einige Form von Hybrid-System. Inhaltsbasierte Empfehlungssysteme können auch Meinungs-basierte Empfehlungssysteme umfassen. In einigen Fällen ist es den Nutzern erlaubt, die Textüberprüfung oder das Feedback zu den Artikeln zu hinterlassen. Diese benutzergenerierten Texte sind implizite Daten für das Empfehlungssystem, da sie potenziell reich an Ressourcen sowohl von Feature/Aspekten des Artikels sind, als auch von der Bewertung/Sentiment der Benutzer auf den Gegenstand. Die aus den benutzergenerierten Bewertungen gewonnenen Eigenschaften sind verbesserte Metadaten von Produkten, da sie auch Aspekte des Produkts wie Metadaten widerspiegeln, werden extrahierte Funktionen von den Benutzern häufig betroffen. Sentiments, die aus den Bewertungen extrahiert werden, können als Bewertungen der Nutzer auf den entsprechenden Features angesehen werden. Populäre Ansätze von Meinungs-basiertem Empfehlungssystem verwenden verschiedene Techniken wie Textabbau, Informationsabruf, Stimmungsanalyse (siehe auch Multimodale Stimmungsanalyse) und Deep Learning. Sitzungsbasierte Empfehlungssysteme Diese Empfehlungssysteme nutzen die Interaktionen eines Benutzers innerhalb einer Sitzung, um Empfehlungen zu generieren. Session-basierte Empfehlungssysteme werden bei Youtube und Amazon eingesetzt. Diese sind besonders nützlich, wenn die Geschichte (z.B. vergangene Klicks, Einkäufe) eines Benutzers in der aktuellen Benutzersitzung nicht oder nicht relevant ist. Domains, in denen sitzungsbasierte Empfehlungen besonders relevant sind, umfassen Video, E-Commerce, Reisen, Musik und mehr. Die meisten Instanzen von sitzungsbasierten Empfehlungssystemen verlassen sich auf die Abfolge neuer Interaktionen innerhalb einer Sitzung, ohne dass zusätzliche Details (historische, demografische) des Benutzers erforderlich sind. Techniken für sitzungsbasierte Empfehlungen basieren hauptsächlich auf generativen sequentiellen Modellen wie Recurrent Neural Networks, Transformers und anderen Deep Learning-basierten Ansätzen Verstärkungslernen für Empfehlungssysteme Das Empfehlungsproblem ist als besonderes Beispiel eines Verstärkungslernproblems zu sehen, wobei der Benutzer die Umgebung ist, auf die der Agent, das Empfehlungssystem einwirkt, um eine Belohnung zu erhalten, beispielsweise einen Klick oder einen Eingriff durch den Benutzer. Ein Aspekt der Stärkung des Lernens, der im Bereich der Empfehlungssysteme von besonderer Bedeutung ist, ist die Tatsache, dass die Modelle oder Richtlinien durch eine Belohnung für den Empfehlungsbeauftragten erlernt werden können. Dies ist im Gegensatz zu herkömmlichen Lerntechniken, die sich auf beaufsichtigte Lernansätze stützen, die weniger flexibel sind, können die Bewehrung Lernempfehlungstechniken dazu beitragen, Modelle zu trainieren, die direkt auf Maßzahlen des Engagements und des Nutzerinteresses optimiert werden können. Multi-Kriterien-Empfehlersysteme Multi-Kriterien-Empfehlersysteme (MCRS) können als Empfehlungssysteme definiert werden, die Präferenzinformationen nach mehreren Kriterien einschließen. Anstelle der Entwicklung von Empfehlungstechniken auf Basis eines einzigen Kriteriumswertes, der allgemeinen Präferenz des Benutzers u für den Gegenstand i, versuchen diese Systeme, eine Bewertung für unexplorierte Elemente von u vorherzusagen, indem sie Präferenzinformationen über mehrere Kriterien ausnutzen, die diesen allgemeinen Präferenzwert beeinflussen. Mehrere Forscher nähern sich MCRS als Multi-Kriterien-Entscheidungs-Problem (MCDM) und wenden MCDM-Methoden und Techniken an, um MCRS-Systeme zu implementieren. Siehe dieses Kapitel für eine erweiterte Einführung. Risikobereite Empfehlungssysteme Die meisten bestehenden Ansätze für Empfehlungssysteme konzentrieren sich auf die Empfehlung der relevantesten Inhalte für Nutzer, die kontextbezogene Informationen verwenden, jedoch nicht das Risiko der Störung des Benutzers mit unerwünschten Benachrichtigungen berücksichtigen. Es ist wichtig, das Risiko zu prüfen, den Benutzer zu ärgern, indem er Empfehlungen unter bestimmten Umständen z.B. während eines professionellen Treffens, frühmorgens oder spät in der Nacht drängt. Daher hängt die Leistung des Empfehlungssystems zum Teil davon ab, inwieweit es das Risiko in den Empfehlungsprozess eingebunden hat. Eine Möglichkeit, dieses Problem zu verwalten, ist DRARS, ein System, das die kontextbezogene Empfehlung als Bandit-Problem modelliert. Dieses System kombiniert eine Content-basierte Technik und einen Kontext-Bandit-Algorithmus. Mobile Empfehlungssysteme Mobile Empfehlungssysteme nutzen Internet-Zugriff auf Smartphones, um personalisierte, kontextsensitive Empfehlungen anzubieten. Dies ist ein besonders schwieriger Forschungsbereich, da mobile Daten komplexer sind als Daten, mit denen sich die Empfehlungssysteme oft auseinandersetzen müssen. Es ist heterogen, laut, erfordert räumliche und zeitliche Autokorrelation und hat Validierungs- und Allgemeinheitsprobleme. Es gibt drei Faktoren, die die mobilen Empfehlungssysteme und die Genauigkeit der Vorhersageergebnisse beeinflussen könnten: der Kontext, die Empfehlungsmethode und die Privatsphäre. Darüber hinaus leiden mobile Empfehlungssysteme an einem Transplantationsproblem – Empfehlungen können nicht in allen Regionen gelten (z.B. wäre es unklug, ein Rezept in einem Bereich zu empfehlen, in dem alle Zutaten nicht verfügbar sind). Ein Beispiel für ein mobiles Empfehlungssystem sind die Ansätze von Unternehmen wie Uber und Lyft, um Fahrrouten für Taxifahrer in einer Stadt zu generieren. Dieses System verwendet GPS-Daten der Routen, die Taxifahrer während der Arbeit nehmen, die Ort (Länge und Länge,) Zeitstempel und Betriebsstatus (mit oder ohne Passagiere). Es verwendet diese Daten, um eine Liste von Pickup-Punkte entlang einer Strecke zu empfehlen, mit dem Ziel, Belegungszeiten und Gewinne zu optimieren. Hybride Empfehlungssysteme Die meisten Empfehlungssysteme nutzen nun einen hybriden Ansatz, der die kollaborative Filterung, inhaltliche Filterung und andere Ansätze kombiniert. Es gibt keinen Grund, warum mehrere verschiedene Techniken desselben Typs nicht hybridisiert werden konnten. Hybride Ansätze können auf verschiedene Weise umgesetzt werden: durch die getrennte Erstellung von inhaltlichen und kollaborativen Prognosen und anschließende Kombination; durch die Hinzufügung von inhaltlichen Fähigkeiten zu einem kollaborativen Ansatz (und umgekehrt) oder durch die Einbindung der Ansätze in ein Modell (siehe eine vollständige Überprüfung der Empfehlungssysteme). Mehrere Studien, die die Leistung des Hybriden empirisch mit den reinen kollaborativen und inhaltlichen Methoden vergleichen und zeigten, dass die Hybridmethoden genauere Empfehlungen liefern können als reine Ansätze. Diese Methoden können auch verwendet werden, um einige der häufigsten Probleme in Empfehlungssystemen wie Kaltstart und Sparsity-Problem zu überwinden, sowie den Wissens Engineering Engpass in wissensbasierten Ansätzen. Netflix ist ein gutes Beispiel für den Einsatz von Hybrid-Empfehlungssystemen. Die Website gibt Empfehlungen, indem sie die Beobachtungs- und Suchgewohnheiten von ähnlichen Benutzern (d.h. kollaborative Filterung) sowie Filmen, die Eigenschaften mit Filmen teilen, die ein Benutzer hoch bewertet hat (content-based filtering). Einige Hybridisierungstechniken umfassen: Gewicht: Kombinieren Sie die Punktzahl der verschiedenen Empfehlungskomponenten numerisch. Schalter: Auswahl unter Empfehlungskomponenten und Anwendung der ausgewählten. Mixed: Empfehlungen verschiedener Empfehlungsträger werden gemeinsam vorgestellt, um die Empfehlung zu geben. Funktion Kombination: Merkmale, die aus verschiedenen Wissensquellen abgeleitet werden, werden zusammengeführt und einem einzigen Empfehlungsalgorithmus gegeben. Feature Augmentation: Eingabe einer Funktion oder eines Satzes von Funktionen, die dann Teil der Eingabe zur nächsten Technik ist. Cascade:Recommenders werden strenge Priorität eingeräumt, wobei die untere Priorität die Krawatten in der Scoring der höheren bricht. Meta-Level: Eine Empfehlungstechnik wird angewendet und produziert eine Art Modell, das dann die Eingabe der nächsten Technik ist. Der Netflix-Preis Eines der Ereignisse, die die Forschung in den Empfehlungssystemen erregte, war der Netflix-Preis. Von 2006 bis 2009, Netflix gesponserte einen Wettbewerb, bietet einen großen Preis von $1,000,000 für das Team, die einen angebotenen Datensatz von über 100 Millionen Film-Ratings und Rückkehr-Empfehlungen, die 10% genauer als die von dem bestehenden Empfehlungssystem des Unternehmens angeboten. Dieser Wettbewerb erregte die Suche nach neuen und genaueren Algorithmen. Am 21. September 2009 erhielt das Team von BellKor's Pragmatic Chaos den großen Preis von 1.000.000 US$. Der genaueste Algorithmus im Jahr 2007 verwendet eine Ensemblemethode von 107 verschiedenen algorithmischen Ansätzen, gemischt in eine einzige Vorhersage. Wie von den Gewinnern angegeben, Bell et al.: Prädiktive Genauigkeit wird wesentlich verbessert, wenn mehrere Prädiktoren gemischt werden. Unsere Erfahrung ist, dass sich die meisten Anstrengungen darauf konzentrieren sollten, wesentlich verschiedene Ansätze zu entwickeln, anstatt eine einzige Technik zu verfeinern. Folglich ist unsere Lösung ein Ensemble vieler Methoden. Viele Vorteile, die auf das Web aufgrund des Netflix-Projekts angewiesen sind. Einige Teams haben ihre Technologie genommen und sie auf andere Märkte angewendet. Einige Mitglieder des Teams, die den zweiten Platz beendeten, gründeten Gravity R&D, eine Empfehlungs-Engine, die in der RecSys Community aktiv ist. 4-Tell, Inc. erstellte eine Netflix-Projekt-erweiterte Lösung für E-Commerce-Websites. Um den Datensatz, den Netflix für den Netflix-Preis-Wettbewerb anbietet, entstand eine Reihe von Datenschutzproblemen. Obwohl die Datensätze anonymisiert wurden, um die Privatsphäre der Kunden zu erhalten, konnten 2007 zwei Forscher der University of Texas einzelne Nutzer identifizieren, indem sie die Datensätze mit Filmbewertungen auf der Internet Movie Database übereinstimmen. Im Dezember 2009 verklagte ein anonymer Netflix-Nutzer Netflix in Doe v. Netflix, der behauptete, dass Netflix gegen die US-Messengesetze und das Video-Datenschutzgesetz verstoßen hatte, indem er die Datensätze veröffentlichte.Dies sowie Bedenken der Bundeshandelskommission führten 2010 zu einer Streichung eines zweiten Netflix-Preiswettbewerbs. Durchführungsmaßnahmen Die Bewertung ist wichtig, um die Wirksamkeit von Empfehlungsalgorithmen zu bewerten. Um die Wirksamkeit von Empfehlungssystemen zu messen und verschiedene Ansätze zu vergleichen, stehen drei Arten von Bewertungen zur Verfügung: Anwenderstudien, Online-Bewertungen (A/B-Tests) und Offline-Bewertungen. Die gebräuchlichen Metriken sind der mittlere quadratische Fehler und der wurzelmittlere quadratische Fehler, der im Netflix-Preis verwendet wurde. Die Informationsabrufmetriken wie Präzision und Rückruf oder DCG sind nützlich, um die Qualität einer Empfehlungsmethode zu bewerten. Diversität, Neuheit und Berichterstattung werden auch als wichtige Aspekte bei der Bewertung betrachtet. Viele der klassischen Bewertungsmaßnahmen sind jedoch sehr kritisiert. Die Bewertung der Leistung eines Empfehlungsalgorithmus auf einem festen Testdatensatz wird immer äußerst schwierig sein, da es nicht möglich ist, die Reaktionen der realen Nutzer auf die Empfehlungen genau vorherzusagen. Somit wird jede Metrik, die die Wirksamkeit eines Algorithmus in Offline-Daten berechnet, ungenau sein. Benutzerstudien sind ziemlich klein. Einige Dutzend oder Hunderte von Nutzern werden Empfehlungen vorgestellt, die durch verschiedene Empfehlungsansätze erstellt werden, und dann beurteilen die Nutzer, welche Empfehlungen am besten sind. In A/B-Tests werden Empfehlungen für typischerweise Tausende von Benutzern eines realen Produktes gezeigt, und das Empfehlungssystem wählt zufällig mindestens zwei verschiedene Empfehlungsansätze zur Erstellung von Empfehlungen. Die Wirksamkeit wird mit impliziten Effektivitätsmaßen wie Conversion Rate oder Click-Through Rate gemessen. Offline-Auswertungen basieren auf historischen Daten, z.B. einem Datensatz, der Informationen darüber enthält, wie Nutzer zuvor Filme bewertet haben. Die Wirksamkeit von Empfehlungsansätzen wird dann gemessen, basierend darauf, wie gut ein Empfehlungsansatz die Bewertungen der Nutzer im Datensatz vorhersagen kann. Während eine Bewertung ein expliziter Ausdruck ist, ob ein Benutzer einen Film mochte, sind solche Informationen nicht in allen Domänen verfügbar. Zum Beispiel, in der Domäne der Zitationsempfehlungssysteme, Benutzer in der Regel keine Zitation oder empfohlenen Artikel. In solchen Fällen können Offline-Auswertungen implizite Maßnahmen der Effektivität nutzen. Beispielsweise kann davon ausgegangen werden, dass ein Empfehlungssystem wirksam ist, das möglichst viele Artikel empfehlen kann, die in der Referenzliste eines Forschungsartikels enthalten sind. Diese Art von Offline-Bewertungen wird jedoch von vielen Forschern kritisch betrachtet. So wurde gezeigt, dass die Ergebnisse von Offline-Auswertungen eine geringe Korrelation mit den Ergebnissen aus Anwenderstudien oder A/B-Tests aufweisen. Ein für die Offline-Auswertung populärer Datensatz wurde gezeigt, dass duplizierte Daten enthalten und somit zu falschen Schlussfolgerungen bei der Auswertung von Algorithmen führen. Oft korrelieren die Ergebnisse so genannter Offline-Auswertungen nicht mit tatsächlich bewerteter Nutzerzufriedenheit. Dies liegt wahrscheinlich daran, dass Offline-Training stark in Richtung auf die hoch erreichbaren Elemente vorgespannt ist und Offline-Testdaten durch die Ausgänge des Online-Empfehlungsmoduls stark beeinflusst werden. Die Forscher haben den Schluss gezogen, dass die Ergebnisse der Offline-Bewertungen kritisch betrachtet werden sollten. Über die Genauigkeit hinaus In der Regel geht es um die Suche nach den besten Empfehlungsalgorithmen. Es gibt jedoch eine Reihe von Faktoren, die auch wichtig sind. Diversity – Nutzer neigen dazu, mit Empfehlungen zufriedener zu sein, wenn es eine höhere Intra-Listen-Diversität gibt, z.B. Gegenstände verschiedener Künstler. Beharrlichkeit des Fragestellers – In einigen Situationen ist es effektiver, Empfehlungen neu zu zeigen oder die Nutzer neu zu bewerten, als neue Elemente anzuzeigen. Dafür gibt es mehrere Gründe. Benutzer können Elemente ignorieren, wenn sie zum ersten Mal gezeigt werden, zum Beispiel, weil sie keine Zeit hatten, die Empfehlungen sorgfältig zu überprüfen. Datenschutz – Empfehlersysteme müssen sich in der Regel mit Datenschutzbedenken auseinandersetzen, weil Benutzer sensible Informationen offenbaren müssen. Die Erstellung von Benutzerprofilen mit kollaborativer Filterung kann aus Sicht der Privatsphäre problematisch sein. Viele europäische Länder haben eine starke Kultur der Privatsphäre der Daten, und jeder Versuch, jedes Niveau der Benutzerprofilierung einzuführen, kann zu einer negativen Kundenreaktion führen. Viele Forschungen wurden in diesem Bereich zu laufenden Datenschutzproblemen durchgeführt. Der Netflix-Preis ist besonders bemerkenswert für die detaillierten persönlichen Informationen, die in seinem Datensatz veröffentlicht werden. Ramakrishnan et al.have hat einen umfangreichen Überblick über die Trade-offs zwischen Personalisierung und Privatsphäre geführt und festgestellt, dass die Kombination von schwachen Bindungen (eine unerwartete Verbindung, die serendipitöse Empfehlungen liefert) und andere Datenquellen verwendet werden können, um Identitäten von Nutzern in einem anonymisierten Datensatz zu erkennen. Nutzerdemografie – Beel et al.found, dass Nutzerdemografien beeinflussen können, wie zufriedene Nutzer mit Empfehlungen sind. In ihrem Beitrag zeigen sie, dass ältere Nutzer eher an Empfehlungen interessiert sind als jüngere Nutzer. Robustheit – Wenn Benutzer am Empfehlungssystem teilnehmen können, muss das Problem des Betrugs angesprochen werden. Serendipity – Serendipity ist ein Maß für "wie überraschend die Empfehlungen sind". Zum Beispiel könnte ein Empfehlungssystem, das Milch an einen Kunden in einem Lebensmittelgeschäft empfiehlt, perfekt genau sein, aber es ist keine gute Empfehlung, weil es ein offensichtliches Produkt für den Kunden zu kaufen ist. ["Serenditipity] dient zwei Zwecken: Erstens, die Chance, dass Benutzer Interesse verlieren, weil die Wahl-Set zu gleichmäßig abnimmt. Zweitens werden diese Elemente benötigt, um Algorithmen zu lernen und sich zu verbessern". Trust – Ein Empfehlungssystem ist für einen Benutzer von geringem Wert, wenn der Benutzer dem System nicht vertraut. Vertrauen kann durch ein Empfehlungssystem gebaut werden, indem es erklärt, wie es Empfehlungen generiert, und warum es einen Artikel empfiehlt. Labelling – Benutzerzufriedenheit mit Empfehlungen kann durch die Kennzeichnung der Empfehlungen beeinflusst werden. So waren in der zitierten Studie Click-Through Rate (CTR) für Empfehlungen, die als Sponsored bezeichnet wurden, niedriger (CTR = 5,93%) als CTR für identische Empfehlungen, die als Organic markiert wurden (CTR = 8,86%). In dieser Studie wurden Empfehlungen ohne Label am besten durchgeführt (CTR=9.87%). Reproduzierbarkeits-Empfehler-Systeme sind schwer zu bewerten offline, mit einigen Forschern behaupten, dass dies zu einer Reproduzierbarkeitskrise in Empfehlungssystemen Publikationen geführt hat. Eine kürzliche Erhebung über eine kleine Anzahl ausgewählter Publikationen, die auf das Top-k-Empfehlungsproblem, das in den Top-Konferenzen (SIGIR, KDD, WWW, RecSys, IJCAI) veröffentlicht wurde, Anwendung finden, hat gezeigt, dass im Durchschnitt weniger als 40 % der Artikel von den Autoren der Umfrage wiedergegeben werden konnten, wobei in einigen Konferenzen nur 14% zu verzeichnen waren. Insgesamt identifizieren die Studien 26 Artikel, nur 12 von ihnen könnten von den Autoren reproduziert werden und 11 von ihnen könnten durch viel ältere und einfachere richtig abgestimmte Basislinien auf Offline-Bewertungsmetriken übertroffen werden. Die Artikel zeigen auch eine Reihe potenzieller Probleme im heutigen Forschungsstipendium und fordern eine verbesserte wissenschaftliche Praxis in diesem Bereich. Ein ähnliches Papier derselben Gruppe wurde auf Sequenz-Aware-Empfehlungssystemen veröffentlicht. Neuere Arbeiten zur Benchmarking einer Reihe von gleichen Methoden kamen zu qualitativ sehr unterschiedlichen Ergebnissen, wobei sich neuronale Methoden als eine der besten Methoden erwiesen haben. Deep Learning und neurale Methoden für Empfehlungssysteme wurden in den Gewinnlösungen in mehreren neueren Empfehlungssystemen, WSDM, RecSys Challenge, eingesetzt. Darüber hinaus sind neuronale und tiefe Lernmethoden in der Industrie weit verbreitet, wo sie umfassend getestet werden. Das Thema Reproduzierbarkeit ist in Empfehlungssystemen nicht neu. Bis 2011 kritisierte Ekstrand, Konstan, et al., dass "es derzeit schwierig ist, die Forschungsergebnisse der Empfehlungssysteme zu reproduzieren und zu erweitern", und dass Auswertungen "nicht konsequent behandelt werden". Konstan und Adomavicius kommen zu dem Schluss, dass "die Forschungsgemeinschaft von Asker Systems einer Krise gegenübersteht, in der eine beträchtliche Anzahl von Papieren Ergebnisse zeigt, die wenig zum kollektiven Wissen beitragen [...] oft, weil die Forschung nicht die [...] Bewertung richtig beurteilt werden und somit sinnvolle Beiträge leisten kann." Infolgedessen kann viel Forschung über Empfehlungssysteme als nicht reproduzierbar angesehen werden. Daher finden die Betreiber von Empfehlungssystemen in der aktuellen Forschung wenig Hinweise auf die Beantwortung der Frage, welche Empfehlungsansätze für die Verwendung in einem Empfehlungssystem herangehen. Said & Bellogín führte eine Studie über auf dem Gebiet veröffentlichte Papiere durch und bewertete einige der beliebtesten Frameworks für Empfehlung und fand große Inkonsistenzen in Ergebnissen, auch wenn die gleichen Algorithmen und Datensätze verwendet wurden. Einige Forscher zeigten, dass kleinere Variationen in den Empfehlungsalgorithmen oder Szenarien zu starken Veränderungen der Wirksamkeit eines Empfehlungssystems führten. Sie kommen zu dem Schluss, dass sieben Maßnahmen notwendig sind, um die aktuelle Situation zu verbessern: "(1) Umfrage andere Forschungsfelder und von ihnen lernen, (2) finden ein gemeinsames Verständnis der Reproduzierbarkeit, (3) identifizieren und verstehen die Determinanten, die die Reproduzierbarkeit beeinflussen, (4) führen umfassendere Experimente (5) modernisieren Publikationspraktiken, (6) fördern die Entwicklung und Nutzung von Empfehlungsrahmen, und (7) erstellen Best-Practice-Richtlinien für die Empfehlungs-Systemforschung." Siehe auch Referenzen Weiter lesen BooksKim Falk (Januar 2019) Praktische Fragebögen, Manning Publications, ISBN 9781617292705 Bharat Bhasker; K. Srikumar (2010). E-Commerce.CUP.ISBN 978-0-07-068067-8.Archiviert vom Original am 2010-09-01. Francesco Ricci; Lior Rokach; Bracha Shapira; Paul B. Kantor, eds. (2011). Empfehlen Systems Handbook.Springer.ISBN 978-0-387-85819-7.Bracha Shapira; Lior Rokach (Juni 2012). Building Effective Asker Systems.ISBN 978-1-4419-0047-0.Archiviert vom Original am 2014-05-01. Dietmar Jannach; Markus Zanker; Alexander Felfernig; Gerhard Friedrich (2010). Empfehlungssysteme:An Einführung.CUP.ISBN 978-0-521-49336-9.Archiviert aus dem Original auf 2015-08-31. Wissenschaftliche Artikel Prem Melville, Raymond J. Mooney und Ramadass Nagarajan. (2002)Content-Boosted Collaborative Filtering for Improved Recommendations. Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002,) S.187–192, Edmonton, Kanada, Juli 2002. Meyer, Frank (2012)." Empfehlungssysteme in industriellen Kontexten".arXiv:1203.4487 [cs.IR].Bouneffouf, Djallel (2012,) "Nach den Interessen des Nutzers an Mobile Context-Aware-Empfehlersystemen: The Hybrid-e-Graddy Algorithm", Mitteilungen der 2012 26th International Conference on Advanced Information Networking and Applications Workshops (PDF, Science) Externe Links Robert M. Bell; Jim Bennett; Yehuda Koren & Chris Volinsky (Mai 2009). "Der Million Dollar Programming Prize". IEEE Spectrum. Archiviert aus dem Original am 2009-05-11. Retrieved 2018-12-10. Hangartner, Rick. "Was ist die Fragestellerindustrie?" MSearchGroove, 17. Dezember 2007.ACM Konferenz zu Empfehlen Systems Recsys Gruppe auf Politecnico di Milano Data Science: Daten zu Insights vom MIT (Recommendation Systems)