Im maschinellen Lernen ist Backpropagation (backprop, BP) ein weit verbreiteter Algorithmus zur Ausbildung von Feedforward-Neural-Netzwerken. Bei anderen künstlichen neuronalen Netzen (ANNs) und für Funktionen im Allgemeinen existieren Verallgemeinerungen der Backpropagation. Diese Algorithmenklassen werden alle allgemein als Backpropagation bezeichnet". Bei der Anbringung eines neuronalen Netzes berechnet die Backpropagation den Gradienten der Verlustfunktion in Bezug auf die Gewichte des Netzes für ein einzelnes Ein-Ausgangsbeispiel und macht so effizient, im Gegensatz zu einer naiven direkten Berechnung des Gradienten gegenüber jedem Gewicht einzeln. Diese Effizienz macht es möglich, Gradientenmethoden zum Training von mehrschichtigen Netzwerken zu verwenden, Gewichte zu aktualisieren, um Verlust zu minimieren; Gradientenabstieg oder Varianten wie stochastische Gradientenabstieg werden häufig verwendet. Der Backpropagationsalgorithmus arbeitet durch Berechnung des Gradienten der Verlustfunktion gegenüber jedem Gewicht durch die Kettenregel, Berechnung der Gradienten-Einschicht zu einem Zeitpunkt, iterieren von der letzten Schicht zurück, um redundante Berechnungen von Zwischenbegriffen in der Kettenregel zu vermeiden; dies ist ein Beispiel für dynamische Programmierung. Der Begriff Backpropagation bezieht sich ausschließlich auf den Algorithmus zur Berechnung des Gradienten, nicht wie der Gradient verwendet wird; der Begriff wird jedoch häufig lose verwendet, um auf den gesamten Lernalgorithmus zu verweisen, einschließlich der Verwendung des Gradienten, wie z.B. durch stochastische Gradientenabstieg. Backpropagation verallgemeinert die Gradientenberechnung in der Delta-Regel, die einschichtige Version der Backpropagation ist, und wird wiederum durch automatische Differenzierung verallgemeinert, wobei Backpropagation ein besonderer Fall der Reverse Akkumulation ist (oder "Reverse Mode"). Der Begriff Backpropagation und seine allgemeine Nutzung in neuronalen Netzwerken wurde in Rumelhart, Hinton & Williams (1986a) bekannt gegeben, dann in Rumelhart, Hinton & Williams (1986b) aufgearbeitet und populär gemacht, aber die Technik wurde selbstständig wiederentdeckt viele Male, und hatte viele Vorgänger aus den 1960er Jahren; siehe § History. Eine moderne Übersicht gibt es im Deep Learning Lehrbuch von Goodfellow, Bengio & Courville (2016). Übersicht Backpropagation berechnet den Gradienten im Gewichtsraum eines zukunftsweisenden neuronalen Netzes bezüglich einer Verlustfunktion. Anmerkung: x {\displaystyle x} : Eingabe (Funktionsvektor) y {\displaystyle y} : Zielausgabe Für die Klassifizierung wird die Ausgabe ein Vektor von Klassenwahrscheinlichkeiten (z.B. ( 0.1 , 0.7 , 0.2 ) {\displaystyle (0,0.1,0.7,0.2)} sein, und die Zielausgabe ist eine bestimmte Klasse, codiert durch die ein-hot/dummy Variable (z.B. ( 0 , 1 , 0 ) {\displaystyle (0,1,0)} ). C {\displaystyle C}: Verlustfunktion oder "Kostenfunktion"Für die Klassifizierung ist dies in der Regel Cross Entropy (XC, Log loss), während für Regression ist es in der Regel quadratische Fehlerverlust (SEL.) L {\displaystyle L} : die Anzahl der Schichten W l = (w j k l ) {\displaystyle W^{l}=(w_{jk}^{l) : die Gewichte zwischen Schicht l - 1 {\displaystyle l-1} und l {\displaystyle l}, wobei w j k l {\displaystyle w_{jk}^{l das Gewicht zwischen dem k {\displaystyle k} -th node in Schicht l - 1\displaystyle l-1} und dem j\displaystyle j} -th node in layer l\displaystyle l} f Aktivierungsfunktionen bei Schicht l {\displaystyle l} Für die Klassifikation ist die letzte Schicht in der Regel die logistische Funktion für die binäre Klassifikation, und softmax (softargmax) für die mehrstufige Klassifikation, während für die versteckten Schichten war dies traditionell eine sigmoide Funktion (logistische Funktion oder andere) auf jedem Knoten (Koordinate), aber heute ist mehr variiert, mit Gleichrichter (Ramp, ReLU) gemeinsam. Bei der Ableitung der Rückvermehrung werden weitere Zwischenmengen verwendet, die nach Bedarf eingeführt werden. Bias-Bedingungen werden nicht speziell behandelt, da sie einem Gewicht mit einem festen Eingang von 1 entsprechen. Zum Zwecke der Backpropagation spielen die spezifischen Verlust- und Aktivierungsfunktionen keine Rolle, solange sie und ihre Derivate effizient ausgewertet werden können. Das Gesamtnetz ist eine Kombination aus Funktionskomposition und Matrixmultiplikation: g ( x ) := f L ( W L f L - 1 (W L - 1 ⋯ f 1 (W 1 x ) ⋯ ) ) {\displaystyle g(x): = f^{L}(W^{L}f{L-1}(W^{L-1}\cdots f^1}(W^ Für ein Trainingsset gibt es eine Reihe von Ein-Ausgabe-Paare, { ( x i, y i ) } {\displaystyle Left\{(x_{i},y_{i})\right .Für jedes Ein-Ausgabe-Paare (x i, y i )\displaystyle (x_{i},y_{i) im Trainingsset ist der Verlust des Modells auf diesem Paar und die Zielausgabe y i {\displaystyle y_{i} : C ( y i, g ( x i) ) {\displaystyle C(y_{i},g(x_{i) Beachten Sie die Unterscheidung: Während der Modellauswertung werden die Gewichte fixiert, während die Eingänge variieren (und die Zielausgabe kann unbekannt sein), und das Netzwerk endet mit der Ausgangsschicht (es enthält nicht die Verlustfunktion). Während der Modellausbildung wird das Ein-Ausgabe-Paar fixiert, während die Gewichte variieren, und das Netzwerk endet mit der Verlustfunktion. Backpropagation berechnet den Gradienten für ein festes Ein-Ausgabe-Paar (x i, y i ) {\displaystyle (x_{i},y_{i), wobei die Gewichte w j k l {\displaystyle w_{jk}^{l variieren können. Jede einzelne Komponente des Gradienten, ∂ C / ∂ w j k l, {\displaystyle \partial C/\partial w_{jk}^{l, kann durch die Kettenregel berechnet werden; dies aber separat für jedes Gewicht ist ineffizient. Backpropagation berechnet den Gradienten effizient, indem duplikate Berechnungen vermieden und nicht unnötige Zwischenwerte berechnet werden, indem der Gradient jeder Schicht - speziell der Gradient des gewichteten Eingangs jeder Schicht, der mit δ l {\displaystyle \delta {^l} bezeichnet wird - von hinten nach vorne berechnet wird. Informell ist der Schlüsselpunkt, dass, da der einzige Weg ein Gewicht in W l {\displaystyle W^{l} den Verlust durch seine Wirkung auf die nächste Schicht beeinflusst, und es tut so linear, δ l {\displaystyle \delta {^l} sind die einzigen Daten, die Sie benötigen, um die Gradienten der Gewichte in der Schicht l {\displaystyle l} zu berechnen. Dies vermeidet Ineffizienz auf zwei Arten. Erstens, es vermeidet Vervielfältigung, weil bei der Berechnung des Gradienten in der Schicht l {\displaystyle l}, Sie müssen nicht alle Derivate auf späteren Schichten l + 1 , l + 2 ,... {\displaystyle l+1,l+2,\ldots } jedes Mal. Zweitens vermeidet es unnötige Zwischenberechnungen, da es in jedem Stadium den Gradienten der Gewichte bezüglich der Endleistung (der Verlust) direkt berechnet, anstatt die Derivate der Werte versteckter Schichten in Bezug auf Gewichtsänderungen ∂ a j' l' / ∂ w j k l {\displaystyle \partial a_{j'}^{l'}/\partial zu berechnen. w_{jk}^{l .Backpropagation kann für einfache Feedforward-Netzwerke in Bezug auf Matrixmultiplikation, oder allgemeiner in Bezug auf den angrenzenden Graph ausgedrückt werden. Matrix Multiplikation Für den Grundfall eines Feedforward-Netzwerks, bei dem Knoten in jeder Schicht nur mit Knoten in der unmittelbaren nächsten Schicht verbunden sind (ohne Überspringen von Schichten), und es gibt eine Verlustfunktion, die einen Skalarverlust für die endgültige Ausgabe berechnet, kann Backpropagation einfach durch Matrixmultiplikation verstanden werden. Im Wesentlichen wertet die Backpropagation die Expression für die Ableitung der Kostenfunktion als Produkt von Derivaten zwischen jeder Schicht von links nach rechts – rückwärts – aus, wobei der Gradient der Gewichte zwischen jeder Schicht eine einfache Modifikation der Teilprodukte ist (der "Rückwärts propagierte Fehler"). Bei einem Eingangs-Ausgangspaar (x, y ) {\displaystyle (x,y)} ist der Verlust: C ( y , f L ( W L f L - 1 ( W L - 1 ⋯ f 2 ( W 2 f 1 ( W 1 x ) )) ) ) ) {\displaystyle C(y,f^{L}(W^{L}f^{L-1}(W^{L-1}\cdots f^{2}(W^{2}f^{1}(W^{1}x)))\cdots )} Um dies zu komplizieren, beginnt man mit dem Eingang x {\displaystyle x} und arbeitet vorwärts; Die Aktivierung a l {\displaystyle a^{l} sowie die Derivate (f l )' {\displaystyle (f^{l'}) (auswertt bei z l {\displaystyle z^^{l}) müssen für den Rückwärtsgang geätzt werden. Die Ableitung des Verlusts in Bezug auf die Eingänge wird durch die Kettenregel gegeben; beachten Sie, dass jeder Begriff ein Gesamtderivat ist, das am Wert des Netzwerks (an jedem Knoten) am Eingang x {\displaystyle x} ausgewertet wird: dgl. C d a L ⋅ d a L d z L ⋅ d z L d a L − 1 ⋅ d a L − 1 d z L − 1 ∙ d z L − 1 d a L − 2 ⋅ d a 1 d z 1 ∙ ∂ z 1 ∂ x. {\displaystyle} ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ dz^{L-1}{da^{L-2}}\cdots {\frac ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Diese Begriffe sind: die Ableitung der Verlustfunktion, die Ableitungen der Aktivierungsfunktionen und die Massematrizen: d C d a L ∙ (f L ) ⋅ W L ⋅ (f L − 1 )' ⋅ W L − 1 ⋯ (f 1 ) ∙ W 1 . {\displaystyle} dC}{da^{L}}}\cdot (f^{L})'\cdot W^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Der Gradient MENT {\displaystyle \nabla } ist die Transponierung der Ausgabe in Bezug auf die Eingabe, so werden die Matrizen transponiert und die Reihenfolge der Multiplikation umgekehrt, aber die Einträge sind die gleichen: Einführung der Hilfsmenge δ l {\displaystyle \delta {^l} für die Teilprodukte (multiplizieren von rechts nach links), interpretiert als "Fehler auf Ebene l {\displaystyle l} " und definiert als Gradient der Eingangswerte auf Ebene l {\displaystyle l} :δ Der Gradient der Gewichte in der Schicht l {\displaystyle l} ist dann: MENT W l C = δ l (a l - 1 ) T . {\displaystyle \nabla _W^{l}C=\delta l}(a^{l-1})^{T. Der Faktor einer l - 1 {\displaystyle a^{l-1} ist, weil die Gewichte W l {\displaystyle W{l} zwischen der Ebene l - 1\displaystyle l-1} und lstyle\displaystyle l} die Pegel l\display Die δ l {\displaystyle \delta {^l} lässt sich leicht rekursiv berechnen wie: δ l - 1 := ( f l - 1 )' ⋅ ( W l ) T Θ δ l . {\displaystyle \delta l-1}:=(f^{l-1})'\cdot (W^{l})^^\cdot Die Gradienten der Gewichte können somit mit wenigen Matrixmultiplikationen für jede Ebene berechnet werden; dies ist Rückverbreitung. Im Vergleich zu naiv-Computing-Forwards (unter Verwendung der δ l {\displaystyle \delta {^l} zur Illustration): δ 1 = (f 1 ) ' ⋅ ( W 2 ) T ∙ (f 2 ) ⋅ ⋅ ⋅ ⋅  ′  W ( W L - 1 ) T ∙ (f L - 1 ) ∙ ( W L ) T ∙ (f L ) ∙ L ) ‡ ) L}&=(f^{L})'\cdot \nabla _a^{L}C,\end{ausgeglichen gibt es zwei Schlüsselunterschiede mit Rückverbreitung: Computing δ l - 1 {\displaystyle \delta {^l-1} in Bezug auf δ l {\displaystyle \delta {^l} vermeidet die offensichtliche doppelte Multiplikation der Schichten l {\displaystyle l} und darüber hinaus. Multiplying ausgehend von MENT a L C {\displaystyle \nabla _a^{L}C – propagiert den Fehler rückwärts – bedeutet, dass jeder Schritt einfach einen Vektor multipliziert ( δ l {\displaystyle \delta {^l}) durch die Matrizen der Gewichte (W l ) T {\displaystyle (W^{l})^{T und Aktivierungsderivate Dagegen bedeutet die Multiplikation nach vorne, ausgehend von den Änderungen an einer früheren Schicht, dass jede Multiplikation eine Matrix durch eine Matrix multipliziert. Dies ist viel teurer, und entspricht dem Tracking jeder mögliche Weg einer Veränderung in einer Schicht l {\displaystyle l} vorwärts auf Veränderungen in der Schicht l + 2 {\displaystyle l+2} (für Multiplikation W l + 1 {\displaystyle W{l+1} von W l + 2 {\displaystyle l+2} W^{l+2}, mit zusätzlichen Multiplikationen für die Derivate der Aktivierungen, die unnötig die Zwischengrößen berechnen, wie Gewichtsänderungen die Werte von versteckten Knoten beeinflussen. Diagramm Für allgemeinere Graphiken und andere erweiterte Variationen kann die Backpropagation in Bezug auf die automatische Differenzierung verstanden werden, wobei Backpropagation ein besonderer Fall der Reverse Akkumulation ist (oder "Reverse-Mode".) Intuition Motivation Ziel eines überwachten Lernalgorithmus ist es, eine Funktion zu finden, die eine Reihe von Eingaben am besten auf ihre korrekte Ausgabe abbildet. Die Motivation für die Backpropagation besteht darin, ein mehrschichtiges neuronales Netz so zu trainieren, dass es die entsprechenden internen Darstellungen erlernen kann, um eine beliebige Zuordnung von Eingabe zu Ausgabe zu erlernen. Lernen als Optimierungsproblem Um die mathematische Ableitung des Backpropagationsalgorithmus zu verstehen, hilft es zunächst, einige Intuition über die Beziehung zwischen der tatsächlichen Ausgabe eines Neurons und der richtigen Ausgabe für ein bestimmtes Trainingsbeispiel zu entwickeln. Betrachten Sie ein einfaches neuronales Netz mit zwei Eingangseinheiten, einer Ausgangseinheit und keiner versteckten Einheiten, wobei jedes Neuron einen linearen Ausgang (im Gegensatz zu den meisten Arbeiten an neuronalen Netzwerken, in denen die Zuordnung von Eingängen zu Ausgängen nicht linear ist) verwendet, das ist die gewichtete Summe seines Eingangs. Zunächst werden vor dem Training die Gewichte zufällig eingestellt. Dann erfährt das Neuron von Trainingsbeispielen, die in diesem Fall aus einem Satz von Tupeln bestehen ( x 1 , x 2 , t ) {\displaystyle (x_{1},x_{2},t), wobei x 1 {\displaystyle x_{1} und x 2 {\displaystyle x_{2} die Eingänge zum Netzwerk sind und t die richtige Ausgabe ist (die Ausgabe, die das Netzwerk erzeugen sollte). Das erste Netzwerk, gegeben x 1 {\displaystyle x_{1} und x 2 {\displaystyle x_{2}, wird eine Ausgabe y berechnen, die wahrscheinlich von t abweicht (bei zufälligen Gewichten). Zur Messung der Diskrepanz zwischen dem Zielausgang t und dem berechneten Ausgang y wird eine Verlustfunktion L (t, y) {\displaystyle L(t,y)} verwendet. Bei Regressionsanalyseproblemen kann der quadratische Fehler als Verlustfunktion verwendet werden, um die kategorische Kreuzentropie einzustufen. Als Beispiel betrachten Sie ein Regressionsproblem mit dem quadratischen Fehler als Verlust: L (t, y ) = ( t - y ) 2 = E, {\displaystyle L(t,y)=(t-y)^{2}=E, wobei E die Diskrepanz oder Fehler ist. Betrachten Sie das Netzwerk auf einem einzigen Trainingsfall: ( 1 , 1 , 0 ) {\displaystyle (1,1,0)} .Thus, der Eingang x 1 {\displaystyle x_{1} und x 2 {\displaystyle x_{2} sind 1 bzw. 1 und der richtige Ausgang, t ist 0. Wird nun die Relation zwischen dem Ausgang y des Netzes auf der horizontalen Achse und dem Fehler E auf der vertikalen Achse aufgetragen, so ergibt sich eine Parabel. Das Minimum der Parabel entspricht dem Ausgang y, der den Fehler E minimiert. Bei einem einzigen Trainingsfall berührt das Minimum auch die horizontale Achse, was bedeutet, dass der Fehler Null ist und das Netzwerk einen Ausgang y erzeugen kann, der genau dem Zielausgang t entspricht. Die Leistung eines Neurons hängt jedoch von der gewichteten Summe aller Eingänge ab: y = x 1 w 1 + x 2 w 2 , {\displaystyle y=x_{1}w_{1}+x_{2}w_{2, wobei w 1 {\displaystyle w_{1} und w 2 {\displaystyle w_{2} die Gewichte auf der Verbindung von den Eingabeeinheiten zur Ausgabeeinheit sind. Daher hängt der Fehler auch von den ankommenden Gewichten zum Neuron ab, was letztendlich im Netzwerk geändert werden muss, um das Lernen zu ermöglichen. In diesem Beispiel wird beim Injizieren der Trainingsdaten die Verlustfunktion E = ( t - y ) 2 = y 2 = ( x 1 w 1 + x 2 w 2 ) 2 = ( w 1 + w 2 ) 2 . (\displaystyle E=(t-y)^{2}=y^{2}=(x_{1}w_{1}+x_{2}w_{2}){2}=(w_{1}+w_{2})^{2}. Dann nimmt die Verlustfunktion E {\displaystyle E} die Form eines parabolischen Zylinders mit seiner Basis entlang w 1 = - w 2 {\displaystyle w_{1}=-w_{2 .Da alle Gewichtsmengen, die w 1 erfüllen = - w 2 {\displaystyle w_{1}=-w_{2 minimiert die Verlustfunktion, in diesem Fall sind zusätzliche Zwänge erforderlich, um eine einzigartige Lösung zu konvergieren. Zusätzliche Zwänge könnten entweder durch die Festlegung spezifischer Bedingungen für die Gewichte oder durch Injizieren zusätzlicher Trainingsdaten erzeugt werden.Ein allgemein verwendeter Algorithmus, um die Menge der Gewichte zu finden, die den Fehler minimiert ist Gradientenabstieg. Durch Rückvermehrung wird die steilste Abwärtsrichtung der Verlustfunktion gegenüber den vorliegenden synaptischen Gewichten berechnet. Dann können die Gewichte entlang der steilsten Abstiegsrichtung geändert werden und der Fehler wird effizient minimiert. Ableitung Bei der Gradientenabstiegsmethode wird die Ableitung der Verlustfunktion in Bezug auf die Gewichte des Netzes berechnet. Dies geschieht in der Regel mit Backpropagation. Unter der Annahme eines Ausgangsneurons ist die quadratische Fehlerfunktion E = L (t, y ) {\displaystyle E=L(t,y)}, wobei E {\displaystyle E} der Verlust für die Ausgabe y {\displaystyle y} und der Zielwert t {\displaystyle t} ist, t\displaystyle t} die Zielausgabe für eine Trainingsprobe ist und y {\displaystyle y Für jeden Neuron j {\displaystyle j} wird sein Ausgang o j {\displaystyle o_{j} als o j = φ (netto j ) = φ (netto) = φ (n = 1 n w k o k ) , {\displaystyle o_{j}=\varphi (text{net}_{j}=\varphi links(\sum k=1}{n}) Eine historisch genutzte Aktivierungsfunktion ist die logistische Funktion: φ (z ) = 1 1 + e - z {\displaystyle \varphi (z)={\frac 1}{1+e^{-z die eine bequeme Ableitung von: d φ (z ) d z = φ (z ) ( 1 - φ (z ) ) {\displaystyle {\frac {d\varphi (z)}=\varphi z)(1-\varphi (z)} aufweist Das Eingangsnetz {\displaystyle \text{net}_{j zu einem Neuron ist die gewichtete Summe der Ausgänge o k {\displaystyle o_{k} früherer Neuronen. Ist das Neuron in der ersten Schicht nach der Eingangsschicht, so sind die o k {\displaystyle o_{k} der Eingangsschicht einfach die Eingänge x k {\displaystyle x_{k} zum Netzwerk. Die Anzahl der Eingabeeinheiten am Neuron ist n {\displaystyle n} . Die Variable w k j {\displaystyle w_{kj} bezeichnet das Gewicht zwischen Neuron k {\displaystyle k} der vorherigen Schicht und Neuron j {\displaystyle j} der aktuellen Schicht. Das Finden des Derivats des Fehlers Die partielle Ableitung des Fehlers in Bezug auf ein Gewicht w i j {\displaystyle w_{ij} erfolgt zweimal mit der Kettenregel: Im letzten Faktor der rechten Seite des obigen, nur ein Begriff im Summennetz j {\displaystyle \text{net}_{j hängt von w i j {\displaystyle w_{ij} ab, so dass wenn das Neuron in der ersten Schicht nach der Eingangsschicht ist, o i {\displaystyle o_{i} nur x i {\displaystyle x_{i} {\partial}partial Text{net}_{j}}\varphi (Text{net}_{j})=\varphi text{net}_{j}(1-\varphi \text{net}_{j})=o_{j}(1-o_{j}{j}{j}{j}}{j}}}}\varphi (Text{net}_{j})= Dies ist der Grund, warum die Backpropagation erfordert, dass die Aktivierungsfunktion differenzierbar ist. (Die ReLU-Aktivierungsfunktion, die bei 0 nicht differenzierbar ist, ist jedoch sehr beliebt geworden, z.B. in AlexNet) Der erste Faktor ist einfach auszuwerten, ob sich das Neuron in der Ausgangsschicht befindet, weil dann o j = y {\displaystyle o_{j}=y und wenn die Hälfte des quadratischen Fehlers als Verlustfunktion verwendet wird, können wir es als ∂ E ∂ o j = ∂ E ∂ y = ∂ y 1 2 ( t - y ) 2 = y - t {\displaystyle {\frac E{\partial {\cH00FF} {\cH00FF}{\cH00FF}{\cH00FF}{\cH00FF}{\cH00FF}{\cH00FF}{\cH00FF}}{\cH00FF}{\cH00FF}{\cH00FF}{\cH00FF}{\cH00FF}}} {\frac} {\frac {\partial y}}{\frac 1}{2}}(t-y)^{2}=y-t Ist j {\displaystyle j} jedoch in einer beliebigen inneren Schicht des Netzes, so ist das Finden der Ableitung E {\displaystyle E} in Bezug auf o j {\displaystyle o_{j} weniger offensichtlich. E {\displaystyle E} als Funktion betrachtet, wobei alle Neuronen L = { u, v , ... , w } {\displaystyle L=\{u,v,\dots ,w\} empfangenden Eingang von Neuron j {\displaystyle j}, ∂ E ( o j ∂ o j = ∂ E (n e t u, net v , ..., n e t w ∂ o j {\displaystyle {\frac {\partial E(o_{j}}}{\partial o_{j}}={\frac {\partial E(\mathrm {net} u},{\text{net}_{v},\dots ,\mathrm {net}_w})}{\partial o_{j} und das vollständige Derivat in Bezug auf o j\displaystyle o_{j} erhält man einen rekursiven Ausdruck für das Derivat: Daher kann das Derivat in Bezug auf o j {\displaystyle o_{j} berechnet werden, wenn alle Derivate in Bezug auf die Ausgänge o l {\displaystyle o_{\ell } der nächsten Schicht - die näher an der Ausgangsneuron - bekannt sind. [Anmerkung, wenn eines der Neuronen im Set L {\displaystyle L} wurden nicht mit Neuron j {\displaystyle j} verbunden, sie wären unabhängig von w i j {\displaystyle w_{ij} und die entsprechende Teilableitung unter der Summation würde auf 0 verschwinden.] Substituiert Eq.2, Eq.3 Eq.4 und Eq.5 in Eq.1 erhalten wir: ∂ E ∂ w i j = ∂ E ∂ o j ∂ o j ∂ net j ∂ net j ∂ net j ∂ w i j = ∂ E ∂ o j ∂ o j ∂ netto j o i `displaystyle {\frac {\partial E}{\partial ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ {\partial E}{\partial ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ {\partial text{net}_{j}{\partial ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ {\partial E}{\partial ) ∂ ∂ w i j = o i δ j {\displaystyle {\frac {\partial E}{\partial ! {_j} mit δ j = ∂ E ∂ o j ∂ o j ∂ netto j = { ∂ L ( o j, t ) ∂ o j d φ ( netto j ) d netto j, wenn j ein Ausgangsneuron ist, ( Σ l ε L w j l δ l δ l ) d netto j, wenn j ein inneres Neuron ist. {\displaystyle \delta _j}={\frac {\partial E}{\partial o_{j}{\frac {\partial o_{j}{\partial text{net}_{j}}}={\begin{cases}{\frac {\partial L(o_{j},t)}{\partial (Text{net}{j}{d{\text}}}{\text}}}{\text}}{\text{j}}}{\text{if}}}{\text{if}}} }j{\text ist ein Ausgangsneuron,}\\\\\(\sum {_\ell \in L}w_{j\ell \}delta (Text{net}_{j}{d{\text{net}}}}{d{\text{net}}}{\text{j}}}{\text{if} }j{\text ist ein innerer Neuron.}}\end{cases, wenn φ {\displaystyle \varphi } die logistische Funktion ist, und der Fehler ist der quadratische Fehler: δ j = ∂ E ∂ o j ∂ o j ∂ net j = { o j − t j ∂o j ( 1 - o j ) wenn j ein Ausgangsneuron ist ( Σ l ε L w j l δ l δ l ) o j ( 1 - o j ), wenn j ein inneres Neuron ist. {\displaystyle \delta _j}={\frac {\partial E}{\partial o_{j}{\frac {\partial o_{j}{\partial text{net}_{j}}}={\begin{cases}(o_{j}-t_{j})o_{j}(1-o_{j})&{\text{if} }j{\text ist ein Ausgangsneuron,}\\\\\(\sum {_\ell \in L}w_{j\ell \}delta {_\ell o_{j}(1-o_{j})&{\text{if }j{\text ist ein innerer Neuron}}\end{cases Um das Gewicht w i j {\displaystyle w_{ij} mit Gradientenabstieg zu aktualisieren, muss eine Lernrate gewählt werden, 0 {\displaystyle \eta >0} .Die Gewichtsänderung muss die Auswirkungen auf E {\displaystyle E} einer Zunahme oder Abnahme von w i j {\displaystyle w_{ij} widerspiegeln. Wenn ∂ E ∂ w i > 0 {\displaystyle {\displaystyle {\partial E{\partial w_{ij}{\\\\\\\\\displaystyle n {\displaystyle n {\displaystyle n {\\display n} Δ w i j = - η ∂ E ∂ w i j = - η i δ j {\displaystyle \Delta w_{ij}=\eta ! E{\partial ! O_{i} {_j} Verlustfunktion Die Verlustfunktion ist eine Funktion, die Werte einer oder mehrerer Variablen auf eine reale Zahl abbildet, die intuitiv einige mit diesen Werten verbundene Kosten darstellt. Zur Backpropagation berechnet die Verlustfunktion die Differenz zwischen dem Netzausgang und dessen erwarteten Ausgang, nachdem sich ein Trainingsbeispiel über das Netzwerk ausgebreitet hat. AnnahmenDer mathematische Ausdruck der Verlustfunktion muss zwei Bedingungen erfüllen, damit sie möglicherweise in der Rückverbreitung verwendet werden kann. Das erste ist, dass es als Durchschnitt E = 1 n Σ x E x {\textstyle E={\frac 1}{n}\sum x}E_{x über Fehlerfunktionen E x {\textstyle E_{x}, für n {\textstyle n} einzelne Trainingsbeispiele, x {\textstyle x} geschrieben werden kann. Grund für diese Annahme ist, dass der Backpropagationsalgorithmus den Gradienten der Fehlerfunktion für ein einziges Trainingsbeispiel berechnet, das auf die Gesamtfehlerfunktion generalisiert werden muss. Die zweite Annahme ist, dass sie in Abhängigkeit von den Ausgängen aus dem neuronalen Netz geschrieben werden kann. Beispielverlustfunktion Lassen Sie y, y' {\displaystyle y,y'} Vektoren in R n {\displaystyle \mathbb {R} {^n} sein.Selektieren Sie eine Fehlerfunktion E (y, y') {\displaystyle E(y,y'}) die Differenz zwischen zwei Ausgängen. Die Standardwahl ist das Quadrat des Euclideschen Abstandes zwischen den Vektoren y {\displaystyle y} und y' {\displaystyle y'} : Die Fehlerfunktion über n {\textstyle n} Trainingsbeispiele kann dann als Durchschnitt der Verluste über einzelne Beispiele geschrieben werden: Einschränkungen Gradientenabstieg mit Rückverbreitung ist nicht garantiert, das globale Minimum der Fehlerfunktion zu finden, sondern nur ein lokales Minimum; auch hat es Schwierigkeiten Plateaus in der Fehlerfunktion Landschaft zu kreuzen. Dieses Problem, das durch die Nichtkonvexität von Fehlerfunktionen in neuronalen Netzwerken verursacht wurde, war lange gedacht, ein großer Nachteil zu sein, aber Yann LeCun et al.argue, dass in vielen praktischen Problemen, ist es nicht. Backpropagation Lernen erfordert keine Normalisierung von Eingabevektoren; die Normalisierung könnte jedoch die Leistung verbessern. Die Backpropagation erfordert, dass die Ableitungen von Aktivierungsfunktionen zu Netzwerkdesignzeit bekannt sind. Geschichte Der Begriff Backpropagation und seine allgemeine Verwendung in neuronalen Netzwerken wurde in Rumelhart, Hinton & Williams (1986a) bekannt gegeben, dann in Rumelhart, Hinton & Williams (1986b) aufgearbeitet und populär gemacht, aber die Technik wurde unabhängig wieder entdeckt viele Male, und hatte viele Vorgänger aus den 1960er Jahren. Die Grundlagen der kontinuierlichen Backpropagation wurden im Rahmen der Kontrolltheorie von Henry J. Kelley 1960 und von Arthur E. Bryson 1961 abgeleitet. Sie nutzten Prinzipien der dynamischen Programmierung. Im Jahr 1962 veröffentlichte Stuart Dreyfus eine einfachere Ableitung basierend auf der Kettenregel. Bryson und Ho beschreiben es 1969 als mehrstufiges dynamisches Systemoptimierungsverfahren. Die Backpropagation wurde von mehreren Forschern in den frühen 60er Jahren abgeleitet und bereits 1970 von Seppo Linnainmaa auf Computern durchgeführt. Paul Werbos war zuerst in den USA, um vorschlagen, dass es für neuronale Netze verwendet werden könnte, nachdem es in seiner 1974 Dissertation eingehend analysiert wurde. Während nicht auf neuronale Netze angewendet, veröffentlichte Linnainmaa 1970 die allgemeine Methode zur automatischen Differenzierung (AD). Obwohl sehr kontrovers, glauben einige Wissenschaftler, dass dies tatsächlich der erste Schritt in Richtung der Entwicklung eines Rückverbreitungsalgorithmus war. Im Jahre 1973 passt Dreyfus Parameter von Reglern im Verhältnis zu Fehlergradienten an. 1974 erwähnte Werbos die Möglichkeit, dieses Prinzip auf künstliche neuronale Netze anzuwenden, und 1982 wendete er Linnainmaas AD-Methode auf nichtlineare Funktionen an. Später wurde die Werbos-Methode 1985 von Parker und 1986 von Rumelhart, Hinton und Williams wiederentdeckt und beschrieben. Rumelhart, Hinton und Williams zeigten experimentell, dass diese Methode nützliche interne Darstellungen von eingehenden Daten in versteckten Schichten von neuronalen Netzwerken erzeugen kann. Yann LeCun schlug in seiner Doktorarbeit 1987 die moderne Form des Back-Propagation-Learning-Algorithmus für neuronale Netzwerke vor. 1993 gewann Eric Wan einen internationalen Mustererkennungswettbewerb durch Backpropagation. Während der 2000er Jahre fiel es aus Gunsten, kehrte aber in den 2010er Jahren zurück und profitierte von billigen, leistungsstarken GPU-basierten Rechensystemen. Dies war vor allem in der Spracherkennung, der Bildverarbeitung, der natürlichen Sprachverarbeitung und der Sprachstruktur-Lernforschung (in der es verwendet wurde, um eine Vielzahl von Phänomenen im Zusammenhang mit dem ersten und zweiten Sprachlernen zu erklären). Fehler-Backpropagation wurde vorgeschlagen, menschliche Gehirn ERP-Komponenten wie die N400 und P600 zu erklären. Siehe auch KÃ1⁄4nstliches neuronales Netz Biologisches neuronales Netz katastrophale Interferenz Ensemble Lernen AdaBoost Overfitting Neural Backpropagation Backpropagation durch Zeit Noten Referenzen Weiter lesen Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016)."6.5 Back-Propagation und andere Differenzierungsalgorithmen". Deep Learning.MIT Press.pp.200–220.ISBN 9780262035613.Nielsen, Michael A. (2015). "Wie der Backpropagationalgorithmus funktioniert". Neurale Netzwerke und Deep Learning. Determination Presse. McCaffrey, James (Oktober 2012)."Neural Network Back-Propagation für Programmierer". MSDN Magazine. Rojas, Raúl (1996). "The Backpropagation Algorithm" (PDF). Neurale Netzwerke: Eine systematische Einführung. Berlin: Springer. ISBN 3-540-60505-3. Externe Links Backpropagation neuronales Netzwerk-Tutorial bei der Wikiversity Bernacki, Mariusz; Włodarczyk, Przemysław (2004)."Principles of training multilayer neuronal network using backpropagation".Karpathy, Andrej (2016). " Vortrag 4: Backpropagation, Neural Networks 1".CS231n.Stanford University – via YouTube."Was ist Backpropagation wirklich tun?".3Blue1Brown.November 3, 2017 – via YouTube.