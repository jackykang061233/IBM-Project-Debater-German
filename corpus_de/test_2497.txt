Bei der Bildverarbeitung und Bildverarbeitung ist ein Merkmal eine Information über den Inhalt eines Bildes; typischerweise darüber, ob ein bestimmter Bereich des Bildes bestimmte Eigenschaften aufweist. Eigenschaften können spezifische Strukturen im Bild wie Punkte, Kanten oder Objekte sein. Merkmale können auch das Ergebnis einer allgemeinen Nachbarschaftsoperation oder Merkmalserkennung sein, die auf das Bild angewendet wird. Weitere Beispiele von Merkmalen beziehen sich auf Bewegungen in Bildsequenzen oder auf Formen, die in Kurven oder Grenzen zwischen verschiedenen Bildbereichen definiert sind. Im Allgemeinen ist ein Merkmal jede Information, die für die Lösung der Rechenaufgabe im Zusammenhang mit einer bestimmten Anwendung relevant ist. Dies ist der gleiche Sinn wie bei der maschinellen Lern- und Mustererkennung im Allgemeinen, obwohl die Bildverarbeitung eine sehr anspruchsvolle Sammlung von Merkmalen aufweist. Das Merkmalskonzept ist sehr allgemein und die Auswahl von Merkmalen in einem bestimmten Computer-Visionssystem kann stark von dem spezifischen Problem abhängig sein. Wenn Merkmale in Bezug auf lokale Nachbarschaftsoperationen definiert werden, die auf ein Bild angewendet werden, kann ein Verfahren, das allgemein als Merkmalsextraktion bezeichnet wird, zwischen Merkmalserkennungsansätzen unterscheiden, die lokale Entscheidungen treffen, ob es ein Merkmal eines bestimmten Typs an einem bestimmten Bildpunkt gibt oder nicht, und denjenigen, die nicht-binäre Daten als Ergebnis produzieren. Die Unterscheidung wird dann relevant, wenn die resultierenden detektierten Merkmale relativ sparsam sind. Obwohl lokale Entscheidungen getroffen werden, muss die Ausgabe aus einem Merkmalserfassungsschritt kein binäres Bild sein. Das Ergebnis wird oft in Sätzen von (verknüpften oder unverbundenen) Koordinaten der Bildpunkte dargestellt, in denen Merkmale erkannt wurden, manchmal mit Subpixelgenauigkeit. Wenn die Merkmalsextraktion ohne lokale Entscheidungsfindung erfolgt, wird das Ergebnis oft als Merkmalsbild bezeichnet. Folglich kann ein Merkmalsbild als Bild in dem Sinne betrachtet werden, dass es eine Funktion der gleichen räumlichen (oder zeitlichen) Variablen wie das ursprüngliche Bild ist, wobei die Pixelwerte jedoch anstelle von Intensität oder Farbe Informationen über Bildmerkmale halten. Dies bedeutet, dass ein Merkmalsbild ähnlich wie ein gewöhnliches, von einem Bildsensor erzeugtes Bild verarbeitet werden kann. Feature-Bilder werden häufig auch als integrierter Schritt in Algorithmen zur Merkmalserkennung berechnet. Begriff Es gibt keine universelle oder genaue Definition dessen, was ein Merkmal darstellt, und die genaue Definition hängt oft von dem Problem oder der Art der Anwendung ab. Dennoch wird typischerweise ein Merkmal als interessanter Teil eines Bildes definiert und Funktionen werden als Ausgangspunkt für viele Computer-Visionsalgorithmen verwendet. Da Funktionen als Ausgangspunkt und Hauptprimitiven für nachfolgende Algorithmen verwendet werden, wird der Gesamtalgorithmus oft nur so gut sein wie sein Merkmalsdetektor. Folglich ist die wünschenswerte Eigenschaft für einen Merkmalsdetektor Wiederholbarkeit: ob das gleiche Merkmal in zwei oder mehr verschiedenen Bildern derselben Szene detektiert wird. Die Merkmalserkennung ist eine Low-Level-Bildverarbeitung. Das heißt, es wird in der Regel als erste Operation auf einem Bild ausgeführt und untersucht jedes Pixel, um zu sehen, ob an diesem Pixel ein Feature vorhanden ist. Ist dies Teil eines größeren Algorithmus, so wird der Algorithmus typischerweise nur das Bild im Bereich der Merkmale untersuchen. Als integrierte Voraussetzung für die Merkmalserkennung wird das Eingabebild in der Regel von einem Gaussian-Kernel in einer Skalen-Raum-Darstellung geglättet und ein oder mehrere Merkmalsbilder berechnet, oft in Bezug auf lokale Bildderivate-Operationen ausgedrückt. Gelegentlich kann bei rechnerisch aufwendiger Merkmalserkennung und zeitlicher Zwänge ein höherer Level-Algorithmus verwendet werden, um die Merkmalserkennungsstufe zu führen, so dass nur bestimmte Teile des Bildes nach Merkmalen gesucht werden. Es gibt viele Computer-Vision-Algorithmen, die Feature-Erkennung als Anfangsschritt verwenden, so dass dadurch eine sehr große Anzahl von Feature-Detektoren entwickelt wurden. Diese unterscheiden sich in den Arten von Funktionen, die rechnerische Komplexität und die Wiederholbarkeit. Typen Kanten Kanten sind Punkte, an denen zwischen zwei Bildbereichen eine Grenze (oder eine Kante) vorhanden ist. Im allgemeinen kann eine Kante nahezu willkürlich ausgebildet sein und Knotenpunkte aufweisen. In der Praxis werden Kanten üblicherweise als Sätze von Punkten im Bild definiert, die eine starke Gradientengröße aufweisen. Darüber hinaus werden einige gemeinsame Algorithmen dann hohe Gradientenpunkte zusammenketten, um eine vollständigere Beschreibung einer Kante zu bilden. Diese Algorithmen stellen in der Regel einige Einschränkungen auf die Eigenschaften einer Kante, wie Form, Glätte und Gradientenwert. Lokal weisen Kanten eine eindimensionale Struktur auf. Ecken / Zinspunkte Die Begriffe Ecken und Zinspunkte werden etwas austauschbar verwendet und beziehen sich auf punktartige Merkmale in einem Bild, die eine lokale zweidimensionale Struktur aufweisen. Der Name Corner entstand, da die frühen Algorithmen zuerst die Kantenerkennung durchgeführt hatten und dann die Kanten analysierten, um schnelle Richtungsänderungen (Ecken) zu finden. Diese Algorithmen wurden dann so entwickelt, dass eine explizite Kantenerkennung nicht mehr erforderlich war, z.B. durch die Suche nach hohen Krümmungen im Bildgradienten. Es wurde dann bemerkt, dass die so genannten Ecken auch an Teilen des Bildes, die nicht Ecken im traditionellen Sinne waren, erkannt wurden (z.B. ein kleiner heller Fleck auf einem dunklen Hintergrund kann erkannt werden). Diese Punkte werden häufig als Zinspunkte bezeichnet, aber der Begriff Ecke wird von der Tradition verwendet. Blobs / Bereiche von Zinspunkten Blobs bieten eine ergänzende Beschreibung von Bildstrukturen in Bezug auf Regionen, im Gegensatz zu Ecken, die punktförmiger sind. Dennoch können Blob-Deskriptoren oft einen bevorzugten Punkt (ein lokales Maximum einer Bedienerantwort oder einen Schwerpunkt) enthalten, was bedeutet, dass viele Blob-Detektoren auch als Interessepunkt-Operatoren angesehen werden können. Blob-Detektoren können Bereiche in einem Bild erfassen, die zu glatt sind, um von einem Eckdetektor detektiert zu werden. Betrachten Sie, ein Bild zu schrumpfen und dann Eckerkennung durchzuführen. Der Detektor wird auf Punkte reagieren, die scharf im Shrunk-Bild sind, kann aber im Originalbild glatt sein. An dieser Stelle wird der Unterschied zwischen einem Eckdetektor und einem Blobdetektor etwas vage. Diese Unterscheidung kann in großem Umfang durch eine entsprechende Skalenbezeichnung behoben werden. Dennoch werden aufgrund ihrer Ansprecheigenschaften auf verschiedene Arten von Bildstrukturen in unterschiedlichen Skalen auch die LoG- und DoH-Blob-Detektoren im Artikel zur Eckerkennung erwähnt. Ritten Für langgestreckte Objekte ist der Begriff der Stege ein natürliches Werkzeug. Als Verallgemeinerung einer medialen Achse ist ein aus einem Grauwertbild berechneter Grat-Deskriptor zu erkennen. Aus praktischer Sicht kann ein Kamm als eine eindimensionale Kurve betrachtet werden, die eine Symmetrieachse darstellt, und zusätzlich ein Attribut der jedem Kammpunkt zugeordneten lokalen Kammbreite aufweist. Leider ist es jedoch algorithmisch schwieriger, Grat-Features aus allgemeinen Klassen von Grau-Level-Bildern zu extrahieren als Kanten-, Eck- oder Blob-Features. Dennoch werden Gratdeskriptoren häufig zur Straßenextraktion in Luftbildern und zur Entnahme von Blutgefäßen in medizinischen Bildern verwendet – siehe Graterkennung. Detection Feature-Erkennung umfasst Methoden zur Berechnung von Abstraktionen von Bildinformationen und lokale Entscheidungen an jedem Bildpunkt, ob an diesem Punkt ein Bildmerkmal eines bestimmten Typs vorliegt oder nicht. Die resultierenden Merkmale werden Teilmengen der Bilddomäne sein, oft in Form isolierter Punkte, kontinuierlicher Kurven oder verbundener Bereiche. Extraktion Sobald Merkmale erkannt wurden, kann ein lokales Bild-Patch um das Feature extrahiert werden. Diese Extraktion kann durchaus erhebliche Mengen an Bildverarbeitung beinhalten. Das Ergebnis ist als Merkmalsdeskriptor oder Merkmalsvektor bekannt. Unter den Ansätzen, die zur Beschreibung verwendet werden, kann man N-jets und lokale Histogramme erwähnen (siehe skalierungsinvariante Merkmalstransformation zum Beispiel eines lokalen Histogramm-Deskriptors). Neben einer solchen Attributinformation kann der Merkmalsdetektionsschritt selbst auch komplementäre Attribute, wie die Kantenorientierung und Gradientengröße in der Kantendetektion und die Polarität und die Stärke des Blobs in der Blobdetektion, bereitstellen. Low-Level Edge-Erkennung Eckerkennung Blob-Erkennung Ridge-Erkennung Scale-invariant Merkmal transformieren Curvature Edge-Richtung, Änderung der Intensität, Autokorrelation. Bildbewegung Bewegungserkennung. Flächenbasierter, differenzierter Ansatz. Optische Strömung. Formbasiertes Thresholding Blob Extraktion Vorlage passend Hough Transformation Linien Kreise / Ellipsen Arbitrary Formen (generalized Hough Transformation) Funktioniert mit jedem parametrisierbaren Merkmal (Klassenvariablen, Cluster-Erkennung usw.). Allgemeine Hough-Transformation Flexible Methoden Deformierbare, parametrisierte Formen Aktive Konturen (Snakes) Darstellung Ein bestimmtes Bildmerkmal, definiert in Bezug auf eine bestimmte Struktur in den Bilddaten, kann oft auf verschiedene Weise dargestellt werden. Beispielsweise kann in jedem Bildpunkt eine Kante als boolesche Größe dargestellt werden, die beschreibt, ob an dieser Stelle eine Kante vorhanden ist. Alternativ können wir stattdessen eine Darstellung verwenden, die statt einer booleschen Aussage der Existenz der Kante ein gewisses Maß liefert und diese mit Informationen über die Orientierung der Kante kombiniert. Ebenso kann die Farbe eines bestimmten Bereichs entweder in Bezug auf die mittlere Farbe (drei Skalare) oder ein Farbhistogramm (drei Funktionen) dargestellt werden. Wenn ein Computer-Vision-System oder Computer-Vision-Algorithmus ausgelegt ist, kann die Wahl der Feature-Darstellung ein kritisches Problem sein. In einigen Fällen kann ein höheres Detail in der Beschreibung eines Merkmals für die Lösung des Problems notwendig sein, aber dies kommt zu den Kosten, mit mehr Daten und anspruchsvoller Verarbeitung zu umgehen. Im Folgenden werden einige der für die Auswahl einer geeigneten Darstellung relevanten Faktoren diskutiert. In dieser Diskussion wird ein Beispiel einer Merkmalsdarstellung als Merkmalsdeskriptor oder einfach als Deskriptor bezeichnet. Bestimmtheit oder Vertrauen Zwei Beispiele von Bildmerkmalen sind lokale Kantenorientierung und lokale Geschwindigkeit in einer Bildsequenz. Bei der Orientierung kann der Wert dieses Merkmals mehr oder weniger undefiniert sein, wenn in der entsprechenden Nachbarschaft mehr als eine Kante vorhanden ist. Lokale Geschwindigkeit ist undefiniert, wenn der entsprechende Bildbereich keine räumliche Variation enthält. Als Folge dieser Beobachtung kann es von Bedeutung sein, eine Merkmalsdarstellung zu verwenden, die ein Maß an Sicherheit oder Vertrauen im Zusammenhang mit der Aussage über den Merkmalswert umfasst. Ansonsten ist es eine typische Situation, dass derselbe Deskriptor verwendet wird, um Merkmalswerte mit geringer Sicherheit und Merkmalswerte nahe Null darzustellen, wobei sich bei der Interpretation dieses Deskriptors eine Mehrdeutigkeit ergibt. Je nach Anwendung kann eine solche Mehrdeutigkeit annehmbar sein oder nicht. Insbesondere, wenn bei der späteren Verarbeitung ein Merkmalsbild verwendet wird, kann es eine gute Idee sein, eine Merkmalsdarstellung zu verwenden, die Informationen über Sicherheit oder Vertrauen enthält. Dies ermöglicht es, einen neuen Merkmalsdeskriptor aus mehreren Deskriptoren zu berechnen, beispielsweise am gleichen Bildpunkt, aber an verschiedenen Skalen, oder von verschiedenen, aber benachbarten Punkten, in Bezug auf einen gewichteten Durchschnitt, in dem die Gewichte aus den entsprechenden Gewissheiten abgeleitet werden. Im einfachsten Fall kann die entsprechende Berechnung als Tiefpassfilterung des Merkmalsbildes realisiert werden. Das resultierende Merkmalsbild wird im Allgemeinen geräuschstabiler sein. Durchschnittliche Die Darstellung der entsprechenden Merkmalswerte kann neben der in der Darstellung enthaltenen Sicherheit auch für einen Mittelungsvorgang geeignet sein oder nicht. Die meisten Merkmalsdarstellungen können in der Praxis gemittelt werden, aber nur in bestimmten Fällen kann der resultierende Deskriptor eine korrekte Interpretation in Bezug auf einen Merkmalswert gegeben werden. Solche Darstellungen werden als durchschnittlich bezeichnet. Wird beispielsweise die Orientierung einer Kante in einem Winkel dargestellt, muss diese Darstellung eine Diskontinuität aufweisen, bei der sich der Winkel von seinem maximalen Wert auf seinen minimalen Wert wickelt. Folglich kann es vorkommen, dass zwei ähnliche Orientierungen durch Winkel dargestellt sind, die einen Mittelwert haben, der nicht nahe an einem der ursprünglichen Winkel liegt und somit diese Darstellung nicht durchschnittlich ist. Es gibt andere Darstellungen der Kantenorientierung, wie z.B. der Struktur Tensor, die durchschnittbar sind. Ein anderes Beispiel betrifft die Bewegung, wobei in manchen Fällen nur die Normalgeschwindigkeit relativ zu einer Kante extrahiert werden kann. Wurden zwei derartige Merkmale extrahiert und man kann davon ausgehen, daß diese Geschwindigkeit nicht als Mittelwert der Normalgeschwindigkeitsvektoren angegeben ist. Daher sind normale Geschwindigkeitsvektoren nicht durchschnittlich. Stattdessen gibt es andere Darstellungen von Bewegungen mit Matrizen oder Tensoren, die die wahre Geschwindigkeit in Bezug auf einen mittleren Betrieb der normalen Geschwindigkeitsdeskriptoren geben. Merkmalsvektoren und Merkmalsräume In einigen Anwendungen genügt es nicht, nur eine Art von Merkmal zu extrahieren, um die relevanten Informationen aus den Bilddaten zu erhalten. Stattdessen werden zwei oder mehr verschiedene Merkmale extrahiert, was zu zwei oder mehr Merkmalsdeskriptoren an jedem Bildpunkt führt. Eine häufige Praxis besteht darin, die von allen diesen Deskriptoren bereitgestellten Informationen als die Elemente eines einzigen Vektors, allgemein als Merkmalsvektor bezeichnet, zu organisieren. Der Satz aller möglichen Merkmalsvektoren stellt einen Merkmalsraum dar. Ein gemeinsames Beispiel für Merkmalsvektoren erscheint, wenn jeder Bildpunkt als Zugehörigkeit zu einer bestimmten Klasse eingestuft werden soll. Unter der Annahme, dass jeder Bildpunkt einen entsprechenden Merkmalsvektor auf Basis eines geeigneten Merkmalssatzes aufweist, d.h. jede Klasse in dem entsprechenden Merkmalsraum gut getrennt ist, kann die Klassifizierung jedes Bildpunktes mittels Standard-Klassifikationsverfahren erfolgen. Ein anderes und verwandtes Beispiel tritt auf, wenn die neuronale netzbasierte Verarbeitung auf Bilder angewendet wird. Die dem neuronalen Netz zugeführten Eingangsdaten werden oft als Merkmalsvektor aus jedem Bildpunkt angegeben, wobei der Vektor aus mehreren verschiedenen aus den Bilddaten extrahierten Merkmalen aufgebaut ist. Während einer Lernphase kann das Netzwerk selbst herausfinden, welche Kombinationen verschiedener Merkmale zur Lösung des Problems nützlich sind. Multi-Level-Funktionsbearbeitung Die Extraktion von Features wird manchmal über mehrere Skalierungen gemacht. Eines dieser Methoden ist die Skalierungsinvariante Merkmalstransformation (SIFT) ist ein Merkmalsdetektionsalgorithmus in der Computervision; in diesem Algorithmus werden verschiedene Skalen eines Bildes analysiert, um Features zu extrahieren. Siehe auch Computer Vision Automatische Bild-Annotation Feature-Erlernen Feature-Auswahl Vordergrund-Erkennung Vektorisierung (Bild-Tracing) Referenzen Weiter lesen T. Lindeberg (2009). " Skala-Raum In Benjamin Wah (Hg.). Encyclopedia of Computer Science and Engineering.IV. John Wiley and Sons.pp.2495–2504.doi:10.1002/9780470050118.ecse609.ISBN 978-0470050118.(Zusammenfassung und Überprüfung einer Reihe von Merkmalsdetektoren, die auf einer Skalen-Raum-Operation formuliert sind)