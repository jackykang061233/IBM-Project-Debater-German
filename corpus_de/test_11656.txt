Google Brain ist ein vertieftes, künstliches Intelligenz-Forschungsteam im Rahmen von Google AI, einer Forschungsabteilung in Google, die sich für künstliche Intelligenz einsetzt. Google Brain kombiniert im Jahr 2011 Open-Ended-Distributionsforschung mit Informationssystemen und großen Rechenressourcen. Das Team hat Instrumente wie TensorFlow geschaffen, die es ermöglichen, von der Öffentlichkeit neurale Netze mit mehreren internen Forschungsprojekten der AI zu nutzen. Ziel des Teams ist die Schaffung von Forschungsmöglichkeiten im Bereich des maschinellen Lernens und der natürlichen Sprachverarbeitung. Geschichte Das Google Brain-Projekt begann im Jahr 2011 als Teil-Forschungskooperation zwischen Google-Mittler Dean, Google Researcher Greg Corrado und Universitätsprofessor Andrew Ng.Ng hatten Interesse daran, das Problem der künstlichen Intelligenz seit 2006 zu lösen, und 2011 begann die Zusammenarbeit mit Dean und Corrado, um ein umfangreiches, tiefes Lernsoftware-System aufzubauen, DestBelief zusätzlich zur Cloud Computing-Infrastruktur von Google. Google Brain begann als Google X-Projekt und wurde so erfolgreich, dass es auf Google abgestuft wurde: Astro Teller hat gesagt, dass Google Brain im Juni 2012 für die Gesamtkosten von Google X.In New York Times bezahlt hat, dass ein Zusammenschluss von 16.000 Prozessoren in 1000 Computern, die sich für die Umstellung bestimmter Aspekte der menschlichen Gehirntätigkeit einsetzen, erfolgreich ausgebildet war, um eine Katze auf der Grundlage von 10 Millionen digitalen Bildern aus YouTube-Videos zu erkennen. Die Geschichte wurde auch von National Public Radio abgedeckt. Google hat im März 2013 Geoffrey Hinton, ein führender Forscher im Bereich des tiefen Lernens, eingestellt und das Unternehmen DNNResearch Inc. unter Leitung von Hinton erworben. Hinton sagte, er werde seine Zukunft zwischen seiner Universitätsforschung und seiner Arbeit in Google teilen. Team und Standort Google Brain wurden zunächst von Google Fellow Jeff Dean und Gastprofessor Andrew Ng.In 2014 gegründet, das Team umfasst Jeff Dean, KUKA Le, Ilya Sutskever, Alex Krizhevsky, Samy Bengio und Vincent Vanhoucke. 2017 gehören die Teammitglieder Anelia Angelova, Samy Bengio, Greg Corrado, George Dahl, Michael Isard, Anjuli Kannan, Hugo Larochelle, Chris Olah, Salih Edneer, Vincent Vanhoucke, Vijay Vasudevan und Fernanda Viegas. Chris Lattner, der Apples Programmierungssprache zügig gründete und dann das autonome Team von Tesla für sechs Monate lief, trat im August 2017 mit Google Brain zusammen. Lattner verließ das Team im Januar 2020 und trat SiFive bei. Google Brain wird 2021 von Jeff Dean, Geoffrey Hinton und Zoubin Ghahramani geleitet. Andere Mitglieder sind u. a. die Herren You Heller, Pi-Chuan Chang, Ian Simon, Jean-Philippe Vert, Nevena Lazic, Anelia Angelova, Lukasz Kaiser, Carrie Jun Cai, Eric Breck, Ruoming Pang, Carlos Riquelme, David Ha.Samy Bengio verließen im April 2021 das Team mit Zoubin Ghahramani unter seiner Verantwortung. Google Research umfasst Google Brain und basiert auf Bergsicht, Kalifornien. Sie hat auch Satellitengruppen in Accra, Amsterdam, Atlanta, Peking, Berlin, Cambridge (Massachusetts), Israel, Los Angeles, London, Montreal, München, New York City, Paris, Pittsburgh, Pittsburgh, San Francisco, Seattle, Tokio, Toronto und Zürich. Projekte Künstliches Verschlüsselungssystem Google Brain hat im Oktober 2016 ein Experiment entwickelt, um festzustellen, dass die Neuralnetze in der Lage sind, eine sichere symmetrische Verschlüsselung zu erhalten. In diesem Experiment wurden drei Neuralnetze geschaffen: Alice, Bob und Eve.Adhering an die Idee eines generativen Adversarial-Netzes (GAN), das Ziel des Experiments war für Alice, um eine verschlüsselte Botschaft an Bob zu senden, dass Bob entschlüsseln könnte, aber der Adversor, Eve, konnte nicht sein. Alice und Bob hielten einen Vorteil über Eve, da sie einen Schlüssel für Verschlüsselung und Entschlüsselung teilten. Google Brain hat die Fähigkeit von Neuralnetzen bewiesen, sichere Verschlüsselung zu erfahren. Imageverbesserung Google Brain hat im Februar 2017 eine probabilistische Methode für die Umwandlung von Bildern mit 8x8 Entschließung in eine Entschließung von 32x32 festgelegt. Die Methode, die auf einem bereits existierenden probabilistischen Modell namens PixelCNN aufbaut, um Pixel Übersetzungen zu generieren. Die vorgeschlagene Software nutzt zwei Neuralnetze, um Angleichungen für das Pixel von übersetzten Bildern zu machen. Das erste Netzwerk, das als „Klimanetz“ bekannt ist, verringert die hochauflösenden Bilder auf 8x8 und versucht, Kartierungen aus dem Original 8x8 Bild zu diesen höheren Auflösungen zu erstellen. Das andere Netzwerk, das als „prior-Netzwerk“ bekannt ist, nutzt die Kartierungen des vorherigen Netzes, um dem Originalbild näher zu kommen. Das daraus resultierende Übersetzungsbild ist nicht das gleiche Bild in einer höheren Auflösung, sondern eine 32x32-Resolution, die auf anderen vorhandenen hochauflösenden Bildern basiert. Google Brain's Ergebnisse zeigen die Möglichkeit von Neuralnetzen, um Bilder zu verbessern. Google Übersetzung Das Google Brain Team trug zum Google Übersetzungsprojekt bei, indem es ein neues tiefes Lernsystem einsetzt, das künstliche Neuralnetze mit großen Datenbanken von mehrsprachigen Texten verbindet. Im September 2016 wurde Google Neural Maschinen Übersetzung (GNMT) ins Leben gerufen, ein Lernrahmen für End-to-end, der aus einer Vielzahl von Beispielen lernen kann. Früher würde das Konzept von Google Übersetzungs (PBMT) von Google Übersetzung (PBMT) statistisch das Wort analysieren und versuchen, die entsprechenden Wörter in anderen Sprachen abzugleichen, ohne die umliegenden Sätze zu erwägen. BMT bewertet jedoch nicht die Wahl eines Ersatzes für jedes einzelne Wort in der gewünschten Sprache, sondern bewertet Textsegmente im Zusammenhang mit dem Rest der Strafe, um präzisere Ersatzstoffe zu wählen. Im Vergleich zu älteren PBMT-Modellen hat das GNMT-Modell eine Verbesserung von 24% gegenüber der menschlichen Übersetzung mit einem Rückgang der Fehler um 60 % erreicht. Das GMNT hat auch eine erhebliche Verbesserung für unvorhergesehene schwierige Übersetzungen wie chinesisches auf Englisch gezeigt. Obwohl die Einführung des GMNT die Qualität der Übersetzungen von Google Übersetzung in die Pilotsprachen erhöht hat, war es sehr schwierig, solche Verbesserungen für alle seiner 103 Sprachen zu schaffen. Google Brain Team konnte mit diesem Problem ein Mehrsprachiges GNMT-System entwickeln, das das frühere System erweitert und Übersetzungen zwischen verschiedenen Sprachen ermöglichte. Darüber hinaus ermöglicht es es Null-Shot Übersetzungen, die Übersetzungen zwischen zwei Sprachen sind, die das System noch nie ausdrücklich gesehen hat. Google kündigte an, dass Google Übersetzung jetzt auch ohne Umschichtung mit Neuralnetzen umgehen kann. Dies bedeutet, dass es möglich ist, die Rede in einer Sprache direkt in eine andere Sprache zu übersetzen, ohne sie zuerst zu übersetzen. Laut den Forschern in Google Brain kann dieser Zwischenschritt durch Neuralnetze vermieden werden. Um das System zu lernen, haben sie es vielen Stunden spanischen Audio zusammen mit dem entsprechenden englischen Text ausgesetzt. Die verschiedenen Ebenen der Neuralnetze, die das menschliche Gehirn replizieren, konnten die entsprechenden Teile miteinander verbinden und anschließend die Audio-Wellenform, bis sie in den englischen Text umgewandelt wurde, angreifen. Ein weiterer Rückschlag des GMNT-Modells ist, dass es die Zeit der Übersetzung verursacht, um exponentiell mit der Zahl der Wörter in der Strafe zu erhöhen. Dies führte dazu, dass das Google Brain Team 2000 weitere Prozessoren hinzufügt, um sicherzustellen, dass der neue Übersetzungsprozess immer noch schnell und zuverlässig ist. Robotik mit dem Ziel, traditionelle Roboter-Kontrollalgorithmen zu verbessern, wenn neue Fähigkeiten eines Roboters Handprogrammiert werden müssen, entwickeln Roboter-Forscher auf Google Brain maschinelle Lerntechniken, damit die Roboter selbst neue Fähigkeiten erwerben können. Sie versuchen auch, Möglichkeiten für den Informationsaustausch zwischen Robotern zu entwickeln, damit Roboter während ihres Lernprozesses voneinander lernen können, auch bekannt als Cloud-Roboter. Infolgedessen hat Google 2019 die Google Cloud Robotics Plattform für Entwickler ins Leben gerufen, um Robotik, AI und Cloud miteinander zu kombinieren, um eine effiziente Roboterautomatisierung durch Cloud-connected-Chips zu ermöglichen. Robotik-Forschung auf Google Brain hat sich vor allem auf die Verbesserung und Anwendung von Deep Learning-Algorithmen konzentriert, um die Roboter in die Lage zu versetzen, ihre Aufgaben durch Erfahrung, Simulation, menschliche Demonstrationen und/oder visuelle Vertretungen zu erfüllen. Google Brain-Forscher zeigten beispielsweise, dass Roboter in ausgewählten Boxen lernen können, indem sie in einem Umfeld experimentieren, ohne vorherprogrammiert zu werden. In einer anderen Forschung haben Forscher Roboter ausgebildet, um Verhaltensmuster zu lernen, wie Flüssigkeit aus einem Becher; Roboter aus Videos menschlicher Demonstrationen, die aus mehreren Blickwinkeln aufgezeichnet wurden. Google Brain-Forscher haben mit anderen Unternehmen und akademischen Einrichtungen für die Robotik-Forschung zusammengearbeitet. Im Jahr 2016 arbeitet das Google Brain Team mit Forschern bei X in einer Forschung auf dem Gebiet der kognitiven Erfassung zusammen. Ihre Methode erlaubte die Echtzeit-Roboterkontrolle für die Erfassung neuartiger Objekte mit Selbstkorrektur. Im Jahr 2020 haben Forscher aus Google Brain, Intel AI Lab und Berkeley UC ein AI-Modell für Roboter entwickelt, um operationsbezogene Aufgaben wie die Verhängung von Schulungen mit chirurgischen Videos zu lernen. Interaktiver Redner Anerkennung mit verstärktem Lernen 2020 präsentierten Google Brain Team und Universität Lille ein Modell für die automatische Anerkennung von Rednern, die sie als Interactive-Botschafter bezeichneten. Das ISR-Modul erkennt einen Sprecher aus einer bestimmten Liste von Rednern nur an, indem er einige benutzerspezifische Worte fordert. Das Modell kann geändert werden, um Sprachsegmente im Zusammenhang mit Text-To-Speech Training auszuwählen. Man kann auch schädliche Sprachgeneratoren zum Schutz der Daten verhindern. Tensor Fluss Tenor Flow ist eine Open-Source-Software-Bibliothek, die von Google Brain betrieben wird, die es jedem ermöglicht, das maschinelle Lernen zu nutzen, indem es die Werkzeuge bereitstellt, um ein eigenes Neuralnetz zu nutzen. Das Werkzeug wurde von den Landwirten genutzt, um die Menge der manuellen Arbeit zu reduzieren, die erforderlich ist, um ihren Ertrag zu ermitteln, indem es mit einem Datenkatalog menschlicher Bilder ausgebildet. Magenta Magenta ist ein Projekt, das Google Brain nutzt, um neue Informationen in Form von Kunst und Musik zu schaffen anstatt bestehende Daten einzustufen und zu differenzieren. TensorFlow wurde mit einer Reihe von Werkzeugen für die Nutzer aktualisiert, um das Neuralnetz zu leiten, um Bilder und Musik zu erstellen. Das Team von Valdosta State University stellte jedoch fest, dass die AI versucht, die menschliche Absicht in der Künstlerschaft perfekt zu reproduzieren, ähnlich wie die Übersetzungsprobleme. Medizinische Anwendungen Das Image Sortierungspotential von Google Brain wurde genutzt, um bestimmte medizinische Bedingungen zu erkennen, indem man Muster sucht, die menschliche Ärzte möglicherweise nicht in der Lage sind, eine frühere Diagnose vorzulegen. Während der Vorsorge für Brustkrebs wurde diese Methode gefunden, um ein Viertel der falschen positiven Rate von Humanpathologen zu haben, die mehr Zeit benötigen, um jedes Foto zu betrachten und ihren gesamten Fokus auf diese Aufgabe nicht zu verbringen. Aufgrund der sehr spezifischen Ausbildung des Neuralnetzes für eine einzelne Aufgabe kann es nicht andere in einem Foto vorkommende Erkrankungen erkennen, die ein Mensch leicht zu sehen haben. Andere Produkte von Google Die Technologie von Google Brain-Projekten wird derzeit in verschiedenen anderen Google-Produkten wie dem Spracherkennungssystem von Android, der Fotosuche für Google-Fotos, der intelligenten Antwort in AdWords und Videoempfehlungen in YouTube verwendet. Google Brain hat in Wired Magazine, National Public Radio und Big Think empfangen. Diese Artikel haben Interviews mit den wichtigsten Teammitgliedern Ray Kurzweil und Andrew Ng aufgenommen und konzentrieren sich auf die Erläuterung der Ziele und Anwendungen des Projekts. ControversyIn Dezember 2020, AI eethikist Timnit Gebru verließ Google. Obwohl die genaue Natur ihrer Anteilnahme oder Brände umstritten ist, war die Ursache der Abfahrt die Ablehnung, ein Papier mit dem Titel „Denger von Stochastic Parrots: Can Language Modelle sind Too Big?“ zurückzuziehen. In diesem Papier wurden potenzielle Risiken des Wachstums von AI wie Google Brain untersucht, einschließlich Umweltauswirkungen, Verzerrungen bei Fortbildungsdaten und der Fähigkeit, die Öffentlichkeit zu täuschen. Megan Kacholia, Vizepräsident von Google Brain, wurde gebeten, das Papier zurückzuziehen. Seit April 2021 haben fast 7.000 derzeitige oder frühere Google-Bedienstete und Industrie-Unternehmer ein offenes Schreiben unterzeichnet, mit dem Google von „Forschung censorship“ missbraucht und die Behandlung von Gebru auf dem Unternehmen verurteilt wird. Google hat im Februar 2021 eine der Führer des AI-Eigenschaftsteams des Unternehmens Margaret Mitchell gefeuert. Laut Aussage des Unternehmens wurde behauptet, dass Mitchell die Gesellschaftspolitik durch die Verwendung automatisierter Instrumente für die Unterstützung von Gebru zerbrochen hatte. In demselben Monat begannen Ingenieure außerhalb des Ethik-Teams, die „künftige“ Beendigung von Gebru als Grund zu beenden. Im April 2021 kündigte Google Brain Co-Unternehmer Samy Bengio seinen Rücktritt vom Unternehmen an. Bengio wurde zwar nicht vor der Beendigung von Gebru's Manager unterrichtet, aber er hat sich online zur Unterstützung ihrer und Mitchell entsendet. Bengios Ankündigung konzentrierte sich zwar auf persönliches Wachstum als Grund für das Verlassen, doch anonyme Quellen erklärten Reuters, dass die Turbulenzen innerhalb des AI-Eigenschaftsteams eine Rolle in seinen Überlegungen gespielt haben. Siehe auch Künstliche Intelligenz Deep Learning Glossar der künstlichen Intelligenz Quanten Künstliche Intelligenz Lab – wird von Google in Zusammenarbeit mit der NASA und der University Space Research Association Noogene TensorFlow TimnitGebru Samy Bengio durchgeführt. Links