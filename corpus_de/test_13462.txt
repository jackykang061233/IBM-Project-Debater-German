Die Analyse der klinischen Studien umfasst viele verwandte Themen, u.a. die Wahl eines geschätzten und (Wirkungsgröße) von Interesse, das eng mit den Zielen der Studie verknüpft ist, die Wahl und Definition von Analysesätzen, die Wahl eines geeigneten statistischen Modells für die Art der untersuchten Daten, die angemessene Abrechnung des Behandlungsprozesses, die Handhabung fehlender Daten, die Behandlung mehrerer Vergleiche oder Endpunkte, die Abrechnung von Zwischenanalysen und Studienanpassungen sowie eine entsprechende Datenpräsentation. Ein grundlegendes Leitfaden zu diesem Thema ist die Internationale Konferenz zur Harmonisierung der technischen Anforderungen für die Registrierung von Arzneimitteln für die menschliche Ernährungsberatung E9. Wahl des Analysesets Die Nichteinbeziehung aller Teilnehmer an der Analyse kann die Testergebnisse beeinträchtigen. Die meisten Versuche liefern jedoch keine perfekten Daten."Protokollverletzungen" können auftreten, z.B. wenn die Patienten nicht den vollen Eingriff oder den korrekten Eingriff erhalten oder einige unzulängliche Patienten im Irrtum zufällig zugeordnet werden. Obwohl die meisten klinischen Studien sorgfältig geplant sind, können viele Probleme während der Durchführung der Studie auftreten. Einige Beispiele sind wie folgt: Patienten, die die Inklusions- und/oder Ausschlusskriterien nicht erfüllen, sind in der Studie enthalten, Ein Patient ist randomisiert auf die Behandlung A, wird aber mit der Behandlung B behandelt, Einige Patienten fallen aus der Studie, oder Einige Patienten sind nicht konform, d.h. nehmen Sie nicht ihre Medikamente wie angewiesen, und so weiter. Wie behandelte As-behandelte Analyse hat die allgemeine Idee, die Themen durch die Behandlung Regime, die sie erhalten. Sie berücksichtigt nicht, welche Behandlung sie für die Behandlung zugewiesen wurden. Die Absicht, Randomized klinischen Studien zu behandeln, die durch den Intention-to-treat (ITT)-Ansatz analysiert werden, bieten faire Vergleiche zwischen den Behandlungsgruppen, weil es die Vorspannung im Zusammenhang mit dem nicht-random-Verlust der Teilnehmer vermeidet. Das grundlegende ITT-Prinzip besteht darin, dass die Teilnehmer an den Versuchen in den Gruppen analysiert werden sollten, an denen sie randomisiert wurden, unabhängig davon, ob sie die zugeteilte Intervention erhalten oder eingehalten haben. Allerdings haben medizinische Ermittler oft Schwierigkeiten, die ITT-Analyse aufgrund von klinischen Studienproblemen wie fehlenden Daten oder der Einhaltung von Protokollen zu akzeptieren. Pro Protokoll Diese Analyse kann nur auf die Teilnehmer beschränkt werden, die das Protokoll in Bezug auf die Förderfähigkeit, die Einhaltung der Intervention und die Ergebnisbewertung erfüllen. Diese Analyse wird als On- oder "per Protokoll"-Analyse bezeichnet. Eine Per-Protocol-Analyse stellt ein "Best-Case-Szenario" dar, um die Wirkung des untersuchten Arzneimittels zu zeigen. Durch die Beschränkung der Analyse auf eine ausgewählte Patientenpopulation zeigt sie jedoch nicht alle Auswirkungen des neuen Medikaments. Ferner kann die Einhaltung der Behandlung durch andere Faktoren beeinflusst werden, die das Ergebnis beeinflussen. Daher sind Per-Protokoll-Effekte in Gefahr, während die Vorabschätzung nicht erfolgt. Fehlende Daten Eines der wichtigsten Probleme bei der Analyse einer klinischen Studie ist das Auftreten des Ausfalls. Gemäß der Erklärung von Helsinki müssen Patienten in klinischen Studien ganz freiwillig teilnehmen und das Recht haben, jederzeit die Studie zu verlassen. Dieser ethische Imperativ macht fehlende Daten zu einem unvermeidlichen Problem der klinischen Studien und erfordert entsprechende Analysemethoden, um sie zu berücksichtigen. Da Patienten oft ausfallen, weil sie eine Behandlung finden scheint nicht für sie zu arbeiten oder weil sie schädliche Nebenwirkungen verursacht, sind fehlende Daten oft mit der Wirksamkeit oder Sicherheit der Behandlung korreliert. Diese Art der Auswahlvorspannung macht eine zuverlässige Bewertung der Ergebnisse einer klinischen Studie besonders schwierig. Methoden zur Adressierung fehlender Daten machen Annahmen über die Beziehung zwischen Dropout- und Studienergebnissen, um Ergebnisse zu erzeugen, die die fehlenden Daten berücksichtigen. Da die Annahmen, die einer bestimmten Methode zugrunde liegen, für eine bestimmte Studie unangemessen sein können, ist es erforderlich, die Frage zu beantworten. Letzte Beobachtung Eine Methode zur Verarbeitung fehlender Daten ist es, Werte auf Basis bestehender Daten einfach zu erfassen oder auszufüllen. Eine Standardmethode hierfür ist die Methode Last-Observation-Carried-Forward (LOCF). Das LOCF-Verfahren ermöglicht die Analyse der Daten. Die jüngsten Untersuchungen zeigen jedoch, dass diese Methode eine voreingenommene Schätzung des Behandlungseffekts liefert und die Variabilität des geschätzten Ergebnisses unterschätzt. Als Beispiel nehmen Sie an, dass es 8 wöchentliche Bewertungen nach der Basisbeobachtung gibt. Sinkt ein Patient nach der dritten Woche aus der Studie heraus, so wird dieser Wert "vorwärts" und angenommen, dass er seine Punktzahl für die 5 fehlenden Datenpunkte ist. Die Annahme ist, dass sich die Patienten von Beginn der Studie bis zum Ende allmählich verbessern, so dass die Vorgabe eines Zwischenwertes eine konservative Schätzung ist, wie gut die Person getan hätte, wenn sie in der Studie geblieben wäre. Die Vorteile des LOCF-Ansatzes sind: Es minimiert die Anzahl der Themen, die aus der Analyse eliminiert werden, und Es ermöglicht die Analyse, die Trends im Laufe der Zeit zu untersuchen, anstatt sich einfach auf den Endpunkt zu konzentrieren. Die Nationale Akademie der Wissenschaften, in einem beratenden Bericht an die Food and Drug Administration über fehlende Daten in klinischen Studien, empfohlen gegen die unkritische Anwendung von Methoden wie LOCF, in dem besagt, dass "Eine Imputationsmethoden wie letzte Beobachtung vorgetragen und grundlegende Beobachtung vorgetragen werden sollte nicht als primärer Ansatz für die Behandlung von fehlenden Daten verwendet werden, es sei denn, die Annahmen, die sie zugrunde liegen, sind wissenschaftlich gerechtfertigt. " Die grundlegende Annahme, die der LOCF zugrunde liegt - dass Patienten, die Behandlungen erhalten, besser werden, was die Behandlung fehlender Daten als wenn die Vergangenheit unverändert konservativ fortgeführt hätte - ist oft nicht wahr. Viele Medikamente behandeln Bedingungen wie Krebs, Herzinsuffizienz oder AIDS, bei denen Patienten erwartet werden, sich zu verschlechtern oder zu sterben, während unter Beobachtung; und wo Erfolg kommt von der Aufrechterhaltung des Status quo, Verlängerung des Lebens oder Verhinderung von Verschlechterung, nicht von der Heilung oder Verbesserung. Darüber hinaus können auch heilende Medikamente schädliche und manchmal tödliche Nebenwirkungen und Sicherheitsprobleme haben. Für diese Arten von Testkontexten kann die Handhabung fehlender Daten, als ob die Vergangenheit unverändert geblieben wäre, zu einer Überbrückung der Wirksamkeit oder zu einer Unterbrückung von schädlichen Sicherheitsproblemen führen, wodurch die Ergebnisse in einer Weise, die die Untersuchungsbehandlung sicherer oder wirksamer erscheinen lässt als es tatsächlich ist. Darüber hinaus, auch wenn sie nicht unangemessene Vorurteile hinzufügen, überschätzen einfache Imputationsmethoden die Genauigkeit und Zuverlässigkeit der Schätzungen und die Macht der Studie, die Behandlung zu bewerten. Wenn Daten fehlen, wird die Stichprobengröße, auf der Schätzungen basieren, abgesenkt. Einfache Imputationsmethoden ignorieren diese Abnahme der Probengröße und neigen daher dazu, die Variabilität der Ergebnisse zu unterschätzen. Mehrere Imputationsmethoden Die Nationale Akademie der Wissenschaften Beratung Panel stattdessen empfohlen Methoden, die gültige Typ I Fehlerquoten unter explizit genannten Annahmen unter Berücksichtigung fehlender Datenstatus, und die Verwendung von mehreren Imputationsmethoden basierend auf allen im Modell verfügbaren Daten. Es empfahl eine breitere Verwendung von Bootstrap und Generalized Schätzgleichung Methoden, wenn die Annahmen, die ihnen zugrunde liegen, wie Missing bei Random für GEE Methoden, gerechtfertigt werden kann. Sie empfahl, Hilfsdaten zu sammeln, die mit Dropouts verbunden sind, um robustere und zuverlässige Modelle zu liefern, Informationen über Grund für den Drop-out zu sammeln; und, wenn möglich, nach oben auf Drop-outs und Erhalt der Wirksamkeit Ergebnisdaten. Schließlich empfahl sie eine Sensitivitätsanalyse im Rahmen der klinischen Studie zur Beurteilung der Empfindlichkeit der Ergebnisse auf die Annahmen über den fehlenden Datenmechanismus. Während die vom National Academy of Science-Bericht empfohlenen Methoden in jüngster Zeit weiterentwickelt, robuster sind und unter einer größeren Vielfalt von Bedingungen arbeiten werden, als Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Ein-Methoden wie LOCF. Wie die International Conference on Harmonization E9 Guidance on Statisticial Principles for Clinical Trials von 1998 bemerkte, "Leitlinien für statistische Prinzipien für klinische Versuche können leider keine allgemein anwendbaren Methoden zur Behandlung fehlender Werte empfohlen werden." Ein fachkundiges statistisches und medizinisches Urteil muss die Methode auswählen, die für die besonderen Versuchsbedingungen der verfügbaren unvollkommenen Techniken am besten geeignet ist, je nach den Zielen, Endpunkten, statistischen Methoden und Kontexten. Referenzen AR Waladkhani.(2008). Durchführung klinischer Studien. Ein theoretischer und praktischer Leitfaden. ISBN 978-3-940934-00-0