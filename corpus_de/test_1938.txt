Ein Touchscreen oder Touchscreen ist die Montage eines Eingabe- '(Touch-Panel) und Ausgabe- (Display)-Geräts. Das Touchpanel wird normalerweise auf der Oberseite einer elektronischen visuellen Anzeige eines Informationsverarbeitungssystems geschichtet. Das Display ist oft ein LCD AMOLED oder OLED-Display, während das System in der Regel ein Laptop, Tablet oder Smartphone ist. Ein Benutzer kann die Eingabe oder Steuerung des Informationsverarbeitungssystems durch einfache oder Multi-Touch-Gesten durch Berührung des Bildschirms mit einem speziellen Stylus oder einem oder mehreren Fingern geben. Einige Touchscreens verwenden gewöhnliche oder speziell beschichtete Handschuhe, um zu arbeiten, während andere nur mit einem speziellen Stylus oder Stift arbeiten können. Der Benutzer kann den Touchscreen verwenden, um auf das angezeigte zu reagieren und, wenn die Software erlaubt, zu steuern, wie es angezeigt wird; zooming, um die Textgröße zu erhöhen. Der Touchscreen ermöglicht es dem Benutzer, direkt mit dem angezeigten zu interagieren, anstatt mit einer Maus, einem Touchpad oder anderen solchen Geräten (außer einem Stil, der für die meisten modernen Touchscreens optional ist). Touchscreens sind in Geräten wie Spielkonsolen, Personalcomputern, elektronischen Abstimmungsmaschinen und Point-of-sale (POS) Systemen üblich. Sie können auch an Computern oder als Endgeräte an Netzwerken befestigt werden. Sie spielen eine herausragende Rolle bei der Gestaltung von digitalen Geräten wie persönlichen digitalen Assistenten (PDAs) und einigen E-Readern. Touchscreens sind auch in pädagogischen Einstellungen wie Klassenzimmer oder auf College-Campuses wichtig. Die Popularität von Smartphones, Tablets und vielen Arten von Informationsgeräten treibt die Nachfrage und Akzeptanz von gemeinsamen Touchscreens für tragbare und funktionale Elektronik. Touchscreens finden sich im medizinischen Bereich, in der Schwerindustrie, in automatisierten Tellermaschinen (ATMs) und in Kiosken wie Museumsdisplays oder Raumautomation, wo Tastatur- und Maussysteme keine entsprechend intuitive, schnelle oder genaue Interaktion des Benutzers mit dem Inhalt des Displays zulassen. Historisch wurden der Touchscreen-Sensor und seine dazugehörigen Controller-basierten Firmware von einer Vielzahl von nachgelagerten Systemintegratoren zur Verfügung gestellt, nicht von Display-, Chip- oder Motherboard-Herstellern. Display-Hersteller und Chip-Hersteller haben den Trend zur Akzeptanz von Touchscreens als Benutzeroberflächenkomponente erkannt und begonnen, Touchscreens in die grundlegende Gestaltung ihrer Produkte zu integrieren. Die Geschichte Eric Johnson, des Royal Radar Establishment, in Malvern, England, beschreibt seine Arbeit auf kapazitiven Touchscreens in einem kurzen Artikel, der 1965 veröffentlicht wurde und dann – mit Fotografien und Diagrammen – in einem Artikel, der 1967 veröffentlicht wurde. Die Anwendung der Touch-Technologie für die Luftverkehrskontrolle wurde in einem Artikel beschrieben, der 1968 veröffentlicht wurde. Frank Beck und Bent Stumpe, Ingenieure der CERN (European Organization for Nuclear Research), entwickelten Anfang der 1970er Jahre einen transparenten Touchscreen, der auf Stumpes Arbeit in einer Fernsehfabrik in den frühen 1960er Jahren basierte. Anschließend von CERN hergestellt, und kurz danach von Industriepartnern, wurde es 1973 eingesetzt. Mitte der 1960er Jahre war ein weiterer Vorläufer von Touchscreens, ein Ultraschall-Curtain-basiertes Zeigegerät vor einem Terminal-Display, von einem Team um Rainer Mallebrein bei Telefunken Konstanz für ein Luftverkehrsleitsystem entwickelt worden. 1970 entwickelte sich dies zu einem Gerät namens Touchinput-Einrichtung ("Touch-Eingangsanlage)" für das SIG 50-Terminal unter Verwendung eines leitfähigen beschichteten Glasschirms vor dem Display. Dies wurde 1971 patentiert und das Patent wurde ein paar Jahre später erteilt. Das gleiche Team hatte bereits die Rollkugel Maus RKS 100-86 für die SIG 100-86 ein paar Jahre früher erfunden und vermarktet. 1977 begann ein amerikanisches Unternehmen, Elographics, in Zusammenarbeit mit Siemens, mit der Entwicklung einer transparenten Umsetzung einer bestehenden opaken Touchpad-Technologie, US-Patent Nr. 3,911,215 7. Oktober 1975, der von Elographics Gründer George Samuel Hurst entwickelt worden war. Der resultierende Widerstandstechnologie-Touchscreen wurde 1982 erstmals gezeigt. 1972 reichte eine Gruppe an der Universität Illinois ein Patent auf einem optischen Touchscreen ein, der zu einem Standardteil des Studententerminals Magnavox Plato IV wurde und dazu Tausende gebaut wurden. Diese Touchscreens hatten eine gekreuzte Anordnung von 16 x 16 Infrarot-Positionssensoren, die jeweils aus einer LED an einer Kante des Bildschirms und einem aufeinander abgestimmten Phototransistor an der anderen Kante zusammengesetzt sind, die alle vor einer monochromen Plasmadisplay-Panel montiert sind. Diese Anordnung könnte in unmittelbarer Nähe des Bildschirms ein beliebiges Fingerspitzenobjekt erfassen. Ein ähnlicher Touchscreen wurde 1983 auf der HP-150 verwendet. Der HP 150 war einer der weltweit ältesten kommerziellen Touchscreen-Computer. HP montierte ihre Infrarot-Sender und Empfänger um die Lünette einer 9-Zoll-Kathodenstrahlröhre (CRT). 1984 veröffentlichte Fujitsu ein Touch-Pad für das Micro 16, um die Komplexität von Kandji-Zeichen, die als geflieste Grafiken gespeichert wurden, zu unterbringen. Im Jahr 1985 veröffentlichte Sega die Terebi Oekaki, auch bekannt als Sega Graphic Board, für die SG-1000 Videospielkonsole und SC-3000 Heimcomputer. Es bestand aus einem Kunststoffstift und einer Kunststoffplatte mit einem transparenten Fenster, in dem Stiftpressen erfasst werden. Es wurde hauptsächlich mit einer Zeichnungssoftware-Anwendung verwendet. Eine grafische Touch-Tablette wurde 1986 für den Sega AI Computer freigegeben. In den frühen 1980er Jahren wurden berührungsempfindliche Steuerungsdisplay-Einheiten (CDUs) für kommerzielle Flugzeugflugdecks ausgewertet. Die erste Forschung zeigte, dass eine Touch-Schnittstelle die Pilot-Workload reduzieren würde, da die Crew dann Wegepunkte, Funktionen und Aktionen auswählen konnte, anstatt "kopf-down" zu tippen Breiten, Längen und Wegpunkt-Codes auf einer Tastatur. Eine effektive Integration dieser Technologie zielte darauf ab, Flugbesatzungen zu unterstützen, ein hohes Maß an Situationsbewusstsein für alle wichtigen Aspekte des Fahrzeugbetriebs, einschließlich des Flugweges, der Funktionsweise verschiedener Flugzeugsysteme und der momentanen menschlichen Interaktionen, zu erhalten. In den frühen 1980er Jahren beauftragte General Motors seine Division Delco Electronics mit einem Projekt, das darauf abzielte, die nicht-essentiellen Funktionen eines Automobils (d.h. außer Drosselung, Getriebe, Bremsung und Lenkung) von mechanischen oder elektromechanischen Systemen mit möglichst festen Zustandsalternativen zu ersetzen. Das fertige Gerät wurde das ECC für "Electronic Control Center", ein digitales Computer- und Software-Steuersystem, das an verschiedene periphere Sensoren, Servos, Magnete, Antenne und ein monochromes CRT-Touchscreen festverdrahtet wurde, die sowohl als Display- als auch als Sohlenverfahren der Eingabe fungierten. Das ECC ersetzte die herkömmlichen mechanischen Stereo-, Lüfter-, Heizungs- und Klimaanlagen und Displays und konnte in Echtzeit sehr detaillierte und spezifische Informationen über den kumulativen und aktuellen Betriebszustand des Fahrzeugs liefern. Die ECC war Standardausrüstung an der Buick Riviera von 1985 bis 1989 und später der Buick Reatta von 1988 bis 1989, war aber bei den Verbrauchern unbeliebt – zum Teil aufgrund der Technophobie einiger traditioneller Buick-Kunden, vor allem aber wegen aufwendiger technischer Probleme, die durch den Touchscreen des ECC erlitten wurden, was die Klimakontrolle oder den Stereobetrieb unmöglich macht. Die Multi-Touch-Technologie begann im Jahr 1982, als die University of Toronto's Input Research Group das erste Multi-Touch-System für Mensch-Input entwickelt hat, mit einem Glaspanel mit einer hinter dem Glas platzierten Kamera. Im Jahr 1985 entwickelte die Gruppe der University of Toronto, darunter Bill Buxton, eine Multi-Touch-Tablette, die Kapazität anstelle von sperrigen kamerabasierten optischen Sensorsystemen verwendet (siehe Geschichte des Multi-Touch). Die erste kommerziell erhältliche grafische Point-of-sale (POS) Software wurde auf dem 16-Bit Atari 520ST Farbrechner gezeigt. Es verfügte über eine Farb-Touchscreen-Widget-gesteuerte Schnittstelle. Die ViewTouch POS Software wurde erstmals von seinem Entwickler, Gene Mosher, im Atari Computer Demonstrationsbereich der Fall COMDEX expo im Jahr 1986 gezeigt. 1987 startete Casio den Casio PB-1000 Taschenrechner mit einem Touchscreen, bestehend aus einer 4×4 Matrix, wodurch 16 Touch-Bereiche in seinem kleinen LCD-Grafikbildschirm entstehen. Touchscreens hatten einen schlechten Ruf, bis 1988 ungenau zu sein. Die meisten Benutzer-Interface-Bücher würden sagen, dass Touchscreen-Auswahlen auf Ziele beschränkt waren, die größer als der durchschnittliche Finger waren. Zu diesem Zeitpunkt wurden so Auswahlen vorgenommen, dass ein Ziel ausgewählt wurde, sobald der Finger über ihn kam, und die entsprechende Aktion sofort durchgeführt wurde. Fehler waren häufig, aufgrund von Parallax- oder Kalibrierproblemen, was zu Benutzerfrustration führte. "Lift-off-Strategie" wurde von Forschern am University of Maryland Human–Computer Interaction Lab (HCIL) eingeführt. Beim Berühren des Bildschirms wird das Feedback dazu bereitgestellt, was gewählt wird: Benutzer können die Position des Fingers einstellen, und die Aktion erfolgt nur dann, wenn der Finger vom Bildschirm abgehoben wird. Dies erlaubte die Auswahl kleiner Ziele, bis zu einem einzigen Pixel auf einem 640×480 Video Graphics Array (VGA) Bildschirm (ein Standard dieser Zeit). Sears et al.(1990) gab eine Überprüfung der akademischen Forschung über ein- und mehr-Touch Mensch-Computer-Interaktion der Zeit, beschreiben Gesten wie Drehknöpfe, Einstellschieber und tauschen den Bildschirm, um einen Schalter (oder eine U-förmige Geste für einen Kniehebelschalter) zu aktivieren. Das HCIL-Team entwickelte und studierte kleine Touchscreen-Tastaturen (einschließlich einer Studie, die gezeigt hat, dass Benutzer auf einer Touchscreen-Tastatur bei 25 Wpm eingeben konnten), die ihre Einführung auf mobilen Geräten unterstützten. Sie entwickelten und implementierten auch Multi-Touch-Gesten wie die Auswahl eines Bereiches einer Zeile, die Verbindung von Objekten und eine Tipp-Click-Geste, um unter Beibehaltung der Position mit einem anderen Finger auszuwählen. Im Jahr 1990 zeigte HCIL einen Touchscreen-Slider, der später als Stand der Technik in der Sperrbild-Patentschrift zwischen Apple und anderen Touchscreen-Handy-Anbietern (bezogen auf US 7,657,849) zitiert wurde. 1991–1992 führte der Sun Star7 Prototyp PDA einen Touchscreen mit Inertial-Scrolling durch. 1993 veröffentlichte IBM den IBM Simon das erste Touchscreen-Handy. Ein früher Versuch einer Handspielkonsole mit Touchscreen-Steuerungen war Segas zielgerichteter Nachfolger des Game Gears, obwohl das Gerät schließlich geschnitzt wurde und aufgrund der teuren Kosten der Touchscreen-Technologie in den frühen 1990er Jahren nie freigegeben wurde. Das erste Handy mit einem kapazitiven Touchscreen wurde LG Prada im Mai 2007 veröffentlicht (was vor dem ersten iPhone war). Touchscreens würden für Videospiele bis zur Veröffentlichung des Nintendo DS im Jahr 2004 nicht beliebt verwendet werden. Bis vor kurzem konnten die meisten Verbraucher-Touchscreens nur einen Punkt des Kontakts zu einer Zeit spüren, und wenige hatten die Fähigkeit zu spüren, wie schwer man anfasst. Dies hat sich mit der Vermarktung von Multi-Touch-Technologie geändert und die Apple Watch wird im April 2015 mit einem kraftempfindlichen Display veröffentlicht. Im Jahr 2007 wurden 93 % der ausgelieferten Touchscreens resistent und nur 4 % der Kapazität projiziert. 2013 wurden 3% der ausgelieferten Touchscreens widerstehend und 90% der Kapazität projiziert. Technologien Es gibt eine Vielzahl von Touchscreen-Technologien mit verschiedenen Methoden der Berührungserkennung. Resistenz Ein resistives Touchscreen-Panel besteht aus mehreren dünnen Schichten, deren wichtigster Bestandteil zwei transparente elektrisch resistive Schichten sind, die einander mit einem dünnen Spalt zwischen einander zugewandt sind. Die Deckschicht (die berührt wird) weist auf der Unterseite eine Beschichtung auf, darunter eine ähnliche Widerstandsschicht auf ihrem Substrat. Eine Schicht weist entlang ihrer Seiten leitende Verbindungen auf, die andere nach oben und unten. Auf eine Schicht wird eine Spannung angelegt und von der anderen erfasst. Drückt ein Objekt, wie z.B. eine Fingerspitze oder Tastspitze, auf die Außenfläche, so berühren sich die beiden Schichten an dieser Stelle zu verbinden. Das Panel verhält sich dann als ein Paar Spannungsteiler, eine Achse zu einem Zeitpunkt. Durch schnelles Umschalten zwischen jeder Schicht kann die Druckposition auf dem Bildschirm erfasst werden. Resistive Berührung wird in Restaurants, Fabriken und Krankenhäusern aufgrund seiner hohen Toleranz für Flüssigkeiten und Verunreinigungen verwendet. Ein großer Vorteil der Resist-Touch-Technologie ist ihre niedrigen Kosten. Darüber hinaus können sie, da nur ein ausreichender Druck für die zu erfassende Berührung erforderlich ist, mit Handschuhen an oder mit allem, was als Fingerersatz starr ist, verwendet werden. Nachteile sind die Notwendigkeit, nach unten zu drücken, und die Gefahr von Beschädigungen durch scharfe Objekte. Resistive Touchscreens leiden auch unter schlechterem Kontrast, da zusätzliche Reflexionen (d.h. Blendung) aus den über den Bildschirm gelegten Materialschichten bestehen. Dies ist die Art von Touchscreen, die von Nintendo in der DS-Familie, der 3DS-Familie und der Wii U GamePad verwendet wurde. Oberflächenakustische Welle Oberflächenakustische Welle (SAW) Technologie verwendet Ultraschallwellen, die das Touchscreen-Panel passieren. Wenn das Panel berührt wird, wird ein Teil der Welle absorbiert. Die Veränderung der Ultraschallwellen wird vom Regler zur Bestimmung der Position des Berührungsereignisses verarbeitet. Oberflächenakustische Wellen-Touchscreen-Paneele können durch äußere Elemente beschädigt werden. Verunreinigungen auf der Oberfläche können auch die Funktionalität des Touchscreens beeinträchtigen. Kapazitiv Ein kapazitives Touchscreen-Panel besteht aus einem Isolator, wie Glas, beschichtet mit einem transparenten Leiter, wie Indiumzinnoxid (ITO). Da der menschliche Körper auch ein elektrischer Leiter ist, führt eine Berührung der Oberfläche des Bildschirms zu einer Verzerrung des elektrostatischen Feldes des Bildschirms, messbar als Kapazitätsänderung. Verschiedene Technologien können verwendet werden, um den Ort der Berührung zu bestimmen. Der Ort wird dann zur Verarbeitung an den Controller gesendet. Touchscreens, die Silber anstelle von ITO verwenden, existieren, da ITO aufgrund der Verwendung von Indium mehrere Umweltprobleme verursacht. Bei der Steuerung handelt es sich typischerweise um einen komplementären metalloxid-semiconductor (CMOS) anwendungsspezifischen integrierten Schaltkreis (ASIC)-Chip, der wiederum üblicherweise die Signale an einen CMOS-digitalen Signalprozessor (DSP) zur Verarbeitung sendet. Im Gegensatz zu einem resistiven Touchscreen können einige kapazitive Touchscreens nicht verwendet werden, um einen Finger durch elektrisch isolierendes Material wie Handschuhe zu erfassen. Dieser Nachteil wirkt sich insbesondere auf die Bedienbarkeit in der Unterhaltungselektronik wie Touch-Tablet-PCs und kapazitive Smartphones bei kaltem Wetter aus, wenn man Handschuhe tragen kann. Es kann mit einem speziellen kapazitiven Stylus oder einem speziellen Applikationshandschuh mit einem bestickten Patch aus leitfähigem Gewinde überwunden werden, der einen elektrischen Kontakt mit dem Fingerspitzen des Benutzers ermöglicht. Ein hochwertiges Schaltnetzteil mit entsprechend instabiler, lauter Spannung kann die Genauigkeit, Genauigkeit und Empfindlichkeit kapazitiver Touchscreens vorübergehend beeinträchtigen. Einige kapazitive Displayhersteller entwickeln weiterhin dünnere und genauere Touchscreens. Die für mobile Geräte werden nun mit in-cell-Technologie, wie in Samsung Super AMOLED-Bildschirme, produziert, die eine Schicht durch den Aufbau der Kondensatoren im Display selbst eliminiert. Diese Art von Touchscreen reduziert den sichtbaren Abstand zwischen dem Finger des Benutzers und was der Benutzer auf dem Bildschirm berührt, wodurch die Dicke und das Gewicht des Displays reduziert wird, was in Smartphones erwünscht ist. Ein einfacher Parallelplattenkondensator weist zwei durch eine dielektrische Schicht getrennte Leiter auf. Die meisten Energie in diesem System wird direkt zwischen den Platten konzentriert. Einige der Energie fließt über in den Bereich außerhalb der Platten, und die elektrischen Feldlinien, die mit diesem Effekt verbunden sind, werden Freingfelder genannt. Ein Teil der Herausforderung, einen praktischen kapazitiven Sensor zu machen, besteht darin, eine Reihe von Leiterbahnen zu entwerfen, die Felder in einen aktiven, einem Benutzer zugänglichen Sensorbereich leiten. Ein Parallelplattenkondensator ist für ein solches Sensormuster keine gute Wahl. Das Verlegen eines Fingers in der Nähe von elektrischen Feldern verleiht dem kapazitiven System eine leitfähige Oberfläche. Die vom Finger hinzugefügte zusätzliche Ladungsspeicherkapazität wird als Fingerkapazität oder CF bezeichnet. Die Kapazität des Sensors ohne vorhandenen Finger ist als parasitäre Kapazität oder CP bekannt. Oberflächenkapazität In dieser Grundtechnologie ist nur eine Seite des Isolators mit einer leitfähigen Schicht beschichtet. Auf die Schicht wird eine kleine Spannung angelegt, die zu einem gleichmäßigen elektrostatischen Feld führt. Wenn ein Leiter, wie ein menschlicher Finger, die unbeschichtete Oberfläche berührt, wird dynamisch ein Kondensator gebildet. Die Steuerung des Sensors kann den Ort der Berührung indirekt aus der Änderung der Kapazität, gemessen von den vier Ecken der Platte, bestimmen. Da es keine beweglichen Teile hat, ist es mäßig haltbar, hat aber eine begrenzte Auflösung, ist anfällig für falsche Signale von parasitärer kapazitiver Kopplung und benötigt eine Kalibrierung bei der Herstellung. Es wird daher am häufigsten in einfachen Anwendungen wie industrielle Steuerungen und Kioske verwendet. Obwohl einige Standard-Kapazitätserfassungsverfahren projiziert sind, in dem Sinne, dass sie zum Erfassen eines Fingers durch eine nicht leitende Oberfläche verwendet werden können, sind sie sehr empfindlich auf Temperaturschwankungen, die die Abtastplatten erweitern oder zusammenziehen, was Schwankungen der Kapazität dieser Platten verursacht. Diese Schwankungen führen zu einer Menge Hintergrundgeräusche, so dass ein starkes Fingersignal für eine genaue Detektion erforderlich ist. Dies begrenzt Anwendungen, bei denen der Finger das Tastelement direkt berührt oder durch eine relativ dünne, nicht leitende Oberfläche erfasst wird. Die projizierte kapazitive Touch-Technologie (PCT; auch PCAP) ist eine Variante der kapazitiven Touch-Technologie, aber wo die Empfindlichkeit gegenüber Berührung, Genauigkeit, Auflösung und Berührungsgeschwindigkeit durch die Verwendung einer einfachen Form der "Künstlichen Intelligenz" erheblich verbessert wurde. Durch diese intelligente Verarbeitung kann die Fingererfassung durch sehr dickes Glas und sogar Doppelverglasung genau und zuverlässig projiziert werden. Einige moderne PCT-Touch-Bildschirme bestehen aus Tausenden von diskreten Tasten, aber die meisten PCT-Touch-Bildschirme sind aus einer x/y Matrix aus Zeilen und Spalten aus leitfähigem Material, auf Glasplatten geschichtet. Dies kann entweder durch Ätzen einer einzigen leitfähigen Schicht zu einem Gittermuster von Elektroden, durch Ätzen von zwei getrennten, senkrechten Schichten aus leitfähigem Material mit parallelen Linien oder Spuren zu einem Gitter oder durch Umformen eines x/y Rasters von feinen, isolierenden beschichteten Drähten in einer einzigen Schicht erfolgen. Die Anzahl der gleichzeitig detektierbaren Finger wird durch die Anzahl der Kreuzungspunkte (x * y) bestimmt. Die Anzahl der Überkreuzungspunkte kann jedoch durch ein diagonales Gitterlayout nahezu verdoppelt werden, wobei anstelle von x-Elementen nur immer y-Elemente kreuzt jedes leitfähige Element jedes andere Element. Die leitfähige Schicht ist oft transparent, wobei sie aus Indiumzinnoxid (ITO) besteht, einem transparenten elektrischen Leiter. In einigen Ausführungen erzeugt die an diesem Raster angelegte Spannung ein einheitliches elektrostatisches Feld, das gemessen werden kann. Wenn ein leitfähiges Objekt, wie ein Finger, mit einem PCT-Panel in Kontakt kommt, verzerrt es das lokale elektrostatische Feld an dieser Stelle. Dies ist als Kapazitätsänderung messbar. Überbrückt ein Finger den Spalt zwischen zwei der Spuren, wird das Ladungsfeld weiter unterbrochen und von der Steuerung detektiert. Die Kapazität kann an jedem einzelnen Punkt des Rasters geändert und gemessen werden. Dieses System kann Berührungen genau verfolgen. Aufgrund der oberen Schicht eines PCT-Glass ist es robuster als weniger teure Resist-Touch-Technologie. Im Gegensatz zur herkömmlichen kapazitiven Touch-Technologie ist es möglich, dass ein PCT-System einen passiven Taster oder Handschuhfinger abtastet. Feuchtigkeit auf der Oberfläche der Platte, hohe Feuchtigkeit oder gesammelter Staub kann die Leistung beeinträchtigen. Diese Umweltfaktoren sind jedoch kein Problem mit "Enddraht"-basierten Touchscreens, da drahtbasierte Touchscreens eine wesentlich geringere parasitäre Kapazität aufweisen und ein größerer Abstand zwischen benachbarten Leitern besteht. Es gibt zwei Arten von PCT: gegenseitige Kapazität und Selbstkapazität. Gegenseitige Kapazität Dies ist ein gemeinsamer PCT-Ansatz, der die Tatsache nutzt, dass die meisten leitfähigen Objekte eine Ladung halten können, wenn sie sehr nah zusammen sind. Bei gegenseitigen kapazitiven Sensoren wird an jedem Schnittpunkt des Rasters von der Zeilenspur und Spaltenspur ein Kondensator gebildet.Ein 16 x 14 Array würde beispielsweise 224 unabhängige Kondensatoren aufweisen. An die Zeilen oder Spalten wird eine Spannung angelegt. Das lokale elektrostatische Feld, das wiederum die gegenseitige Kapazität reduziert, verändert das Erreichen eines Fingers oder eines leitfähigen Tasters nahe der Oberfläche des Sensors. Die Kapazitätsänderung an jedem einzelnen Punkt des Rasters kann gemessen werden, um die Berührungsstelle durch Messung der Spannung in der anderen Achse genau zu bestimmen. Die gegenseitige Kapazität ermöglicht einen Multi-Touch-Betrieb, bei dem mehrere Finger, Palmen oder Styli gleichzeitig genau verfolgt werden können. Selbstkapitulation Selbstkapazitanzsensoren können das gleiche X-Y-Gitter als gegenseitige Kapazitätssensoren aufweisen, aber die Spalten und Zeilen arbeiten unabhängig voneinander. Bei Selbstkapazitanz wird die kapazitive Belastung eines Fingers an jeder Spalten- oder Zeilenelektrode durch einen Stromzähler oder die Frequenzänderung eines RC-Oszillators gemessen. Ein Finger kann überall entlang der ganzen Länge einer Reihe erkannt werden. Wird dieser Finger auch von einer Spalte erfasst, so kann davon ausgegangen werden, dass die Fingerposition am Schnittpunkt dieses Zeilen/Spaltenpaars liegt. Dies ermöglicht die schnelle und genaue Erkennung eines einzigen Fingers, aber es verursacht einige Mehrdeutigkeit, wenn mehr als ein Finger erkannt werden soll. Zwei Finger können vier mögliche Detektionspositionen aufweisen, von denen nur zwei wahr sind. Durch selektive De-sensibilisierung von Berührungspunkten in der Befriedigung werden jedoch widersprüchliche Ergebnisse leicht eliminiert. Dies ermöglicht die Verwendung von "Self Capacitance" für Multi-Touch-Betrieb. Alternativ kann eine Mehrdeutigkeit vermieden werden, indem ein de-sensibilisierendes Signal an alle, aber eine der Spalten angelegt wird. Dies lässt nur einen kurzen Abschnitt jeder Reihe empfindlich zu berühren. Durch die Auswahl einer Folge dieser Abschnitte entlang der Reihe ist es möglich, die genaue Position mehrerer Finger entlang dieser Zeile zu bestimmen. Dieser Vorgang kann dann für alle anderen Zeilen wiederholt werden, bis der gesamte Bildschirm abgetastet wurde. Selbstkapazitive Touchscreen-Schichten werden auf Mobiltelefonen wie dem Sony Xperia Sola, dem Samsung Galaxy S4, Galaxy Note 3, Galaxy S5 und Galaxy Alpha verwendet. Selbstkapazität ist weit empfindlicher als die gegenseitige Kapazität und wird hauptsächlich für einzelne Berührung, einfache gestische und Näherungserfassung verwendet, wo der Finger nicht einmal die Glasoberfläche berühren muss. Die gegenseitige Kapazität wird hauptsächlich für Multitouch-Anwendungen verwendet. Viele Touchscreen-Hersteller nutzen sowohl selbst- als auch gegenseitige Kapazitätstechnologien im gleichen Produkt und kombinieren damit ihre individuellen Vorteile. Verwendung von Stylus auf kapazitiven Bildschirmen Capacitive Touchscreens müssen nicht unbedingt mit einem Finger betrieben werden, aber bis vor kurzem die speziellen Styli benötigt könnte ziemlich teuer zu kaufen. Die Kosten dieser Technologie sind in den letzten Jahren stark gesunken und kapazitive Styli sind jetzt weit verbreitet für eine nominelle Ladung, und oft kostenlos mit mobilem Zubehör. Diese bestehen aus einem elektrisch leitenden Schaft mit einer weichleitenden Gummispitze, wodurch die Finger mit der Spitze des Stylus widerstandsfähig verbunden werden. Infrarotnetz Ein Infrarot-Touchscreen verwendet eine Reihe von X-Y Infrarot-LED- und Photodetektorpaaren um die Kanten des Bildschirms, um eine Störung im Muster von LED-Strahlen zu erkennen. Diese LED-Strahlen kreuzen sich in vertikalen und horizontalen Mustern. Dies hilft den Sensoren, die genaue Lage der Berührung zu erfassen. Ein wesentlicher Vorteil eines solchen Systems ist, dass es im Wesentlichen jedes opake Objekt einschließlich eines Fingers, Handschuhfingers, Stylus oder Stifts erkennen kann. Es wird in der Regel in Outdoor-Anwendungen und POS-Systeme verwendet, die sich nicht auf einen Leiter (wie einen bloßen Finger) verlassen können, um den Touchscreen zu aktivieren. Im Gegensatz zu kapazitiven Touchscreens benötigen Infrarot-Touchscreens keine Musterung auf dem Glas, was die Haltbarkeit und die optische Klarheit des Gesamtsystems erhöht. Infrarot-Touchscreens sind empfindlich auf Schmutz und Staub, die die Infrarotstrahlen stören können, und leiden unter Parallax in gekrümmten Oberflächen und versehentlichen Presse, wenn der Benutzer einen Finger über den Bildschirm schwebt, während die Suche nach dem zu wählenden Gegenstand. Infrarot-Acryl-Projektion Ein transluzentes Acrylblatt wird als Rückprojektionsbildschirm verwendet, um Informationen anzuzeigen. Die Kanten der Acrylfolie werden von Infrarot-LEDs beleuchtet und Infrarot-Kameras werden auf der Rückseite des Blattes fokussiert. Auf dem Blatt platzierte Objekte sind durch die Kameras nachweisbar. Wenn das Blatt vom Benutzer berührt wird, führt die Verformung zu einer Leckage von Infrarotlicht, das an den Stellen des maximalen Drucks ansteigt und die Berührungsstelle des Benutzers anzeigt. Microsofts PixelSense-Tabletten verwenden diese Technologie. Optische Abbildungsoptiken sind eine relativ moderne Entwicklung in der Touchscreen-Technologie, bei der zwei oder mehr Bildsensoren (wie CMOS-Sensoren) um die Kanten (meist die Ecken) des Bildschirms gelegt werden. Infrarot-Rücklichter werden auf der gegenüberliegenden Seite des Bildschirms im Sichtfeld des Sensors platziert. Eine Berührung blockiert einige Lichter von den Sensoren und die Lage und Größe des berührenden Objekts kann berechnet werden (siehe visuelle Hülle). Diese Technologie wächst in der Popularität aufgrund ihrer Skalierbarkeit, Vielseitigkeit und Erschwinglichkeit für größere Touchscreens. Dispersive Signaltechnik Dieses im Jahr 2002 von 3M vorgestellte System erfasst eine Berührung mit Sensoren zur Messung der Piezoizität im Glas. Komplexe Algorithmen interpretieren diese Informationen und liefern den tatsächlichen Ort der Berührung. Die Technologie wird nicht durch Staub und andere äußere Elemente, einschließlich Kratzer, beeinflusst. Da auf dem Bildschirm keine zusätzlichen Elemente erforderlich sind, geht es auch um eine hervorragende optische Übersichtlichkeit. Jedes Objekt kann verwendet werden, um Berührungsereignisse zu erzeugen, einschließlich Handschuhfinger. Ein Nachteil ist, dass das System nach der ersten Berührung keinen bewegungslosen Finger erkennen kann. Aus dem gleichen Grund stört jedoch Ruheobjekte keine Berührungserkennung. Akustische Impulserkennung Der Schlüssel zu dieser Technologie ist, dass eine Berührung an einer beliebigen Position auf der Oberfläche eine Schallwelle im Substrat erzeugt, die dann ein einzigartiges kombiniertes Signal erzeugt, das von drei oder mehr winzigen Wandlern gemessen wird, die an den Kanten des Touchscreens angebracht sind. Das digitalisierte Signal wird mit einer Liste verglichen, die jeder Position auf der Oberfläche entspricht und den Berührungsort bestimmt. Eine bewegte Berührung wird durch schnelle Wiederholung dieses Prozesses verfolgt. Extrane und Umgebungsgeräusche werden ignoriert, da sie kein gespeichertes Soundprofil entsprechen. Die Technologie unterscheidet sich von anderen schallbasierten Technologien durch die Verwendung eines einfachen Look-up-Verfahrens anstelle von teuren Signalverarbeitungshardware. Wie bei dem dispersiven Signaltechnik-System kann nach der ersten Berührung kein bewegungsloser Finger detektiert werden. Aus demselben Grund wird die Berührungserkennung jedoch nicht durch irgendwelche ruhenden Objekte gestört. Die Technologie wurde von SoundTouch Ltd in den frühen 2000er Jahren, wie von der Patentfamilie EP1852772 beschrieben, entwickelt und 2006 von der Division Elo von Tyco International als Akustische Pulserkennung in den Markt eingeführt. Der von Elo verwendete Touchscreen ist aus gewöhnlichem Glas gefertigt und bietet gute Haltbarkeit und optische Klarheit. Die Technologie hält in der Regel Genauigkeit mit Kratzern und Staub auf dem Bildschirm. Die Technologie eignet sich auch gut für Displays, die physikalisch größer sind. Baugewerbe Es gibt mehrere prinzipielle Möglichkeiten, einen Touchscreen zu erstellen. Die wichtigsten Ziele sind, einen oder mehrere Finger zu erkennen, die ein Display berühren, den Befehl zu interpretieren, den dieser darstellt, und den Befehl an die entsprechende Anwendung zu übermitteln. Im resistiven Ansatz, der früher die populärste Technik war, gibt es typischerweise vier Schichten: Top-Polyester-beschichtete Schicht mit einer transparenten metallisch leitfähigen Beschichtung auf der Unterseite. Kleber Abstandshalter Glasschicht mit einer transparenten metallisch leitfähigen Beschichtung auf der oberen Klebeschicht auf der Rückseite des Glases zur Montage beschichtet. Wenn ein Benutzer die Oberfläche berührt, registriert das System die Änderung des elektrischen Stroms, der durch das Display fließt. Die Dispersive-Signaltechnologie misst den piezoelektrischen Effekt - die beim Aufbringen von mechanischer Kraft auf ein Material erzeugte Spannung -, was bei Berührung eines verstärkten Glassubstrats chemisch auftritt. Es gibt zwei infrarotbasierte Ansätze. Eine Reihe von Sensoren erfasst einerseits einen Finger, der das Display berührt oder fast berührt, wodurch Infrarotlichtstrahlen über den Bildschirm projiziert werden. In den anderen, unten montierten Infrarot-Kameras zeichnen Wärme von Bildschirmberührungen auf. In jedem Fall bestimmt das System den vorgesehenen Befehl basierend auf den Steuerungen, die zum Zeitpunkt und am Ort der Berührung auf dem Bildschirm angezeigt werden. Entwicklung Die Entwicklung von Multi-Touch-Bildschirmen erleichterte das Tracking von mehr als einem Finger auf dem Bildschirm; so sind Operationen möglich, die mehr als einen Finger benötigen. Diese Geräte ermöglichen es auch, dass mehrere Benutzer gleichzeitig mit dem Touchscreen interagieren. Mit dem wachsenden Einsatz von Touchscreens werden die Kosten der Touchscreen-Technologie routinemäßig in die Produkte aufgenommen, die sie integrieren und fast eliminiert. Touchscreen-Technologie hat Zuverlässigkeit gezeigt und findet sich in Flugzeugen, Automobilen, Gaming-Konsolen, Maschinensteuerungen, Geräten und Handgeräten einschließlich Handys; der Touchscreen-Markt für mobile Geräte wurde bis 2009 für US$5 Milliarden projiziert. Die Fähigkeit, auf dem Bildschirm selbst genau zu zeigen, wird auch mit den aufstrebenden Grafik-Tablet-Screen-Hybriden vorangetrieben. Polyvinylidenfluorid (PVFD) spielt bei dieser Innovation aufgrund seiner hohen piezoelektrischen Eigenschaften eine wichtige Rolle, die es der Tablette ermöglicht, Druck zu spüren, so dass sich die Dinge wie das digitale Gemälde eher wie Papier und Bleistift verhalten. TapSense, bekannt gegeben im Oktober 2011, ermöglicht Touchscreens zu unterscheiden, welchen Teil der Hand für die Eingabe verwendet wurde, wie z.B. Fingerspitzen, Knöchel und Fingernägel. Dies könnte auf vielfältige Weise zum Beispiel zum Kopieren und Einfügen von Briefen, zur Aktivierung verschiedener Zeichenmodi usw. verwendet werden. Eine reale praktische Integration zwischen Fernsehbildern und den Funktionen eines normalen modernen PC könnte in naher Zukunft eine Innovation sein: zum Beispiel All-Live-Informationen über einen Film oder die Schauspieler auf Video, eine Liste anderer Musik während eines normalen Videoclips eines Liedes oder Nachrichten über eine Person. Ergonomie und Nutzung Touchscreen Genauigkeit Damit Touchscreens effektive Eingabegeräte sein können, müssen Benutzer in der Lage sein, Ziele genau auszuwählen und eine versehentliche Auswahl benachbarter Ziele zu vermeiden. Das Design von Touchscreen-Schnittstellen sollte die technischen Fähigkeiten des Systems, der Ergonomie, der kognitiven Psychologie und der menschlichen Physiologie widerspiegeln. In den 1990er Jahren wurden zunächst Richtlinien für Touchscreen-Designs entwickelt, die auf der Frühforschung und der tatsächlichen Nutzung älterer Systeme basieren, typischerweise unter Verwendung von Infrarot-Gittern, die stark von der Größe der Finger des Benutzers abhängig waren. Diese Richtlinien sind weniger relevant für den Großteil der modernen Geräte, die kapazitive oder resistive Touch-Technologie verwenden. Seit Mitte der 2000er Jahre haben Hersteller von Betriebssystemen für Smartphones Standards promulgiert, aber diese variieren zwischen den Herstellern und ermöglichen eine signifikante Variation der Größe basierend auf Technologieänderungen, so sind aus menschlicher Sicht nicht geeignet. Viel wichtiger ist die Genauigkeit, die Menschen bei der Auswahl von Zielen mit dem Finger oder einem Stift-Stylus haben. Die Genauigkeit der Benutzerauswahl variiert je nach Position auf dem Bildschirm: Benutzer sind am genauesten in der Mitte, weniger an der linken und rechten Kante, und am oberen Rand und insbesondere der unteren Kante. Die R95 Genauigkeit (erforderlicher Radius für 95% Zielgenauigkeit) variiert von 7 mm (0,28 in) in der Mitte bis 12 mm (0,47 in) in den unteren Ecken. Benutzer sind sich dessen bewusst, und nehmen Sie mehr Zeit, um Ziele auszuwählen, die kleiner sind oder an den Kanten oder Ecken des Touchscreens. Diese Benutzerungenauigkeit ist ein Ergebnis von Parallax, Sehschärfe und der Geschwindigkeit der Rückkopplungsschleife zwischen den Augen und den Fingern. Die Präzision des menschlichen Fingers allein ist viel, viel höher als dies, so dass bei der Bereitstellung von Assistenztechnologien - wie z.B. auf dem Bildschirm Lupen - Anwender ihren Finger (bei Berührung mit dem Bildschirm) mit einer Genauigkeit von 0,1 mm (0,004 in) bewegen können. Handposition, digital verwendet und Switch Benutzer von handgehaltenen und tragbaren Touchscreen-Geräten halten sie in einer Vielzahl von Möglichkeiten, und ändern routinemäßig ihre Methode der Halterung und Auswahl, um die Position und Art der Eingabe anzupassen. Es gibt vier grundlegende Arten von handgeführten Interaktionen: Halten zumindest teilweise mit beiden Händen, tippen mit einem einzigen Daumen Halten mit zwei Händen und tippen mit beiden Daumen Halten mit einer Hand, tippen mit dem Finger (oder selten, Daumen) einer anderen Hand Halten Sie das Gerät in einer Hand, und tippen mit dem Daumen von derselben Hand. Während bei vielen allgemeinen Interaktionen nur selten (1–3) % auf das Zwei-Thumb-Tapping stoßen, wird es für 41 % der Schreib-Interaktion verwendet. Außerdem werden häufig Vorrichtungen auf Oberflächen (Deks oder Tische) aufgesetzt und insbesondere Tabletten in Ständen eingesetzt. Der Benutzer kann in diesen Fällen mit dem Finger oder dem Daumen aufzeigen, auswählen oder Geste auswählen und die Verwendung dieser Methoden variieren. Kombiniert mit Haptics Touchscreens werden häufig mit haptischen Antwortsystemen verwendet. Ein gemeinsames Beispiel für diese Technologie ist das vibrierende Feedback, das bei einem Knopf auf dem Touchscreen bereitgestellt wird. Haptics werden verwendet, um die Erfahrung des Benutzers mit Touchscreens zu verbessern, indem simulierte taktile Rückmeldungen bereitgestellt werden, und kann so konzipiert werden, dass es sofort reagiert, teilweise gegen die On-Screen-Ansprechlatenz. Die Forschung der University of Glasgow (Brewster, Chohan, and Brown, 2007; und vor kurzem Hogan) zeigt, dass Touchscreen-Nutzer die Eingabefehler (bis 20)% reduzieren, die Eingabegeschwindigkeit (bis 20)% erhöhen und ihre kognitive Belastung (um 40)% senken, wenn Touchscreens mit Haptik oder taktiles Feedback kombiniert werden. Darüber hinaus untersuchte eine Studie, die 2013 von Boston College durchgeführt wurde, die Auswirkungen, die die haptische Stimulation von Touchscreens auf das Auslösen psychologischer Eigentum an einem Produkt hatte. Ihre Forschung kam zu dem Schluss, dass eine Touchscreen-Fähigkeit, hohe Mengen an haptischem Engagement zu integrieren, dazu führte, dass Kunden mehr Zufriedenheit mit den Produkten, die sie entworfen oder kaufen. Die Studie berichtete auch, dass die Verbraucher mit einem Touchscreen bereit waren, einen höheren Preispunkt für die Waren zu akzeptieren, die sie kauften. Customer Service Touchscreen-Technologie wurde im 21. Jahrhundert in viele Aspekte der Kundendienstindustrie integriert. Die Restaurantindustrie ist ein gutes Beispiel für die Implementierung von Touchscreen in diese Domain. Kettenrestaurants wie Taco Bell, Panera Bread und McDonald bieten Touchscreens als Option, wenn Kunden Artikel aus dem Menü bestellen. Während die Zugabe von Touchscreens eine Entwicklung für diese Branche ist, können Kunden wählen, um den Touchscreen zu umgehen und von einem traditionellen Kasse bestellen. Ein Restaurant in Bangalore hat versucht, den Bestellvorgang vollständig zu automatisieren. Kunden setzen sich auf einen Tisch mit Touchscreens ein und bestellen ein umfangreiches Menü. Nach der Bestellung wird sie elektronisch in die Küche geschickt. Diese Arten von Touchscreens passen zu den im Lead-Bereich erwähnten Point of Sale (POS) Systemen. "Gorilla Arm" Der erweiterte Einsatz gestischer Schnittstellen ohne die Fähigkeit des Benutzers, seinen Arm zu ruhen, wird als "gorilla arm" bezeichnet. Es kann zu Müdigkeit und sogar repetitive Stressverletzungen führen, wenn routinemäßig in einer Arbeitsumgebung verwendet. Einige frühe pen-basierte Schnittstellen erforderten den Bediener in dieser Position für einen Großteil des Arbeitstages zu arbeiten. Eine Lösung hierfür ist in vielen Zusammenhängen, wenn der Benutzer seine Hand oder Arm auf dem Eingabegerät oder einem Rahmen umsetzen kann. Dieses Phänomen wird oft als ein Beispiel für Bewegungen genannt, die durch richtige ergonomische Gestaltung minimiert werden. Ununterstützte Touchscreens sind in Anwendungen wie Geldautomaten und Datenkiosken immer noch recht häufig, sind aber kein Problem, da der typische Benutzer nur für kurze und weit entfernte Zeiträume eingreift. Fingerabdrücke Touchscreens können unter dem Problem der Fingerabdrücke auf dem Display leiden. Dies kann durch den Einsatz von Materialien mit optischen Beschichtungen gemildert werden, um die sichtbaren Effekte von Fingerabdruckölen zu reduzieren. Die meisten modernen Smartphones haben oleophobe Beschichtungen, die die Menge an Ölrückständen verringern. Eine weitere Option ist die Installation eines matt-finish Anti-Glar-Bildschirmschutzes, der eine leicht aufgerauhte Oberfläche erzeugt, die nicht leicht hält Smudges. Glove Touch Touch Touchscreens funktionieren nicht die meiste Zeit, wenn der Benutzer Handschuhe trägt. Die Dicke des Handschuhs und das Material, aus dem sie hergestellt werden, spielen dabei eine wichtige Rolle und die Fähigkeit eines Touchscreens, einen Touch aufzunehmen. Siehe auch Referenzen Quellen = Externe Links ==