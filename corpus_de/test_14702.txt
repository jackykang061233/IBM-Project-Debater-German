Das Semantic Web ist eine Erweiterung des World Wide Web durch Standards des World Wide Web Consortium (W3C). Ziel des Semantic Web ist es, Internetdaten maschinenlesbar zu machen. Um die Kodierung von Semantik mit den Daten zu ermöglichen, werden Technologien wie Resource Description Framework (RDF) und Web Ontology Language (OWL) verwendet. Diese Technologien werden verwendet, um Metadaten formal darzustellen. Zum Beispiel kann Onlogie Konzepte, Zusammenhänge zwischen Wesen und Kategorien von Dingen beschreiben. Diese eingebetteten Semantiken bieten erhebliche Vorteile, wie etwa die Begründung von Daten und der Betrieb mit heterogenen Datenquellen. Diese Standards fördern gemeinsame Datenformate und Austauschprotokolle im Web, im Wesentlichen der RDF. Laut W3C bietet das Semantic Web einen gemeinsamen Rahmen, der es ermöglicht, Daten über Anwendungs-, Unternehmens- und Gemeindegrenzen hinweg zu teilen und wiederverwendet zu werden." Das Semantic Web gilt daher als Integrator für verschiedene Content- und Informationsanwendungen und -systeme. Der Begriff wurde von Tim Berners-Lee für ein Datennetz (oder Datenwebseite) prägen, das durch Maschinen verarbeitet werden kann - das heißt, dass ein Großteil der Bedeutung maschinell lesbar ist. Während seine Kritiker ihre Machbarkeit in Frage gestellt haben, argumentieren die Befürworter, dass Anwendungen in der Bibliotheks- und Informationswissenschaft, Industrie, Biologie und Humanwissenschaften Forschung bereits die Gültigkeit des ursprünglichen Konzepts nachgewiesen haben. Berners-Lee drückte seine Vision des Semantischen Webs 1999 wie folgt aus: Ich habe einen Traum für das Web [in dem Computer] in der Lage sind, alle Daten im Web zu analysieren – die Inhalte, Links und Transaktionen zwischen Mensch und Computer. Ein "Semantisches Web", das dies ermöglicht, muss noch entstehen, aber wenn es so ist, werden die täglichen Mechanismen des Handels, der Bürokratie und unseres täglichen Lebens von Maschinen behandelt, die mit Maschinen sprechen. Die "intelligenten Agenten" Menschen müssen für das Alter gequält werden schließlich materialisieren. Der wissenschaftliche amerikanische Artikel von Berners-Lee, Hendler und Lassila von 2001 beschrieb eine erwartete Entwicklung des bestehenden Web in ein Semantisches Web. Im Jahr 2006 erklärten Berners-Lee und Kollegen: "Diese einfache Idee... bleibt weitgehend unrealisiert". Im Jahr 2013 enthielten mehr als vier Millionen Web-Domains (von rund 250 Millionen insgesamt) Semantic Web-Markup. Beispiel Im folgenden Beispiel wird der Text "Paul Schuster wurde in Dresden geboren" auf einer Website annotiert, die eine Person mit ihrem Geburtsort verbindet. Das folgende HTML-Fragment zeigt, wie ein kleines Diagramm beschrieben wird, in RDFa-syntax mit einem schema.org vocabulary und einem Wikidata ID: Das Beispiel definiert die folgenden fünf Tripel (in Turtle syntax dargestellt). Jedes Dreifach stellt eine Kante in dem resultierenden Diagramm dar: Das erste Element des Dreifachen (das Subjekt) ist der Name des Knotens, an dem die Kante beginnt, das zweite Element (das Prädikat) die Art der Kante, und das letzte und dritte Element (das Objekt) entweder den Namen des Knotens, an dem die Kante endet oder einen Literalwert (z.B. ein Text, eine Zahl, etc.) Die Dreifache führen in dem in der angegebenen Abbildung dargestellten Diagramm. Einer der Vorteile der Verwendung von Uniform Resource Identifiers (URIs) ist, dass sie mit dem HTTP-Protokoll abgeleitet werden können. Nach den sogenannten Linked Open Data-Prinzipien sollte eine solche dereferenzierte URI zu einem Dokument führen, das weitere Daten über die gegebene URI bietet. In diesem Beispiel sind alle URIs sowohl für Kanten als auch für Knoten (z.B. http://schema.org/Person, http://schema.org/birthPlace, http://www.wikidata.org/entity/Q1731) kann abgeleitet werden und wird zu weiteren RDF-Diagrammen führen, die die URI beschreiben, z.B. dass Dresden eine Stadt in Deutschland ist, oder dass eine Person im Sinne dieser URI fiktiv sein kann. Der zweite Graph zeigt das vorangegangene Beispiel, bereichert aber nun mit einigen der Dreifache aus den Dokumenten, die sich aus der Entferencing ergeben https://schema.org/Person (grüner Rand) und https://www.wikidata.org/entity/Q1731 (blaue Kanten). Zusätzlich zu den Kanten, die in den betreffenden Dokumenten explizit angegeben werden, können Kanten automatisch abgeleitet werden: das Dreifache aus dem ursprünglichen RDFa-Fragment und das Dreifache aus dem Dokument unter https://schema.org/Person (grüner Rand in der Figur) erlauben, das folgende Dreifache bei OWL-Semantik (rote gestrichelte Linie in der zweiten Abbildung) zu unterziehen:) Hintergrund Das Konzept des semantischen Netzwerkmodells wurde Anfang der 1960er Jahre von Forschern wie dem kognitiven Wissenschaftler Allan M. Collins, Linguist M. Ross Quillian und Psychologe Elizabeth F. Loftus als eine Form gebildet, um semantisch strukturiertes Wissen zu repräsentieren. Wenn es im Kontext des modernen Internets angewendet wird, erweitert es das Netzwerk von hyperlinkten human lesbaren Webseiten, indem maschinenlesbare Metadaten über Seiten eingefügt werden und wie sie miteinander verwandt sind. Dies ermöglicht es automatisierten Agenten, auf das Web intelligenter zuzugreifen und mehr Aufgaben im Auftrag von Nutzern auszuführen. Der Begriff "Semantic Web" wurde von Tim Berners-Lee, dem Erfinder des World Wide Web und Direktor des World Wide Web Consortiums (W3C), geprägt, das die Entwicklung der vorgeschlagenen Semantic Web Standards überwacht. Er definiert das Semantische Web als "ein Datennetz, das direkt und indirekt über Maschinen verarbeitet werden kann". Viele der vom W3C vorgeschlagenen Technologien existierten bereits, bevor sie unter dem W3C-Draht positioniert wurden. Diese werden in verschiedenen Kontexten verwendet, insbesondere in Bezug auf Informationen, die eine begrenzte und definierte Domäne umfassen, und bei denen die Weitergabe von Daten eine gemeinsame Notwendigkeit ist, wie wissenschaftliche Forschung oder Datenaustausch zwischen Unternehmen. Darüber hinaus sind andere Technologien mit ähnlichen Zielen entstanden, wie Mikroformate. Einschränkungen von HTML Viele Dateien auf einem typischen Computer können auch lose in human lesbare Dokumente und maschinenlesbare Daten unterteilt werden. Dokumente wie Mail-Nachrichten, Berichte und Broschüren werden vom Menschen gelesen. Daten, wie Kalender, Adressbücher, Wiedergabelisten und Tabellenkalkulationen werden mit einem Anwendungsprogramm dargestellt, mit dem sie angezeigt, gesucht und kombiniert werden können. Derzeit basiert das World Wide Web vor allem auf Dokumenten, die in Hypertext Markup Language (HTML) geschrieben wurden, einer Markup-Konvention, die zur Kodierung eines Texts verwendet wird, der mit Multimedia-Objekten wie Bildern und interaktiven Formen intersperiert wird. Metadaten-Tags bieten ein Verfahren, mit dem Computer den Inhalt von Webseiten kategorisieren können. In den folgenden Beispielen sind die Feldnamen Keywords, Beschreibung und Autor Werte wie Computing und "Chap Widgets zum Verkauf" und "John Doe" zugeordnet. Aufgrund dieser Metadaten-Tagung und Kategorisierung können andere Computersysteme, die auf diese Daten zugreifen und teilen möchten, die relevanten Werte leicht identifizieren. Mit HTML und einem Tool, um es (perhaps Web-Browser-Software, vielleicht ein anderer Benutzer Agent,) kann man eine Seite erstellen und präsentieren, die Artikel zum Verkauf auflistet. Das HTML dieser Katalog-Seite kann einfache, dokument-Ebene Behauptungen wie "dieses Dokuments Titel ist "Widget Superstore", aber es gibt keine Möglichkeit innerhalb des HTML selbst eindeutig zu behaupten, dass, zum Beispiel Artikel X586172 ist ein Acme Gizmo mit einem Einzelhandelspreis von €199, oder dass es ein Verbraucherprodukt ist. Vielmehr kann HTML nur sagen, dass die Zeitspanne des Textes X586172 etwas ist, das in der Nähe von "Acme Gizmo" und €199, etc. positioniert werden sollte. Es gibt keine Möglichkeit, "das ist ein Katalog" zu sagen oder sogar festzustellen, dass "Acme Gizmo" eine Art Titel ist oder dass €199 ein Preis ist. Es gibt auch keine Möglichkeit, auszudrücken, dass diese Informationen bei der Beschreibung eines diskreten Gegenstands zusammengefügt werden, der sich von anderen, vielleicht auf der Seite aufgeführten Punkten unterscheidet. Semantic HTML bezieht sich auf die traditionelle HTML-Praxis von Markup nach Absicht, anstatt Layoutdetails direkt anzugeben. So ist z.B. die Verwendung von <em> mit Schwerpunkt anstatt < i,>, die Italics angibt. Layoutdetails stehen dem Browser in Kombination mit Cascading Style Sheets zur Verfügung. Aber diese Praxis fällt nicht auf die Angabe der Semantik von Gegenständen wie zum Verkauf oder Preise. Mikroformate erweitern HTML-Syntax, um maschinenlesbare semantische Markierungen über Objekte wie Menschen, Organisationen, Veranstaltungen und Produkte zu erstellen. Ähnliche Initiativen umfassen RDFa, Microdata und Schema.org Semantic Web-Lösungen Das Semantic Web nimmt die Lösung weiter. Es umfasst die Veröffentlichung in speziell für Daten konzipierten Sprachen: Ressourcenbeschreibung Framework (RDF,) Web Ontology Language (OWL,) und Extensible Markup Language (XML). HTML beschreibt Dokumente und die Verbindungen zwischen ihnen. RDF, OWL und XML hingegen können beliebige Dinge wie Menschen, Meetings oder Flugzeugteile beschreiben. Diese Technologien werden kombiniert, um Beschreibungen bereitzustellen, die den Inhalt von Webdokumenten ergänzen oder ersetzen. So kann sich der Inhalt als in Web zugänglichen Datenbanken gespeicherte beschreibende Daten manifestieren oder als Markup innerhalb von Dokumenten (insbesondere in Extensible HTML (XHTML) intersperiert mit XML, oder häufiger rein in XML, mit Layout oder Rendering Cues separat gespeichert). Die maschinenlesbaren Beschreibungen ermöglichen Inhaltsmanagern, dem Inhalt Bedeutung hinzuzufügen, d.h. die Struktur des Wissens, das wir über diesen Inhalt haben, zu beschreiben. Auf diese Weise kann eine Maschine das Wissen selbst anstelle von Text verarbeiten, indem sie Prozesse, die der menschlichen deduktiven Argumentation und Inferenz ähnlich sind, verwendet, wodurch sinnvollere Ergebnisse erzielt werden und Computern helfen, automatisierte Informationssammlung und Forschung durchzuführen. Ein Beispiel für einen Tag, der in einer nicht-semantischen Webseite verwendet wird: Ähnliche Informationen in einer semantischen Webseite zu kodieren, könnte so aussehen: Tim Berners-Lee nennt das resultierende Netzwerk von Linked Data den Giant Global Graph, im Gegensatz zum HTML-basierten World Wide Web. Berners-Lee schlägt vor, dass die Zukunft, wenn die Vergangenheit Dokument-Sharing war, Daten-Sharing ist. Seine Antwort auf die Frage, wie drei Punkte der Unterricht. Eine URL sollte auf die Daten hinweisen. Zwei, jeder, der auf die URL zugreift, sollte Daten zurück erhalten. Drei, Beziehungen in den Daten sollten auf zusätzliche URLs mit Daten zeigen. Web 3.0 Semantic Web Tim Berners-Lee hat das Semantic Web als Bestandteil von Web 3.0 beschrieben. Leute fragen immer, was Web 3.0 ist. Ich denke vielleicht, wenn Sie eine Überlagerung von skalierbaren Vektorgrafiken haben – alles, was reißt und faltet und misst – auf Web 2.0 und Zugriff auf ein semantisches Web, das über einen riesigen Datenraum integriert ist, haben Sie Zugriff auf eine unglaubliche Datenressource ... "Semantic Web" wird manchmal als Synonym für "Web 3.0" verwendet, obwohl die Definition jedes Begriffs variiert. Die Dezentralisierung Web 3.0 hat als eine Bewegung von der Zentralisierung von Dienstleistungen wie Such-, Social Media- und Chat-Anwendungen begonnen, die von einer einzigen Organisation zur Funktion abhängig sind und als "die nächste, Post-Big Tech Phase" bezeichnet wird. Guardian Journalist John Harris hat das Web 3.0-Konzept günstig im Anfangs-2019 geprüft und insbesondere von Berners‐ Lee auf einem Dezentralisierungsprojekt namens Solid, basierend auf persönlichen Datenspeichern oder Pods, über die Einzelpersonen die Kontrolle behalten. Berners‐Lee hat ein Startup, Inrupt, um die Idee voranzutreiben und freiwillige Entwickler anzuziehen. Durch die Dezentralisierung kann der Übergang zu Web 3.0 die Probleme der Opazität von Webdiensten, Zensur, weniger organisatorischen Einfluss auf Demokratie und Vertraulichkeit personenbezogener Daten lösen. "Blockchain phones" werden gedacht, als Gateway zu Web 3.0 oder "decentralized web" erstellt zu werden. Herausforderungen Einige der Herausforderungen für das Semantische Web beinhalten Weite, Vagemut, Ungewissheit, Inkonsistenz und Betrug. Automatisierte Argumentationssysteme müssen sich mit all diesen Problemen befassen, um das Versprechen des Semantischen Webs zu liefern. Vastness: Das World Wide Web enthält viele Milliarden von Seiten. Die SNOMED CT-Klassik-Terminologie enthält allein 370.000 Klassennamen, und die vorhandene Technologie konnte noch nicht alle semantisch duplizierten Begriffe beseitigen. Jedes automatisierte Argumentationssystem muss mit wirklich riesigen Eingängen umgehen. Vageness: Das sind unpräzise Konzepte wie jung oder groß". Dies ergibt sich aus der Ungewissheit der Nutzeranfragen, der von Content Providern vertretenen Konzepte, der Anpassung von Abfragebegriffen an Anbieterbegriffe und der Kombination verschiedener Wissensbasen mit überlappenden, aber subtil unterschiedlichen Konzepten. Fuzzy-Logik ist die häufigste Technik für den Umgang mit Vageness. Ungewissheit: Das sind präzise Konzepte mit unsicheren Werten. Beispielsweise kann ein Patient eine Reihe von Symptomen aufweisen, die einer Anzahl unterschiedlicher Diagnostik entsprechen, die jeweils eine unterschiedliche Wahrscheinlichkeit aufweisen. Die probabilistischen Argumentationstechniken werden in der Regel angewandt, um die Unsicherheit zu lösen. Inkonsistenz: Dies sind logische Widersprüche, die bei der Entwicklung großer Ontologien zwangsläufig entstehen und wenn Ontologien aus getrennten Quellen kombiniert werden. Die verführerische Vernunft scheitert katastrophal, wenn sie mit Unannehmlichkeit konfrontiert ist, weil "alles aus einem Widerspruch folgt". Defeasible Argumentation und parakonsistente Argumentation sind zwei Techniken, die zur Bewältigung der Unstimmigkeit eingesetzt werden können. Deceit: Dies ist, wenn der Hersteller der Informationen bewusst irreführend den Verbraucher der Informationen. Cryptographie-Techniken werden derzeit verwendet, um diese Bedrohung zu lindern. Durch die Bereitstellung eines Mittels zur Bestimmung der Integrität der Informationen, einschließlich derjenigen, die sich auf die Identität des Unternehmens bezieht, das die Informationen erstellt oder veröffentlicht hat, müssen jedoch noch Glaubwürdigkeitsfragen im Falle eines potenziellen Betrugs behandelt werden. Diese Herausforderungenliste ist illustrativ und nicht erschöpfend, und sie konzentriert sich auf die Herausforderungen der "vereinigenden Logik" und Beweisschichten des Semantischen Webs. Das World Wide Web Consortium (W3C)Inkubator Group for Uncertainty Reasoning for the World Wide Web (URW3-XG) Endbericht bricht diese Probleme zusammen unter der einzigen Rubrik der Unsicherheit". Viele der hier genannten Techniken benötigen Erweiterungen zur Web Ontology Language (OWL), um z.B. bedingte Wahrscheinlichkeiten zu erkennen. Dies ist ein Bereich der aktiven Forschung. Standards Standardisierung für Semantic Web im Kontext von Web 3.0 steht unter der Pflege von W3C. Komponenten Der Begriff "Semantic Web" wird oft speziell verwendet, um sich auf die Formate und Technologien zu beziehen, die es ermöglichen. Die Erfassung, Strukturierung und Wiederherstellung von verknüpften Daten werden durch Technologien ermöglicht, die eine formale Beschreibung von Konzepten, Begriffen und Beziehungen innerhalb einer bestimmten Wissensdomäne bieten. Diese Technologien sind als W3C-Standards definiert und beinhalten: Ressourcenbeschreibung Framework (RDF,) eine allgemeine Methode zur Beschreibung von Informationen RDF Schema (RDFS)Simple Knowledge Organization System (SKOS) SPARQL, eine RDF-Abfrage-Sprache Notation3(N3,) entwickelt mit menschlicher Weblesbarkeit im Denken N-Triples, ein Format zur Speicherung und Übertragung von Daten Turtle (Terse RDF Triple Language) Web Ontology Die Funktionen und Zusammenhänge der Komponenten lassen sich wie folgt zusammenfassen: XML bietet eine elementare Syntax für die Inhaltsstruktur innerhalb von Dokumenten, verbindet jedoch keine Semantik mit der Bedeutung des Inhalts innerhalb von Dokumenten. XML ist derzeit in den meisten Fällen keine notwendige Komponente der Semantic Web-Technologien, da alternative Syntaxes vorhanden sind, wie Turtle. Schildkröte ist ein de facto Standard, aber nicht durch einen formalen Standardisierungsprozess. XML-Schema ist eine Sprache, um die Struktur und den Inhalt von Elementen, die in XML-Dokumenten enthalten sind, bereitzustellen und einzuschränken. RDF ist eine einfache Sprache zum Ausdrucken von Datenmodellen, die sich auf Objekte ("Web-Ressourcen") und deren Beziehungen beziehen. Ein RDF-basiertes Modell kann in einer Vielzahl von Syntaxen dargestellt werden, z.B. RDF/XML, N3, Turtle und RDFa. RDF ist ein grundlegender Standard des Semantic Web. RDF-Schema erweitert RDF und ist ein Vokabular zur Beschreibung von Eigenschaften und Klassen von RDF-basierten Ressourcen, mit Semantik für Verallgemeinerungshierarchien solcher Eigenschaften und Klassen. OWL fügt mehr Vokabular zur Beschreibung von Eigenschaften und Klassen hinzu: u.a. Beziehungen zwischen Klassen (z.B. Ungeziefer,) Karzinalität (z.B. "exakte ein",") Gleichheit, reichere Typisierung von Eigenschaften, Eigenschaften (z.B. Symmetrie) und aufgezählte Klassen. SPARQL ist eine Protokoll- und Abfragesprache für semantische Webdatenquellen. RIF ist das W3C Regel-Wechselformat. Es ist eine XML-Sprache, um Webregeln auszudrücken, die Computer ausführen können. RIF bietet mehrere Versionen, genannt Dialekte. Es umfasst einen RIF-Grund-Logic-Dialect (RIF-BLD) und RIF-Produktionsregeln Dialect (RIF PRD). Aktueller Stand der Standardisierung Gut etablierte Standards: RDF RDFS Rule Interchange Format (RIF) SPARQL Unicode Uniform Resource Identifier Web Ontology Language (OWL) XML Noch nicht vollständig realisiert: Verknüpfung von Logik- und Beweisschichten Semantic Web Rule Language (SWRL) Anwendungen Die Absicht besteht darin, die Usability und die Nützlichkeit des Webs und seiner miteinander verbundenen Ressourcen zu verbessern, indem semantische Webdienste geschaffen werden, wie z.B.: Server, die bestehende Datensysteme mit den RDF- und SPARQL-Standards aussetzen. Viele Konverter zu RDF existieren aus verschiedenen Anwendungen. Beziehungsdatenbanken sind eine wichtige Quelle. Der semantische Webserver legt dem bestehenden System an, ohne seine Bedienung zu beeinträchtigen. Dokumente "markiert" mit semantischen Informationen (eine Erweiterung der HTML <meta> Tags, die in den heutigen Webseiten verwendet werden, um Informationen für Web-Suchmaschinen mit Web-Crawlern zu liefern). Dies könnte maschinenverstandene Informationen über den menschverstandenen Inhalt des Dokuments sein (z.B. der Schöpfer, Titel, Beschreibung usw.) oder es könnten rein Metadaten sein, die eine Reihe von Tatsachen darstellen (z.B. Ressourcen und Dienstleistungen auf der Website). Beachten Sie, dass alles, was mit einem einheitlichen Ressourcen-Identifier (URI) identifiziert werden kann, beschrieben werden kann, so dass das semantische Web über Tiere, Menschen, Orte, Ideen, etc. Grund sein kann. Es gibt vier semantische Annotationsformate, die in HTML-Dokumenten verwendet werden können; Microformat, RDFa, Microdata und JSON-LD.Semantic markup wird oft automatisch erzeugt, anstatt manuell. Häufige Metadaten-Vokabulare (Ontologien) und Karten zwischen Vokabularen, die es Dokumenten-Erstellern ermöglichen, ihre Dokumente zu markieren, damit Agenten die Informationen in den mitgelieferten Metadaten verwenden können (so dass Autor im Sinne von "Autor der Seite" nicht mit Autor im Sinne eines Buches verwechselt wird, das Gegenstand einer Buchüberprüfung ist). Automatisierte Agenten, um Aufgaben für Benutzer des semantischen Webs mit diesen Daten auszuführen. Web-basierte Dienste (oft mit Agenten ihrer eigenen) um Informationen speziell an Agenten zu liefern, zum Beispiel einen Trust-Service, den ein Agent fragen könnte, ob einige Online-Shop hat eine Geschichte von schlechtem Service oder Spamming. Solche Dienste könnten für öffentliche Suchmaschinen nützlich sein oder für das Wissensmanagement innerhalb einer Organisation genutzt werden. Zu den Business-Anwendungen gehören: Erleichterung der Integration von Informationen aus gemischten Quellen Lösen von Mehrdeutigkeiten in der Unternehmensterminologie Verbesserung der Informationsabrufe und damit Verringerung der Informationsüberlastung und Erhöhung der Verfeinerung und Genauigkeit der abgerufenen Daten Identifizierung relevanter Informationen in Bezug auf eine bestimmte Domain Bereitstellung von Entscheidungsunterstützung In einem Unternehmen gibt es eine geschlossene Gruppe von Nutzern und das Management ist in der Lage, Unternehmensleitlinien wie die Annahme von spezifischen Ontologien und die Verwendung von semantischen Anmerkungen durchzusetzen. Im Vergleich zum öffentlichen Semantic Web gibt es weniger Anforderungen an die Skalierbarkeit und die innerhalb eines Unternehmens zirkulierenden Informationen können generell vertrauter sein; die Privatsphäre ist weniger von einem Problem außerhalb des Umgangs mit Kundendaten. Skeptische Reaktionen Praktische Machbarkeitskritiken stellen die grundlegende Machbarkeit einer vollständigen oder sogar teilweisen Erfüllung des Semantischen Webs in Frage, wobei sowohl Schwierigkeiten bei der Einrichtung als auch eine mangelnde allgemeine Gebrauchstauglichkeit aufgezeigt werden, die die erforderliche Anstrengung verhindert. In einem Papier von 2003 weisen Marshall und Shipman den kognitiven Überkopf auf, der dem formalisierenden Wissen innewohnt, verglichen mit der Autorisierung des traditionellen Web-Hypertexts: Während das Erlernen der Grundlagen von HTML relativ einfach ist, erfordert das Erlernen einer Wissensdarstellungssprache oder eines Werkzeugs, dass der Autor über die Methoden der Darstellung der Abstraktion und deren Wirkung auf die Argumentation erfährt.Zum Beispiel ist das Verständnis der Klassen-Instance-Beziehung oder der Super-Klasse-Subclass-Beziehung mehr als das Verständnis, dass ein Konzept ein "Typ von" ein anderes Konzept ist.[...] Diese Abstraktionen werden Informatikern im Allgemeinen und Wissensingenieuren speziell gelehrt, passen aber nicht der ähnlichen natürlichen Sprache Bedeutung eines "Typs" etwas. Eine effektive Nutzung einer solchen formalen Repräsentation erfordert, dass der Autor neben anderen Fähigkeiten, die von der Domain benötigt werden, zum Fachmann wird.[...] Sobald man eine formale Repräsentationssprache gelernt hat, ist es immer noch viel mehr Anstrengung, Ideen in dieser Repräsentation auszudrücken als in einer weniger formalen Repräsentation [...]. Dies ist eine Form der Programmierung, die auf der Erklärung der semantischen Daten basiert und ein Verständnis dafür erfordert, wie die Argumentationsalgorithmen die autorisierten Strukturen interpretieren. Laut Marshall und Shipman fügt die stillschweigende und sich verändernde Natur von viel Wissen zum Problem der Wissenstechnik hinzu und begrenzt die Anwendbarkeit des Semantic Web auf bestimmte Domänen. Eine weitere Frage, die sie hervorheben, sind die bereichs- oder organisationsspezifischen Möglichkeiten, Wissen auszudrücken, die durch Gemeinschaftsabkommen gelöst werden müssen, anstatt nur technische Mittel. Wie sich herausstellte, haben spezialisierte Gemeinschaften und Organisationen für Intra-Unternehmensprojekte tendenziell semantische Web-Technologien zu übernehmen, die größer sind als periphere und weniger spezialisierte Gemeinschaften. Die praktischen Zwänge zur Adoption haben sich weniger herausfordernd gezeigt, wo Domain und Umfang begrenzter ist als die der Öffentlichkeit und der World-WideWeb. Schließlich sehen Marshall und Shipman pragmatische Probleme in der Idee von (Knowledge Navigator-style) intelligenten Agenten, die im weitgehend manuell geheilten Semantic Web arbeiten: In Situationen, in denen Benutzerbedürfnisse bekannt sind und verteilte Informationsressourcen gut beschrieben werden, kann dieser Ansatz sehr effektiv sein; in Situationen, die nicht vorgesehen sind und die eine nicht erwartete Vielzahl von Informationsressourcen zusammenbringen, ist der Google-Ansatz robuster. Des Weiteren die Semantik Web setzt auf Inferenzketten, die spröde sind; ein fehlendes Element der Kette führt zu einem Ausfall der gewünschten Aktion, während der Mensch fehlende Stücke in einem Google-ähnlichen Ansatz liefern kann.[...] Kosten-Nutzen-Trade können zugunsten speziell erstellter Semantic Web-Metadaten arbeiten, die darauf ausgerichtet sind, vernünftige gut strukturierte Domain-spezifische Informationsressourcen zusammenzuweben; die enge Aufmerksamkeit auf die Benutzer/Kundenbedürfnisse wird diese Verbände antreiben, wenn sie erfolgreich sein sollen. Cory Doctorow's Kritik (Metacrap) ist aus der Perspektive des menschlichen Verhaltens und der persönlichen Präferenzen. Zum Beispiel können die Menschen in Web-Seiten spontane Metadaten enthalten, um semantische Web-Engines zu irreführen, die naiv die Richtigkeit der Metadaten annehmen. Dieses Phänomen war mit Metatags bekannt, die den Altavista-Ranking-Algorithmus zur Erhöhung des Rankings bestimmter Webseiten täuschen: Die Google-Indexing-Engine sucht gezielt solche Manipulationsversuche. Peter Gärdenfors und Timo Honkela weisen darauf hin, dass logische semantische Webtechnologien nur einen Bruchteil der relevanten Phänomene im Zusammenhang mit der Semantik umfassen. Zensur und Privatsphäre Enthusiasmus über das semantische Web könnte durch Bedenken in Bezug auf Zensur und Privatsphäre temperiert werden. So können nun beispielsweise Text-Analysiertechniken durch Verwendung von anderen Worten, Metaphern, beispielsweise durch Verwendung von Bildern anstelle von Wörtern, einfach umgangen werden. Eine fortschrittliche Implementierung des semantischen Webs würde es den Regierungen wesentlich erleichtern, die Anzeige und Erstellung von Online-Informationen zu kontrollieren, da diese Informationen für eine automatisierte Content-Blocking-Maschine viel einfacher zu verstehen wären. Darüber hinaus wurde auch die Frage angesprochen, dass mit der Verwendung von FOAF-Dateien und Geolokationsmetadaten sehr wenig Anonymität mit der Autorschaft von Artikeln zu Dingen wie einem persönlichen Blog verbunden wäre. Einige dieser Bedenken wurden im Projekt "Policy Aware Web" angesprochen und ist ein aktives Forschungs- und Entwicklungsthema. Verdoppeln von Ausgabeformaten Eine weitere Kritik am semantischen Web ist, dass es viel zeitraubender wäre, Inhalte zu erstellen und zu veröffentlichen, weil es zwei Formate für ein Stück Daten geben müsste: ein für die menschliche Betrachtung und ein für Maschinen. Viele Web-Anwendungen in der Entwicklung beschäftigen sich jedoch mit diesem Problem, indem ein maschinenlesbares Format auf der Veröffentlichung von Daten oder der Anforderung eines Rechners für solche Daten erstellt wird. Die Entwicklung von Mikroformaten war eine Reaktion auf diese Art von Kritik. Ein weiteres Argument zur Verteidigung der Durchführbarkeit semantisches Web ist der wahrscheinlich sinkende Preis von menschlichen Intelligenz Aufgaben in digitalen Arbeitsmärkten, wie Amazons Mechanischer Türk. Spezifikationen wie eRDF und RDFa ermöglichen es, beliebige RDF-Daten in HTML-Seiten einzubetten. Mit dem GRDDL (Gleaning Resource Descriptions from Dialects of Language)-Mechanismus können vorhandene Materialien (einschließlich Mikroformate) automatisch als RDF interpretiert werden, so dass Verlage nur ein einziges Format wie HTML verwenden müssen. Forschungsaktivitäten für Unternehmensanwendungen Die erste Forschungsgruppe, die sich explizit auf das Corporate Semantic Web konzentrierte, war das 2002 gegründete ACACIA-Team der INRIA-Sophia-Antipolis. Die Ergebnisse ihrer Arbeit umfassen die RDF(S)-basierte Corese-Suchmaschine und die Anwendung semantischer Webtechnologie im Bereich der verteilten künstlichen Intelligenz für Wissensmanagement (z.B. Ontologien und Multi-Agenent-Systeme für unternehmensemantisches Web) und E-Learning. Seit 2008 konzentriert sich die Forschungsgruppe Corporate Semantic Web an der Freien Universität Berlin auf Bausteine: Corporate Semantic Search, Corporate Semantic Collaboration und Corporate Ontology Engineering. Die Ontologie-Engineering-Forschung umfasst die Frage, wie man nicht-Experten bei der Erstellung von Ontologien und semantisch annotierten Inhalten mit einbezieht und explizite Kenntnisse aus der Interaktion von Nutzern innerhalb von Unternehmen extrahiert. Die Zukunft der Anwendungen Tim O'Reilly, der den Begriff Web 2.0 prägte, schlug eine langfristige Vision des Semantischen Webs als Datenwebsite vor, in dem anspruchsvolle Anwendungen das Datennetz manipulieren. Das Daten-Web verwandelt das World Wide Web von einem verteilten Dateisystem in ein verteiltes Datenbanksystem. Siehe auch Referenzen Weitere Lektüre Liyang Yu (14. Dezember 2014). Ein Entwicklerhandbuch zum Semantischen Web, 2. ed.Springer.ISBN 978-3-662-43796-4.Aaron Swartz's A Programmable Web: Ein unvollendetes Werk, das von Morgan & Claypool Publishers nach Aaron Swartzs Tod im Januar 2013 gespendet wurde. Grigoris Antoniou, Frank van Harmelen (31. März 2008).Ein Semantischer Web Primer, 2. Auflage. Die MIT Press.ISBN 978-0-262-01242-3.Allemang, Dean; Hendler, James; Gandon, Fabien (August 3, 2020). Semantisches Web für den Arbeits-Ontologe : Effektive Modellierung für verknüpfte Daten, RDFS und OWL (Dritte ed.). [New York, NY, USA:] ACM Bücher; 3. Auflage. ISBN 978-1450376143. Pascal Hitzler; Markus Krötzsch; Sebastian Rudolph (25. August 2009). Stiftungen von Semantic Web Technologies.CRCPress.ISBN 978-1-4200-9050-5.Thomas B. Passin (1. März 2004). Explorer's Guide to the Semantic Web.Manning Publications.ISBN 978-1-932394-20-7. Jeffrey T. Pollock (23. März 2009).Semantisches Web für Dummies. Für Dummies.ISBN 978-0-470-39679-7.Hitzler, Pascal (Februar 2021)."Ein Überblick über das Semantische Webfeld".Kommunikation des ACM.64 (2:) 76–83.doi:10.1145/3397512 Externe Links Offizielle Website Durchbruch Analyse: Ein Datenraum für Informationskoexistenz