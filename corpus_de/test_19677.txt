In statistischer Modellierung ist die Regressionsanalyse eine Reihe statistischer Prozesse, um die Beziehungen zwischen einer abhängigen variablen (häufig das Ergebnis oder die Reaktionsvariable genannt) und einem oder mehreren unabhängigen Variablen (häufig sogenannten Berechenten, Kovariaten, „Begründetvariablen“ oder Merkmalen) zu erfassen. Die häufigste Form der Regressionsanalyse ist lineare Regression, in der die Linie (oder eine komplexere lineare Kombination) die Daten nach einem spezifischen mathematischen Kriterium am engsten passt. Beispielsweise berechnet die Methode der normalen mindestens Quadrate die einzigartige Linie (oder ein Hyperflugzeug), die die Summe der flächendeckenden Unterschiede zwischen den wahren Daten und dieser Linie (oder dem Hyperflugzeug) minimiert. Konkrete mathematische Gründe (siehe lineare Regression) ermöglichen es dem Forscher, die bedingte Erwartung der abhängigen Variablen zu schätzen, wenn die unabhängigen Variablen auf einer Reihe von Werten basieren. Weniger gemeinsame Regressionsformen verwenden leicht unterschiedliche Verfahren zur Schätzung alternativer Standortparameter (z.B. Quantile Regression oder Necessaryzustandanalyse) oder Schätzung der bedingten Erwartung über eine breitere Sammlung nichtlinearer Modelle (z.B. nicht-metrische Regression). Regressionsanalysen werden in erster Linie für zwei konzeptuelle Zwecke verwendet. Erstens wird die Regressionsanalyse weit verbreitet zur Vorhersage und Vorhersage verwendet, wo ihre Verwendung erhebliche Überschneidungen mit dem Bereich des maschinellen Lernens hat. Zweitens kann in einigen Situationen eine Regressionsanalyse verwendet werden, um Kausalbeziehungen zwischen den unabhängigen und abhängigen Variablen zu vermeiden. Wichtig ist, dass die Regressionen selbst nur die Beziehungen zwischen einer abhängigen variablen und einer Sammlung unabhängiger Variablen in einem festen Datensatz aufzeigen. Um Regressionen für Vorhersagen oder Kausalzusammenziehungen zu verwenden, muss ein Forscher sorgfältig wissen, warum bestehende Beziehungen eine prädiktive Macht für einen neuen Kontext haben oder warum eine Beziehung zwischen zwei Variablen eine Kausalde hat. Letztere ist besonders wichtig, wenn die Forscher die Kausalbeziehungen mit Beobachtungsdaten schätzen wollen. Geschichte Die frühe Art der Regression war die Methode von mindestens Quadratmetern, die von der Legendre 1805 und von Gauss 1809 veröffentlicht wurde. Legendre und Gausss nutzten beide die Methode, um das Problem zu bestimmen, von den Astrobeobachtungen, den Entbiten von Gremien über die Sun (meist kommend, aber auch später die neu entdeckten Minderjährigen). Gausss veröffentlichte 1821 eine Weiterentwicklung der Theorie von mindestens Quadratmetern, einschließlich einer Version der Gaus-Markov-Theorem. Francis Galton wurde im 19. Jahrhundert zur Beschreibung eines biologischen Phänomens verurteilt. Das Phänomen war, dass die Höhe der Nachkommen von Großnachläsern tendenziell tendenziell zu einem normalen Durchschnitt zurückgehen (ein Phänomen, das auch als Regression auf das bedeutet bekannt ist). Für Galton war die Regression nur diese biologische Bedeutung, aber seine Arbeit wurde später von Udny Yule und Karl Pearson auf einen allgemeineren statistischen Kontext ausgeweitet. In der Arbeit von Yule und Pearson wird die gemeinsame Verteilung der Reaktions- und erläuternden Variablen als Gaussian angenommen. Diese Annahme wurde von R.A Fisher in seinen Werken von 1922 und 1916 abgeschwächt. Fisher hat angenommen, dass die bedingte Verteilung der Reaktionsvariable Gausssian ist, aber die gemeinsame Verteilung ist nicht erforderlich. In diesem Zusammenhang ist die Annahme der Fischer näher an die Formulierung von Gauss von 1821. In den 1950er und 1960er Jahren verwendeten Ökonomen elektromechanische Schaltrechner zur Berechnung von Regressionen. Vor 1970 dauerte es bis zu 24 Stunden, um das Ergebnis einer Regression zu erhalten. Regressionsmethoden sind weiterhin ein Bereich der aktiven Forschung. In den letzten Jahrzehnten wurden neue Methoden für eine robuste Regression, Regression entwickelt, die mit korrelativen Reaktionen wie Zeitreihen und Wachstumskurven, Regression, bei denen der vorhergesagte (unabhängige variable) oder Reaktionsvariablenkurvenkurven, Bilder, Graphen oder andere komplexe Daten, Regressionsmethoden, die verschiedene Arten fehlender Daten, nichtmetrische Regression, Bayesische Regressionsmethoden für Regression, Regression in denen die vorhergesagten Variablen mit Fehlern gemessen werden, Regression mit mehr Berechenbarkeitsvariablen, als Beobachtungen und Degression. Regressionsmodell In der Praxis wählten die Forscher zunächst ein Modell aus, mit dem sie ihre gewählte Methode (z.B. gewöhnliche mindestens Quadrate) bewerten möchten, um die Parameter dieses Modells zu schätzen. Regressionsmodelle umfassen folgende Komponenten: Die unbekannten Parameter, die oft als scalar oder Vektor β dampfstyle \beta } .Die unabhängigen Variablen, die in Daten beobachtet werden und häufig als Vektor X i {\displaystyle X_{i} (wo i {\displaystyle i} eine Reihe von Daten verdichtet). Die abhängige Variablen, die in Daten beobachtet werden und oft unter Verwendung des scalar Y i WELLdisplaystyle Y_{i} verdichtet werden.Die Fehlerbedingungen, die nicht unmittelbar in Daten beobachtet werden, werden oft unter Verwendung des scalar e i scalar e i ggiodisplaystyle e__{i} vereitelt. In verschiedenen Anwendungsbereichen werden unterschiedliche terminologien anstelle von abhängigen und unabhängigen Variablen verwendet. Die meisten Regressionsmodelle schlagen vor, dass Y i WELLdisplaystyle Y_{i} eine Funktion von X i {\displaystyle X_{i} und β Memedisplaystyle \beta } ist, mit e i {\displaystyle e___{i}, die eine Zusatzfehlerfrist darstellt, die für unmodellierte Determinanten von Y i {\displaystyle Y_{i} oder zufälliges statistisches Lärm: Y i = f ( X i, β ß i) + edisplaystyle KING Stil Y_{i}=f(X_{i},\beta )+e_{i} Das Ziel der Forscher besteht darin, die Funktion f ( X i , β ) faserstyle f(X_{i},\beta )} zu schätzen, die die Daten am engsten anpasst. Um die Regressionsanalyse durchzuführen, muss die Form der Funktion f {\displaystyle f} angegeben werden. Manchmal basiert die Form dieser Funktion auf dem Wissen über die Beziehung zwischen Y i KINGstyle Y_{i} und X i {\displaystyle X_{i}, das sich nicht auf die Daten stützt. Kommt kein solches Wissen zur Verfügung, wird eine flexible oder bequeme Form für f Memedisplaystyle f} gewählt. Beispielsweise kann eine einfache einseitige Regression f ( X i , β ) = β 0 + β vorschlagen 1 X i WELLdisplaystyle f(X_{i},\beta )\=beta {_0}+\beta 1}X_{i , was darauf hindeutet, dass der Forscher Y i = β 0 + β 1 X i + e i livstyle Y_{i}=\beta {_0}+\beta 1}X_{i}+e_{i soll eine angemessene Angleichung für den statistischen Prozess darstellen, der die Daten generiert. Sobald die Forscher ihr bevorzugtes statistisches Modell bestimmen, bieten unterschiedliche Formen der Regressionsanalyse Instrumente zur Schätzung der Parameter β dampfdisplaystyle \beta } . Zum Beispiel gibt es mindestens Quadrate (einschließlich der am häufigsten auftretenden Variante, der kleinsten Quadrate) den Wert der β ß ß ß \beta }, die die Summe der äquivalenten Fehler  i i ( Y i − f ( X i, β ) 2 displaystyle \ i \ iY_style (Y_i-A-A-X-.-Methode, X-X-X-}-}-}-}-}-}-}-}-}-}-}-}-}-}-}-}-}-}-}-}-} } } } } } } } } } } } } } } } } } } } } } } } } } } } } } } } } } } }  Mit dieser Schätzung kann der Forscher dann den Wert verwenden, den Y i ^ = f ( X i , β ^ ) Memedisplaystyle Memehat Y_{i==f(X_{i}, cuhat Memebeta }})} zur Vorhersage oder Bewertung der Richtigkeit des Modells bei der Erläuterung der Daten. unabhängig davon, ob der Forscher an der Schätzung β ^ {\displaystyle  cuhat HANAbeta }}} oder anhand des vorhergesagten Werts Y i ^ KINGstyle  cuhat Y_{i} auf Kontext und Ziele angewiesen ist. Wie in normalen Quadraten beschrieben, werden in der Regel mindestens Quadrate häufig verwendet, weil die geschätzte Funktion f ( X i , β ^ ) {\displaystyle f(X_{i}, cuhat  cubeta }}) die bedingten Erwartungen an E ( Y i [X i ) Memestyle E(Y_{i}X_{i}ever, Alternativvarianten (z.B. absolute Abweichungen oder Quantile Regression) sinnvoll sind, wenn die Forscher andere Vorbildfunktionen (X) · {i}, {i} {i} ·ever, Varianten (z. Es ist wichtig zu beachten, dass genügend Daten zur Schätzung eines Regressionsmodells vorliegen müssen. Man braucht beispielsweise, dass ein Forscher Zugang zu N Memedisplaystyle N} Folgedaten mit einem abhängigen und zwei unabhängigen Variablen hat: ( Y i , X 1 i , X 2 i ) Memestyle (Y_{i},X_{1i},X_{2i) .Sup schlägt weiter vor, dass der Forscher ein bivariate lineares Modell über mindestens Quadrate berechnen möchte: Y i = β 0 + β 1 X 1 i + β 2 X 2 i + e i displaystyle Y_{i}=\beta {_0}+\beta 1}X_{1i}+\beta 2}X_{2i}+e_{i . Wenn der Forscher nur Zugang zu den Daten von N = 2 Memedisplaystyle N=2} hat, könnten sie auf unbegrenzte Weise viele Kombinationen finden ( β ^ 0 , β ^ 1 , β ^ 2 ) {\displaystyle {(\hat Memebeta _0}, 7.8beta _1}, 7.8beta {_2), dass jede Kombination gewählt werden kann, dass die Daten gleichwertig sind: 1 X 1 i + β ^ 2 X 2 i KINGstyle Y__{i}=Olhat HANAbeta _0}+ CALhat 7.8beta 1}X_{1i}+Barhat Memebeta 2}X_{2i , die alle zur  i i e ^ i 2 =  to führen i ( Y ^ i - ( β ^ 0 + β ^ 1 X 1 i + β ^ 2 X 2 i ) 2 = 0 KINGstyle \sum _i}{\hat e__{i}^{2}=\sum _i}(Gethat) Y__{i}-(Gethat HANAbeta _0} 1}X_{1i} + cuhat ggiobeta 2}X_{2i})^{2}=0 und sind daher gültige Lösungen, die die Summe der Quadratkilometer minimieren. Um zu verstehen, warum es unbegrenzt viele Optionen gibt, ist darauf hinzuweisen, dass das System der N = 2 {\displaystyle N=2} für 3 Unbekannte gelöst werden muss, was das System unterstellt. Alternativ kann man auf unbegrenzte Weise viele dreidimensionale Flugzeuge, die über N = 2 Memestyle N=2} übertragbar sind. Mehr als allgemein, um ein Modell von mindestens Quadraten mit k Memedisplaystyle k} unterschiedliche Parameter zu schätzen, muss ein N ≥ k displaystyle N\geq k} unterschiedliche Datenpunkte haben. Kommt N {\ k HANAdisplaystyle N<k}, gibt es keine Reihe von Parametern, die die Daten perfekt passen werden. Die Menge N - k HANAdisplaystyle N-k} erscheint oft in der Regressionsanalyse und wird als Grad der Freiheit im Modell bezeichnet. Außerdem müssen die unabhängigen Variablen ( X 1 i , X 2 i , . , X k i ) Memestyle (X_{1i},X_{2i},...,X_{2i},X_{ki) linear unabhängig sein: Eine darf nicht in der Lage sein, alle unabhängigen Variablen durch Zugabe und Vervielfältigung der verbleibenden unabhängigen Variablen zu renovieren. Diese Bedingung stellt sicher, dass X T X T X {\displaystyle X XT} X ist eine unwiderrufliche Matrix und damit eine einzigartige Lösung β ^ KINGstyle Memehat ggiobeta . existiert. zugrunde liegende Annahmen Ein Regression ist einfach eine Berechnung der Daten. Um die Produktion einer Regression als eine sinnvolle statistische Menge zu interpretieren, die echte Beziehungen in der Welt fördert, stützen sich die Forscher häufig auf eine Reihe klassischer Annahmen. Diese umfassen häufig: Die Probe ist repräsentativ für die Gesamtbevölkerung. Die unabhängigen Variablen werden ohne Fehler gemessen. Abweichungen vom Modell haben einen zu erwartenden Wert von Null, bedingt durch Kovariate: E (e i ) = 0 Kaffeedisplaystyle E(e_{i}|X_{i})=0 Die Varianz der Reste e i {\displaystyle e_{i} ist ständig über Beobachtungen (Höhnlichkeit). Reste e iKINGstyle e_{i} ist nicht miteinander verbunden. Mathematiklich ist die Varianz-Risikomatrix diagonal. Eine Hand der Bedingungen reicht aus, um die am wenigsten geeigneten Eigenschaften zu besitzen: Insbesondere die Gaus-Markov-Annahmen bedeuten, dass die Parametervoranschläge unvoreingenommen, kohärent und effizient in der Klasse linearer, unvoreingenommener Ester liegen. Ärzte haben eine Vielzahl von Methoden entwickelt, um einige oder alle dieser wünschenswerten Eigenschaften in realen Umgebungen zu erhalten, da diese klassische Annahmen nicht genau halten können. Modellierung von Fehlern in Variablen kann beispielsweise zu vernünftigen Schätzungen führen, dass unabhängige Variablen mit Fehlern gemessen werden. Hetersssenklichkeitskonsistente Standardfehler ermöglichen die Varianz von e i {\displaystyle e_{i}, um die Werte von X i displaystyle X_{i} zu ändern .Cor-bedingte Fehler, die innerhalb der Teilsätze der Daten bestehen oder spezifische Muster folgen, können mit Hilfe von gruppenspezifischen Standardfehlern, geographisch gewichteter Regression oder von Newey-West-Standardfehlern unter anderem behandelt werden. Wenn Folgedaten an Orte im Weltraum entsprechen, kann die Wahl, wie das Modell e i {\displaystyle e_{i} innerhalb geografischer Einheiten wichtige Folgen haben. Das Unterfeld von Ökonometrien konzentriert sich weitgehend auf die Entwicklung von Techniken, die es Forschern ermöglichen, in Echtzeit realistische Schlussfolgerungen zu machen, in denen klassische Annahmen nicht genau bestehen. lineare Regression lineare Regression ist die Modellspezifikation, dass die abhängige variable, y i KINGstyle y_{i} eine lineare Kombination der Parameter ist (aber nicht linear in den unabhängigen Variablen). Beispielsweise gibt es in einfacher linearer Regression für Modellierung von n {\displaystyle n} Datenpunkte gibt es eine unabhängige Variablen: x i {\displaystyle x_{i} und zwei Parameter, β 0 {\displaystyle \beta {_0} und β 1 {\displaystyle \beta {_1} : y i = β 0 + β 1 x i +  i i , i = 1 , ... n, n . . . . n y_{i} {_0}+\beta 1}x_{i}+\varepsilon {_i},\quad i=1,\dots ,n.!! Mehr lineare Regression gibt es mehrere unabhängige Variablen oder Funktionen unabhängiger Variablen. Hinzufügen eines Begriffs in x i 2 Kaffeedisplaystyle x_{i}^{2 an die vorhergehende Regression: parabola: y i = β 0 + β 1 x i + β 2 x i 2 +  i i , i = 1 , ... n , n y_{i} {_0}+\beta 1} 2}x_{i}^{2}+\varepsilon {_i, i i=1,\dots ,n.!! Dies ist immer noch lineare Regression; obwohl der Ausdruck auf der rechten Seite quadratisch in der unabhängigen variablen x i {\displaystyle x_{i} ist, ist er linear in den Parametern β 0 RARstyle \beta {_0} , β 1 574 \beta {_1} und β 2 . KINGstyle \beta {_2}. In beiden Fällen ist  i i {\displaydisplaystyle \varepsilon {_i} eine Fehlerfrist und die Unterbeschreibung i {\displaystyle i} eine besondere Beobachtung. Rückführung unserer Aufmerksamkeit auf den genauen Punkt: In Anbetracht einer Zufallsstichprobe der Bevölkerung schätzen wir die Populationsparameter und erwerben das lineare Regressionsmodell: y ^ i = β ^ 0 + β ^ 1 x i . KINGstyle y__{i}=ñedhat 7.8beta _0}+ CALlonghat 7.8beta 1}x_{i. Rest, e i = y i − y ^ i KINGstyle e_{i}=y_{i} y__{i ) ist der Unterschied zwischen dem Wert der vom Modell vorhergesagten abhängigen variablen Variablen, y ^ i {\displaystyle Memeallhat y}}_{i ) und dem wahren Wert der abhängigen variablen, y i KINGstyle y_{i} . Eine Methode der Schätzung ist normal. Diese Methode enthält Parameterschätzungen, die die Summe der Quadratkilometer minimieren, SSR: S R =  i i = 1 n e i 2 . KINGstyle SSR=\sum i=1}^{n}e_{i.2,\. Minimierung dieser Funktion führt zu einer Reihe normaler Gleichungen, einer Reihe gleichzeitiger linearer Gleichungen in den Parametern, die gelöst werden, um die Parameter Ester, β ^ 0 , β ^ 1 {\displaystyle HANA ONAside Memebeta _0}, {_1 . Im Falle einer einfachen Regression sind die Formeln für die am wenigsten geschätzten Quadrate β ^ 1 = s ( x i − x ̄ ) ( y i − y ̄ ) ) ( x i − x ) ) 2 Memedisplaystyle JPY {i}-Barbar y{\)}{\sum (x_{i}-Barbar x}})(y_{i}-Barbar y}}) (sum (x_{i}-Getbar x}}) 02 β ^ 0 = y ̄ . − β . . .  1  1  1  1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  Unter der Annahme, dass die Begriffsbestimmung der Bevölkerung eine konstante Varianz aufweist, wird die Schätzung dieser Varianz durch:    2 2 = S R n − 2 . Memedisplaystyle  cuhat ggiohat sigma 7.8_}varepsilon ^2}= Finanzfrac SSR-2n-2,\. Dies ist der durchschnittliche Quadratfehler (MSE) der Regression. Der Nenner ist die Stichprobengröße, die durch die Anzahl der Modellparameter, die aus den gleichen Daten (n ‐ p ) Memedisplaystyle (n-p)} für p {\displaystyle p} Regressoren oder (n ‐ 1 ) Memestyle (n-p-1)} geschätzt werden, wenn eine Überwachung verwendet wird. In diesem Fall p = 1 {\displaydisplaystyle p=1} so ist der Nenner n - 2 Memestyle n-2}. Standardfehler der Parameterschätzungen werden von   ^ β 1 =    1 1 ) ( x i − x ̄ )) angegeben. 2 Memedisplaystyle 7.8_}beta _1== Fisssigma 7.8_}varepsilon .sqrt 7.8frac 1}{\sum (x_{i}-Barbar x}})^{2 . . .  1 1 n + x  2 2  ( ( x i − x ̄ ) 2 = σ . . . .  1  1  i  i  i 2 n . KINGstyle SSOhat HANASigma 7.8_}beta _0== 7.8_}varepsilon  sqrt SSOfrac 1}}n{\ + Fifrac ggiobar x}}^{2)sum (x_{i}-Olbar x}})=2{\= Fissigma ggio_}beta _1qsqrt ggiofracfrac 7.8sum x_{i}^{2}}{n. Nach der weiteren Annahme, dass die Begriffsbestimmung für die Bevölkerung normalerweise verteilt ist, kann der Forscher diese geschätzten Standardfehler verwenden, um Vertrauensintervalle zu schaffen und Hypothesis-Tests über die Bevölkerungsparameter durchzuführen. lineares Modell Im allgemeineren Multi-Regressionsmodell gibt es p Memestyle p} unabhängige Variablen: y i = β 1 x i 1 + β 2 x i 2 +  + + β p x i p +  i i , {\displaystyle y_{i} 1}x_{i1}+\beta 2}x_{i2}+\cdots +\beta p}x_{ip}+\varepsilon {_i, where, wo x i j {\displaystyle x_{ij} die i {\displaystyle i} -th Beobachtung auf der j {\displaystyle j} -th unabhängige Variablen. Kommt die erste unabhängige Variablen den Wert 1 für alle i {\displaystyle i}, x i 1 = 1 {\displaystyle x_{i1}=1 , dann β 1 {\displaystyle \beta {_1} wird die Regressionsüberwachung genannt. Die wenigsten Quadratmeter-Parameter-Schätzungen werden aus p Memestyle p} Normalgleichungen erzielt. Rest kann als  i i = y geschrieben werden i − β ^ 1 x i 1 − ⋯ − β ^ p x i p . KINGstyle \varepsilon i}=y_{i}-Barhat Memebeta 1}x_{i1}-\cdots {-\hat livbeta p}x_{ip. s i = 1   k = 1 p x i k β ^ k = ∑ i = 1 n x i j y i , j = 1 , ... , p . .  steuerliche \sum _i=1}^{n,sum k=1}^{p}x_{ij}x_{ik}{\hat livbeta {_k}=\sum i=1}^{n}x_{ij}y_{i,\ j=1,\dots p.. In Matrixnotation werden die normalen Gleichungen geschrieben wie ( X  X X ) β ^ = X s Y , {\displaystyle \ Mathematik (X^{\top }X) cuhat  Binnenmarktzeichen Memebeta =}X Ytop Y ,\,}, wo das i j KINGstyle ij} Element X {\displaystyle \ Mathematik {X} ist x}i j {\displaystyle x_{ij} , i {\displaystyle i} Element des Spaltenvektors Y {\displaystyle Y} ist y i {\displaystyle y_{i} und das j {\displaystyle j} Element β β ^ 7.8displaystyle  cuhat faserzeichen {\ {\ β ^ j {\displaydisplaystyle Memebeta {_j .Thus X Memestyle \ Mathematik {X} } ist n × p {\displaystyle n\times p} , Y Memestyle Y} ist n × 1 {\displaystyle n\times 1}, und β ^ KING  fihat oli oli n oli {\ {\ {\ {\  1  1 1 {\ 1 s {\ {\  1 1 s s {\ {\ s {\ 1 s  1 s s s s s  1 s s s s s  1  1  1  1  1  1  1  1  1  1  1 s s  1  1  1  1 s s  1 s s s s s s  1  1  1 s  1 s  1  1  1  1  1  1  1  1  1  1  1  1  1 1} .Die Lösung ist β ^ = ( X  X X ) − 1 X . Y . . Memedisplaystyle \dl  cuhat  Binnenmarktzeichen Memebeta =(}X^{\top X)-1-1}X Ytop Y .\,} Diagnosen Nach dem Bau eines Regressionsmodells kann es wichtig sein, die Eignung des Modells und die statistische Bedeutung der geschätzten Parameter zu bestätigen. Häufig verwendete Prüfungen der Eignung umfassen die R-Quadrat, Analysen des Musters der Reste und Hypothesis-Tests. Statistische Bedeutung kann von einem F-Test des Gesamtanpassers überprüft werden, gefolgt von T-Tests einzelner Parameter. Interpretationen dieser Diagnosetests stehen in hohem Maße auf den Annahmen des Modells. Obwohl die Prüfung der Reste zur Ungültigkeit eines Modells verwendet werden kann, sind die Ergebnisse eines T-Tests oder F-Tests manchmal schwieriger zu interpretieren, wenn die Annahmen des Modells verletzt werden. Wenn die Fehlerfrist beispielsweise nicht eine normale Verteilung aufweist, werden die geschätzten Parameter nicht den normalen Vertriebenen folgen und die Ausgewogenheit erschweren. Mit relativ großen Proben kann jedoch ein zentraler Grenzwert verwendet werden, so dass hypothesis-Tests unter Verwendung von asymptotischen Annäherungen führen können. Begrenzte abhängige Variablen Limited abhängige Variablen, die Reaktionsvariablen sind, die Kategorithmen sind oder Variablen sind, die nur in einer bestimmten Bandbreite fallen, entstehen häufig in Ökometrien. Die Reaktionsvariable kann nicht kontinuierlich sein (begrenzt auf einige Unterstufen der tatsächlichen Linie). für binäre (zero oder ein) Variablen, wenn die Analyse mit einer linearen Regression von mindestens Quadratmetern führt, wird das Modell als lineares Wahrscheinlichkeitsmodell bezeichnet. Nichtlineare Modelle für binäre Variablen umfassen das Probit- und Logit-Modell. Das multivariate Probit-Modell ist eine Standardmethode, die eine gemeinsame Beziehung zwischen mehreren binären abhängigen Variablen und einigen unabhängigen Variablen erschüttert. Für kategorische Variablen mit mehr als zwei Werten gibt es das multinomiale Logit. Für ordinale Variablen mit mehr als zwei Werten gibt es das bestellte Logit und bestellte Probit-Modelle. Censored Regressionsmodelle können verwendet werden, wenn die abhängige Variablen nur manchmal beobachtet werden, und Heckman Korrekturartmodelle können verwendet werden, wenn die Probe nicht zufällig von der Bevölkerung von Interesse ausgewählt wird. Eine Alternative zu solchen Verfahren ist lineare Regression auf der Grundlage von polychoric Korrelation (oder polyserialen Korrelationen) zwischen den kategorischen Variablen. Solche Verfahren unterscheiden sich in den Annahmen über die Verteilung der Variablen in der Bevölkerung. Wenn die variable Wirkung mit niedrigen Werten positiv ist und die Wiederholung des Ereignisses darstellt, dann werden Modelle wie die Poisson-Regression oder das negative binomiale Modell verwendet. Nichtlineare Regression Wenn die Modellfunktion in den Parameter nicht linear ist, muss die Summe der Quadrate durch ein iteratives Verfahren minimiert werden. Dies führt viele Komplikationen ein, die in Unterschieden zwischen linearen und nichtlinearen mindestens Quadraten zusammengefasst werden. Interpolation und Extrapolation Regressionsmodelle erwarten einen Wert der Y variablen Werte der X-variablen. Vorhersagen innerhalb der Bandbreite der Werte in dem für die Modellierung verwendeten Datenset sind informell als Interpolation bekannt. Vorhersage außerhalb dieser Datenpalette ist als Extrapolation bekannt. Darbietende Extrapolation setzt sich stark auf die Regressionsannahmen ein. Je weiter die Extrapolation außerhalb der Daten geht, desto mehr Raum ist das Modell, weil Unterschiede zwischen den Annahmen und den Stichprobendaten oder den wahren Werten bestehen. In der Regel wird empfohlen, bei der Durchführung von Extrapolation den geschätzten Wert der abhängigen variablen Variablen mit einem Vorhersageintervall, das die Unsicherheit darstellt, zu begleiten. In solchen Intervallen ist es tendenziell, schnell zu expandieren, da die Werte der unabhängigen Variablen (s) außerhalb des von den beobachteten Daten abgedeckten Bereichs bewegt wurden. Manche sagen aus solchen Gründen und anderen, dass es vielleicht unlauter wäre, Extrapolation durchzuführen. Jedoch deckt dies nicht die vollständige Reihe von Modellfehlern ab, die möglicherweise gemacht werden: insbesondere die Annahme einer besonderen Form für die Beziehung zwischen Y und X. In einer ordnungsgemäß durchgeführten Regressionsanalyse wird untersucht, wie gut das angenommene Formular mit den beobachteten Daten übereinstimmt, aber es kann nur innerhalb der Bandbreite der tatsächlich verfügbaren Werte der unabhängigen Variablen geschehen. Dies bedeutet, dass jede Extrapolation besonders von den Annahmen abhängig ist, die über die strukturelle Form der Regressionsbeziehung gemacht werden. Best-Practice-Empfehlung hier ist, dass ein linear-in-variablen und linear-in-Parameter-Beziehungen nicht nur für Rechenzwecke bestimmt werden sollten, sondern dass alle verfügbaren Kenntnisse beim Aufbau eines Regressionsmodells eingesetzt werden sollten. Wenn dieses Wissen die Tatsache einschließt, dass die abhängige variable nicht über eine bestimmte Bandbreite von Werten hinausgehen kann, kann dies auch bei der Auswahl des Modells verwendet werden – selbst wenn der beobachtete Datenset keine Werte hat, die besonders nahe solchen Grenzen liegen. Die Auswirkungen dieses Schritts, eine geeignete funktionelle Form für die Regression zu wählen, können sehr groß sein, wenn die Extrapolation berücksichtigt wird. Mindestens kann sichergestellt werden, dass jede Extrapolation, die aus einem eingebauten Modell entsteht, realistisch ist (oder mit dem, was bekannt ist). Leistungs- und Stichprobenberechnungen Es gibt keine allgemein anerkannten Methoden für die Anzahl der Beobachtungen gegenüber der Anzahl unabhängiger Variablen im Modell. Eine von Good und Hardin geleitete Regel ist N = m n {\displaystyle N=m^{n} , wo N {\displaystyle N} die Stichprobe ist, n RARstyle n} ist die Anzahl unabhängiger Variablen und m Memedisplaystyle m} die Anzahl der Beobachtungen, die erforderlich sind, um die Genauigkeit zu erreichen, wenn das Modell nur eine unabhängige Variablen hatte. Ein Forscher baut beispielsweise ein lineares Regressionsmodell mit einem Datenset auf, der 1000 Patienten enthält ( N displaystyle N} ). Kommt der Forscher zu dem Schluss, dass fünf Beobachtungen erforderlich sind, um eine gerade Linie ( m HANAstyle m} ) genau festzulegen, so kann die maximale Anzahl unabhängiger Variablen, die das Modell unterstützen kann, 4 betragen, weil Log  1000 1000 log  5 5 = 4.29 {\displayfrac ggiofrac 1000{\log 5 5=4.29 Andere Methoden Obwohl die Parameter eines Regressionsmodells in der Regel anhand der Methode von mindestens Quadratmetern geschätzt werden, sind andere Methoden, die verwendet wurden, u. a.: Biesische Methoden, z.B. lineare Regression Percentage-Regression, für Situationen, in denen die Verringerung der prozentualen Fehler als angemessen gilt. Leaste absolute Abweichungen, die in Anwesenheit von Auslierern robuster sind, die zu einer quantifizierten Regression führen, erfordern eine große Anzahl von Beobachtungen und ist rechnerisch intensive Szenariooptimierung, die zu einer Zeitvorhersagemodellen des Fernunterrichts führt, die durch die Suche nach einer sinnvollen Entfernung in einem bestimmten Eingangsraum gelernt werden. Software Alle wichtigen statistischen Software-Pakete führen mindestens Quadratmeter Regressionsanalyse und Gleichgültigkeit durch. Einfache lineare Regression und mehrfache Regression mit mindestens Quadraten können in einigen Bandbreiten-Anwendungen und in einigen Rechenrechnern erfolgen. Viele statistische Software-Pakete können verschiedene Arten von nichtparametrischen und robusten Regressionen durchführen, diese Methoden sind weniger standardisiert; unterschiedliche Softwarepakete verwenden unterschiedliche Methoden und eine Methode mit einem bestimmten Namen können in verschiedenen Paketen unterschiedlich umgesetzt werden. Spezialisierte Regressionssoftware wurde für den Einsatz in Bereichen wie Erhebungsanalyse und Neugründung entwickelt. Lesen Sie auch die weitere Lesung William H. Kruskal und Judith M. Tanur, ed.(1978), "Linear Hypothesen," Internationale Veröffentlichung von Statistiken. Free Press, v. 1,Evan J. Williams, "I. Regression", S.523–41.Julian C. Stanley, "II.Analysis of Variance", S.541–554.Lindley, D.V. (1987) "Regression und Korrelationsanalyse", "New Palgrave: Ein Wirtschaftswissenschaftler, v. 4, S. 120–23. Birkes, David und Brian, Y, Alternative Regressionsmethoden.ISBN 0-471-56881-3 Chatfield, C. (1993) "Calcating Interval Forecasts," Journal of Business and Economic Statistics, 11.pp.121–135. Draper, N.R; Smith, H. (1998). angewandte Regressionsanalyse (3rd ed). John Kuhn. J. (1997). angewandte Regressionsanalyse, Linearmodelle und verwandte Methoden. Sage Hardle, W. Applied Nonparametric Regression (1990), ISBN 0-521-42950-1 Meade, Nigel; Islam, Towhidul (1995)."Prediction Intervalle für Wachstumskurven. Journal of Forecasting.14 (5): 413–430.doi:10.1002/for.3980140502.A Sen, M. Srivastava, Regression – Theorie, Methoden und Anwendungen, Springer-Verlag, Berlin, 2011 (4. Druck). T Strutz: Datensicherung und Uncertainty (eine praktische Einführung, um mindestens Quadratmeter und darüber hinaus gewichtet zu werden). Vieweg+Teubner, ISBN @3-8348-1022-9.Malakooti, B. (2013). Betriebs- und Produktionssysteme mit mehreren Zielen. John Kuhn & Sons. Externe Links "Regressionsanalyse," Veröffentlichung von Mathematik, EMS Presse, 2001 [1994]Earliest Verwendungen: Regression – Grundgeschichte und Referenzregression von Weakly Cor-Daten – Wie lineare Regressionsfehler auftreten können, wenn Y-range viel kleiner ist als X-range Die Stabilität – das Paradox ist eine internationale Beziehungstheorie für die Wirkung von Kernwaffen und die gegenseitige Verminderung. Man stellt fest, dass die Wahrscheinlichkeit eines direkten Krieges zwischen beiden Ländern erheblich sinkt, aber die Wahrscheinlichkeit kleiner oder indirekter Konflikte zwischen ihnen steigt. Dies geschieht, weil rationale Akteure nukleare Kriege vermeiden wollen, so dass sie weder große Konflikte beginnen noch Minderjährige Konflikte in größere Konflikte bringen können – so ist es sicher, in kleinere Konflikte zu treten. Zum Beispiel haben die Vereinigten Staaten und die Sowjetunion während des Kalten Krieges nie miteinander in Kriegsführung geflohen, sondern Kampf gegen Korrespondentitätskriege in Korea, Vietnam, Angola, dem Nahen Osten, Nicaragua und Afghanistan gekämpft und erhebliche Summen an Geld und Personal für den relativen Einfluss auf die dritte Welt ausgegeben. Im Jahr 2009 veröffentlichte eine im Amtsblatt der Konfliktlösung veröffentlichte Studie quantitative Bewertung der nuklearen Friedenshypothese und fand Unterstützung für das Bestehen des Stabilitäts-Instability Paradoxs. In der Studie wurde festgestellt, dass Kernwaffen die strategische Stabilität fördern und große Kriege verhindern, dass sie gleichzeitig höhere Intensitätskonflikte zulassen. Wenn ein nukleares Monopol zwischen zwei Staaten besteht und ihr Gegner nicht, besteht eine größere Kriegsgefahr. Kommt es hingegen zu einer beiderseitigen nuklearen Besitzung mit beiden Staaten, die über nukleare Waffen verfügen, kommt der Konflikt vorab zu. Dieser Effekt kann in den Beziehungen Indien-Pakistan und in gewissem Maße in Russland-NATO-Beziehungen gesehen werden. Mechanismus Stabilität – Unfähigkeitswidrig macht deutlich, dass beide Konfliktparteien den strategischen Konflikt und das teilnehmende Risiko eines strategischen nuklearen Austauschs als unhaltbar betrachten und damit eine Eskalation substrategischer Konflikte auf strategischer Ebene vermeiden werden. Diese effektive „Cap“ auf substrategischen militärisch militärisch motivierten Konfliktverhütungshorten stellt fest, dass sie in solchen Konflikten mit dem Vertrauen eintreten, dass sie nicht aus Kontrolle gerät und ihre strategischen Interessen bedrohen würde. Die ursächliche Kraft dieser Theorie des verstärkten substrategischen Konflikts ist die gegenseitige Anerkennung der Unhaltbarkeit von Konflikten auf der Ebene strategischer Interessen – ein Produkt der MAD [Mutually Assured Destruction]. Mit strategischen Interessen, die die "rote Linie" bilden, wäre es nicht ehrgeizig, die politischen Ziele durch den militärisierten Konflikt zu verfolgen, ohne dass die Bedingungen eines solchen Konflikts über ihre Kontrolle hinausgehen und ihre strategischen Interessen gefährden. wirksam, mit dem Risiko einer unkontrollierten Eskalation werden die Nettokosten für die Konfliktbereitschaft gesenkt. Vermutungen Einer der wichtigsten Annahmen im Konzept der gegenseitigen Verwahrung und des Stabilitätsphänomens, da dies dazu führt, dass alle Akteure rational sind und dass diese Rationalität eine vollständige Zerstörung bedeutet. Insbesondere der zweite Teil der Annahme kann nicht unbedingt in der Real-Weltpolitik gegeben werden. Wenn es sich um eine demokratische Nation handelt, deren Führer glauben, dass sie nach dem Leben ausreichend besser sind als unser derzeitiges Leben, ist es für sie sinnvoll, alles in ihrer Macht zu tun, um so einen schnellen Übergang für möglichst viele Menschen zu erleichtern. Einige Atheisten haben diesen Zusammenhang zwischen bestimmten religiösen Überzeugungen und der Politik von Massenvernichtungswaffen hervorgehoben, um die wahrgenommenen Gefahren der demokratischen Gesellschaften zu erkennen. Siehe auch nukleare Frieden Minimale Abschreckungstheorie; Links