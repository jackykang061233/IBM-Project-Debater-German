Informationstechnologie (IT) ist der Einsatz von Computern zur Schaffung, Verarbeitung, Speicherung und Austausch aller Arten von elektronischen Daten und Informationen. IT wird in der Regel im Rahmen von Geschäftstätigkeiten im Gegensatz zu persönlichen oder Unterhaltungstechnologien verwendet. IT gilt als Teil der Informations- und Kommunikationstechnologien (IKT). Informationstechnologie (IT-System) ist in der Regel ein Informationssystem, ein Kommunikationssystem oder speziell ein Computersystem – einschließlich aller Hardware, Software und peripherer Ausrüstung –, das von einer begrenzten Gruppe von IT-Nutzern betrieben wird. Humans wurden gelagert, retrieving, manipulation und Kommunikation von Informationen, da die Sumerians in Mesopotamia Schreiben in etwa 3000 BC entwickelt haben. Jedoch hat die Begriff Informationstechnologie in ihrem modernen Sinne erstmals in einem 1958 veröffentlichten Artikel in der Harvard Business Review veröffentlicht; die Autoren Kristian J. Leavitt und Thomas L. Whisler gaben jedoch an, dass "die neue Technologie noch keinen einheitlichen Namen hat. Wir werden die Informationstechnologie (IT) nennen. Ihre Definition besteht aus drei Kategorien: Verfahren zur Verarbeitung, Anwendung statistischer und mathematischer Methoden auf die Entscheidungsfindung und die Simulation des höheren Denkens durch Computerprogramme. Der Begriff wird häufig als Synonym für Computer und Computernetze verwendet, umfasst aber auch andere Informationsaustauschtechnologien wie Fernsehen und Telefone. Mehrere Produkte oder Dienstleistungen innerhalb einer Wirtschaft sind mit der Informationstechnologie verbunden, darunter Computer-Hardware, Software, Elektronik, Halbleiter, Internet, Telecom-Ausrüstung und E-Commerce. Gestützt auf die eingesetzten Speicher- und Verarbeitungstechnologien ist es möglich, vier verschiedene Phasen der IT-Entwicklung zu unterscheiden: vormechanisch (3000 BC – 1450 AD), mechanische (1450-1840), elektromechanisch (1840-1940) und elektronische (1940–present). Dieser Artikel konzentriert sich auf den letzten Zeitraum (elektronisch). Geschichte von Computer-Technologiegeräten wurde für Tausende von Jahren verwendet, wahrscheinlich zunächst in Form einer großen Aufkleber. Der Antikythera-Mechanismus, der von Anfang des ersten Jahrhunderts BC ausgeht, gilt in der Regel als der früheste bekannte mechanische Analogcomputer und der frühe bekannte Mechanismus. Vergleichbare Geräte wurden in Europa bis zum 16. Jahrhundert nicht gefunden, und es war nicht bis 1645, dass der erste mechanische Rechner, der in der Lage ist, die vier grundlegenden arithmetischen Operationen durchzuführen, entwickelt wurde. Elektrocomputer, die entweder Relais oder Ventile verwenden, begannen in den frühen 1940er Jahren zu erscheinen. Die im Jahr 1941 fertiggestellte elektromechanische Zuse Z3 war der erste programmierbare Computer der Welt und mit modernen Standards einer der ersten Maschinen, die als komplette Rechenmaschine angesehen werden könnten. Coverlustus entwickelte im Zweiten Weltkrieg den ersten elektronischen Computer, um deutsche Nachrichten zu entschlüsseln. Obwohl es programmierbar war, war es nicht allgemein sinnvoll, nur eine einzige Aufgabe zu erfüllen. Es fehlte auch an der Fähigkeit, sein Programm in Erinnerung zu speichern; die Programmierung wurde mit Steckern und Schaltern durchgeführt, um die internen Verkabelungen zu ändern. Der erste anerkannte moderne elektronische Speichercomputer war das Manchester Baby, das sein erstes Programm am 21. Juni 1948 lief. In den späten 1940er Jahren ermöglichte die Entwicklung von Transisten in Bell Laboratories eine neue Generation von Computern, die mit einem deutlich geringeren Stromverbrauch konzipiert werden können. Der erste kommerziell verfügbare Computer, der Ferranti Mark I, enthielt 4050 Ventile und hatte einen Stromverbrauch von 25 Kilowatt. Vergleichsweise verbrauchte der erste transistorisierte Computer, der auf der Universität Manchester entwickelt wurde und bis November 1953 betriebsbereit ist, in seiner endgültigen Fassung nur 150 Kilowatt. Mehrere andere bahnbrechende Halbleitertechniken umfassen den integrierten Schaltkreis (IC), der von Jack Kilby in Texas Instruments und Robert Noyce im Jahr 1959 bei Fairchild Semiconductor, dem Metalloxide-Semiconductor Feld-Effekt-Tistor (MOSFET) entwickelt wurde, der von Mohamed Atalla und Dawon Kahng in Bell Laboratories im Jahr 1959 entwickelt wurde, und den Mikroprozessor, der von Ted Hoff, Federico Faggin, Masatoshi Shima und Stanley Mazor im Jahr 1971 entwickelt wurde. Diese wichtigen Erfindungen führten in den siebziger Jahren zur Entwicklung des persönlichen Computers (PC) und zur Entwicklung der Informations- und Kommunikationstechnologien (IKT). Elektronische Datenverarbeitung Datenspeicherung frühe elektronische Computer wie Coverlustus nutzte die Verwendung von gestreckten Maschinen, ein langes Papier, auf dem Daten durch eine Reihe von Löchern vertreten sind, eine Technologie, die nun veraltet ist. Elektronische Datenspeicherung, die in modernen Computern verwendet wird, stammt aus dem Zweiten Weltkrieg, wenn eine Form von Verzögerungsspeichern entwickelt wurde, um das Schwergewicht von Radarsignalen zu entfernen, deren erste praktische Anwendung die Quecksilber-Verschiebungslinie war. Das erste zufällig zugängliche digitale Speichergerät war das Williamsrohr, das auf einem Standard-Kathode-rayrohr basiert, aber die in ihm gespeicherten Informationen und die verspätete Netzspeicher waren unzufrieden, da es ständig auffrischt werden musste und somit verloren ging, nachdem die Macht entfernt wurde. Die früheste Form der nicht-volatile Computerspeicher war die Magnetfälschung, die im Jahr 1957 entwickelt wurde und in der Ferranti Mark 1 verwendet wurde, der weltweit erste kommerziell nutzbare elektronische Computer. IBM hat im Jahr 1956 die erste Festplattenantriebe eingeführt, die Teil ihres 305 RAMAC-Computersystems ist. Die meisten digitalen Daten werden heute immer noch auf Festplatten gespeichert, oder auf Medien wie CD-ROMs. Bis 2002 wurden die meisten Informationen auf analogen Geräten gespeichert, aber dieses Jahr hat die digitale Speicherkapazität zum ersten Mal analog überschritten. 2007 wurden fast 94 % der weltweit gespeicherten Daten digital gehalten: 52 % auf Festplatten, 28% auf optischen Geräten und 11 % auf dem digitalen Magnetband. Schätzungen zufolge stieg die weltweite Kapazität, Informationen über elektronische Geräte zu speichern, von weniger als 3 Exabyte im Jahr 1986 auf 295 Exabyte im Jahr 2007, was etwa alle 3 Jahre verdoppelt. Datenbanken (DMS) sind in den 60er Jahren entstanden, um das Problem der Speicherung und Rückführung großer Datenmengen genau und schnell anzugehen. Ein frühes solches System war das Informationsmanagement von IBM (IMS), das noch mehr als 50 Jahre später weit verbreitet ist. IMS speichert hierarchisch Daten, aber in den 1970er Jahren schlug Ted Kabeljau ein alternatives System für die Speicherung vor, das auf einer bestimmten Theorie und prädikativen Logik und den vertrauten Konzepten von Tabellen, Reihen und Spalten beruht. 1981 wurde das erste kommerziell verfügbare System zur Verwaltung von Datenbanken (RDBMS) von Oracle freigegeben. All DMS besteht aus Komponenten, die es ermöglichen, die Daten, die sie speichern, gleichzeitig von vielen Nutzern zugänglich zu machen und gleichzeitig ihre Integrität zu wahren. Alle Datenbanken sind in einem Punkt üblich, dass die Struktur der darin enthaltenen Daten in einem Datenbankschema definiert und getrennt von den Daten selbst gespeichert wird. In den letzten Jahren ist die extensible Markup-Sprache (XML) zu einem populären Format für die Datenvertretung geworden. XML-Daten können zwar in normalen Dateisystemen gespeichert werden, werden jedoch häufig in Datenbanken gespeichert, um ihre „benachteiligte Umsetzung, die nach Jahren theoretischer und praktischer Anstrengungen überprüft wird, zu nutzen“. Als Weiterentwicklung der Standard-allgemeinisierten Markup Language (SGML) bietet die auf dem Text basierende Struktur von XML den Vorteil, sowohl maschinell als auch humanibel zu sein. Datenabruf In der Datenbank wurde ein programmbezogenes unabhängiges, eigenständige, strukturiertes Abfragen (Parameter) eingeführt, das auf der Grundlage von Interalal Al basiert. Daten und Informationen sind nicht gleich. Jedes gespeicherte Produkt ist Daten, aber es wird nur Informationen, wenn es organisiert und sinnvoll präsentiert wird. Die meisten digitalen Daten der Welt sind unstrukturiert und in einer Vielzahl unterschiedlicher physischer Formate auch innerhalb einer einzigen Organisation gespeichert. Datenlager wurden in den 80er Jahren entwickelt, um diese Disparategeschäfte zu integrieren. Sie enthalten in der Regel aus verschiedenen Quellen gewonnene Daten, einschließlich externer Quellen wie dem Internet, die so organisiert sind, um Entscheidungshilfesysteme (DSS) zu erleichtern. Datenübermittlung hat drei Aspekte: Übertragung, propagation und Empfang. Man kann als Rundfunk weitestgehend kategorisiert werden, in dem Informationen einseitig nachgelagert oder Telekommunikation mit bidirektionalen vor- und nachgelagerten Kanälen übermittelt werden. XML wurde seit Anfang 2000 zunehmend als Mittel für den Datenaustausch eingesetzt, insbesondere für maschinenlesbare Interaktionen wie diejenigen, die an netzorientierten Protokollen wie SOAP beteiligt sind, die "Daten-in-transit" beschreiben und nicht. Datenmanipulation Hilbert und Lopez erkennen das exponentielle Tempo des technologischen Wandels (eine Art von Moore's Law): Maschinenspezifische Kapazität zur Berechnung von Informationen pro Kopf um etwa 14 Monate zwischen 1986 und 2007; die Pro-Kopf-Kapazität der allgemeinen Computer der Welt verdoppelte sich alle 18 Monate in den gleichen zwei Jahrzehnten; die globale Telekommunikationskapazität pro Kopf verdoppelte sich alle 34 Monate; die Speicherkapazität der Welt erfordert rund 40 Monate bis doppelt (alle 3 Jahre); und die pro-Kopf-Übertragung hat alle 12 Jahre. massive Datenmengen werden täglich weltweit gespeichert, es sei denn, sie können analysiert und wirksam präsentiert werden, wenn sie im Wesentlichen in den sogenannten Datensammlungen liegen: "Datenarchive, die selten besucht werden". Um dieses Problem anzugehen, wurde in den späten 80er Jahren der Bereich des Data Mining – „der Prozess der Entdeckung interessanter Muster und Kenntnisse großer Datenmengen“ herauskristallisiert. Perspektiven der akademischen Perspektive In einem akademischen Zusammenhang definiert der Verband für Computermaschinen IT als "Untergraduierten" Programme, die Studenten auf die Bedürfnisse von Unternehmen, Regierungen, Gesundheitswesen, Schulen und anderen Organisationen vorbereiten. IT-Fachleute übernehmen die Verantwortung für die Auswahl von Hardware- und Softwareprodukten, die für eine Organisation geeignet sind, die Integration dieser Produkte mit organisatorischen Bedürfnissen und Infrastrukturen, die Installation, die Standardisierung und die Aufrechterhaltung dieser Anwendungen für die Computernutzer der Organisation." Konkret haben sie oft dieselben grundlegenden Kurse. Computerwissenschaften (CS) Programme konzentrieren sich tendenziell stärker auf Theorie und Design, während die Programme für Informationstechnologie strukturiert sind, um den Hochschulabsolventen Fachwissen bei der praktischen Anwendung von Technologielösungen zur Unterstützung moderner Geschäfts- und Nutzerbedürfnisse zu vermitteln. Unternehmen aus kommerzieller und beschäftigungspolitischer Sicht im Bereich der Informationstechnologie werden häufig als Gruppe als "Tech-Sektor" oder als "Tech-Industrie" diskutiert. Diese Titel können jederzeit irreführend sein und sollten nicht für „Tech-Unternehmen“ irreführend sein; dies ist in der Regel groß, für gemeinnützige Unternehmen, die Verbrauchertechnik und Software verkaufen. Man sollte auch wissen, dass aus geschäftlicher Sicht die Dienste der Informationstechnologie ein „Kostenzentrum“ sind, das die meisten Zeit ist. Ein Kostenzentrum ist eine Abteilung oder ein Personal, das in einem Unternehmen Ausgaben oder „Kosten“ verursacht, anstatt Gewinne oder Einnahmen zu erzielen. moderne Unternehmen setzen sich in hohem Maße auf die Technologie für ihre täglichen Operationen ein, so dass die Kosten, die zur Deckung von Technologien, die Unternehmen in effizienterer Weise erleichtern, in der Regel als „gerecht die Kosten für das Geschäft“ angesehen werden. IT-Abteilungen werden von der höheren Führungsposition zugewiesen und müssen versuchen, die gewünschten Leistungen zu erreichen, während sie in diesem Haushalt bleiben. Regierung und Privatsektor könnten unterschiedliche Finanzierungsmechanismen haben, aber die Grundsätze sind mehr oder weniger gleich. Dies ist ein oft übersehener Grund für das schnelle Interesse an Automatisierung und künstlicher Intelligenz, aber der konstante Druck, mehr mit weniger zu tun, öffnet die Tür zur Automatisierung, um mindestens einige kleinere Operationen in großen Unternehmen zu kontrollieren. Viele Unternehmen verfügen nun über IT-Abteilungen für die Verwaltung der Computer, Netze und andere technische Bereiche ihrer Unternehmen. Unternehmen haben auch versucht, IT mit Geschäftsergebnissen und Entscheidungsprozessen durch eine BizOps oder eine Geschäftsabteilung zu integrieren. In einem wirtschaftlichen Kontext hat die International Information Technology Association of America die Informationstechnologie als "Studie, Design, Entwicklung, Anwendung, Unterstützung oder Verwaltung computergestützter Informationssysteme" definiert. Zu den Aufgaben, die in diesem Bereich tätig sind, gehören die Netzverwaltung, Softwareentwicklung und -installation sowie die Planung und Verwaltung des Technologielebenszyklus einer Organisation, durch den Hardware und Software erhalten, modernisiert und ersetzt werden. Informationsdienste Informationsdienste sind ein Begriff, der für eine Vielzahl von IT-bezogenen Dienstleistungen, die von kommerziellen Unternehmen angeboten werden, sowie Datenmakler leicht anwendbar ist. Ethical Perspektiven In den 1940er Jahren wurde der Bereich der Informationsethik von mathematician Norbert Wiener geschaffen. Manche ethische Fragen im Zusammenhang mit der Nutzung der Informationstechnologie umfassen: urheberrechtlich geschützte Dateien, die ohne Erlaubnis der Inhaber von Urheberrechten gespeichert sind, überwachen ihre E-Mails und andere Internet-Nutzung unerbetene E-Mails Hacker auf Online-Datenbanken Websites, die Cookies oder pädagogische Geräte installieren, um Online-Aktivitäten der Nutzer zu überwachen, die möglicherweise von Datenmaklern genutzt werden können Lesen Sie auch die Citations Literatur Weitere Lesen Allen, T; Morton, M. S. Morton, eds. (1994), Informationstechnologie und die Corporation der 90er Jahre, Oxford University Press Gitta, Cosmas und South, David (2011). Südliche Innovationen Magazin Ausgabe 1: Handys und Informationstechnologie: Amt der Vereinten Nationen für Süd-Süd-Zusammenarbeit. ISSN 2222-9280 Gleick, James (2011). Information: Eine Geschichte, eine Theorie, ein Hochwasser. New York: Pantheon Bücher.Preis, Wilson T. 1981, Einführung in Computerdatenverarbeitung, Holt-Saunders International Editions, ISBN @4-8337-0012-2 Shelly, Gary, Cashman, Thomas, Vermaat, Misty und Walker, Tim. (1999). Computer 2000: Konzepte für eine vernetzte Welt. Cambridge, Massachusetts: Kurstechnik. Webster, Frank und Robins, Kevin. Informationstechnologie – Eine Luddite-Analyse. Norwood, NJ: Ablex. Externe Links Lernmaterialien im Zusammenhang mit der Informationstechnologie bei Wikiversity Media im Zusammenhang mit der Informationstechnologie bei der Quoten für die Informationstechnologie bei Wikilist